{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 36861,
     "status": "ok",
     "timestamp": 1733216742525,
     "user": {
      "displayName": "Pietro Corrieri",
      "userId": "06910475198903735173"
     },
     "user_tz": -60
    },
    "id": "7dpLaARRw7ji",
    "outputId": "7ffd61bd-e397-4694-8219-2c9906030238"
   },
   "outputs": [],
   "source": [
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')\n",
    "\n",
    "# %cd drive/MyDrive/ST/stargan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 8109,
     "status": "ok",
     "timestamp": 1733216750630,
     "user": {
      "displayName": "Pietro Corrieri",
      "userId": "06910475198903735173"
     },
     "user_tz": -60
    },
    "id": "LrS5ZMgU2kpq",
    "outputId": "8f1a5205-b538-42c2-cbf9-69c2b426db63"
   },
   "outputs": [],
   "source": [
    "from core.TSTR_scores_da.TSTR_scores import *\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "seed = 2710\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed(seed)\n",
    "np.random.seed(seed)\n",
    "random.seed(seed)\n",
    "\n",
    "\n",
    "dataset_name = 'realworld_mobiact'\n",
    "syn_name = 'syn'\n",
    "\n",
    "num_epochs = 1\n",
    "num_runs = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 180036,
     "status": "ok",
     "timestamp": 1733216930662,
     "user": {
      "displayName": "Pietro Corrieri",
      "userId": "06910475198903735173"
     },
     "user_tz": -60
    },
    "id": "YqD9RDOHw7ju",
    "outputId": "b17ecd7b-c0b0-4f14-b1ba-9a377b27e976"
   },
   "outputs": [],
   "source": [
    "compute_TSTR_Dp(dataset_name, num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 718724,
     "status": "ok",
     "timestamp": 1733217649381,
     "user": {
      "displayName": "Pietro Corrieri",
      "userId": "06910475198903735173"
     },
     "user_tz": -60
    },
    "id": "NK2FDwLR2kpr",
    "outputId": "f5ee0363-d81e-4e6d-c441-4dbed61b8a88"
   },
   "outputs": [],
   "source": [
    "compute_TSTR_Df(dataset_name, num_epochs, num_runs, augment=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 889076,
     "status": "ok",
     "timestamp": 1733218538451,
     "user": {
      "displayName": "Pietro Corrieri",
      "userId": "06910475198903735173"
     },
     "user_tz": -60
    },
    "id": "GqQIX8orw7jx",
    "outputId": "dee41b95-0ee8-46cd-f06e-c38729a19b1b"
   },
   "outputs": [],
   "source": [
    "compute_TSTR_Df(dataset_name, num_epochs, num_runs, augment=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 1498291,
     "status": "ok",
     "timestamp": 1733220036729,
     "user": {
      "displayName": "Pietro Corrieri",
      "userId": "06910475198903735173"
     },
     "user_tz": -60
    },
    "id": "rmj6emYPw7jy",
    "outputId": "1912508f-b5e1-4788-c53b-2bad3913556d"
   },
   "outputs": [],
   "source": [
    "compute_TSTR_Syn(dataset_name, syn_name, num_epochs, num_runs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compute_TSTR_CORAL(dataset_name, num_epochs, num_runs, augment=False, coral_weight=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compute_TSTR_CORAL(dataset_name, num_epochs, num_runs, augment=True, coral_weight=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Result visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from tabulate import tabulate\n",
    "\n",
    "# Define datasets, experiment names, and expected filenames\n",
    "experiment_names = [\"Df\", \"Df_aug\", \"Syn\", \"Dp\", \"CORAL\", \"CORAL_aug\"]\n",
    "required_files = [f\"{dataset_name}_{experiment}.csv\" for experiment in experiment_names]\n",
    "\n",
    "# Directory containing the result files\n",
    "results_dir = \"results_prova\"\n",
    "\n",
    "# Check for missing files\n",
    "missing_files = [file for file in required_files if not os.path.isfile(os.path.join(results_dir, file))]\n",
    "\n",
    "# Print results\n",
    "if missing_files:\n",
    "    print(\"The following files are missing:\")\n",
    "    for file in missing_files:\n",
    "        print(file)\n",
    "else:\n",
    "    print(\"All required files are present.\\n\")\n",
    "\n",
    "def create_summary_csv(dataset, results_dir=\"results\"):\n",
    "    \n",
    "    # Dictionary to store data for each source across experiments and modes\n",
    "    data_acc = {}\n",
    "    data_f1 = {}\n",
    "    data_loss = {}\n",
    "    \n",
    "    for experiment in experiment_names:\n",
    "        file_path = os.path.join(results_dir, f\"{dataset}_{experiment}.csv\")\n",
    "        if os.path.isfile(file_path):\n",
    "            # Read the file\n",
    "            df = pd.read_csv(file_path)[['accuracy', 'f1', 'loss']]\n",
    "            # Compute average values\n",
    "            data_acc[experiment] = df['accuracy'].mean()\n",
    "            data_f1[experiment] = df['f1'].mean()\n",
    "            data_loss[experiment] = df['loss'].mean()\n",
    "    \n",
    "    # Combine all data into a single DataFrame\n",
    "    summary = pd.DataFrame([data_acc, data_f1, data_loss], index=['accuracy', 'f1', 'loss'])\n",
    "    \n",
    "    # Display the summary using tabulate\n",
    "    print(tabulate(summary.round(2), headers='keys', tablefmt='pretty'))\n",
    "\n",
    "create_summary_csv(dataset_name, results_dir)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
