{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from torch.optim.lr_scheduler import LambdaLR\n",
    "import torch.optim as optim\n",
    "import os\n",
    "import csv\n",
    "import random\n",
    "import copy\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "seed = 2710\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed(seed)\n",
    "np.random.seed(seed)\n",
    "random.seed(seed)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(22599, 3, 128) (22599,) (22599,) (22599,)\n"
     ]
    }
   ],
   "source": [
    "with open('data/realworld_mobiact.pkl', 'rb') as f:\n",
    "    x, y, k = pickle.load(f)\n",
    "with open('data/realworld_mobiact_fs.pkl', 'rb') as f:\n",
    "    fs = pickle.load(f)\n",
    "\n",
    "print(x.shape, y.shape, k.shape, fs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11783, 3, 128) (11783,) (11783,) (11783,)\n",
      "(10816, 3, 128) (10816,) (10816,) (10816,)\n"
     ]
    }
   ],
   "source": [
    "mask_rw = (k < 15)\n",
    "mask_ma = (k >= 15)\n",
    "\n",
    "x_rw, y_rw, k_rw, fs_rw = x[mask_rw], y[mask_rw], k[mask_rw], fs[mask_rw]\n",
    "x_ma, y_ma, k_ma, fs_ma = x[mask_ma], y[mask_ma], k[mask_ma], fs[mask_ma]\n",
    "\n",
    "print(x_rw.shape, y_rw.shape, k_rw.shape, fs_rw.shape)\n",
    "print(x_ma.shape, y_ma.shape, k_ma.shape, fs_ma.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8652, 3, 128) (8652,)\n",
      "(2164, 3, 128) (2164,)\n"
     ]
    }
   ],
   "source": [
    "x_ma_train, x_ma_test, y_ma_train, y_ma_test = train_test_split(x_ma, y_ma, test_size=0.2, random_state=seed, stratify=y_ma, shuffle=True)\n",
    "\n",
    "print(x_ma_train.shape, y_ma_train.shape)\n",
    "print(x_ma_test.shape, y_ma_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TSTRClassifier(nn.Module):\n",
    "    def __init__(self, num_timesteps=128, num_channels=3, num_classes=4):\n",
    "        super(TSTRClassifier, self).__init__()\n",
    "\n",
    "        self.conv1 = nn.Conv1d(num_channels, 16, kernel_size=5, stride=1, padding=2)\n",
    "        self.bn1 = nn.BatchNorm1d(16)\n",
    "        self.conv2 = nn.Conv1d(16, 32, kernel_size=5, stride=1, padding=2)\n",
    "        self.bn2 = nn.BatchNorm1d(32)\n",
    "        self.conv3 = nn.Conv1d(32, 64, kernel_size=5, stride=1, padding=2)\n",
    "        self.bn3 = nn.BatchNorm1d(64)\n",
    "        self.conv4 = nn.Conv1d(64, 128, kernel_size=5, stride=1, padding=2)\n",
    "        self.bn4 = nn.BatchNorm1d(128)\n",
    "        self.pool = nn.MaxPool1d(kernel_size=2, stride=2)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.dropout = nn.Dropout(p=0.25)\n",
    "\n",
    "        self.fc_shared = nn.Linear(num_timesteps * 8, 100)\n",
    "\n",
    "        self.fc_class = nn.Linear(100, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(self.relu(self.bn1(self.conv1(x))))\n",
    "        x = self.pool(self.relu(self.bn2(self.conv2(x))))\n",
    "        x = self.pool(self.relu(self.bn3(self.conv3(x))))\n",
    "        x = self.pool(self.relu(self.bn4(self.conv4(x))))\n",
    "        x = x.view(x.size(0), -1)  # Flatten\n",
    "        x = self.dropout(x)\n",
    "        x = self.relu(self.fc_shared(x))\n",
    "\n",
    "        # Final output for class prediction\n",
    "        class_outputs = self.fc_class(x)\n",
    "        return class_outputs\n",
    "\n",
    "\n",
    "def train_model(model, train_loader, val_loader, optimizer, num_epochs=100, augment=False):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model.to(device)\n",
    "\n",
    "    loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "    loss_train = []\n",
    "    loss_val = []\n",
    "    accuracy_val = []\n",
    "    best_model_state = None\n",
    "    best_loss = np.inf\n",
    "    best_accuracy = 0\n",
    "    best_f1 = 0\n",
    "\n",
    "    # Set up linear learning rate decay\n",
    "    lambda_lr = lambda epoch: 1 - epoch / num_epochs\n",
    "    scheduler = LambdaLR(optimizer, lr_lambda=lambda_lr)\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        total_loss = 0\n",
    "        for x_batch, y_batch in train_loader:\n",
    "            x_batch, y_batch = x_batch.to(device), y_batch.to(device)\n",
    "            # if augment:\n",
    "                # x_batch, _ = augment_batch(x_batch)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(x_batch)\n",
    "            loss = loss_fn(outputs, y_batch)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_loss += loss.item()\n",
    "        total_loss /= len(train_loader)\n",
    "        loss_train.append(total_loss)\n",
    "\n",
    "        # Update learning rate\n",
    "        scheduler.step()\n",
    "\n",
    "        val_accuracy, val_loss, val_f1 = evaluate_model(model, val_loader)\n",
    "        if val_loss < best_loss:\n",
    "            best_epoch = epoch\n",
    "            best_accuracy = val_accuracy\n",
    "            best_f1 = val_f1\n",
    "            best_loss = val_loss\n",
    "            best_model_state = model.state_dict().copy()\n",
    "\n",
    "        loss_val.append(val_loss)\n",
    "        accuracy_val.append(val_accuracy)\n",
    "\n",
    "        current_lr = scheduler.get_last_lr()[0]\n",
    "        if (epoch+1) % 10 == 0:\n",
    "            print(f\"\\tEpoch {epoch + 1}/{num_epochs} - Train loss: {total_loss:.4f} - Val accuracy: {val_accuracy:.4f} - Val loss: {val_loss:.4f} - Val F1: {val_f1:.4f} - LR: {current_lr:.2e}\")\n",
    "\n",
    "    print(f\"\\tBest epoch: {best_epoch + 1} - Best val accuracy: {best_accuracy:.4f} - Best val loss: {best_loss:.4f} - Best val F1: {best_f1:.4f}\\n\")\n",
    "\n",
    "    # Load best model state\n",
    "    model.load_state_dict(best_model_state)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = TSTRClassifier()\n",
    "\n",
    "train_model()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "stargan-v2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
