{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 26439,
     "status": "ok",
     "timestamp": 1732616544319,
     "user": {
      "displayName": "Pietro Cirino",
      "userId": "07315473796200699505"
     },
     "user_tz": -60
    },
    "id": "I0_1KsKpCPtk",
    "outputId": "b6d31f1a-3ebf-4aa8-8c49-9ed100d6f0ac"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n",
      "/content/drive/MyDrive/ST/stargan\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "%cd drive/MyDrive/ST/stargan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lLVVBGiQmD5W"
   },
   "source": [
    "# Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "executionInfo": {
     "elapsed": 6661,
     "status": "ok",
     "timestamp": 1732616550978,
     "user": {
      "displayName": "Pietro Cirino",
      "userId": "07315473796200699505"
     },
     "user_tz": -60
    },
    "id": "yh05UGFkCPtm"
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from torch.optim.lr_scheduler import LambdaLR\n",
    "import torch.optim as optim\n",
    "import os\n",
    "import csv\n",
    "import random\n",
    "import copy\n",
    "\n",
    "seed = 2710\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed(seed)\n",
    "np.random.seed(seed)\n",
    "random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1732616550978,
     "user": {
      "displayName": "Pietro Cirino",
      "userId": "07315473796200699505"
     },
     "user_tz": -60
    },
    "id": "UJN2bKbaCPtm"
   },
   "outputs": [],
   "source": [
    "config = {\n",
    "    'realworld': {\n",
    "        'dataset_name': 'realworld',\n",
    "        'num_df_domains': 10,\n",
    "        'num_dp_domains': 5,\n",
    "        'num_classes': 4,\n",
    "        'class_names': ['WAL', 'RUN', 'CLD', 'CLU'],\n",
    "        'num_timesteps': 128,\n",
    "        'num_channels': 3,\n",
    "        'num_classes': 4,\n",
    "    },\n",
    "    'cwru': {\n",
    "        'dataset_name': 'cwru_256_3ch_5cl',\n",
    "        'num_df_domains': 4,\n",
    "        'num_dp_domains': 4,\n",
    "        'num_classes': 5,\n",
    "        'class_names': ['IR', 'Ball', 'OR_centred', 'OR_orthogonal', 'OR_opposite'],\n",
    "        'num_timesteps': 256,\n",
    "        'num_channels': 3,\n",
    "        'num_classes': 5,\n",
    "    },\n",
    "    'realworld_mobiact': {\n",
    "        'dataset_name': 'realworld_mobiact',\n",
    "        'num_df_domains': 15,\n",
    "        'num_dp_domains': 61,\n",
    "        'num_classes': 4,\n",
    "        'class_names': ['WAL', 'RUN', 'CLD', 'CLU'],\n",
    "        'num_timesteps': 128,\n",
    "        'num_channels': 3,\n",
    "        'num_classes': 4,\n",
    "    }\n",
    "}\n",
    "\n",
    "syn_name = 'rwma11'\n",
    "num_epochs = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1732616550979,
     "user": {
      "displayName": "Pietro Cirino",
      "userId": "07315473796200699505"
     },
     "user_tz": -60
    },
    "id": "XwSwaF-LCPtn"
   },
   "outputs": [],
   "source": [
    "def get_data(dataset, domains_set, src_class, domain=None, rot=False):\n",
    "    # Load configurations\n",
    "    dataset_name = config[dataset]['dataset_name']\n",
    "    class_idx = config[dataset]['class_names'].index(src_class)\n",
    "    num_df_domains = config[dataset]['num_df_domains']\n",
    "\n",
    "    if rot:\n",
    "        dataset_name += '_rot'\n",
    "\n",
    "    try:\n",
    "        with open(f'data/{dataset_name}.pkl', 'rb') as f:\n",
    "            x, y, k = pickle.load(f)\n",
    "        with open(f'data/{dataset_name}_fs.pkl', 'rb') as f:\n",
    "            fs = pickle.load(f)\n",
    "    except FileNotFoundError:\n",
    "        raise FileNotFoundError(f\"Dataset files for {dataset} not found.\")\n",
    "\n",
    "\n",
    "    if domains_set == 'df':\n",
    "        mask = (y != class_idx) & (k < num_df_domains)\n",
    "    elif domains_set == 'dp':\n",
    "        mask = (y != class_idx) & (k >= num_df_domains) & (fs == 0)\n",
    "    elif domains_set == 'dpfs':\n",
    "        mask = (y != class_idx) & (k >= num_df_domains) & (fs == 1)\n",
    "    else:\n",
    "        raise ValueError(f\"Invalid domains set: {domains_set}\")\n",
    "\n",
    "    # Apply initial mask\n",
    "    x, y, k = x[mask], y[mask], k[mask]\n",
    "\n",
    "    # Additional domain filtering if specified\n",
    "    if domain is not None:\n",
    "        domain_mask = (k == domain)\n",
    "        x, y, k = x[domain_mask], y[domain_mask], k[domain_mask]\n",
    "\n",
    "    assert len(x) > 0, f\"No data found\"\n",
    "    assert len(x) == len(y) == len(k), f\"Data length mismatch\"\n",
    "\n",
    "    return x, y, k\n",
    "\n",
    "\n",
    "\n",
    "def get_syn_data(dataset, syn_name, src_class, domain=None, fs=False):\n",
    "    # Load configurations\n",
    "    class_names = config[dataset]['class_names']\n",
    "\n",
    "    try:\n",
    "        with open(f'data/{dataset}_{syn_name}.pkl', 'rb') as f:\n",
    "            x, y, k = pickle.load(f)\n",
    "    except FileNotFoundError:\n",
    "        raise FileNotFoundError(f\"Dataset files for {dataset} not found.\")\n",
    "\n",
    "    with open(f'data/{dataset}_{syn_name}_fs.pkl', 'rb') as f:\n",
    "        fs = pickle.load(f)\n",
    "\n",
    "    x, y, k = x[fs == 0], y[fs == 0], k[fs == 0]\n",
    "\n",
    "    if domain is not None:\n",
    "        domain_mask = (k == domain)\n",
    "        x, y, k = x[domain_mask], y[domain_mask], k[domain_mask]\n",
    "\n",
    "    assert len(x) > 0, f\"No data found\"\n",
    "    assert len(x) == len(y) == len(k), f\"Data length mismatch\"\n",
    "\n",
    "    return x, y, k\n",
    "\n",
    "\n",
    "\n",
    "class TSTRClassifier(nn.Module):\n",
    "    def __init__(self, num_timesteps=128, num_channels=3, num_classes=5):\n",
    "        super(TSTRClassifier, self).__init__()\n",
    "\n",
    "        self.conv1 = nn.Conv1d(num_channels, 16, kernel_size=5, stride=1, padding=2)\n",
    "        self.bn1 = nn.BatchNorm1d(16)\n",
    "        self.conv2 = nn.Conv1d(16, 32, kernel_size=5, stride=1, padding=2)\n",
    "        self.bn2 = nn.BatchNorm1d(32)\n",
    "        self.conv3 = nn.Conv1d(32, 64, kernel_size=5, stride=1, padding=2)\n",
    "        self.bn3 = nn.BatchNorm1d(64)\n",
    "        self.conv4 = nn.Conv1d(64, 128, kernel_size=5, stride=1, padding=2)\n",
    "        self.bn4 = nn.BatchNorm1d(128)\n",
    "        self.pool = nn.MaxPool1d(kernel_size=2, stride=2)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.dropout = nn.Dropout(p=0.25)\n",
    "\n",
    "        self.fc_shared = nn.Linear(num_timesteps * 8, 100)\n",
    "\n",
    "        self.fc_class = nn.Linear(100, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(self.relu(self.bn1(self.conv1(x))))\n",
    "        x = self.pool(self.relu(self.bn2(self.conv2(x))))\n",
    "        x = self.pool(self.relu(self.bn3(self.conv3(x))))\n",
    "        x = self.pool(self.relu(self.bn4(self.conv4(x))))\n",
    "        x = x.view(x.size(0), -1)  # Flatten\n",
    "        x = self.dropout(x)\n",
    "        x = self.relu(self.fc_shared(x))\n",
    "\n",
    "        # Final output for class prediction\n",
    "        class_outputs = self.fc_class(x)\n",
    "        return class_outputs\n",
    "\n",
    "\n",
    "\n",
    "def remap_labels(y):\n",
    "    label_map = {clss: i for i, clss in enumerate(np.unique(y))}\n",
    "    return np.array([label_map[clss] for clss in y])\n",
    "\n",
    "\n",
    "\n",
    "def get_dataloader(x, y, shuffle=False):\n",
    "    x = torch.tensor(x, dtype=torch.float32)\n",
    "    y = remap_labels(y)\n",
    "    y = torch.tensor(y, dtype=torch.long)\n",
    "\n",
    "    # Determine dataset size and batch size\n",
    "    dataset_size = len(x)\n",
    "    if dataset_size <= 100:\n",
    "        batch_size = dataset_size\n",
    "    elif dataset_size <= 1000:\n",
    "        batch_size = 16\n",
    "    elif dataset_size <= 5000:\n",
    "        batch_size = 32\n",
    "    else:\n",
    "        batch_size = 64\n",
    "\n",
    "    dataset = TensorDataset(x, y)\n",
    "    loader = DataLoader(dataset, batch_size=batch_size, shuffle=shuffle)\n",
    "\n",
    "    return loader\n",
    "\n",
    "\n",
    "def random_rotation_matrix():\n",
    "    \"\"\"Generate a random rotation matrix from a predefined set of quaternions.\"\"\"\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    # Randomly generate a quaternion\n",
    "    q = np.random.rand(4)\n",
    "\n",
    "    # Convert quaternion to rotation matrix\n",
    "    q = torch.tensor(q, device=device, dtype=torch.float32)\n",
    "    q = q / torch.norm(q)  # Normalize quaternion\n",
    "    q0, q1, q2, q3 = q\n",
    "\n",
    "    R = torch.tensor([\n",
    "        [1 - 2*q2**2 - 2*q3**2, 2*q1*q2 - 2*q3*q0, 2*q1*q3 + 2*q2*q0],\n",
    "        [2*q1*q2 + 2*q3*q0, 1 - 2*q1**2 - 2*q3**2, 2*q2*q3 - 2*q1*q0],\n",
    "        [2*q1*q3 - 2*q2*q0, 2*q2*q3 + 2*q1*q0, 1 - 2*q1**2 - 2*q2**2]\n",
    "    ], device=device, dtype=torch.float32)\n",
    "\n",
    "    return R, q\n",
    "\n",
    "\n",
    "def augment_batch(x_real):\n",
    "    \"\"\"Apply random rotation to the batch of real time series.\"\"\"\n",
    "    min_val, max_val = -19.61, 19.61\n",
    "    x_real = x_real * (max_val - min_val) + min_val  # De-normalize\n",
    "    R, q = random_rotation_matrix()\n",
    "    x_real = torch.matmul(R, x_real)  # Apply rotation\n",
    "    x_real = (x_real - min_val) / (max_val - min_val)  # Re-normalize\n",
    "    return x_real, q\n",
    "\n",
    "\n",
    "\n",
    "def evaluate_model(model, test_loader):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "\n",
    "    loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "    total_loss = 0\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for x_batch, y_batch in test_loader:\n",
    "            x_batch, y_batch = x_batch.to(device), y_batch.to(device)\n",
    "            outputs = model(x_batch)\n",
    "            loss = loss_fn(outputs, y_batch)\n",
    "            total_loss += loss.item()\n",
    "\n",
    "            _, predicted_labels = torch.max(outputs, 1)\n",
    "            all_preds.extend(predicted_labels.detach().cpu().numpy())\n",
    "            all_labels.extend(y_batch.detach().cpu().numpy())\n",
    "\n",
    "    all_labels = np.array(all_labels)\n",
    "    all_preds = np.array(all_preds)\n",
    "    accuracy = accuracy_score(all_labels, all_preds)\n",
    "    f1 = f1_score(all_labels, all_preds, average='weighted')\n",
    "    total_loss /= len(test_loader)\n",
    "\n",
    "    return accuracy, total_loss, f1\n",
    "\n",
    "\n",
    "\n",
    "def train_model(model, train_loader, val_loader, optimizer, num_epochs=100, augment=False):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model.to(device)\n",
    "\n",
    "    loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "    loss_train = []\n",
    "    loss_val = []\n",
    "    accuracy_val = []\n",
    "    best_model_state = None\n",
    "    best_loss = np.inf\n",
    "    best_accuracy = 0\n",
    "    best_f1 = 0\n",
    "\n",
    "    # Set up linear learning rate decay\n",
    "    lambda_lr = lambda epoch: 1 - epoch / num_epochs\n",
    "    scheduler = LambdaLR(optimizer, lr_lambda=lambda_lr)\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        total_loss = 0\n",
    "        for x_batch, y_batch in train_loader:\n",
    "            x_batch, y_batch = x_batch.to(device), y_batch.to(device)\n",
    "            if augment:\n",
    "                x_batch, _ = augment_batch(x_batch)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(x_batch)\n",
    "            loss = loss_fn(outputs, y_batch)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_loss += loss.item()\n",
    "        total_loss /= len(train_loader)\n",
    "        loss_train.append(total_loss)\n",
    "\n",
    "        # Update learning rate\n",
    "        scheduler.step()\n",
    "\n",
    "        val_accuracy, val_loss, val_f1 = evaluate_model(model, val_loader)\n",
    "        if val_loss < best_loss:\n",
    "            best_epoch = epoch\n",
    "            best_accuracy = val_accuracy\n",
    "            best_f1 = val_f1\n",
    "            best_loss = val_loss\n",
    "            best_model_state = model.state_dict().copy()\n",
    "\n",
    "        loss_val.append(val_loss)\n",
    "        accuracy_val.append(val_accuracy)\n",
    "\n",
    "        current_lr = scheduler.get_last_lr()[0]\n",
    "        if (epoch+1) % 10 == 0:\n",
    "            print(f\"\\tEpoch {epoch + 1}/{num_epochs} - Train loss: {total_loss:.4f} - Val accuracy: {val_accuracy:.4f} - Val loss: {val_loss:.4f} - Val F1: {val_f1:.4f} - LR: {current_lr:.2e}\")\n",
    "\n",
    "    print(f\"\\tBest epoch: {best_epoch + 1} - Best val accuracy: {best_accuracy:.4f} - Best val loss: {best_loss:.4f} - Best val F1: {best_f1:.4f}\\n\")\n",
    "\n",
    "    # Load best model state\n",
    "    model.load_state_dict(best_model_state)\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "\n",
    "def train_and_test(x_train, y_train, x_test, y_test, dataset, num_epochs=100, augment=False):\n",
    "    assert np.array_equal(np.unique(y_train), np.unique(y_test)), \"Training and test labels do not match\"\n",
    "\n",
    "    x_tr, x_val, y_tr, y_val = train_test_split(x_train, y_train, test_size=0.2, stratify=y_train, shuffle=True, random_state=seed)\n",
    "\n",
    "    train_loader = get_dataloader(x_tr, y_tr, shuffle=True)\n",
    "    val_loader = get_dataloader(x_val, y_val)\n",
    "    test_loader = get_dataloader(x_test, y_test)\n",
    "\n",
    "    model = TSTRClassifier(num_timesteps=config[dataset]['num_timesteps'],\n",
    "                           num_channels=config[dataset]['num_channels'],\n",
    "                           num_classes=config[dataset]['num_classes']-1)\n",
    "    initial_lr = 0.0001\n",
    "    optimizer = optim.Adam(model.parameters(), lr=initial_lr)\n",
    "\n",
    "    trained_model = train_model(model, train_loader, val_loader, optimizer, num_epochs, augment)\n",
    "\n",
    "    test_accuracy, test_loss, test_f1 = evaluate_model(trained_model, test_loader)\n",
    "\n",
    "    return test_accuracy, test_loss, test_f1\n",
    "\n",
    "\n",
    "\n",
    "def train_only(x_train, y_train, dataset, num_epochs=100, augment=False):\n",
    "\n",
    "    x_tr, x_val, y_tr, y_val = train_test_split(x_train, y_train, test_size=0.2, stratify=y_train, shuffle=True, random_state=seed)\n",
    "\n",
    "    train_loader = get_dataloader(x_tr, y_tr, shuffle=True)\n",
    "    val_loader = get_dataloader(x_val, y_val)\n",
    "\n",
    "    model = TSTRClassifier(num_timesteps=config[dataset]['num_timesteps'],\n",
    "                           num_channels=config[dataset]['num_channels'],\n",
    "                           num_classes=config[dataset]['num_classes']-1)\n",
    "    initial_lr = 0.0001\n",
    "    optimizer = optim.Adam(model.parameters(), lr=initial_lr)\n",
    "\n",
    "    trained_model = train_model(model, train_loader, val_loader, optimizer, num_epochs, augment=augment)\n",
    "\n",
    "    return trained_model\n",
    "\n",
    "\n",
    "\n",
    "def train_classifier_cv(x_train, y_train, dataset, num_epochs=100):\n",
    "    skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=seed)\n",
    "\n",
    "    accs = []\n",
    "    losses = []\n",
    "    f1s = []\n",
    "\n",
    "    for train_index, test_index in skf.split(x_train, y_train):\n",
    "        x_train_fold, x_test_fold = x_train[train_index], x_train[test_index]\n",
    "        y_train_fold, y_test_fold = y_train[train_index], y_train[test_index]\n",
    "\n",
    "        acc, loss, f1 = train_and_test(x_train_fold, y_train_fold, x_test_fold, y_test_fold, dataset, num_epochs)\n",
    "        accs.append(acc)\n",
    "        losses.append(loss)\n",
    "        f1s.append(f1)\n",
    "    return np.mean(accs), np.mean(losses), np.mean(f1s)\n",
    "\n",
    "\n",
    "\n",
    "def fine_tune(model, x_train, y_train, num_epochs=100):\n",
    "    # Freeze feature extraction layers\n",
    "    for name, param in model.named_parameters():\n",
    "        if 'conv' in name or 'bn' in name:\n",
    "            param.requires_grad = False\n",
    "\n",
    "    x_tr, x_val, y_tr, y_val = train_test_split(x_train, y_train, test_size=0.2, stratify=y_train, shuffle=True, random_state=seed)\n",
    "\n",
    "    train_loader = get_dataloader(x_tr, y_tr, shuffle=True)\n",
    "    val_loader = get_dataloader(x_val, y_val)\n",
    "\n",
    "    initial_lr = 0.00001\n",
    "    optimizer = optim.Adam(filter(lambda p: p.requires_grad, model.parameters()), lr=initial_lr)\n",
    "\n",
    "    trained_model = train_model(model, train_loader, val_loader, optimizer, num_epochs)\n",
    "\n",
    "    return trained_model\n",
    "\n",
    "\n",
    "\n",
    "def save_scores(source, domain, accuracy, loss, f1, name, dataset):\n",
    "    results_dir = 'results'\n",
    "    # Ensure the directory exists\n",
    "    os.makedirs(results_dir, exist_ok=True)\n",
    "    # Path to the CSV file\n",
    "    file_path = os.path.join(results_dir, f'{dataset}_{name}.csv')\n",
    "    # Check if the file exists\n",
    "    file_exists = os.path.exists(file_path)\n",
    "\n",
    "    # Open the file in append mode if it exists, or write mode if it doesn't\n",
    "    with open(file_path, mode='a' if file_exists else 'w', newline='') as file:\n",
    "        writer = csv.writer(file)\n",
    "        # If the file does not exist, write the header\n",
    "        if not file_exists:\n",
    "            writer.writerow(['source', 'domain', 'accuracy', 'loss', 'f1'])\n",
    "        # Write the data rows\n",
    "        writer.writerow([source, domain, accuracy, loss, f1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PRAlLTPumD5Z"
   },
   "source": [
    "# TSTR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 326170,
     "status": "ok",
     "timestamp": 1732616877145,
     "user": {
      "displayName": "Pietro Cirino",
      "userId": "07315473796200699505"
     },
     "user_tz": -60
    },
    "id": "XrDIDrL9CPtn",
    "outputId": "6a7bc60a-ff61-4b8b-8573-c2b2690f05d3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source class: WAL\n",
      "\n",
      "Domain: 15\n",
      "x_dp_dom.shape: (50, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Training and evaluating on Dp data via cross-validation...\n",
      "\tEpoch 10/100 - Train loss: 0.6204 - Val accuracy: 0.2500 - Val loss: 1.1244 - Val F1: 0.1000 - LR: 9.00e-05\n",
      "\tEpoch 20/100 - Train loss: 0.3222 - Val accuracy: 0.2500 - Val loss: 1.1118 - Val F1: 0.1000 - LR: 8.00e-05\n",
      "\tEpoch 30/100 - Train loss: 0.1628 - Val accuracy: 0.3750 - Val loss: 1.1155 - Val F1: 0.2778 - LR: 7.00e-05\n",
      "\tEpoch 40/100 - Train loss: 0.1092 - Val accuracy: 0.5000 - Val loss: 0.9516 - Val F1: 0.3750 - LR: 6.00e-05\n",
      "\tEpoch 50/100 - Train loss: 0.0749 - Val accuracy: 1.0000 - Val loss: 0.4202 - Val F1: 1.0000 - LR: 5.00e-05\n",
      "\tEpoch 60/100 - Train loss: 0.0541 - Val accuracy: 1.0000 - Val loss: 0.1393 - Val F1: 1.0000 - LR: 4.00e-05\n",
      "\tEpoch 70/100 - Train loss: 0.0436 - Val accuracy: 1.0000 - Val loss: 0.0767 - Val F1: 1.0000 - LR: 3.00e-05\n",
      "\tEpoch 80/100 - Train loss: 0.0414 - Val accuracy: 1.0000 - Val loss: 0.0599 - Val F1: 1.0000 - LR: 2.00e-05\n",
      "\tEpoch 90/100 - Train loss: 0.0387 - Val accuracy: 1.0000 - Val loss: 0.0537 - Val F1: 1.0000 - LR: 1.00e-05\n",
      "\tEpoch 100/100 - Train loss: 0.0367 - Val accuracy: 1.0000 - Val loss: 0.0517 - Val F1: 1.0000 - LR: 0.00e+00\n",
      "\tBest epoch: 100 - Best val accuracy: 1.0000 - Best val loss: 0.0517 - Best val F1: 1.0000\n",
      "\n",
      "\tEpoch 10/100 - Train loss: 0.4956 - Val accuracy: 0.5000 - Val loss: 1.0900 - Val F1: 0.3750 - LR: 9.00e-05\n",
      "\tEpoch 20/100 - Train loss: 0.2352 - Val accuracy: 0.2500 - Val loss: 1.0802 - Val F1: 0.1000 - LR: 8.00e-05\n",
      "\tEpoch 30/100 - Train loss: 0.1128 - Val accuracy: 0.5000 - Val loss: 1.0366 - Val F1: 0.3750 - LR: 7.00e-05\n",
      "\tEpoch 40/100 - Train loss: 0.0678 - Val accuracy: 0.5000 - Val loss: 0.7743 - Val F1: 0.3750 - LR: 6.00e-05\n",
      "\tEpoch 50/100 - Train loss: 0.0501 - Val accuracy: 1.0000 - Val loss: 0.2353 - Val F1: 1.0000 - LR: 5.00e-05\n",
      "\tEpoch 60/100 - Train loss: 0.0345 - Val accuracy: 1.0000 - Val loss: 0.0748 - Val F1: 1.0000 - LR: 4.00e-05\n",
      "\tEpoch 70/100 - Train loss: 0.0292 - Val accuracy: 1.0000 - Val loss: 0.0471 - Val F1: 1.0000 - LR: 3.00e-05\n",
      "\tEpoch 80/100 - Train loss: 0.0257 - Val accuracy: 1.0000 - Val loss: 0.0391 - Val F1: 1.0000 - LR: 2.00e-05\n",
      "\tEpoch 90/100 - Train loss: 0.0262 - Val accuracy: 1.0000 - Val loss: 0.0358 - Val F1: 1.0000 - LR: 1.00e-05\n",
      "\tEpoch 100/100 - Train loss: 0.0263 - Val accuracy: 1.0000 - Val loss: 0.0346 - Val F1: 1.0000 - LR: 0.00e+00\n",
      "\tBest epoch: 100 - Best val accuracy: 1.0000 - Best val loss: 0.0346 - Best val F1: 1.0000\n",
      "\n",
      "\tEpoch 10/100 - Train loss: 0.5054 - Val accuracy: 0.7500 - Val loss: 1.0860 - Val F1: 0.6500 - LR: 9.00e-05\n",
      "\tEpoch 20/100 - Train loss: 0.2552 - Val accuracy: 0.2500 - Val loss: 1.0835 - Val F1: 0.1000 - LR: 8.00e-05\n",
      "\tEpoch 30/100 - Train loss: 0.1259 - Val accuracy: 0.2500 - Val loss: 1.1162 - Val F1: 0.1000 - LR: 7.00e-05\n",
      "\tEpoch 40/100 - Train loss: 0.0747 - Val accuracy: 0.5000 - Val loss: 0.9279 - Val F1: 0.3750 - LR: 6.00e-05\n",
      "\tEpoch 50/100 - Train loss: 0.0499 - Val accuracy: 0.8750 - Val loss: 0.3584 - Val F1: 0.8786 - LR: 5.00e-05\n",
      "\tEpoch 60/100 - Train loss: 0.0419 - Val accuracy: 1.0000 - Val loss: 0.1032 - Val F1: 1.0000 - LR: 4.00e-05\n",
      "\tEpoch 70/100 - Train loss: 0.0311 - Val accuracy: 1.0000 - Val loss: 0.0538 - Val F1: 1.0000 - LR: 3.00e-05\n",
      "\tEpoch 80/100 - Train loss: 0.0271 - Val accuracy: 1.0000 - Val loss: 0.0406 - Val F1: 1.0000 - LR: 2.00e-05\n",
      "\tEpoch 90/100 - Train loss: 0.0290 - Val accuracy: 1.0000 - Val loss: 0.0358 - Val F1: 1.0000 - LR: 1.00e-05\n",
      "\tEpoch 100/100 - Train loss: 0.0275 - Val accuracy: 1.0000 - Val loss: 0.0343 - Val F1: 1.0000 - LR: 0.00e+00\n",
      "\tBest epoch: 100 - Best val accuracy: 1.0000 - Best val loss: 0.0343 - Best val F1: 1.0000\n",
      "\n",
      "\tEpoch 10/100 - Train loss: 0.6020 - Val accuracy: 0.6250 - Val loss: 1.0745 - Val F1: 0.4808 - LR: 9.00e-05\n",
      "\tEpoch 20/100 - Train loss: 0.3059 - Val accuracy: 0.1250 - Val loss: 1.0740 - Val F1: 0.0278 - LR: 8.00e-05\n",
      "\tEpoch 30/100 - Train loss: 0.1644 - Val accuracy: 0.3750 - Val loss: 1.0668 - Val F1: 0.2857 - LR: 7.00e-05\n",
      "\tEpoch 40/100 - Train loss: 0.1021 - Val accuracy: 0.3750 - Val loss: 0.8836 - Val F1: 0.2857 - LR: 6.00e-05\n",
      "\tEpoch 50/100 - Train loss: 0.0678 - Val accuracy: 0.8750 - Val loss: 0.4942 - Val F1: 0.8889 - LR: 5.00e-05\n",
      "\tEpoch 60/100 - Train loss: 0.0551 - Val accuracy: 1.0000 - Val loss: 0.2127 - Val F1: 1.0000 - LR: 4.00e-05\n",
      "\tEpoch 70/100 - Train loss: 0.0417 - Val accuracy: 1.0000 - Val loss: 0.1143 - Val F1: 1.0000 - LR: 3.00e-05\n",
      "\tEpoch 80/100 - Train loss: 0.0422 - Val accuracy: 1.0000 - Val loss: 0.0821 - Val F1: 1.0000 - LR: 2.00e-05\n",
      "\tEpoch 90/100 - Train loss: 0.0375 - Val accuracy: 1.0000 - Val loss: 0.0708 - Val F1: 1.0000 - LR: 1.00e-05\n",
      "\tEpoch 100/100 - Train loss: 0.0346 - Val accuracy: 1.0000 - Val loss: 0.0668 - Val F1: 1.0000 - LR: 0.00e+00\n",
      "\tBest epoch: 100 - Best val accuracy: 1.0000 - Best val loss: 0.0668 - Best val F1: 1.0000\n",
      "\n",
      "\tEpoch 10/100 - Train loss: 0.4938 - Val accuracy: 0.1250 - Val loss: 1.1212 - Val F1: 0.0278 - LR: 9.00e-05\n",
      "\tEpoch 20/100 - Train loss: 0.2281 - Val accuracy: 0.1250 - Val loss: 1.2652 - Val F1: 0.0278 - LR: 8.00e-05\n",
      "\tEpoch 30/100 - Train loss: 0.1061 - Val accuracy: 0.1250 - Val loss: 1.5066 - Val F1: 0.0278 - LR: 7.00e-05\n",
      "\tEpoch 40/100 - Train loss: 0.0656 - Val accuracy: 0.3750 - Val loss: 1.3116 - Val F1: 0.2857 - LR: 6.00e-05\n",
      "\tEpoch 50/100 - Train loss: 0.0402 - Val accuracy: 0.7500 - Val loss: 0.5653 - Val F1: 0.7812 - LR: 5.00e-05\n",
      "\tEpoch 60/100 - Train loss: 0.0335 - Val accuracy: 1.0000 - Val loss: 0.1505 - Val F1: 1.0000 - LR: 4.00e-05\n",
      "\tEpoch 70/100 - Train loss: 0.0306 - Val accuracy: 1.0000 - Val loss: 0.0578 - Val F1: 1.0000 - LR: 3.00e-05\n",
      "\tEpoch 80/100 - Train loss: 0.0236 - Val accuracy: 1.0000 - Val loss: 0.0382 - Val F1: 1.0000 - LR: 2.00e-05\n",
      "\tEpoch 90/100 - Train loss: 0.0247 - Val accuracy: 1.0000 - Val loss: 0.0322 - Val F1: 1.0000 - LR: 1.00e-05\n",
      "\tEpoch 100/100 - Train loss: 0.0216 - Val accuracy: 1.0000 - Val loss: 0.0303 - Val F1: 1.0000 - LR: 0.00e+00\n",
      "\tBest epoch: 100 - Best val accuracy: 1.0000 - Best val loss: 0.0303 - Best val F1: 1.0000\n",
      "\n",
      "Source class: WAL | Domain: 15 | Accuracy: 1.0000 | Loss: 0.0452 | F1: 1.0000\n",
      "\n",
      "Domain: 16\n",
      "x_dp_dom.shape: (54, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Training and evaluating on Dp data via cross-validation...\n",
      "\tEpoch 10/100 - Train loss: 0.5895 - Val accuracy: 0.2222 - Val loss: 1.1187 - Val F1: 0.0808 - LR: 9.00e-05\n",
      "\tEpoch 20/100 - Train loss: 0.3997 - Val accuracy: 0.2222 - Val loss: 1.2166 - Val F1: 0.0808 - LR: 8.00e-05\n",
      "\tEpoch 30/100 - Train loss: 0.3008 - Val accuracy: 0.2222 - Val loss: 1.3419 - Val F1: 0.0808 - LR: 7.00e-05\n",
      "\tEpoch 40/100 - Train loss: 0.2362 - Val accuracy: 0.1111 - Val loss: 1.3086 - Val F1: 0.0444 - LR: 6.00e-05\n",
      "\tEpoch 50/100 - Train loss: 0.1806 - Val accuracy: 0.4444 - Val loss: 0.7813 - Val F1: 0.4907 - LR: 5.00e-05\n",
      "\tEpoch 60/100 - Train loss: 0.1559 - Val accuracy: 0.6667 - Val loss: 0.4805 - Val F1: 0.6444 - LR: 4.00e-05\n",
      "\tEpoch 70/100 - Train loss: 0.1284 - Val accuracy: 0.7778 - Val loss: 0.4338 - Val F1: 0.7778 - LR: 3.00e-05\n",
      "\tEpoch 80/100 - Train loss: 0.1055 - Val accuracy: 0.7778 - Val loss: 0.4299 - Val F1: 0.7778 - LR: 2.00e-05\n",
      "\tEpoch 90/100 - Train loss: 0.1187 - Val accuracy: 0.7778 - Val loss: 0.4318 - Val F1: 0.7778 - LR: 1.00e-05\n",
      "\tEpoch 100/100 - Train loss: 0.0887 - Val accuracy: 0.7778 - Val loss: 0.4328 - Val F1: 0.7778 - LR: 0.00e+00\n",
      "\tBest epoch: 78 - Best val accuracy: 0.7778 - Best val loss: 0.4298 - Best val F1: 0.7778\n",
      "\n",
      "\tEpoch 10/100 - Train loss: 0.6318 - Val accuracy: 0.5556 - Val loss: 1.0916 - Val F1: 0.3968 - LR: 9.00e-05\n",
      "\tEpoch 20/100 - Train loss: 0.4218 - Val accuracy: 0.2222 - Val loss: 1.2044 - Val F1: 0.1444 - LR: 8.00e-05\n",
      "\tEpoch 30/100 - Train loss: 0.3170 - Val accuracy: 0.2222 - Val loss: 1.4023 - Val F1: 0.0808 - LR: 7.00e-05\n",
      "\tEpoch 40/100 - Train loss: 0.2389 - Val accuracy: 0.2222 - Val loss: 1.4637 - Val F1: 0.0808 - LR: 6.00e-05\n",
      "\tEpoch 50/100 - Train loss: 0.1925 - Val accuracy: 0.3333 - Val loss: 0.9811 - Val F1: 0.2741 - LR: 5.00e-05\n",
      "\tEpoch 60/100 - Train loss: 0.1593 - Val accuracy: 0.7778 - Val loss: 0.4594 - Val F1: 0.7037 - LR: 4.00e-05\n",
      "\tEpoch 70/100 - Train loss: 0.1202 - Val accuracy: 0.8889 - Val loss: 0.3260 - Val F1: 0.8815 - LR: 3.00e-05\n",
      "\tEpoch 80/100 - Train loss: 0.1200 - Val accuracy: 0.8889 - Val loss: 0.2960 - Val F1: 0.8815 - LR: 2.00e-05\n",
      "\tEpoch 90/100 - Train loss: 0.1111 - Val accuracy: 0.8889 - Val loss: 0.2898 - Val F1: 0.8815 - LR: 1.00e-05\n",
      "\tEpoch 100/100 - Train loss: 0.1011 - Val accuracy: 0.8889 - Val loss: 0.2875 - Val F1: 0.8815 - LR: 0.00e+00\n",
      "\tBest epoch: 100 - Best val accuracy: 0.8889 - Best val loss: 0.2875 - Best val F1: 0.8815\n",
      "\n",
      "\tEpoch 10/100 - Train loss: 0.6528 - Val accuracy: 0.2222 - Val loss: 1.1227 - Val F1: 0.0889 - LR: 9.00e-05\n",
      "\tEpoch 20/100 - Train loss: 0.4134 - Val accuracy: 0.2222 - Val loss: 1.2998 - Val F1: 0.1270 - LR: 8.00e-05\n",
      "\tEpoch 30/100 - Train loss: 0.2974 - Val accuracy: 0.3333 - Val loss: 1.5692 - Val F1: 0.2370 - LR: 7.00e-05\n",
      "\tEpoch 40/100 - Train loss: 0.2337 - Val accuracy: 0.3333 - Val loss: 1.6621 - Val F1: 0.2370 - LR: 6.00e-05\n",
      "\tEpoch 50/100 - Train loss: 0.1908 - Val accuracy: 0.4444 - Val loss: 1.0387 - Val F1: 0.4074 - LR: 5.00e-05\n",
      "\tEpoch 60/100 - Train loss: 0.1620 - Val accuracy: 1.0000 - Val loss: 0.4411 - Val F1: 1.0000 - LR: 4.00e-05\n",
      "\tEpoch 70/100 - Train loss: 0.1368 - Val accuracy: 1.0000 - Val loss: 0.2914 - Val F1: 1.0000 - LR: 3.00e-05\n",
      "\tEpoch 80/100 - Train loss: 0.1334 - Val accuracy: 1.0000 - Val loss: 0.2593 - Val F1: 1.0000 - LR: 2.00e-05\n",
      "\tEpoch 90/100 - Train loss: 0.1172 - Val accuracy: 1.0000 - Val loss: 0.2489 - Val F1: 1.0000 - LR: 1.00e-05\n",
      "\tEpoch 100/100 - Train loss: 0.1204 - Val accuracy: 1.0000 - Val loss: 0.2458 - Val F1: 1.0000 - LR: 0.00e+00\n",
      "\tBest epoch: 100 - Best val accuracy: 1.0000 - Best val loss: 0.2458 - Best val F1: 1.0000\n",
      "\n",
      "\tEpoch 10/100 - Train loss: 0.5685 - Val accuracy: 0.5556 - Val loss: 1.0906 - Val F1: 0.3968 - LR: 9.00e-05\n",
      "\tEpoch 20/100 - Train loss: 0.3910 - Val accuracy: 0.2222 - Val loss: 1.1438 - Val F1: 0.0808 - LR: 8.00e-05\n",
      "\tEpoch 30/100 - Train loss: 0.2873 - Val accuracy: 0.4444 - Val loss: 1.2470 - Val F1: 0.3210 - LR: 7.00e-05\n",
      "\tEpoch 40/100 - Train loss: 0.2198 - Val accuracy: 0.4444 - Val loss: 1.2111 - Val F1: 0.2889 - LR: 6.00e-05\n",
      "\tEpoch 50/100 - Train loss: 0.1601 - Val accuracy: 1.0000 - Val loss: 0.6546 - Val F1: 1.0000 - LR: 5.00e-05\n",
      "\tEpoch 60/100 - Train loss: 0.1212 - Val accuracy: 1.0000 - Val loss: 0.2696 - Val F1: 1.0000 - LR: 4.00e-05\n",
      "\tEpoch 70/100 - Train loss: 0.0998 - Val accuracy: 1.0000 - Val loss: 0.1814 - Val F1: 1.0000 - LR: 3.00e-05\n",
      "\tEpoch 80/100 - Train loss: 0.0874 - Val accuracy: 1.0000 - Val loss: 0.1539 - Val F1: 1.0000 - LR: 2.00e-05\n",
      "\tEpoch 90/100 - Train loss: 0.0815 - Val accuracy: 1.0000 - Val loss: 0.1407 - Val F1: 1.0000 - LR: 1.00e-05\n",
      "\tEpoch 100/100 - Train loss: 0.0790 - Val accuracy: 1.0000 - Val loss: 0.1349 - Val F1: 1.0000 - LR: 0.00e+00\n",
      "\tBest epoch: 100 - Best val accuracy: 1.0000 - Best val loss: 0.1349 - Best val F1: 1.0000\n",
      "\n",
      "\tEpoch 10/100 - Train loss: 0.6416 - Val accuracy: 0.2222 - Val loss: 1.0996 - Val F1: 0.0808 - LR: 9.00e-05\n",
      "\tEpoch 20/100 - Train loss: 0.4448 - Val accuracy: 0.2222 - Val loss: 1.2499 - Val F1: 0.0808 - LR: 8.00e-05\n",
      "\tEpoch 30/100 - Train loss: 0.3191 - Val accuracy: 0.2222 - Val loss: 1.5275 - Val F1: 0.0808 - LR: 7.00e-05\n",
      "\tEpoch 40/100 - Train loss: 0.2667 - Val accuracy: 0.2222 - Val loss: 1.5758 - Val F1: 0.0889 - LR: 6.00e-05\n",
      "\tEpoch 50/100 - Train loss: 0.2097 - Val accuracy: 0.3333 - Val loss: 0.9752 - Val F1: 0.2963 - LR: 5.00e-05\n",
      "\tEpoch 60/100 - Train loss: 0.1741 - Val accuracy: 0.7778 - Val loss: 0.4487 - Val F1: 0.7037 - LR: 4.00e-05\n",
      "\tEpoch 70/100 - Train loss: 0.1590 - Val accuracy: 0.7778 - Val loss: 0.3147 - Val F1: 0.7037 - LR: 3.00e-05\n",
      "\tEpoch 80/100 - Train loss: 0.1276 - Val accuracy: 0.7778 - Val loss: 0.2834 - Val F1: 0.7037 - LR: 2.00e-05\n",
      "\tEpoch 90/100 - Train loss: 0.1244 - Val accuracy: 0.7778 - Val loss: 0.2734 - Val F1: 0.7037 - LR: 1.00e-05\n",
      "\tEpoch 100/100 - Train loss: 0.1231 - Val accuracy: 0.7778 - Val loss: 0.2693 - Val F1: 0.7037 - LR: 0.00e+00\n",
      "\tBest epoch: 100 - Best val accuracy: 0.7778 - Best val loss: 0.2693 - Best val F1: 0.7037\n",
      "\n",
      "Source class: WAL | Domain: 16 | Accuracy: 0.8527 | Loss: 0.3456 | F1: 0.8527\n",
      "\n",
      "Domain: 17\n",
      "x_dp_dom.shape: (53, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Training and evaluating on Dp data via cross-validation...\n",
      "\tEpoch 10/100 - Train loss: 0.7046 - Val accuracy: 0.5556 - Val loss: 1.0854 - Val F1: 0.3968 - LR: 9.00e-05\n",
      "\tEpoch 20/100 - Train loss: 0.4564 - Val accuracy: 0.2222 - Val loss: 1.1427 - Val F1: 0.0808 - LR: 8.00e-05\n",
      "\tEpoch 30/100 - Train loss: 0.3449 - Val accuracy: 0.2222 - Val loss: 1.2438 - Val F1: 0.0988 - LR: 7.00e-05\n",
      "\tEpoch 40/100 - Train loss: 0.2574 - Val accuracy: 0.3333 - Val loss: 1.2421 - Val F1: 0.2116 - LR: 6.00e-05\n",
      "\tEpoch 50/100 - Train loss: 0.1987 - Val accuracy: 0.8889 - Val loss: 0.7619 - Val F1: 0.8938 - LR: 5.00e-05\n",
      "\tEpoch 60/100 - Train loss: 0.1521 - Val accuracy: 1.0000 - Val loss: 0.3043 - Val F1: 1.0000 - LR: 4.00e-05\n",
      "\tEpoch 70/100 - Train loss: 0.1264 - Val accuracy: 1.0000 - Val loss: 0.1691 - Val F1: 1.0000 - LR: 3.00e-05\n",
      "\tEpoch 80/100 - Train loss: 0.1046 - Val accuracy: 1.0000 - Val loss: 0.1254 - Val F1: 1.0000 - LR: 2.00e-05\n",
      "\tEpoch 90/100 - Train loss: 0.0947 - Val accuracy: 1.0000 - Val loss: 0.1076 - Val F1: 1.0000 - LR: 1.00e-05\n",
      "\tEpoch 100/100 - Train loss: 0.0948 - Val accuracy: 1.0000 - Val loss: 0.1011 - Val F1: 1.0000 - LR: 0.00e+00\n",
      "\tBest epoch: 100 - Best val accuracy: 1.0000 - Best val loss: 0.1011 - Best val F1: 1.0000\n",
      "\n",
      "\tEpoch 10/100 - Train loss: 0.6223 - Val accuracy: 0.2222 - Val loss: 1.1232 - Val F1: 0.0808 - LR: 9.00e-05\n",
      "\tEpoch 20/100 - Train loss: 0.4030 - Val accuracy: 0.2222 - Val loss: 1.1914 - Val F1: 0.1111 - LR: 8.00e-05\n",
      "\tEpoch 30/100 - Train loss: 0.2685 - Val accuracy: 0.3333 - Val loss: 1.2631 - Val F1: 0.2370 - LR: 7.00e-05\n",
      "\tEpoch 40/100 - Train loss: 0.1811 - Val accuracy: 0.3333 - Val loss: 1.0704 - Val F1: 0.2370 - LR: 6.00e-05\n",
      "\tEpoch 50/100 - Train loss: 0.1376 - Val accuracy: 0.7778 - Val loss: 0.5392 - Val F1: 0.7901 - LR: 5.00e-05\n",
      "\tEpoch 60/100 - Train loss: 0.1009 - Val accuracy: 1.0000 - Val loss: 0.2291 - Val F1: 1.0000 - LR: 4.00e-05\n",
      "\tEpoch 70/100 - Train loss: 0.0849 - Val accuracy: 1.0000 - Val loss: 0.1403 - Val F1: 1.0000 - LR: 3.00e-05\n",
      "\tEpoch 80/100 - Train loss: 0.0703 - Val accuracy: 1.0000 - Val loss: 0.1111 - Val F1: 1.0000 - LR: 2.00e-05\n",
      "\tEpoch 90/100 - Train loss: 0.0675 - Val accuracy: 1.0000 - Val loss: 0.1003 - Val F1: 1.0000 - LR: 1.00e-05\n",
      "\tEpoch 100/100 - Train loss: 0.0731 - Val accuracy: 1.0000 - Val loss: 0.0969 - Val F1: 1.0000 - LR: 0.00e+00\n",
      "\tBest epoch: 100 - Best val accuracy: 1.0000 - Best val loss: 0.0969 - Best val F1: 1.0000\n",
      "\n",
      "\tEpoch 10/100 - Train loss: 0.7067 - Val accuracy: 0.2222 - Val loss: 1.1137 - Val F1: 0.0808 - LR: 9.00e-05\n",
      "\tEpoch 20/100 - Train loss: 0.4325 - Val accuracy: 0.2222 - Val loss: 1.1801 - Val F1: 0.0808 - LR: 8.00e-05\n",
      "\tEpoch 30/100 - Train loss: 0.3062 - Val accuracy: 0.2222 - Val loss: 1.3000 - Val F1: 0.0808 - LR: 7.00e-05\n",
      "\tEpoch 40/100 - Train loss: 0.2109 - Val accuracy: 0.2222 - Val loss: 1.1699 - Val F1: 0.0808 - LR: 6.00e-05\n",
      "\tEpoch 50/100 - Train loss: 0.1571 - Val accuracy: 0.5556 - Val loss: 0.6465 - Val F1: 0.5278 - LR: 5.00e-05\n",
      "\tEpoch 60/100 - Train loss: 0.1303 - Val accuracy: 1.0000 - Val loss: 0.3266 - Val F1: 1.0000 - LR: 4.00e-05\n",
      "\tEpoch 70/100 - Train loss: 0.1150 - Val accuracy: 1.0000 - Val loss: 0.2127 - Val F1: 1.0000 - LR: 3.00e-05\n",
      "\tEpoch 80/100 - Train loss: 0.0964 - Val accuracy: 1.0000 - Val loss: 0.1747 - Val F1: 1.0000 - LR: 2.00e-05\n",
      "\tEpoch 90/100 - Train loss: 0.0952 - Val accuracy: 1.0000 - Val loss: 0.1602 - Val F1: 1.0000 - LR: 1.00e-05\n",
      "\tEpoch 100/100 - Train loss: 0.0848 - Val accuracy: 1.0000 - Val loss: 0.1551 - Val F1: 1.0000 - LR: 0.00e+00\n",
      "\tBest epoch: 100 - Best val accuracy: 1.0000 - Best val loss: 0.1551 - Best val F1: 1.0000\n",
      "\n",
      "\tEpoch 10/100 - Train loss: 0.5876 - Val accuracy: 0.2222 - Val loss: 1.1172 - Val F1: 0.0808 - LR: 9.00e-05\n",
      "\tEpoch 20/100 - Train loss: 0.3769 - Val accuracy: 0.2222 - Val loss: 1.1887 - Val F1: 0.0808 - LR: 8.00e-05\n",
      "\tEpoch 30/100 - Train loss: 0.2785 - Val accuracy: 0.2222 - Val loss: 1.3048 - Val F1: 0.0808 - LR: 7.00e-05\n",
      "\tEpoch 40/100 - Train loss: 0.1920 - Val accuracy: 0.4444 - Val loss: 1.2200 - Val F1: 0.3210 - LR: 6.00e-05\n",
      "\tEpoch 50/100 - Train loss: 0.1540 - Val accuracy: 0.7778 - Val loss: 0.6902 - Val F1: 0.7870 - LR: 5.00e-05\n",
      "\tEpoch 60/100 - Train loss: 0.1205 - Val accuracy: 1.0000 - Val loss: 0.3249 - Val F1: 1.0000 - LR: 4.00e-05\n",
      "\tEpoch 70/100 - Train loss: 0.1038 - Val accuracy: 1.0000 - Val loss: 0.2127 - Val F1: 1.0000 - LR: 3.00e-05\n",
      "\tEpoch 80/100 - Train loss: 0.0816 - Val accuracy: 1.0000 - Val loss: 0.1797 - Val F1: 1.0000 - LR: 2.00e-05\n",
      "\tEpoch 90/100 - Train loss: 0.0736 - Val accuracy: 1.0000 - Val loss: 0.1672 - Val F1: 1.0000 - LR: 1.00e-05\n",
      "\tEpoch 100/100 - Train loss: 0.0756 - Val accuracy: 1.0000 - Val loss: 0.1632 - Val F1: 1.0000 - LR: 0.00e+00\n",
      "\tBest epoch: 100 - Best val accuracy: 1.0000 - Best val loss: 0.1632 - Best val F1: 1.0000\n",
      "\n",
      "\tEpoch 10/100 - Train loss: 0.6857 - Val accuracy: 0.2222 - Val loss: 1.1187 - Val F1: 0.0808 - LR: 9.00e-05\n",
      "\tEpoch 20/100 - Train loss: 0.3903 - Val accuracy: 0.2222 - Val loss: 1.1361 - Val F1: 0.0808 - LR: 8.00e-05\n",
      "\tEpoch 30/100 - Train loss: 0.2408 - Val accuracy: 0.2222 - Val loss: 1.2099 - Val F1: 0.0808 - LR: 7.00e-05\n",
      "\tEpoch 40/100 - Train loss: 0.1707 - Val accuracy: 0.2222 - Val loss: 1.2648 - Val F1: 0.0808 - LR: 6.00e-05\n",
      "\tEpoch 50/100 - Train loss: 0.1127 - Val accuracy: 0.3333 - Val loss: 0.9966 - Val F1: 0.2741 - LR: 5.00e-05\n",
      "\tEpoch 60/100 - Train loss: 0.0795 - Val accuracy: 0.7778 - Val loss: 0.5075 - Val F1: 0.7037 - LR: 4.00e-05\n",
      "\tEpoch 70/100 - Train loss: 0.0690 - Val accuracy: 1.0000 - Val loss: 0.2908 - Val F1: 1.0000 - LR: 3.00e-05\n",
      "\tEpoch 80/100 - Train loss: 0.0586 - Val accuracy: 1.0000 - Val loss: 0.2264 - Val F1: 1.0000 - LR: 2.00e-05\n",
      "\tEpoch 90/100 - Train loss: 0.0535 - Val accuracy: 1.0000 - Val loss: 0.2065 - Val F1: 1.0000 - LR: 1.00e-05\n",
      "\tEpoch 100/100 - Train loss: 0.0461 - Val accuracy: 1.0000 - Val loss: 0.2013 - Val F1: 1.0000 - LR: 0.00e+00\n",
      "\tBest epoch: 100 - Best val accuracy: 1.0000 - Best val loss: 0.2013 - Best val F1: 1.0000\n",
      "\n",
      "Source class: WAL | Domain: 17 | Accuracy: 0.9418 | Loss: 0.1886 | F1: 0.9385\n",
      "\n",
      "Domain: 18\n",
      "x_dp_dom.shape: (54, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Training and evaluating on Dp data via cross-validation...\n",
      "\tEpoch 10/100 - Train loss: 0.6107 - Val accuracy: 0.2222 - Val loss: 1.1128 - Val F1: 0.0808 - LR: 9.00e-05\n",
      "\tEpoch 20/100 - Train loss: 0.3929 - Val accuracy: 0.2222 - Val loss: 1.2205 - Val F1: 0.0808 - LR: 8.00e-05\n",
      "\tEpoch 30/100 - Train loss: 0.2934 - Val accuracy: 0.2222 - Val loss: 1.4034 - Val F1: 0.0808 - LR: 7.00e-05\n",
      "\tEpoch 40/100 - Train loss: 0.2292 - Val accuracy: 0.3333 - Val loss: 1.4489 - Val F1: 0.2099 - LR: 6.00e-05\n",
      "\tEpoch 50/100 - Train loss: 0.1750 - Val accuracy: 0.6667 - Val loss: 0.9292 - Val F1: 0.6918 - LR: 5.00e-05\n",
      "\tEpoch 60/100 - Train loss: 0.1414 - Val accuracy: 0.7778 - Val loss: 0.5007 - Val F1: 0.7901 - LR: 4.00e-05\n",
      "\tEpoch 70/100 - Train loss: 0.1122 - Val accuracy: 0.8889 - Val loss: 0.3755 - Val F1: 0.8938 - LR: 3.00e-05\n",
      "\tEpoch 80/100 - Train loss: 0.0941 - Val accuracy: 0.8889 - Val loss: 0.3279 - Val F1: 0.8938 - LR: 2.00e-05\n",
      "\tEpoch 90/100 - Train loss: 0.0896 - Val accuracy: 0.8889 - Val loss: 0.3081 - Val F1: 0.8938 - LR: 1.00e-05\n",
      "\tEpoch 100/100 - Train loss: 0.0808 - Val accuracy: 1.0000 - Val loss: 0.3003 - Val F1: 1.0000 - LR: 0.00e+00\n",
      "\tBest epoch: 100 - Best val accuracy: 1.0000 - Best val loss: 0.3003 - Best val F1: 1.0000\n",
      "\n",
      "\tEpoch 10/100 - Train loss: 0.5613 - Val accuracy: 0.2222 - Val loss: 1.1187 - Val F1: 0.0808 - LR: 9.00e-05\n",
      "\tEpoch 20/100 - Train loss: 0.3579 - Val accuracy: 0.2222 - Val loss: 1.2332 - Val F1: 0.0808 - LR: 8.00e-05\n",
      "\tEpoch 30/100 - Train loss: 0.2455 - Val accuracy: 0.2222 - Val loss: 1.3332 - Val F1: 0.0889 - LR: 7.00e-05\n",
      "\tEpoch 40/100 - Train loss: 0.1738 - Val accuracy: 0.4444 - Val loss: 1.0410 - Val F1: 0.4286 - LR: 6.00e-05\n",
      "\tEpoch 50/100 - Train loss: 0.1261 - Val accuracy: 0.7778 - Val loss: 0.5328 - Val F1: 0.7901 - LR: 5.00e-05\n",
      "\tEpoch 60/100 - Train loss: 0.0905 - Val accuracy: 1.0000 - Val loss: 0.3307 - Val F1: 1.0000 - LR: 4.00e-05\n",
      "\tEpoch 70/100 - Train loss: 0.0751 - Val accuracy: 1.0000 - Val loss: 0.2593 - Val F1: 1.0000 - LR: 3.00e-05\n",
      "\tEpoch 80/100 - Train loss: 0.0667 - Val accuracy: 1.0000 - Val loss: 0.2296 - Val F1: 1.0000 - LR: 2.00e-05\n",
      "\tEpoch 90/100 - Train loss: 0.0614 - Val accuracy: 1.0000 - Val loss: 0.2159 - Val F1: 1.0000 - LR: 1.00e-05\n",
      "\tEpoch 100/100 - Train loss: 0.0594 - Val accuracy: 1.0000 - Val loss: 0.2106 - Val F1: 1.0000 - LR: 0.00e+00\n",
      "\tBest epoch: 100 - Best val accuracy: 1.0000 - Best val loss: 0.2106 - Best val F1: 1.0000\n",
      "\n",
      "\tEpoch 10/100 - Train loss: 0.5941 - Val accuracy: 0.2222 - Val loss: 1.1386 - Val F1: 0.0808 - LR: 9.00e-05\n",
      "\tEpoch 20/100 - Train loss: 0.3528 - Val accuracy: 0.2222 - Val loss: 1.3420 - Val F1: 0.0808 - LR: 8.00e-05\n",
      "\tEpoch 30/100 - Train loss: 0.2533 - Val accuracy: 0.2222 - Val loss: 1.6069 - Val F1: 0.0808 - LR: 7.00e-05\n",
      "\tEpoch 40/100 - Train loss: 0.1885 - Val accuracy: 0.2222 - Val loss: 1.4507 - Val F1: 0.0808 - LR: 6.00e-05\n",
      "\tEpoch 50/100 - Train loss: 0.1325 - Val accuracy: 0.8889 - Val loss: 0.6099 - Val F1: 0.8815 - LR: 5.00e-05\n",
      "\tEpoch 60/100 - Train loss: 0.1049 - Val accuracy: 0.8889 - Val loss: 0.2797 - Val F1: 0.8815 - LR: 4.00e-05\n",
      "\tEpoch 70/100 - Train loss: 0.0876 - Val accuracy: 0.8889 - Val loss: 0.2355 - Val F1: 0.8815 - LR: 3.00e-05\n",
      "\tEpoch 80/100 - Train loss: 0.0689 - Val accuracy: 0.8889 - Val loss: 0.2214 - Val F1: 0.8815 - LR: 2.00e-05\n",
      "\tEpoch 90/100 - Train loss: 0.0701 - Val accuracy: 0.8889 - Val loss: 0.2158 - Val F1: 0.8815 - LR: 1.00e-05\n",
      "\tEpoch 100/100 - Train loss: 0.0675 - Val accuracy: 0.8889 - Val loss: 0.2139 - Val F1: 0.8815 - LR: 0.00e+00\n",
      "\tBest epoch: 100 - Best val accuracy: 0.8889 - Best val loss: 0.2139 - Best val F1: 0.8815\n",
      "\n",
      "\tEpoch 10/100 - Train loss: 0.6512 - Val accuracy: 0.2222 - Val loss: 1.1203 - Val F1: 0.0808 - LR: 9.00e-05\n",
      "\tEpoch 20/100 - Train loss: 0.4459 - Val accuracy: 0.2222 - Val loss: 1.2009 - Val F1: 0.0808 - LR: 8.00e-05\n",
      "\tEpoch 30/100 - Train loss: 0.3070 - Val accuracy: 0.2222 - Val loss: 1.3337 - Val F1: 0.0808 - LR: 7.00e-05\n",
      "\tEpoch 40/100 - Train loss: 0.2296 - Val accuracy: 0.2222 - Val loss: 1.3012 - Val F1: 0.0808 - LR: 6.00e-05\n",
      "\tEpoch 50/100 - Train loss: 0.1673 - Val accuracy: 0.8889 - Val loss: 0.7302 - Val F1: 0.8938 - LR: 5.00e-05\n",
      "\tEpoch 60/100 - Train loss: 0.1257 - Val accuracy: 1.0000 - Val loss: 0.3130 - Val F1: 1.0000 - LR: 4.00e-05\n",
      "\tEpoch 70/100 - Train loss: 0.0981 - Val accuracy: 1.0000 - Val loss: 0.2068 - Val F1: 1.0000 - LR: 3.00e-05\n",
      "\tEpoch 80/100 - Train loss: 0.0901 - Val accuracy: 1.0000 - Val loss: 0.1746 - Val F1: 1.0000 - LR: 2.00e-05\n",
      "\tEpoch 90/100 - Train loss: 0.0796 - Val accuracy: 1.0000 - Val loss: 0.1623 - Val F1: 1.0000 - LR: 1.00e-05\n",
      "\tEpoch 100/100 - Train loss: 0.0771 - Val accuracy: 1.0000 - Val loss: 0.1580 - Val F1: 1.0000 - LR: 0.00e+00\n",
      "\tBest epoch: 100 - Best val accuracy: 1.0000 - Best val loss: 0.1580 - Best val F1: 1.0000\n",
      "\n",
      "\tEpoch 10/100 - Train loss: 0.6321 - Val accuracy: 0.5556 - Val loss: 1.0869 - Val F1: 0.5278 - LR: 9.00e-05\n",
      "\tEpoch 20/100 - Train loss: 0.3931 - Val accuracy: 0.2222 - Val loss: 1.1772 - Val F1: 0.0808 - LR: 8.00e-05\n",
      "\tEpoch 30/100 - Train loss: 0.2911 - Val accuracy: 0.2222 - Val loss: 1.2899 - Val F1: 0.0808 - LR: 7.00e-05\n",
      "\tEpoch 40/100 - Train loss: 0.2208 - Val accuracy: 0.4444 - Val loss: 1.0879 - Val F1: 0.4074 - LR: 6.00e-05\n",
      "\tEpoch 50/100 - Train loss: 0.1694 - Val accuracy: 1.0000 - Val loss: 0.4721 - Val F1: 1.0000 - LR: 5.00e-05\n",
      "\tEpoch 60/100 - Train loss: 0.1308 - Val accuracy: 1.0000 - Val loss: 0.2211 - Val F1: 1.0000 - LR: 4.00e-05\n",
      "\tEpoch 70/100 - Train loss: 0.1130 - Val accuracy: 1.0000 - Val loss: 0.1550 - Val F1: 1.0000 - LR: 3.00e-05\n",
      "\tEpoch 80/100 - Train loss: 0.1034 - Val accuracy: 1.0000 - Val loss: 0.1301 - Val F1: 1.0000 - LR: 2.00e-05\n",
      "\tEpoch 90/100 - Train loss: 0.0908 - Val accuracy: 1.0000 - Val loss: 0.1187 - Val F1: 1.0000 - LR: 1.00e-05\n",
      "\tEpoch 100/100 - Train loss: 0.0800 - Val accuracy: 1.0000 - Val loss: 0.1143 - Val F1: 1.0000 - LR: 0.00e+00\n",
      "\tBest epoch: 100 - Best val accuracy: 1.0000 - Best val loss: 0.1143 - Best val F1: 1.0000\n",
      "\n",
      "Source class: WAL | Domain: 18 | Accuracy: 0.9436 | Loss: 0.1914 | F1: 0.9431\n",
      "\n",
      "Domain: 19\n",
      "x_dp_dom.shape: (54, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Training and evaluating on Dp data via cross-validation...\n",
      "\tEpoch 10/100 - Train loss: 0.6276 - Val accuracy: 0.2222 - Val loss: 1.0978 - Val F1: 0.0808 - LR: 9.00e-05\n",
      "\tEpoch 20/100 - Train loss: 0.4134 - Val accuracy: 0.2222 - Val loss: 1.1667 - Val F1: 0.0808 - LR: 8.00e-05\n",
      "\tEpoch 30/100 - Train loss: 0.3094 - Val accuracy: 0.2222 - Val loss: 1.2830 - Val F1: 0.0808 - LR: 7.00e-05\n",
      "\tEpoch 40/100 - Train loss: 0.2540 - Val accuracy: 0.2222 - Val loss: 1.2337 - Val F1: 0.0889 - LR: 6.00e-05\n",
      "\tEpoch 50/100 - Train loss: 0.2007 - Val accuracy: 0.7778 - Val loss: 0.7131 - Val F1: 0.7827 - LR: 5.00e-05\n",
      "\tEpoch 60/100 - Train loss: 0.1438 - Val accuracy: 1.0000 - Val loss: 0.2921 - Val F1: 1.0000 - LR: 4.00e-05\n",
      "\tEpoch 70/100 - Train loss: 0.1241 - Val accuracy: 1.0000 - Val loss: 0.1604 - Val F1: 1.0000 - LR: 3.00e-05\n",
      "\tEpoch 80/100 - Train loss: 0.1112 - Val accuracy: 1.0000 - Val loss: 0.1183 - Val F1: 1.0000 - LR: 2.00e-05\n",
      "\tEpoch 90/100 - Train loss: 0.0882 - Val accuracy: 1.0000 - Val loss: 0.1014 - Val F1: 1.0000 - LR: 1.00e-05\n",
      "\tEpoch 100/100 - Train loss: 0.0875 - Val accuracy: 1.0000 - Val loss: 0.0956 - Val F1: 1.0000 - LR: 0.00e+00\n",
      "\tBest epoch: 100 - Best val accuracy: 1.0000 - Best val loss: 0.0956 - Best val F1: 1.0000\n",
      "\n",
      "\tEpoch 10/100 - Train loss: 0.5451 - Val accuracy: 0.2222 - Val loss: 1.0876 - Val F1: 0.0808 - LR: 9.00e-05\n",
      "\tEpoch 20/100 - Train loss: 0.3717 - Val accuracy: 0.2222 - Val loss: 1.1932 - Val F1: 0.0808 - LR: 8.00e-05\n",
      "\tEpoch 30/100 - Train loss: 0.2833 - Val accuracy: 0.2222 - Val loss: 1.3804 - Val F1: 0.0808 - LR: 7.00e-05\n",
      "\tEpoch 40/100 - Train loss: 0.2186 - Val accuracy: 0.2222 - Val loss: 1.4004 - Val F1: 0.0808 - LR: 6.00e-05\n",
      "\tEpoch 50/100 - Train loss: 0.1620 - Val accuracy: 0.5556 - Val loss: 0.8925 - Val F1: 0.5767 - LR: 5.00e-05\n",
      "\tEpoch 60/100 - Train loss: 0.1392 - Val accuracy: 1.0000 - Val loss: 0.3712 - Val F1: 1.0000 - LR: 4.00e-05\n",
      "\tEpoch 70/100 - Train loss: 0.1095 - Val accuracy: 1.0000 - Val loss: 0.2219 - Val F1: 1.0000 - LR: 3.00e-05\n",
      "\tEpoch 80/100 - Train loss: 0.1015 - Val accuracy: 1.0000 - Val loss: 0.1790 - Val F1: 1.0000 - LR: 2.00e-05\n",
      "\tEpoch 90/100 - Train loss: 0.0927 - Val accuracy: 1.0000 - Val loss: 0.1629 - Val F1: 1.0000 - LR: 1.00e-05\n",
      "\tEpoch 100/100 - Train loss: 0.0959 - Val accuracy: 1.0000 - Val loss: 0.1568 - Val F1: 1.0000 - LR: 0.00e+00\n",
      "\tBest epoch: 100 - Best val accuracy: 1.0000 - Best val loss: 0.1568 - Best val F1: 1.0000\n",
      "\n",
      "\tEpoch 10/100 - Train loss: 0.5822 - Val accuracy: 0.2222 - Val loss: 1.1297 - Val F1: 0.0808 - LR: 9.00e-05\n",
      "\tEpoch 20/100 - Train loss: 0.3564 - Val accuracy: 0.2222 - Val loss: 1.2951 - Val F1: 0.0808 - LR: 8.00e-05\n",
      "\tEpoch 30/100 - Train loss: 0.2282 - Val accuracy: 0.2222 - Val loss: 1.5397 - Val F1: 0.0808 - LR: 7.00e-05\n",
      "\tEpoch 40/100 - Train loss: 0.1569 - Val accuracy: 0.4444 - Val loss: 1.5362 - Val F1: 0.3210 - LR: 6.00e-05\n",
      "\tEpoch 50/100 - Train loss: 0.1232 - Val accuracy: 0.5556 - Val loss: 0.9426 - Val F1: 0.5185 - LR: 5.00e-05\n",
      "\tEpoch 60/100 - Train loss: 0.0831 - Val accuracy: 0.8889 - Val loss: 0.3849 - Val F1: 0.8938 - LR: 4.00e-05\n",
      "\tEpoch 70/100 - Train loss: 0.0655 - Val accuracy: 1.0000 - Val loss: 0.2164 - Val F1: 1.0000 - LR: 3.00e-05\n",
      "\tEpoch 80/100 - Train loss: 0.0624 - Val accuracy: 1.0000 - Val loss: 0.1703 - Val F1: 1.0000 - LR: 2.00e-05\n",
      "\tEpoch 90/100 - Train loss: 0.0525 - Val accuracy: 1.0000 - Val loss: 0.1549 - Val F1: 1.0000 - LR: 1.00e-05\n",
      "\tEpoch 100/100 - Train loss: 0.0490 - Val accuracy: 1.0000 - Val loss: 0.1502 - Val F1: 1.0000 - LR: 0.00e+00\n",
      "\tBest epoch: 100 - Best val accuracy: 1.0000 - Best val loss: 0.1502 - Best val F1: 1.0000\n",
      "\n",
      "\tEpoch 10/100 - Train loss: 0.6190 - Val accuracy: 0.2222 - Val loss: 1.1290 - Val F1: 0.0808 - LR: 9.00e-05\n",
      "\tEpoch 20/100 - Train loss: 0.3887 - Val accuracy: 0.2222 - Val loss: 1.2574 - Val F1: 0.0808 - LR: 8.00e-05\n",
      "\tEpoch 30/100 - Train loss: 0.3020 - Val accuracy: 0.2222 - Val loss: 1.4523 - Val F1: 0.0808 - LR: 7.00e-05\n",
      "\tEpoch 40/100 - Train loss: 0.2167 - Val accuracy: 0.2222 - Val loss: 1.4228 - Val F1: 0.0988 - LR: 6.00e-05\n",
      "\tEpoch 50/100 - Train loss: 0.1692 - Val accuracy: 0.5556 - Val loss: 0.7592 - Val F1: 0.5648 - LR: 5.00e-05\n",
      "\tEpoch 60/100 - Train loss: 0.1322 - Val accuracy: 1.0000 - Val loss: 0.2734 - Val F1: 1.0000 - LR: 4.00e-05\n",
      "\tEpoch 70/100 - Train loss: 0.1123 - Val accuracy: 1.0000 - Val loss: 0.1461 - Val F1: 1.0000 - LR: 3.00e-05\n",
      "\tEpoch 80/100 - Train loss: 0.0907 - Val accuracy: 1.0000 - Val loss: 0.1135 - Val F1: 1.0000 - LR: 2.00e-05\n",
      "\tEpoch 90/100 - Train loss: 0.0868 - Val accuracy: 1.0000 - Val loss: 0.1014 - Val F1: 1.0000 - LR: 1.00e-05\n",
      "\tEpoch 100/100 - Train loss: 0.0772 - Val accuracy: 1.0000 - Val loss: 0.0971 - Val F1: 1.0000 - LR: 0.00e+00\n",
      "\tBest epoch: 100 - Best val accuracy: 1.0000 - Best val loss: 0.0971 - Best val F1: 1.0000\n",
      "\n",
      "\tEpoch 10/100 - Train loss: 0.6492 - Val accuracy: 0.2222 - Val loss: 1.1189 - Val F1: 0.0808 - LR: 9.00e-05\n",
      "\tEpoch 20/100 - Train loss: 0.3883 - Val accuracy: 0.2222 - Val loss: 1.2210 - Val F1: 0.0808 - LR: 8.00e-05\n",
      "\tEpoch 30/100 - Train loss: 0.2742 - Val accuracy: 0.2222 - Val loss: 1.4020 - Val F1: 0.0808 - LR: 7.00e-05\n",
      "\tEpoch 40/100 - Train loss: 0.2035 - Val accuracy: 0.2222 - Val loss: 1.4920 - Val F1: 0.0808 - LR: 6.00e-05\n",
      "\tEpoch 50/100 - Train loss: 0.1550 - Val accuracy: 0.3333 - Val loss: 1.0064 - Val F1: 0.2741 - LR: 5.00e-05\n",
      "\tEpoch 60/100 - Train loss: 0.1199 - Val accuracy: 0.8889 - Val loss: 0.3292 - Val F1: 0.8815 - LR: 4.00e-05\n",
      "\tEpoch 70/100 - Train loss: 0.1011 - Val accuracy: 1.0000 - Val loss: 0.1544 - Val F1: 1.0000 - LR: 3.00e-05\n",
      "\tEpoch 80/100 - Train loss: 0.0870 - Val accuracy: 1.0000 - Val loss: 0.1153 - Val F1: 1.0000 - LR: 2.00e-05\n",
      "\tEpoch 90/100 - Train loss: 0.0780 - Val accuracy: 1.0000 - Val loss: 0.1013 - Val F1: 1.0000 - LR: 1.00e-05\n",
      "\tEpoch 100/100 - Train loss: 0.0787 - Val accuracy: 1.0000 - Val loss: 0.0960 - Val F1: 1.0000 - LR: 0.00e+00\n",
      "\tBest epoch: 100 - Best val accuracy: 1.0000 - Best val loss: 0.0960 - Best val F1: 1.0000\n",
      "\n",
      "Source class: WAL | Domain: 19 | Accuracy: 0.9818 | Loss: 0.1441 | F1: 0.9818\n",
      "\n",
      "Domain: 20\n",
      "x_dp_dom.shape: (51, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Training and evaluating on Dp data via cross-validation...\n",
      "\tEpoch 10/100 - Train loss: 0.6748 - Val accuracy: 0.2500 - Val loss: 1.1026 - Val F1: 0.1000 - LR: 9.00e-05\n",
      "\tEpoch 20/100 - Train loss: 0.4257 - Val accuracy: 0.2500 - Val loss: 1.1464 - Val F1: 0.1000 - LR: 8.00e-05\n",
      "\tEpoch 30/100 - Train loss: 0.2968 - Val accuracy: 0.2500 - Val loss: 1.2596 - Val F1: 0.1000 - LR: 7.00e-05\n",
      "\tEpoch 40/100 - Train loss: 0.2045 - Val accuracy: 0.2500 - Val loss: 1.2040 - Val F1: 0.1000 - LR: 6.00e-05\n",
      "\tEpoch 50/100 - Train loss: 0.1632 - Val accuracy: 0.7500 - Val loss: 0.7618 - Val F1: 0.6667 - LR: 5.00e-05\n",
      "\tEpoch 60/100 - Train loss: 0.1276 - Val accuracy: 0.7500 - Val loss: 0.5256 - Val F1: 0.6667 - LR: 4.00e-05\n",
      "\tEpoch 70/100 - Train loss: 0.1039 - Val accuracy: 0.7500 - Val loss: 0.4667 - Val F1: 0.6667 - LR: 3.00e-05\n",
      "\tEpoch 80/100 - Train loss: 0.0953 - Val accuracy: 0.7500 - Val loss: 0.4477 - Val F1: 0.6667 - LR: 2.00e-05\n",
      "\tEpoch 90/100 - Train loss: 0.0839 - Val accuracy: 0.7500 - Val loss: 0.4437 - Val F1: 0.6667 - LR: 1.00e-05\n",
      "\tEpoch 100/100 - Train loss: 0.0863 - Val accuracy: 0.7500 - Val loss: 0.4433 - Val F1: 0.6667 - LR: 0.00e+00\n",
      "\tBest epoch: 98 - Best val accuracy: 0.7500 - Best val loss: 0.4432 - Best val F1: 0.6667\n",
      "\n",
      "\tEpoch 10/100 - Train loss: 0.5966 - Val accuracy: 0.2222 - Val loss: 1.0868 - Val F1: 0.0808 - LR: 9.00e-05\n",
      "\tEpoch 20/100 - Train loss: 0.3708 - Val accuracy: 0.2222 - Val loss: 1.1566 - Val F1: 0.0808 - LR: 8.00e-05\n",
      "\tEpoch 30/100 - Train loss: 0.2516 - Val accuracy: 0.2222 - Val loss: 1.2539 - Val F1: 0.0808 - LR: 7.00e-05\n",
      "\tEpoch 40/100 - Train loss: 0.1809 - Val accuracy: 0.2222 - Val loss: 1.0532 - Val F1: 0.0808 - LR: 6.00e-05\n",
      "\tEpoch 50/100 - Train loss: 0.1354 - Val accuracy: 0.7778 - Val loss: 0.4765 - Val F1: 0.7037 - LR: 5.00e-05\n",
      "\tEpoch 60/100 - Train loss: 0.1096 - Val accuracy: 1.0000 - Val loss: 0.2436 - Val F1: 1.0000 - LR: 4.00e-05\n",
      "\tEpoch 70/100 - Train loss: 0.0848 - Val accuracy: 1.0000 - Val loss: 0.1738 - Val F1: 1.0000 - LR: 3.00e-05\n",
      "\tEpoch 80/100 - Train loss: 0.0714 - Val accuracy: 1.0000 - Val loss: 0.1473 - Val F1: 1.0000 - LR: 2.00e-05\n",
      "\tEpoch 90/100 - Train loss: 0.0638 - Val accuracy: 1.0000 - Val loss: 0.1366 - Val F1: 1.0000 - LR: 1.00e-05\n",
      "\tEpoch 100/100 - Train loss: 0.0624 - Val accuracy: 1.0000 - Val loss: 0.1329 - Val F1: 1.0000 - LR: 0.00e+00\n",
      "\tBest epoch: 100 - Best val accuracy: 1.0000 - Best val loss: 0.1329 - Best val F1: 1.0000\n",
      "\n",
      "\tEpoch 10/100 - Train loss: 0.6096 - Val accuracy: 0.2222 - Val loss: 1.1112 - Val F1: 0.0808 - LR: 9.00e-05\n",
      "\tEpoch 20/100 - Train loss: 0.4027 - Val accuracy: 0.2222 - Val loss: 1.2052 - Val F1: 0.0808 - LR: 8.00e-05\n",
      "\tEpoch 30/100 - Train loss: 0.2883 - Val accuracy: 0.2222 - Val loss: 1.3131 - Val F1: 0.0808 - LR: 7.00e-05\n",
      "\tEpoch 40/100 - Train loss: 0.2188 - Val accuracy: 0.3333 - Val loss: 1.1053 - Val F1: 0.2741 - LR: 6.00e-05\n",
      "\tEpoch 50/100 - Train loss: 0.1672 - Val accuracy: 0.6667 - Val loss: 0.6796 - Val F1: 0.6208 - LR: 5.00e-05\n",
      "\tEpoch 60/100 - Train loss: 0.1451 - Val accuracy: 0.6667 - Val loss: 0.4957 - Val F1: 0.6208 - LR: 4.00e-05\n",
      "\tEpoch 70/100 - Train loss: 0.1092 - Val accuracy: 0.8889 - Val loss: 0.4250 - Val F1: 0.8815 - LR: 3.00e-05\n",
      "\tEpoch 80/100 - Train loss: 0.0890 - Val accuracy: 0.8889 - Val loss: 0.4007 - Val F1: 0.8815 - LR: 2.00e-05\n",
      "\tEpoch 90/100 - Train loss: 0.0829 - Val accuracy: 0.8889 - Val loss: 0.3913 - Val F1: 0.8815 - LR: 1.00e-05\n",
      "\tEpoch 100/100 - Train loss: 0.0860 - Val accuracy: 0.8889 - Val loss: 0.3884 - Val F1: 0.8815 - LR: 0.00e+00\n",
      "\tBest epoch: 100 - Best val accuracy: 0.8889 - Best val loss: 0.3884 - Best val F1: 0.8815\n",
      "\n",
      "\tEpoch 10/100 - Train loss: 0.6726 - Val accuracy: 0.2222 - Val loss: 1.0895 - Val F1: 0.0808 - LR: 9.00e-05\n",
      "\tEpoch 20/100 - Train loss: 0.3992 - Val accuracy: 0.2222 - Val loss: 1.1844 - Val F1: 0.0808 - LR: 8.00e-05\n",
      "\tEpoch 30/100 - Train loss: 0.2686 - Val accuracy: 0.2222 - Val loss: 1.3437 - Val F1: 0.0808 - LR: 7.00e-05\n",
      "\tEpoch 40/100 - Train loss: 0.1881 - Val accuracy: 0.2222 - Val loss: 1.3760 - Val F1: 0.0808 - LR: 6.00e-05\n",
      "\tEpoch 50/100 - Train loss: 0.1372 - Val accuracy: 0.4444 - Val loss: 0.9886 - Val F1: 0.4162 - LR: 5.00e-05\n",
      "\tEpoch 60/100 - Train loss: 0.1081 - Val accuracy: 0.6667 - Val loss: 0.6148 - Val F1: 0.6208 - LR: 4.00e-05\n",
      "\tEpoch 70/100 - Train loss: 0.0912 - Val accuracy: 0.8889 - Val loss: 0.4743 - Val F1: 0.8815 - LR: 3.00e-05\n",
      "\tEpoch 80/100 - Train loss: 0.0744 - Val accuracy: 0.8889 - Val loss: 0.4227 - Val F1: 0.8815 - LR: 2.00e-05\n",
      "\tEpoch 90/100 - Train loss: 0.0684 - Val accuracy: 0.8889 - Val loss: 0.4044 - Val F1: 0.8815 - LR: 1.00e-05\n",
      "\tEpoch 100/100 - Train loss: 0.0651 - Val accuracy: 0.8889 - Val loss: 0.3978 - Val F1: 0.8815 - LR: 0.00e+00\n",
      "\tBest epoch: 100 - Best val accuracy: 0.8889 - Best val loss: 0.3978 - Best val F1: 0.8815\n",
      "\n",
      "\tEpoch 10/100 - Train loss: 0.6391 - Val accuracy: 0.5556 - Val loss: 1.0861 - Val F1: 0.3968 - LR: 9.00e-05\n",
      "\tEpoch 20/100 - Train loss: 0.4109 - Val accuracy: 0.2222 - Val loss: 1.1615 - Val F1: 0.0808 - LR: 8.00e-05\n",
      "\tEpoch 30/100 - Train loss: 0.2754 - Val accuracy: 0.2222 - Val loss: 1.2906 - Val F1: 0.0808 - LR: 7.00e-05\n",
      "\tEpoch 40/100 - Train loss: 0.2029 - Val accuracy: 0.2222 - Val loss: 1.0942 - Val F1: 0.0808 - LR: 6.00e-05\n",
      "\tEpoch 50/100 - Train loss: 0.1446 - Val accuracy: 0.7778 - Val loss: 0.5758 - Val F1: 0.7037 - LR: 5.00e-05\n",
      "\tEpoch 60/100 - Train loss: 0.1210 - Val accuracy: 0.8889 - Val loss: 0.3837 - Val F1: 0.8815 - LR: 4.00e-05\n",
      "\tEpoch 70/100 - Train loss: 0.0989 - Val accuracy: 0.8889 - Val loss: 0.3323 - Val F1: 0.8815 - LR: 3.00e-05\n",
      "\tEpoch 80/100 - Train loss: 0.0901 - Val accuracy: 0.8889 - Val loss: 0.3170 - Val F1: 0.8815 - LR: 2.00e-05\n",
      "\tEpoch 90/100 - Train loss: 0.0741 - Val accuracy: 0.8889 - Val loss: 0.3113 - Val F1: 0.8815 - LR: 1.00e-05\n",
      "\tEpoch 100/100 - Train loss: 0.0701 - Val accuracy: 0.8889 - Val loss: 0.3101 - Val F1: 0.8815 - LR: 0.00e+00\n",
      "\tBest epoch: 100 - Best val accuracy: 0.8889 - Best val loss: 0.3101 - Best val F1: 0.8815\n",
      "\n",
      "Source class: WAL | Domain: 20 | Accuracy: 0.9200 | Loss: 0.2493 | F1: 0.9135\n",
      "\n",
      "Domain: 21\n",
      "x_dp_dom.shape: (47, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Training and evaluating on Dp data via cross-validation...\n",
      "\tEpoch 10/100 - Train loss: 0.5935 - Val accuracy: 0.2500 - Val loss: 1.1161 - Val F1: 0.1000 - LR: 9.00e-05\n",
      "\tEpoch 20/100 - Train loss: 0.3566 - Val accuracy: 0.2500 - Val loss: 1.2039 - Val F1: 0.1000 - LR: 8.00e-05\n",
      "\tEpoch 30/100 - Train loss: 0.2392 - Val accuracy: 0.2500 - Val loss: 1.4114 - Val F1: 0.1000 - LR: 7.00e-05\n",
      "\tEpoch 40/100 - Train loss: 0.1710 - Val accuracy: 0.2500 - Val loss: 1.4345 - Val F1: 0.1000 - LR: 6.00e-05\n",
      "\tEpoch 50/100 - Train loss: 0.1152 - Val accuracy: 0.7500 - Val loss: 0.8611 - Val F1: 0.7222 - LR: 5.00e-05\n",
      "\tEpoch 60/100 - Train loss: 0.0981 - Val accuracy: 0.8750 - Val loss: 0.4009 - Val F1: 0.8250 - LR: 4.00e-05\n",
      "\tEpoch 70/100 - Train loss: 0.0791 - Val accuracy: 0.8750 - Val loss: 0.2680 - Val F1: 0.8250 - LR: 3.00e-05\n",
      "\tEpoch 80/100 - Train loss: 0.0721 - Val accuracy: 0.8750 - Val loss: 0.2179 - Val F1: 0.8250 - LR: 2.00e-05\n",
      "\tEpoch 90/100 - Train loss: 0.0629 - Val accuracy: 0.8750 - Val loss: 0.1981 - Val F1: 0.8250 - LR: 1.00e-05\n",
      "\tEpoch 100/100 - Train loss: 0.0623 - Val accuracy: 0.8750 - Val loss: 0.1912 - Val F1: 0.8250 - LR: 0.00e+00\n",
      "\tBest epoch: 100 - Best val accuracy: 0.8750 - Best val loss: 0.1912 - Best val F1: 0.8250\n",
      "\n",
      "\tEpoch 10/100 - Train loss: 0.6411 - Val accuracy: 0.2500 - Val loss: 1.0642 - Val F1: 0.1000 - LR: 9.00e-05\n",
      "\tEpoch 20/100 - Train loss: 0.3621 - Val accuracy: 0.2500 - Val loss: 1.1304 - Val F1: 0.1000 - LR: 8.00e-05\n",
      "\tEpoch 30/100 - Train loss: 0.2324 - Val accuracy: 0.2500 - Val loss: 1.2916 - Val F1: 0.1000 - LR: 7.00e-05\n",
      "\tEpoch 40/100 - Train loss: 0.1643 - Val accuracy: 0.2500 - Val loss: 1.1485 - Val F1: 0.1000 - LR: 6.00e-05\n",
      "\tEpoch 50/100 - Train loss: 0.1020 - Val accuracy: 0.8750 - Val loss: 0.5486 - Val F1: 0.8250 - LR: 5.00e-05\n",
      "\tEpoch 60/100 - Train loss: 0.0811 - Val accuracy: 0.8750 - Val loss: 0.2929 - Val F1: 0.8250 - LR: 4.00e-05\n",
      "\tEpoch 70/100 - Train loss: 0.0678 - Val accuracy: 0.8750 - Val loss: 0.2379 - Val F1: 0.8250 - LR: 3.00e-05\n",
      "\tEpoch 80/100 - Train loss: 0.0624 - Val accuracy: 0.8750 - Val loss: 0.2195 - Val F1: 0.8250 - LR: 2.00e-05\n",
      "\tEpoch 90/100 - Train loss: 0.0528 - Val accuracy: 0.8750 - Val loss: 0.2120 - Val F1: 0.8250 - LR: 1.00e-05\n",
      "\tEpoch 100/100 - Train loss: 0.0532 - Val accuracy: 0.8750 - Val loss: 0.2093 - Val F1: 0.8250 - LR: 0.00e+00\n",
      "\tBest epoch: 100 - Best val accuracy: 0.8750 - Best val loss: 0.2093 - Best val F1: 0.8250\n",
      "\n",
      "\tEpoch 10/100 - Train loss: 0.5813 - Val accuracy: 0.2500 - Val loss: 1.1115 - Val F1: 0.1000 - LR: 9.00e-05\n",
      "\tEpoch 20/100 - Train loss: 0.3721 - Val accuracy: 0.2500 - Val loss: 1.2449 - Val F1: 0.1000 - LR: 8.00e-05\n",
      "\tEpoch 30/100 - Train loss: 0.2529 - Val accuracy: 0.2500 - Val loss: 1.4824 - Val F1: 0.1000 - LR: 7.00e-05\n",
      "\tEpoch 40/100 - Train loss: 0.1994 - Val accuracy: 0.2500 - Val loss: 1.5393 - Val F1: 0.1000 - LR: 6.00e-05\n",
      "\tEpoch 50/100 - Train loss: 0.1464 - Val accuracy: 0.5000 - Val loss: 0.8903 - Val F1: 0.4821 - LR: 5.00e-05\n",
      "\tEpoch 60/100 - Train loss: 0.1109 - Val accuracy: 0.8750 - Val loss: 0.3635 - Val F1: 0.8250 - LR: 4.00e-05\n",
      "\tEpoch 70/100 - Train loss: 0.0992 - Val accuracy: 0.8750 - Val loss: 0.2413 - Val F1: 0.8250 - LR: 3.00e-05\n",
      "\tEpoch 80/100 - Train loss: 0.0834 - Val accuracy: 0.8750 - Val loss: 0.2056 - Val F1: 0.8250 - LR: 2.00e-05\n",
      "\tEpoch 90/100 - Train loss: 0.0706 - Val accuracy: 0.8750 - Val loss: 0.1905 - Val F1: 0.8250 - LR: 1.00e-05\n",
      "\tEpoch 100/100 - Train loss: 0.0675 - Val accuracy: 0.8750 - Val loss: 0.1848 - Val F1: 0.8250 - LR: 0.00e+00\n",
      "\tBest epoch: 100 - Best val accuracy: 0.8750 - Best val loss: 0.1848 - Best val F1: 0.8250\n",
      "\n",
      "\tEpoch 10/100 - Train loss: 0.6389 - Val accuracy: 0.2500 - Val loss: 1.0978 - Val F1: 0.1000 - LR: 9.00e-05\n",
      "\tEpoch 20/100 - Train loss: 0.3921 - Val accuracy: 0.2500 - Val loss: 1.1353 - Val F1: 0.1000 - LR: 8.00e-05\n",
      "\tEpoch 30/100 - Train loss: 0.2581 - Val accuracy: 0.2500 - Val loss: 1.2749 - Val F1: 0.1000 - LR: 7.00e-05\n",
      "\tEpoch 40/100 - Train loss: 0.1754 - Val accuracy: 0.2500 - Val loss: 1.3299 - Val F1: 0.1000 - LR: 6.00e-05\n",
      "\tEpoch 50/100 - Train loss: 0.1339 - Val accuracy: 0.5000 - Val loss: 0.8885 - Val F1: 0.4821 - LR: 5.00e-05\n",
      "\tEpoch 60/100 - Train loss: 0.1038 - Val accuracy: 0.8750 - Val loss: 0.4530 - Val F1: 0.8250 - LR: 4.00e-05\n",
      "\tEpoch 70/100 - Train loss: 0.0787 - Val accuracy: 0.8750 - Val loss: 0.3359 - Val F1: 0.8250 - LR: 3.00e-05\n",
      "\tEpoch 80/100 - Train loss: 0.0768 - Val accuracy: 0.8750 - Val loss: 0.3055 - Val F1: 0.8250 - LR: 2.00e-05\n",
      "\tEpoch 90/100 - Train loss: 0.0632 - Val accuracy: 0.8750 - Val loss: 0.2960 - Val F1: 0.8250 - LR: 1.00e-05\n",
      "\tEpoch 100/100 - Train loss: 0.0665 - Val accuracy: 0.8750 - Val loss: 0.2936 - Val F1: 0.8250 - LR: 0.00e+00\n",
      "\tBest epoch: 100 - Best val accuracy: 0.8750 - Best val loss: 0.2936 - Best val F1: 0.8250\n",
      "\n",
      "\tEpoch 10/100 - Train loss: 0.5760 - Val accuracy: 0.2500 - Val loss: 1.0791 - Val F1: 0.1000 - LR: 9.00e-05\n",
      "\tEpoch 20/100 - Train loss: 0.3754 - Val accuracy: 0.2500 - Val loss: 1.1442 - Val F1: 0.1000 - LR: 8.00e-05\n",
      "\tEpoch 30/100 - Train loss: 0.2483 - Val accuracy: 0.2500 - Val loss: 1.3097 - Val F1: 0.1000 - LR: 7.00e-05\n",
      "\tEpoch 40/100 - Train loss: 0.2014 - Val accuracy: 0.2500 - Val loss: 1.3388 - Val F1: 0.1000 - LR: 6.00e-05\n",
      "\tEpoch 50/100 - Train loss: 0.1457 - Val accuracy: 0.7500 - Val loss: 0.7987 - Val F1: 0.7222 - LR: 5.00e-05\n",
      "\tEpoch 60/100 - Train loss: 0.1170 - Val accuracy: 0.8750 - Val loss: 0.4076 - Val F1: 0.8250 - LR: 4.00e-05\n",
      "\tEpoch 70/100 - Train loss: 0.0982 - Val accuracy: 0.8750 - Val loss: 0.3211 - Val F1: 0.8250 - LR: 3.00e-05\n",
      "\tEpoch 80/100 - Train loss: 0.0821 - Val accuracy: 0.8750 - Val loss: 0.3048 - Val F1: 0.8250 - LR: 2.00e-05\n",
      "\tEpoch 90/100 - Train loss: 0.0671 - Val accuracy: 0.8750 - Val loss: 0.3012 - Val F1: 0.8250 - LR: 1.00e-05\n",
      "\tEpoch 100/100 - Train loss: 0.0724 - Val accuracy: 0.8750 - Val loss: 0.3006 - Val F1: 0.8250 - LR: 0.00e+00\n",
      "\tBest epoch: 98 - Best val accuracy: 0.8750 - Best val loss: 0.3005 - Best val F1: 0.8250\n",
      "\n",
      "Source class: WAL | Domain: 21 | Accuracy: 0.8956 | Loss: 0.2821 | F1: 0.8754\n",
      "\n",
      "Domain: 22\n",
      "x_dp_dom.shape: (54, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Training and evaluating on Dp data via cross-validation...\n",
      "\tEpoch 10/100 - Train loss: 0.6867 - Val accuracy: 0.2222 - Val loss: 1.1204 - Val F1: 0.0808 - LR: 9.00e-05\n",
      "\tEpoch 20/100 - Train loss: 0.4263 - Val accuracy: 0.2222 - Val loss: 1.2344 - Val F1: 0.0808 - LR: 8.00e-05\n",
      "\tEpoch 30/100 - Train loss: 0.2524 - Val accuracy: 0.2222 - Val loss: 1.4518 - Val F1: 0.0889 - LR: 7.00e-05\n",
      "\tEpoch 40/100 - Train loss: 0.1729 - Val accuracy: 0.2222 - Val loss: 1.6135 - Val F1: 0.0889 - LR: 6.00e-05\n",
      "\tEpoch 50/100 - Train loss: 0.1300 - Val accuracy: 0.2222 - Val loss: 1.2798 - Val F1: 0.0889 - LR: 5.00e-05\n",
      "\tEpoch 60/100 - Train loss: 0.0923 - Val accuracy: 0.8889 - Val loss: 0.6193 - Val F1: 0.8815 - LR: 4.00e-05\n",
      "\tEpoch 70/100 - Train loss: 0.0770 - Val accuracy: 0.7778 - Val loss: 0.3872 - Val F1: 0.7778 - LR: 3.00e-05\n",
      "\tEpoch 80/100 - Train loss: 0.0679 - Val accuracy: 0.7778 - Val loss: 0.3361 - Val F1: 0.7778 - LR: 2.00e-05\n",
      "\tEpoch 90/100 - Train loss: 0.0721 - Val accuracy: 0.7778 - Val loss: 0.3221 - Val F1: 0.7778 - LR: 1.00e-05\n",
      "\tEpoch 100/100 - Train loss: 0.0582 - Val accuracy: 0.7778 - Val loss: 0.3178 - Val F1: 0.7778 - LR: 0.00e+00\n",
      "\tBest epoch: 100 - Best val accuracy: 0.7778 - Best val loss: 0.3178 - Best val F1: 0.7778\n",
      "\n",
      "\tEpoch 10/100 - Train loss: 0.7480 - Val accuracy: 0.5556 - Val loss: 1.0920 - Val F1: 0.3968 - LR: 9.00e-05\n",
      "\tEpoch 20/100 - Train loss: 0.4685 - Val accuracy: 0.2222 - Val loss: 1.1806 - Val F1: 0.0808 - LR: 8.00e-05\n",
      "\tEpoch 30/100 - Train loss: 0.3229 - Val accuracy: 0.2222 - Val loss: 1.3894 - Val F1: 0.0808 - LR: 7.00e-05\n",
      "\tEpoch 40/100 - Train loss: 0.2243 - Val accuracy: 0.2222 - Val loss: 1.5472 - Val F1: 0.0808 - LR: 6.00e-05\n",
      "\tEpoch 50/100 - Train loss: 0.1788 - Val accuracy: 0.2222 - Val loss: 1.1262 - Val F1: 0.0988 - LR: 5.00e-05\n",
      "\tEpoch 60/100 - Train loss: 0.1361 - Val accuracy: 0.8889 - Val loss: 0.4754 - Val F1: 0.8815 - LR: 4.00e-05\n",
      "\tEpoch 70/100 - Train loss: 0.1160 - Val accuracy: 1.0000 - Val loss: 0.3011 - Val F1: 1.0000 - LR: 3.00e-05\n",
      "\tEpoch 80/100 - Train loss: 0.0987 - Val accuracy: 0.8889 - Val loss: 0.2672 - Val F1: 0.8815 - LR: 2.00e-05\n",
      "\tEpoch 90/100 - Train loss: 0.0950 - Val accuracy: 0.8889 - Val loss: 0.2579 - Val F1: 0.8815 - LR: 1.00e-05\n",
      "\tEpoch 100/100 - Train loss: 0.0996 - Val accuracy: 0.8889 - Val loss: 0.2532 - Val F1: 0.8815 - LR: 0.00e+00\n",
      "\tBest epoch: 100 - Best val accuracy: 0.8889 - Best val loss: 0.2532 - Best val F1: 0.8815\n",
      "\n",
      "\tEpoch 10/100 - Train loss: 0.7417 - Val accuracy: 0.2222 - Val loss: 1.0965 - Val F1: 0.0808 - LR: 9.00e-05\n",
      "\tEpoch 20/100 - Train loss: 0.4588 - Val accuracy: 0.2222 - Val loss: 1.1578 - Val F1: 0.0808 - LR: 8.00e-05\n",
      "\tEpoch 30/100 - Train loss: 0.3143 - Val accuracy: 0.2222 - Val loss: 1.2648 - Val F1: 0.0988 - LR: 7.00e-05\n",
      "\tEpoch 40/100 - Train loss: 0.2296 - Val accuracy: 0.2222 - Val loss: 1.1969 - Val F1: 0.0988 - LR: 6.00e-05\n",
      "\tEpoch 50/100 - Train loss: 0.1616 - Val accuracy: 1.0000 - Val loss: 0.6685 - Val F1: 1.0000 - LR: 5.00e-05\n",
      "\tEpoch 60/100 - Train loss: 0.1373 - Val accuracy: 1.0000 - Val loss: 0.3499 - Val F1: 1.0000 - LR: 4.00e-05\n",
      "\tEpoch 70/100 - Train loss: 0.1098 - Val accuracy: 1.0000 - Val loss: 0.2700 - Val F1: 1.0000 - LR: 3.00e-05\n",
      "\tEpoch 80/100 - Train loss: 0.0903 - Val accuracy: 1.0000 - Val loss: 0.2469 - Val F1: 1.0000 - LR: 2.00e-05\n",
      "\tEpoch 90/100 - Train loss: 0.0853 - Val accuracy: 0.8889 - Val loss: 0.2382 - Val F1: 0.8754 - LR: 1.00e-05\n",
      "\tEpoch 100/100 - Train loss: 0.0805 - Val accuracy: 0.8889 - Val loss: 0.2352 - Val F1: 0.8754 - LR: 0.00e+00\n",
      "\tBest epoch: 100 - Best val accuracy: 0.8889 - Best val loss: 0.2352 - Best val F1: 0.8754\n",
      "\n",
      "\tEpoch 10/100 - Train loss: 0.6222 - Val accuracy: 0.2222 - Val loss: 1.1135 - Val F1: 0.0808 - LR: 9.00e-05\n",
      "\tEpoch 20/100 - Train loss: 0.3750 - Val accuracy: 0.1111 - Val loss: 1.1884 - Val F1: 0.0635 - LR: 8.00e-05\n",
      "\tEpoch 30/100 - Train loss: 0.2497 - Val accuracy: 0.2222 - Val loss: 1.3308 - Val F1: 0.0988 - LR: 7.00e-05\n",
      "\tEpoch 40/100 - Train loss: 0.1683 - Val accuracy: 0.3333 - Val loss: 1.3415 - Val F1: 0.2000 - LR: 6.00e-05\n",
      "\tEpoch 50/100 - Train loss: 0.1265 - Val accuracy: 0.4444 - Val loss: 0.8624 - Val F1: 0.4804 - LR: 5.00e-05\n",
      "\tEpoch 60/100 - Train loss: 0.1019 - Val accuracy: 0.7778 - Val loss: 0.4926 - Val F1: 0.7778 - LR: 4.00e-05\n",
      "\tEpoch 70/100 - Train loss: 0.0793 - Val accuracy: 0.7778 - Val loss: 0.4240 - Val F1: 0.7643 - LR: 3.00e-05\n",
      "\tEpoch 80/100 - Train loss: 0.0724 - Val accuracy: 0.7778 - Val loss: 0.4216 - Val F1: 0.7643 - LR: 2.00e-05\n",
      "\tEpoch 90/100 - Train loss: 0.0751 - Val accuracy: 0.7778 - Val loss: 0.4238 - Val F1: 0.7643 - LR: 1.00e-05\n",
      "\tEpoch 100/100 - Train loss: 0.0641 - Val accuracy: 0.7778 - Val loss: 0.4250 - Val F1: 0.7643 - LR: 0.00e+00\n",
      "\tBest epoch: 75 - Best val accuracy: 0.7778 - Best val loss: 0.4208 - Best val F1: 0.7643\n",
      "\n",
      "\tEpoch 10/100 - Train loss: 0.7340 - Val accuracy: 0.2222 - Val loss: 1.1236 - Val F1: 0.0808 - LR: 9.00e-05\n",
      "\tEpoch 20/100 - Train loss: 0.4876 - Val accuracy: 0.2222 - Val loss: 1.1879 - Val F1: 0.0808 - LR: 8.00e-05\n",
      "\tEpoch 30/100 - Train loss: 0.3294 - Val accuracy: 0.2222 - Val loss: 1.3075 - Val F1: 0.0889 - LR: 7.00e-05\n",
      "\tEpoch 40/100 - Train loss: 0.2393 - Val accuracy: 0.2222 - Val loss: 1.2605 - Val F1: 0.0889 - LR: 6.00e-05\n",
      "\tEpoch 50/100 - Train loss: 0.1619 - Val accuracy: 0.7778 - Val loss: 0.7456 - Val F1: 0.7827 - LR: 5.00e-05\n",
      "\tEpoch 60/100 - Train loss: 0.1266 - Val accuracy: 1.0000 - Val loss: 0.3554 - Val F1: 1.0000 - LR: 4.00e-05\n",
      "\tEpoch 70/100 - Train loss: 0.1089 - Val accuracy: 1.0000 - Val loss: 0.2559 - Val F1: 1.0000 - LR: 3.00e-05\n",
      "\tEpoch 80/100 - Train loss: 0.0901 - Val accuracy: 1.0000 - Val loss: 0.2318 - Val F1: 1.0000 - LR: 2.00e-05\n",
      "\tEpoch 90/100 - Train loss: 0.0892 - Val accuracy: 1.0000 - Val loss: 0.2228 - Val F1: 1.0000 - LR: 1.00e-05\n",
      "\tEpoch 100/100 - Train loss: 0.0784 - Val accuracy: 1.0000 - Val loss: 0.2193 - Val F1: 1.0000 - LR: 0.00e+00\n",
      "\tBest epoch: 100 - Best val accuracy: 1.0000 - Best val loss: 0.2193 - Best val F1: 1.0000\n",
      "\n",
      "Source class: WAL | Domain: 22 | Accuracy: 0.8673 | Loss: 0.3081 | F1: 0.8491\n",
      "\n",
      "Domain: 23\n",
      "x_dp_dom.shape: (52, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Training and evaluating on Dp data via cross-validation...\n",
      "\tEpoch 10/100 - Train loss: 0.6730 - Val accuracy: 0.3333 - Val loss: 1.1212 - Val F1: 0.2000 - LR: 9.00e-05\n",
      "\tEpoch 20/100 - Train loss: 0.4538 - Val accuracy: 0.2222 - Val loss: 1.2214 - Val F1: 0.0808 - LR: 8.00e-05\n",
      "\tEpoch 30/100 - Train loss: 0.3321 - Val accuracy: 0.4444 - Val loss: 1.3612 - Val F1: 0.2889 - LR: 7.00e-05\n",
      "\tEpoch 40/100 - Train loss: 0.2480 - Val accuracy: 0.3333 - Val loss: 1.2787 - Val F1: 0.2000 - LR: 6.00e-05\n",
      "\tEpoch 50/100 - Train loss: 0.2029 - Val accuracy: 0.6667 - Val loss: 0.7965 - Val F1: 0.6918 - LR: 5.00e-05\n",
      "\tEpoch 60/100 - Train loss: 0.1551 - Val accuracy: 0.7778 - Val loss: 0.4777 - Val F1: 0.7901 - LR: 4.00e-05\n",
      "\tEpoch 70/100 - Train loss: 0.1267 - Val accuracy: 0.8889 - Val loss: 0.3704 - Val F1: 0.8815 - LR: 3.00e-05\n",
      "\tEpoch 80/100 - Train loss: 0.1138 - Val accuracy: 0.8889 - Val loss: 0.3287 - Val F1: 0.8815 - LR: 2.00e-05\n",
      "\tEpoch 90/100 - Train loss: 0.1033 - Val accuracy: 0.8889 - Val loss: 0.3105 - Val F1: 0.8815 - LR: 1.00e-05\n",
      "\tEpoch 100/100 - Train loss: 0.0955 - Val accuracy: 0.8889 - Val loss: 0.3023 - Val F1: 0.8815 - LR: 0.00e+00\n",
      "\tBest epoch: 100 - Best val accuracy: 0.8889 - Best val loss: 0.3023 - Best val F1: 0.8815\n",
      "\n",
      "\tEpoch 10/100 - Train loss: 0.5813 - Val accuracy: 0.2222 - Val loss: 1.1141 - Val F1: 0.0808 - LR: 9.00e-05\n",
      "\tEpoch 20/100 - Train loss: 0.3748 - Val accuracy: 0.2222 - Val loss: 1.2541 - Val F1: 0.0808 - LR: 8.00e-05\n",
      "\tEpoch 30/100 - Train loss: 0.2304 - Val accuracy: 0.2222 - Val loss: 1.4362 - Val F1: 0.0889 - LR: 7.00e-05\n",
      "\tEpoch 40/100 - Train loss: 0.1854 - Val accuracy: 0.2222 - Val loss: 1.1245 - Val F1: 0.1481 - LR: 6.00e-05\n",
      "\tEpoch 50/100 - Train loss: 0.1397 - Val accuracy: 0.7778 - Val loss: 0.5051 - Val F1: 0.7037 - LR: 5.00e-05\n",
      "\tEpoch 60/100 - Train loss: 0.1101 - Val accuracy: 0.8889 - Val loss: 0.2966 - Val F1: 0.8815 - LR: 4.00e-05\n",
      "\tEpoch 70/100 - Train loss: 0.0968 - Val accuracy: 0.8889 - Val loss: 0.2470 - Val F1: 0.8815 - LR: 3.00e-05\n",
      "\tEpoch 80/100 - Train loss: 0.0829 - Val accuracy: 0.8889 - Val loss: 0.2293 - Val F1: 0.8815 - LR: 2.00e-05\n",
      "\tEpoch 90/100 - Train loss: 0.0747 - Val accuracy: 0.8889 - Val loss: 0.2220 - Val F1: 0.8815 - LR: 1.00e-05\n",
      "\tEpoch 100/100 - Train loss: 0.0680 - Val accuracy: 0.8889 - Val loss: 0.2194 - Val F1: 0.8815 - LR: 0.00e+00\n",
      "\tBest epoch: 100 - Best val accuracy: 0.8889 - Best val loss: 0.2194 - Best val F1: 0.8815\n",
      "\n",
      "\tEpoch 10/100 - Train loss: 0.6715 - Val accuracy: 0.2222 - Val loss: 1.1271 - Val F1: 0.0808 - LR: 9.00e-05\n",
      "\tEpoch 20/100 - Train loss: 0.4250 - Val accuracy: 0.2222 - Val loss: 1.2311 - Val F1: 0.0808 - LR: 8.00e-05\n",
      "\tEpoch 30/100 - Train loss: 0.2838 - Val accuracy: 0.2222 - Val loss: 1.3956 - Val F1: 0.0808 - LR: 7.00e-05\n",
      "\tEpoch 40/100 - Train loss: 0.2211 - Val accuracy: 0.2222 - Val loss: 1.1800 - Val F1: 0.0988 - LR: 6.00e-05\n",
      "\tEpoch 50/100 - Train loss: 0.1625 - Val accuracy: 0.7778 - Val loss: 0.5824 - Val F1: 0.7037 - LR: 5.00e-05\n",
      "\tEpoch 60/100 - Train loss: 0.1359 - Val accuracy: 0.8889 - Val loss: 0.3485 - Val F1: 0.8815 - LR: 4.00e-05\n",
      "\tEpoch 70/100 - Train loss: 0.1141 - Val accuracy: 1.0000 - Val loss: 0.2951 - Val F1: 1.0000 - LR: 3.00e-05\n",
      "\tEpoch 80/100 - Train loss: 0.0943 - Val accuracy: 0.8889 - Val loss: 0.2802 - Val F1: 0.8815 - LR: 2.00e-05\n",
      "\tEpoch 90/100 - Train loss: 0.0825 - Val accuracy: 0.8889 - Val loss: 0.2744 - Val F1: 0.8815 - LR: 1.00e-05\n",
      "\tEpoch 100/100 - Train loss: 0.0834 - Val accuracy: 0.8889 - Val loss: 0.2725 - Val F1: 0.8815 - LR: 0.00e+00\n",
      "\tBest epoch: 100 - Best val accuracy: 0.8889 - Best val loss: 0.2725 - Best val F1: 0.8815\n",
      "\n",
      "\tEpoch 10/100 - Train loss: 0.5966 - Val accuracy: 0.2222 - Val loss: 1.1006 - Val F1: 0.0808 - LR: 9.00e-05\n",
      "\tEpoch 20/100 - Train loss: 0.3813 - Val accuracy: 0.2222 - Val loss: 1.1782 - Val F1: 0.0808 - LR: 8.00e-05\n",
      "\tEpoch 30/100 - Train loss: 0.2813 - Val accuracy: 0.2222 - Val loss: 1.2947 - Val F1: 0.0808 - LR: 7.00e-05\n",
      "\tEpoch 40/100 - Train loss: 0.2222 - Val accuracy: 0.2222 - Val loss: 1.1367 - Val F1: 0.0889 - LR: 6.00e-05\n",
      "\tEpoch 50/100 - Train loss: 0.1583 - Val accuracy: 0.7778 - Val loss: 0.6036 - Val F1: 0.7037 - LR: 5.00e-05\n",
      "\tEpoch 60/100 - Train loss: 0.1385 - Val accuracy: 0.8889 - Val loss: 0.3577 - Val F1: 0.8815 - LR: 4.00e-05\n",
      "\tEpoch 70/100 - Train loss: 0.1137 - Val accuracy: 0.8889 - Val loss: 0.2828 - Val F1: 0.8815 - LR: 3.00e-05\n",
      "\tEpoch 80/100 - Train loss: 0.1038 - Val accuracy: 0.8889 - Val loss: 0.2505 - Val F1: 0.8815 - LR: 2.00e-05\n",
      "\tEpoch 90/100 - Train loss: 0.0945 - Val accuracy: 0.8889 - Val loss: 0.2363 - Val F1: 0.8815 - LR: 1.00e-05\n",
      "\tEpoch 100/100 - Train loss: 0.0851 - Val accuracy: 0.8889 - Val loss: 0.2313 - Val F1: 0.8815 - LR: 0.00e+00\n",
      "\tBest epoch: 100 - Best val accuracy: 0.8889 - Best val loss: 0.2313 - Best val F1: 0.8815\n",
      "\n",
      "\tEpoch 10/100 - Train loss: 0.6146 - Val accuracy: 0.5556 - Val loss: 1.0824 - Val F1: 0.3968 - LR: 9.00e-05\n",
      "\tEpoch 20/100 - Train loss: 0.4081 - Val accuracy: 0.2222 - Val loss: 1.1771 - Val F1: 0.0808 - LR: 8.00e-05\n",
      "\tEpoch 30/100 - Train loss: 0.2858 - Val accuracy: 0.2222 - Val loss: 1.3284 - Val F1: 0.0808 - LR: 7.00e-05\n",
      "\tEpoch 40/100 - Train loss: 0.2062 - Val accuracy: 0.2222 - Val loss: 1.2722 - Val F1: 0.0889 - LR: 6.00e-05\n",
      "\tEpoch 50/100 - Train loss: 0.1590 - Val accuracy: 0.6667 - Val loss: 0.8042 - Val F1: 0.6208 - LR: 5.00e-05\n",
      "\tEpoch 60/100 - Train loss: 0.1177 - Val accuracy: 0.6667 - Val loss: 0.4973 - Val F1: 0.6420 - LR: 4.00e-05\n",
      "\tEpoch 70/100 - Train loss: 0.1045 - Val accuracy: 0.8889 - Val loss: 0.3888 - Val F1: 0.8815 - LR: 3.00e-05\n",
      "\tEpoch 80/100 - Train loss: 0.0886 - Val accuracy: 0.8889 - Val loss: 0.3454 - Val F1: 0.8815 - LR: 2.00e-05\n",
      "\tEpoch 90/100 - Train loss: 0.0863 - Val accuracy: 0.8889 - Val loss: 0.3271 - Val F1: 0.8815 - LR: 1.00e-05\n",
      "\tEpoch 100/100 - Train loss: 0.0785 - Val accuracy: 0.8889 - Val loss: 0.3192 - Val F1: 0.8815 - LR: 0.00e+00\n",
      "\tBest epoch: 100 - Best val accuracy: 0.8889 - Best val loss: 0.3192 - Best val F1: 0.8815\n",
      "\n",
      "Source class: WAL | Domain: 23 | Accuracy: 0.8255 | Loss: 0.3083 | F1: 0.7918\n",
      "\n",
      "Domain: 24\n",
      "x_dp_dom.shape: (51, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Training and evaluating on Dp data via cross-validation...\n",
      "\tEpoch 10/100 - Train loss: 0.6339 - Val accuracy: 0.2500 - Val loss: 1.1151 - Val F1: 0.1000 - LR: 9.00e-05\n",
      "\tEpoch 20/100 - Train loss: 0.3992 - Val accuracy: 0.2500 - Val loss: 1.1565 - Val F1: 0.1000 - LR: 8.00e-05\n",
      "\tEpoch 30/100 - Train loss: 0.3307 - Val accuracy: 0.5000 - Val loss: 1.1542 - Val F1: 0.3333 - LR: 7.00e-05\n",
      "\tEpoch 40/100 - Train loss: 0.2667 - Val accuracy: 0.7500 - Val loss: 0.8641 - Val F1: 0.7500 - LR: 6.00e-05\n",
      "\tEpoch 50/100 - Train loss: 0.2290 - Val accuracy: 0.8750 - Val loss: 0.5411 - Val F1: 0.8786 - LR: 5.00e-05\n",
      "\tEpoch 60/100 - Train loss: 0.1922 - Val accuracy: 1.0000 - Val loss: 0.3743 - Val F1: 1.0000 - LR: 4.00e-05\n",
      "\tEpoch 70/100 - Train loss: 0.1722 - Val accuracy: 1.0000 - Val loss: 0.2999 - Val F1: 1.0000 - LR: 3.00e-05\n",
      "\tEpoch 80/100 - Train loss: 0.1567 - Val accuracy: 1.0000 - Val loss: 0.2630 - Val F1: 1.0000 - LR: 2.00e-05\n",
      "\tEpoch 90/100 - Train loss: 0.1442 - Val accuracy: 1.0000 - Val loss: 0.2440 - Val F1: 1.0000 - LR: 1.00e-05\n",
      "\tEpoch 100/100 - Train loss: 0.1484 - Val accuracy: 1.0000 - Val loss: 0.2362 - Val F1: 1.0000 - LR: 0.00e+00\n",
      "\tBest epoch: 100 - Best val accuracy: 1.0000 - Best val loss: 0.2362 - Best val F1: 1.0000\n",
      "\n",
      "\tEpoch 10/100 - Train loss: 0.6376 - Val accuracy: 0.5556 - Val loss: 1.0895 - Val F1: 0.3968 - LR: 9.00e-05\n",
      "\tEpoch 20/100 - Train loss: 0.4382 - Val accuracy: 0.2222 - Val loss: 1.1636 - Val F1: 0.0808 - LR: 8.00e-05\n",
      "\tEpoch 30/100 - Train loss: 0.3279 - Val accuracy: 0.2222 - Val loss: 1.1454 - Val F1: 0.0988 - LR: 7.00e-05\n",
      "\tEpoch 40/100 - Train loss: 0.2772 - Val accuracy: 0.7778 - Val loss: 0.8047 - Val F1: 0.7827 - LR: 6.00e-05\n",
      "\tEpoch 50/100 - Train loss: 0.2367 - Val accuracy: 0.7778 - Val loss: 0.5839 - Val F1: 0.7827 - LR: 5.00e-05\n",
      "\tEpoch 60/100 - Train loss: 0.1848 - Val accuracy: 0.7778 - Val loss: 0.5003 - Val F1: 0.7827 - LR: 4.00e-05\n",
      "\tEpoch 70/100 - Train loss: 0.1652 - Val accuracy: 0.8889 - Val loss: 0.4514 - Val F1: 0.8938 - LR: 3.00e-05\n",
      "\tEpoch 80/100 - Train loss: 0.1405 - Val accuracy: 0.8889 - Val loss: 0.4252 - Val F1: 0.8938 - LR: 2.00e-05\n",
      "\tEpoch 90/100 - Train loss: 0.1529 - Val accuracy: 0.8889 - Val loss: 0.4119 - Val F1: 0.8938 - LR: 1.00e-05\n",
      "\tEpoch 100/100 - Train loss: 0.1468 - Val accuracy: 0.8889 - Val loss: 0.4050 - Val F1: 0.8938 - LR: 0.00e+00\n",
      "\tBest epoch: 100 - Best val accuracy: 0.8889 - Best val loss: 0.4050 - Best val F1: 0.8938\n",
      "\n",
      "\tEpoch 10/100 - Train loss: 0.6009 - Val accuracy: 0.2222 - Val loss: 1.1204 - Val F1: 0.0808 - LR: 9.00e-05\n",
      "\tEpoch 20/100 - Train loss: 0.4143 - Val accuracy: 0.2222 - Val loss: 1.1956 - Val F1: 0.0808 - LR: 8.00e-05\n",
      "\tEpoch 30/100 - Train loss: 0.3246 - Val accuracy: 0.2222 - Val loss: 1.2624 - Val F1: 0.0808 - LR: 7.00e-05\n",
      "\tEpoch 40/100 - Train loss: 0.2781 - Val accuracy: 0.3333 - Val loss: 1.0899 - Val F1: 0.2963 - LR: 6.00e-05\n",
      "\tEpoch 50/100 - Train loss: 0.2496 - Val accuracy: 0.7778 - Val loss: 0.7490 - Val F1: 0.7827 - LR: 5.00e-05\n",
      "\tEpoch 60/100 - Train loss: 0.2080 - Val accuracy: 0.7778 - Val loss: 0.6066 - Val F1: 0.7827 - LR: 4.00e-05\n",
      "\tEpoch 70/100 - Train loss: 0.1868 - Val accuracy: 0.8889 - Val loss: 0.5495 - Val F1: 0.8938 - LR: 3.00e-05\n",
      "\tEpoch 80/100 - Train loss: 0.1566 - Val accuracy: 0.8889 - Val loss: 0.5189 - Val F1: 0.8938 - LR: 2.00e-05\n",
      "\tEpoch 90/100 - Train loss: 0.1443 - Val accuracy: 0.8889 - Val loss: 0.5031 - Val F1: 0.8938 - LR: 1.00e-05\n",
      "\tEpoch 100/100 - Train loss: 0.1457 - Val accuracy: 0.8889 - Val loss: 0.4960 - Val F1: 0.8938 - LR: 0.00e+00\n",
      "\tBest epoch: 100 - Best val accuracy: 0.8889 - Best val loss: 0.4960 - Best val F1: 0.8938\n",
      "\n",
      "\tEpoch 10/100 - Train loss: 0.6242 - Val accuracy: 0.5556 - Val loss: 1.0871 - Val F1: 0.5278 - LR: 9.00e-05\n",
      "\tEpoch 20/100 - Train loss: 0.4374 - Val accuracy: 0.2222 - Val loss: 1.1424 - Val F1: 0.0808 - LR: 8.00e-05\n",
      "\tEpoch 30/100 - Train loss: 0.3452 - Val accuracy: 0.2222 - Val loss: 1.1415 - Val F1: 0.0808 - LR: 7.00e-05\n",
      "\tEpoch 40/100 - Train loss: 0.2827 - Val accuracy: 0.8889 - Val loss: 0.7976 - Val F1: 0.8815 - LR: 6.00e-05\n",
      "\tEpoch 50/100 - Train loss: 0.2113 - Val accuracy: 0.8889 - Val loss: 0.4166 - Val F1: 0.8815 - LR: 5.00e-05\n",
      "\tEpoch 60/100 - Train loss: 0.1754 - Val accuracy: 0.8889 - Val loss: 0.3011 - Val F1: 0.8815 - LR: 4.00e-05\n",
      "\tEpoch 70/100 - Train loss: 0.1374 - Val accuracy: 0.8889 - Val loss: 0.2642 - Val F1: 0.8815 - LR: 3.00e-05\n",
      "\tEpoch 80/100 - Train loss: 0.1187 - Val accuracy: 0.8889 - Val loss: 0.2460 - Val F1: 0.8815 - LR: 2.00e-05\n",
      "\tEpoch 90/100 - Train loss: 0.1271 - Val accuracy: 0.8889 - Val loss: 0.2361 - Val F1: 0.8815 - LR: 1.00e-05\n",
      "\tEpoch 100/100 - Train loss: 0.1047 - Val accuracy: 0.8889 - Val loss: 0.2325 - Val F1: 0.8815 - LR: 0.00e+00\n",
      "\tBest epoch: 100 - Best val accuracy: 0.8889 - Best val loss: 0.2325 - Best val F1: 0.8815\n",
      "\n",
      "\tEpoch 10/100 - Train loss: 0.6462 - Val accuracy: 0.2222 - Val loss: 1.1297 - Val F1: 0.0889 - LR: 9.00e-05\n",
      "\tEpoch 20/100 - Train loss: 0.4428 - Val accuracy: 0.2222 - Val loss: 1.1698 - Val F1: 0.0808 - LR: 8.00e-05\n",
      "\tEpoch 30/100 - Train loss: 0.3796 - Val accuracy: 0.2222 - Val loss: 1.1941 - Val F1: 0.0808 - LR: 7.00e-05\n",
      "\tEpoch 40/100 - Train loss: 0.3238 - Val accuracy: 0.6667 - Val loss: 0.9431 - Val F1: 0.6918 - LR: 6.00e-05\n",
      "\tEpoch 50/100 - Train loss: 0.2911 - Val accuracy: 1.0000 - Val loss: 0.5278 - Val F1: 1.0000 - LR: 5.00e-05\n",
      "\tEpoch 60/100 - Train loss: 0.2683 - Val accuracy: 1.0000 - Val loss: 0.3569 - Val F1: 1.0000 - LR: 4.00e-05\n",
      "\tEpoch 70/100 - Train loss: 0.2339 - Val accuracy: 1.0000 - Val loss: 0.3056 - Val F1: 1.0000 - LR: 3.00e-05\n",
      "\tEpoch 80/100 - Train loss: 0.2052 - Val accuracy: 1.0000 - Val loss: 0.2838 - Val F1: 1.0000 - LR: 2.00e-05\n",
      "\tEpoch 90/100 - Train loss: 0.2145 - Val accuracy: 1.0000 - Val loss: 0.2716 - Val F1: 1.0000 - LR: 1.00e-05\n",
      "\tEpoch 100/100 - Train loss: 0.2034 - Val accuracy: 1.0000 - Val loss: 0.2666 - Val F1: 1.0000 - LR: 0.00e+00\n",
      "\tBest epoch: 100 - Best val accuracy: 1.0000 - Best val loss: 0.2666 - Best val F1: 1.0000\n",
      "\n",
      "Source class: WAL | Domain: 24 | Accuracy: 0.9218 | Loss: 0.2815 | F1: 0.9215\n",
      "\n",
      "Domain: 25\n",
      "x_dp_dom.shape: (54, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Training and evaluating on Dp data via cross-validation...\n",
      "\tEpoch 10/100 - Train loss: 0.6332 - Val accuracy: 0.2222 - Val loss: 1.1206 - Val F1: 0.0808 - LR: 9.00e-05\n",
      "\tEpoch 20/100 - Train loss: 0.4129 - Val accuracy: 0.2222 - Val loss: 1.2497 - Val F1: 0.0808 - LR: 8.00e-05\n",
      "\tEpoch 30/100 - Train loss: 0.3229 - Val accuracy: 0.2222 - Val loss: 1.4208 - Val F1: 0.0988 - LR: 7.00e-05\n",
      "\tEpoch 40/100 - Train loss: 0.2489 - Val accuracy: 0.2222 - Val loss: 1.2277 - Val F1: 0.1270 - LR: 6.00e-05\n",
      "\tEpoch 50/100 - Train loss: 0.2094 - Val accuracy: 0.7778 - Val loss: 0.5830 - Val F1: 0.7037 - LR: 5.00e-05\n",
      "\tEpoch 60/100 - Train loss: 0.1708 - Val accuracy: 1.0000 - Val loss: 0.3144 - Val F1: 1.0000 - LR: 4.00e-05\n",
      "\tEpoch 70/100 - Train loss: 0.1284 - Val accuracy: 1.0000 - Val loss: 0.2319 - Val F1: 1.0000 - LR: 3.00e-05\n",
      "\tEpoch 80/100 - Train loss: 0.1203 - Val accuracy: 1.0000 - Val loss: 0.1985 - Val F1: 1.0000 - LR: 2.00e-05\n",
      "\tEpoch 90/100 - Train loss: 0.1117 - Val accuracy: 1.0000 - Val loss: 0.1837 - Val F1: 1.0000 - LR: 1.00e-05\n",
      "\tEpoch 100/100 - Train loss: 0.0992 - Val accuracy: 1.0000 - Val loss: 0.1785 - Val F1: 1.0000 - LR: 0.00e+00\n",
      "\tBest epoch: 100 - Best val accuracy: 1.0000 - Best val loss: 0.1785 - Best val F1: 1.0000\n",
      "\n",
      "\tEpoch 10/100 - Train loss: 0.6357 - Val accuracy: 0.5556 - Val loss: 1.0935 - Val F1: 0.3968 - LR: 9.00e-05\n",
      "\tEpoch 20/100 - Train loss: 0.4514 - Val accuracy: 0.2222 - Val loss: 1.1700 - Val F1: 0.0808 - LR: 8.00e-05\n",
      "\tEpoch 30/100 - Train loss: 0.3543 - Val accuracy: 0.3333 - Val loss: 1.3036 - Val F1: 0.2099 - LR: 7.00e-05\n",
      "\tEpoch 40/100 - Train loss: 0.3031 - Val accuracy: 0.3333 - Val loss: 1.1484 - Val F1: 0.2099 - LR: 6.00e-05\n",
      "\tEpoch 50/100 - Train loss: 0.2560 - Val accuracy: 0.8889 - Val loss: 0.5626 - Val F1: 0.8815 - LR: 5.00e-05\n",
      "\tEpoch 60/100 - Train loss: 0.2239 - Val accuracy: 1.0000 - Val loss: 0.3042 - Val F1: 1.0000 - LR: 4.00e-05\n",
      "\tEpoch 70/100 - Train loss: 0.2093 - Val accuracy: 1.0000 - Val loss: 0.2380 - Val F1: 1.0000 - LR: 3.00e-05\n",
      "\tEpoch 80/100 - Train loss: 0.1756 - Val accuracy: 1.0000 - Val loss: 0.2135 - Val F1: 1.0000 - LR: 2.00e-05\n",
      "\tEpoch 90/100 - Train loss: 0.1669 - Val accuracy: 1.0000 - Val loss: 0.2024 - Val F1: 1.0000 - LR: 1.00e-05\n",
      "\tEpoch 100/100 - Train loss: 0.1821 - Val accuracy: 1.0000 - Val loss: 0.1984 - Val F1: 1.0000 - LR: 0.00e+00\n",
      "\tBest epoch: 100 - Best val accuracy: 1.0000 - Best val loss: 0.1984 - Best val F1: 1.0000\n",
      "\n",
      "\tEpoch 10/100 - Train loss: 0.6384 - Val accuracy: 0.2222 - Val loss: 1.1021 - Val F1: 0.0808 - LR: 9.00e-05\n",
      "\tEpoch 20/100 - Train loss: 0.4513 - Val accuracy: 0.2222 - Val loss: 1.1679 - Val F1: 0.0808 - LR: 8.00e-05\n",
      "\tEpoch 30/100 - Train loss: 0.3689 - Val accuracy: 0.2222 - Val loss: 1.2154 - Val F1: 0.0808 - LR: 7.00e-05\n",
      "\tEpoch 40/100 - Train loss: 0.2875 - Val accuracy: 0.6667 - Val loss: 0.9247 - Val F1: 0.6208 - LR: 6.00e-05\n",
      "\tEpoch 50/100 - Train loss: 0.2320 - Val accuracy: 0.7778 - Val loss: 0.4556 - Val F1: 0.7037 - LR: 5.00e-05\n",
      "\tEpoch 60/100 - Train loss: 0.1994 - Val accuracy: 0.8889 - Val loss: 0.2977 - Val F1: 0.8815 - LR: 4.00e-05\n",
      "\tEpoch 70/100 - Train loss: 0.1678 - Val accuracy: 1.0000 - Val loss: 0.2317 - Val F1: 1.0000 - LR: 3.00e-05\n",
      "\tEpoch 80/100 - Train loss: 0.1482 - Val accuracy: 1.0000 - Val loss: 0.1959 - Val F1: 1.0000 - LR: 2.00e-05\n",
      "\tEpoch 90/100 - Train loss: 0.1421 - Val accuracy: 1.0000 - Val loss: 0.1780 - Val F1: 1.0000 - LR: 1.00e-05\n",
      "\tEpoch 100/100 - Train loss: 0.1345 - Val accuracy: 1.0000 - Val loss: 0.1715 - Val F1: 1.0000 - LR: 0.00e+00\n",
      "\tBest epoch: 100 - Best val accuracy: 1.0000 - Best val loss: 0.1715 - Best val F1: 1.0000\n",
      "\n",
      "\tEpoch 10/100 - Train loss: 0.5727 - Val accuracy: 0.2222 - Val loss: 1.1083 - Val F1: 0.0808 - LR: 9.00e-05\n",
      "\tEpoch 20/100 - Train loss: 0.4165 - Val accuracy: 0.2222 - Val loss: 1.2131 - Val F1: 0.0808 - LR: 8.00e-05\n",
      "\tEpoch 30/100 - Train loss: 0.3599 - Val accuracy: 0.2222 - Val loss: 1.3505 - Val F1: 0.0808 - LR: 7.00e-05\n",
      "\tEpoch 40/100 - Train loss: 0.3059 - Val accuracy: 0.2222 - Val loss: 1.1262 - Val F1: 0.1111 - LR: 6.00e-05\n",
      "\tEpoch 50/100 - Train loss: 0.2736 - Val accuracy: 0.7778 - Val loss: 0.4783 - Val F1: 0.7037 - LR: 5.00e-05\n",
      "\tEpoch 60/100 - Train loss: 0.2375 - Val accuracy: 1.0000 - Val loss: 0.3055 - Val F1: 1.0000 - LR: 4.00e-05\n",
      "\tEpoch 70/100 - Train loss: 0.2194 - Val accuracy: 1.0000 - Val loss: 0.2633 - Val F1: 1.0000 - LR: 3.00e-05\n",
      "\tEpoch 80/100 - Train loss: 0.2019 - Val accuracy: 1.0000 - Val loss: 0.2424 - Val F1: 1.0000 - LR: 2.00e-05\n",
      "\tEpoch 90/100 - Train loss: 0.1826 - Val accuracy: 1.0000 - Val loss: 0.2311 - Val F1: 1.0000 - LR: 1.00e-05\n",
      "\tEpoch 100/100 - Train loss: 0.1882 - Val accuracy: 1.0000 - Val loss: 0.2264 - Val F1: 1.0000 - LR: 0.00e+00\n",
      "\tBest epoch: 100 - Best val accuracy: 1.0000 - Best val loss: 0.2264 - Best val F1: 1.0000\n",
      "\n",
      "\tEpoch 10/100 - Train loss: 0.5296 - Val accuracy: 0.3333 - Val loss: 1.0917 - Val F1: 0.2741 - LR: 9.00e-05\n",
      "\tEpoch 20/100 - Train loss: 0.3928 - Val accuracy: 0.2222 - Val loss: 1.2299 - Val F1: 0.0808 - LR: 8.00e-05\n",
      "\tEpoch 30/100 - Train loss: 0.3167 - Val accuracy: 0.2222 - Val loss: 1.3832 - Val F1: 0.0808 - LR: 7.00e-05\n",
      "\tEpoch 40/100 - Train loss: 0.2621 - Val accuracy: 0.2222 - Val loss: 1.2075 - Val F1: 0.1270 - LR: 6.00e-05\n",
      "\tEpoch 50/100 - Train loss: 0.2323 - Val accuracy: 0.7778 - Val loss: 0.6423 - Val F1: 0.7037 - LR: 5.00e-05\n",
      "\tEpoch 60/100 - Train loss: 0.1764 - Val accuracy: 0.6667 - Val loss: 0.4109 - Val F1: 0.6444 - LR: 4.00e-05\n",
      "\tEpoch 70/100 - Train loss: 0.1647 - Val accuracy: 0.7778 - Val loss: 0.3602 - Val F1: 0.7778 - LR: 3.00e-05\n",
      "\tEpoch 80/100 - Train loss: 0.1370 - Val accuracy: 0.7778 - Val loss: 0.3435 - Val F1: 0.7778 - LR: 2.00e-05\n",
      "\tEpoch 90/100 - Train loss: 0.1232 - Val accuracy: 0.7778 - Val loss: 0.3347 - Val F1: 0.7778 - LR: 1.00e-05\n",
      "\tEpoch 100/100 - Train loss: 0.1285 - Val accuracy: 0.7778 - Val loss: 0.3311 - Val F1: 0.7778 - LR: 0.00e+00\n",
      "\tBest epoch: 100 - Best val accuracy: 0.7778 - Best val loss: 0.3311 - Best val F1: 0.7778\n",
      "\n",
      "Source class: WAL | Domain: 25 | Accuracy: 0.8527 | Loss: 0.3350 | F1: 0.8482\n",
      "\n",
      "Domain: 26\n",
      "x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Training and evaluating on Dp data via cross-validation...\n",
      "\tEpoch 10/100 - Train loss: 0.5683 - Val accuracy: 0.7143 - Val loss: 1.0608 - Val F1: 0.5952 - LR: 9.00e-05\n",
      "\tEpoch 20/100 - Train loss: 0.3257 - Val accuracy: 0.1429 - Val loss: 1.2034 - Val F1: 0.0714 - LR: 8.00e-05\n",
      "\tEpoch 30/100 - Train loss: 0.1955 - Val accuracy: 0.1429 - Val loss: 1.4019 - Val F1: 0.0571 - LR: 7.00e-05\n",
      "\tEpoch 40/100 - Train loss: 0.1409 - Val accuracy: 0.2857 - Val loss: 1.2164 - Val F1: 0.3095 - LR: 6.00e-05\n",
      "\tEpoch 50/100 - Train loss: 0.1063 - Val accuracy: 0.7143 - Val loss: 0.5611 - Val F1: 0.7063 - LR: 5.00e-05\n",
      "\tEpoch 60/100 - Train loss: 0.0706 - Val accuracy: 0.8571 - Val loss: 0.2948 - Val F1: 0.8095 - LR: 4.00e-05\n",
      "\tEpoch 70/100 - Train loss: 0.0630 - Val accuracy: 1.0000 - Val loss: 0.2316 - Val F1: 1.0000 - LR: 3.00e-05\n",
      "\tEpoch 80/100 - Train loss: 0.0611 - Val accuracy: 1.0000 - Val loss: 0.2137 - Val F1: 1.0000 - LR: 2.00e-05\n",
      "\tEpoch 90/100 - Train loss: 0.0460 - Val accuracy: 1.0000 - Val loss: 0.2082 - Val F1: 1.0000 - LR: 1.00e-05\n",
      "\tEpoch 100/100 - Train loss: 0.0497 - Val accuracy: 1.0000 - Val loss: 0.2066 - Val F1: 1.0000 - LR: 0.00e+00\n",
      "\tBest epoch: 100 - Best val accuracy: 1.0000 - Best val loss: 0.2066 - Best val F1: 1.0000\n",
      "\n",
      "\tEpoch 10/100 - Train loss: 0.6915 - Val accuracy: 0.7143 - Val loss: 1.0521 - Val F1: 0.5952 - LR: 9.00e-05\n",
      "\tEpoch 20/100 - Train loss: 0.4313 - Val accuracy: 0.7143 - Val loss: 1.0286 - Val F1: 0.5952 - LR: 8.00e-05\n",
      "\tEpoch 30/100 - Train loss: 0.2987 - Val accuracy: 0.4286 - Val loss: 1.0886 - Val F1: 0.4558 - LR: 7.00e-05\n",
      "\tEpoch 40/100 - Train loss: 0.1931 - Val accuracy: 0.5714 - Val loss: 0.9773 - Val F1: 0.5929 - LR: 6.00e-05\n",
      "\tEpoch 50/100 - Train loss: 0.1616 - Val accuracy: 0.8571 - Val loss: 0.6321 - Val F1: 0.8095 - LR: 5.00e-05\n",
      "\tEpoch 60/100 - Train loss: 0.1155 - Val accuracy: 0.8571 - Val loss: 0.3976 - Val F1: 0.8095 - LR: 4.00e-05\n",
      "\tEpoch 70/100 - Train loss: 0.0836 - Val accuracy: 0.8571 - Val loss: 0.3193 - Val F1: 0.8095 - LR: 3.00e-05\n",
      "\tEpoch 80/100 - Train loss: 0.0753 - Val accuracy: 0.8571 - Val loss: 0.2924 - Val F1: 0.7922 - LR: 2.00e-05\n",
      "\tEpoch 90/100 - Train loss: 0.0789 - Val accuracy: 0.8571 - Val loss: 0.2823 - Val F1: 0.7922 - LR: 1.00e-05\n",
      "\tEpoch 100/100 - Train loss: 0.0632 - Val accuracy: 0.8571 - Val loss: 0.2790 - Val F1: 0.7922 - LR: 0.00e+00\n",
      "\tBest epoch: 100 - Best val accuracy: 0.8571 - Best val loss: 0.2790 - Best val F1: 0.7922\n",
      "\n",
      "\tEpoch 10/100 - Train loss: 0.6701 - Val accuracy: 0.1429 - Val loss: 1.0904 - Val F1: 0.0357 - LR: 9.00e-05\n",
      "\tEpoch 20/100 - Train loss: 0.4074 - Val accuracy: 0.1429 - Val loss: 1.1463 - Val F1: 0.0357 - LR: 8.00e-05\n",
      "\tEpoch 30/100 - Train loss: 0.2596 - Val accuracy: 0.1429 - Val loss: 1.3584 - Val F1: 0.0357 - LR: 7.00e-05\n",
      "\tEpoch 40/100 - Train loss: 0.1671 - Val accuracy: 0.1429 - Val loss: 1.3465 - Val F1: 0.0357 - LR: 6.00e-05\n",
      "\tEpoch 50/100 - Train loss: 0.1241 - Val accuracy: 0.7143 - Val loss: 0.8658 - Val F1: 0.7063 - LR: 5.00e-05\n",
      "\tEpoch 60/100 - Train loss: 0.0969 - Val accuracy: 0.8571 - Val loss: 0.4533 - Val F1: 0.8095 - LR: 4.00e-05\n",
      "\tEpoch 70/100 - Train loss: 0.0792 - Val accuracy: 0.8571 - Val loss: 0.3264 - Val F1: 0.8095 - LR: 3.00e-05\n",
      "\tEpoch 80/100 - Train loss: 0.0726 - Val accuracy: 0.8571 - Val loss: 0.2966 - Val F1: 0.8095 - LR: 2.00e-05\n",
      "\tEpoch 90/100 - Train loss: 0.0640 - Val accuracy: 0.8571 - Val loss: 0.2896 - Val F1: 0.8095 - LR: 1.00e-05\n",
      "\tEpoch 100/100 - Train loss: 0.0572 - Val accuracy: 0.8571 - Val loss: 0.2878 - Val F1: 0.8095 - LR: 0.00e+00\n",
      "\tBest epoch: 100 - Best val accuracy: 0.8571 - Best val loss: 0.2878 - Best val F1: 0.8095\n",
      "\n",
      "\tEpoch 10/100 - Train loss: 0.5938 - Val accuracy: 0.7143 - Val loss: 1.0223 - Val F1: 0.5952 - LR: 9.00e-05\n",
      "\tEpoch 20/100 - Train loss: 0.3899 - Val accuracy: 0.7143 - Val loss: 1.0467 - Val F1: 0.5952 - LR: 8.00e-05\n",
      "\tEpoch 30/100 - Train loss: 0.2757 - Val accuracy: 0.1429 - Val loss: 1.2156 - Val F1: 0.0357 - LR: 7.00e-05\n",
      "\tEpoch 40/100 - Train loss: 0.2062 - Val accuracy: 0.1429 - Val loss: 1.3188 - Val F1: 0.0357 - LR: 6.00e-05\n",
      "\tEpoch 50/100 - Train loss: 0.1687 - Val accuracy: 0.5714 - Val loss: 0.8975 - Val F1: 0.5929 - LR: 5.00e-05\n",
      "\tEpoch 60/100 - Train loss: 0.1352 - Val accuracy: 0.8571 - Val loss: 0.3755 - Val F1: 0.8095 - LR: 4.00e-05\n",
      "\tEpoch 70/100 - Train loss: 0.1148 - Val accuracy: 0.8571 - Val loss: 0.2504 - Val F1: 0.8095 - LR: 3.00e-05\n",
      "\tEpoch 80/100 - Train loss: 0.1028 - Val accuracy: 0.8571 - Val loss: 0.2232 - Val F1: 0.8095 - LR: 2.00e-05\n",
      "\tEpoch 90/100 - Train loss: 0.0988 - Val accuracy: 0.8571 - Val loss: 0.2144 - Val F1: 0.8095 - LR: 1.00e-05\n",
      "\tEpoch 100/100 - Train loss: 0.0958 - Val accuracy: 0.8571 - Val loss: 0.2118 - Val F1: 0.8095 - LR: 0.00e+00\n",
      "\tBest epoch: 100 - Best val accuracy: 0.8571 - Best val loss: 0.2118 - Best val F1: 0.8095\n",
      "\n",
      "\tEpoch 10/100 - Train loss: 0.5718 - Val accuracy: 0.1429 - Val loss: 1.0810 - Val F1: 0.0357 - LR: 9.00e-05\n",
      "\tEpoch 20/100 - Train loss: 0.3828 - Val accuracy: 0.1429 - Val loss: 1.1406 - Val F1: 0.0357 - LR: 8.00e-05\n",
      "\tEpoch 30/100 - Train loss: 0.2661 - Val accuracy: 0.1429 - Val loss: 1.2513 - Val F1: 0.0357 - LR: 7.00e-05\n",
      "\tEpoch 40/100 - Train loss: 0.1798 - Val accuracy: 0.1429 - Val loss: 1.1645 - Val F1: 0.0357 - LR: 6.00e-05\n",
      "\tEpoch 50/100 - Train loss: 0.1499 - Val accuracy: 1.0000 - Val loss: 0.5997 - Val F1: 1.0000 - LR: 5.00e-05\n",
      "\tEpoch 60/100 - Train loss: 0.1070 - Val accuracy: 1.0000 - Val loss: 0.2951 - Val F1: 1.0000 - LR: 4.00e-05\n",
      "\tEpoch 70/100 - Train loss: 0.0909 - Val accuracy: 1.0000 - Val loss: 0.2416 - Val F1: 1.0000 - LR: 3.00e-05\n",
      "\tEpoch 80/100 - Train loss: 0.0777 - Val accuracy: 0.8571 - Val loss: 0.2290 - Val F1: 0.7922 - LR: 2.00e-05\n",
      "\tEpoch 90/100 - Train loss: 0.0762 - Val accuracy: 0.8571 - Val loss: 0.2245 - Val F1: 0.7922 - LR: 1.00e-05\n",
      "\tEpoch 100/100 - Train loss: 0.0683 - Val accuracy: 0.8571 - Val loss: 0.2228 - Val F1: 0.7922 - LR: 0.00e+00\n",
      "\tBest epoch: 100 - Best val accuracy: 0.8571 - Best val loss: 0.2228 - Best val F1: 0.7922\n",
      "\n",
      "Source class: WAL | Domain: 26 | Accuracy: 0.9528 | Loss: 0.2436 | F1: 0.9409\n",
      "\n",
      "Domain: 27\n",
      "x_dp_dom.shape: (54, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Training and evaluating on Dp data via cross-validation...\n",
      "\tEpoch 10/100 - Train loss: 0.5992 - Val accuracy: 0.2222 - Val loss: 1.1157 - Val F1: 0.0808 - LR: 9.00e-05\n",
      "\tEpoch 20/100 - Train loss: 0.3875 - Val accuracy: 0.2222 - Val loss: 1.2066 - Val F1: 0.0808 - LR: 8.00e-05\n",
      "\tEpoch 30/100 - Train loss: 0.2871 - Val accuracy: 0.2222 - Val loss: 1.3666 - Val F1: 0.0808 - LR: 7.00e-05\n",
      "\tEpoch 40/100 - Train loss: 0.2296 - Val accuracy: 0.2222 - Val loss: 1.2567 - Val F1: 0.0808 - LR: 6.00e-05\n",
      "\tEpoch 50/100 - Train loss: 0.1735 - Val accuracy: 0.6667 - Val loss: 0.7048 - Val F1: 0.6208 - LR: 5.00e-05\n",
      "\tEpoch 60/100 - Train loss: 0.1597 - Val accuracy: 0.8889 - Val loss: 0.3631 - Val F1: 0.8815 - LR: 4.00e-05\n",
      "\tEpoch 70/100 - Train loss: 0.1341 - Val accuracy: 0.8889 - Val loss: 0.2606 - Val F1: 0.8815 - LR: 3.00e-05\n",
      "\tEpoch 80/100 - Train loss: 0.1160 - Val accuracy: 1.0000 - Val loss: 0.2225 - Val F1: 1.0000 - LR: 2.00e-05\n",
      "\tEpoch 90/100 - Train loss: 0.1078 - Val accuracy: 1.0000 - Val loss: 0.2078 - Val F1: 1.0000 - LR: 1.00e-05\n",
      "\tEpoch 100/100 - Train loss: 0.1014 - Val accuracy: 1.0000 - Val loss: 0.2025 - Val F1: 1.0000 - LR: 0.00e+00\n",
      "\tBest epoch: 100 - Best val accuracy: 1.0000 - Best val loss: 0.2025 - Best val F1: 1.0000\n",
      "\n",
      "\tEpoch 10/100 - Train loss: 0.6177 - Val accuracy: 0.5556 - Val loss: 1.0852 - Val F1: 0.3968 - LR: 9.00e-05\n",
      "\tEpoch 20/100 - Train loss: 0.4101 - Val accuracy: 0.2222 - Val loss: 1.1356 - Val F1: 0.0808 - LR: 8.00e-05\n",
      "\tEpoch 30/100 - Train loss: 0.3409 - Val accuracy: 0.2222 - Val loss: 1.2589 - Val F1: 0.0808 - LR: 7.00e-05\n",
      "\tEpoch 40/100 - Train loss: 0.2894 - Val accuracy: 0.4444 - Val loss: 1.1923 - Val F1: 0.3210 - LR: 6.00e-05\n",
      "\tEpoch 50/100 - Train loss: 0.2469 - Val accuracy: 0.7778 - Val loss: 0.7515 - Val F1: 0.7827 - LR: 5.00e-05\n",
      "\tEpoch 60/100 - Train loss: 0.2135 - Val accuracy: 0.8889 - Val loss: 0.4110 - Val F1: 0.8815 - LR: 4.00e-05\n",
      "\tEpoch 70/100 - Train loss: 0.1888 - Val accuracy: 0.8889 - Val loss: 0.2881 - Val F1: 0.8815 - LR: 3.00e-05\n",
      "\tEpoch 80/100 - Train loss: 0.1588 - Val accuracy: 1.0000 - Val loss: 0.2451 - Val F1: 1.0000 - LR: 2.00e-05\n",
      "\tEpoch 90/100 - Train loss: 0.1465 - Val accuracy: 1.0000 - Val loss: 0.2279 - Val F1: 1.0000 - LR: 1.00e-05\n",
      "\tEpoch 100/100 - Train loss: 0.1581 - Val accuracy: 1.0000 - Val loss: 0.2207 - Val F1: 1.0000 - LR: 0.00e+00\n",
      "\tBest epoch: 100 - Best val accuracy: 1.0000 - Best val loss: 0.2207 - Best val F1: 1.0000\n",
      "\n",
      "\tEpoch 10/100 - Train loss: 0.6222 - Val accuracy: 0.2222 - Val loss: 1.0982 - Val F1: 0.0808 - LR: 9.00e-05\n",
      "\tEpoch 20/100 - Train loss: 0.4160 - Val accuracy: 0.2222 - Val loss: 1.2278 - Val F1: 0.0808 - LR: 8.00e-05\n",
      "\tEpoch 30/100 - Train loss: 0.2927 - Val accuracy: 0.2222 - Val loss: 1.4073 - Val F1: 0.0889 - LR: 7.00e-05\n",
      "\tEpoch 40/100 - Train loss: 0.2268 - Val accuracy: 0.4444 - Val loss: 1.2770 - Val F1: 0.2751 - LR: 6.00e-05\n",
      "\tEpoch 50/100 - Train loss: 0.1662 - Val accuracy: 0.8889 - Val loss: 0.7286 - Val F1: 0.8938 - LR: 5.00e-05\n",
      "\tEpoch 60/100 - Train loss: 0.1514 - Val accuracy: 1.0000 - Val loss: 0.3657 - Val F1: 1.0000 - LR: 4.00e-05\n",
      "\tEpoch 70/100 - Train loss: 0.1165 - Val accuracy: 1.0000 - Val loss: 0.2441 - Val F1: 1.0000 - LR: 3.00e-05\n",
      "\tEpoch 80/100 - Train loss: 0.0995 - Val accuracy: 1.0000 - Val loss: 0.2019 - Val F1: 1.0000 - LR: 2.00e-05\n",
      "\tEpoch 90/100 - Train loss: 0.0991 - Val accuracy: 1.0000 - Val loss: 0.1832 - Val F1: 1.0000 - LR: 1.00e-05\n",
      "\tEpoch 100/100 - Train loss: 0.1064 - Val accuracy: 1.0000 - Val loss: 0.1758 - Val F1: 1.0000 - LR: 0.00e+00\n",
      "\tBest epoch: 100 - Best val accuracy: 1.0000 - Best val loss: 0.1758 - Best val F1: 1.0000\n",
      "\n",
      "\tEpoch 10/100 - Train loss: 0.5850 - Val accuracy: 0.2222 - Val loss: 1.0960 - Val F1: 0.0808 - LR: 9.00e-05\n",
      "\tEpoch 20/100 - Train loss: 0.4139 - Val accuracy: 0.2222 - Val loss: 1.1962 - Val F1: 0.0808 - LR: 8.00e-05\n",
      "\tEpoch 30/100 - Train loss: 0.3338 - Val accuracy: 0.2222 - Val loss: 1.3167 - Val F1: 0.0808 - LR: 7.00e-05\n",
      "\tEpoch 40/100 - Train loss: 0.2715 - Val accuracy: 0.3333 - Val loss: 1.0837 - Val F1: 0.3333 - LR: 6.00e-05\n",
      "\tEpoch 50/100 - Train loss: 0.2472 - Val accuracy: 0.7778 - Val loss: 0.5487 - Val F1: 0.7037 - LR: 5.00e-05\n",
      "\tEpoch 60/100 - Train loss: 0.2001 - Val accuracy: 0.8889 - Val loss: 0.3375 - Val F1: 0.8815 - LR: 4.00e-05\n",
      "\tEpoch 70/100 - Train loss: 0.1728 - Val accuracy: 0.8889 - Val loss: 0.2849 - Val F1: 0.8815 - LR: 3.00e-05\n",
      "\tEpoch 80/100 - Train loss: 0.1493 - Val accuracy: 0.8889 - Val loss: 0.2626 - Val F1: 0.8815 - LR: 2.00e-05\n",
      "\tEpoch 90/100 - Train loss: 0.1503 - Val accuracy: 1.0000 - Val loss: 0.2510 - Val F1: 1.0000 - LR: 1.00e-05\n",
      "\tEpoch 100/100 - Train loss: 0.1455 - Val accuracy: 1.0000 - Val loss: 0.2464 - Val F1: 1.0000 - LR: 0.00e+00\n",
      "\tBest epoch: 100 - Best val accuracy: 1.0000 - Best val loss: 0.2464 - Best val F1: 1.0000\n",
      "\n",
      "\tEpoch 10/100 - Train loss: 0.6585 - Val accuracy: 0.7778 - Val loss: 1.0894 - Val F1: 0.6828 - LR: 9.00e-05\n",
      "\tEpoch 20/100 - Train loss: 0.4162 - Val accuracy: 0.2222 - Val loss: 1.1619 - Val F1: 0.0808 - LR: 8.00e-05\n",
      "\tEpoch 30/100 - Train loss: 0.3245 - Val accuracy: 0.3333 - Val loss: 1.2451 - Val F1: 0.2370 - LR: 7.00e-05\n",
      "\tEpoch 40/100 - Train loss: 0.2398 - Val accuracy: 0.3333 - Val loss: 1.0800 - Val F1: 0.2099 - LR: 6.00e-05\n",
      "\tEpoch 50/100 - Train loss: 0.1876 - Val accuracy: 0.8889 - Val loss: 0.5508 - Val F1: 0.8815 - LR: 5.00e-05\n",
      "\tEpoch 60/100 - Train loss: 0.1631 - Val accuracy: 0.8889 - Val loss: 0.3079 - Val F1: 0.8815 - LR: 4.00e-05\n",
      "\tEpoch 70/100 - Train loss: 0.1397 - Val accuracy: 0.8889 - Val loss: 0.2492 - Val F1: 0.8815 - LR: 3.00e-05\n",
      "\tEpoch 80/100 - Train loss: 0.1162 - Val accuracy: 0.8889 - Val loss: 0.2300 - Val F1: 0.8815 - LR: 2.00e-05\n",
      "\tEpoch 90/100 - Train loss: 0.1148 - Val accuracy: 0.8889 - Val loss: 0.2209 - Val F1: 0.8815 - LR: 1.00e-05\n",
      "\tEpoch 100/100 - Train loss: 0.1080 - Val accuracy: 0.8889 - Val loss: 0.2170 - Val F1: 0.8815 - LR: 0.00e+00\n",
      "\tBest epoch: 100 - Best val accuracy: 0.8889 - Best val loss: 0.2170 - Best val F1: 0.8815\n",
      "\n",
      "Source class: WAL | Domain: 27 | Accuracy: 0.8873 | Loss: 0.2820 | F1: 0.8834\n",
      "\n",
      "Domain: 28\n",
      "x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Training and evaluating on Dp data via cross-validation...\n",
      "\tEpoch 10/100 - Train loss: 0.5337 - Val accuracy: 0.7143 - Val loss: 1.0544 - Val F1: 0.5952 - LR: 9.00e-05\n",
      "\tEpoch 20/100 - Train loss: 0.3388 - Val accuracy: 0.1429 - Val loss: 1.1638 - Val F1: 0.0357 - LR: 8.00e-05\n",
      "\tEpoch 30/100 - Train loss: 0.2655 - Val accuracy: 0.1429 - Val loss: 1.3634 - Val F1: 0.0357 - LR: 7.00e-05\n",
      "\tEpoch 40/100 - Train loss: 0.1951 - Val accuracy: 0.2857 - Val loss: 1.0816 - Val F1: 0.2952 - LR: 6.00e-05\n",
      "\tEpoch 50/100 - Train loss: 0.1579 - Val accuracy: 0.8571 - Val loss: 0.4567 - Val F1: 0.8095 - LR: 5.00e-05\n",
      "\tEpoch 60/100 - Train loss: 0.1424 - Val accuracy: 1.0000 - Val loss: 0.2580 - Val F1: 1.0000 - LR: 4.00e-05\n",
      "\tEpoch 70/100 - Train loss: 0.1275 - Val accuracy: 1.0000 - Val loss: 0.2231 - Val F1: 1.0000 - LR: 3.00e-05\n",
      "\tEpoch 80/100 - Train loss: 0.1153 - Val accuracy: 1.0000 - Val loss: 0.2127 - Val F1: 1.0000 - LR: 2.00e-05\n",
      "\tEpoch 90/100 - Train loss: 0.0991 - Val accuracy: 1.0000 - Val loss: 0.2085 - Val F1: 1.0000 - LR: 1.00e-05\n",
      "\tEpoch 100/100 - Train loss: 0.0938 - Val accuracy: 1.0000 - Val loss: 0.2070 - Val F1: 1.0000 - LR: 0.00e+00\n",
      "\tBest epoch: 100 - Best val accuracy: 1.0000 - Best val loss: 0.2070 - Best val F1: 1.0000\n",
      "\n",
      "\tEpoch 10/100 - Train loss: 0.4762 - Val accuracy: 0.7143 - Val loss: 1.0708 - Val F1: 0.5952 - LR: 9.00e-05\n",
      "\tEpoch 20/100 - Train loss: 0.3016 - Val accuracy: 0.1429 - Val loss: 1.1627 - Val F1: 0.0357 - LR: 8.00e-05\n",
      "\tEpoch 30/100 - Train loss: 0.2366 - Val accuracy: 0.1429 - Val loss: 1.3203 - Val F1: 0.0357 - LR: 7.00e-05\n",
      "\tEpoch 40/100 - Train loss: 0.1901 - Val accuracy: 0.1429 - Val loss: 1.1282 - Val F1: 0.0476 - LR: 6.00e-05\n",
      "\tEpoch 50/100 - Train loss: 0.1506 - Val accuracy: 1.0000 - Val loss: 0.4535 - Val F1: 1.0000 - LR: 5.00e-05\n",
      "\tEpoch 60/100 - Train loss: 0.1398 - Val accuracy: 0.8571 - Val loss: 0.2497 - Val F1: 0.8095 - LR: 4.00e-05\n",
      "\tEpoch 70/100 - Train loss: 0.1193 - Val accuracy: 0.8571 - Val loss: 0.2172 - Val F1: 0.8095 - LR: 3.00e-05\n",
      "\tEpoch 80/100 - Train loss: 0.1155 - Val accuracy: 0.8571 - Val loss: 0.2091 - Val F1: 0.8095 - LR: 2.00e-05\n",
      "\tEpoch 90/100 - Train loss: 0.1008 - Val accuracy: 0.8571 - Val loss: 0.2047 - Val F1: 0.8095 - LR: 1.00e-05\n",
      "\tEpoch 100/100 - Train loss: 0.0967 - Val accuracy: 0.8571 - Val loss: 0.2028 - Val F1: 0.8095 - LR: 0.00e+00\n",
      "\tBest epoch: 100 - Best val accuracy: 0.8571 - Best val loss: 0.2028 - Best val F1: 0.8095\n",
      "\n",
      "\tEpoch 10/100 - Train loss: 0.6014 - Val accuracy: 0.7143 - Val loss: 1.0825 - Val F1: 0.5952 - LR: 9.00e-05\n",
      "\tEpoch 20/100 - Train loss: 0.3734 - Val accuracy: 0.1429 - Val loss: 1.1203 - Val F1: 0.0357 - LR: 8.00e-05\n",
      "\tEpoch 30/100 - Train loss: 0.2419 - Val accuracy: 0.1429 - Val loss: 1.2995 - Val F1: 0.0408 - LR: 7.00e-05\n",
      "\tEpoch 40/100 - Train loss: 0.1832 - Val accuracy: 0.1429 - Val loss: 1.2940 - Val F1: 0.0714 - LR: 6.00e-05\n",
      "\tEpoch 50/100 - Train loss: 0.1560 - Val accuracy: 0.8571 - Val loss: 0.7832 - Val F1: 0.8095 - LR: 5.00e-05\n",
      "\tEpoch 60/100 - Train loss: 0.1199 - Val accuracy: 0.7143 - Val loss: 0.3755 - Val F1: 0.7143 - LR: 4.00e-05\n",
      "\tEpoch 70/100 - Train loss: 0.1055 - Val accuracy: 0.7143 - Val loss: 0.2927 - Val F1: 0.7143 - LR: 3.00e-05\n",
      "\tEpoch 80/100 - Train loss: 0.0884 - Val accuracy: 0.7143 - Val loss: 0.2798 - Val F1: 0.7143 - LR: 2.00e-05\n",
      "\tEpoch 90/100 - Train loss: 0.0749 - Val accuracy: 0.7143 - Val loss: 0.2779 - Val F1: 0.7143 - LR: 1.00e-05\n",
      "\tEpoch 100/100 - Train loss: 0.0811 - Val accuracy: 0.7143 - Val loss: 0.2772 - Val F1: 0.7143 - LR: 0.00e+00\n",
      "\tBest epoch: 100 - Best val accuracy: 0.7143 - Best val loss: 0.2772 - Best val F1: 0.7143\n",
      "\n",
      "\tEpoch 10/100 - Train loss: 0.5245 - Val accuracy: 0.7143 - Val loss: 1.0563 - Val F1: 0.5952 - LR: 9.00e-05\n",
      "\tEpoch 20/100 - Train loss: 0.3265 - Val accuracy: 0.1429 - Val loss: 1.1228 - Val F1: 0.0357 - LR: 8.00e-05\n",
      "\tEpoch 30/100 - Train loss: 0.2383 - Val accuracy: 0.1429 - Val loss: 1.2714 - Val F1: 0.0476 - LR: 7.00e-05\n",
      "\tEpoch 40/100 - Train loss: 0.1894 - Val accuracy: 0.1429 - Val loss: 1.1684 - Val F1: 0.0476 - LR: 6.00e-05\n",
      "\tEpoch 50/100 - Train loss: 0.1374 - Val accuracy: 0.8571 - Val loss: 0.6271 - Val F1: 0.8095 - LR: 5.00e-05\n",
      "\tEpoch 60/100 - Train loss: 0.1117 - Val accuracy: 0.8571 - Val loss: 0.3616 - Val F1: 0.8095 - LR: 4.00e-05\n",
      "\tEpoch 70/100 - Train loss: 0.0995 - Val accuracy: 0.8571 - Val loss: 0.3124 - Val F1: 0.8095 - LR: 3.00e-05\n",
      "\tEpoch 80/100 - Train loss: 0.0792 - Val accuracy: 0.8571 - Val loss: 0.3029 - Val F1: 0.8095 - LR: 2.00e-05\n",
      "\tEpoch 90/100 - Train loss: 0.0776 - Val accuracy: 0.8571 - Val loss: 0.3011 - Val F1: 0.8095 - LR: 1.00e-05\n",
      "\tEpoch 100/100 - Train loss: 0.0707 - Val accuracy: 0.8571 - Val loss: 0.3008 - Val F1: 0.8095 - LR: 0.00e+00\n",
      "\tBest epoch: 100 - Best val accuracy: 0.8571 - Best val loss: 0.3008 - Best val F1: 0.8095\n",
      "\n",
      "\tEpoch 10/100 - Train loss: 0.5262 - Val accuracy: 0.7143 - Val loss: 1.0817 - Val F1: 0.5952 - LR: 9.00e-05\n",
      "\tEpoch 20/100 - Train loss: 0.3268 - Val accuracy: 0.1429 - Val loss: 1.2410 - Val F1: 0.0357 - LR: 8.00e-05\n",
      "\tEpoch 30/100 - Train loss: 0.2356 - Val accuracy: 0.1429 - Val loss: 1.5017 - Val F1: 0.0357 - LR: 7.00e-05\n",
      "\tEpoch 40/100 - Train loss: 0.1946 - Val accuracy: 0.1429 - Val loss: 1.5322 - Val F1: 0.0357 - LR: 6.00e-05\n",
      "\tEpoch 50/100 - Train loss: 0.1633 - Val accuracy: 0.7143 - Val loss: 0.7817 - Val F1: 0.7063 - LR: 5.00e-05\n",
      "\tEpoch 60/100 - Train loss: 0.1320 - Val accuracy: 0.8571 - Val loss: 0.3325 - Val F1: 0.8095 - LR: 4.00e-05\n",
      "\tEpoch 70/100 - Train loss: 0.1074 - Val accuracy: 0.8571 - Val loss: 0.2520 - Val F1: 0.8095 - LR: 3.00e-05\n",
      "\tEpoch 80/100 - Train loss: 0.1142 - Val accuracy: 0.8571 - Val loss: 0.2340 - Val F1: 0.8095 - LR: 2.00e-05\n",
      "\tEpoch 90/100 - Train loss: 0.0959 - Val accuracy: 0.8571 - Val loss: 0.2276 - Val F1: 0.8095 - LR: 1.00e-05\n",
      "\tEpoch 100/100 - Train loss: 0.1003 - Val accuracy: 0.8571 - Val loss: 0.2250 - Val F1: 0.8095 - LR: 0.00e+00\n",
      "\tBest epoch: 100 - Best val accuracy: 0.8571 - Best val loss: 0.2250 - Best val F1: 0.8095\n",
      "\n",
      "Source class: WAL | Domain: 28 | Accuracy: 0.8333 | Loss: 0.2612 | F1: 0.8250\n",
      "\n",
      "Domain: 29\n",
      "x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Training and evaluating on Dp data via cross-validation...\n",
      "\tEpoch 10/100 - Train loss: 0.4880 - Val accuracy: 0.1429 - Val loss: 1.0946 - Val F1: 0.0357 - LR: 9.00e-05\n",
      "\tEpoch 20/100 - Train loss: 0.2544 - Val accuracy: 0.1429 - Val loss: 1.2995 - Val F1: 0.0357 - LR: 8.00e-05\n",
      "\tEpoch 30/100 - Train loss: 0.1498 - Val accuracy: 0.2857 - Val loss: 1.6205 - Val F1: 0.1286 - LR: 7.00e-05\n",
      "\tEpoch 40/100 - Train loss: 0.0913 - Val accuracy: 0.1429 - Val loss: 1.8269 - Val F1: 0.0408 - LR: 6.00e-05\n",
      "\tEpoch 50/100 - Train loss: 0.0586 - Val accuracy: 0.2857 - Val loss: 1.5203 - Val F1: 0.1286 - LR: 5.00e-05\n",
      "\tEpoch 60/100 - Train loss: 0.0456 - Val accuracy: 0.8571 - Val loss: 0.6064 - Val F1: 0.8730 - LR: 4.00e-05\n",
      "\tEpoch 70/100 - Train loss: 0.0395 - Val accuracy: 0.8571 - Val loss: 0.2731 - Val F1: 0.8095 - LR: 3.00e-05\n",
      "\tEpoch 80/100 - Train loss: 0.0334 - Val accuracy: 0.8571 - Val loss: 0.2110 - Val F1: 0.8095 - LR: 2.00e-05\n",
      "\tEpoch 90/100 - Train loss: 0.0279 - Val accuracy: 0.8571 - Val loss: 0.1966 - Val F1: 0.8095 - LR: 1.00e-05\n",
      "\tEpoch 100/100 - Train loss: 0.0263 - Val accuracy: 0.8571 - Val loss: 0.1930 - Val F1: 0.8095 - LR: 0.00e+00\n",
      "\tBest epoch: 100 - Best val accuracy: 0.8571 - Best val loss: 0.1930 - Best val F1: 0.8095\n",
      "\n",
      "\tEpoch 10/100 - Train loss: 0.6741 - Val accuracy: 0.7143 - Val loss: 1.0465 - Val F1: 0.5952 - LR: 9.00e-05\n",
      "\tEpoch 20/100 - Train loss: 0.4328 - Val accuracy: 0.7143 - Val loss: 1.0761 - Val F1: 0.6494 - LR: 8.00e-05\n",
      "\tEpoch 30/100 - Train loss: 0.2938 - Val accuracy: 0.1429 - Val loss: 1.2675 - Val F1: 0.0357 - LR: 7.00e-05\n",
      "\tEpoch 40/100 - Train loss: 0.2239 - Val accuracy: 0.1429 - Val loss: 1.2785 - Val F1: 0.0357 - LR: 6.00e-05\n",
      "\tEpoch 50/100 - Train loss: 0.1681 - Val accuracy: 0.8571 - Val loss: 0.6427 - Val F1: 0.8095 - LR: 5.00e-05\n",
      "\tEpoch 60/100 - Train loss: 0.1372 - Val accuracy: 1.0000 - Val loss: 0.2551 - Val F1: 1.0000 - LR: 4.00e-05\n",
      "\tEpoch 70/100 - Train loss: 0.1249 - Val accuracy: 1.0000 - Val loss: 0.1868 - Val F1: 1.0000 - LR: 3.00e-05\n",
      "\tEpoch 80/100 - Train loss: 0.1143 - Val accuracy: 1.0000 - Val loss: 0.1660 - Val F1: 1.0000 - LR: 2.00e-05\n",
      "\tEpoch 90/100 - Train loss: 0.0939 - Val accuracy: 1.0000 - Val loss: 0.1582 - Val F1: 1.0000 - LR: 1.00e-05\n",
      "\tEpoch 100/100 - Train loss: 0.0924 - Val accuracy: 1.0000 - Val loss: 0.1558 - Val F1: 1.0000 - LR: 0.00e+00\n",
      "\tBest epoch: 100 - Best val accuracy: 1.0000 - Best val loss: 0.1558 - Best val F1: 1.0000\n",
      "\n",
      "\tEpoch 10/100 - Train loss: 0.7133 - Val accuracy: 0.7143 - Val loss: 1.0790 - Val F1: 0.5952 - LR: 9.00e-05\n",
      "\tEpoch 20/100 - Train loss: 0.4337 - Val accuracy: 0.1429 - Val loss: 1.1022 - Val F1: 0.0408 - LR: 8.00e-05\n",
      "\tEpoch 30/100 - Train loss: 0.2880 - Val accuracy: 0.1429 - Val loss: 1.2513 - Val F1: 0.0952 - LR: 7.00e-05\n",
      "\tEpoch 40/100 - Train loss: 0.1810 - Val accuracy: 0.2857 - Val loss: 1.2551 - Val F1: 0.1429 - LR: 6.00e-05\n",
      "\tEpoch 50/100 - Train loss: 0.1146 - Val accuracy: 1.0000 - Val loss: 0.7696 - Val F1: 1.0000 - LR: 5.00e-05\n",
      "\tEpoch 60/100 - Train loss: 0.0913 - Val accuracy: 1.0000 - Val loss: 0.3411 - Val F1: 1.0000 - LR: 4.00e-05\n",
      "\tEpoch 70/100 - Train loss: 0.0776 - Val accuracy: 1.0000 - Val loss: 0.2200 - Val F1: 1.0000 - LR: 3.00e-05\n",
      "\tEpoch 80/100 - Train loss: 0.0667 - Val accuracy: 0.8571 - Val loss: 0.1893 - Val F1: 0.8095 - LR: 2.00e-05\n",
      "\tEpoch 90/100 - Train loss: 0.0644 - Val accuracy: 0.8571 - Val loss: 0.1796 - Val F1: 0.8095 - LR: 1.00e-05\n",
      "\tEpoch 100/100 - Train loss: 0.0571 - Val accuracy: 0.8571 - Val loss: 0.1763 - Val F1: 0.8095 - LR: 0.00e+00\n",
      "\tBest epoch: 100 - Best val accuracy: 0.8571 - Best val loss: 0.1763 - Best val F1: 0.8095\n",
      "\n",
      "\tEpoch 10/100 - Train loss: 0.5921 - Val accuracy: 0.7143 - Val loss: 1.0505 - Val F1: 0.5952 - LR: 9.00e-05\n",
      "\tEpoch 20/100 - Train loss: 0.3592 - Val accuracy: 0.1429 - Val loss: 1.1255 - Val F1: 0.0357 - LR: 8.00e-05\n",
      "\tEpoch 30/100 - Train loss: 0.2367 - Val accuracy: 0.1429 - Val loss: 1.3553 - Val F1: 0.0357 - LR: 7.00e-05\n",
      "\tEpoch 40/100 - Train loss: 0.1626 - Val accuracy: 0.1429 - Val loss: 1.5455 - Val F1: 0.0357 - LR: 6.00e-05\n",
      "\tEpoch 50/100 - Train loss: 0.1275 - Val accuracy: 0.1429 - Val loss: 1.2313 - Val F1: 0.0357 - LR: 5.00e-05\n",
      "\tEpoch 60/100 - Train loss: 0.0821 - Val accuracy: 0.8571 - Val loss: 0.4464 - Val F1: 0.8095 - LR: 4.00e-05\n",
      "\tEpoch 70/100 - Train loss: 0.0799 - Val accuracy: 0.8571 - Val loss: 0.2101 - Val F1: 0.8095 - LR: 3.00e-05\n",
      "\tEpoch 80/100 - Train loss: 0.0701 - Val accuracy: 1.0000 - Val loss: 0.1592 - Val F1: 1.0000 - LR: 2.00e-05\n",
      "\tEpoch 90/100 - Train loss: 0.0620 - Val accuracy: 1.0000 - Val loss: 0.1434 - Val F1: 1.0000 - LR: 1.00e-05\n",
      "\tEpoch 100/100 - Train loss: 0.0546 - Val accuracy: 1.0000 - Val loss: 0.1385 - Val F1: 1.0000 - LR: 0.00e+00\n",
      "\tBest epoch: 100 - Best val accuracy: 1.0000 - Best val loss: 0.1385 - Best val F1: 1.0000\n",
      "\n",
      "\tEpoch 10/100 - Train loss: 0.5807 - Val accuracy: 0.7143 - Val loss: 1.0522 - Val F1: 0.5952 - LR: 9.00e-05\n",
      "\tEpoch 20/100 - Train loss: 0.3570 - Val accuracy: 0.1429 - Val loss: 1.2098 - Val F1: 0.0357 - LR: 8.00e-05\n",
      "\tEpoch 30/100 - Train loss: 0.2415 - Val accuracy: 0.1429 - Val loss: 1.5249 - Val F1: 0.0357 - LR: 7.00e-05\n",
      "\tEpoch 40/100 - Train loss: 0.1884 - Val accuracy: 0.1429 - Val loss: 1.6731 - Val F1: 0.0357 - LR: 6.00e-05\n",
      "\tEpoch 50/100 - Train loss: 0.1340 - Val accuracy: 0.1429 - Val loss: 1.1793 - Val F1: 0.0476 - LR: 5.00e-05\n",
      "\tEpoch 60/100 - Train loss: 0.1176 - Val accuracy: 0.8571 - Val loss: 0.4102 - Val F1: 0.8095 - LR: 4.00e-05\n",
      "\tEpoch 70/100 - Train loss: 0.0890 - Val accuracy: 1.0000 - Val loss: 0.1980 - Val F1: 1.0000 - LR: 3.00e-05\n",
      "\tEpoch 80/100 - Train loss: 0.0803 - Val accuracy: 1.0000 - Val loss: 0.1525 - Val F1: 1.0000 - LR: 2.00e-05\n",
      "\tEpoch 90/100 - Train loss: 0.0689 - Val accuracy: 1.0000 - Val loss: 0.1376 - Val F1: 1.0000 - LR: 1.00e-05\n",
      "\tEpoch 100/100 - Train loss: 0.0709 - Val accuracy: 1.0000 - Val loss: 0.1326 - Val F1: 1.0000 - LR: 0.00e+00\n",
      "\tBest epoch: 100 - Best val accuracy: 1.0000 - Best val loss: 0.1326 - Best val F1: 1.0000\n",
      "\n",
      "Source class: WAL | Domain: 29 | Accuracy: 0.9778 | Loss: 0.2335 | F1: 0.9778\n",
      "\n",
      "Domain: 30\n",
      "x_dp_dom.shape: (50, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Training and evaluating on Dp data via cross-validation...\n",
      "\tEpoch 10/100 - Train loss: 0.6504 - Val accuracy: 0.5000 - Val loss: 1.0780 - Val F1: 0.3333 - LR: 9.00e-05\n",
      "\tEpoch 20/100 - Train loss: 0.4268 - Val accuracy: 0.2500 - Val loss: 1.1346 - Val F1: 0.1000 - LR: 8.00e-05\n",
      "\tEpoch 30/100 - Train loss: 0.2846 - Val accuracy: 0.2500 - Val loss: 1.2638 - Val F1: 0.1000 - LR: 7.00e-05\n",
      "\tEpoch 40/100 - Train loss: 0.2119 - Val accuracy: 0.2500 - Val loss: 1.2748 - Val F1: 0.1000 - LR: 6.00e-05\n",
      "\tEpoch 50/100 - Train loss: 0.1561 - Val accuracy: 0.6250 - Val loss: 0.9458 - Val F1: 0.5714 - LR: 5.00e-05\n",
      "\tEpoch 60/100 - Train loss: 0.1303 - Val accuracy: 0.7500 - Val loss: 0.7255 - Val F1: 0.6667 - LR: 4.00e-05\n",
      "\tEpoch 70/100 - Train loss: 0.1053 - Val accuracy: 0.7500 - Val loss: 0.6577 - Val F1: 0.6667 - LR: 3.00e-05\n",
      "\tEpoch 80/100 - Train loss: 0.0941 - Val accuracy: 0.6250 - Val loss: 0.6439 - Val F1: 0.6000 - LR: 2.00e-05\n",
      "\tEpoch 90/100 - Train loss: 0.0937 - Val accuracy: 0.5000 - Val loss: 0.6423 - Val F1: 0.5000 - LR: 1.00e-05\n",
      "\tEpoch 100/100 - Train loss: 0.0921 - Val accuracy: 0.5000 - Val loss: 0.6421 - Val F1: 0.5000 - LR: 0.00e+00\n",
      "\tBest epoch: 100 - Best val accuracy: 0.5000 - Best val loss: 0.6421 - Best val F1: 0.5000\n",
      "\n",
      "\tEpoch 10/100 - Train loss: 0.6585 - Val accuracy: 0.2500 - Val loss: 1.1023 - Val F1: 0.1000 - LR: 9.00e-05\n",
      "\tEpoch 20/100 - Train loss: 0.4135 - Val accuracy: 0.2500 - Val loss: 1.1424 - Val F1: 0.1000 - LR: 8.00e-05\n",
      "\tEpoch 30/100 - Train loss: 0.2935 - Val accuracy: 0.1250 - Val loss: 1.2864 - Val F1: 0.0556 - LR: 7.00e-05\n",
      "\tEpoch 40/100 - Train loss: 0.2192 - Val accuracy: 0.1250 - Val loss: 1.4192 - Val F1: 0.0556 - LR: 6.00e-05\n",
      "\tEpoch 50/100 - Train loss: 0.1706 - Val accuracy: 0.2500 - Val loss: 1.1434 - Val F1: 0.2625 - LR: 5.00e-05\n",
      "\tEpoch 60/100 - Train loss: 0.1410 - Val accuracy: 0.5000 - Val loss: 0.7465 - Val F1: 0.5119 - LR: 4.00e-05\n",
      "\tEpoch 70/100 - Train loss: 0.1231 - Val accuracy: 0.6250 - Val loss: 0.6234 - Val F1: 0.5694 - LR: 3.00e-05\n",
      "\tEpoch 80/100 - Train loss: 0.1089 - Val accuracy: 0.6250 - Val loss: 0.6051 - Val F1: 0.5694 - LR: 2.00e-05\n",
      "\tEpoch 90/100 - Train loss: 0.1010 - Val accuracy: 0.6250 - Val loss: 0.6018 - Val F1: 0.5694 - LR: 1.00e-05\n",
      "\tEpoch 100/100 - Train loss: 0.0998 - Val accuracy: 0.6250 - Val loss: 0.6011 - Val F1: 0.5694 - LR: 0.00e+00\n",
      "\tBest epoch: 98 - Best val accuracy: 0.6250 - Best val loss: 0.6009 - Best val F1: 0.5694\n",
      "\n",
      "\tEpoch 10/100 - Train loss: 0.6503 - Val accuracy: 0.5000 - Val loss: 1.0863 - Val F1: 0.3333 - LR: 9.00e-05\n",
      "\tEpoch 20/100 - Train loss: 0.4439 - Val accuracy: 0.2500 - Val loss: 1.1411 - Val F1: 0.1000 - LR: 8.00e-05\n",
      "\tEpoch 30/100 - Train loss: 0.3193 - Val accuracy: 0.2500 - Val loss: 1.2456 - Val F1: 0.1000 - LR: 7.00e-05\n",
      "\tEpoch 40/100 - Train loss: 0.2539 - Val accuracy: 0.2500 - Val loss: 1.2403 - Val F1: 0.1000 - LR: 6.00e-05\n",
      "\tEpoch 50/100 - Train loss: 0.2012 - Val accuracy: 0.6250 - Val loss: 0.8668 - Val F1: 0.5714 - LR: 5.00e-05\n",
      "\tEpoch 60/100 - Train loss: 0.1753 - Val accuracy: 0.7500 - Val loss: 0.6053 - Val F1: 0.6667 - LR: 4.00e-05\n",
      "\tEpoch 70/100 - Train loss: 0.1576 - Val accuracy: 0.8750 - Val loss: 0.5455 - Val F1: 0.8667 - LR: 3.00e-05\n",
      "\tEpoch 80/100 - Train loss: 0.1422 - Val accuracy: 0.6250 - Val loss: 0.5382 - Val F1: 0.5694 - LR: 2.00e-05\n",
      "\tEpoch 90/100 - Train loss: 0.1221 - Val accuracy: 0.6250 - Val loss: 0.5393 - Val F1: 0.5694 - LR: 1.00e-05\n",
      "\tEpoch 100/100 - Train loss: 0.1212 - Val accuracy: 0.6250 - Val loss: 0.5414 - Val F1: 0.5694 - LR: 0.00e+00\n",
      "\tBest epoch: 79 - Best val accuracy: 0.6250 - Best val loss: 0.5382 - Best val F1: 0.5694\n",
      "\n",
      "\tEpoch 10/100 - Train loss: 0.6115 - Val accuracy: 0.2500 - Val loss: 1.0993 - Val F1: 0.1000 - LR: 9.00e-05\n",
      "\tEpoch 20/100 - Train loss: 0.3784 - Val accuracy: 0.2500 - Val loss: 1.1843 - Val F1: 0.1000 - LR: 8.00e-05\n",
      "\tEpoch 30/100 - Train loss: 0.2772 - Val accuracy: 0.2500 - Val loss: 1.4180 - Val F1: 0.1000 - LR: 7.00e-05\n",
      "\tEpoch 40/100 - Train loss: 0.2002 - Val accuracy: 0.2500 - Val loss: 1.5920 - Val F1: 0.1000 - LR: 6.00e-05\n",
      "\tEpoch 50/100 - Train loss: 0.1443 - Val accuracy: 0.1250 - Val loss: 1.2887 - Val F1: 0.2083 - LR: 5.00e-05\n",
      "\tEpoch 60/100 - Train loss: 0.1228 - Val accuracy: 0.6250 - Val loss: 0.9743 - Val F1: 0.6250 - LR: 4.00e-05\n",
      "\tEpoch 70/100 - Train loss: 0.1055 - Val accuracy: 0.6250 - Val loss: 1.0373 - Val F1: 0.5682 - LR: 3.00e-05\n",
      "\tEpoch 80/100 - Train loss: 0.0907 - Val accuracy: 0.6250 - Val loss: 1.1390 - Val F1: 0.5682 - LR: 2.00e-05\n",
      "\tEpoch 90/100 - Train loss: 0.0840 - Val accuracy: 0.6250 - Val loss: 1.1932 - Val F1: 0.5682 - LR: 1.00e-05\n",
      "\tEpoch 100/100 - Train loss: 0.0776 - Val accuracy: 0.6250 - Val loss: 1.2177 - Val F1: 0.5682 - LR: 0.00e+00\n",
      "\tBest epoch: 62 - Best val accuracy: 0.6250 - Best val loss: 0.9688 - Best val F1: 0.5682\n",
      "\n",
      "\tEpoch 10/100 - Train loss: 0.6019 - Val accuracy: 0.1250 - Val loss: 1.0916 - Val F1: 0.0278 - LR: 9.00e-05\n",
      "\tEpoch 20/100 - Train loss: 0.4039 - Val accuracy: 0.1250 - Val loss: 1.2085 - Val F1: 0.0278 - LR: 8.00e-05\n",
      "\tEpoch 30/100 - Train loss: 0.2791 - Val accuracy: 0.1250 - Val loss: 1.4115 - Val F1: 0.0278 - LR: 7.00e-05\n",
      "\tEpoch 40/100 - Train loss: 0.2274 - Val accuracy: 0.1250 - Val loss: 1.4924 - Val F1: 0.0278 - LR: 6.00e-05\n",
      "\tEpoch 50/100 - Train loss: 0.1795 - Val accuracy: 0.5000 - Val loss: 1.0268 - Val F1: 0.5104 - LR: 5.00e-05\n",
      "\tEpoch 60/100 - Train loss: 0.1465 - Val accuracy: 0.7500 - Val loss: 0.5793 - Val F1: 0.6875 - LR: 4.00e-05\n",
      "\tEpoch 70/100 - Train loss: 0.1387 - Val accuracy: 0.7500 - Val loss: 0.4797 - Val F1: 0.6875 - LR: 3.00e-05\n",
      "\tEpoch 80/100 - Train loss: 0.1089 - Val accuracy: 0.7500 - Val loss: 0.4785 - Val F1: 0.6515 - LR: 2.00e-05\n",
      "\tEpoch 90/100 - Train loss: 0.1110 - Val accuracy: 0.7500 - Val loss: 0.4859 - Val F1: 0.6515 - LR: 1.00e-05\n",
      "\tEpoch 100/100 - Train loss: 0.1026 - Val accuracy: 0.7500 - Val loss: 0.4905 - Val F1: 0.6515 - LR: 0.00e+00\n",
      "\tBest epoch: 74 - Best val accuracy: 0.7500 - Best val loss: 0.4754 - Best val F1: 0.6875\n",
      "\n",
      "Source class: WAL | Domain: 30 | Accuracy: 0.8400 | Loss: 0.3201 | F1: 0.8302\n",
      "\n",
      "Domain: 31\n",
      "x_dp_dom.shape: (43, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Training and evaluating on Dp data via cross-validation...\n",
      "\tEpoch 10/100 - Train loss: 0.6664 - Val accuracy: 0.7143 - Val loss: 1.0194 - Val F1: 0.5952 - LR: 9.00e-05\n",
      "\tEpoch 20/100 - Train loss: 0.4373 - Val accuracy: 0.4286 - Val loss: 1.0504 - Val F1: 0.4558 - LR: 8.00e-05\n",
      "\tEpoch 30/100 - Train loss: 0.2916 - Val accuracy: 0.1429 - Val loss: 1.1458 - Val F1: 0.0357 - LR: 7.00e-05\n",
      "\tEpoch 40/100 - Train loss: 0.2086 - Val accuracy: 0.4286 - Val loss: 1.0696 - Val F1: 0.4286 - LR: 6.00e-05\n",
      "\tEpoch 50/100 - Train loss: 0.1468 - Val accuracy: 0.8571 - Val loss: 0.5938 - Val F1: 0.8730 - LR: 5.00e-05\n",
      "\tEpoch 60/100 - Train loss: 0.1325 - Val accuracy: 1.0000 - Val loss: 0.2615 - Val F1: 1.0000 - LR: 4.00e-05\n",
      "\tEpoch 70/100 - Train loss: 0.1119 - Val accuracy: 1.0000 - Val loss: 0.1661 - Val F1: 1.0000 - LR: 3.00e-05\n",
      "\tEpoch 80/100 - Train loss: 0.0805 - Val accuracy: 1.0000 - Val loss: 0.1408 - Val F1: 1.0000 - LR: 2.00e-05\n",
      "\tEpoch 90/100 - Train loss: 0.0889 - Val accuracy: 1.0000 - Val loss: 0.1316 - Val F1: 1.0000 - LR: 1.00e-05\n",
      "\tEpoch 100/100 - Train loss: 0.0776 - Val accuracy: 1.0000 - Val loss: 0.1283 - Val F1: 1.0000 - LR: 0.00e+00\n",
      "\tBest epoch: 100 - Best val accuracy: 1.0000 - Best val loss: 0.1283 - Best val F1: 1.0000\n",
      "\n",
      "\tEpoch 10/100 - Train loss: 0.6136 - Val accuracy: 0.7143 - Val loss: 1.0491 - Val F1: 0.5952 - LR: 9.00e-05\n",
      "\tEpoch 20/100 - Train loss: 0.3970 - Val accuracy: 0.8571 - Val loss: 1.0575 - Val F1: 0.7922 - LR: 8.00e-05\n",
      "\tEpoch 30/100 - Train loss: 0.2751 - Val accuracy: 0.2857 - Val loss: 1.0949 - Val F1: 0.1837 - LR: 7.00e-05\n",
      "\tEpoch 40/100 - Train loss: 0.2062 - Val accuracy: 1.0000 - Val loss: 0.7660 - Val F1: 1.0000 - LR: 6.00e-05\n",
      "\tEpoch 50/100 - Train loss: 0.1547 - Val accuracy: 1.0000 - Val loss: 0.3307 - Val F1: 1.0000 - LR: 5.00e-05\n",
      "\tEpoch 60/100 - Train loss: 0.1216 - Val accuracy: 1.0000 - Val loss: 0.1793 - Val F1: 1.0000 - LR: 4.00e-05\n",
      "\tEpoch 70/100 - Train loss: 0.1126 - Val accuracy: 1.0000 - Val loss: 0.1324 - Val F1: 1.0000 - LR: 3.00e-05\n",
      "\tEpoch 80/100 - Train loss: 0.0858 - Val accuracy: 1.0000 - Val loss: 0.1139 - Val F1: 1.0000 - LR: 2.00e-05\n",
      "\tEpoch 90/100 - Train loss: 0.0834 - Val accuracy: 1.0000 - Val loss: 0.1056 - Val F1: 1.0000 - LR: 1.00e-05\n",
      "\tEpoch 100/100 - Train loss: 0.0876 - Val accuracy: 1.0000 - Val loss: 0.1022 - Val F1: 1.0000 - LR: 0.00e+00\n",
      "\tBest epoch: 100 - Best val accuracy: 1.0000 - Best val loss: 0.1022 - Best val F1: 1.0000\n",
      "\n",
      "\tEpoch 10/100 - Train loss: 0.5547 - Val accuracy: 0.7143 - Val loss: 1.0583 - Val F1: 0.5952 - LR: 9.00e-05\n",
      "\tEpoch 20/100 - Train loss: 0.3556 - Val accuracy: 0.1429 - Val loss: 1.1172 - Val F1: 0.0357 - LR: 8.00e-05\n",
      "\tEpoch 30/100 - Train loss: 0.2445 - Val accuracy: 0.2857 - Val loss: 1.2685 - Val F1: 0.1286 - LR: 7.00e-05\n",
      "\tEpoch 40/100 - Train loss: 0.1852 - Val accuracy: 0.2857 - Val loss: 1.2675 - Val F1: 0.1837 - LR: 6.00e-05\n",
      "\tEpoch 50/100 - Train loss: 0.1483 - Val accuracy: 0.8571 - Val loss: 0.7068 - Val F1: 0.8730 - LR: 5.00e-05\n",
      "\tEpoch 60/100 - Train loss: 0.1160 - Val accuracy: 1.0000 - Val loss: 0.2383 - Val F1: 1.0000 - LR: 4.00e-05\n",
      "\tEpoch 70/100 - Train loss: 0.1009 - Val accuracy: 1.0000 - Val loss: 0.1414 - Val F1: 1.0000 - LR: 3.00e-05\n",
      "\tEpoch 80/100 - Train loss: 0.0931 - Val accuracy: 1.0000 - Val loss: 0.1244 - Val F1: 1.0000 - LR: 2.00e-05\n",
      "\tEpoch 90/100 - Train loss: 0.0767 - Val accuracy: 1.0000 - Val loss: 0.1207 - Val F1: 1.0000 - LR: 1.00e-05\n",
      "\tEpoch 100/100 - Train loss: 0.0799 - Val accuracy: 1.0000 - Val loss: 0.1201 - Val F1: 1.0000 - LR: 0.00e+00\n",
      "\tBest epoch: 97 - Best val accuracy: 1.0000 - Best val loss: 0.1200 - Best val F1: 1.0000\n",
      "\n",
      "\tEpoch 10/100 - Train loss: 0.5763 - Val accuracy: 0.1429 - Val loss: 1.0910 - Val F1: 0.0357 - LR: 9.00e-05\n",
      "\tEpoch 20/100 - Train loss: 0.3362 - Val accuracy: 0.1429 - Val loss: 1.1040 - Val F1: 0.0357 - LR: 8.00e-05\n",
      "\tEpoch 30/100 - Train loss: 0.2070 - Val accuracy: 0.2857 - Val loss: 1.1179 - Val F1: 0.1837 - LR: 7.00e-05\n",
      "\tEpoch 40/100 - Train loss: 0.1453 - Val accuracy: 0.5714 - Val loss: 0.9266 - Val F1: 0.6082 - LR: 6.00e-05\n",
      "\tEpoch 50/100 - Train loss: 0.1103 - Val accuracy: 0.8571 - Val loss: 0.5494 - Val F1: 0.8730 - LR: 5.00e-05\n",
      "\tEpoch 60/100 - Train loss: 0.0920 - Val accuracy: 1.0000 - Val loss: 0.3293 - Val F1: 1.0000 - LR: 4.00e-05\n",
      "\tEpoch 70/100 - Train loss: 0.0657 - Val accuracy: 1.0000 - Val loss: 0.2413 - Val F1: 1.0000 - LR: 3.00e-05\n",
      "\tEpoch 80/100 - Train loss: 0.0632 - Val accuracy: 1.0000 - Val loss: 0.2082 - Val F1: 1.0000 - LR: 2.00e-05\n",
      "\tEpoch 90/100 - Train loss: 0.0556 - Val accuracy: 1.0000 - Val loss: 0.1942 - Val F1: 1.0000 - LR: 1.00e-05\n",
      "\tEpoch 100/100 - Train loss: 0.0500 - Val accuracy: 1.0000 - Val loss: 0.1890 - Val F1: 1.0000 - LR: 0.00e+00\n",
      "\tBest epoch: 100 - Best val accuracy: 1.0000 - Best val loss: 0.1890 - Best val F1: 1.0000\n",
      "\n",
      "\tEpoch 10/100 - Train loss: 0.5525 - Val accuracy: 0.8571 - Val loss: 1.0903 - Val F1: 0.7922 - LR: 9.00e-05\n",
      "\tEpoch 20/100 - Train loss: 0.3805 - Val accuracy: 0.2857 - Val loss: 1.0967 - Val F1: 0.1429 - LR: 8.00e-05\n",
      "\tEpoch 30/100 - Train loss: 0.2636 - Val accuracy: 0.2857 - Val loss: 1.1492 - Val F1: 0.1837 - LR: 7.00e-05\n",
      "\tEpoch 40/100 - Train loss: 0.1890 - Val accuracy: 0.4286 - Val loss: 0.9996 - Val F1: 0.4286 - LR: 6.00e-05\n",
      "\tEpoch 50/100 - Train loss: 0.1549 - Val accuracy: 1.0000 - Val loss: 0.5750 - Val F1: 1.0000 - LR: 5.00e-05\n",
      "\tEpoch 60/100 - Train loss: 0.1389 - Val accuracy: 1.0000 - Val loss: 0.3117 - Val F1: 1.0000 - LR: 4.00e-05\n",
      "\tEpoch 70/100 - Train loss: 0.1209 - Val accuracy: 1.0000 - Val loss: 0.2268 - Val F1: 1.0000 - LR: 3.00e-05\n",
      "\tEpoch 80/100 - Train loss: 0.1026 - Val accuracy: 1.0000 - Val loss: 0.1978 - Val F1: 1.0000 - LR: 2.00e-05\n",
      "\tEpoch 90/100 - Train loss: 0.1070 - Val accuracy: 1.0000 - Val loss: 0.1865 - Val F1: 1.0000 - LR: 1.00e-05\n",
      "\tEpoch 100/100 - Train loss: 0.0895 - Val accuracy: 1.0000 - Val loss: 0.1823 - Val F1: 1.0000 - LR: 0.00e+00\n",
      "\tBest epoch: 100 - Best val accuracy: 1.0000 - Best val loss: 0.1823 - Best val F1: 1.0000\n",
      "\n",
      "Source class: WAL | Domain: 31 | Accuracy: 0.9500 | Loss: 0.2721 | F1: 0.9470\n",
      "\n",
      "Domain: 32\n",
      "x_dp_dom.shape: (52, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Training and evaluating on Dp data via cross-validation...\n",
      "\tEpoch 10/100 - Train loss: 0.6732 - Val accuracy: 0.2222 - Val loss: 1.1112 - Val F1: 0.0808 - LR: 9.00e-05\n",
      "\tEpoch 20/100 - Train loss: 0.3950 - Val accuracy: 0.1111 - Val loss: 1.1663 - Val F1: 0.0444 - LR: 8.00e-05\n",
      "\tEpoch 30/100 - Train loss: 0.2632 - Val accuracy: 0.3333 - Val loss: 1.2527 - Val F1: 0.2116 - LR: 7.00e-05\n",
      "\tEpoch 40/100 - Train loss: 0.1826 - Val accuracy: 0.4444 - Val loss: 1.1254 - Val F1: 0.2889 - LR: 6.00e-05\n",
      "\tEpoch 50/100 - Train loss: 0.1299 - Val accuracy: 0.7778 - Val loss: 0.6695 - Val F1: 0.7722 - LR: 5.00e-05\n",
      "\tEpoch 60/100 - Train loss: 0.0907 - Val accuracy: 1.0000 - Val loss: 0.3744 - Val F1: 1.0000 - LR: 4.00e-05\n",
      "\tEpoch 70/100 - Train loss: 0.0717 - Val accuracy: 1.0000 - Val loss: 0.2679 - Val F1: 1.0000 - LR: 3.00e-05\n",
      "\tEpoch 80/100 - Train loss: 0.0622 - Val accuracy: 1.0000 - Val loss: 0.2296 - Val F1: 1.0000 - LR: 2.00e-05\n",
      "\tEpoch 90/100 - Train loss: 0.0602 - Val accuracy: 1.0000 - Val loss: 0.2147 - Val F1: 1.0000 - LR: 1.00e-05\n",
      "\tEpoch 100/100 - Train loss: 0.0572 - Val accuracy: 1.0000 - Val loss: 0.2100 - Val F1: 1.0000 - LR: 0.00e+00\n",
      "\tBest epoch: 100 - Best val accuracy: 1.0000 - Best val loss: 0.2100 - Best val F1: 1.0000\n",
      "\n",
      "\tEpoch 10/100 - Train loss: 0.6060 - Val accuracy: 0.2222 - Val loss: 1.1622 - Val F1: 0.1376 - LR: 9.00e-05\n",
      "\tEpoch 20/100 - Train loss: 0.3592 - Val accuracy: 0.2222 - Val loss: 1.3752 - Val F1: 0.0808 - LR: 8.00e-05\n",
      "\tEpoch 30/100 - Train loss: 0.2334 - Val accuracy: 0.2222 - Val loss: 1.7472 - Val F1: 0.0808 - LR: 7.00e-05\n",
      "\tEpoch 40/100 - Train loss: 0.1553 - Val accuracy: 0.2222 - Val loss: 1.8305 - Val F1: 0.0808 - LR: 6.00e-05\n",
      "\tEpoch 50/100 - Train loss: 0.1200 - Val accuracy: 0.5556 - Val loss: 0.9744 - Val F1: 0.5767 - LR: 5.00e-05\n",
      "\tEpoch 60/100 - Train loss: 0.0854 - Val accuracy: 1.0000 - Val loss: 0.2995 - Val F1: 1.0000 - LR: 4.00e-05\n",
      "\tEpoch 70/100 - Train loss: 0.0771 - Val accuracy: 1.0000 - Val loss: 0.1618 - Val F1: 1.0000 - LR: 3.00e-05\n",
      "\tEpoch 80/100 - Train loss: 0.0579 - Val accuracy: 1.0000 - Val loss: 0.1278 - Val F1: 1.0000 - LR: 2.00e-05\n",
      "\tEpoch 90/100 - Train loss: 0.0583 - Val accuracy: 1.0000 - Val loss: 0.1153 - Val F1: 1.0000 - LR: 1.00e-05\n",
      "\tEpoch 100/100 - Train loss: 0.0606 - Val accuracy: 1.0000 - Val loss: 0.1109 - Val F1: 1.0000 - LR: 0.00e+00\n",
      "\tBest epoch: 100 - Best val accuracy: 1.0000 - Best val loss: 0.1109 - Best val F1: 1.0000\n",
      "\n",
      "\tEpoch 10/100 - Train loss: 0.5868 - Val accuracy: 0.2222 - Val loss: 1.1515 - Val F1: 0.0808 - LR: 9.00e-05\n",
      "\tEpoch 20/100 - Train loss: 0.4003 - Val accuracy: 0.2222 - Val loss: 1.2526 - Val F1: 0.0808 - LR: 8.00e-05\n",
      "\tEpoch 30/100 - Train loss: 0.2959 - Val accuracy: 0.2222 - Val loss: 1.3945 - Val F1: 0.0808 - LR: 7.00e-05\n",
      "\tEpoch 40/100 - Train loss: 0.2208 - Val accuracy: 0.2222 - Val loss: 1.3708 - Val F1: 0.0808 - LR: 6.00e-05\n",
      "\tEpoch 50/100 - Train loss: 0.1705 - Val accuracy: 0.6667 - Val loss: 0.8262 - Val F1: 0.6918 - LR: 5.00e-05\n",
      "\tEpoch 60/100 - Train loss: 0.1253 - Val accuracy: 0.8889 - Val loss: 0.4268 - Val F1: 0.8815 - LR: 4.00e-05\n",
      "\tEpoch 70/100 - Train loss: 0.1058 - Val accuracy: 0.7778 - Val loss: 0.3143 - Val F1: 0.7778 - LR: 3.00e-05\n",
      "\tEpoch 80/100 - Train loss: 0.0861 - Val accuracy: 0.7778 - Val loss: 0.2814 - Val F1: 0.7778 - LR: 2.00e-05\n",
      "\tEpoch 90/100 - Train loss: 0.0814 - Val accuracy: 0.7778 - Val loss: 0.2682 - Val F1: 0.7778 - LR: 1.00e-05\n",
      "\tEpoch 100/100 - Train loss: 0.0791 - Val accuracy: 0.7778 - Val loss: 0.2630 - Val F1: 0.7778 - LR: 0.00e+00\n",
      "\tBest epoch: 100 - Best val accuracy: 0.7778 - Best val loss: 0.2630 - Best val F1: 0.7778\n",
      "\n",
      "\tEpoch 10/100 - Train loss: 0.6529 - Val accuracy: 0.2222 - Val loss: 1.1208 - Val F1: 0.0808 - LR: 9.00e-05\n",
      "\tEpoch 20/100 - Train loss: 0.4002 - Val accuracy: 0.2222 - Val loss: 1.1880 - Val F1: 0.0808 - LR: 8.00e-05\n",
      "\tEpoch 30/100 - Train loss: 0.2523 - Val accuracy: 0.2222 - Val loss: 1.3141 - Val F1: 0.0808 - LR: 7.00e-05\n",
      "\tEpoch 40/100 - Train loss: 0.1652 - Val accuracy: 0.2222 - Val loss: 1.2618 - Val F1: 0.0808 - LR: 6.00e-05\n",
      "\tEpoch 50/100 - Train loss: 0.1109 - Val accuracy: 0.6667 - Val loss: 0.7194 - Val F1: 0.6918 - LR: 5.00e-05\n",
      "\tEpoch 60/100 - Train loss: 0.0865 - Val accuracy: 0.8889 - Val loss: 0.3446 - Val F1: 0.8815 - LR: 4.00e-05\n",
      "\tEpoch 70/100 - Train loss: 0.0742 - Val accuracy: 0.8889 - Val loss: 0.2297 - Val F1: 0.8815 - LR: 3.00e-05\n",
      "\tEpoch 80/100 - Train loss: 0.0654 - Val accuracy: 0.8889 - Val loss: 0.1923 - Val F1: 0.8815 - LR: 2.00e-05\n",
      "\tEpoch 90/100 - Train loss: 0.0527 - Val accuracy: 1.0000 - Val loss: 0.1777 - Val F1: 1.0000 - LR: 1.00e-05\n",
      "\tEpoch 100/100 - Train loss: 0.0558 - Val accuracy: 1.0000 - Val loss: 0.1723 - Val F1: 1.0000 - LR: 0.00e+00\n",
      "\tBest epoch: 100 - Best val accuracy: 1.0000 - Best val loss: 0.1723 - Best val F1: 1.0000\n",
      "\n",
      "\tEpoch 10/100 - Train loss: 0.6119 - Val accuracy: 0.2222 - Val loss: 1.1144 - Val F1: 0.0808 - LR: 9.00e-05\n",
      "\tEpoch 20/100 - Train loss: 0.3854 - Val accuracy: 0.2222 - Val loss: 1.1883 - Val F1: 0.0808 - LR: 8.00e-05\n",
      "\tEpoch 30/100 - Train loss: 0.2462 - Val accuracy: 0.1111 - Val loss: 1.3301 - Val F1: 0.0494 - LR: 7.00e-05\n",
      "\tEpoch 40/100 - Train loss: 0.1825 - Val accuracy: 0.2222 - Val loss: 1.3269 - Val F1: 0.1444 - LR: 6.00e-05\n",
      "\tEpoch 50/100 - Train loss: 0.1329 - Val accuracy: 0.6667 - Val loss: 0.8121 - Val F1: 0.6833 - LR: 5.00e-05\n",
      "\tEpoch 60/100 - Train loss: 0.0915 - Val accuracy: 0.8889 - Val loss: 0.3614 - Val F1: 0.8815 - LR: 4.00e-05\n",
      "\tEpoch 70/100 - Train loss: 0.0692 - Val accuracy: 0.8889 - Val loss: 0.2590 - Val F1: 0.8815 - LR: 3.00e-05\n",
      "\tEpoch 80/100 - Train loss: 0.0636 - Val accuracy: 0.8889 - Val loss: 0.2352 - Val F1: 0.8815 - LR: 2.00e-05\n",
      "\tEpoch 90/100 - Train loss: 0.0592 - Val accuracy: 0.8889 - Val loss: 0.2270 - Val F1: 0.8815 - LR: 1.00e-05\n",
      "\tEpoch 100/100 - Train loss: 0.0540 - Val accuracy: 0.8889 - Val loss: 0.2243 - Val F1: 0.8815 - LR: 0.00e+00\n",
      "\tBest epoch: 100 - Best val accuracy: 0.8889 - Best val loss: 0.2243 - Best val F1: 0.8815\n",
      "\n",
      "Source class: WAL | Domain: 32 | Accuracy: 0.9818 | Loss: 0.1321 | F1: 0.9801\n",
      "\n",
      "Domain: 33\n",
      "x_dp_dom.shape: (44, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Training and evaluating on Dp data via cross-validation...\n",
      "\tEpoch 10/100 - Train loss: 0.5668 - Val accuracy: 0.1429 - Val loss: 1.0998 - Val F1: 0.0357 - LR: 9.00e-05\n",
      "\tEpoch 20/100 - Train loss: 0.3488 - Val accuracy: 0.2857 - Val loss: 1.1878 - Val F1: 0.1270 - LR: 8.00e-05\n",
      "\tEpoch 30/100 - Train loss: 0.2153 - Val accuracy: 0.2857 - Val loss: 1.3764 - Val F1: 0.1270 - LR: 7.00e-05\n",
      "\tEpoch 40/100 - Train loss: 0.1551 - Val accuracy: 0.2857 - Val loss: 1.2279 - Val F1: 0.1429 - LR: 6.00e-05\n",
      "\tEpoch 50/100 - Train loss: 0.1085 - Val accuracy: 0.7143 - Val loss: 0.6268 - Val F1: 0.6803 - LR: 5.00e-05\n",
      "\tEpoch 60/100 - Train loss: 0.0923 - Val accuracy: 0.8571 - Val loss: 0.3440 - Val F1: 0.8000 - LR: 4.00e-05\n",
      "\tEpoch 70/100 - Train loss: 0.0709 - Val accuracy: 0.8571 - Val loss: 0.2808 - Val F1: 0.8000 - LR: 3.00e-05\n",
      "\tEpoch 80/100 - Train loss: 0.0597 - Val accuracy: 0.8571 - Val loss: 0.2623 - Val F1: 0.8000 - LR: 2.00e-05\n",
      "\tEpoch 90/100 - Train loss: 0.0578 - Val accuracy: 1.0000 - Val loss: 0.2544 - Val F1: 1.0000 - LR: 1.00e-05\n",
      "\tEpoch 100/100 - Train loss: 0.0570 - Val accuracy: 1.0000 - Val loss: 0.2517 - Val F1: 1.0000 - LR: 0.00e+00\n",
      "\tBest epoch: 100 - Best val accuracy: 1.0000 - Best val loss: 0.2517 - Best val F1: 1.0000\n",
      "\n",
      "\tEpoch 10/100 - Train loss: 0.6594 - Val accuracy: 0.5714 - Val loss: 1.0805 - Val F1: 0.4156 - LR: 9.00e-05\n",
      "\tEpoch 20/100 - Train loss: 0.4187 - Val accuracy: 0.2857 - Val loss: 1.1153 - Val F1: 0.1270 - LR: 8.00e-05\n",
      "\tEpoch 30/100 - Train loss: 0.3060 - Val accuracy: 0.2857 - Val loss: 1.1992 - Val F1: 0.1270 - LR: 7.00e-05\n",
      "\tEpoch 40/100 - Train loss: 0.2179 - Val accuracy: 0.2857 - Val loss: 1.1114 - Val F1: 0.1270 - LR: 6.00e-05\n",
      "\tEpoch 50/100 - Train loss: 0.1652 - Val accuracy: 0.7143 - Val loss: 0.6273 - Val F1: 0.6803 - LR: 5.00e-05\n",
      "\tEpoch 60/100 - Train loss: 0.1293 - Val accuracy: 1.0000 - Val loss: 0.3452 - Val F1: 1.0000 - LR: 4.00e-05\n",
      "\tEpoch 70/100 - Train loss: 0.1098 - Val accuracy: 1.0000 - Val loss: 0.2611 - Val F1: 1.0000 - LR: 3.00e-05\n",
      "\tEpoch 80/100 - Train loss: 0.0977 - Val accuracy: 1.0000 - Val loss: 0.2369 - Val F1: 1.0000 - LR: 2.00e-05\n",
      "\tEpoch 90/100 - Train loss: 0.0880 - Val accuracy: 1.0000 - Val loss: 0.2274 - Val F1: 1.0000 - LR: 1.00e-05\n",
      "\tEpoch 100/100 - Train loss: 0.0798 - Val accuracy: 1.0000 - Val loss: 0.2241 - Val F1: 1.0000 - LR: 0.00e+00\n",
      "\tBest epoch: 100 - Best val accuracy: 1.0000 - Best val loss: 0.2241 - Best val F1: 1.0000\n",
      "\n",
      "\tEpoch 10/100 - Train loss: 0.5088 - Val accuracy: 0.1429 - Val loss: 1.1099 - Val F1: 0.0357 - LR: 9.00e-05\n",
      "\tEpoch 20/100 - Train loss: 0.3374 - Val accuracy: 0.2857 - Val loss: 1.1969 - Val F1: 0.1270 - LR: 8.00e-05\n",
      "\tEpoch 30/100 - Train loss: 0.2439 - Val accuracy: 0.2857 - Val loss: 1.3387 - Val F1: 0.1270 - LR: 7.00e-05\n",
      "\tEpoch 40/100 - Train loss: 0.1836 - Val accuracy: 0.2857 - Val loss: 1.2645 - Val F1: 0.1633 - LR: 6.00e-05\n",
      "\tEpoch 50/100 - Train loss: 0.1454 - Val accuracy: 0.8571 - Val loss: 0.6036 - Val F1: 0.8000 - LR: 5.00e-05\n",
      "\tEpoch 60/100 - Train loss: 0.1158 - Val accuracy: 0.8571 - Val loss: 0.2941 - Val F1: 0.8000 - LR: 4.00e-05\n",
      "\tEpoch 70/100 - Train loss: 0.0966 - Val accuracy: 1.0000 - Val loss: 0.2295 - Val F1: 1.0000 - LR: 3.00e-05\n",
      "\tEpoch 80/100 - Train loss: 0.0915 - Val accuracy: 1.0000 - Val loss: 0.2104 - Val F1: 1.0000 - LR: 2.00e-05\n",
      "\tEpoch 90/100 - Train loss: 0.0824 - Val accuracy: 1.0000 - Val loss: 0.2028 - Val F1: 1.0000 - LR: 1.00e-05\n",
      "\tEpoch 100/100 - Train loss: 0.0845 - Val accuracy: 1.0000 - Val loss: 0.2000 - Val F1: 1.0000 - LR: 0.00e+00\n",
      "\tBest epoch: 100 - Best val accuracy: 1.0000 - Best val loss: 0.2000 - Best val F1: 1.0000\n",
      "\n",
      "\tEpoch 10/100 - Train loss: 0.5345 - Val accuracy: 0.7143 - Val loss: 1.0448 - Val F1: 0.5952 - LR: 9.00e-05\n",
      "\tEpoch 20/100 - Train loss: 0.3097 - Val accuracy: 0.1429 - Val loss: 1.1483 - Val F1: 0.0357 - LR: 8.00e-05\n",
      "\tEpoch 30/100 - Train loss: 0.2163 - Val accuracy: 0.1429 - Val loss: 1.3684 - Val F1: 0.0357 - LR: 7.00e-05\n",
      "\tEpoch 40/100 - Train loss: 0.1490 - Val accuracy: 0.2857 - Val loss: 1.2485 - Val F1: 0.2789 - LR: 6.00e-05\n",
      "\tEpoch 50/100 - Train loss: 0.1067 - Val accuracy: 0.8571 - Val loss: 0.6620 - Val F1: 0.8095 - LR: 5.00e-05\n",
      "\tEpoch 60/100 - Train loss: 0.0874 - Val accuracy: 0.8571 - Val loss: 0.3515 - Val F1: 0.8095 - LR: 4.00e-05\n",
      "\tEpoch 70/100 - Train loss: 0.0688 - Val accuracy: 0.8571 - Val loss: 0.2689 - Val F1: 0.8095 - LR: 3.00e-05\n",
      "\tEpoch 80/100 - Train loss: 0.0636 - Val accuracy: 0.8571 - Val loss: 0.2452 - Val F1: 0.8095 - LR: 2.00e-05\n",
      "\tEpoch 90/100 - Train loss: 0.0517 - Val accuracy: 0.8571 - Val loss: 0.2365 - Val F1: 0.8095 - LR: 1.00e-05\n",
      "\tEpoch 100/100 - Train loss: 0.0471 - Val accuracy: 0.8571 - Val loss: 0.2339 - Val F1: 0.8095 - LR: 0.00e+00\n",
      "\tBest epoch: 100 - Best val accuracy: 0.8571 - Best val loss: 0.2339 - Best val F1: 0.8095\n",
      "\n",
      "\tEpoch 10/100 - Train loss: 0.5924 - Val accuracy: 0.6250 - Val loss: 1.0471 - Val F1: 0.4808 - LR: 9.00e-05\n",
      "\tEpoch 20/100 - Train loss: 0.3410 - Val accuracy: 0.2500 - Val loss: 1.0746 - Val F1: 0.1000 - LR: 8.00e-05\n",
      "\tEpoch 30/100 - Train loss: 0.2254 - Val accuracy: 0.2500 - Val loss: 1.2097 - Val F1: 0.1000 - LR: 7.00e-05\n",
      "\tEpoch 40/100 - Train loss: 0.1366 - Val accuracy: 0.2500 - Val loss: 1.1643 - Val F1: 0.1000 - LR: 6.00e-05\n",
      "\tEpoch 50/100 - Train loss: 0.1024 - Val accuracy: 0.8750 - Val loss: 0.5923 - Val F1: 0.8250 - LR: 5.00e-05\n",
      "\tEpoch 60/100 - Train loss: 0.0740 - Val accuracy: 0.8750 - Val loss: 0.3072 - Val F1: 0.8250 - LR: 4.00e-05\n",
      "\tEpoch 70/100 - Train loss: 0.0624 - Val accuracy: 0.8750 - Val loss: 0.2445 - Val F1: 0.8250 - LR: 3.00e-05\n",
      "\tEpoch 80/100 - Train loss: 0.0597 - Val accuracy: 0.8750 - Val loss: 0.2298 - Val F1: 0.8250 - LR: 2.00e-05\n",
      "\tEpoch 90/100 - Train loss: 0.0532 - Val accuracy: 0.8750 - Val loss: 0.2252 - Val F1: 0.8250 - LR: 1.00e-05\n",
      "\tEpoch 100/100 - Train loss: 0.0458 - Val accuracy: 0.8750 - Val loss: 0.2238 - Val F1: 0.8250 - LR: 0.00e+00\n",
      "\tBest epoch: 100 - Best val accuracy: 0.8750 - Best val loss: 0.2238 - Best val F1: 0.8250\n",
      "\n",
      "Source class: WAL | Domain: 33 | Accuracy: 0.9306 | Loss: 0.2518 | F1: 0.9172\n",
      "\n",
      "Domain: 34\n",
      "x_dp_dom.shape: (49, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Training and evaluating on Dp data via cross-validation...\n",
      "\tEpoch 10/100 - Train loss: 0.7137 - Val accuracy: 0.2500 - Val loss: 1.1132 - Val F1: 0.1000 - LR: 9.00e-05\n",
      "\tEpoch 20/100 - Train loss: 0.4699 - Val accuracy: 0.2500 - Val loss: 1.1984 - Val F1: 0.1000 - LR: 8.00e-05\n",
      "\tEpoch 30/100 - Train loss: 0.3184 - Val accuracy: 0.2500 - Val loss: 1.3113 - Val F1: 0.1000 - LR: 7.00e-05\n",
      "\tEpoch 40/100 - Train loss: 0.2612 - Val accuracy: 0.2500 - Val loss: 1.1798 - Val F1: 0.1000 - LR: 6.00e-05\n",
      "\tEpoch 50/100 - Train loss: 0.2165 - Val accuracy: 0.7500 - Val loss: 0.7740 - Val F1: 0.7556 - LR: 5.00e-05\n",
      "\tEpoch 60/100 - Train loss: 0.1690 - Val accuracy: 0.7500 - Val loss: 0.5446 - Val F1: 0.7556 - LR: 4.00e-05\n",
      "\tEpoch 70/100 - Train loss: 0.1391 - Val accuracy: 0.7500 - Val loss: 0.4629 - Val F1: 0.7556 - LR: 3.00e-05\n",
      "\tEpoch 80/100 - Train loss: 0.1303 - Val accuracy: 0.8750 - Val loss: 0.4340 - Val F1: 0.8889 - LR: 2.00e-05\n",
      "\tEpoch 90/100 - Train loss: 0.1214 - Val accuracy: 0.8750 - Val loss: 0.4233 - Val F1: 0.8889 - LR: 1.00e-05\n",
      "\tEpoch 100/100 - Train loss: 0.1255 - Val accuracy: 0.8750 - Val loss: 0.4184 - Val F1: 0.8889 - LR: 0.00e+00\n",
      "\tBest epoch: 100 - Best val accuracy: 0.8750 - Best val loss: 0.4184 - Best val F1: 0.8889\n",
      "\n",
      "\tEpoch 10/100 - Train loss: 0.7068 - Val accuracy: 0.6250 - Val loss: 1.0769 - Val F1: 0.4808 - LR: 9.00e-05\n",
      "\tEpoch 20/100 - Train loss: 0.4783 - Val accuracy: 0.2500 - Val loss: 1.1636 - Val F1: 0.1000 - LR: 8.00e-05\n",
      "\tEpoch 30/100 - Train loss: 0.2961 - Val accuracy: 0.2500 - Val loss: 1.3102 - Val F1: 0.1000 - LR: 7.00e-05\n",
      "\tEpoch 40/100 - Train loss: 0.2169 - Val accuracy: 0.5000 - Val loss: 1.0334 - Val F1: 0.4821 - LR: 6.00e-05\n",
      "\tEpoch 50/100 - Train loss: 0.1686 - Val accuracy: 0.7500 - Val loss: 0.5147 - Val F1: 0.6932 - LR: 5.00e-05\n",
      "\tEpoch 60/100 - Train loss: 0.1160 - Val accuracy: 0.7500 - Val loss: 0.4075 - Val F1: 0.6932 - LR: 4.00e-05\n",
      "\tEpoch 70/100 - Train loss: 0.0993 - Val accuracy: 0.7500 - Val loss: 0.4143 - Val F1: 0.6932 - LR: 3.00e-05\n",
      "\tEpoch 80/100 - Train loss: 0.0867 - Val accuracy: 0.7500 - Val loss: 0.4255 - Val F1: 0.6932 - LR: 2.00e-05\n",
      "\tEpoch 90/100 - Train loss: 0.0811 - Val accuracy: 0.7500 - Val loss: 0.4309 - Val F1: 0.6932 - LR: 1.00e-05\n",
      "\tEpoch 100/100 - Train loss: 0.0758 - Val accuracy: 0.7500 - Val loss: 0.4333 - Val F1: 0.6932 - LR: 0.00e+00\n",
      "\tBest epoch: 62 - Best val accuracy: 0.7500 - Best val loss: 0.4064 - Best val F1: 0.6932\n",
      "\n",
      "\tEpoch 10/100 - Train loss: 0.6989 - Val accuracy: 0.6250 - Val loss: 1.0728 - Val F1: 0.4808 - LR: 9.00e-05\n",
      "\tEpoch 20/100 - Train loss: 0.4820 - Val accuracy: 0.2500 - Val loss: 1.1410 - Val F1: 0.1000 - LR: 8.00e-05\n",
      "\tEpoch 30/100 - Train loss: 0.3258 - Val accuracy: 0.2500 - Val loss: 1.2513 - Val F1: 0.1000 - LR: 7.00e-05\n",
      "\tEpoch 40/100 - Train loss: 0.2266 - Val accuracy: 0.2500 - Val loss: 1.0732 - Val F1: 0.1000 - LR: 6.00e-05\n",
      "\tEpoch 50/100 - Train loss: 0.1716 - Val accuracy: 0.7500 - Val loss: 0.5995 - Val F1: 0.7222 - LR: 5.00e-05\n",
      "\tEpoch 60/100 - Train loss: 0.1361 - Val accuracy: 0.8750 - Val loss: 0.3464 - Val F1: 0.8250 - LR: 4.00e-05\n",
      "\tEpoch 70/100 - Train loss: 0.1158 - Val accuracy: 0.8750 - Val loss: 0.2677 - Val F1: 0.8250 - LR: 3.00e-05\n",
      "\tEpoch 80/100 - Train loss: 0.0984 - Val accuracy: 0.8750 - Val loss: 0.2409 - Val F1: 0.8250 - LR: 2.00e-05\n",
      "\tEpoch 90/100 - Train loss: 0.0898 - Val accuracy: 0.8750 - Val loss: 0.2294 - Val F1: 0.8250 - LR: 1.00e-05\n",
      "\tEpoch 100/100 - Train loss: 0.0781 - Val accuracy: 0.8750 - Val loss: 0.2248 - Val F1: 0.8250 - LR: 0.00e+00\n",
      "\tBest epoch: 100 - Best val accuracy: 0.8750 - Best val loss: 0.2248 - Best val F1: 0.8250\n",
      "\n",
      "\tEpoch 10/100 - Train loss: 0.6518 - Val accuracy: 0.2500 - Val loss: 1.0970 - Val F1: 0.1000 - LR: 9.00e-05\n",
      "\tEpoch 20/100 - Train loss: 0.4433 - Val accuracy: 0.2500 - Val loss: 1.1892 - Val F1: 0.1000 - LR: 8.00e-05\n",
      "\tEpoch 30/100 - Train loss: 0.3410 - Val accuracy: 0.2500 - Val loss: 1.3620 - Val F1: 0.1000 - LR: 7.00e-05\n",
      "\tEpoch 40/100 - Train loss: 0.2627 - Val accuracy: 0.2500 - Val loss: 1.2650 - Val F1: 0.1000 - LR: 6.00e-05\n",
      "\tEpoch 50/100 - Train loss: 0.2103 - Val accuracy: 0.8750 - Val loss: 0.6190 - Val F1: 0.8250 - LR: 5.00e-05\n",
      "\tEpoch 60/100 - Train loss: 0.1776 - Val accuracy: 0.8750 - Val loss: 0.3267 - Val F1: 0.8250 - LR: 4.00e-05\n",
      "\tEpoch 70/100 - Train loss: 0.1384 - Val accuracy: 0.8750 - Val loss: 0.2628 - Val F1: 0.8250 - LR: 3.00e-05\n",
      "\tEpoch 80/100 - Train loss: 0.1299 - Val accuracy: 0.8750 - Val loss: 0.2401 - Val F1: 0.8250 - LR: 2.00e-05\n",
      "\tEpoch 90/100 - Train loss: 0.1147 - Val accuracy: 0.8750 - Val loss: 0.2300 - Val F1: 0.8250 - LR: 1.00e-05\n",
      "\tEpoch 100/100 - Train loss: 0.1016 - Val accuracy: 0.8750 - Val loss: 0.2263 - Val F1: 0.8250 - LR: 0.00e+00\n",
      "\tBest epoch: 100 - Best val accuracy: 0.8750 - Best val loss: 0.2263 - Best val F1: 0.8250\n",
      "\n",
      "\tEpoch 10/100 - Train loss: 0.6300 - Val accuracy: 0.6250 - Val loss: 1.0583 - Val F1: 0.4808 - LR: 9.00e-05\n",
      "\tEpoch 20/100 - Train loss: 0.4073 - Val accuracy: 0.2500 - Val loss: 1.1541 - Val F1: 0.1000 - LR: 8.00e-05\n",
      "\tEpoch 30/100 - Train loss: 0.2875 - Val accuracy: 0.2500 - Val loss: 1.3720 - Val F1: 0.1000 - LR: 7.00e-05\n",
      "\tEpoch 40/100 - Train loss: 0.1879 - Val accuracy: 0.2500 - Val loss: 1.4010 - Val F1: 0.1000 - LR: 6.00e-05\n",
      "\tEpoch 50/100 - Train loss: 0.1355 - Val accuracy: 0.6250 - Val loss: 0.9338 - Val F1: 0.6116 - LR: 5.00e-05\n",
      "\tEpoch 60/100 - Train loss: 0.0993 - Val accuracy: 0.7500 - Val loss: 0.5660 - Val F1: 0.7222 - LR: 4.00e-05\n",
      "\tEpoch 70/100 - Train loss: 0.0881 - Val accuracy: 0.8750 - Val loss: 0.4288 - Val F1: 0.8250 - LR: 3.00e-05\n",
      "\tEpoch 80/100 - Train loss: 0.0743 - Val accuracy: 0.8750 - Val loss: 0.3839 - Val F1: 0.8250 - LR: 2.00e-05\n",
      "\tEpoch 90/100 - Train loss: 0.0706 - Val accuracy: 0.8750 - Val loss: 0.3677 - Val F1: 0.8250 - LR: 1.00e-05\n",
      "\tEpoch 100/100 - Train loss: 0.0663 - Val accuracy: 0.8750 - Val loss: 0.3625 - Val F1: 0.8250 - LR: 0.00e+00\n",
      "\tBest epoch: 100 - Best val accuracy: 0.8750 - Best val loss: 0.3625 - Best val F1: 0.8250\n",
      "\n",
      "Source class: WAL | Domain: 34 | Accuracy: 0.8133 | Loss: 0.3545 | F1: 0.7884\n",
      "\n",
      "Domain: 35\n",
      "x_dp_dom.shape: (48, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Training and evaluating on Dp data via cross-validation...\n",
      "\tEpoch 10/100 - Train loss: 0.5666 - Val accuracy: 0.2500 - Val loss: 1.1052 - Val F1: 0.1000 - LR: 9.00e-05\n",
      "\tEpoch 20/100 - Train loss: 0.3694 - Val accuracy: 0.2500 - Val loss: 1.2265 - Val F1: 0.1000 - LR: 8.00e-05\n",
      "\tEpoch 30/100 - Train loss: 0.2482 - Val accuracy: 0.2500 - Val loss: 1.4339 - Val F1: 0.1000 - LR: 7.00e-05\n",
      "\tEpoch 40/100 - Train loss: 0.1950 - Val accuracy: 0.2500 - Val loss: 1.3951 - Val F1: 0.1000 - LR: 6.00e-05\n",
      "\tEpoch 50/100 - Train loss: 0.1532 - Val accuracy: 0.7500 - Val loss: 0.7715 - Val F1: 0.7222 - LR: 5.00e-05\n",
      "\tEpoch 60/100 - Train loss: 0.1135 - Val accuracy: 0.8750 - Val loss: 0.3350 - Val F1: 0.8250 - LR: 4.00e-05\n",
      "\tEpoch 70/100 - Train loss: 0.0994 - Val accuracy: 0.8750 - Val loss: 0.2380 - Val F1: 0.8250 - LR: 3.00e-05\n",
      "\tEpoch 80/100 - Train loss: 0.0847 - Val accuracy: 0.8750 - Val loss: 0.2108 - Val F1: 0.8250 - LR: 2.00e-05\n",
      "\tEpoch 90/100 - Train loss: 0.0807 - Val accuracy: 0.8750 - Val loss: 0.2000 - Val F1: 0.8250 - LR: 1.00e-05\n",
      "\tEpoch 100/100 - Train loss: 0.0742 - Val accuracy: 0.8750 - Val loss: 0.1960 - Val F1: 0.8250 - LR: 0.00e+00\n",
      "\tBest epoch: 100 - Best val accuracy: 0.8750 - Best val loss: 0.1960 - Best val F1: 0.8250\n",
      "\n",
      "\tEpoch 10/100 - Train loss: 0.7246 - Val accuracy: 0.1250 - Val loss: 1.1077 - Val F1: 0.0278 - LR: 9.00e-05\n",
      "\tEpoch 20/100 - Train loss: 0.4482 - Val accuracy: 0.2500 - Val loss: 1.1538 - Val F1: 0.1000 - LR: 8.00e-05\n",
      "\tEpoch 30/100 - Train loss: 0.3255 - Val accuracy: 0.2500 - Val loss: 1.2772 - Val F1: 0.1000 - LR: 7.00e-05\n",
      "\tEpoch 40/100 - Train loss: 0.2644 - Val accuracy: 0.2500 - Val loss: 1.1676 - Val F1: 0.1000 - LR: 6.00e-05\n",
      "\tEpoch 50/100 - Train loss: 0.2156 - Val accuracy: 0.8750 - Val loss: 0.6402 - Val F1: 0.8250 - LR: 5.00e-05\n",
      "\tEpoch 60/100 - Train loss: 0.1849 - Val accuracy: 0.8750 - Val loss: 0.3255 - Val F1: 0.8250 - LR: 4.00e-05\n",
      "\tEpoch 70/100 - Train loss: 0.1681 - Val accuracy: 0.8750 - Val loss: 0.2387 - Val F1: 0.8250 - LR: 3.00e-05\n",
      "\tEpoch 80/100 - Train loss: 0.1420 - Val accuracy: 0.8750 - Val loss: 0.2098 - Val F1: 0.8250 - LR: 2.00e-05\n",
      "\tEpoch 90/100 - Train loss: 0.1346 - Val accuracy: 0.8750 - Val loss: 0.1976 - Val F1: 0.8250 - LR: 1.00e-05\n",
      "\tEpoch 100/100 - Train loss: 0.1265 - Val accuracy: 1.0000 - Val loss: 0.1931 - Val F1: 1.0000 - LR: 0.00e+00\n",
      "\tBest epoch: 100 - Best val accuracy: 1.0000 - Best val loss: 0.1931 - Best val F1: 1.0000\n",
      "\n",
      "\tEpoch 10/100 - Train loss: 0.5255 - Val accuracy: 0.2500 - Val loss: 1.1051 - Val F1: 0.1000 - LR: 9.00e-05\n",
      "\tEpoch 20/100 - Train loss: 0.3389 - Val accuracy: 0.2500 - Val loss: 1.2626 - Val F1: 0.1000 - LR: 8.00e-05\n",
      "\tEpoch 30/100 - Train loss: 0.2472 - Val accuracy: 0.2500 - Val loss: 1.5110 - Val F1: 0.1000 - LR: 7.00e-05\n",
      "\tEpoch 40/100 - Train loss: 0.2035 - Val accuracy: 0.2500 - Val loss: 1.4225 - Val F1: 0.1000 - LR: 6.00e-05\n",
      "\tEpoch 50/100 - Train loss: 0.1726 - Val accuracy: 0.7500 - Val loss: 0.7392 - Val F1: 0.7222 - LR: 5.00e-05\n",
      "\tEpoch 60/100 - Train loss: 0.1519 - Val accuracy: 0.8750 - Val loss: 0.3792 - Val F1: 0.8250 - LR: 4.00e-05\n",
      "\tEpoch 70/100 - Train loss: 0.1139 - Val accuracy: 0.8750 - Val loss: 0.2770 - Val F1: 0.8250 - LR: 3.00e-05\n",
      "\tEpoch 80/100 - Train loss: 0.1074 - Val accuracy: 0.8750 - Val loss: 0.2436 - Val F1: 0.8250 - LR: 2.00e-05\n",
      "\tEpoch 90/100 - Train loss: 0.1144 - Val accuracy: 1.0000 - Val loss: 0.2292 - Val F1: 1.0000 - LR: 1.00e-05\n",
      "\tEpoch 100/100 - Train loss: 0.1105 - Val accuracy: 1.0000 - Val loss: 0.2233 - Val F1: 1.0000 - LR: 0.00e+00\n",
      "\tBest epoch: 100 - Best val accuracy: 1.0000 - Best val loss: 0.2233 - Best val F1: 1.0000\n",
      "\n",
      "\tEpoch 10/100 - Train loss: 0.6621 - Val accuracy: 0.6250 - Val loss: 1.0291 - Val F1: 0.4808 - LR: 9.00e-05\n",
      "\tEpoch 20/100 - Train loss: 0.4573 - Val accuracy: 0.2500 - Val loss: 1.0724 - Val F1: 0.1000 - LR: 8.00e-05\n",
      "\tEpoch 30/100 - Train loss: 0.2891 - Val accuracy: 0.2500 - Val loss: 1.1816 - Val F1: 0.1000 - LR: 7.00e-05\n",
      "\tEpoch 40/100 - Train loss: 0.2246 - Val accuracy: 0.2500 - Val loss: 1.1171 - Val F1: 0.1000 - LR: 6.00e-05\n",
      "\tEpoch 50/100 - Train loss: 0.1748 - Val accuracy: 0.7500 - Val loss: 0.7202 - Val F1: 0.7222 - LR: 5.00e-05\n",
      "\tEpoch 60/100 - Train loss: 0.1434 - Val accuracy: 0.8750 - Val loss: 0.4089 - Val F1: 0.8250 - LR: 4.00e-05\n",
      "\tEpoch 70/100 - Train loss: 0.1249 - Val accuracy: 0.8750 - Val loss: 0.3018 - Val F1: 0.8250 - LR: 3.00e-05\n",
      "\tEpoch 80/100 - Train loss: 0.1060 - Val accuracy: 0.8750 - Val loss: 0.2643 - Val F1: 0.8250 - LR: 2.00e-05\n",
      "\tEpoch 90/100 - Train loss: 0.0953 - Val accuracy: 0.8750 - Val loss: 0.2481 - Val F1: 0.8250 - LR: 1.00e-05\n",
      "\tEpoch 100/100 - Train loss: 0.0931 - Val accuracy: 0.8750 - Val loss: 0.2419 - Val F1: 0.8250 - LR: 0.00e+00\n",
      "\tBest epoch: 100 - Best val accuracy: 0.8750 - Best val loss: 0.2419 - Best val F1: 0.8250\n",
      "\n",
      "\tEpoch 10/100 - Train loss: 0.6142 - Val accuracy: 0.2500 - Val loss: 1.1204 - Val F1: 0.1000 - LR: 9.00e-05\n",
      "\tEpoch 20/100 - Train loss: 0.3919 - Val accuracy: 0.2500 - Val loss: 1.1580 - Val F1: 0.1000 - LR: 8.00e-05\n",
      "\tEpoch 30/100 - Train loss: 0.2510 - Val accuracy: 0.2500 - Val loss: 1.2754 - Val F1: 0.1000 - LR: 7.00e-05\n",
      "\tEpoch 40/100 - Train loss: 0.1858 - Val accuracy: 0.2500 - Val loss: 1.1890 - Val F1: 0.1250 - LR: 6.00e-05\n",
      "\tEpoch 50/100 - Train loss: 0.1381 - Val accuracy: 0.7500 - Val loss: 0.7336 - Val F1: 0.7500 - LR: 5.00e-05\n",
      "\tEpoch 60/100 - Train loss: 0.1044 - Val accuracy: 0.7500 - Val loss: 0.4115 - Val F1: 0.7500 - LR: 4.00e-05\n",
      "\tEpoch 70/100 - Train loss: 0.0899 - Val accuracy: 1.0000 - Val loss: 0.3250 - Val F1: 1.0000 - LR: 3.00e-05\n",
      "\tEpoch 80/100 - Train loss: 0.0781 - Val accuracy: 1.0000 - Val loss: 0.2970 - Val F1: 1.0000 - LR: 2.00e-05\n",
      "\tEpoch 90/100 - Train loss: 0.0771 - Val accuracy: 1.0000 - Val loss: 0.2856 - Val F1: 1.0000 - LR: 1.00e-05\n",
      "\tEpoch 100/100 - Train loss: 0.0687 - Val accuracy: 1.0000 - Val loss: 0.2815 - Val F1: 1.0000 - LR: 0.00e+00\n",
      "\tBest epoch: 100 - Best val accuracy: 1.0000 - Best val loss: 0.2815 - Best val F1: 1.0000\n",
      "\n",
      "Source class: WAL | Domain: 35 | Accuracy: 0.8733 | Loss: 0.2647 | F1: 0.8313\n",
      "\n",
      "Domain: 36\n",
      "x_dp_dom.shape: (43, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Training and evaluating on Dp data via cross-validation...\n",
      "\tEpoch 10/100 - Train loss: 0.5236 - Val accuracy: 0.7143 - Val loss: 1.0567 - Val F1: 0.5952 - LR: 9.00e-05\n",
      "\tEpoch 20/100 - Train loss: 0.3007 - Val accuracy: 0.1429 - Val loss: 1.1352 - Val F1: 0.0357 - LR: 8.00e-05\n",
      "\tEpoch 30/100 - Train loss: 0.2002 - Val accuracy: 0.1429 - Val loss: 1.2829 - Val F1: 0.0357 - LR: 7.00e-05\n",
      "\tEpoch 40/100 - Train loss: 0.1397 - Val accuracy: 0.1429 - Val loss: 1.4271 - Val F1: 0.0357 - LR: 6.00e-05\n",
      "\tEpoch 50/100 - Train loss: 0.1146 - Val accuracy: 0.1429 - Val loss: 1.2607 - Val F1: 0.0357 - LR: 5.00e-05\n",
      "\tEpoch 60/100 - Train loss: 0.0947 - Val accuracy: 0.8571 - Val loss: 0.5572 - Val F1: 0.8095 - LR: 4.00e-05\n",
      "\tEpoch 70/100 - Train loss: 0.0690 - Val accuracy: 1.0000 - Val loss: 0.2401 - Val F1: 1.0000 - LR: 3.00e-05\n",
      "\tEpoch 80/100 - Train loss: 0.0632 - Val accuracy: 1.0000 - Val loss: 0.1631 - Val F1: 1.0000 - LR: 2.00e-05\n",
      "\tEpoch 90/100 - Train loss: 0.0623 - Val accuracy: 1.0000 - Val loss: 0.1417 - Val F1: 1.0000 - LR: 1.00e-05\n",
      "\tEpoch 100/100 - Train loss: 0.0552 - Val accuracy: 1.0000 - Val loss: 0.1345 - Val F1: 1.0000 - LR: 0.00e+00\n",
      "\tBest epoch: 100 - Best val accuracy: 1.0000 - Best val loss: 0.1345 - Best val F1: 1.0000\n",
      "\n",
      "\tEpoch 10/100 - Train loss: 0.5371 - Val accuracy: 0.7143 - Val loss: 1.0886 - Val F1: 0.5952 - LR: 9.00e-05\n",
      "\tEpoch 20/100 - Train loss: 0.3391 - Val accuracy: 0.1429 - Val loss: 1.2026 - Val F1: 0.0357 - LR: 8.00e-05\n",
      "\tEpoch 30/100 - Train loss: 0.2244 - Val accuracy: 0.1429 - Val loss: 1.4100 - Val F1: 0.0357 - LR: 7.00e-05\n",
      "\tEpoch 40/100 - Train loss: 0.1591 - Val accuracy: 0.1429 - Val loss: 1.4862 - Val F1: 0.0357 - LR: 6.00e-05\n",
      "\tEpoch 50/100 - Train loss: 0.1209 - Val accuracy: 0.4286 - Val loss: 1.0142 - Val F1: 0.4286 - LR: 5.00e-05\n",
      "\tEpoch 60/100 - Train loss: 0.0980 - Val accuracy: 1.0000 - Val loss: 0.3636 - Val F1: 1.0000 - LR: 4.00e-05\n",
      "\tEpoch 70/100 - Train loss: 0.0817 - Val accuracy: 1.0000 - Val loss: 0.1497 - Val F1: 1.0000 - LR: 3.00e-05\n",
      "\tEpoch 80/100 - Train loss: 0.0746 - Val accuracy: 1.0000 - Val loss: 0.1045 - Val F1: 1.0000 - LR: 2.00e-05\n",
      "\tEpoch 90/100 - Train loss: 0.0665 - Val accuracy: 1.0000 - Val loss: 0.0919 - Val F1: 1.0000 - LR: 1.00e-05\n",
      "\tEpoch 100/100 - Train loss: 0.0750 - Val accuracy: 1.0000 - Val loss: 0.0877 - Val F1: 1.0000 - LR: 0.00e+00\n",
      "\tBest epoch: 100 - Best val accuracy: 1.0000 - Best val loss: 0.0877 - Best val F1: 1.0000\n",
      "\n",
      "\tEpoch 10/100 - Train loss: 0.5404 - Val accuracy: 0.7143 - Val loss: 1.0494 - Val F1: 0.5952 - LR: 9.00e-05\n",
      "\tEpoch 20/100 - Train loss: 0.3464 - Val accuracy: 0.1429 - Val loss: 1.1930 - Val F1: 0.0357 - LR: 8.00e-05\n",
      "\tEpoch 30/100 - Train loss: 0.2298 - Val accuracy: 0.2857 - Val loss: 1.4241 - Val F1: 0.1429 - LR: 7.00e-05\n",
      "\tEpoch 40/100 - Train loss: 0.1713 - Val accuracy: 0.2857 - Val loss: 1.5302 - Val F1: 0.1429 - LR: 6.00e-05\n",
      "\tEpoch 50/100 - Train loss: 0.1293 - Val accuracy: 0.4286 - Val loss: 0.9817 - Val F1: 0.3905 - LR: 5.00e-05\n",
      "\tEpoch 60/100 - Train loss: 0.1007 - Val accuracy: 1.0000 - Val loss: 0.3188 - Val F1: 1.0000 - LR: 4.00e-05\n",
      "\tEpoch 70/100 - Train loss: 0.0795 - Val accuracy: 1.0000 - Val loss: 0.1584 - Val F1: 1.0000 - LR: 3.00e-05\n",
      "\tEpoch 80/100 - Train loss: 0.0700 - Val accuracy: 1.0000 - Val loss: 0.1199 - Val F1: 1.0000 - LR: 2.00e-05\n",
      "\tEpoch 90/100 - Train loss: 0.0570 - Val accuracy: 1.0000 - Val loss: 0.1066 - Val F1: 1.0000 - LR: 1.00e-05\n",
      "\tEpoch 100/100 - Train loss: 0.0632 - Val accuracy: 1.0000 - Val loss: 0.1020 - Val F1: 1.0000 - LR: 0.00e+00\n",
      "\tBest epoch: 100 - Best val accuracy: 1.0000 - Best val loss: 0.1020 - Best val F1: 1.0000\n",
      "\n",
      "\tEpoch 10/100 - Train loss: 0.5547 - Val accuracy: 0.1429 - Val loss: 1.0866 - Val F1: 0.0357 - LR: 9.00e-05\n",
      "\tEpoch 20/100 - Train loss: 0.3580 - Val accuracy: 0.1429 - Val loss: 1.1941 - Val F1: 0.0357 - LR: 8.00e-05\n",
      "\tEpoch 30/100 - Train loss: 0.2476 - Val accuracy: 0.1429 - Val loss: 1.3962 - Val F1: 0.0357 - LR: 7.00e-05\n",
      "\tEpoch 40/100 - Train loss: 0.1938 - Val accuracy: 0.1429 - Val loss: 1.4789 - Val F1: 0.0357 - LR: 6.00e-05\n",
      "\tEpoch 50/100 - Train loss: 0.1662 - Val accuracy: 0.7143 - Val loss: 0.8835 - Val F1: 0.7063 - LR: 5.00e-05\n",
      "\tEpoch 60/100 - Train loss: 0.1418 - Val accuracy: 0.8571 - Val loss: 0.3354 - Val F1: 0.8095 - LR: 4.00e-05\n",
      "\tEpoch 70/100 - Train loss: 0.1113 - Val accuracy: 0.8571 - Val loss: 0.2466 - Val F1: 0.8095 - LR: 3.00e-05\n",
      "\tEpoch 80/100 - Train loss: 0.0997 - Val accuracy: 0.8571 - Val loss: 0.2324 - Val F1: 0.8095 - LR: 2.00e-05\n",
      "\tEpoch 90/100 - Train loss: 0.0923 - Val accuracy: 0.8571 - Val loss: 0.2269 - Val F1: 0.8095 - LR: 1.00e-05\n",
      "\tEpoch 100/100 - Train loss: 0.0938 - Val accuracy: 0.8571 - Val loss: 0.2247 - Val F1: 0.8095 - LR: 0.00e+00\n",
      "\tBest epoch: 100 - Best val accuracy: 0.8571 - Best val loss: 0.2247 - Best val F1: 0.8095\n",
      "\n",
      "\tEpoch 10/100 - Train loss: 0.6238 - Val accuracy: 0.7143 - Val loss: 1.0712 - Val F1: 0.5952 - LR: 9.00e-05\n",
      "\tEpoch 20/100 - Train loss: 0.3764 - Val accuracy: 0.1429 - Val loss: 1.1217 - Val F1: 0.0357 - LR: 8.00e-05\n",
      "\tEpoch 30/100 - Train loss: 0.2482 - Val accuracy: 0.1429 - Val loss: 1.2623 - Val F1: 0.0408 - LR: 7.00e-05\n",
      "\tEpoch 40/100 - Train loss: 0.1893 - Val accuracy: 0.1429 - Val loss: 1.2903 - Val F1: 0.0357 - LR: 6.00e-05\n",
      "\tEpoch 50/100 - Train loss: 0.1439 - Val accuracy: 0.5714 - Val loss: 0.8917 - Val F1: 0.5929 - LR: 5.00e-05\n",
      "\tEpoch 60/100 - Train loss: 0.1184 - Val accuracy: 0.8571 - Val loss: 0.4076 - Val F1: 0.8095 - LR: 4.00e-05\n",
      "\tEpoch 70/100 - Train loss: 0.1006 - Val accuracy: 0.8571 - Val loss: 0.2973 - Val F1: 0.8095 - LR: 3.00e-05\n",
      "\tEpoch 80/100 - Train loss: 0.0997 - Val accuracy: 0.8571 - Val loss: 0.2773 - Val F1: 0.8095 - LR: 2.00e-05\n",
      "\tEpoch 90/100 - Train loss: 0.0850 - Val accuracy: 0.8571 - Val loss: 0.2712 - Val F1: 0.8095 - LR: 1.00e-05\n",
      "\tEpoch 100/100 - Train loss: 0.0850 - Val accuracy: 0.8571 - Val loss: 0.2695 - Val F1: 0.8095 - LR: 0.00e+00\n",
      "\tBest epoch: 100 - Best val accuracy: 0.8571 - Best val loss: 0.2695 - Best val F1: 0.8095\n",
      "\n",
      "Source class: WAL | Domain: 36 | Accuracy: 0.9306 | Loss: 0.2186 | F1: 0.9217\n",
      "\n",
      "Domain: 37\n",
      "x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Training and evaluating on Dp data via cross-validation...\n",
      "\tEpoch 10/100 - Train loss: 0.6163 - Val accuracy: 0.7143 - Val loss: 1.0288 - Val F1: 0.5952 - LR: 9.00e-05\n",
      "\tEpoch 20/100 - Train loss: 0.4113 - Val accuracy: 0.7143 - Val loss: 1.0696 - Val F1: 0.5952 - LR: 8.00e-05\n",
      "\tEpoch 30/100 - Train loss: 0.3000 - Val accuracy: 0.1429 - Val loss: 1.2559 - Val F1: 0.0476 - LR: 7.00e-05\n",
      "\tEpoch 40/100 - Train loss: 0.2298 - Val accuracy: 0.0000 - Val loss: 1.2854 - Val F1: 0.0000 - LR: 6.00e-05\n",
      "\tEpoch 50/100 - Train loss: 0.1872 - Val accuracy: 0.7143 - Val loss: 0.8470 - Val F1: 0.7302 - LR: 5.00e-05\n",
      "\tEpoch 60/100 - Train loss: 0.1572 - Val accuracy: 0.7143 - Val loss: 0.5630 - Val F1: 0.7302 - LR: 4.00e-05\n",
      "\tEpoch 70/100 - Train loss: 0.1456 - Val accuracy: 0.8571 - Val loss: 0.4825 - Val F1: 0.8095 - LR: 3.00e-05\n",
      "\tEpoch 80/100 - Train loss: 0.1246 - Val accuracy: 0.8571 - Val loss: 0.4648 - Val F1: 0.8095 - LR: 2.00e-05\n",
      "\tEpoch 90/100 - Train loss: 0.1195 - Val accuracy: 0.8571 - Val loss: 0.4598 - Val F1: 0.8095 - LR: 1.00e-05\n",
      "\tEpoch 100/100 - Train loss: 0.1134 - Val accuracy: 0.8571 - Val loss: 0.4586 - Val F1: 0.8095 - LR: 0.00e+00\n",
      "\tBest epoch: 100 - Best val accuracy: 0.8571 - Best val loss: 0.4586 - Best val F1: 0.8095\n",
      "\n",
      "\tEpoch 10/100 - Train loss: 0.4716 - Val accuracy: 0.1429 - Val loss: 1.1178 - Val F1: 0.0357 - LR: 9.00e-05\n",
      "\tEpoch 20/100 - Train loss: 0.3106 - Val accuracy: 0.1429 - Val loss: 1.2878 - Val F1: 0.0357 - LR: 8.00e-05\n",
      "\tEpoch 30/100 - Train loss: 0.2289 - Val accuracy: 0.1429 - Val loss: 1.5672 - Val F1: 0.0357 - LR: 7.00e-05\n",
      "\tEpoch 40/100 - Train loss: 0.1804 - Val accuracy: 0.1429 - Val loss: 1.5709 - Val F1: 0.0357 - LR: 6.00e-05\n",
      "\tEpoch 50/100 - Train loss: 0.1376 - Val accuracy: 0.5714 - Val loss: 0.9242 - Val F1: 0.6310 - LR: 5.00e-05\n",
      "\tEpoch 60/100 - Train loss: 0.1060 - Val accuracy: 0.8571 - Val loss: 0.4901 - Val F1: 0.8095 - LR: 4.00e-05\n",
      "\tEpoch 70/100 - Train loss: 0.0934 - Val accuracy: 0.8571 - Val loss: 0.3855 - Val F1: 0.8095 - LR: 3.00e-05\n",
      "\tEpoch 80/100 - Train loss: 0.0839 - Val accuracy: 0.8571 - Val loss: 0.3644 - Val F1: 0.8095 - LR: 2.00e-05\n",
      "\tEpoch 90/100 - Train loss: 0.0759 - Val accuracy: 0.8571 - Val loss: 0.3615 - Val F1: 0.8095 - LR: 1.00e-05\n",
      "\tEpoch 100/100 - Train loss: 0.0677 - Val accuracy: 0.8571 - Val loss: 0.3612 - Val F1: 0.8095 - LR: 0.00e+00\n",
      "\tBest epoch: 100 - Best val accuracy: 0.8571 - Best val loss: 0.3612 - Best val F1: 0.8095\n",
      "\n",
      "\tEpoch 10/100 - Train loss: 0.5917 - Val accuracy: 0.1429 - Val loss: 1.1049 - Val F1: 0.0357 - LR: 9.00e-05\n",
      "\tEpoch 20/100 - Train loss: 0.3747 - Val accuracy: 0.1429 - Val loss: 1.2777 - Val F1: 0.0357 - LR: 8.00e-05\n",
      "\tEpoch 30/100 - Train loss: 0.2774 - Val accuracy: 0.1429 - Val loss: 1.5956 - Val F1: 0.0357 - LR: 7.00e-05\n",
      "\tEpoch 40/100 - Train loss: 0.2007 - Val accuracy: 0.1429 - Val loss: 1.6710 - Val F1: 0.0357 - LR: 6.00e-05\n",
      "\tEpoch 50/100 - Train loss: 0.1494 - Val accuracy: 0.5714 - Val loss: 0.9466 - Val F1: 0.5929 - LR: 5.00e-05\n",
      "\tEpoch 60/100 - Train loss: 0.1203 - Val accuracy: 0.8571 - Val loss: 0.4013 - Val F1: 0.8095 - LR: 4.00e-05\n",
      "\tEpoch 70/100 - Train loss: 0.0964 - Val accuracy: 0.8571 - Val loss: 0.2973 - Val F1: 0.8095 - LR: 3.00e-05\n",
      "\tEpoch 80/100 - Train loss: 0.0885 - Val accuracy: 0.8571 - Val loss: 0.2793 - Val F1: 0.8095 - LR: 2.00e-05\n",
      "\tEpoch 90/100 - Train loss: 0.0880 - Val accuracy: 0.8571 - Val loss: 0.2757 - Val F1: 0.8095 - LR: 1.00e-05\n",
      "\tEpoch 100/100 - Train loss: 0.0821 - Val accuracy: 0.8571 - Val loss: 0.2753 - Val F1: 0.8095 - LR: 0.00e+00\n",
      "\tBest epoch: 98 - Best val accuracy: 0.8571 - Best val loss: 0.2753 - Best val F1: 0.8095\n",
      "\n",
      "\tEpoch 10/100 - Train loss: 0.4701 - Val accuracy: 0.1429 - Val loss: 1.0771 - Val F1: 0.0357 - LR: 9.00e-05\n",
      "\tEpoch 20/100 - Train loss: 0.3143 - Val accuracy: 0.1429 - Val loss: 1.2001 - Val F1: 0.0357 - LR: 8.00e-05\n",
      "\tEpoch 30/100 - Train loss: 0.2334 - Val accuracy: 0.1429 - Val loss: 1.3930 - Val F1: 0.0357 - LR: 7.00e-05\n",
      "\tEpoch 40/100 - Train loss: 0.1826 - Val accuracy: 0.1429 - Val loss: 1.4197 - Val F1: 0.0357 - LR: 6.00e-05\n",
      "\tEpoch 50/100 - Train loss: 0.1336 - Val accuracy: 0.7143 - Val loss: 0.8369 - Val F1: 0.7063 - LR: 5.00e-05\n",
      "\tEpoch 60/100 - Train loss: 0.1084 - Val accuracy: 0.8571 - Val loss: 0.4411 - Val F1: 0.8095 - LR: 4.00e-05\n",
      "\tEpoch 70/100 - Train loss: 0.0963 - Val accuracy: 0.8571 - Val loss: 0.3404 - Val F1: 0.8095 - LR: 3.00e-05\n",
      "\tEpoch 80/100 - Train loss: 0.0811 - Val accuracy: 0.8571 - Val loss: 0.3140 - Val F1: 0.8095 - LR: 2.00e-05\n",
      "\tEpoch 90/100 - Train loss: 0.0713 - Val accuracy: 0.8571 - Val loss: 0.3049 - Val F1: 0.8095 - LR: 1.00e-05\n",
      "\tEpoch 100/100 - Train loss: 0.0675 - Val accuracy: 0.8571 - Val loss: 0.3025 - Val F1: 0.8095 - LR: 0.00e+00\n",
      "\tBest epoch: 100 - Best val accuracy: 0.8571 - Best val loss: 0.3025 - Best val F1: 0.8095\n",
      "\n",
      "\tEpoch 10/100 - Train loss: 0.5435 - Val accuracy: 0.7143 - Val loss: 1.0457 - Val F1: 0.5952 - LR: 9.00e-05\n",
      "\tEpoch 20/100 - Train loss: 0.3457 - Val accuracy: 0.1429 - Val loss: 1.1262 - Val F1: 0.0357 - LR: 8.00e-05\n",
      "\tEpoch 30/100 - Train loss: 0.2335 - Val accuracy: 0.1429 - Val loss: 1.3047 - Val F1: 0.0357 - LR: 7.00e-05\n",
      "\tEpoch 40/100 - Train loss: 0.1646 - Val accuracy: 0.1429 - Val loss: 1.3540 - Val F1: 0.0357 - LR: 6.00e-05\n",
      "\tEpoch 50/100 - Train loss: 0.1262 - Val accuracy: 0.7143 - Val loss: 0.8545 - Val F1: 0.7063 - LR: 5.00e-05\n",
      "\tEpoch 60/100 - Train loss: 0.0866 - Val accuracy: 0.8571 - Val loss: 0.4312 - Val F1: 0.8095 - LR: 4.00e-05\n",
      "\tEpoch 70/100 - Train loss: 0.0784 - Val accuracy: 0.8571 - Val loss: 0.3166 - Val F1: 0.8095 - LR: 3.00e-05\n",
      "\tEpoch 80/100 - Train loss: 0.0683 - Val accuracy: 0.8571 - Val loss: 0.2839 - Val F1: 0.8095 - LR: 2.00e-05\n",
      "\tEpoch 90/100 - Train loss: 0.0646 - Val accuracy: 0.8571 - Val loss: 0.2740 - Val F1: 0.8095 - LR: 1.00e-05\n",
      "\tEpoch 100/100 - Train loss: 0.0624 - Val accuracy: 0.8571 - Val loss: 0.2709 - Val F1: 0.8095 - LR: 0.00e+00\n",
      "\tBest epoch: 100 - Best val accuracy: 0.8571 - Best val loss: 0.2709 - Best val F1: 0.8095\n",
      "\n",
      "Source class: WAL | Domain: 37 | Accuracy: 0.8556 | Loss: 0.3321 | F1: 0.8342\n",
      "\n",
      "Domain: 38\n",
      "x_dp_dom.shape: (47, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Training and evaluating on Dp data via cross-validation...\n",
      "\tEpoch 10/100 - Train loss: 0.6464 - Val accuracy: 0.2500 - Val loss: 1.1072 - Val F1: 0.1000 - LR: 9.00e-05\n",
      "\tEpoch 20/100 - Train loss: 0.4014 - Val accuracy: 0.2500 - Val loss: 1.1900 - Val F1: 0.1000 - LR: 8.00e-05\n",
      "\tEpoch 30/100 - Train loss: 0.2426 - Val accuracy: 0.1250 - Val loss: 1.4103 - Val F1: 0.0714 - LR: 7.00e-05\n",
      "\tEpoch 40/100 - Train loss: 0.1508 - Val accuracy: 0.1250 - Val loss: 1.4328 - Val F1: 0.0714 - LR: 6.00e-05\n",
      "\tEpoch 50/100 - Train loss: 0.1096 - Val accuracy: 0.5000 - Val loss: 0.9693 - Val F1: 0.5000 - LR: 5.00e-05\n",
      "\tEpoch 60/100 - Train loss: 0.0822 - Val accuracy: 0.7500 - Val loss: 0.6713 - Val F1: 0.6515 - LR: 4.00e-05\n",
      "\tEpoch 70/100 - Train loss: 0.0717 - Val accuracy: 0.7500 - Val loss: 0.6620 - Val F1: 0.6515 - LR: 3.00e-05\n",
      "\tEpoch 80/100 - Train loss: 0.0573 - Val accuracy: 0.7500 - Val loss: 0.6863 - Val F1: 0.6515 - LR: 2.00e-05\n",
      "\tEpoch 90/100 - Train loss: 0.0577 - Val accuracy: 0.7500 - Val loss: 0.7013 - Val F1: 0.6515 - LR: 1.00e-05\n",
      "\tEpoch 100/100 - Train loss: 0.0541 - Val accuracy: 0.7500 - Val loss: 0.7079 - Val F1: 0.6515 - LR: 0.00e+00\n",
      "\tBest epoch: 65 - Best val accuracy: 0.7500 - Best val loss: 0.6542 - Best val F1: 0.6515\n",
      "\n",
      "\tEpoch 10/100 - Train loss: 0.5674 - Val accuracy: 0.1250 - Val loss: 1.1102 - Val F1: 0.0278 - LR: 9.00e-05\n",
      "\tEpoch 20/100 - Train loss: 0.3432 - Val accuracy: 0.1250 - Val loss: 1.2905 - Val F1: 0.0278 - LR: 8.00e-05\n",
      "\tEpoch 30/100 - Train loss: 0.2393 - Val accuracy: 0.1250 - Val loss: 1.5714 - Val F1: 0.0278 - LR: 7.00e-05\n",
      "\tEpoch 40/100 - Train loss: 0.1859 - Val accuracy: 0.1250 - Val loss: 1.5397 - Val F1: 0.0278 - LR: 6.00e-05\n",
      "\tEpoch 50/100 - Train loss: 0.1516 - Val accuracy: 0.7500 - Val loss: 0.8016 - Val F1: 0.7639 - LR: 5.00e-05\n",
      "\tEpoch 60/100 - Train loss: 0.1095 - Val accuracy: 0.8750 - Val loss: 0.3411 - Val F1: 0.8750 - LR: 4.00e-05\n",
      "\tEpoch 70/100 - Train loss: 0.0917 - Val accuracy: 0.8750 - Val loss: 0.2635 - Val F1: 0.8750 - LR: 3.00e-05\n",
      "\tEpoch 80/100 - Train loss: 0.0839 - Val accuracy: 1.0000 - Val loss: 0.2430 - Val F1: 1.0000 - LR: 2.00e-05\n",
      "\tEpoch 90/100 - Train loss: 0.0802 - Val accuracy: 1.0000 - Val loss: 0.2348 - Val F1: 1.0000 - LR: 1.00e-05\n",
      "\tEpoch 100/100 - Train loss: 0.0744 - Val accuracy: 1.0000 - Val loss: 0.2318 - Val F1: 1.0000 - LR: 0.00e+00\n",
      "\tBest epoch: 100 - Best val accuracy: 1.0000 - Best val loss: 0.2318 - Best val F1: 1.0000\n",
      "\n",
      "\tEpoch 10/100 - Train loss: 0.6912 - Val accuracy: 0.6250 - Val loss: 1.0907 - Val F1: 0.4808 - LR: 9.00e-05\n",
      "\tEpoch 20/100 - Train loss: 0.4471 - Val accuracy: 0.1250 - Val loss: 1.2177 - Val F1: 0.0625 - LR: 8.00e-05\n",
      "\tEpoch 30/100 - Train loss: 0.3220 - Val accuracy: 0.1250 - Val loss: 1.3536 - Val F1: 0.0714 - LR: 7.00e-05\n",
      "\tEpoch 40/100 - Train loss: 0.2345 - Val accuracy: 0.5000 - Val loss: 1.1447 - Val F1: 0.5238 - LR: 6.00e-05\n",
      "\tEpoch 50/100 - Train loss: 0.1962 - Val accuracy: 0.8750 - Val loss: 0.6189 - Val F1: 0.8750 - LR: 5.00e-05\n",
      "\tEpoch 60/100 - Train loss: 0.1532 - Val accuracy: 0.8750 - Val loss: 0.3498 - Val F1: 0.8750 - LR: 4.00e-05\n",
      "\tEpoch 70/100 - Train loss: 0.1364 - Val accuracy: 0.8750 - Val loss: 0.2941 - Val F1: 0.8750 - LR: 3.00e-05\n",
      "\tEpoch 80/100 - Train loss: 0.1168 - Val accuracy: 0.7500 - Val loss: 0.2821 - Val F1: 0.7500 - LR: 2.00e-05\n",
      "\tEpoch 90/100 - Train loss: 0.1054 - Val accuracy: 0.7500 - Val loss: 0.2786 - Val F1: 0.7500 - LR: 1.00e-05\n",
      "\tEpoch 100/100 - Train loss: 0.1111 - Val accuracy: 0.7500 - Val loss: 0.2774 - Val F1: 0.7500 - LR: 0.00e+00\n",
      "\tBest epoch: 100 - Best val accuracy: 0.7500 - Best val loss: 0.2774 - Best val F1: 0.7500\n",
      "\n",
      "\tEpoch 10/100 - Train loss: 0.6974 - Val accuracy: 0.6250 - Val loss: 1.0395 - Val F1: 0.4808 - LR: 9.00e-05\n",
      "\tEpoch 20/100 - Train loss: 0.4900 - Val accuracy: 0.6250 - Val loss: 1.0352 - Val F1: 0.4808 - LR: 8.00e-05\n",
      "\tEpoch 30/100 - Train loss: 0.3304 - Val accuracy: 0.3750 - Val loss: 1.0934 - Val F1: 0.3194 - LR: 7.00e-05\n",
      "\tEpoch 40/100 - Train loss: 0.2276 - Val accuracy: 0.5000 - Val loss: 1.0307 - Val F1: 0.4821 - LR: 6.00e-05\n",
      "\tEpoch 50/100 - Train loss: 0.1634 - Val accuracy: 0.6250 - Val loss: 0.7085 - Val F1: 0.6116 - LR: 5.00e-05\n",
      "\tEpoch 60/100 - Train loss: 0.1330 - Val accuracy: 0.8750 - Val loss: 0.4028 - Val F1: 0.8250 - LR: 4.00e-05\n",
      "\tEpoch 70/100 - Train loss: 0.1081 - Val accuracy: 0.8750 - Val loss: 0.2868 - Val F1: 0.8250 - LR: 3.00e-05\n",
      "\tEpoch 80/100 - Train loss: 0.0827 - Val accuracy: 0.8750 - Val loss: 0.2535 - Val F1: 0.8250 - LR: 2.00e-05\n",
      "\tEpoch 90/100 - Train loss: 0.0889 - Val accuracy: 0.8750 - Val loss: 0.2422 - Val F1: 0.8250 - LR: 1.00e-05\n",
      "\tEpoch 100/100 - Train loss: 0.0841 - Val accuracy: 0.8750 - Val loss: 0.2388 - Val F1: 0.8250 - LR: 0.00e+00\n",
      "\tBest epoch: 100 - Best val accuracy: 0.8750 - Best val loss: 0.2388 - Best val F1: 0.8250\n",
      "\n",
      "\tEpoch 10/100 - Train loss: 0.5680 - Val accuracy: 0.3750 - Val loss: 1.0944 - Val F1: 0.3929 - LR: 9.00e-05\n",
      "\tEpoch 20/100 - Train loss: 0.3535 - Val accuracy: 0.2500 - Val loss: 1.1987 - Val F1: 0.1000 - LR: 8.00e-05\n",
      "\tEpoch 30/100 - Train loss: 0.2542 - Val accuracy: 0.2500 - Val loss: 1.4137 - Val F1: 0.1000 - LR: 7.00e-05\n",
      "\tEpoch 40/100 - Train loss: 0.1996 - Val accuracy: 0.2500 - Val loss: 1.4022 - Val F1: 0.1000 - LR: 6.00e-05\n",
      "\tEpoch 50/100 - Train loss: 0.1488 - Val accuracy: 0.8750 - Val loss: 0.7036 - Val F1: 0.8806 - LR: 5.00e-05\n",
      "\tEpoch 60/100 - Train loss: 0.1198 - Val accuracy: 1.0000 - Val loss: 0.2805 - Val F1: 1.0000 - LR: 4.00e-05\n",
      "\tEpoch 70/100 - Train loss: 0.1023 - Val accuracy: 1.0000 - Val loss: 0.1997 - Val F1: 1.0000 - LR: 3.00e-05\n",
      "\tEpoch 80/100 - Train loss: 0.0888 - Val accuracy: 1.0000 - Val loss: 0.1806 - Val F1: 1.0000 - LR: 2.00e-05\n",
      "\tEpoch 90/100 - Train loss: 0.0937 - Val accuracy: 1.0000 - Val loss: 0.1738 - Val F1: 1.0000 - LR: 1.00e-05\n",
      "\tEpoch 100/100 - Train loss: 0.0797 - Val accuracy: 1.0000 - Val loss: 0.1713 - Val F1: 1.0000 - LR: 0.00e+00\n",
      "\tBest epoch: 100 - Best val accuracy: 1.0000 - Best val loss: 0.1713 - Best val F1: 1.0000\n",
      "\n",
      "Source class: WAL | Domain: 38 | Accuracy: 0.8133 | Loss: 0.4594 | F1: 0.7730\n",
      "\n",
      "Domain: 39\n",
      "x_dp_dom.shape: (54, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Training and evaluating on Dp data via cross-validation...\n",
      "\tEpoch 10/100 - Train loss: 0.5598 - Val accuracy: 0.5556 - Val loss: 1.0671 - Val F1: 0.3968 - LR: 9.00e-05\n",
      "\tEpoch 20/100 - Train loss: 0.3293 - Val accuracy: 0.2222 - Val loss: 1.0866 - Val F1: 0.0808 - LR: 8.00e-05\n",
      "\tEpoch 30/100 - Train loss: 0.1801 - Val accuracy: 0.4444 - Val loss: 1.0990 - Val F1: 0.2751 - LR: 7.00e-05\n",
      "\tEpoch 40/100 - Train loss: 0.1101 - Val accuracy: 0.4444 - Val loss: 0.8872 - Val F1: 0.2751 - LR: 6.00e-05\n",
      "\tEpoch 50/100 - Train loss: 0.0703 - Val accuracy: 0.8889 - Val loss: 0.4868 - Val F1: 0.8938 - LR: 5.00e-05\n",
      "\tEpoch 60/100 - Train loss: 0.0551 - Val accuracy: 0.8889 - Val loss: 0.2633 - Val F1: 0.8938 - LR: 4.00e-05\n",
      "\tEpoch 70/100 - Train loss: 0.0433 - Val accuracy: 0.8889 - Val loss: 0.1925 - Val F1: 0.8938 - LR: 3.00e-05\n",
      "\tEpoch 80/100 - Train loss: 0.0379 - Val accuracy: 0.8889 - Val loss: 0.1678 - Val F1: 0.8938 - LR: 2.00e-05\n",
      "\tEpoch 90/100 - Train loss: 0.0351 - Val accuracy: 0.8889 - Val loss: 0.1583 - Val F1: 0.8938 - LR: 1.00e-05\n",
      "\tEpoch 100/100 - Train loss: 0.0340 - Val accuracy: 0.8889 - Val loss: 0.1553 - Val F1: 0.8938 - LR: 0.00e+00\n",
      "\tBest epoch: 100 - Best val accuracy: 0.8889 - Best val loss: 0.1553 - Best val F1: 0.8938\n",
      "\n",
      "\tEpoch 10/100 - Train loss: 0.5326 - Val accuracy: 0.2222 - Val loss: 1.0876 - Val F1: 0.0808 - LR: 9.00e-05\n",
      "\tEpoch 20/100 - Train loss: 0.2568 - Val accuracy: 0.4444 - Val loss: 1.0785 - Val F1: 0.2751 - LR: 8.00e-05\n",
      "\tEpoch 30/100 - Train loss: 0.1293 - Val accuracy: 0.4444 - Val loss: 1.0144 - Val F1: 0.2751 - LR: 7.00e-05\n",
      "\tEpoch 40/100 - Train loss: 0.0776 - Val accuracy: 0.5556 - Val loss: 0.6586 - Val F1: 0.4899 - LR: 6.00e-05\n",
      "\tEpoch 50/100 - Train loss: 0.0529 - Val accuracy: 1.0000 - Val loss: 0.2025 - Val F1: 1.0000 - LR: 5.00e-05\n",
      "\tEpoch 60/100 - Train loss: 0.0399 - Val accuracy: 1.0000 - Val loss: 0.0758 - Val F1: 1.0000 - LR: 4.00e-05\n",
      "\tEpoch 70/100 - Train loss: 0.0320 - Val accuracy: 1.0000 - Val loss: 0.0479 - Val F1: 1.0000 - LR: 3.00e-05\n",
      "\tEpoch 80/100 - Train loss: 0.0291 - Val accuracy: 1.0000 - Val loss: 0.0387 - Val F1: 1.0000 - LR: 2.00e-05\n",
      "\tEpoch 90/100 - Train loss: 0.0282 - Val accuracy: 1.0000 - Val loss: 0.0349 - Val F1: 1.0000 - LR: 1.00e-05\n",
      "\tEpoch 100/100 - Train loss: 0.0258 - Val accuracy: 1.0000 - Val loss: 0.0336 - Val F1: 1.0000 - LR: 0.00e+00\n",
      "\tBest epoch: 100 - Best val accuracy: 1.0000 - Best val loss: 0.0336 - Best val F1: 1.0000\n",
      "\n",
      "\tEpoch 10/100 - Train loss: 0.5833 - Val accuracy: 0.3333 - Val loss: 1.0941 - Val F1: 0.2741 - LR: 9.00e-05\n",
      "\tEpoch 20/100 - Train loss: 0.3057 - Val accuracy: 0.4444 - Val loss: 1.1282 - Val F1: 0.2751 - LR: 8.00e-05\n",
      "\tEpoch 30/100 - Train loss: 0.1674 - Val accuracy: 0.4444 - Val loss: 1.1157 - Val F1: 0.2751 - LR: 7.00e-05\n",
      "\tEpoch 40/100 - Train loss: 0.1007 - Val accuracy: 0.4444 - Val loss: 0.9174 - Val F1: 0.2751 - LR: 6.00e-05\n",
      "\tEpoch 50/100 - Train loss: 0.0688 - Val accuracy: 0.7778 - Val loss: 0.4524 - Val F1: 0.7870 - LR: 5.00e-05\n",
      "\tEpoch 60/100 - Train loss: 0.0496 - Val accuracy: 1.0000 - Val loss: 0.1379 - Val F1: 1.0000 - LR: 4.00e-05\n",
      "\tEpoch 70/100 - Train loss: 0.0410 - Val accuracy: 1.0000 - Val loss: 0.0606 - Val F1: 1.0000 - LR: 3.00e-05\n",
      "\tEpoch 80/100 - Train loss: 0.0380 - Val accuracy: 1.0000 - Val loss: 0.0422 - Val F1: 1.0000 - LR: 2.00e-05\n",
      "\tEpoch 90/100 - Train loss: 0.0327 - Val accuracy: 1.0000 - Val loss: 0.0362 - Val F1: 1.0000 - LR: 1.00e-05\n",
      "\tEpoch 100/100 - Train loss: 0.0307 - Val accuracy: 1.0000 - Val loss: 0.0341 - Val F1: 1.0000 - LR: 0.00e+00\n",
      "\tBest epoch: 100 - Best val accuracy: 1.0000 - Best val loss: 0.0341 - Best val F1: 1.0000\n",
      "\n",
      "\tEpoch 10/100 - Train loss: 0.5827 - Val accuracy: 0.2222 - Val loss: 1.1235 - Val F1: 0.0808 - LR: 9.00e-05\n",
      "\tEpoch 20/100 - Train loss: 0.3032 - Val accuracy: 0.2222 - Val loss: 1.1918 - Val F1: 0.0808 - LR: 8.00e-05\n",
      "\tEpoch 30/100 - Train loss: 0.1738 - Val accuracy: 0.3333 - Val loss: 1.2636 - Val F1: 0.2099 - LR: 7.00e-05\n",
      "\tEpoch 40/100 - Train loss: 0.1073 - Val accuracy: 0.4444 - Val loss: 1.1251 - Val F1: 0.2889 - LR: 6.00e-05\n",
      "\tEpoch 50/100 - Train loss: 0.0688 - Val accuracy: 0.7778 - Val loss: 0.4727 - Val F1: 0.7870 - LR: 5.00e-05\n",
      "\tEpoch 60/100 - Train loss: 0.0545 - Val accuracy: 1.0000 - Val loss: 0.1222 - Val F1: 1.0000 - LR: 4.00e-05\n",
      "\tEpoch 70/100 - Train loss: 0.0470 - Val accuracy: 1.0000 - Val loss: 0.0633 - Val F1: 1.0000 - LR: 3.00e-05\n",
      "\tEpoch 80/100 - Train loss: 0.0386 - Val accuracy: 1.0000 - Val loss: 0.0484 - Val F1: 1.0000 - LR: 2.00e-05\n",
      "\tEpoch 90/100 - Train loss: 0.0342 - Val accuracy: 1.0000 - Val loss: 0.0429 - Val F1: 1.0000 - LR: 1.00e-05\n",
      "\tEpoch 100/100 - Train loss: 0.0380 - Val accuracy: 1.0000 - Val loss: 0.0409 - Val F1: 1.0000 - LR: 0.00e+00\n",
      "\tBest epoch: 100 - Best val accuracy: 1.0000 - Best val loss: 0.0409 - Best val F1: 1.0000\n",
      "\n",
      "\tEpoch 10/100 - Train loss: 0.5470 - Val accuracy: 0.2222 - Val loss: 1.1105 - Val F1: 0.0808 - LR: 9.00e-05\n",
      "\tEpoch 20/100 - Train loss: 0.3085 - Val accuracy: 0.2222 - Val loss: 1.1194 - Val F1: 0.1111 - LR: 8.00e-05\n",
      "\tEpoch 30/100 - Train loss: 0.1906 - Val accuracy: 0.4444 - Val loss: 1.1165 - Val F1: 0.2751 - LR: 7.00e-05\n",
      "\tEpoch 40/100 - Train loss: 0.1259 - Val accuracy: 0.4444 - Val loss: 0.8975 - Val F1: 0.2751 - LR: 6.00e-05\n",
      "\tEpoch 50/100 - Train loss: 0.0844 - Val accuracy: 0.8889 - Val loss: 0.4624 - Val F1: 0.8938 - LR: 5.00e-05\n",
      "\tEpoch 60/100 - Train loss: 0.0667 - Val accuracy: 0.8889 - Val loss: 0.2375 - Val F1: 0.8938 - LR: 4.00e-05\n",
      "\tEpoch 70/100 - Train loss: 0.0539 - Val accuracy: 0.8889 - Val loss: 0.1630 - Val F1: 0.8938 - LR: 3.00e-05\n",
      "\tEpoch 80/100 - Train loss: 0.0464 - Val accuracy: 0.8889 - Val loss: 0.1354 - Val F1: 0.8938 - LR: 2.00e-05\n",
      "\tEpoch 90/100 - Train loss: 0.0440 - Val accuracy: 0.8889 - Val loss: 0.1240 - Val F1: 0.8938 - LR: 1.00e-05\n",
      "\tEpoch 100/100 - Train loss: 0.0425 - Val accuracy: 0.8889 - Val loss: 0.1199 - Val F1: 0.8938 - LR: 0.00e+00\n",
      "\tBest epoch: 100 - Best val accuracy: 0.8889 - Best val loss: 0.1199 - Best val F1: 0.8938\n",
      "\n",
      "Source class: WAL | Domain: 39 | Accuracy: 0.9636 | Loss: 0.0823 | F1: 0.9649\n",
      "\n",
      "Domain: 40\n",
      "x_dp_dom.shape: (44, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Training and evaluating on Dp data via cross-validation...\n",
      "\tEpoch 10/100 - Train loss: 0.5893 - Val accuracy: 0.2857 - Val loss: 1.0942 - Val F1: 0.1270 - LR: 9.00e-05\n",
      "\tEpoch 20/100 - Train loss: 0.3811 - Val accuracy: 0.2857 - Val loss: 1.1464 - Val F1: 0.1270 - LR: 8.00e-05\n",
      "\tEpoch 30/100 - Train loss: 0.2613 - Val accuracy: 0.2857 - Val loss: 1.3014 - Val F1: 0.1270 - LR: 7.00e-05\n",
      "\tEpoch 40/100 - Train loss: 0.1932 - Val accuracy: 0.2857 - Val loss: 1.4061 - Val F1: 0.1270 - LR: 6.00e-05\n",
      "\tEpoch 50/100 - Train loss: 0.1450 - Val accuracy: 0.2857 - Val loss: 1.1632 - Val F1: 0.1633 - LR: 5.00e-05\n",
      "\tEpoch 60/100 - Train loss: 0.1182 - Val accuracy: 1.0000 - Val loss: 0.5775 - Val F1: 1.0000 - LR: 4.00e-05\n",
      "\tEpoch 70/100 - Train loss: 0.0967 - Val accuracy: 1.0000 - Val loss: 0.3957 - Val F1: 1.0000 - LR: 3.00e-05\n",
      "\tEpoch 80/100 - Train loss: 0.0862 - Val accuracy: 1.0000 - Val loss: 0.3780 - Val F1: 1.0000 - LR: 2.00e-05\n",
      "\tEpoch 90/100 - Train loss: 0.0764 - Val accuracy: 0.8571 - Val loss: 0.3818 - Val F1: 0.8413 - LR: 1.00e-05\n",
      "\tEpoch 100/100 - Train loss: 0.0801 - Val accuracy: 0.8571 - Val loss: 0.3861 - Val F1: 0.8413 - LR: 0.00e+00\n",
      "\tBest epoch: 79 - Best val accuracy: 1.0000 - Best val loss: 0.3779 - Best val F1: 1.0000\n",
      "\n",
      "\tEpoch 10/100 - Train loss: 0.5219 - Val accuracy: 0.5714 - Val loss: 1.0699 - Val F1: 0.4156 - LR: 9.00e-05\n",
      "\tEpoch 20/100 - Train loss: 0.3562 - Val accuracy: 0.2857 - Val loss: 1.1142 - Val F1: 0.1270 - LR: 8.00e-05\n",
      "\tEpoch 30/100 - Train loss: 0.2458 - Val accuracy: 0.2857 - Val loss: 1.2238 - Val F1: 0.1270 - LR: 7.00e-05\n",
      "\tEpoch 40/100 - Train loss: 0.1851 - Val accuracy: 0.4286 - Val loss: 1.1452 - Val F1: 0.3714 - LR: 6.00e-05\n",
      "\tEpoch 50/100 - Train loss: 0.1354 - Val accuracy: 0.8571 - Val loss: 0.6788 - Val F1: 0.8000 - LR: 5.00e-05\n",
      "\tEpoch 60/100 - Train loss: 0.1152 - Val accuracy: 0.8571 - Val loss: 0.3630 - Val F1: 0.8000 - LR: 4.00e-05\n",
      "\tEpoch 70/100 - Train loss: 0.0967 - Val accuracy: 0.8571 - Val loss: 0.3162 - Val F1: 0.8000 - LR: 3.00e-05\n",
      "\tEpoch 80/100 - Train loss: 0.0861 - Val accuracy: 0.8571 - Val loss: 0.3107 - Val F1: 0.8000 - LR: 2.00e-05\n",
      "\tEpoch 90/100 - Train loss: 0.0771 - Val accuracy: 0.8571 - Val loss: 0.3093 - Val F1: 0.8000 - LR: 1.00e-05\n",
      "\tEpoch 100/100 - Train loss: 0.0686 - Val accuracy: 0.8571 - Val loss: 0.3092 - Val F1: 0.8000 - LR: 0.00e+00\n",
      "\tBest epoch: 96 - Best val accuracy: 0.8571 - Best val loss: 0.3090 - Best val F1: 0.8000\n",
      "\n",
      "\tEpoch 10/100 - Train loss: 0.6726 - Val accuracy: 0.5714 - Val loss: 1.0729 - Val F1: 0.4156 - LR: 9.00e-05\n",
      "\tEpoch 20/100 - Train loss: 0.4435 - Val accuracy: 0.1429 - Val loss: 1.0929 - Val F1: 0.0357 - LR: 8.00e-05\n",
      "\tEpoch 30/100 - Train loss: 0.2989 - Val accuracy: 0.1429 - Val loss: 1.1789 - Val F1: 0.0357 - LR: 7.00e-05\n",
      "\tEpoch 40/100 - Train loss: 0.2039 - Val accuracy: 0.2857 - Val loss: 1.1409 - Val F1: 0.2313 - LR: 6.00e-05\n",
      "\tEpoch 50/100 - Train loss: 0.1497 - Val accuracy: 1.0000 - Val loss: 0.6913 - Val F1: 1.0000 - LR: 5.00e-05\n",
      "\tEpoch 60/100 - Train loss: 0.1182 - Val accuracy: 0.8571 - Val loss: 0.3846 - Val F1: 0.8000 - LR: 4.00e-05\n",
      "\tEpoch 70/100 - Train loss: 0.0941 - Val accuracy: 0.8571 - Val loss: 0.3239 - Val F1: 0.8000 - LR: 3.00e-05\n",
      "\tEpoch 80/100 - Train loss: 0.0810 - Val accuracy: 0.8571 - Val loss: 0.3178 - Val F1: 0.8000 - LR: 2.00e-05\n",
      "\tEpoch 90/100 - Train loss: 0.0814 - Val accuracy: 0.8571 - Val loss: 0.3182 - Val F1: 0.8000 - LR: 1.00e-05\n",
      "\tEpoch 100/100 - Train loss: 0.0760 - Val accuracy: 0.8571 - Val loss: 0.3195 - Val F1: 0.8000 - LR: 0.00e+00\n",
      "\tBest epoch: 80 - Best val accuracy: 0.8571 - Best val loss: 0.3178 - Best val F1: 0.8000\n",
      "\n",
      "\tEpoch 10/100 - Train loss: 0.6482 - Val accuracy: 0.7143 - Val loss: 1.0378 - Val F1: 0.5952 - LR: 9.00e-05\n",
      "\tEpoch 20/100 - Train loss: 0.3942 - Val accuracy: 0.7143 - Val loss: 1.0663 - Val F1: 0.5952 - LR: 8.00e-05\n",
      "\tEpoch 30/100 - Train loss: 0.2646 - Val accuracy: 0.1429 - Val loss: 1.2048 - Val F1: 0.0476 - LR: 7.00e-05\n",
      "\tEpoch 40/100 - Train loss: 0.1713 - Val accuracy: 0.2857 - Val loss: 1.1080 - Val F1: 0.2952 - LR: 6.00e-05\n",
      "\tEpoch 50/100 - Train loss: 0.1250 - Val accuracy: 0.8571 - Val loss: 0.5772 - Val F1: 0.8095 - LR: 5.00e-05\n",
      "\tEpoch 60/100 - Train loss: 0.1000 - Val accuracy: 0.8571 - Val loss: 0.2976 - Val F1: 0.8095 - LR: 4.00e-05\n",
      "\tEpoch 70/100 - Train loss: 0.0868 - Val accuracy: 0.8571 - Val loss: 0.2438 - Val F1: 0.8095 - LR: 3.00e-05\n",
      "\tEpoch 80/100 - Train loss: 0.0718 - Val accuracy: 0.8571 - Val loss: 0.2349 - Val F1: 0.8095 - LR: 2.00e-05\n",
      "\tEpoch 90/100 - Train loss: 0.0643 - Val accuracy: 0.8571 - Val loss: 0.2339 - Val F1: 0.8095 - LR: 1.00e-05\n",
      "\tEpoch 100/100 - Train loss: 0.0622 - Val accuracy: 0.8571 - Val loss: 0.2342 - Val F1: 0.8095 - LR: 0.00e+00\n",
      "\tBest epoch: 91 - Best val accuracy: 0.8571 - Best val loss: 0.2339 - Best val F1: 0.8095\n",
      "\n",
      "\tEpoch 10/100 - Train loss: 0.5643 - Val accuracy: 0.2500 - Val loss: 1.0955 - Val F1: 0.1000 - LR: 9.00e-05\n",
      "\tEpoch 20/100 - Train loss: 0.3294 - Val accuracy: 0.2500 - Val loss: 1.2118 - Val F1: 0.1000 - LR: 8.00e-05\n",
      "\tEpoch 30/100 - Train loss: 0.2261 - Val accuracy: 0.2500 - Val loss: 1.3780 - Val F1: 0.1000 - LR: 7.00e-05\n",
      "\tEpoch 40/100 - Train loss: 0.1712 - Val accuracy: 0.2500 - Val loss: 1.3201 - Val F1: 0.1000 - LR: 6.00e-05\n",
      "\tEpoch 50/100 - Train loss: 0.1270 - Val accuracy: 1.0000 - Val loss: 0.5780 - Val F1: 1.0000 - LR: 5.00e-05\n",
      "\tEpoch 60/100 - Train loss: 0.0938 - Val accuracy: 1.0000 - Val loss: 0.2737 - Val F1: 1.0000 - LR: 4.00e-05\n",
      "\tEpoch 70/100 - Train loss: 0.0884 - Val accuracy: 1.0000 - Val loss: 0.2264 - Val F1: 1.0000 - LR: 3.00e-05\n",
      "\tEpoch 80/100 - Train loss: 0.0671 - Val accuracy: 1.0000 - Val loss: 0.2123 - Val F1: 1.0000 - LR: 2.00e-05\n",
      "\tEpoch 90/100 - Train loss: 0.0651 - Val accuracy: 1.0000 - Val loss: 0.2052 - Val F1: 1.0000 - LR: 1.00e-05\n",
      "\tEpoch 100/100 - Train loss: 0.0697 - Val accuracy: 1.0000 - Val loss: 0.2028 - Val F1: 1.0000 - LR: 0.00e+00\n",
      "\tBest epoch: 100 - Best val accuracy: 1.0000 - Best val loss: 0.2028 - Best val F1: 1.0000\n",
      "\n",
      "Source class: WAL | Domain: 40 | Accuracy: 0.8861 | Loss: 0.2770 | F1: 0.8729\n",
      "\n",
      "Domain: 41\n",
      "x_dp_dom.shape: (45, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Training and evaluating on Dp data via cross-validation...\n",
      "\tEpoch 10/100 - Train loss: 0.6976 - Val accuracy: 0.6250 - Val loss: 1.0550 - Val F1: 0.4808 - LR: 9.00e-05\n",
      "\tEpoch 20/100 - Train loss: 0.4083 - Val accuracy: 0.6250 - Val loss: 1.0285 - Val F1: 0.5208 - LR: 8.00e-05\n",
      "\tEpoch 30/100 - Train loss: 0.2600 - Val accuracy: 0.8750 - Val loss: 1.0260 - Val F1: 0.8598 - LR: 7.00e-05\n",
      "\tEpoch 40/100 - Train loss: 0.1667 - Val accuracy: 0.8750 - Val loss: 0.9453 - Val F1: 0.8598 - LR: 6.00e-05\n",
      "\tEpoch 50/100 - Train loss: 0.1271 - Val accuracy: 0.7500 - Val loss: 0.6754 - Val F1: 0.6932 - LR: 5.00e-05\n",
      "\tEpoch 60/100 - Train loss: 0.0913 - Val accuracy: 0.6250 - Val loss: 0.5860 - Val F1: 0.5208 - LR: 4.00e-05\n",
      "\tEpoch 70/100 - Train loss: 0.0686 - Val accuracy: 0.6250 - Val loss: 0.6163 - Val F1: 0.5208 - LR: 3.00e-05\n",
      "\tEpoch 80/100 - Train loss: 0.0580 - Val accuracy: 0.6250 - Val loss: 0.6535 - Val F1: 0.5208 - LR: 2.00e-05\n",
      "\tEpoch 90/100 - Train loss: 0.0569 - Val accuracy: 0.6250 - Val loss: 0.6746 - Val F1: 0.5208 - LR: 1.00e-05\n",
      "\tEpoch 100/100 - Train loss: 0.0563 - Val accuracy: 0.6250 - Val loss: 0.6835 - Val F1: 0.5208 - LR: 0.00e+00\n",
      "\tBest epoch: 60 - Best val accuracy: 0.6250 - Best val loss: 0.5860 - Best val F1: 0.5208\n",
      "\n",
      "\tEpoch 10/100 - Train loss: 0.6340 - Val accuracy: 0.6250 - Val loss: 1.0746 - Val F1: 0.4808 - LR: 9.00e-05\n",
      "\tEpoch 20/100 - Train loss: 0.3690 - Val accuracy: 0.6250 - Val loss: 0.9897 - Val F1: 0.4808 - LR: 8.00e-05\n",
      "\tEpoch 30/100 - Train loss: 0.2226 - Val accuracy: 0.6250 - Val loss: 0.8611 - Val F1: 0.5208 - LR: 7.00e-05\n",
      "\tEpoch 40/100 - Train loss: 0.1587 - Val accuracy: 0.8750 - Val loss: 0.6078 - Val F1: 0.8250 - LR: 6.00e-05\n",
      "\tEpoch 50/100 - Train loss: 0.1062 - Val accuracy: 0.8750 - Val loss: 0.4006 - Val F1: 0.8250 - LR: 5.00e-05\n",
      "\tEpoch 60/100 - Train loss: 0.0840 - Val accuracy: 0.8750 - Val loss: 0.3222 - Val F1: 0.8250 - LR: 4.00e-05\n",
      "\tEpoch 70/100 - Train loss: 0.0671 - Val accuracy: 0.8750 - Val loss: 0.2989 - Val F1: 0.8250 - LR: 3.00e-05\n",
      "\tEpoch 80/100 - Train loss: 0.0594 - Val accuracy: 0.8750 - Val loss: 0.2895 - Val F1: 0.8250 - LR: 2.00e-05\n",
      "\tEpoch 90/100 - Train loss: 0.0579 - Val accuracy: 0.8750 - Val loss: 0.2855 - Val F1: 0.8250 - LR: 1.00e-05\n",
      "\tEpoch 100/100 - Train loss: 0.0625 - Val accuracy: 0.8750 - Val loss: 0.2843 - Val F1: 0.8250 - LR: 0.00e+00\n",
      "\tBest epoch: 100 - Best val accuracy: 0.8750 - Best val loss: 0.2843 - Best val F1: 0.8250\n",
      "\n",
      "\tEpoch 10/100 - Train loss: 0.5466 - Val accuracy: 0.6250 - Val loss: 1.0288 - Val F1: 0.4808 - LR: 9.00e-05\n",
      "\tEpoch 20/100 - Train loss: 0.2993 - Val accuracy: 0.6250 - Val loss: 0.9267 - Val F1: 0.4808 - LR: 8.00e-05\n",
      "\tEpoch 30/100 - Train loss: 0.2071 - Val accuracy: 0.6250 - Val loss: 0.7796 - Val F1: 0.4808 - LR: 7.00e-05\n",
      "\tEpoch 40/100 - Train loss: 0.1278 - Val accuracy: 0.7500 - Val loss: 0.5775 - Val F1: 0.6932 - LR: 6.00e-05\n",
      "\tEpoch 50/100 - Train loss: 0.1039 - Val accuracy: 0.7500 - Val loss: 0.4359 - Val F1: 0.6932 - LR: 5.00e-05\n",
      "\tEpoch 60/100 - Train loss: 0.0760 - Val accuracy: 0.8750 - Val loss: 0.3861 - Val F1: 0.8250 - LR: 4.00e-05\n",
      "\tEpoch 70/100 - Train loss: 0.0561 - Val accuracy: 0.8750 - Val loss: 0.3836 - Val F1: 0.8250 - LR: 3.00e-05\n",
      "\tEpoch 80/100 - Train loss: 0.0568 - Val accuracy: 0.8750 - Val loss: 0.3888 - Val F1: 0.8250 - LR: 2.00e-05\n",
      "\tEpoch 90/100 - Train loss: 0.0541 - Val accuracy: 0.8750 - Val loss: 0.3912 - Val F1: 0.8250 - LR: 1.00e-05\n",
      "\tEpoch 100/100 - Train loss: 0.0468 - Val accuracy: 0.8750 - Val loss: 0.3923 - Val F1: 0.8250 - LR: 0.00e+00\n",
      "\tBest epoch: 66 - Best val accuracy: 0.8750 - Best val loss: 0.3825 - Best val F1: 0.8250\n",
      "\n",
      "\tEpoch 10/100 - Train loss: 0.6596 - Val accuracy: 0.6250 - Val loss: 1.0552 - Val F1: 0.4808 - LR: 9.00e-05\n",
      "\tEpoch 20/100 - Train loss: 0.3945 - Val accuracy: 0.6250 - Val loss: 0.9823 - Val F1: 0.4808 - LR: 8.00e-05\n",
      "\tEpoch 30/100 - Train loss: 0.2604 - Val accuracy: 0.7500 - Val loss: 0.8783 - Val F1: 0.6875 - LR: 7.00e-05\n",
      "\tEpoch 40/100 - Train loss: 0.1774 - Val accuracy: 0.8750 - Val loss: 0.6358 - Val F1: 0.8598 - LR: 6.00e-05\n",
      "\tEpoch 50/100 - Train loss: 0.1348 - Val accuracy: 0.8750 - Val loss: 0.4481 - Val F1: 0.8598 - LR: 5.00e-05\n",
      "\tEpoch 60/100 - Train loss: 0.0950 - Val accuracy: 0.8750 - Val loss: 0.3756 - Val F1: 0.8598 - LR: 4.00e-05\n",
      "\tEpoch 70/100 - Train loss: 0.0808 - Val accuracy: 0.8750 - Val loss: 0.3521 - Val F1: 0.8598 - LR: 3.00e-05\n",
      "\tEpoch 80/100 - Train loss: 0.0705 - Val accuracy: 0.8750 - Val loss: 0.3423 - Val F1: 0.8598 - LR: 2.00e-05\n",
      "\tEpoch 90/100 - Train loss: 0.0667 - Val accuracy: 0.8750 - Val loss: 0.3376 - Val F1: 0.8598 - LR: 1.00e-05\n",
      "\tEpoch 100/100 - Train loss: 0.0615 - Val accuracy: 0.8750 - Val loss: 0.3356 - Val F1: 0.8598 - LR: 0.00e+00\n",
      "\tBest epoch: 100 - Best val accuracy: 0.8750 - Best val loss: 0.3356 - Best val F1: 0.8598\n",
      "\n",
      "\tEpoch 10/100 - Train loss: 0.5886 - Val accuracy: 0.6250 - Val loss: 1.0515 - Val F1: 0.4808 - LR: 9.00e-05\n",
      "\tEpoch 20/100 - Train loss: 0.3149 - Val accuracy: 0.1250 - Val loss: 1.0504 - Val F1: 0.0625 - LR: 8.00e-05\n",
      "\tEpoch 30/100 - Train loss: 0.1710 - Val accuracy: 0.2500 - Val loss: 1.0940 - Val F1: 0.1000 - LR: 7.00e-05\n",
      "\tEpoch 40/100 - Train loss: 0.1005 - Val accuracy: 0.1250 - Val loss: 0.9823 - Val F1: 0.0556 - LR: 6.00e-05\n",
      "\tEpoch 50/100 - Train loss: 0.0665 - Val accuracy: 0.8750 - Val loss: 0.7020 - Val F1: 0.8750 - LR: 5.00e-05\n",
      "\tEpoch 60/100 - Train loss: 0.0520 - Val accuracy: 0.8750 - Val loss: 0.5595 - Val F1: 0.8750 - LR: 4.00e-05\n",
      "\tEpoch 70/100 - Train loss: 0.0384 - Val accuracy: 0.8750 - Val loss: 0.5540 - Val F1: 0.8750 - LR: 3.00e-05\n",
      "\tEpoch 80/100 - Train loss: 0.0351 - Val accuracy: 0.8750 - Val loss: 0.5665 - Val F1: 0.8750 - LR: 2.00e-05\n",
      "\tEpoch 90/100 - Train loss: 0.0358 - Val accuracy: 0.8750 - Val loss: 0.5733 - Val F1: 0.8750 - LR: 1.00e-05\n",
      "\tEpoch 100/100 - Train loss: 0.0337 - Val accuracy: 0.8750 - Val loss: 0.5762 - Val F1: 0.8750 - LR: 0.00e+00\n",
      "\tBest epoch: 66 - Best val accuracy: 0.8750 - Best val loss: 0.5505 - Best val F1: 0.8750\n",
      "\n",
      "Source class: WAL | Domain: 41 | Accuracy: 0.8444 | Loss: 0.4516 | F1: 0.8270\n",
      "\n",
      "Domain: 42\n",
      "x_dp_dom.shape: (46, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Training and evaluating on Dp data via cross-validation...\n",
      "\tEpoch 10/100 - Train loss: 0.6075 - Val accuracy: 0.6250 - Val loss: 1.0726 - Val F1: 0.4808 - LR: 9.00e-05\n",
      "\tEpoch 20/100 - Train loss: 0.3662 - Val accuracy: 0.2500 - Val loss: 1.1370 - Val F1: 0.1000 - LR: 8.00e-05\n",
      "\tEpoch 30/100 - Train loss: 0.2693 - Val accuracy: 0.2500 - Val loss: 1.3136 - Val F1: 0.1000 - LR: 7.00e-05\n",
      "\tEpoch 40/100 - Train loss: 0.1817 - Val accuracy: 0.3750 - Val loss: 1.3172 - Val F1: 0.2083 - LR: 6.00e-05\n",
      "\tEpoch 50/100 - Train loss: 0.1344 - Val accuracy: 0.7500 - Val loss: 0.7951 - Val F1: 0.7521 - LR: 5.00e-05\n",
      "\tEpoch 60/100 - Train loss: 0.0949 - Val accuracy: 1.0000 - Val loss: 0.3675 - Val F1: 1.0000 - LR: 4.00e-05\n",
      "\tEpoch 70/100 - Train loss: 0.0986 - Val accuracy: 1.0000 - Val loss: 0.2414 - Val F1: 1.0000 - LR: 3.00e-05\n",
      "\tEpoch 80/100 - Train loss: 0.0781 - Val accuracy: 1.0000 - Val loss: 0.2032 - Val F1: 1.0000 - LR: 2.00e-05\n",
      "\tEpoch 90/100 - Train loss: 0.0714 - Val accuracy: 1.0000 - Val loss: 0.1886 - Val F1: 1.0000 - LR: 1.00e-05\n",
      "\tEpoch 100/100 - Train loss: 0.0617 - Val accuracy: 1.0000 - Val loss: 0.1828 - Val F1: 1.0000 - LR: 0.00e+00\n",
      "\tBest epoch: 100 - Best val accuracy: 1.0000 - Best val loss: 0.1828 - Best val F1: 1.0000\n",
      "\n",
      "\tEpoch 10/100 - Train loss: 0.6626 - Val accuracy: 0.6250 - Val loss: 1.0720 - Val F1: 0.4808 - LR: 9.00e-05\n",
      "\tEpoch 20/100 - Train loss: 0.4041 - Val accuracy: 0.2500 - Val loss: 1.1761 - Val F1: 0.1000 - LR: 8.00e-05\n",
      "\tEpoch 30/100 - Train loss: 0.2668 - Val accuracy: 0.2500 - Val loss: 1.3835 - Val F1: 0.1000 - LR: 7.00e-05\n",
      "\tEpoch 40/100 - Train loss: 0.1908 - Val accuracy: 0.2500 - Val loss: 1.3760 - Val F1: 0.1000 - LR: 6.00e-05\n",
      "\tEpoch 50/100 - Train loss: 0.1474 - Val accuracy: 0.8750 - Val loss: 0.7196 - Val F1: 0.8250 - LR: 5.00e-05\n",
      "\tEpoch 60/100 - Train loss: 0.1243 - Val accuracy: 1.0000 - Val loss: 0.3068 - Val F1: 1.0000 - LR: 4.00e-05\n",
      "\tEpoch 70/100 - Train loss: 0.1018 - Val accuracy: 1.0000 - Val loss: 0.2256 - Val F1: 1.0000 - LR: 3.00e-05\n",
      "\tEpoch 80/100 - Train loss: 0.0847 - Val accuracy: 1.0000 - Val loss: 0.2054 - Val F1: 1.0000 - LR: 2.00e-05\n",
      "\tEpoch 90/100 - Train loss: 0.0824 - Val accuracy: 1.0000 - Val loss: 0.1972 - Val F1: 1.0000 - LR: 1.00e-05\n",
      "\tEpoch 100/100 - Train loss: 0.0692 - Val accuracy: 1.0000 - Val loss: 0.1941 - Val F1: 1.0000 - LR: 0.00e+00\n",
      "\tBest epoch: 100 - Best val accuracy: 1.0000 - Best val loss: 0.1941 - Best val F1: 1.0000\n",
      "\n",
      "\tEpoch 10/100 - Train loss: 0.6948 - Val accuracy: 0.7500 - Val loss: 1.0576 - Val F1: 0.6875 - LR: 9.00e-05\n",
      "\tEpoch 20/100 - Train loss: 0.4591 - Val accuracy: 0.2500 - Val loss: 1.0652 - Val F1: 0.1000 - LR: 8.00e-05\n",
      "\tEpoch 30/100 - Train loss: 0.3092 - Val accuracy: 0.2500 - Val loss: 1.1873 - Val F1: 0.1000 - LR: 7.00e-05\n",
      "\tEpoch 40/100 - Train loss: 0.2224 - Val accuracy: 0.2500 - Val loss: 1.2368 - Val F1: 0.1000 - LR: 6.00e-05\n",
      "\tEpoch 50/100 - Train loss: 0.1668 - Val accuracy: 0.7500 - Val loss: 0.8221 - Val F1: 0.7222 - LR: 5.00e-05\n",
      "\tEpoch 60/100 - Train loss: 0.1428 - Val accuracy: 1.0000 - Val loss: 0.4105 - Val F1: 1.0000 - LR: 4.00e-05\n",
      "\tEpoch 70/100 - Train loss: 0.1104 - Val accuracy: 1.0000 - Val loss: 0.2631 - Val F1: 1.0000 - LR: 3.00e-05\n",
      "\tEpoch 80/100 - Train loss: 0.0948 - Val accuracy: 1.0000 - Val loss: 0.2227 - Val F1: 1.0000 - LR: 2.00e-05\n",
      "\tEpoch 90/100 - Train loss: 0.0928 - Val accuracy: 1.0000 - Val loss: 0.2106 - Val F1: 1.0000 - LR: 1.00e-05\n",
      "\tEpoch 100/100 - Train loss: 0.0881 - Val accuracy: 1.0000 - Val loss: 0.2069 - Val F1: 1.0000 - LR: 0.00e+00\n",
      "\tBest epoch: 100 - Best val accuracy: 1.0000 - Best val loss: 0.2069 - Best val F1: 1.0000\n",
      "\n",
      "\tEpoch 10/100 - Train loss: 0.5918 - Val accuracy: 0.6250 - Val loss: 1.0740 - Val F1: 0.4808 - LR: 9.00e-05\n",
      "\tEpoch 20/100 - Train loss: 0.3788 - Val accuracy: 0.2500 - Val loss: 1.0933 - Val F1: 0.1000 - LR: 8.00e-05\n",
      "\tEpoch 30/100 - Train loss: 0.2518 - Val accuracy: 0.2500 - Val loss: 1.1666 - Val F1: 0.1111 - LR: 7.00e-05\n",
      "\tEpoch 40/100 - Train loss: 0.1880 - Val accuracy: 0.1250 - Val loss: 1.0465 - Val F1: 0.0714 - LR: 6.00e-05\n",
      "\tEpoch 50/100 - Train loss: 0.1258 - Val accuracy: 0.7500 - Val loss: 0.5943 - Val F1: 0.7500 - LR: 5.00e-05\n",
      "\tEpoch 60/100 - Train loss: 0.1013 - Val accuracy: 0.7500 - Val loss: 0.3576 - Val F1: 0.7500 - LR: 4.00e-05\n",
      "\tEpoch 70/100 - Train loss: 0.0831 - Val accuracy: 0.7500 - Val loss: 0.3086 - Val F1: 0.7500 - LR: 3.00e-05\n",
      "\tEpoch 80/100 - Train loss: 0.0709 - Val accuracy: 0.7500 - Val loss: 0.2982 - Val F1: 0.7500 - LR: 2.00e-05\n",
      "\tEpoch 90/100 - Train loss: 0.0690 - Val accuracy: 0.7500 - Val loss: 0.2950 - Val F1: 0.7500 - LR: 1.00e-05\n",
      "\tEpoch 100/100 - Train loss: 0.0756 - Val accuracy: 0.7500 - Val loss: 0.2939 - Val F1: 0.7500 - LR: 0.00e+00\n",
      "\tBest epoch: 100 - Best val accuracy: 0.7500 - Best val loss: 0.2939 - Best val F1: 0.7500\n",
      "\n",
      "\tEpoch 10/100 - Train loss: 0.6600 - Val accuracy: 0.6250 - Val loss: 1.0629 - Val F1: 0.4808 - LR: 9.00e-05\n",
      "\tEpoch 20/100 - Train loss: 0.4426 - Val accuracy: 0.2500 - Val loss: 1.0653 - Val F1: 0.1000 - LR: 8.00e-05\n",
      "\tEpoch 30/100 - Train loss: 0.3051 - Val accuracy: 0.2500 - Val loss: 1.1386 - Val F1: 0.1000 - LR: 7.00e-05\n",
      "\tEpoch 40/100 - Train loss: 0.2233 - Val accuracy: 0.2500 - Val loss: 1.0906 - Val F1: 0.1000 - LR: 6.00e-05\n",
      "\tEpoch 50/100 - Train loss: 0.1734 - Val accuracy: 0.8750 - Val loss: 0.7225 - Val F1: 0.8250 - LR: 5.00e-05\n",
      "\tEpoch 60/100 - Train loss: 0.1368 - Val accuracy: 0.7500 - Val loss: 0.4338 - Val F1: 0.7500 - LR: 4.00e-05\n",
      "\tEpoch 70/100 - Train loss: 0.1251 - Val accuracy: 0.7500 - Val loss: 0.3591 - Val F1: 0.7500 - LR: 3.00e-05\n",
      "\tEpoch 80/100 - Train loss: 0.1057 - Val accuracy: 0.7500 - Val loss: 0.3451 - Val F1: 0.7500 - LR: 2.00e-05\n",
      "\tEpoch 90/100 - Train loss: 0.1038 - Val accuracy: 0.8750 - Val loss: 0.3436 - Val F1: 0.8750 - LR: 1.00e-05\n",
      "\tEpoch 100/100 - Train loss: 0.0870 - Val accuracy: 0.8750 - Val loss: 0.3443 - Val F1: 0.8750 - LR: 0.00e+00\n",
      "\tBest epoch: 89 - Best val accuracy: 0.8750 - Best val loss: 0.3436 - Best val F1: 0.8750\n",
      "\n",
      "Source class: WAL | Domain: 42 | Accuracy: 0.9133 | Loss: 0.3241 | F1: 0.8944\n",
      "\n",
      "Domain: 43\n",
      "x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Training and evaluating on Dp data via cross-validation...\n",
      "\tEpoch 10/100 - Train loss: 0.5636 - Val accuracy: 0.7143 - Val loss: 1.0880 - Val F1: 0.7063 - LR: 9.00e-05\n",
      "\tEpoch 20/100 - Train loss: 0.3588 - Val accuracy: 0.1429 - Val loss: 1.1629 - Val F1: 0.0357 - LR: 8.00e-05\n",
      "\tEpoch 30/100 - Train loss: 0.2536 - Val accuracy: 0.1429 - Val loss: 1.3839 - Val F1: 0.0357 - LR: 7.00e-05\n",
      "\tEpoch 40/100 - Train loss: 0.1876 - Val accuracy: 0.1429 - Val loss: 1.3016 - Val F1: 0.0408 - LR: 6.00e-05\n",
      "\tEpoch 50/100 - Train loss: 0.1460 - Val accuracy: 0.7143 - Val loss: 0.7060 - Val F1: 0.7063 - LR: 5.00e-05\n",
      "\tEpoch 60/100 - Train loss: 0.1311 - Val accuracy: 0.8571 - Val loss: 0.3731 - Val F1: 0.8095 - LR: 4.00e-05\n",
      "\tEpoch 70/100 - Train loss: 0.1126 - Val accuracy: 0.8571 - Val loss: 0.2812 - Val F1: 0.8095 - LR: 3.00e-05\n",
      "\tEpoch 80/100 - Train loss: 0.1015 - Val accuracy: 0.8571 - Val loss: 0.2510 - Val F1: 0.8095 - LR: 2.00e-05\n",
      "\tEpoch 90/100 - Train loss: 0.0974 - Val accuracy: 0.8571 - Val loss: 0.2394 - Val F1: 0.8095 - LR: 1.00e-05\n",
      "\tEpoch 100/100 - Train loss: 0.0943 - Val accuracy: 0.8571 - Val loss: 0.2347 - Val F1: 0.8095 - LR: 0.00e+00\n",
      "\tBest epoch: 100 - Best val accuracy: 0.8571 - Best val loss: 0.2347 - Best val F1: 0.8095\n",
      "\n",
      "\tEpoch 10/100 - Train loss: 0.5683 - Val accuracy: 0.7143 - Val loss: 1.0334 - Val F1: 0.5952 - LR: 9.00e-05\n",
      "\tEpoch 20/100 - Train loss: 0.3859 - Val accuracy: 0.4286 - Val loss: 1.0879 - Val F1: 0.4796 - LR: 8.00e-05\n",
      "\tEpoch 30/100 - Train loss: 0.2826 - Val accuracy: 0.1429 - Val loss: 1.1898 - Val F1: 0.0476 - LR: 7.00e-05\n",
      "\tEpoch 40/100 - Train loss: 0.2118 - Val accuracy: 0.7143 - Val loss: 0.9613 - Val F1: 0.7500 - LR: 6.00e-05\n",
      "\tEpoch 50/100 - Train loss: 0.1618 - Val accuracy: 1.0000 - Val loss: 0.4700 - Val F1: 1.0000 - LR: 5.00e-05\n",
      "\tEpoch 60/100 - Train loss: 0.1253 - Val accuracy: 1.0000 - Val loss: 0.3072 - Val F1: 1.0000 - LR: 4.00e-05\n",
      "\tEpoch 70/100 - Train loss: 0.1115 - Val accuracy: 1.0000 - Val loss: 0.2825 - Val F1: 1.0000 - LR: 3.00e-05\n",
      "\tEpoch 80/100 - Train loss: 0.0935 - Val accuracy: 1.0000 - Val loss: 0.2813 - Val F1: 1.0000 - LR: 2.00e-05\n",
      "\tEpoch 90/100 - Train loss: 0.0871 - Val accuracy: 1.0000 - Val loss: 0.2830 - Val F1: 1.0000 - LR: 1.00e-05\n",
      "\tEpoch 100/100 - Train loss: 0.0903 - Val accuracy: 0.8571 - Val loss: 0.2849 - Val F1: 0.7922 - LR: 0.00e+00\n",
      "\tBest epoch: 76 - Best val accuracy: 1.0000 - Best val loss: 0.2810 - Best val F1: 1.0000\n",
      "\n",
      "\tEpoch 10/100 - Train loss: 0.5391 - Val accuracy: 0.1429 - Val loss: 1.0985 - Val F1: 0.0357 - LR: 9.00e-05\n",
      "\tEpoch 20/100 - Train loss: 0.3297 - Val accuracy: 0.1429 - Val loss: 1.2081 - Val F1: 0.0357 - LR: 8.00e-05\n",
      "\tEpoch 30/100 - Train loss: 0.2119 - Val accuracy: 0.1429 - Val loss: 1.4770 - Val F1: 0.0476 - LR: 7.00e-05\n",
      "\tEpoch 40/100 - Train loss: 0.1365 - Val accuracy: 0.1429 - Val loss: 1.5138 - Val F1: 0.0476 - LR: 6.00e-05\n",
      "\tEpoch 50/100 - Train loss: 0.1031 - Val accuracy: 0.7143 - Val loss: 0.8028 - Val F1: 0.7063 - LR: 5.00e-05\n",
      "\tEpoch 60/100 - Train loss: 0.0779 - Val accuracy: 0.8571 - Val loss: 0.4965 - Val F1: 0.8095 - LR: 4.00e-05\n",
      "\tEpoch 70/100 - Train loss: 0.0694 - Val accuracy: 0.8571 - Val loss: 0.4765 - Val F1: 0.8095 - LR: 3.00e-05\n",
      "\tEpoch 80/100 - Train loss: 0.0549 - Val accuracy: 0.8571 - Val loss: 0.4864 - Val F1: 0.8095 - LR: 2.00e-05\n",
      "\tEpoch 90/100 - Train loss: 0.0530 - Val accuracy: 0.8571 - Val loss: 0.4950 - Val F1: 0.8095 - LR: 1.00e-05\n",
      "\tEpoch 100/100 - Train loss: 0.0511 - Val accuracy: 0.8571 - Val loss: 0.4994 - Val F1: 0.8095 - LR: 0.00e+00\n",
      "\tBest epoch: 67 - Best val accuracy: 0.8571 - Best val loss: 0.4756 - Best val F1: 0.8095\n",
      "\n",
      "\tEpoch 10/100 - Train loss: 0.7034 - Val accuracy: 0.7143 - Val loss: 1.0291 - Val F1: 0.5952 - LR: 9.00e-05\n",
      "\tEpoch 20/100 - Train loss: 0.4832 - Val accuracy: 0.7143 - Val loss: 0.9944 - Val F1: 0.5952 - LR: 8.00e-05\n",
      "\tEpoch 30/100 - Train loss: 0.3516 - Val accuracy: 0.7143 - Val loss: 0.9779 - Val F1: 0.7063 - LR: 7.00e-05\n",
      "\tEpoch 40/100 - Train loss: 0.2682 - Val accuracy: 0.8571 - Val loss: 0.6556 - Val F1: 0.8095 - LR: 6.00e-05\n",
      "\tEpoch 50/100 - Train loss: 0.1937 - Val accuracy: 0.8571 - Val loss: 0.3607 - Val F1: 0.8095 - LR: 5.00e-05\n",
      "\tEpoch 60/100 - Train loss: 0.1654 - Val accuracy: 0.8571 - Val loss: 0.2945 - Val F1: 0.8095 - LR: 4.00e-05\n",
      "\tEpoch 70/100 - Train loss: 0.1315 - Val accuracy: 0.8571 - Val loss: 0.2811 - Val F1: 0.8095 - LR: 3.00e-05\n",
      "\tEpoch 80/100 - Train loss: 0.1256 - Val accuracy: 0.8571 - Val loss: 0.2733 - Val F1: 0.8095 - LR: 2.00e-05\n",
      "\tEpoch 90/100 - Train loss: 0.1034 - Val accuracy: 0.8571 - Val loss: 0.2682 - Val F1: 0.8095 - LR: 1.00e-05\n",
      "\tEpoch 100/100 - Train loss: 0.1004 - Val accuracy: 0.8571 - Val loss: 0.2662 - Val F1: 0.8095 - LR: 0.00e+00\n",
      "\tBest epoch: 100 - Best val accuracy: 0.8571 - Best val loss: 0.2662 - Best val F1: 0.8095\n",
      "\n",
      "\tEpoch 10/100 - Train loss: 0.5913 - Val accuracy: 0.7143 - Val loss: 1.0642 - Val F1: 0.5952 - LR: 9.00e-05\n",
      "\tEpoch 20/100 - Train loss: 0.3722 - Val accuracy: 0.1429 - Val loss: 1.1322 - Val F1: 0.0357 - LR: 8.00e-05\n",
      "\tEpoch 30/100 - Train loss: 0.2829 - Val accuracy: 0.1429 - Val loss: 1.3082 - Val F1: 0.0408 - LR: 7.00e-05\n",
      "\tEpoch 40/100 - Train loss: 0.2114 - Val accuracy: 0.1429 - Val loss: 1.1833 - Val F1: 0.0408 - LR: 6.00e-05\n",
      "\tEpoch 50/100 - Train loss: 0.1694 - Val accuracy: 0.8571 - Val loss: 0.5318 - Val F1: 0.8730 - LR: 5.00e-05\n",
      "\tEpoch 60/100 - Train loss: 0.1523 - Val accuracy: 1.0000 - Val loss: 0.2618 - Val F1: 1.0000 - LR: 4.00e-05\n",
      "\tEpoch 70/100 - Train loss: 0.1263 - Val accuracy: 1.0000 - Val loss: 0.2117 - Val F1: 1.0000 - LR: 3.00e-05\n",
      "\tEpoch 80/100 - Train loss: 0.1233 - Val accuracy: 1.0000 - Val loss: 0.1978 - Val F1: 1.0000 - LR: 2.00e-05\n",
      "\tEpoch 90/100 - Train loss: 0.1104 - Val accuracy: 1.0000 - Val loss: 0.1919 - Val F1: 1.0000 - LR: 1.00e-05\n",
      "\tEpoch 100/100 - Train loss: 0.1044 - Val accuracy: 1.0000 - Val loss: 0.1901 - Val F1: 1.0000 - LR: 0.00e+00\n",
      "\tBest epoch: 100 - Best val accuracy: 1.0000 - Best val loss: 0.1901 - Best val F1: 1.0000\n",
      "\n",
      "Source class: WAL | Domain: 43 | Accuracy: 0.8778 | Loss: 0.3845 | F1: 0.8717\n",
      "\n",
      "Domain: 44\n",
      "x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Training and evaluating on Dp data via cross-validation...\n",
      "\tEpoch 10/100 - Train loss: 0.5857 - Val accuracy: 0.7143 - Val loss: 1.0789 - Val F1: 0.5952 - LR: 9.00e-05\n",
      "\tEpoch 20/100 - Train loss: 0.3726 - Val accuracy: 0.1429 - Val loss: 1.1630 - Val F1: 0.0357 - LR: 8.00e-05\n",
      "\tEpoch 30/100 - Train loss: 0.2589 - Val accuracy: 0.1429 - Val loss: 1.3580 - Val F1: 0.0357 - LR: 7.00e-05\n",
      "\tEpoch 40/100 - Train loss: 0.2158 - Val accuracy: 0.1429 - Val loss: 1.3428 - Val F1: 0.0357 - LR: 6.00e-05\n",
      "\tEpoch 50/100 - Train loss: 0.1818 - Val accuracy: 0.7143 - Val loss: 0.7906 - Val F1: 0.7063 - LR: 5.00e-05\n",
      "\tEpoch 60/100 - Train loss: 0.1439 - Val accuracy: 0.8571 - Val loss: 0.3989 - Val F1: 0.8095 - LR: 4.00e-05\n",
      "\tEpoch 70/100 - Train loss: 0.1240 - Val accuracy: 0.8571 - Val loss: 0.3200 - Val F1: 0.8095 - LR: 3.00e-05\n",
      "\tEpoch 80/100 - Train loss: 0.1089 - Val accuracy: 0.8571 - Val loss: 0.3111 - Val F1: 0.8095 - LR: 2.00e-05\n",
      "\tEpoch 90/100 - Train loss: 0.1021 - Val accuracy: 0.8571 - Val loss: 0.3120 - Val F1: 0.8095 - LR: 1.00e-05\n",
      "\tEpoch 100/100 - Train loss: 0.0990 - Val accuracy: 0.8571 - Val loss: 0.3134 - Val F1: 0.8095 - LR: 0.00e+00\n",
      "\tBest epoch: 81 - Best val accuracy: 0.8571 - Best val loss: 0.3110 - Best val F1: 0.8095\n",
      "\n",
      "\tEpoch 10/100 - Train loss: 0.5909 - Val accuracy: 0.7143 - Val loss: 1.0652 - Val F1: 0.5952 - LR: 9.00e-05\n",
      "\tEpoch 20/100 - Train loss: 0.4145 - Val accuracy: 0.1429 - Val loss: 1.1132 - Val F1: 0.0357 - LR: 8.00e-05\n",
      "\tEpoch 30/100 - Train loss: 0.2919 - Val accuracy: 0.0000 - Val loss: 1.2528 - Val F1: 0.0000 - LR: 7.00e-05\n",
      "\tEpoch 40/100 - Train loss: 0.2335 - Val accuracy: 0.1429 - Val loss: 1.2780 - Val F1: 0.0357 - LR: 6.00e-05\n",
      "\tEpoch 50/100 - Train loss: 0.2004 - Val accuracy: 0.7143 - Val loss: 0.7599 - Val F1: 0.7063 - LR: 5.00e-05\n",
      "\tEpoch 60/100 - Train loss: 0.1842 - Val accuracy: 0.8571 - Val loss: 0.3611 - Val F1: 0.8095 - LR: 4.00e-05\n",
      "\tEpoch 70/100 - Train loss: 0.1603 - Val accuracy: 0.8571 - Val loss: 0.2931 - Val F1: 0.8095 - LR: 3.00e-05\n",
      "\tEpoch 80/100 - Train loss: 0.1555 - Val accuracy: 0.7143 - Val loss: 0.2958 - Val F1: 0.6494 - LR: 2.00e-05\n",
      "\tEpoch 90/100 - Train loss: 0.1355 - Val accuracy: 0.7143 - Val loss: 0.3042 - Val F1: 0.6494 - LR: 1.00e-05\n",
      "\tEpoch 100/100 - Train loss: 0.1306 - Val accuracy: 0.7143 - Val loss: 0.3086 - Val F1: 0.6494 - LR: 0.00e+00\n",
      "\tBest epoch: 73 - Best val accuracy: 0.8571 - Best val loss: 0.2915 - Best val F1: 0.8095\n",
      "\n",
      "\tEpoch 10/100 - Train loss: 0.5361 - Val accuracy: 0.1429 - Val loss: 1.0960 - Val F1: 0.0357 - LR: 9.00e-05\n",
      "\tEpoch 20/100 - Train loss: 0.3513 - Val accuracy: 0.1429 - Val loss: 1.2101 - Val F1: 0.0357 - LR: 8.00e-05\n",
      "\tEpoch 30/100 - Train loss: 0.2830 - Val accuracy: 0.0000 - Val loss: 1.3959 - Val F1: 0.0000 - LR: 7.00e-05\n",
      "\tEpoch 40/100 - Train loss: 0.2325 - Val accuracy: 0.1429 - Val loss: 1.4405 - Val F1: 0.0952 - LR: 6.00e-05\n",
      "\tEpoch 50/100 - Train loss: 0.1927 - Val accuracy: 0.7143 - Val loss: 0.8339 - Val F1: 0.7500 - LR: 5.00e-05\n",
      "\tEpoch 60/100 - Train loss: 0.1601 - Val accuracy: 1.0000 - Val loss: 0.3093 - Val F1: 1.0000 - LR: 4.00e-05\n",
      "\tEpoch 70/100 - Train loss: 0.1503 - Val accuracy: 1.0000 - Val loss: 0.2183 - Val F1: 1.0000 - LR: 3.00e-05\n",
      "\tEpoch 80/100 - Train loss: 0.1250 - Val accuracy: 1.0000 - Val loss: 0.2045 - Val F1: 1.0000 - LR: 2.00e-05\n",
      "\tEpoch 90/100 - Train loss: 0.1277 - Val accuracy: 1.0000 - Val loss: 0.2014 - Val F1: 1.0000 - LR: 1.00e-05\n",
      "\tEpoch 100/100 - Train loss: 0.1206 - Val accuracy: 1.0000 - Val loss: 0.2013 - Val F1: 1.0000 - LR: 0.00e+00\n",
      "\tBest epoch: 96 - Best val accuracy: 1.0000 - Best val loss: 0.2010 - Best val F1: 1.0000\n",
      "\n",
      "\tEpoch 10/100 - Train loss: 0.5188 - Val accuracy: 0.7143 - Val loss: 1.0590 - Val F1: 0.5952 - LR: 9.00e-05\n",
      "\tEpoch 20/100 - Train loss: 0.3276 - Val accuracy: 0.1429 - Val loss: 1.2131 - Val F1: 0.0357 - LR: 8.00e-05\n",
      "\tEpoch 30/100 - Train loss: 0.2301 - Val accuracy: 0.1429 - Val loss: 1.4798 - Val F1: 0.0357 - LR: 7.00e-05\n",
      "\tEpoch 40/100 - Train loss: 0.1897 - Val accuracy: 0.1429 - Val loss: 1.4208 - Val F1: 0.0357 - LR: 6.00e-05\n",
      "\tEpoch 50/100 - Train loss: 0.1433 - Val accuracy: 0.7143 - Val loss: 0.6858 - Val F1: 0.7302 - LR: 5.00e-05\n",
      "\tEpoch 60/100 - Train loss: 0.1274 - Val accuracy: 0.8571 - Val loss: 0.3162 - Val F1: 0.8095 - LR: 4.00e-05\n",
      "\tEpoch 70/100 - Train loss: 0.1038 - Val accuracy: 1.0000 - Val loss: 0.2194 - Val F1: 1.0000 - LR: 3.00e-05\n",
      "\tEpoch 80/100 - Train loss: 0.0945 - Val accuracy: 1.0000 - Val loss: 0.1894 - Val F1: 1.0000 - LR: 2.00e-05\n",
      "\tEpoch 90/100 - Train loss: 0.0939 - Val accuracy: 1.0000 - Val loss: 0.1774 - Val F1: 1.0000 - LR: 1.00e-05\n",
      "\tEpoch 100/100 - Train loss: 0.0871 - Val accuracy: 1.0000 - Val loss: 0.1729 - Val F1: 1.0000 - LR: 0.00e+00\n",
      "\tBest epoch: 100 - Best val accuracy: 1.0000 - Best val loss: 0.1729 - Best val F1: 1.0000\n",
      "\n",
      "\tEpoch 10/100 - Train loss: 0.5819 - Val accuracy: 0.1429 - Val loss: 1.1114 - Val F1: 0.0357 - LR: 9.00e-05\n",
      "\tEpoch 20/100 - Train loss: 0.3648 - Val accuracy: 0.1429 - Val loss: 1.1825 - Val F1: 0.0357 - LR: 8.00e-05\n",
      "\tEpoch 30/100 - Train loss: 0.2549 - Val accuracy: 0.1429 - Val loss: 1.3883 - Val F1: 0.0357 - LR: 7.00e-05\n",
      "\tEpoch 40/100 - Train loss: 0.2146 - Val accuracy: 0.1429 - Val loss: 1.3636 - Val F1: 0.0357 - LR: 6.00e-05\n",
      "\tEpoch 50/100 - Train loss: 0.1854 - Val accuracy: 0.8571 - Val loss: 0.6558 - Val F1: 0.8095 - LR: 5.00e-05\n",
      "\tEpoch 60/100 - Train loss: 0.1481 - Val accuracy: 0.8571 - Val loss: 0.2790 - Val F1: 0.8095 - LR: 4.00e-05\n",
      "\tEpoch 70/100 - Train loss: 0.1298 - Val accuracy: 0.8571 - Val loss: 0.2071 - Val F1: 0.8095 - LR: 3.00e-05\n",
      "\tEpoch 80/100 - Train loss: 0.1131 - Val accuracy: 0.8571 - Val loss: 0.1887 - Val F1: 0.8095 - LR: 2.00e-05\n",
      "\tEpoch 90/100 - Train loss: 0.1061 - Val accuracy: 0.8571 - Val loss: 0.1819 - Val F1: 0.8095 - LR: 1.00e-05\n",
      "\tEpoch 100/100 - Train loss: 0.1165 - Val accuracy: 0.8571 - Val loss: 0.1797 - Val F1: 0.8095 - LR: 0.00e+00\n",
      "\tBest epoch: 100 - Best val accuracy: 0.8571 - Best val loss: 0.1797 - Best val F1: 0.8095\n",
      "\n",
      "Source class: WAL | Domain: 44 | Accuracy: 0.8778 | Loss: 0.2713 | F1: 0.8456\n",
      "\n",
      "Domain: 45\n",
      "x_dp_dom.shape: (52, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Training and evaluating on Dp data via cross-validation...\n",
      "\tEpoch 10/100 - Train loss: 0.6778 - Val accuracy: 0.2222 - Val loss: 1.1157 - Val F1: 0.0808 - LR: 9.00e-05\n",
      "\tEpoch 20/100 - Train loss: 0.4233 - Val accuracy: 0.2222 - Val loss: 1.1820 - Val F1: 0.0808 - LR: 8.00e-05\n",
      "\tEpoch 30/100 - Train loss: 0.3116 - Val accuracy: 0.2222 - Val loss: 1.3376 - Val F1: 0.0808 - LR: 7.00e-05\n",
      "\tEpoch 40/100 - Train loss: 0.2367 - Val accuracy: 0.3333 - Val loss: 1.2856 - Val F1: 0.2011 - LR: 6.00e-05\n",
      "\tEpoch 50/100 - Train loss: 0.1819 - Val accuracy: 0.7778 - Val loss: 0.7692 - Val F1: 0.7827 - LR: 5.00e-05\n",
      "\tEpoch 60/100 - Train loss: 0.1338 - Val accuracy: 1.0000 - Val loss: 0.3766 - Val F1: 1.0000 - LR: 4.00e-05\n",
      "\tEpoch 70/100 - Train loss: 0.1211 - Val accuracy: 1.0000 - Val loss: 0.2724 - Val F1: 1.0000 - LR: 3.00e-05\n",
      "\tEpoch 80/100 - Train loss: 0.1160 - Val accuracy: 1.0000 - Val loss: 0.2427 - Val F1: 1.0000 - LR: 2.00e-05\n",
      "\tEpoch 90/100 - Train loss: 0.0975 - Val accuracy: 1.0000 - Val loss: 0.2311 - Val F1: 1.0000 - LR: 1.00e-05\n",
      "\tEpoch 100/100 - Train loss: 0.0971 - Val accuracy: 1.0000 - Val loss: 0.2270 - Val F1: 1.0000 - LR: 0.00e+00\n",
      "\tBest epoch: 100 - Best val accuracy: 1.0000 - Best val loss: 0.2270 - Best val F1: 1.0000\n",
      "\n",
      "\tEpoch 10/100 - Train loss: 0.6604 - Val accuracy: 0.5556 - Val loss: 1.0863 - Val F1: 0.4274 - LR: 9.00e-05\n",
      "\tEpoch 20/100 - Train loss: 0.4088 - Val accuracy: 0.2222 - Val loss: 1.1912 - Val F1: 0.0808 - LR: 8.00e-05\n",
      "\tEpoch 30/100 - Train loss: 0.3047 - Val accuracy: 0.2222 - Val loss: 1.3685 - Val F1: 0.0808 - LR: 7.00e-05\n",
      "\tEpoch 40/100 - Train loss: 0.2384 - Val accuracy: 0.2222 - Val loss: 1.2856 - Val F1: 0.0808 - LR: 6.00e-05\n",
      "\tEpoch 50/100 - Train loss: 0.1882 - Val accuracy: 0.7778 - Val loss: 0.6978 - Val F1: 0.7037 - LR: 5.00e-05\n",
      "\tEpoch 60/100 - Train loss: 0.1559 - Val accuracy: 0.7778 - Val loss: 0.3583 - Val F1: 0.7037 - LR: 4.00e-05\n",
      "\tEpoch 70/100 - Train loss: 0.1345 - Val accuracy: 0.8889 - Val loss: 0.2794 - Val F1: 0.8815 - LR: 3.00e-05\n",
      "\tEpoch 80/100 - Train loss: 0.1233 - Val accuracy: 0.8889 - Val loss: 0.2541 - Val F1: 0.8815 - LR: 2.00e-05\n",
      "\tEpoch 90/100 - Train loss: 0.1152 - Val accuracy: 0.8889 - Val loss: 0.2429 - Val F1: 0.8815 - LR: 1.00e-05\n",
      "\tEpoch 100/100 - Train loss: 0.1086 - Val accuracy: 0.8889 - Val loss: 0.2390 - Val F1: 0.8815 - LR: 0.00e+00\n",
      "\tBest epoch: 100 - Best val accuracy: 0.8889 - Best val loss: 0.2390 - Best val F1: 0.8815\n",
      "\n",
      "\tEpoch 10/100 - Train loss: 0.6553 - Val accuracy: 0.5556 - Val loss: 1.0861 - Val F1: 0.3968 - LR: 9.00e-05\n",
      "\tEpoch 20/100 - Train loss: 0.3900 - Val accuracy: 0.2222 - Val loss: 1.2043 - Val F1: 0.0808 - LR: 8.00e-05\n",
      "\tEpoch 30/100 - Train loss: 0.2605 - Val accuracy: 0.2222 - Val loss: 1.3938 - Val F1: 0.0808 - LR: 7.00e-05\n",
      "\tEpoch 40/100 - Train loss: 0.1976 - Val accuracy: 0.2222 - Val loss: 1.3654 - Val F1: 0.1270 - LR: 6.00e-05\n",
      "\tEpoch 50/100 - Train loss: 0.1453 - Val accuracy: 0.6667 - Val loss: 0.7459 - Val F1: 0.6208 - LR: 5.00e-05\n",
      "\tEpoch 60/100 - Train loss: 0.1181 - Val accuracy: 0.8889 - Val loss: 0.3761 - Val F1: 0.8815 - LR: 4.00e-05\n",
      "\tEpoch 70/100 - Train loss: 0.0966 - Val accuracy: 0.8889 - Val loss: 0.3053 - Val F1: 0.8815 - LR: 3.00e-05\n",
      "\tEpoch 80/100 - Train loss: 0.0828 - Val accuracy: 0.8889 - Val loss: 0.2904 - Val F1: 0.8815 - LR: 2.00e-05\n",
      "\tEpoch 90/100 - Train loss: 0.0690 - Val accuracy: 0.8889 - Val loss: 0.2866 - Val F1: 0.8815 - LR: 1.00e-05\n",
      "\tEpoch 100/100 - Train loss: 0.0640 - Val accuracy: 0.8889 - Val loss: 0.2856 - Val F1: 0.8815 - LR: 0.00e+00\n",
      "\tBest epoch: 100 - Best val accuracy: 0.8889 - Best val loss: 0.2856 - Best val F1: 0.8815\n",
      "\n",
      "\tEpoch 10/100 - Train loss: 0.5798 - Val accuracy: 0.2222 - Val loss: 1.1076 - Val F1: 0.0808 - LR: 9.00e-05\n",
      "\tEpoch 20/100 - Train loss: 0.3875 - Val accuracy: 0.2222 - Val loss: 1.1980 - Val F1: 0.0808 - LR: 8.00e-05\n",
      "\tEpoch 30/100 - Train loss: 0.3022 - Val accuracy: 0.2222 - Val loss: 1.3263 - Val F1: 0.0808 - LR: 7.00e-05\n",
      "\tEpoch 40/100 - Train loss: 0.2441 - Val accuracy: 0.2222 - Val loss: 1.2087 - Val F1: 0.0889 - LR: 6.00e-05\n",
      "\tEpoch 50/100 - Train loss: 0.1973 - Val accuracy: 0.7778 - Val loss: 0.6526 - Val F1: 0.7037 - LR: 5.00e-05\n",
      "\tEpoch 60/100 - Train loss: 0.1522 - Val accuracy: 0.7778 - Val loss: 0.3911 - Val F1: 0.7037 - LR: 4.00e-05\n",
      "\tEpoch 70/100 - Train loss: 0.1345 - Val accuracy: 0.7778 - Val loss: 0.3342 - Val F1: 0.7037 - LR: 3.00e-05\n",
      "\tEpoch 80/100 - Train loss: 0.1170 - Val accuracy: 0.7778 - Val loss: 0.3137 - Val F1: 0.7037 - LR: 2.00e-05\n",
      "\tEpoch 90/100 - Train loss: 0.1091 - Val accuracy: 0.7778 - Val loss: 0.3031 - Val F1: 0.7037 - LR: 1.00e-05\n",
      "\tEpoch 100/100 - Train loss: 0.0980 - Val accuracy: 0.7778 - Val loss: 0.2974 - Val F1: 0.7037 - LR: 0.00e+00\n",
      "\tBest epoch: 100 - Best val accuracy: 0.7778 - Best val loss: 0.2974 - Best val F1: 0.7037\n",
      "\n",
      "\tEpoch 10/100 - Train loss: 0.6723 - Val accuracy: 0.2222 - Val loss: 1.1439 - Val F1: 0.0808 - LR: 9.00e-05\n",
      "\tEpoch 20/100 - Train loss: 0.4252 - Val accuracy: 0.2222 - Val loss: 1.2619 - Val F1: 0.0808 - LR: 8.00e-05\n",
      "\tEpoch 30/100 - Train loss: 0.3252 - Val accuracy: 0.2222 - Val loss: 1.4508 - Val F1: 0.0808 - LR: 7.00e-05\n",
      "\tEpoch 40/100 - Train loss: 0.2512 - Val accuracy: 0.2222 - Val loss: 1.4446 - Val F1: 0.1270 - LR: 6.00e-05\n",
      "\tEpoch 50/100 - Train loss: 0.1777 - Val accuracy: 0.5556 - Val loss: 0.8016 - Val F1: 0.5693 - LR: 5.00e-05\n",
      "\tEpoch 60/100 - Train loss: 0.1629 - Val accuracy: 0.8889 - Val loss: 0.3643 - Val F1: 0.8815 - LR: 4.00e-05\n",
      "\tEpoch 70/100 - Train loss: 0.1349 - Val accuracy: 0.8889 - Val loss: 0.2691 - Val F1: 0.8815 - LR: 3.00e-05\n",
      "\tEpoch 80/100 - Train loss: 0.1286 - Val accuracy: 1.0000 - Val loss: 0.2394 - Val F1: 1.0000 - LR: 2.00e-05\n",
      "\tEpoch 90/100 - Train loss: 0.1070 - Val accuracy: 1.0000 - Val loss: 0.2269 - Val F1: 1.0000 - LR: 1.00e-05\n",
      "\tEpoch 100/100 - Train loss: 0.1009 - Val accuracy: 1.0000 - Val loss: 0.2221 - Val F1: 1.0000 - LR: 0.00e+00\n",
      "\tBest epoch: 100 - Best val accuracy: 1.0000 - Best val loss: 0.2221 - Best val F1: 1.0000\n",
      "\n",
      "Source class: WAL | Domain: 45 | Accuracy: 0.9236 | Loss: 0.2380 | F1: 0.9067\n",
      "\n",
      "Domain: 46\n",
      "x_dp_dom.shape: (48, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Training and evaluating on Dp data via cross-validation...\n",
      "\tEpoch 10/100 - Train loss: 0.5979 - Val accuracy: 0.6250 - Val loss: 1.0685 - Val F1: 0.4808 - LR: 9.00e-05\n",
      "\tEpoch 20/100 - Train loss: 0.3603 - Val accuracy: 0.2500 - Val loss: 1.1725 - Val F1: 0.1000 - LR: 8.00e-05\n",
      "\tEpoch 30/100 - Train loss: 0.2576 - Val accuracy: 0.2500 - Val loss: 1.3585 - Val F1: 0.1000 - LR: 7.00e-05\n",
      "\tEpoch 40/100 - Train loss: 0.2187 - Val accuracy: 0.2500 - Val loss: 1.3118 - Val F1: 0.1000 - LR: 6.00e-05\n",
      "\tEpoch 50/100 - Train loss: 0.1633 - Val accuracy: 0.6250 - Val loss: 0.8201 - Val F1: 0.6354 - LR: 5.00e-05\n",
      "\tEpoch 60/100 - Train loss: 0.1332 - Val accuracy: 1.0000 - Val loss: 0.3543 - Val F1: 1.0000 - LR: 4.00e-05\n",
      "\tEpoch 70/100 - Train loss: 0.1057 - Val accuracy: 1.0000 - Val loss: 0.2022 - Val F1: 1.0000 - LR: 3.00e-05\n",
      "\tEpoch 80/100 - Train loss: 0.0989 - Val accuracy: 1.0000 - Val loss: 0.1558 - Val F1: 1.0000 - LR: 2.00e-05\n",
      "\tEpoch 90/100 - Train loss: 0.0888 - Val accuracy: 1.0000 - Val loss: 0.1377 - Val F1: 1.0000 - LR: 1.00e-05\n",
      "\tEpoch 100/100 - Train loss: 0.0970 - Val accuracy: 1.0000 - Val loss: 0.1307 - Val F1: 1.0000 - LR: 0.00e+00\n",
      "\tBest epoch: 100 - Best val accuracy: 1.0000 - Best val loss: 0.1307 - Best val F1: 1.0000\n",
      "\n",
      "\tEpoch 10/100 - Train loss: 0.5814 - Val accuracy: 0.2500 - Val loss: 1.0735 - Val F1: 0.1000 - LR: 9.00e-05\n",
      "\tEpoch 20/100 - Train loss: 0.3781 - Val accuracy: 0.2500 - Val loss: 1.1724 - Val F1: 0.1000 - LR: 8.00e-05\n",
      "\tEpoch 30/100 - Train loss: 0.2731 - Val accuracy: 0.2500 - Val loss: 1.3040 - Val F1: 0.1000 - LR: 7.00e-05\n",
      "\tEpoch 40/100 - Train loss: 0.2099 - Val accuracy: 0.2500 - Val loss: 1.2400 - Val F1: 0.1000 - LR: 6.00e-05\n",
      "\tEpoch 50/100 - Train loss: 0.1631 - Val accuracy: 0.8750 - Val loss: 0.6269 - Val F1: 0.8250 - LR: 5.00e-05\n",
      "\tEpoch 60/100 - Train loss: 0.1296 - Val accuracy: 1.0000 - Val loss: 0.2584 - Val F1: 1.0000 - LR: 4.00e-05\n",
      "\tEpoch 70/100 - Train loss: 0.1127 - Val accuracy: 1.0000 - Val loss: 0.1727 - Val F1: 1.0000 - LR: 3.00e-05\n",
      "\tEpoch 80/100 - Train loss: 0.0884 - Val accuracy: 1.0000 - Val loss: 0.1463 - Val F1: 1.0000 - LR: 2.00e-05\n",
      "\tEpoch 90/100 - Train loss: 0.0889 - Val accuracy: 1.0000 - Val loss: 0.1366 - Val F1: 1.0000 - LR: 1.00e-05\n",
      "\tEpoch 100/100 - Train loss: 0.0757 - Val accuracy: 1.0000 - Val loss: 0.1334 - Val F1: 1.0000 - LR: 0.00e+00\n",
      "\tBest epoch: 100 - Best val accuracy: 1.0000 - Best val loss: 0.1334 - Best val F1: 1.0000\n",
      "\n",
      "\tEpoch 10/100 - Train loss: 0.5795 - Val accuracy: 0.2500 - Val loss: 1.0971 - Val F1: 0.1000 - LR: 9.00e-05\n",
      "\tEpoch 20/100 - Train loss: 0.3688 - Val accuracy: 0.2500 - Val loss: 1.1735 - Val F1: 0.1000 - LR: 8.00e-05\n",
      "\tEpoch 30/100 - Train loss: 0.2675 - Val accuracy: 0.2500 - Val loss: 1.3036 - Val F1: 0.1000 - LR: 7.00e-05\n",
      "\tEpoch 40/100 - Train loss: 0.2007 - Val accuracy: 0.3750 - Val loss: 0.9660 - Val F1: 0.3194 - LR: 6.00e-05\n",
      "\tEpoch 50/100 - Train loss: 0.1670 - Val accuracy: 0.8750 - Val loss: 0.3904 - Val F1: 0.8250 - LR: 5.00e-05\n",
      "\tEpoch 60/100 - Train loss: 0.1317 - Val accuracy: 0.8750 - Val loss: 0.2127 - Val F1: 0.8250 - LR: 4.00e-05\n",
      "\tEpoch 70/100 - Train loss: 0.1072 - Val accuracy: 1.0000 - Val loss: 0.1658 - Val F1: 1.0000 - LR: 3.00e-05\n",
      "\tEpoch 80/100 - Train loss: 0.0923 - Val accuracy: 1.0000 - Val loss: 0.1453 - Val F1: 1.0000 - LR: 2.00e-05\n",
      "\tEpoch 90/100 - Train loss: 0.0878 - Val accuracy: 1.0000 - Val loss: 0.1357 - Val F1: 1.0000 - LR: 1.00e-05\n",
      "\tEpoch 100/100 - Train loss: 0.0880 - Val accuracy: 1.0000 - Val loss: 0.1323 - Val F1: 1.0000 - LR: 0.00e+00\n",
      "\tBest epoch: 100 - Best val accuracy: 1.0000 - Best val loss: 0.1323 - Best val F1: 1.0000\n",
      "\n",
      "\tEpoch 10/100 - Train loss: 0.5267 - Val accuracy: 0.2500 - Val loss: 1.1385 - Val F1: 0.1000 - LR: 9.00e-05\n",
      "\tEpoch 20/100 - Train loss: 0.3322 - Val accuracy: 0.2500 - Val loss: 1.2728 - Val F1: 0.1000 - LR: 8.00e-05\n",
      "\tEpoch 30/100 - Train loss: 0.2538 - Val accuracy: 0.2500 - Val loss: 1.5031 - Val F1: 0.1000 - LR: 7.00e-05\n",
      "\tEpoch 40/100 - Train loss: 0.1929 - Val accuracy: 0.2500 - Val loss: 1.4555 - Val F1: 0.1000 - LR: 6.00e-05\n",
      "\tEpoch 50/100 - Train loss: 0.1627 - Val accuracy: 0.8750 - Val loss: 0.6988 - Val F1: 0.8250 - LR: 5.00e-05\n",
      "\tEpoch 60/100 - Train loss: 0.1397 - Val accuracy: 1.0000 - Val loss: 0.2738 - Val F1: 1.0000 - LR: 4.00e-05\n",
      "\tEpoch 70/100 - Train loss: 0.1067 - Val accuracy: 1.0000 - Val loss: 0.1809 - Val F1: 1.0000 - LR: 3.00e-05\n",
      "\tEpoch 80/100 - Train loss: 0.0996 - Val accuracy: 1.0000 - Val loss: 0.1525 - Val F1: 1.0000 - LR: 2.00e-05\n",
      "\tEpoch 90/100 - Train loss: 0.0812 - Val accuracy: 1.0000 - Val loss: 0.1399 - Val F1: 1.0000 - LR: 1.00e-05\n",
      "\tEpoch 100/100 - Train loss: 0.0825 - Val accuracy: 1.0000 - Val loss: 0.1356 - Val F1: 1.0000 - LR: 0.00e+00\n",
      "\tBest epoch: 100 - Best val accuracy: 1.0000 - Best val loss: 0.1356 - Best val F1: 1.0000\n",
      "\n",
      "\tEpoch 10/100 - Train loss: 0.5827 - Val accuracy: 0.2500 - Val loss: 1.1120 - Val F1: 0.1000 - LR: 9.00e-05\n",
      "\tEpoch 20/100 - Train loss: 0.3700 - Val accuracy: 0.2500 - Val loss: 1.2070 - Val F1: 0.1000 - LR: 8.00e-05\n",
      "\tEpoch 30/100 - Train loss: 0.2761 - Val accuracy: 0.2500 - Val loss: 1.3971 - Val F1: 0.1000 - LR: 7.00e-05\n",
      "\tEpoch 40/100 - Train loss: 0.2150 - Val accuracy: 0.2500 - Val loss: 1.3967 - Val F1: 0.1000 - LR: 6.00e-05\n",
      "\tEpoch 50/100 - Train loss: 0.1776 - Val accuracy: 0.5000 - Val loss: 0.8114 - Val F1: 0.4821 - LR: 5.00e-05\n",
      "\tEpoch 60/100 - Train loss: 0.1483 - Val accuracy: 0.8750 - Val loss: 0.3761 - Val F1: 0.8250 - LR: 4.00e-05\n",
      "\tEpoch 70/100 - Train loss: 0.1350 - Val accuracy: 0.8750 - Val loss: 0.2621 - Val F1: 0.8250 - LR: 3.00e-05\n",
      "\tEpoch 80/100 - Train loss: 0.1125 - Val accuracy: 0.8750 - Val loss: 0.2263 - Val F1: 0.8250 - LR: 2.00e-05\n",
      "\tEpoch 90/100 - Train loss: 0.0984 - Val accuracy: 0.8750 - Val loss: 0.2117 - Val F1: 0.8250 - LR: 1.00e-05\n",
      "\tEpoch 100/100 - Train loss: 0.1002 - Val accuracy: 0.8750 - Val loss: 0.2061 - Val F1: 0.8250 - LR: 0.00e+00\n",
      "\tBest epoch: 100 - Best val accuracy: 0.8750 - Best val loss: 0.2061 - Best val F1: 0.8250\n",
      "\n",
      "Source class: WAL | Domain: 46 | Accuracy: 0.9133 | Loss: 0.2129 | F1: 0.8885\n",
      "\n",
      "Domain: 47\n",
      "x_dp_dom.shape: (44, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Training and evaluating on Dp data via cross-validation...\n",
      "\tEpoch 10/100 - Train loss: 0.6111 - Val accuracy: 0.5714 - Val loss: 1.0574 - Val F1: 0.4156 - LR: 9.00e-05\n",
      "\tEpoch 20/100 - Train loss: 0.3747 - Val accuracy: 0.2857 - Val loss: 1.1070 - Val F1: 0.1270 - LR: 8.00e-05\n",
      "\tEpoch 30/100 - Train loss: 0.2428 - Val accuracy: 0.2857 - Val loss: 1.2286 - Val F1: 0.1270 - LR: 7.00e-05\n",
      "\tEpoch 40/100 - Train loss: 0.1798 - Val accuracy: 0.2857 - Val loss: 1.1741 - Val F1: 0.1270 - LR: 6.00e-05\n",
      "\tEpoch 50/100 - Train loss: 0.1393 - Val accuracy: 0.8571 - Val loss: 0.7163 - Val F1: 0.8000 - LR: 5.00e-05\n",
      "\tEpoch 60/100 - Train loss: 0.1008 - Val accuracy: 0.8571 - Val loss: 0.4349 - Val F1: 0.8000 - LR: 4.00e-05\n",
      "\tEpoch 70/100 - Train loss: 0.0945 - Val accuracy: 0.8571 - Val loss: 0.3674 - Val F1: 0.8000 - LR: 3.00e-05\n",
      "\tEpoch 80/100 - Train loss: 0.0805 - Val accuracy: 0.8571 - Val loss: 0.3482 - Val F1: 0.8000 - LR: 2.00e-05\n",
      "\tEpoch 90/100 - Train loss: 0.0825 - Val accuracy: 0.8571 - Val loss: 0.3413 - Val F1: 0.8000 - LR: 1.00e-05\n",
      "\tEpoch 100/100 - Train loss: 0.0686 - Val accuracy: 0.8571 - Val loss: 0.3386 - Val F1: 0.8000 - LR: 0.00e+00\n",
      "\tBest epoch: 100 - Best val accuracy: 0.8571 - Best val loss: 0.3386 - Best val F1: 0.8000\n",
      "\n",
      "\tEpoch 10/100 - Train loss: 0.5453 - Val accuracy: 0.2857 - Val loss: 1.0765 - Val F1: 0.1270 - LR: 9.00e-05\n",
      "\tEpoch 20/100 - Train loss: 0.3624 - Val accuracy: 0.2857 - Val loss: 1.1583 - Val F1: 0.1270 - LR: 8.00e-05\n",
      "\tEpoch 30/100 - Train loss: 0.2550 - Val accuracy: 0.2857 - Val loss: 1.3336 - Val F1: 0.1270 - LR: 7.00e-05\n",
      "\tEpoch 40/100 - Train loss: 0.1833 - Val accuracy: 0.2857 - Val loss: 1.3156 - Val F1: 0.1270 - LR: 6.00e-05\n",
      "\tEpoch 50/100 - Train loss: 0.1447 - Val accuracy: 0.7143 - Val loss: 0.8005 - Val F1: 0.6803 - LR: 5.00e-05\n",
      "\tEpoch 60/100 - Train loss: 0.1184 - Val accuracy: 0.8571 - Val loss: 0.4992 - Val F1: 0.8000 - LR: 4.00e-05\n",
      "\tEpoch 70/100 - Train loss: 0.1019 - Val accuracy: 0.8571 - Val loss: 0.4166 - Val F1: 0.8000 - LR: 3.00e-05\n",
      "\tEpoch 80/100 - Train loss: 0.0834 - Val accuracy: 0.8571 - Val loss: 0.3924 - Val F1: 0.8000 - LR: 2.00e-05\n",
      "\tEpoch 90/100 - Train loss: 0.0830 - Val accuracy: 0.8571 - Val loss: 0.3845 - Val F1: 0.8000 - LR: 1.00e-05\n",
      "\tEpoch 100/100 - Train loss: 0.0767 - Val accuracy: 0.8571 - Val loss: 0.3813 - Val F1: 0.8000 - LR: 0.00e+00\n",
      "\tBest epoch: 100 - Best val accuracy: 0.8571 - Best val loss: 0.3813 - Best val F1: 0.8000\n",
      "\n",
      "\tEpoch 10/100 - Train loss: 0.5984 - Val accuracy: 0.2857 - Val loss: 1.0933 - Val F1: 0.1270 - LR: 9.00e-05\n",
      "\tEpoch 20/100 - Train loss: 0.3891 - Val accuracy: 0.2857 - Val loss: 1.1333 - Val F1: 0.1270 - LR: 8.00e-05\n",
      "\tEpoch 30/100 - Train loss: 0.2706 - Val accuracy: 0.2857 - Val loss: 1.2226 - Val F1: 0.1270 - LR: 7.00e-05\n",
      "\tEpoch 40/100 - Train loss: 0.2093 - Val accuracy: 0.2857 - Val loss: 1.1551 - Val F1: 0.1270 - LR: 6.00e-05\n",
      "\tEpoch 50/100 - Train loss: 0.1627 - Val accuracy: 0.8571 - Val loss: 0.6788 - Val F1: 0.8000 - LR: 5.00e-05\n",
      "\tEpoch 60/100 - Train loss: 0.1353 - Val accuracy: 0.8571 - Val loss: 0.4033 - Val F1: 0.8000 - LR: 4.00e-05\n",
      "\tEpoch 70/100 - Train loss: 0.1083 - Val accuracy: 0.8571 - Val loss: 0.3376 - Val F1: 0.8000 - LR: 3.00e-05\n",
      "\tEpoch 80/100 - Train loss: 0.0896 - Val accuracy: 0.8571 - Val loss: 0.3195 - Val F1: 0.8000 - LR: 2.00e-05\n",
      "\tEpoch 90/100 - Train loss: 0.0993 - Val accuracy: 0.8571 - Val loss: 0.3127 - Val F1: 0.8000 - LR: 1.00e-05\n",
      "\tEpoch 100/100 - Train loss: 0.0895 - Val accuracy: 0.8571 - Val loss: 0.3104 - Val F1: 0.8000 - LR: 0.00e+00\n",
      "\tBest epoch: 100 - Best val accuracy: 0.8571 - Best val loss: 0.3104 - Best val F1: 0.8000\n",
      "\n",
      "\tEpoch 10/100 - Train loss: 0.5228 - Val accuracy: 0.7143 - Val loss: 1.0476 - Val F1: 0.5952 - LR: 9.00e-05\n",
      "\tEpoch 20/100 - Train loss: 0.3417 - Val accuracy: 0.1429 - Val loss: 1.2028 - Val F1: 0.0357 - LR: 8.00e-05\n",
      "\tEpoch 30/100 - Train loss: 0.2646 - Val accuracy: 0.1429 - Val loss: 1.4315 - Val F1: 0.0357 - LR: 7.00e-05\n",
      "\tEpoch 40/100 - Train loss: 0.2031 - Val accuracy: 0.1429 - Val loss: 1.4550 - Val F1: 0.0357 - LR: 6.00e-05\n",
      "\tEpoch 50/100 - Train loss: 0.1742 - Val accuracy: 0.7143 - Val loss: 0.8150 - Val F1: 0.7063 - LR: 5.00e-05\n",
      "\tEpoch 60/100 - Train loss: 0.1514 - Val accuracy: 0.8571 - Val loss: 0.3219 - Val F1: 0.8095 - LR: 4.00e-05\n",
      "\tEpoch 70/100 - Train loss: 0.1265 - Val accuracy: 0.8571 - Val loss: 0.2368 - Val F1: 0.8095 - LR: 3.00e-05\n",
      "\tEpoch 80/100 - Train loss: 0.1098 - Val accuracy: 0.8571 - Val loss: 0.2162 - Val F1: 0.8095 - LR: 2.00e-05\n",
      "\tEpoch 90/100 - Train loss: 0.1100 - Val accuracy: 0.8571 - Val loss: 0.2098 - Val F1: 0.8095 - LR: 1.00e-05\n",
      "\tEpoch 100/100 - Train loss: 0.0960 - Val accuracy: 0.8571 - Val loss: 0.2083 - Val F1: 0.8095 - LR: 0.00e+00\n",
      "\tBest epoch: 100 - Best val accuracy: 0.8571 - Best val loss: 0.2083 - Best val F1: 0.8095\n",
      "\n",
      "\tEpoch 10/100 - Train loss: 0.5690 - Val accuracy: 0.2500 - Val loss: 1.0825 - Val F1: 0.1000 - LR: 9.00e-05\n",
      "\tEpoch 20/100 - Train loss: 0.3596 - Val accuracy: 0.2500 - Val loss: 1.1286 - Val F1: 0.1000 - LR: 8.00e-05\n",
      "\tEpoch 30/100 - Train loss: 0.2546 - Val accuracy: 0.2500 - Val loss: 1.2648 - Val F1: 0.1000 - LR: 7.00e-05\n",
      "\tEpoch 40/100 - Train loss: 0.1886 - Val accuracy: 0.2500 - Val loss: 1.1928 - Val F1: 0.1000 - LR: 6.00e-05\n",
      "\tEpoch 50/100 - Train loss: 0.1513 - Val accuracy: 0.8750 - Val loss: 0.5700 - Val F1: 0.8250 - LR: 5.00e-05\n",
      "\tEpoch 60/100 - Train loss: 0.1241 - Val accuracy: 1.0000 - Val loss: 0.2871 - Val F1: 1.0000 - LR: 4.00e-05\n",
      "\tEpoch 70/100 - Train loss: 0.1053 - Val accuracy: 1.0000 - Val loss: 0.2465 - Val F1: 1.0000 - LR: 3.00e-05\n",
      "\tEpoch 80/100 - Train loss: 0.0814 - Val accuracy: 1.0000 - Val loss: 0.2381 - Val F1: 1.0000 - LR: 2.00e-05\n",
      "\tEpoch 90/100 - Train loss: 0.0842 - Val accuracy: 1.0000 - Val loss: 0.2352 - Val F1: 1.0000 - LR: 1.00e-05\n",
      "\tEpoch 100/100 - Train loss: 0.0735 - Val accuracy: 1.0000 - Val loss: 0.2348 - Val F1: 1.0000 - LR: 0.00e+00\n",
      "\tBest epoch: 98 - Best val accuracy: 1.0000 - Best val loss: 0.2347 - Best val F1: 1.0000\n",
      "\n",
      "Source class: WAL | Domain: 47 | Accuracy: 0.8861 | Loss: 0.3013 | F1: 0.8493\n",
      "\n",
      "Domain: 48\n",
      "x_dp_dom.shape: (48, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Training and evaluating on Dp data via cross-validation...\n",
      "\tEpoch 10/100 - Train loss: 0.5341 - Val accuracy: 0.1250 - Val loss: 1.1088 - Val F1: 0.0357 - LR: 9.00e-05\n",
      "\tEpoch 20/100 - Train loss: 0.3225 - Val accuracy: 0.2500 - Val loss: 1.2696 - Val F1: 0.1000 - LR: 8.00e-05\n",
      "\tEpoch 30/100 - Train loss: 0.2369 - Val accuracy: 0.2500 - Val loss: 1.5044 - Val F1: 0.1000 - LR: 7.00e-05\n",
      "\tEpoch 40/100 - Train loss: 0.1778 - Val accuracy: 0.2500 - Val loss: 1.3332 - Val F1: 0.1000 - LR: 6.00e-05\n",
      "\tEpoch 50/100 - Train loss: 0.1448 - Val accuracy: 0.7500 - Val loss: 0.6297 - Val F1: 0.7222 - LR: 5.00e-05\n",
      "\tEpoch 60/100 - Train loss: 0.1154 - Val accuracy: 0.8750 - Val loss: 0.3306 - Val F1: 0.8250 - LR: 4.00e-05\n",
      "\tEpoch 70/100 - Train loss: 0.0965 - Val accuracy: 0.8750 - Val loss: 0.2626 - Val F1: 0.8250 - LR: 3.00e-05\n",
      "\tEpoch 80/100 - Train loss: 0.0792 - Val accuracy: 0.8750 - Val loss: 0.2406 - Val F1: 0.8250 - LR: 2.00e-05\n",
      "\tEpoch 90/100 - Train loss: 0.0690 - Val accuracy: 0.8750 - Val loss: 0.2323 - Val F1: 0.8250 - LR: 1.00e-05\n",
      "\tEpoch 100/100 - Train loss: 0.0654 - Val accuracy: 0.8750 - Val loss: 0.2295 - Val F1: 0.8250 - LR: 0.00e+00\n",
      "\tBest epoch: 100 - Best val accuracy: 0.8750 - Best val loss: 0.2295 - Best val F1: 0.8250\n",
      "\n",
      "\tEpoch 10/100 - Train loss: 0.5910 - Val accuracy: 0.2500 - Val loss: 1.1674 - Val F1: 0.1000 - LR: 9.00e-05\n",
      "\tEpoch 20/100 - Train loss: 0.3726 - Val accuracy: 0.2500 - Val loss: 1.3229 - Val F1: 0.1000 - LR: 8.00e-05\n",
      "\tEpoch 30/100 - Train loss: 0.2699 - Val accuracy: 0.2500 - Val loss: 1.5481 - Val F1: 0.1000 - LR: 7.00e-05\n",
      "\tEpoch 40/100 - Train loss: 0.2058 - Val accuracy: 0.2500 - Val loss: 1.2011 - Val F1: 0.1250 - LR: 6.00e-05\n",
      "\tEpoch 50/100 - Train loss: 0.1601 - Val accuracy: 0.8750 - Val loss: 0.4366 - Val F1: 0.8250 - LR: 5.00e-05\n",
      "\tEpoch 60/100 - Train loss: 0.1302 - Val accuracy: 0.8750 - Val loss: 0.2500 - Val F1: 0.8250 - LR: 4.00e-05\n",
      "\tEpoch 70/100 - Train loss: 0.1046 - Val accuracy: 0.8750 - Val loss: 0.2095 - Val F1: 0.8250 - LR: 3.00e-05\n",
      "\tEpoch 80/100 - Train loss: 0.1000 - Val accuracy: 1.0000 - Val loss: 0.1929 - Val F1: 1.0000 - LR: 2.00e-05\n",
      "\tEpoch 90/100 - Train loss: 0.0889 - Val accuracy: 1.0000 - Val loss: 0.1848 - Val F1: 1.0000 - LR: 1.00e-05\n",
      "\tEpoch 100/100 - Train loss: 0.0842 - Val accuracy: 1.0000 - Val loss: 0.1818 - Val F1: 1.0000 - LR: 0.00e+00\n",
      "\tBest epoch: 100 - Best val accuracy: 1.0000 - Best val loss: 0.1818 - Best val F1: 1.0000\n",
      "\n",
      "\tEpoch 10/100 - Train loss: 0.6283 - Val accuracy: 0.2500 - Val loss: 1.1218 - Val F1: 0.1000 - LR: 9.00e-05\n",
      "\tEpoch 20/100 - Train loss: 0.3677 - Val accuracy: 0.2500 - Val loss: 1.2086 - Val F1: 0.1000 - LR: 8.00e-05\n",
      "\tEpoch 30/100 - Train loss: 0.2444 - Val accuracy: 0.2500 - Val loss: 1.3170 - Val F1: 0.1000 - LR: 7.00e-05\n",
      "\tEpoch 40/100 - Train loss: 0.1762 - Val accuracy: 0.7500 - Val loss: 0.9208 - Val F1: 0.7222 - LR: 6.00e-05\n",
      "\tEpoch 50/100 - Train loss: 0.1230 - Val accuracy: 0.8750 - Val loss: 0.3687 - Val F1: 0.8250 - LR: 5.00e-05\n",
      "\tEpoch 60/100 - Train loss: 0.1007 - Val accuracy: 1.0000 - Val loss: 0.2162 - Val F1: 1.0000 - LR: 4.00e-05\n",
      "\tEpoch 70/100 - Train loss: 0.0800 - Val accuracy: 1.0000 - Val loss: 0.1721 - Val F1: 1.0000 - LR: 3.00e-05\n",
      "\tEpoch 80/100 - Train loss: 0.0675 - Val accuracy: 1.0000 - Val loss: 0.1524 - Val F1: 1.0000 - LR: 2.00e-05\n",
      "\tEpoch 90/100 - Train loss: 0.0667 - Val accuracy: 1.0000 - Val loss: 0.1429 - Val F1: 1.0000 - LR: 1.00e-05\n",
      "\tEpoch 100/100 - Train loss: 0.0596 - Val accuracy: 1.0000 - Val loss: 0.1392 - Val F1: 1.0000 - LR: 0.00e+00\n",
      "\tBest epoch: 100 - Best val accuracy: 1.0000 - Best val loss: 0.1392 - Best val F1: 1.0000\n",
      "\n",
      "\tEpoch 10/100 - Train loss: 0.5228 - Val accuracy: 0.2500 - Val loss: 1.1191 - Val F1: 0.1000 - LR: 9.00e-05\n",
      "\tEpoch 20/100 - Train loss: 0.3248 - Val accuracy: 0.2500 - Val loss: 1.2690 - Val F1: 0.1000 - LR: 8.00e-05\n",
      "\tEpoch 30/100 - Train loss: 0.2369 - Val accuracy: 0.2500 - Val loss: 1.4398 - Val F1: 0.1000 - LR: 7.00e-05\n",
      "\tEpoch 40/100 - Train loss: 0.1663 - Val accuracy: 0.2500 - Val loss: 1.1601 - Val F1: 0.1000 - LR: 6.00e-05\n",
      "\tEpoch 50/100 - Train loss: 0.1450 - Val accuracy: 0.8750 - Val loss: 0.4759 - Val F1: 0.8250 - LR: 5.00e-05\n",
      "\tEpoch 60/100 - Train loss: 0.1120 - Val accuracy: 0.8750 - Val loss: 0.2866 - Val F1: 0.8250 - LR: 4.00e-05\n",
      "\tEpoch 70/100 - Train loss: 0.0884 - Val accuracy: 0.8750 - Val loss: 0.2540 - Val F1: 0.8250 - LR: 3.00e-05\n",
      "\tEpoch 80/100 - Train loss: 0.0743 - Val accuracy: 0.8750 - Val loss: 0.2447 - Val F1: 0.8250 - LR: 2.00e-05\n",
      "\tEpoch 90/100 - Train loss: 0.0708 - Val accuracy: 0.8750 - Val loss: 0.2413 - Val F1: 0.8250 - LR: 1.00e-05\n",
      "\tEpoch 100/100 - Train loss: 0.0707 - Val accuracy: 0.8750 - Val loss: 0.2403 - Val F1: 0.8250 - LR: 0.00e+00\n",
      "\tBest epoch: 100 - Best val accuracy: 0.8750 - Best val loss: 0.2403 - Best val F1: 0.8250\n",
      "\n",
      "\tEpoch 10/100 - Train loss: 0.5394 - Val accuracy: 0.2500 - Val loss: 1.0910 - Val F1: 0.1000 - LR: 9.00e-05\n",
      "\tEpoch 20/100 - Train loss: 0.3186 - Val accuracy: 0.2500 - Val loss: 1.2002 - Val F1: 0.1000 - LR: 8.00e-05\n",
      "\tEpoch 30/100 - Train loss: 0.2184 - Val accuracy: 0.2500 - Val loss: 1.3953 - Val F1: 0.1000 - LR: 7.00e-05\n",
      "\tEpoch 40/100 - Train loss: 0.1530 - Val accuracy: 0.2500 - Val loss: 1.2440 - Val F1: 0.1000 - LR: 6.00e-05\n",
      "\tEpoch 50/100 - Train loss: 0.1096 - Val accuracy: 0.7500 - Val loss: 0.5603 - Val F1: 0.7556 - LR: 5.00e-05\n",
      "\tEpoch 60/100 - Train loss: 0.0826 - Val accuracy: 0.8750 - Val loss: 0.2833 - Val F1: 0.8250 - LR: 4.00e-05\n",
      "\tEpoch 70/100 - Train loss: 0.0754 - Val accuracy: 0.8750 - Val loss: 0.2126 - Val F1: 0.8250 - LR: 3.00e-05\n",
      "\tEpoch 80/100 - Train loss: 0.0650 - Val accuracy: 0.8750 - Val loss: 0.1881 - Val F1: 0.8250 - LR: 2.00e-05\n",
      "\tEpoch 90/100 - Train loss: 0.0545 - Val accuracy: 0.8750 - Val loss: 0.1785 - Val F1: 0.8250 - LR: 1.00e-05\n",
      "\tEpoch 100/100 - Train loss: 0.0508 - Val accuracy: 0.8750 - Val loss: 0.1758 - Val F1: 0.8250 - LR: 0.00e+00\n",
      "\tBest epoch: 100 - Best val accuracy: 0.8750 - Best val loss: 0.1758 - Best val F1: 0.8250\n",
      "\n",
      "Source class: WAL | Domain: 48 | Accuracy: 0.8956 | Loss: 0.2436 | F1: 0.8741\n",
      "\n",
      "Domain: 49\n",
      "x_dp_dom.shape: (53, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Training and evaluating on Dp data via cross-validation...\n",
      "\tEpoch 10/100 - Train loss: 0.6173 - Val accuracy: 0.2222 - Val loss: 1.1115 - Val F1: 0.0808 - LR: 9.00e-05\n",
      "\tEpoch 20/100 - Train loss: 0.3650 - Val accuracy: 0.2222 - Val loss: 1.2243 - Val F1: 0.0808 - LR: 8.00e-05\n",
      "\tEpoch 30/100 - Train loss: 0.2185 - Val accuracy: 0.2222 - Val loss: 1.4322 - Val F1: 0.0808 - LR: 7.00e-05\n",
      "\tEpoch 40/100 - Train loss: 0.1583 - Val accuracy: 0.2222 - Val loss: 1.4591 - Val F1: 0.0808 - LR: 6.00e-05\n",
      "\tEpoch 50/100 - Train loss: 0.1018 - Val accuracy: 0.5556 - Val loss: 0.9274 - Val F1: 0.5278 - LR: 5.00e-05\n",
      "\tEpoch 60/100 - Train loss: 0.0773 - Val accuracy: 0.7778 - Val loss: 0.4770 - Val F1: 0.7901 - LR: 4.00e-05\n",
      "\tEpoch 70/100 - Train loss: 0.0627 - Val accuracy: 0.8889 - Val loss: 0.3098 - Val F1: 0.8815 - LR: 3.00e-05\n",
      "\tEpoch 80/100 - Train loss: 0.0561 - Val accuracy: 1.0000 - Val loss: 0.2561 - Val F1: 1.0000 - LR: 2.00e-05\n",
      "\tEpoch 90/100 - Train loss: 0.0521 - Val accuracy: 1.0000 - Val loss: 0.2361 - Val F1: 1.0000 - LR: 1.00e-05\n",
      "\tEpoch 100/100 - Train loss: 0.0510 - Val accuracy: 1.0000 - Val loss: 0.2301 - Val F1: 1.0000 - LR: 0.00e+00\n",
      "\tBest epoch: 100 - Best val accuracy: 1.0000 - Best val loss: 0.2301 - Best val F1: 1.0000\n",
      "\n",
      "\tEpoch 10/100 - Train loss: 0.6901 - Val accuracy: 0.2222 - Val loss: 1.1122 - Val F1: 0.0808 - LR: 9.00e-05\n",
      "\tEpoch 20/100 - Train loss: 0.3980 - Val accuracy: 0.2222 - Val loss: 1.1974 - Val F1: 0.0808 - LR: 8.00e-05\n",
      "\tEpoch 30/100 - Train loss: 0.2604 - Val accuracy: 0.2222 - Val loss: 1.3797 - Val F1: 0.0808 - LR: 7.00e-05\n",
      "\tEpoch 40/100 - Train loss: 0.1774 - Val accuracy: 0.2222 - Val loss: 1.3983 - Val F1: 0.0808 - LR: 6.00e-05\n",
      "\tEpoch 50/100 - Train loss: 0.1223 - Val accuracy: 0.4444 - Val loss: 0.8866 - Val F1: 0.4162 - LR: 5.00e-05\n",
      "\tEpoch 60/100 - Train loss: 0.0920 - Val accuracy: 0.8889 - Val loss: 0.4115 - Val F1: 0.8815 - LR: 4.00e-05\n",
      "\tEpoch 70/100 - Train loss: 0.0780 - Val accuracy: 0.8889 - Val loss: 0.2452 - Val F1: 0.8815 - LR: 3.00e-05\n",
      "\tEpoch 80/100 - Train loss: 0.0725 - Val accuracy: 0.8889 - Val loss: 0.1999 - Val F1: 0.8815 - LR: 2.00e-05\n",
      "\tEpoch 90/100 - Train loss: 0.0549 - Val accuracy: 0.8889 - Val loss: 0.1843 - Val F1: 0.8815 - LR: 1.00e-05\n",
      "\tEpoch 100/100 - Train loss: 0.0554 - Val accuracy: 0.8889 - Val loss: 0.1796 - Val F1: 0.8815 - LR: 0.00e+00\n",
      "\tBest epoch: 100 - Best val accuracy: 0.8889 - Best val loss: 0.1796 - Best val F1: 0.8815\n",
      "\n",
      "\tEpoch 10/100 - Train loss: 0.6967 - Val accuracy: 0.5556 - Val loss: 1.0917 - Val F1: 0.3968 - LR: 9.00e-05\n",
      "\tEpoch 20/100 - Train loss: 0.4445 - Val accuracy: 0.2222 - Val loss: 1.1548 - Val F1: 0.0808 - LR: 8.00e-05\n",
      "\tEpoch 30/100 - Train loss: 0.3038 - Val accuracy: 0.2222 - Val loss: 1.3009 - Val F1: 0.0808 - LR: 7.00e-05\n",
      "\tEpoch 40/100 - Train loss: 0.1937 - Val accuracy: 0.3333 - Val loss: 1.3379 - Val F1: 0.2370 - LR: 6.00e-05\n",
      "\tEpoch 50/100 - Train loss: 0.1499 - Val accuracy: 0.5556 - Val loss: 0.8853 - Val F1: 0.5767 - LR: 5.00e-05\n",
      "\tEpoch 60/100 - Train loss: 0.1026 - Val accuracy: 0.8889 - Val loss: 0.4221 - Val F1: 0.8815 - LR: 4.00e-05\n",
      "\tEpoch 70/100 - Train loss: 0.0880 - Val accuracy: 0.7778 - Val loss: 0.3134 - Val F1: 0.7778 - LR: 3.00e-05\n",
      "\tEpoch 80/100 - Train loss: 0.0768 - Val accuracy: 0.7778 - Val loss: 0.2967 - Val F1: 0.7778 - LR: 2.00e-05\n",
      "\tEpoch 90/100 - Train loss: 0.0678 - Val accuracy: 0.7778 - Val loss: 0.2932 - Val F1: 0.7778 - LR: 1.00e-05\n",
      "\tEpoch 100/100 - Train loss: 0.0676 - Val accuracy: 0.7778 - Val loss: 0.2923 - Val F1: 0.7778 - LR: 0.00e+00\n",
      "\tBest epoch: 100 - Best val accuracy: 0.7778 - Best val loss: 0.2923 - Best val F1: 0.7778\n",
      "\n",
      "\tEpoch 10/100 - Train loss: 0.5987 - Val accuracy: 0.2222 - Val loss: 1.0986 - Val F1: 0.0808 - LR: 9.00e-05\n",
      "\tEpoch 20/100 - Train loss: 0.3558 - Val accuracy: 0.2222 - Val loss: 1.1806 - Val F1: 0.0808 - LR: 8.00e-05\n",
      "\tEpoch 30/100 - Train loss: 0.2285 - Val accuracy: 0.2222 - Val loss: 1.3332 - Val F1: 0.0808 - LR: 7.00e-05\n",
      "\tEpoch 40/100 - Train loss: 0.1390 - Val accuracy: 0.3333 - Val loss: 1.4522 - Val F1: 0.2370 - LR: 6.00e-05\n",
      "\tEpoch 50/100 - Train loss: 0.0999 - Val accuracy: 0.4444 - Val loss: 1.0927 - Val F1: 0.4321 - LR: 5.00e-05\n",
      "\tEpoch 60/100 - Train loss: 0.0760 - Val accuracy: 1.0000 - Val loss: 0.3979 - Val F1: 1.0000 - LR: 4.00e-05\n",
      "\tEpoch 70/100 - Train loss: 0.0663 - Val accuracy: 1.0000 - Val loss: 0.1959 - Val F1: 1.0000 - LR: 3.00e-05\n",
      "\tEpoch 80/100 - Train loss: 0.0461 - Val accuracy: 1.0000 - Val loss: 0.1562 - Val F1: 1.0000 - LR: 2.00e-05\n",
      "\tEpoch 90/100 - Train loss: 0.0427 - Val accuracy: 1.0000 - Val loss: 0.1445 - Val F1: 1.0000 - LR: 1.00e-05\n",
      "\tEpoch 100/100 - Train loss: 0.0419 - Val accuracy: 1.0000 - Val loss: 0.1409 - Val F1: 1.0000 - LR: 0.00e+00\n",
      "\tBest epoch: 100 - Best val accuracy: 1.0000 - Best val loss: 0.1409 - Best val F1: 1.0000\n",
      "\n",
      "\tEpoch 10/100 - Train loss: 0.6308 - Val accuracy: 0.2222 - Val loss: 1.1110 - Val F1: 0.0808 - LR: 9.00e-05\n",
      "\tEpoch 20/100 - Train loss: 0.4076 - Val accuracy: 0.2222 - Val loss: 1.1797 - Val F1: 0.0808 - LR: 8.00e-05\n",
      "\tEpoch 30/100 - Train loss: 0.2732 - Val accuracy: 0.3333 - Val loss: 1.3262 - Val F1: 0.2370 - LR: 7.00e-05\n",
      "\tEpoch 40/100 - Train loss: 0.2023 - Val accuracy: 0.3333 - Val loss: 1.3660 - Val F1: 0.2370 - LR: 6.00e-05\n",
      "\tEpoch 50/100 - Train loss: 0.1412 - Val accuracy: 0.5556 - Val loss: 0.8771 - Val F1: 0.5556 - LR: 5.00e-05\n",
      "\tEpoch 60/100 - Train loss: 0.1173 - Val accuracy: 1.0000 - Val loss: 0.4071 - Val F1: 1.0000 - LR: 4.00e-05\n",
      "\tEpoch 70/100 - Train loss: 0.0868 - Val accuracy: 1.0000 - Val loss: 0.2509 - Val F1: 1.0000 - LR: 3.00e-05\n",
      "\tEpoch 80/100 - Train loss: 0.0864 - Val accuracy: 1.0000 - Val loss: 0.2035 - Val F1: 1.0000 - LR: 2.00e-05\n",
      "\tEpoch 90/100 - Train loss: 0.0721 - Val accuracy: 1.0000 - Val loss: 0.1867 - Val F1: 1.0000 - LR: 1.00e-05\n",
      "\tEpoch 100/100 - Train loss: 0.0714 - Val accuracy: 1.0000 - Val loss: 0.1807 - Val F1: 1.0000 - LR: 0.00e+00\n",
      "\tBest epoch: 100 - Best val accuracy: 1.0000 - Best val loss: 0.1807 - Best val F1: 1.0000\n",
      "\n",
      "Source class: WAL | Domain: 49 | Accuracy: 0.9818 | Loss: 0.1669 | F1: 0.9818\n",
      "\n",
      "Domain: 50\n",
      "x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Training and evaluating on Dp data via cross-validation...\n",
      "\tEpoch 10/100 - Train loss: 0.5117 - Val accuracy: 0.7143 - Val loss: 1.0463 - Val F1: 0.5952 - LR: 9.00e-05\n",
      "\tEpoch 20/100 - Train loss: 0.3152 - Val accuracy: 0.1429 - Val loss: 1.1636 - Val F1: 0.0357 - LR: 8.00e-05\n",
      "\tEpoch 30/100 - Train loss: 0.2090 - Val accuracy: 0.1429 - Val loss: 1.4277 - Val F1: 0.0357 - LR: 7.00e-05\n",
      "\tEpoch 40/100 - Train loss: 0.1422 - Val accuracy: 0.1429 - Val loss: 1.3386 - Val F1: 0.0408 - LR: 6.00e-05\n",
      "\tEpoch 50/100 - Train loss: 0.1139 - Val accuracy: 0.8571 - Val loss: 0.6402 - Val F1: 0.8095 - LR: 5.00e-05\n",
      "\tEpoch 60/100 - Train loss: 0.0796 - Val accuracy: 0.8571 - Val loss: 0.2743 - Val F1: 0.8095 - LR: 4.00e-05\n",
      "\tEpoch 70/100 - Train loss: 0.0687 - Val accuracy: 0.8571 - Val loss: 0.1863 - Val F1: 0.8095 - LR: 3.00e-05\n",
      "\tEpoch 80/100 - Train loss: 0.0576 - Val accuracy: 0.8571 - Val loss: 0.1597 - Val F1: 0.8095 - LR: 2.00e-05\n",
      "\tEpoch 90/100 - Train loss: 0.0646 - Val accuracy: 0.8571 - Val loss: 0.1494 - Val F1: 0.8095 - LR: 1.00e-05\n",
      "\tEpoch 100/100 - Train loss: 0.0530 - Val accuracy: 0.8571 - Val loss: 0.1459 - Val F1: 0.8095 - LR: 0.00e+00\n",
      "\tBest epoch: 100 - Best val accuracy: 0.8571 - Best val loss: 0.1459 - Best val F1: 0.8095\n",
      "\n",
      "\tEpoch 10/100 - Train loss: 0.5802 - Val accuracy: 0.7143 - Val loss: 1.0521 - Val F1: 0.5952 - LR: 9.00e-05\n",
      "\tEpoch 20/100 - Train loss: 0.3707 - Val accuracy: 0.1429 - Val loss: 1.1412 - Val F1: 0.0357 - LR: 8.00e-05\n",
      "\tEpoch 30/100 - Train loss: 0.2776 - Val accuracy: 0.1429 - Val loss: 1.2946 - Val F1: 0.0357 - LR: 7.00e-05\n",
      "\tEpoch 40/100 - Train loss: 0.1934 - Val accuracy: 0.4286 - Val loss: 1.0077 - Val F1: 0.4653 - LR: 6.00e-05\n",
      "\tEpoch 50/100 - Train loss: 0.1405 - Val accuracy: 0.8571 - Val loss: 0.3937 - Val F1: 0.8095 - LR: 5.00e-05\n",
      "\tEpoch 60/100 - Train loss: 0.1125 - Val accuracy: 1.0000 - Val loss: 0.1889 - Val F1: 1.0000 - LR: 4.00e-05\n",
      "\tEpoch 70/100 - Train loss: 0.0927 - Val accuracy: 1.0000 - Val loss: 0.1367 - Val F1: 1.0000 - LR: 3.00e-05\n",
      "\tEpoch 80/100 - Train loss: 0.0843 - Val accuracy: 1.0000 - Val loss: 0.1174 - Val F1: 1.0000 - LR: 2.00e-05\n",
      "\tEpoch 90/100 - Train loss: 0.0673 - Val accuracy: 1.0000 - Val loss: 0.1091 - Val F1: 1.0000 - LR: 1.00e-05\n",
      "\tEpoch 100/100 - Train loss: 0.0652 - Val accuracy: 1.0000 - Val loss: 0.1063 - Val F1: 1.0000 - LR: 0.00e+00\n",
      "\tBest epoch: 100 - Best val accuracy: 1.0000 - Best val loss: 0.1063 - Best val F1: 1.0000\n",
      "\n",
      "\tEpoch 10/100 - Train loss: 0.5398 - Val accuracy: 0.1429 - Val loss: 1.1107 - Val F1: 0.0357 - LR: 9.00e-05\n",
      "\tEpoch 20/100 - Train loss: 0.3522 - Val accuracy: 0.1429 - Val loss: 1.2240 - Val F1: 0.0357 - LR: 8.00e-05\n",
      "\tEpoch 30/100 - Train loss: 0.2673 - Val accuracy: 0.1429 - Val loss: 1.2685 - Val F1: 0.0357 - LR: 7.00e-05\n",
      "\tEpoch 40/100 - Train loss: 0.1934 - Val accuracy: 0.7143 - Val loss: 0.7818 - Val F1: 0.7302 - LR: 6.00e-05\n",
      "\tEpoch 50/100 - Train loss: 0.1534 - Val accuracy: 0.8571 - Val loss: 0.3434 - Val F1: 0.8095 - LR: 5.00e-05\n",
      "\tEpoch 60/100 - Train loss: 0.1122 - Val accuracy: 0.8571 - Val loss: 0.2183 - Val F1: 0.8095 - LR: 4.00e-05\n",
      "\tEpoch 70/100 - Train loss: 0.0966 - Val accuracy: 1.0000 - Val loss: 0.1783 - Val F1: 1.0000 - LR: 3.00e-05\n",
      "\tEpoch 80/100 - Train loss: 0.0838 - Val accuracy: 1.0000 - Val loss: 0.1610 - Val F1: 1.0000 - LR: 2.00e-05\n",
      "\tEpoch 90/100 - Train loss: 0.0789 - Val accuracy: 1.0000 - Val loss: 0.1530 - Val F1: 1.0000 - LR: 1.00e-05\n",
      "\tEpoch 100/100 - Train loss: 0.0758 - Val accuracy: 1.0000 - Val loss: 0.1496 - Val F1: 1.0000 - LR: 0.00e+00\n",
      "\tBest epoch: 100 - Best val accuracy: 1.0000 - Best val loss: 0.1496 - Best val F1: 1.0000\n",
      "\n",
      "\tEpoch 10/100 - Train loss: 0.6086 - Val accuracy: 0.7143 - Val loss: 1.0304 - Val F1: 0.5952 - LR: 9.00e-05\n",
      "\tEpoch 20/100 - Train loss: 0.3954 - Val accuracy: 0.7143 - Val loss: 1.0391 - Val F1: 0.5952 - LR: 8.00e-05\n",
      "\tEpoch 30/100 - Train loss: 0.2576 - Val accuracy: 0.4286 - Val loss: 1.0147 - Val F1: 0.4558 - LR: 7.00e-05\n",
      "\tEpoch 40/100 - Train loss: 0.1756 - Val accuracy: 0.7143 - Val loss: 0.6839 - Val F1: 0.7063 - LR: 6.00e-05\n",
      "\tEpoch 50/100 - Train loss: 0.1320 - Val accuracy: 1.0000 - Val loss: 0.3709 - Val F1: 1.0000 - LR: 5.00e-05\n",
      "\tEpoch 60/100 - Train loss: 0.0979 - Val accuracy: 1.0000 - Val loss: 0.2387 - Val F1: 1.0000 - LR: 4.00e-05\n",
      "\tEpoch 70/100 - Train loss: 0.0772 - Val accuracy: 1.0000 - Val loss: 0.1903 - Val F1: 1.0000 - LR: 3.00e-05\n",
      "\tEpoch 80/100 - Train loss: 0.0625 - Val accuracy: 1.0000 - Val loss: 0.1701 - Val F1: 1.0000 - LR: 2.00e-05\n",
      "\tEpoch 90/100 - Train loss: 0.0654 - Val accuracy: 1.0000 - Val loss: 0.1610 - Val F1: 1.0000 - LR: 1.00e-05\n",
      "\tEpoch 100/100 - Train loss: 0.0655 - Val accuracy: 1.0000 - Val loss: 0.1573 - Val F1: 1.0000 - LR: 0.00e+00\n",
      "\tBest epoch: 100 - Best val accuracy: 1.0000 - Best val loss: 0.1573 - Best val F1: 1.0000\n",
      "\n",
      "\tEpoch 10/100 - Train loss: 0.5444 - Val accuracy: 0.1429 - Val loss: 1.0757 - Val F1: 0.0357 - LR: 9.00e-05\n",
      "\tEpoch 20/100 - Train loss: 0.3578 - Val accuracy: 0.1429 - Val loss: 1.1246 - Val F1: 0.0357 - LR: 8.00e-05\n",
      "\tEpoch 30/100 - Train loss: 0.2505 - Val accuracy: 0.1429 - Val loss: 1.2725 - Val F1: 0.0357 - LR: 7.00e-05\n",
      "\tEpoch 40/100 - Train loss: 0.1661 - Val accuracy: 0.4286 - Val loss: 1.0639 - Val F1: 0.4558 - LR: 6.00e-05\n",
      "\tEpoch 50/100 - Train loss: 0.1221 - Val accuracy: 0.7143 - Val loss: 0.5320 - Val F1: 0.7063 - LR: 5.00e-05\n",
      "\tEpoch 60/100 - Train loss: 0.0932 - Val accuracy: 1.0000 - Val loss: 0.2898 - Val F1: 1.0000 - LR: 4.00e-05\n",
      "\tEpoch 70/100 - Train loss: 0.0875 - Val accuracy: 1.0000 - Val loss: 0.2171 - Val F1: 1.0000 - LR: 3.00e-05\n",
      "\tEpoch 80/100 - Train loss: 0.0656 - Val accuracy: 1.0000 - Val loss: 0.1897 - Val F1: 1.0000 - LR: 2.00e-05\n",
      "\tEpoch 90/100 - Train loss: 0.0662 - Val accuracy: 1.0000 - Val loss: 0.1771 - Val F1: 1.0000 - LR: 1.00e-05\n",
      "\tEpoch 100/100 - Train loss: 0.0674 - Val accuracy: 1.0000 - Val loss: 0.1723 - Val F1: 1.0000 - LR: 0.00e+00\n",
      "\tBest epoch: 100 - Best val accuracy: 1.0000 - Best val loss: 0.1723 - Best val F1: 1.0000\n",
      "\n",
      "Source class: WAL | Domain: 50 | Accuracy: 0.9278 | Loss: 0.2222 | F1: 0.9043\n",
      "\n",
      "Domain: 51\n",
      "x_dp_dom.shape: (46, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Training and evaluating on Dp data via cross-validation...\n",
      "\tEpoch 10/100 - Train loss: 0.6995 - Val accuracy: 0.6250 - Val loss: 1.0776 - Val F1: 0.4808 - LR: 9.00e-05\n",
      "\tEpoch 20/100 - Train loss: 0.4660 - Val accuracy: 0.1250 - Val loss: 1.1705 - Val F1: 0.0278 - LR: 8.00e-05\n",
      "\tEpoch 30/100 - Train loss: 0.3217 - Val accuracy: 0.1250 - Val loss: 1.3504 - Val F1: 0.0278 - LR: 7.00e-05\n",
      "\tEpoch 40/100 - Train loss: 0.2458 - Val accuracy: 0.1250 - Val loss: 1.2216 - Val F1: 0.0278 - LR: 6.00e-05\n",
      "\tEpoch 50/100 - Train loss: 0.1913 - Val accuracy: 0.7500 - Val loss: 0.7743 - Val F1: 0.7847 - LR: 5.00e-05\n",
      "\tEpoch 60/100 - Train loss: 0.1771 - Val accuracy: 0.8750 - Val loss: 0.5068 - Val F1: 0.8750 - LR: 4.00e-05\n",
      "\tEpoch 70/100 - Train loss: 0.1401 - Val accuracy: 0.8750 - Val loss: 0.4115 - Val F1: 0.8750 - LR: 3.00e-05\n",
      "\tEpoch 80/100 - Train loss: 0.1135 - Val accuracy: 0.8750 - Val loss: 0.3720 - Val F1: 0.8750 - LR: 2.00e-05\n",
      "\tEpoch 90/100 - Train loss: 0.1058 - Val accuracy: 0.8750 - Val loss: 0.3538 - Val F1: 0.8750 - LR: 1.00e-05\n",
      "\tEpoch 100/100 - Train loss: 0.1057 - Val accuracy: 0.8750 - Val loss: 0.3464 - Val F1: 0.8750 - LR: 0.00e+00\n",
      "\tBest epoch: 100 - Best val accuracy: 0.8750 - Best val loss: 0.3464 - Best val F1: 0.8750\n",
      "\n",
      "\tEpoch 10/100 - Train loss: 0.6046 - Val accuracy: 0.1250 - Val loss: 1.1027 - Val F1: 0.0278 - LR: 9.00e-05\n",
      "\tEpoch 20/100 - Train loss: 0.4147 - Val accuracy: 0.2500 - Val loss: 1.1830 - Val F1: 0.1000 - LR: 8.00e-05\n",
      "\tEpoch 30/100 - Train loss: 0.3105 - Val accuracy: 0.2500 - Val loss: 1.2941 - Val F1: 0.1000 - LR: 7.00e-05\n",
      "\tEpoch 40/100 - Train loss: 0.2416 - Val accuracy: 0.3750 - Val loss: 1.1006 - Val F1: 0.3512 - LR: 6.00e-05\n",
      "\tEpoch 50/100 - Train loss: 0.2090 - Val accuracy: 0.8750 - Val loss: 0.5760 - Val F1: 0.8250 - LR: 5.00e-05\n",
      "\tEpoch 60/100 - Train loss: 0.1810 - Val accuracy: 0.8750 - Val loss: 0.3692 - Val F1: 0.8250 - LR: 4.00e-05\n",
      "\tEpoch 70/100 - Train loss: 0.1631 - Val accuracy: 0.8750 - Val loss: 0.3177 - Val F1: 0.8250 - LR: 3.00e-05\n",
      "\tEpoch 80/100 - Train loss: 0.1440 - Val accuracy: 0.8750 - Val loss: 0.3013 - Val F1: 0.8250 - LR: 2.00e-05\n",
      "\tEpoch 90/100 - Train loss: 0.1408 - Val accuracy: 0.8750 - Val loss: 0.2942 - Val F1: 0.8250 - LR: 1.00e-05\n",
      "\tEpoch 100/100 - Train loss: 0.1301 - Val accuracy: 0.8750 - Val loss: 0.2912 - Val F1: 0.8250 - LR: 0.00e+00\n",
      "\tBest epoch: 100 - Best val accuracy: 0.8750 - Best val loss: 0.2912 - Best val F1: 0.8250\n",
      "\n",
      "\tEpoch 10/100 - Train loss: 0.6615 - Val accuracy: 0.6250 - Val loss: 1.0772 - Val F1: 0.4808 - LR: 9.00e-05\n",
      "\tEpoch 20/100 - Train loss: 0.4478 - Val accuracy: 0.1250 - Val loss: 1.1529 - Val F1: 0.0278 - LR: 8.00e-05\n",
      "\tEpoch 30/100 - Train loss: 0.3184 - Val accuracy: 0.1250 - Val loss: 1.2367 - Val F1: 0.0278 - LR: 7.00e-05\n",
      "\tEpoch 40/100 - Train loss: 0.2213 - Val accuracy: 0.6250 - Val loss: 0.8558 - Val F1: 0.6056 - LR: 6.00e-05\n",
      "\tEpoch 50/100 - Train loss: 0.1629 - Val accuracy: 0.8750 - Val loss: 0.4401 - Val F1: 0.8750 - LR: 5.00e-05\n",
      "\tEpoch 60/100 - Train loss: 0.1386 - Val accuracy: 0.8750 - Val loss: 0.3202 - Val F1: 0.8750 - LR: 4.00e-05\n",
      "\tEpoch 70/100 - Train loss: 0.1112 - Val accuracy: 0.8750 - Val loss: 0.2831 - Val F1: 0.8750 - LR: 3.00e-05\n",
      "\tEpoch 80/100 - Train loss: 0.1012 - Val accuracy: 0.8750 - Val loss: 0.2670 - Val F1: 0.8750 - LR: 2.00e-05\n",
      "\tEpoch 90/100 - Train loss: 0.1066 - Val accuracy: 0.8750 - Val loss: 0.2599 - Val F1: 0.8750 - LR: 1.00e-05\n",
      "\tEpoch 100/100 - Train loss: 0.0991 - Val accuracy: 0.8750 - Val loss: 0.2566 - Val F1: 0.8750 - LR: 0.00e+00\n",
      "\tBest epoch: 100 - Best val accuracy: 0.8750 - Best val loss: 0.2566 - Best val F1: 0.8750\n",
      "\n",
      "\tEpoch 10/100 - Train loss: 0.6167 - Val accuracy: 0.6250 - Val loss: 1.0808 - Val F1: 0.4808 - LR: 9.00e-05\n",
      "\tEpoch 20/100 - Train loss: 0.3962 - Val accuracy: 0.1250 - Val loss: 1.1542 - Val F1: 0.0278 - LR: 8.00e-05\n",
      "\tEpoch 30/100 - Train loss: 0.2868 - Val accuracy: 0.1250 - Val loss: 1.2796 - Val F1: 0.0312 - LR: 7.00e-05\n",
      "\tEpoch 40/100 - Train loss: 0.2258 - Val accuracy: 0.3750 - Val loss: 1.1405 - Val F1: 0.3583 - LR: 6.00e-05\n",
      "\tEpoch 50/100 - Train loss: 0.1758 - Val accuracy: 0.8750 - Val loss: 0.6484 - Val F1: 0.8889 - LR: 5.00e-05\n",
      "\tEpoch 60/100 - Train loss: 0.1417 - Val accuracy: 1.0000 - Val loss: 0.3774 - Val F1: 1.0000 - LR: 4.00e-05\n",
      "\tEpoch 70/100 - Train loss: 0.1268 - Val accuracy: 1.0000 - Val loss: 0.2926 - Val F1: 1.0000 - LR: 3.00e-05\n",
      "\tEpoch 80/100 - Train loss: 0.1105 - Val accuracy: 1.0000 - Val loss: 0.2646 - Val F1: 1.0000 - LR: 2.00e-05\n",
      "\tEpoch 90/100 - Train loss: 0.0958 - Val accuracy: 1.0000 - Val loss: 0.2525 - Val F1: 1.0000 - LR: 1.00e-05\n",
      "\tEpoch 100/100 - Train loss: 0.0902 - Val accuracy: 1.0000 - Val loss: 0.2476 - Val F1: 1.0000 - LR: 0.00e+00\n",
      "\tBest epoch: 100 - Best val accuracy: 1.0000 - Best val loss: 0.2476 - Best val F1: 1.0000\n",
      "\n",
      "\tEpoch 10/100 - Train loss: 0.5490 - Val accuracy: 0.6250 - Val loss: 1.0566 - Val F1: 0.4808 - LR: 9.00e-05\n",
      "\tEpoch 20/100 - Train loss: 0.3612 - Val accuracy: 0.1250 - Val loss: 1.1793 - Val F1: 0.0278 - LR: 8.00e-05\n",
      "\tEpoch 30/100 - Train loss: 0.2518 - Val accuracy: 0.1250 - Val loss: 1.3288 - Val F1: 0.0278 - LR: 7.00e-05\n",
      "\tEpoch 40/100 - Train loss: 0.2022 - Val accuracy: 0.5000 - Val loss: 1.1082 - Val F1: 0.5104 - LR: 6.00e-05\n",
      "\tEpoch 50/100 - Train loss: 0.1666 - Val accuracy: 0.7500 - Val loss: 0.5972 - Val F1: 0.6875 - LR: 5.00e-05\n",
      "\tEpoch 60/100 - Train loss: 0.1440 - Val accuracy: 0.7500 - Val loss: 0.4173 - Val F1: 0.6875 - LR: 4.00e-05\n",
      "\tEpoch 70/100 - Train loss: 0.1246 - Val accuracy: 0.7500 - Val loss: 0.3731 - Val F1: 0.6875 - LR: 3.00e-05\n",
      "\tEpoch 80/100 - Train loss: 0.1025 - Val accuracy: 0.7500 - Val loss: 0.3573 - Val F1: 0.6875 - LR: 2.00e-05\n",
      "\tEpoch 90/100 - Train loss: 0.1070 - Val accuracy: 0.7500 - Val loss: 0.3509 - Val F1: 0.6875 - LR: 1.00e-05\n",
      "\tEpoch 100/100 - Train loss: 0.1009 - Val accuracy: 0.7500 - Val loss: 0.3481 - Val F1: 0.6875 - LR: 0.00e+00\n",
      "\tBest epoch: 100 - Best val accuracy: 0.7500 - Best val loss: 0.3481 - Best val F1: 0.6875\n",
      "\n",
      "Source class: WAL | Domain: 51 | Accuracy: 0.8244 | Loss: 0.3223 | F1: 0.7856\n",
      "\n",
      "Domain: 52\n",
      "x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Training and evaluating on Dp data via cross-validation...\n",
      "\tEpoch 10/100 - Train loss: 0.5287 - Val accuracy: 0.7143 - Val loss: 1.0715 - Val F1: 0.5952 - LR: 9.00e-05\n",
      "\tEpoch 20/100 - Train loss: 0.3355 - Val accuracy: 0.1429 - Val loss: 1.1988 - Val F1: 0.0571 - LR: 8.00e-05\n",
      "\tEpoch 30/100 - Train loss: 0.2542 - Val accuracy: 0.1429 - Val loss: 1.4160 - Val F1: 0.0714 - LR: 7.00e-05\n",
      "\tEpoch 40/100 - Train loss: 0.2066 - Val accuracy: 0.1429 - Val loss: 1.3573 - Val F1: 0.0952 - LR: 6.00e-05\n",
      "\tEpoch 50/100 - Train loss: 0.1687 - Val accuracy: 0.8571 - Val loss: 0.7719 - Val F1: 0.8730 - LR: 5.00e-05\n",
      "\tEpoch 60/100 - Train loss: 0.1505 - Val accuracy: 0.8571 - Val loss: 0.4244 - Val F1: 0.8730 - LR: 4.00e-05\n",
      "\tEpoch 70/100 - Train loss: 0.1362 - Val accuracy: 1.0000 - Val loss: 0.3273 - Val F1: 1.0000 - LR: 3.00e-05\n",
      "\tEpoch 80/100 - Train loss: 0.1227 - Val accuracy: 1.0000 - Val loss: 0.2947 - Val F1: 1.0000 - LR: 2.00e-05\n",
      "\tEpoch 90/100 - Train loss: 0.1171 - Val accuracy: 1.0000 - Val loss: 0.2814 - Val F1: 1.0000 - LR: 1.00e-05\n",
      "\tEpoch 100/100 - Train loss: 0.1078 - Val accuracy: 1.0000 - Val loss: 0.2756 - Val F1: 1.0000 - LR: 0.00e+00\n",
      "\tBest epoch: 100 - Best val accuracy: 1.0000 - Best val loss: 0.2756 - Best val F1: 1.0000\n",
      "\n",
      "\tEpoch 10/100 - Train loss: 0.5448 - Val accuracy: 0.7143 - Val loss: 1.0481 - Val F1: 0.5952 - LR: 9.00e-05\n",
      "\tEpoch 20/100 - Train loss: 0.3410 - Val accuracy: 0.1429 - Val loss: 1.1273 - Val F1: 0.0357 - LR: 8.00e-05\n",
      "\tEpoch 30/100 - Train loss: 0.2469 - Val accuracy: 0.1429 - Val loss: 1.2617 - Val F1: 0.0357 - LR: 7.00e-05\n",
      "\tEpoch 40/100 - Train loss: 0.1883 - Val accuracy: 0.1429 - Val loss: 1.2381 - Val F1: 0.0357 - LR: 6.00e-05\n",
      "\tEpoch 50/100 - Train loss: 0.1453 - Val accuracy: 0.8571 - Val loss: 0.6980 - Val F1: 0.8095 - LR: 5.00e-05\n",
      "\tEpoch 60/100 - Train loss: 0.1252 - Val accuracy: 1.0000 - Val loss: 0.2602 - Val F1: 1.0000 - LR: 4.00e-05\n",
      "\tEpoch 70/100 - Train loss: 0.1007 - Val accuracy: 1.0000 - Val loss: 0.1680 - Val F1: 1.0000 - LR: 3.00e-05\n",
      "\tEpoch 80/100 - Train loss: 0.0935 - Val accuracy: 1.0000 - Val loss: 0.1437 - Val F1: 1.0000 - LR: 2.00e-05\n",
      "\tEpoch 90/100 - Train loss: 0.0800 - Val accuracy: 1.0000 - Val loss: 0.1336 - Val F1: 1.0000 - LR: 1.00e-05\n",
      "\tEpoch 100/100 - Train loss: 0.0795 - Val accuracy: 1.0000 - Val loss: 0.1298 - Val F1: 1.0000 - LR: 0.00e+00\n",
      "\tBest epoch: 100 - Best val accuracy: 1.0000 - Best val loss: 0.1298 - Best val F1: 1.0000\n",
      "\n",
      "\tEpoch 10/100 - Train loss: 0.6164 - Val accuracy: 0.7143 - Val loss: 1.0845 - Val F1: 0.5952 - LR: 9.00e-05\n",
      "\tEpoch 20/100 - Train loss: 0.4018 - Val accuracy: 0.1429 - Val loss: 1.1853 - Val F1: 0.0357 - LR: 8.00e-05\n",
      "\tEpoch 30/100 - Train loss: 0.2812 - Val accuracy: 0.1429 - Val loss: 1.3979 - Val F1: 0.0357 - LR: 7.00e-05\n",
      "\tEpoch 40/100 - Train loss: 0.2145 - Val accuracy: 0.1429 - Val loss: 1.4843 - Val F1: 0.0357 - LR: 6.00e-05\n",
      "\tEpoch 50/100 - Train loss: 0.1725 - Val accuracy: 0.2857 - Val loss: 1.0119 - Val F1: 0.3095 - LR: 5.00e-05\n",
      "\tEpoch 60/100 - Train loss: 0.1593 - Val accuracy: 0.8571 - Val loss: 0.4279 - Val F1: 0.8095 - LR: 4.00e-05\n",
      "\tEpoch 70/100 - Train loss: 0.1252 - Val accuracy: 0.8571 - Val loss: 0.2994 - Val F1: 0.8095 - LR: 3.00e-05\n",
      "\tEpoch 80/100 - Train loss: 0.1091 - Val accuracy: 0.8571 - Val loss: 0.2777 - Val F1: 0.8095 - LR: 2.00e-05\n",
      "\tEpoch 90/100 - Train loss: 0.1019 - Val accuracy: 0.7143 - Val loss: 0.2719 - Val F1: 0.7143 - LR: 1.00e-05\n",
      "\tEpoch 100/100 - Train loss: 0.0985 - Val accuracy: 0.7143 - Val loss: 0.2701 - Val F1: 0.7143 - LR: 0.00e+00\n",
      "\tBest epoch: 100 - Best val accuracy: 0.7143 - Best val loss: 0.2701 - Best val F1: 0.7143\n",
      "\n",
      "\tEpoch 10/100 - Train loss: 0.5784 - Val accuracy: 0.1429 - Val loss: 1.1062 - Val F1: 0.0357 - LR: 9.00e-05\n",
      "\tEpoch 20/100 - Train loss: 0.3346 - Val accuracy: 0.1429 - Val loss: 1.2173 - Val F1: 0.0357 - LR: 8.00e-05\n",
      "\tEpoch 30/100 - Train loss: 0.2407 - Val accuracy: 0.1429 - Val loss: 1.4396 - Val F1: 0.0357 - LR: 7.00e-05\n",
      "\tEpoch 40/100 - Train loss: 0.1807 - Val accuracy: 0.1429 - Val loss: 1.4854 - Val F1: 0.0408 - LR: 6.00e-05\n",
      "\tEpoch 50/100 - Train loss: 0.1481 - Val accuracy: 0.7143 - Val loss: 0.8790 - Val F1: 0.7063 - LR: 5.00e-05\n",
      "\tEpoch 60/100 - Train loss: 0.1187 - Val accuracy: 0.8571 - Val loss: 0.3503 - Val F1: 0.8095 - LR: 4.00e-05\n",
      "\tEpoch 70/100 - Train loss: 0.1030 - Val accuracy: 0.8571 - Val loss: 0.2565 - Val F1: 0.8095 - LR: 3.00e-05\n",
      "\tEpoch 80/100 - Train loss: 0.0989 - Val accuracy: 0.8571 - Val loss: 0.2414 - Val F1: 0.8095 - LR: 2.00e-05\n",
      "\tEpoch 90/100 - Train loss: 0.0824 - Val accuracy: 0.8571 - Val loss: 0.2375 - Val F1: 0.8095 - LR: 1.00e-05\n",
      "\tEpoch 100/100 - Train loss: 0.0796 - Val accuracy: 0.8571 - Val loss: 0.2367 - Val F1: 0.8095 - LR: 0.00e+00\n",
      "\tBest epoch: 99 - Best val accuracy: 0.8571 - Best val loss: 0.2367 - Best val F1: 0.8095\n",
      "\n",
      "\tEpoch 10/100 - Train loss: 0.5336 - Val accuracy: 0.7143 - Val loss: 1.0432 - Val F1: 0.5952 - LR: 9.00e-05\n",
      "\tEpoch 20/100 - Train loss: 0.3397 - Val accuracy: 0.1429 - Val loss: 1.1204 - Val F1: 0.0357 - LR: 8.00e-05\n",
      "\tEpoch 30/100 - Train loss: 0.2282 - Val accuracy: 0.1429 - Val loss: 1.2929 - Val F1: 0.0357 - LR: 7.00e-05\n",
      "\tEpoch 40/100 - Train loss: 0.1783 - Val accuracy: 0.1429 - Val loss: 1.3038 - Val F1: 0.0476 - LR: 6.00e-05\n",
      "\tEpoch 50/100 - Train loss: 0.1185 - Val accuracy: 0.5714 - Val loss: 0.7990 - Val F1: 0.6349 - LR: 5.00e-05\n",
      "\tEpoch 60/100 - Train loss: 0.1058 - Val accuracy: 0.7143 - Val loss: 0.4162 - Val F1: 0.7143 - LR: 4.00e-05\n",
      "\tEpoch 70/100 - Train loss: 0.0977 - Val accuracy: 0.7143 - Val loss: 0.3357 - Val F1: 0.7143 - LR: 3.00e-05\n",
      "\tEpoch 80/100 - Train loss: 0.0761 - Val accuracy: 0.7143 - Val loss: 0.3163 - Val F1: 0.7143 - LR: 2.00e-05\n",
      "\tEpoch 90/100 - Train loss: 0.0739 - Val accuracy: 0.7143 - Val loss: 0.3083 - Val F1: 0.7143 - LR: 1.00e-05\n",
      "\tEpoch 100/100 - Train loss: 0.0715 - Val accuracy: 0.7143 - Val loss: 0.3060 - Val F1: 0.7143 - LR: 0.00e+00\n",
      "\tBest epoch: 100 - Best val accuracy: 0.7143 - Best val loss: 0.3060 - Best val F1: 0.7143\n",
      "\n",
      "Source class: WAL | Domain: 52 | Accuracy: 0.8833 | Loss: 0.2783 | F1: 0.8550\n",
      "\n",
      "Domain: 53\n",
      "x_dp_dom.shape: (48, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Training and evaluating on Dp data via cross-validation...\n",
      "\tEpoch 10/100 - Train loss: 0.5350 - Val accuracy: 0.2500 - Val loss: 1.1005 - Val F1: 0.1000 - LR: 9.00e-05\n",
      "\tEpoch 20/100 - Train loss: 0.3365 - Val accuracy: 0.2500 - Val loss: 1.2408 - Val F1: 0.1000 - LR: 8.00e-05\n",
      "\tEpoch 30/100 - Train loss: 0.2608 - Val accuracy: 0.2500 - Val loss: 1.4414 - Val F1: 0.1000 - LR: 7.00e-05\n",
      "\tEpoch 40/100 - Train loss: 0.1961 - Val accuracy: 0.2500 - Val loss: 1.2503 - Val F1: 0.1000 - LR: 6.00e-05\n",
      "\tEpoch 50/100 - Train loss: 0.1534 - Val accuracy: 0.7500 - Val loss: 0.5770 - Val F1: 0.7222 - LR: 5.00e-05\n",
      "\tEpoch 60/100 - Train loss: 0.1117 - Val accuracy: 0.8750 - Val loss: 0.2862 - Val F1: 0.8250 - LR: 4.00e-05\n",
      "\tEpoch 70/100 - Train loss: 0.0968 - Val accuracy: 0.8750 - Val loss: 0.2150 - Val F1: 0.8250 - LR: 3.00e-05\n",
      "\tEpoch 80/100 - Train loss: 0.0873 - Val accuracy: 0.8750 - Val loss: 0.1895 - Val F1: 0.8250 - LR: 2.00e-05\n",
      "\tEpoch 90/100 - Train loss: 0.0748 - Val accuracy: 0.8750 - Val loss: 0.1788 - Val F1: 0.8250 - LR: 1.00e-05\n",
      "\tEpoch 100/100 - Train loss: 0.0677 - Val accuracy: 0.8750 - Val loss: 0.1750 - Val F1: 0.8250 - LR: 0.00e+00\n",
      "\tBest epoch: 100 - Best val accuracy: 0.8750 - Best val loss: 0.1750 - Best val F1: 0.8250\n",
      "\n",
      "\tEpoch 10/100 - Train loss: 0.5532 - Val accuracy: 0.1250 - Val loss: 1.1142 - Val F1: 0.0417 - LR: 9.00e-05\n",
      "\tEpoch 20/100 - Train loss: 0.3820 - Val accuracy: 0.1250 - Val loss: 1.2445 - Val F1: 0.0278 - LR: 8.00e-05\n",
      "\tEpoch 30/100 - Train loss: 0.2776 - Val accuracy: 0.2500 - Val loss: 1.4744 - Val F1: 0.1250 - LR: 7.00e-05\n",
      "\tEpoch 40/100 - Train loss: 0.2167 - Val accuracy: 0.2500 - Val loss: 1.4877 - Val F1: 0.1111 - LR: 6.00e-05\n",
      "\tEpoch 50/100 - Train loss: 0.1537 - Val accuracy: 0.7500 - Val loss: 0.9197 - Val F1: 0.7812 - LR: 5.00e-05\n",
      "\tEpoch 60/100 - Train loss: 0.1245 - Val accuracy: 0.8750 - Val loss: 0.5052 - Val F1: 0.8889 - LR: 4.00e-05\n",
      "\tEpoch 70/100 - Train loss: 0.1159 - Val accuracy: 0.8750 - Val loss: 0.3615 - Val F1: 0.8889 - LR: 3.00e-05\n",
      "\tEpoch 80/100 - Train loss: 0.0808 - Val accuracy: 0.8750 - Val loss: 0.3076 - Val F1: 0.8889 - LR: 2.00e-05\n",
      "\tEpoch 90/100 - Train loss: 0.0854 - Val accuracy: 0.8750 - Val loss: 0.2845 - Val F1: 0.8889 - LR: 1.00e-05\n",
      "\tEpoch 100/100 - Train loss: 0.0802 - Val accuracy: 0.8750 - Val loss: 0.2743 - Val F1: 0.8889 - LR: 0.00e+00\n",
      "\tBest epoch: 100 - Best val accuracy: 0.8750 - Best val loss: 0.2743 - Best val F1: 0.8889\n",
      "\n",
      "\tEpoch 10/100 - Train loss: 0.5549 - Val accuracy: 0.6250 - Val loss: 1.0840 - Val F1: 0.4808 - LR: 9.00e-05\n",
      "\tEpoch 20/100 - Train loss: 0.3526 - Val accuracy: 0.1250 - Val loss: 1.1559 - Val F1: 0.0278 - LR: 8.00e-05\n",
      "\tEpoch 30/100 - Train loss: 0.2538 - Val accuracy: 0.2500 - Val loss: 1.2940 - Val F1: 0.1333 - LR: 7.00e-05\n",
      "\tEpoch 40/100 - Train loss: 0.1840 - Val accuracy: 0.2500 - Val loss: 1.2042 - Val F1: 0.1333 - LR: 6.00e-05\n",
      "\tEpoch 50/100 - Train loss: 0.1376 - Val accuracy: 0.8750 - Val loss: 0.6471 - Val F1: 0.8806 - LR: 5.00e-05\n",
      "\tEpoch 60/100 - Train loss: 0.1094 - Val accuracy: 0.8750 - Val loss: 0.3705 - Val F1: 0.8806 - LR: 4.00e-05\n",
      "\tEpoch 70/100 - Train loss: 0.0897 - Val accuracy: 1.0000 - Val loss: 0.2725 - Val F1: 1.0000 - LR: 3.00e-05\n",
      "\tEpoch 80/100 - Train loss: 0.0756 - Val accuracy: 1.0000 - Val loss: 0.2345 - Val F1: 1.0000 - LR: 2.00e-05\n",
      "\tEpoch 90/100 - Train loss: 0.0641 - Val accuracy: 1.0000 - Val loss: 0.2177 - Val F1: 1.0000 - LR: 1.00e-05\n",
      "\tEpoch 100/100 - Train loss: 0.0646 - Val accuracy: 1.0000 - Val loss: 0.2110 - Val F1: 1.0000 - LR: 0.00e+00\n",
      "\tBest epoch: 100 - Best val accuracy: 1.0000 - Best val loss: 0.2110 - Best val F1: 1.0000\n",
      "\n",
      "\tEpoch 10/100 - Train loss: 0.5697 - Val accuracy: 0.2500 - Val loss: 1.0723 - Val F1: 0.1000 - LR: 9.00e-05\n",
      "\tEpoch 20/100 - Train loss: 0.3864 - Val accuracy: 0.2500 - Val loss: 1.1542 - Val F1: 0.1000 - LR: 8.00e-05\n",
      "\tEpoch 30/100 - Train loss: 0.2441 - Val accuracy: 0.2500 - Val loss: 1.2522 - Val F1: 0.1000 - LR: 7.00e-05\n",
      "\tEpoch 40/100 - Train loss: 0.1905 - Val accuracy: 0.6250 - Val loss: 0.8925 - Val F1: 0.6116 - LR: 6.00e-05\n",
      "\tEpoch 50/100 - Train loss: 0.1238 - Val accuracy: 0.8750 - Val loss: 0.4010 - Val F1: 0.8250 - LR: 5.00e-05\n",
      "\tEpoch 60/100 - Train loss: 0.1014 - Val accuracy: 0.8750 - Val loss: 0.2706 - Val F1: 0.8250 - LR: 4.00e-05\n",
      "\tEpoch 70/100 - Train loss: 0.0830 - Val accuracy: 0.8750 - Val loss: 0.2343 - Val F1: 0.8250 - LR: 3.00e-05\n",
      "\tEpoch 80/100 - Train loss: 0.0781 - Val accuracy: 0.8750 - Val loss: 0.2183 - Val F1: 0.8250 - LR: 2.00e-05\n",
      "\tEpoch 90/100 - Train loss: 0.0659 - Val accuracy: 0.8750 - Val loss: 0.2108 - Val F1: 0.8250 - LR: 1.00e-05\n",
      "\tEpoch 100/100 - Train loss: 0.0615 - Val accuracy: 0.8750 - Val loss: 0.2081 - Val F1: 0.8250 - LR: 0.00e+00\n",
      "\tBest epoch: 100 - Best val accuracy: 0.8750 - Best val loss: 0.2081 - Best val F1: 0.8250\n",
      "\n",
      "\tEpoch 10/100 - Train loss: 0.6342 - Val accuracy: 0.6250 - Val loss: 1.0629 - Val F1: 0.4808 - LR: 9.00e-05\n",
      "\tEpoch 20/100 - Train loss: 0.4097 - Val accuracy: 0.2500 - Val loss: 1.1278 - Val F1: 0.1000 - LR: 8.00e-05\n",
      "\tEpoch 30/100 - Train loss: 0.2917 - Val accuracy: 0.2500 - Val loss: 1.2153 - Val F1: 0.1000 - LR: 7.00e-05\n",
      "\tEpoch 40/100 - Train loss: 0.2031 - Val accuracy: 0.5000 - Val loss: 0.9010 - Val F1: 0.5238 - LR: 6.00e-05\n",
      "\tEpoch 50/100 - Train loss: 0.1462 - Val accuracy: 1.0000 - Val loss: 0.3617 - Val F1: 1.0000 - LR: 5.00e-05\n",
      "\tEpoch 60/100 - Train loss: 0.1139 - Val accuracy: 1.0000 - Val loss: 0.1929 - Val F1: 1.0000 - LR: 4.00e-05\n",
      "\tEpoch 70/100 - Train loss: 0.0924 - Val accuracy: 1.0000 - Val loss: 0.1428 - Val F1: 1.0000 - LR: 3.00e-05\n",
      "\tEpoch 80/100 - Train loss: 0.0834 - Val accuracy: 1.0000 - Val loss: 0.1219 - Val F1: 1.0000 - LR: 2.00e-05\n",
      "\tEpoch 90/100 - Train loss: 0.0681 - Val accuracy: 1.0000 - Val loss: 0.1119 - Val F1: 1.0000 - LR: 1.00e-05\n",
      "\tEpoch 100/100 - Train loss: 0.0673 - Val accuracy: 1.0000 - Val loss: 0.1080 - Val F1: 1.0000 - LR: 0.00e+00\n",
      "\tBest epoch: 100 - Best val accuracy: 1.0000 - Best val loss: 0.1080 - Best val F1: 1.0000\n",
      "\n",
      "Source class: WAL | Domain: 53 | Accuracy: 0.9333 | Loss: 0.2351 | F1: 0.9170\n",
      "\n",
      "Domain: 54\n",
      "x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Training and evaluating on Dp data via cross-validation...\n",
      "\tEpoch 10/100 - Train loss: 0.6048 - Val accuracy: 0.1429 - Val loss: 1.0788 - Val F1: 0.0357 - LR: 9.00e-05\n",
      "\tEpoch 20/100 - Train loss: 0.3636 - Val accuracy: 0.1429 - Val loss: 1.1588 - Val F1: 0.0476 - LR: 8.00e-05\n",
      "\tEpoch 30/100 - Train loss: 0.2444 - Val accuracy: 0.1429 - Val loss: 1.3475 - Val F1: 0.0357 - LR: 7.00e-05\n",
      "\tEpoch 40/100 - Train loss: 0.1878 - Val accuracy: 0.5714 - Val loss: 1.0601 - Val F1: 0.6082 - LR: 6.00e-05\n",
      "\tEpoch 50/100 - Train loss: 0.1318 - Val accuracy: 1.0000 - Val loss: 0.4220 - Val F1: 1.0000 - LR: 5.00e-05\n",
      "\tEpoch 60/100 - Train loss: 0.1027 - Val accuracy: 1.0000 - Val loss: 0.1822 - Val F1: 1.0000 - LR: 4.00e-05\n",
      "\tEpoch 70/100 - Train loss: 0.0777 - Val accuracy: 1.0000 - Val loss: 0.1276 - Val F1: 1.0000 - LR: 3.00e-05\n",
      "\tEpoch 80/100 - Train loss: 0.0664 - Val accuracy: 1.0000 - Val loss: 0.1113 - Val F1: 1.0000 - LR: 2.00e-05\n",
      "\tEpoch 90/100 - Train loss: 0.0754 - Val accuracy: 1.0000 - Val loss: 0.1040 - Val F1: 1.0000 - LR: 1.00e-05\n",
      "\tEpoch 100/100 - Train loss: 0.0660 - Val accuracy: 1.0000 - Val loss: 0.1012 - Val F1: 1.0000 - LR: 0.00e+00\n",
      "\tBest epoch: 100 - Best val accuracy: 1.0000 - Best val loss: 0.1012 - Best val F1: 1.0000\n",
      "\n",
      "\tEpoch 10/100 - Train loss: 0.5495 - Val accuracy: 0.7143 - Val loss: 1.0202 - Val F1: 0.5952 - LR: 9.00e-05\n",
      "\tEpoch 20/100 - Train loss: 0.3407 - Val accuracy: 0.1429 - Val loss: 1.0956 - Val F1: 0.0357 - LR: 8.00e-05\n",
      "\tEpoch 30/100 - Train loss: 0.2545 - Val accuracy: 0.1429 - Val loss: 1.2800 - Val F1: 0.0357 - LR: 7.00e-05\n",
      "\tEpoch 40/100 - Train loss: 0.1721 - Val accuracy: 0.1429 - Val loss: 1.1127 - Val F1: 0.0357 - LR: 6.00e-05\n",
      "\tEpoch 50/100 - Train loss: 0.1533 - Val accuracy: 0.8571 - Val loss: 0.5419 - Val F1: 0.8095 - LR: 5.00e-05\n",
      "\tEpoch 60/100 - Train loss: 0.1265 - Val accuracy: 0.8571 - Val loss: 0.3010 - Val F1: 0.8095 - LR: 4.00e-05\n",
      "\tEpoch 70/100 - Train loss: 0.1003 - Val accuracy: 0.8571 - Val loss: 0.2527 - Val F1: 0.8095 - LR: 3.00e-05\n",
      "\tEpoch 80/100 - Train loss: 0.0930 - Val accuracy: 0.8571 - Val loss: 0.2405 - Val F1: 0.8095 - LR: 2.00e-05\n",
      "\tEpoch 90/100 - Train loss: 0.0891 - Val accuracy: 0.8571 - Val loss: 0.2365 - Val F1: 0.8095 - LR: 1.00e-05\n",
      "\tEpoch 100/100 - Train loss: 0.0793 - Val accuracy: 0.8571 - Val loss: 0.2354 - Val F1: 0.8095 - LR: 0.00e+00\n",
      "\tBest epoch: 100 - Best val accuracy: 0.8571 - Best val loss: 0.2354 - Best val F1: 0.8095\n",
      "\n",
      "\tEpoch 10/100 - Train loss: 0.6205 - Val accuracy: 0.7143 - Val loss: 1.0598 - Val F1: 0.5952 - LR: 9.00e-05\n",
      "\tEpoch 20/100 - Train loss: 0.4138 - Val accuracy: 0.1429 - Val loss: 1.1213 - Val F1: 0.0357 - LR: 8.00e-05\n",
      "\tEpoch 30/100 - Train loss: 0.2774 - Val accuracy: 0.1429 - Val loss: 1.3171 - Val F1: 0.0357 - LR: 7.00e-05\n",
      "\tEpoch 40/100 - Train loss: 0.2302 - Val accuracy: 0.1429 - Val loss: 1.3369 - Val F1: 0.0357 - LR: 6.00e-05\n",
      "\tEpoch 50/100 - Train loss: 0.1924 - Val accuracy: 0.7143 - Val loss: 0.7871 - Val F1: 0.7063 - LR: 5.00e-05\n",
      "\tEpoch 60/100 - Train loss: 0.1526 - Val accuracy: 0.8571 - Val loss: 0.3683 - Val F1: 0.8095 - LR: 4.00e-05\n",
      "\tEpoch 70/100 - Train loss: 0.1354 - Val accuracy: 1.0000 - Val loss: 0.2373 - Val F1: 1.0000 - LR: 3.00e-05\n",
      "\tEpoch 80/100 - Train loss: 0.1332 - Val accuracy: 1.0000 - Val loss: 0.1904 - Val F1: 1.0000 - LR: 2.00e-05\n",
      "\tEpoch 90/100 - Train loss: 0.1189 - Val accuracy: 1.0000 - Val loss: 0.1708 - Val F1: 1.0000 - LR: 1.00e-05\n",
      "\tEpoch 100/100 - Train loss: 0.1079 - Val accuracy: 1.0000 - Val loss: 0.1634 - Val F1: 1.0000 - LR: 0.00e+00\n",
      "\tBest epoch: 100 - Best val accuracy: 1.0000 - Best val loss: 0.1634 - Best val F1: 1.0000\n",
      "\n",
      "\tEpoch 10/100 - Train loss: 0.6095 - Val accuracy: 0.7143 - Val loss: 1.0817 - Val F1: 0.5952 - LR: 9.00e-05\n",
      "\tEpoch 20/100 - Train loss: 0.3446 - Val accuracy: 0.1429 - Val loss: 1.1532 - Val F1: 0.0357 - LR: 8.00e-05\n",
      "\tEpoch 30/100 - Train loss: 0.2419 - Val accuracy: 0.1429 - Val loss: 1.2912 - Val F1: 0.0357 - LR: 7.00e-05\n",
      "\tEpoch 40/100 - Train loss: 0.1909 - Val accuracy: 0.1429 - Val loss: 1.2526 - Val F1: 0.0357 - LR: 6.00e-05\n",
      "\tEpoch 50/100 - Train loss: 0.1507 - Val accuracy: 0.5714 - Val loss: 0.7789 - Val F1: 0.5929 - LR: 5.00e-05\n",
      "\tEpoch 60/100 - Train loss: 0.1091 - Val accuracy: 0.8571 - Val loss: 0.3819 - Val F1: 0.8095 - LR: 4.00e-05\n",
      "\tEpoch 70/100 - Train loss: 0.0956 - Val accuracy: 0.8571 - Val loss: 0.2727 - Val F1: 0.8095 - LR: 3.00e-05\n",
      "\tEpoch 80/100 - Train loss: 0.0835 - Val accuracy: 0.8571 - Val loss: 0.2416 - Val F1: 0.8095 - LR: 2.00e-05\n",
      "\tEpoch 90/100 - Train loss: 0.0780 - Val accuracy: 0.8571 - Val loss: 0.2292 - Val F1: 0.8095 - LR: 1.00e-05\n",
      "\tEpoch 100/100 - Train loss: 0.0879 - Val accuracy: 0.8571 - Val loss: 0.2244 - Val F1: 0.8095 - LR: 0.00e+00\n",
      "\tBest epoch: 100 - Best val accuracy: 0.8571 - Best val loss: 0.2244 - Best val F1: 0.8095\n",
      "\n",
      "\tEpoch 10/100 - Train loss: 0.6111 - Val accuracy: 0.4286 - Val loss: 1.0880 - Val F1: 0.4558 - LR: 9.00e-05\n",
      "\tEpoch 20/100 - Train loss: 0.4048 - Val accuracy: 0.1429 - Val loss: 1.1036 - Val F1: 0.0408 - LR: 8.00e-05\n",
      "\tEpoch 30/100 - Train loss: 0.2800 - Val accuracy: 0.1429 - Val loss: 1.1795 - Val F1: 0.0714 - LR: 7.00e-05\n",
      "\tEpoch 40/100 - Train loss: 0.2303 - Val accuracy: 0.4286 - Val loss: 1.0551 - Val F1: 0.5034 - LR: 6.00e-05\n",
      "\tEpoch 50/100 - Train loss: 0.1953 - Val accuracy: 0.8571 - Val loss: 0.6027 - Val F1: 0.8095 - LR: 5.00e-05\n",
      "\tEpoch 60/100 - Train loss: 0.1673 - Val accuracy: 0.8571 - Val loss: 0.3422 - Val F1: 0.8095 - LR: 4.00e-05\n",
      "\tEpoch 70/100 - Train loss: 0.1552 - Val accuracy: 0.8571 - Val loss: 0.2568 - Val F1: 0.8095 - LR: 3.00e-05\n",
      "\tEpoch 80/100 - Train loss: 0.1303 - Val accuracy: 1.0000 - Val loss: 0.2264 - Val F1: 1.0000 - LR: 2.00e-05\n",
      "\tEpoch 90/100 - Train loss: 0.1259 - Val accuracy: 0.8571 - Val loss: 0.2147 - Val F1: 0.8095 - LR: 1.00e-05\n",
      "\tEpoch 100/100 - Train loss: 0.1094 - Val accuracy: 0.8571 - Val loss: 0.2101 - Val F1: 0.8095 - LR: 0.00e+00\n",
      "\tBest epoch: 100 - Best val accuracy: 0.8571 - Best val loss: 0.2101 - Best val F1: 0.8095\n",
      "\n",
      "Source class: WAL | Domain: 54 | Accuracy: 0.8556 | Loss: 0.2663 | F1: 0.8472\n",
      "\n",
      "Domain: 55\n",
      "x_dp_dom.shape: (49, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Training and evaluating on Dp data via cross-validation...\n",
      "\tEpoch 10/100 - Train loss: 0.5497 - Val accuracy: 0.2500 - Val loss: 1.1089 - Val F1: 0.1000 - LR: 9.00e-05\n",
      "\tEpoch 20/100 - Train loss: 0.3413 - Val accuracy: 0.2500 - Val loss: 1.2707 - Val F1: 0.1000 - LR: 8.00e-05\n",
      "\tEpoch 30/100 - Train loss: 0.2466 - Val accuracy: 0.2500 - Val loss: 1.4691 - Val F1: 0.1000 - LR: 7.00e-05\n",
      "\tEpoch 40/100 - Train loss: 0.1763 - Val accuracy: 0.2500 - Val loss: 1.2662 - Val F1: 0.1111 - LR: 6.00e-05\n",
      "\tEpoch 50/100 - Train loss: 0.1297 - Val accuracy: 1.0000 - Val loss: 0.5107 - Val F1: 1.0000 - LR: 5.00e-05\n",
      "\tEpoch 60/100 - Train loss: 0.1036 - Val accuracy: 1.0000 - Val loss: 0.1918 - Val F1: 1.0000 - LR: 4.00e-05\n",
      "\tEpoch 70/100 - Train loss: 0.0875 - Val accuracy: 1.0000 - Val loss: 0.1239 - Val F1: 1.0000 - LR: 3.00e-05\n",
      "\tEpoch 80/100 - Train loss: 0.0772 - Val accuracy: 1.0000 - Val loss: 0.1011 - Val F1: 1.0000 - LR: 2.00e-05\n",
      "\tEpoch 90/100 - Train loss: 0.0654 - Val accuracy: 1.0000 - Val loss: 0.0919 - Val F1: 1.0000 - LR: 1.00e-05\n",
      "\tEpoch 100/100 - Train loss: 0.0627 - Val accuracy: 1.0000 - Val loss: 0.0886 - Val F1: 1.0000 - LR: 0.00e+00\n",
      "\tBest epoch: 100 - Best val accuracy: 1.0000 - Best val loss: 0.0886 - Best val F1: 1.0000\n",
      "\n",
      "\tEpoch 10/100 - Train loss: 0.5300 - Val accuracy: 0.2500 - Val loss: 1.1148 - Val F1: 0.1000 - LR: 9.00e-05\n",
      "\tEpoch 20/100 - Train loss: 0.3448 - Val accuracy: 0.2500 - Val loss: 1.2538 - Val F1: 0.1000 - LR: 8.00e-05\n",
      "\tEpoch 30/100 - Train loss: 0.2466 - Val accuracy: 0.2500 - Val loss: 1.4305 - Val F1: 0.1000 - LR: 7.00e-05\n",
      "\tEpoch 40/100 - Train loss: 0.1857 - Val accuracy: 0.2500 - Val loss: 1.3403 - Val F1: 0.1111 - LR: 6.00e-05\n",
      "\tEpoch 50/100 - Train loss: 0.1358 - Val accuracy: 0.7500 - Val loss: 0.7373 - Val F1: 0.7847 - LR: 5.00e-05\n",
      "\tEpoch 60/100 - Train loss: 0.1079 - Val accuracy: 0.8750 - Val loss: 0.3806 - Val F1: 0.8750 - LR: 4.00e-05\n",
      "\tEpoch 70/100 - Train loss: 0.0912 - Val accuracy: 0.8750 - Val loss: 0.3017 - Val F1: 0.8750 - LR: 3.00e-05\n",
      "\tEpoch 80/100 - Train loss: 0.0714 - Val accuracy: 0.8750 - Val loss: 0.2863 - Val F1: 0.8750 - LR: 2.00e-05\n",
      "\tEpoch 90/100 - Train loss: 0.0704 - Val accuracy: 0.8750 - Val loss: 0.2819 - Val F1: 0.8750 - LR: 1.00e-05\n",
      "\tEpoch 100/100 - Train loss: 0.0684 - Val accuracy: 0.8750 - Val loss: 0.2796 - Val F1: 0.8750 - LR: 0.00e+00\n",
      "\tBest epoch: 100 - Best val accuracy: 0.8750 - Best val loss: 0.2796 - Best val F1: 0.8750\n",
      "\n",
      "\tEpoch 10/100 - Train loss: 0.5659 - Val accuracy: 0.2500 - Val loss: 1.1025 - Val F1: 0.1000 - LR: 9.00e-05\n",
      "\tEpoch 20/100 - Train loss: 0.3350 - Val accuracy: 0.2500 - Val loss: 1.2121 - Val F1: 0.1000 - LR: 8.00e-05\n",
      "\tEpoch 30/100 - Train loss: 0.2424 - Val accuracy: 0.2500 - Val loss: 1.3578 - Val F1: 0.1000 - LR: 7.00e-05\n",
      "\tEpoch 40/100 - Train loss: 0.1838 - Val accuracy: 0.1250 - Val loss: 1.1935 - Val F1: 0.0714 - LR: 6.00e-05\n",
      "\tEpoch 50/100 - Train loss: 0.1419 - Val accuracy: 0.6250 - Val loss: 0.6271 - Val F1: 0.6806 - LR: 5.00e-05\n",
      "\tEpoch 60/100 - Train loss: 0.1170 - Val accuracy: 0.7500 - Val loss: 0.3431 - Val F1: 0.7500 - LR: 4.00e-05\n",
      "\tEpoch 70/100 - Train loss: 0.0921 - Val accuracy: 0.8750 - Val loss: 0.2796 - Val F1: 0.8750 - LR: 3.00e-05\n",
      "\tEpoch 80/100 - Train loss: 0.0802 - Val accuracy: 0.8750 - Val loss: 0.2622 - Val F1: 0.8750 - LR: 2.00e-05\n",
      "\tEpoch 90/100 - Train loss: 0.0777 - Val accuracy: 0.8750 - Val loss: 0.2538 - Val F1: 0.8750 - LR: 1.00e-05\n",
      "\tEpoch 100/100 - Train loss: 0.0748 - Val accuracy: 0.8750 - Val loss: 0.2505 - Val F1: 0.8750 - LR: 0.00e+00\n",
      "\tBest epoch: 100 - Best val accuracy: 0.8750 - Best val loss: 0.2505 - Best val F1: 0.8750\n",
      "\n",
      "\tEpoch 10/100 - Train loss: 0.5547 - Val accuracy: 0.1250 - Val loss: 1.0958 - Val F1: 0.0278 - LR: 9.00e-05\n",
      "\tEpoch 20/100 - Train loss: 0.3581 - Val accuracy: 0.2500 - Val loss: 1.2227 - Val F1: 0.1000 - LR: 8.00e-05\n",
      "\tEpoch 30/100 - Train loss: 0.2669 - Val accuracy: 0.2500 - Val loss: 1.3841 - Val F1: 0.1000 - LR: 7.00e-05\n",
      "\tEpoch 40/100 - Train loss: 0.1993 - Val accuracy: 0.5000 - Val loss: 0.9629 - Val F1: 0.4821 - LR: 6.00e-05\n",
      "\tEpoch 50/100 - Train loss: 0.1682 - Val accuracy: 0.8750 - Val loss: 0.3174 - Val F1: 0.8250 - LR: 5.00e-05\n",
      "\tEpoch 60/100 - Train loss: 0.1313 - Val accuracy: 1.0000 - Val loss: 0.1858 - Val F1: 1.0000 - LR: 4.00e-05\n",
      "\tEpoch 70/100 - Train loss: 0.1026 - Val accuracy: 1.0000 - Val loss: 0.1496 - Val F1: 1.0000 - LR: 3.00e-05\n",
      "\tEpoch 80/100 - Train loss: 0.0913 - Val accuracy: 1.0000 - Val loss: 0.1336 - Val F1: 1.0000 - LR: 2.00e-05\n",
      "\tEpoch 90/100 - Train loss: 0.0808 - Val accuracy: 1.0000 - Val loss: 0.1256 - Val F1: 1.0000 - LR: 1.00e-05\n",
      "\tEpoch 100/100 - Train loss: 0.0789 - Val accuracy: 1.0000 - Val loss: 0.1228 - Val F1: 1.0000 - LR: 0.00e+00\n",
      "\tBest epoch: 100 - Best val accuracy: 1.0000 - Best val loss: 0.1228 - Best val F1: 1.0000\n",
      "\n",
      "\tEpoch 10/100 - Train loss: 0.5500 - Val accuracy: 0.2500 - Val loss: 1.0886 - Val F1: 0.1000 - LR: 9.00e-05\n",
      "\tEpoch 20/100 - Train loss: 0.3515 - Val accuracy: 0.2500 - Val loss: 1.1199 - Val F1: 0.1000 - LR: 8.00e-05\n",
      "\tEpoch 30/100 - Train loss: 0.2558 - Val accuracy: 0.2500 - Val loss: 1.1440 - Val F1: 0.1000 - LR: 7.00e-05\n",
      "\tEpoch 40/100 - Train loss: 0.1765 - Val accuracy: 0.8750 - Val loss: 0.8271 - Val F1: 0.8250 - LR: 6.00e-05\n",
      "\tEpoch 50/100 - Train loss: 0.1278 - Val accuracy: 1.0000 - Val loss: 0.3478 - Val F1: 1.0000 - LR: 5.00e-05\n",
      "\tEpoch 60/100 - Train loss: 0.0994 - Val accuracy: 1.0000 - Val loss: 0.2084 - Val F1: 1.0000 - LR: 4.00e-05\n",
      "\tEpoch 70/100 - Train loss: 0.0868 - Val accuracy: 1.0000 - Val loss: 0.1742 - Val F1: 1.0000 - LR: 3.00e-05\n",
      "\tEpoch 80/100 - Train loss: 0.0706 - Val accuracy: 1.0000 - Val loss: 0.1598 - Val F1: 1.0000 - LR: 2.00e-05\n",
      "\tEpoch 90/100 - Train loss: 0.0677 - Val accuracy: 1.0000 - Val loss: 0.1532 - Val F1: 1.0000 - LR: 1.00e-05\n",
      "\tEpoch 100/100 - Train loss: 0.0555 - Val accuracy: 1.0000 - Val loss: 0.1511 - Val F1: 1.0000 - LR: 0.00e+00\n",
      "\tBest epoch: 100 - Best val accuracy: 1.0000 - Best val loss: 0.1511 - Best val F1: 1.0000\n",
      "\n",
      "Source class: WAL | Domain: 55 | Accuracy: 0.9378 | Loss: 0.1754 | F1: 0.9363\n",
      "\n",
      "Domain: 56\n",
      "x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Training and evaluating on Dp data via cross-validation...\n",
      "\tEpoch 10/100 - Train loss: 0.5058 - Val accuracy: 0.7143 - Val loss: 1.0374 - Val F1: 0.5952 - LR: 9.00e-05\n",
      "\tEpoch 20/100 - Train loss: 0.3079 - Val accuracy: 0.7143 - Val loss: 1.0636 - Val F1: 0.5952 - LR: 8.00e-05\n",
      "\tEpoch 30/100 - Train loss: 0.1994 - Val accuracy: 0.4286 - Val loss: 1.1139 - Val F1: 0.4286 - LR: 7.00e-05\n",
      "\tEpoch 40/100 - Train loss: 0.1327 - Val accuracy: 0.8571 - Val loss: 0.9029 - Val F1: 0.8730 - LR: 6.00e-05\n",
      "\tEpoch 50/100 - Train loss: 0.1046 - Val accuracy: 1.0000 - Val loss: 0.4825 - Val F1: 1.0000 - LR: 5.00e-05\n",
      "\tEpoch 60/100 - Train loss: 0.0724 - Val accuracy: 1.0000 - Val loss: 0.2846 - Val F1: 1.0000 - LR: 4.00e-05\n",
      "\tEpoch 70/100 - Train loss: 0.0616 - Val accuracy: 1.0000 - Val loss: 0.2230 - Val F1: 1.0000 - LR: 3.00e-05\n",
      "\tEpoch 80/100 - Train loss: 0.0531 - Val accuracy: 1.0000 - Val loss: 0.1996 - Val F1: 1.0000 - LR: 2.00e-05\n",
      "\tEpoch 90/100 - Train loss: 0.0439 - Val accuracy: 1.0000 - Val loss: 0.1894 - Val F1: 1.0000 - LR: 1.00e-05\n",
      "\tEpoch 100/100 - Train loss: 0.0469 - Val accuracy: 1.0000 - Val loss: 0.1858 - Val F1: 1.0000 - LR: 0.00e+00\n",
      "\tBest epoch: 100 - Best val accuracy: 1.0000 - Best val loss: 0.1858 - Best val F1: 1.0000\n",
      "\n",
      "\tEpoch 10/100 - Train loss: 0.5575 - Val accuracy: 0.7143 - Val loss: 1.0742 - Val F1: 0.5952 - LR: 9.00e-05\n",
      "\tEpoch 20/100 - Train loss: 0.3601 - Val accuracy: 0.1429 - Val loss: 1.1312 - Val F1: 0.0357 - LR: 8.00e-05\n",
      "\tEpoch 30/100 - Train loss: 0.2861 - Val accuracy: 0.1429 - Val loss: 1.2258 - Val F1: 0.0357 - LR: 7.00e-05\n",
      "\tEpoch 40/100 - Train loss: 0.2266 - Val accuracy: 0.1429 - Val loss: 1.1267 - Val F1: 0.0357 - LR: 6.00e-05\n",
      "\tEpoch 50/100 - Train loss: 0.2009 - Val accuracy: 1.0000 - Val loss: 0.5535 - Val F1: 1.0000 - LR: 5.00e-05\n",
      "\tEpoch 60/100 - Train loss: 0.1600 - Val accuracy: 1.0000 - Val loss: 0.2784 - Val F1: 1.0000 - LR: 4.00e-05\n",
      "\tEpoch 70/100 - Train loss: 0.1399 - Val accuracy: 1.0000 - Val loss: 0.2084 - Val F1: 1.0000 - LR: 3.00e-05\n",
      "\tEpoch 80/100 - Train loss: 0.1201 - Val accuracy: 1.0000 - Val loss: 0.1842 - Val F1: 1.0000 - LR: 2.00e-05\n",
      "\tEpoch 90/100 - Train loss: 0.1098 - Val accuracy: 1.0000 - Val loss: 0.1738 - Val F1: 1.0000 - LR: 1.00e-05\n",
      "\tEpoch 100/100 - Train loss: 0.1007 - Val accuracy: 1.0000 - Val loss: 0.1699 - Val F1: 1.0000 - LR: 0.00e+00\n",
      "\tBest epoch: 100 - Best val accuracy: 1.0000 - Best val loss: 0.1699 - Best val F1: 1.0000\n",
      "\n",
      "\tEpoch 10/100 - Train loss: 0.5180 - Val accuracy: 0.0000 - Val loss: 1.1118 - Val F1: 0.0000 - LR: 9.00e-05\n",
      "\tEpoch 20/100 - Train loss: 0.3287 - Val accuracy: 0.1429 - Val loss: 1.3281 - Val F1: 0.0357 - LR: 8.00e-05\n",
      "\tEpoch 30/100 - Train loss: 0.2156 - Val accuracy: 0.1429 - Val loss: 1.5854 - Val F1: 0.0357 - LR: 7.00e-05\n",
      "\tEpoch 40/100 - Train loss: 0.1677 - Val accuracy: 0.1429 - Val loss: 1.3633 - Val F1: 0.0357 - LR: 6.00e-05\n",
      "\tEpoch 50/100 - Train loss: 0.1335 - Val accuracy: 0.8571 - Val loss: 0.5324 - Val F1: 0.8095 - LR: 5.00e-05\n",
      "\tEpoch 60/100 - Train loss: 0.1008 - Val accuracy: 1.0000 - Val loss: 0.2347 - Val F1: 1.0000 - LR: 4.00e-05\n",
      "\tEpoch 70/100 - Train loss: 0.0821 - Val accuracy: 1.0000 - Val loss: 0.1681 - Val F1: 1.0000 - LR: 3.00e-05\n",
      "\tEpoch 80/100 - Train loss: 0.0778 - Val accuracy: 1.0000 - Val loss: 0.1455 - Val F1: 1.0000 - LR: 2.00e-05\n",
      "\tEpoch 90/100 - Train loss: 0.0636 - Val accuracy: 1.0000 - Val loss: 0.1359 - Val F1: 1.0000 - LR: 1.00e-05\n",
      "\tEpoch 100/100 - Train loss: 0.0651 - Val accuracy: 1.0000 - Val loss: 0.1324 - Val F1: 1.0000 - LR: 0.00e+00\n",
      "\tBest epoch: 100 - Best val accuracy: 1.0000 - Best val loss: 0.1324 - Best val F1: 1.0000\n",
      "\n",
      "\tEpoch 10/100 - Train loss: 0.5326 - Val accuracy: 0.7143 - Val loss: 1.0645 - Val F1: 0.5952 - LR: 9.00e-05\n",
      "\tEpoch 20/100 - Train loss: 0.3198 - Val accuracy: 0.1429 - Val loss: 1.1541 - Val F1: 0.0357 - LR: 8.00e-05\n",
      "\tEpoch 30/100 - Train loss: 0.2228 - Val accuracy: 0.1429 - Val loss: 1.3384 - Val F1: 0.0357 - LR: 7.00e-05\n",
      "\tEpoch 40/100 - Train loss: 0.1661 - Val accuracy: 0.1429 - Val loss: 1.1711 - Val F1: 0.0357 - LR: 6.00e-05\n",
      "\tEpoch 50/100 - Train loss: 0.1262 - Val accuracy: 0.8571 - Val loss: 0.4407 - Val F1: 0.8095 - LR: 5.00e-05\n",
      "\tEpoch 60/100 - Train loss: 0.0900 - Val accuracy: 1.0000 - Val loss: 0.1800 - Val F1: 1.0000 - LR: 4.00e-05\n",
      "\tEpoch 70/100 - Train loss: 0.0723 - Val accuracy: 1.0000 - Val loss: 0.1232 - Val F1: 1.0000 - LR: 3.00e-05\n",
      "\tEpoch 80/100 - Train loss: 0.0722 - Val accuracy: 1.0000 - Val loss: 0.1026 - Val F1: 1.0000 - LR: 2.00e-05\n",
      "\tEpoch 90/100 - Train loss: 0.0602 - Val accuracy: 1.0000 - Val loss: 0.0935 - Val F1: 1.0000 - LR: 1.00e-05\n",
      "\tEpoch 100/100 - Train loss: 0.0558 - Val accuracy: 1.0000 - Val loss: 0.0903 - Val F1: 1.0000 - LR: 0.00e+00\n",
      "\tBest epoch: 100 - Best val accuracy: 1.0000 - Best val loss: 0.0903 - Best val F1: 1.0000\n",
      "\n",
      "\tEpoch 10/100 - Train loss: 0.4969 - Val accuracy: 0.7143 - Val loss: 1.0551 - Val F1: 0.5952 - LR: 9.00e-05\n",
      "\tEpoch 20/100 - Train loss: 0.3391 - Val accuracy: 0.1429 - Val loss: 1.1178 - Val F1: 0.0357 - LR: 8.00e-05\n",
      "\tEpoch 30/100 - Train loss: 0.2652 - Val accuracy: 0.1429 - Val loss: 1.1916 - Val F1: 0.0357 - LR: 7.00e-05\n",
      "\tEpoch 40/100 - Train loss: 0.2192 - Val accuracy: 0.4286 - Val loss: 0.9556 - Val F1: 0.4558 - LR: 6.00e-05\n",
      "\tEpoch 50/100 - Train loss: 0.1822 - Val accuracy: 0.8571 - Val loss: 0.4549 - Val F1: 0.8095 - LR: 5.00e-05\n",
      "\tEpoch 60/100 - Train loss: 0.1449 - Val accuracy: 0.8571 - Val loss: 0.2823 - Val F1: 0.8095 - LR: 4.00e-05\n",
      "\tEpoch 70/100 - Train loss: 0.1264 - Val accuracy: 0.8571 - Val loss: 0.2400 - Val F1: 0.8095 - LR: 3.00e-05\n",
      "\tEpoch 80/100 - Train loss: 0.1099 - Val accuracy: 1.0000 - Val loss: 0.2236 - Val F1: 1.0000 - LR: 2.00e-05\n",
      "\tEpoch 90/100 - Train loss: 0.0985 - Val accuracy: 1.0000 - Val loss: 0.2166 - Val F1: 1.0000 - LR: 1.00e-05\n",
      "\tEpoch 100/100 - Train loss: 0.1033 - Val accuracy: 1.0000 - Val loss: 0.2143 - Val F1: 1.0000 - LR: 0.00e+00\n",
      "\tBest epoch: 100 - Best val accuracy: 1.0000 - Best val loss: 0.2143 - Best val F1: 1.0000\n",
      "\n",
      "Source class: WAL | Domain: 56 | Accuracy: 0.9750 | Loss: 0.1970 | F1: 0.9720\n",
      "\n",
      "Domain: 57\n",
      "x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Training and evaluating on Dp data via cross-validation...\n",
      "\tEpoch 10/100 - Train loss: 0.5673 - Val accuracy: 0.7143 - Val loss: 1.0140 - Val F1: 0.5952 - LR: 9.00e-05\n",
      "\tEpoch 20/100 - Train loss: 0.3462 - Val accuracy: 0.7143 - Val loss: 0.9871 - Val F1: 0.5952 - LR: 8.00e-05\n",
      "\tEpoch 30/100 - Train loss: 0.2213 - Val accuracy: 0.7143 - Val loss: 1.0060 - Val F1: 0.7063 - LR: 7.00e-05\n",
      "\tEpoch 40/100 - Train loss: 0.1586 - Val accuracy: 0.7143 - Val loss: 0.8950 - Val F1: 0.7063 - LR: 6.00e-05\n",
      "\tEpoch 50/100 - Train loss: 0.1175 - Val accuracy: 0.8571 - Val loss: 0.5494 - Val F1: 0.8095 - LR: 5.00e-05\n",
      "\tEpoch 60/100 - Train loss: 0.0922 - Val accuracy: 0.8571 - Val loss: 0.3624 - Val F1: 0.8095 - LR: 4.00e-05\n",
      "\tEpoch 70/100 - Train loss: 0.0690 - Val accuracy: 0.8571 - Val loss: 0.3106 - Val F1: 0.8095 - LR: 3.00e-05\n",
      "\tEpoch 80/100 - Train loss: 0.0604 - Val accuracy: 0.8571 - Val loss: 0.2917 - Val F1: 0.8095 - LR: 2.00e-05\n",
      "\tEpoch 90/100 - Train loss: 0.0535 - Val accuracy: 0.8571 - Val loss: 0.2849 - Val F1: 0.8095 - LR: 1.00e-05\n",
      "\tEpoch 100/100 - Train loss: 0.0480 - Val accuracy: 0.8571 - Val loss: 0.2828 - Val F1: 0.8095 - LR: 0.00e+00\n",
      "\tBest epoch: 100 - Best val accuracy: 0.8571 - Best val loss: 0.2828 - Best val F1: 0.8095\n",
      "\n",
      "\tEpoch 10/100 - Train loss: 0.6333 - Val accuracy: 0.7143 - Val loss: 1.0531 - Val F1: 0.5952 - LR: 9.00e-05\n",
      "\tEpoch 20/100 - Train loss: 0.3910 - Val accuracy: 0.1429 - Val loss: 1.0838 - Val F1: 0.0357 - LR: 8.00e-05\n",
      "\tEpoch 30/100 - Train loss: 0.2719 - Val accuracy: 0.1429 - Val loss: 1.1630 - Val F1: 0.0357 - LR: 7.00e-05\n",
      "\tEpoch 40/100 - Train loss: 0.1845 - Val accuracy: 0.4286 - Val loss: 1.0621 - Val F1: 0.4558 - LR: 6.00e-05\n",
      "\tEpoch 50/100 - Train loss: 0.1353 - Val accuracy: 0.8571 - Val loss: 0.5166 - Val F1: 0.8095 - LR: 5.00e-05\n",
      "\tEpoch 60/100 - Train loss: 0.1029 - Val accuracy: 0.8571 - Val loss: 0.2760 - Val F1: 0.8095 - LR: 4.00e-05\n",
      "\tEpoch 70/100 - Train loss: 0.0774 - Val accuracy: 0.8571 - Val loss: 0.2171 - Val F1: 0.8095 - LR: 3.00e-05\n",
      "\tEpoch 80/100 - Train loss: 0.0694 - Val accuracy: 0.8571 - Val loss: 0.2002 - Val F1: 0.8095 - LR: 2.00e-05\n",
      "\tEpoch 90/100 - Train loss: 0.0712 - Val accuracy: 0.8571 - Val loss: 0.1932 - Val F1: 0.8095 - LR: 1.00e-05\n",
      "\tEpoch 100/100 - Train loss: 0.0566 - Val accuracy: 0.8571 - Val loss: 0.1913 - Val F1: 0.8095 - LR: 0.00e+00\n",
      "\tBest epoch: 100 - Best val accuracy: 0.8571 - Best val loss: 0.1913 - Best val F1: 0.8095\n",
      "\n",
      "\tEpoch 10/100 - Train loss: 0.6113 - Val accuracy: 0.7143 - Val loss: 1.0258 - Val F1: 0.5952 - LR: 9.00e-05\n",
      "\tEpoch 20/100 - Train loss: 0.3802 - Val accuracy: 0.8571 - Val loss: 1.0319 - Val F1: 0.7922 - LR: 8.00e-05\n",
      "\tEpoch 30/100 - Train loss: 0.2566 - Val accuracy: 0.1429 - Val loss: 1.0566 - Val F1: 0.0357 - LR: 7.00e-05\n",
      "\tEpoch 40/100 - Train loss: 0.1740 - Val accuracy: 0.8571 - Val loss: 0.8626 - Val F1: 0.8095 - LR: 6.00e-05\n",
      "\tEpoch 50/100 - Train loss: 0.1178 - Val accuracy: 0.8571 - Val loss: 0.4769 - Val F1: 0.8095 - LR: 5.00e-05\n",
      "\tEpoch 60/100 - Train loss: 0.0896 - Val accuracy: 0.8571 - Val loss: 0.3103 - Val F1: 0.8095 - LR: 4.00e-05\n",
      "\tEpoch 70/100 - Train loss: 0.0680 - Val accuracy: 0.8571 - Val loss: 0.2506 - Val F1: 0.8095 - LR: 3.00e-05\n",
      "\tEpoch 80/100 - Train loss: 0.0574 - Val accuracy: 1.0000 - Val loss: 0.2255 - Val F1: 1.0000 - LR: 2.00e-05\n",
      "\tEpoch 90/100 - Train loss: 0.0586 - Val accuracy: 1.0000 - Val loss: 0.2155 - Val F1: 1.0000 - LR: 1.00e-05\n",
      "\tEpoch 100/100 - Train loss: 0.0506 - Val accuracy: 1.0000 - Val loss: 0.2123 - Val F1: 1.0000 - LR: 0.00e+00\n",
      "\tBest epoch: 100 - Best val accuracy: 1.0000 - Best val loss: 0.2123 - Best val F1: 1.0000\n",
      "\n",
      "\tEpoch 10/100 - Train loss: 0.5908 - Val accuracy: 0.1429 - Val loss: 1.0764 - Val F1: 0.0357 - LR: 9.00e-05\n",
      "\tEpoch 20/100 - Train loss: 0.3701 - Val accuracy: 0.1429 - Val loss: 1.1942 - Val F1: 0.0357 - LR: 8.00e-05\n",
      "\tEpoch 30/100 - Train loss: 0.2437 - Val accuracy: 0.1429 - Val loss: 1.4413 - Val F1: 0.0357 - LR: 7.00e-05\n",
      "\tEpoch 40/100 - Train loss: 0.1653 - Val accuracy: 0.1429 - Val loss: 1.2559 - Val F1: 0.0357 - LR: 6.00e-05\n",
      "\tEpoch 50/100 - Train loss: 0.1242 - Val accuracy: 0.8571 - Val loss: 0.5455 - Val F1: 0.8095 - LR: 5.00e-05\n",
      "\tEpoch 60/100 - Train loss: 0.0952 - Val accuracy: 0.8571 - Val loss: 0.2708 - Val F1: 0.8095 - LR: 4.00e-05\n",
      "\tEpoch 70/100 - Train loss: 0.0869 - Val accuracy: 1.0000 - Val loss: 0.2068 - Val F1: 1.0000 - LR: 3.00e-05\n",
      "\tEpoch 80/100 - Train loss: 0.0717 - Val accuracy: 1.0000 - Val loss: 0.1848 - Val F1: 1.0000 - LR: 2.00e-05\n",
      "\tEpoch 90/100 - Train loss: 0.0609 - Val accuracy: 1.0000 - Val loss: 0.1754 - Val F1: 1.0000 - LR: 1.00e-05\n",
      "\tEpoch 100/100 - Train loss: 0.0654 - Val accuracy: 1.0000 - Val loss: 0.1721 - Val F1: 1.0000 - LR: 0.00e+00\n",
      "\tBest epoch: 100 - Best val accuracy: 1.0000 - Best val loss: 0.1721 - Best val F1: 1.0000\n",
      "\n",
      "\tEpoch 10/100 - Train loss: 0.5905 - Val accuracy: 0.7143 - Val loss: 1.0261 - Val F1: 0.5952 - LR: 9.00e-05\n",
      "\tEpoch 20/100 - Train loss: 0.3514 - Val accuracy: 0.7143 - Val loss: 0.9786 - Val F1: 0.5952 - LR: 8.00e-05\n",
      "\tEpoch 30/100 - Train loss: 0.2165 - Val accuracy: 0.1429 - Val loss: 1.0463 - Val F1: 0.0357 - LR: 7.00e-05\n",
      "\tEpoch 40/100 - Train loss: 0.1288 - Val accuracy: 0.4286 - Val loss: 0.9595 - Val F1: 0.4558 - LR: 6.00e-05\n",
      "\tEpoch 50/100 - Train loss: 0.0910 - Val accuracy: 0.8571 - Val loss: 0.5537 - Val F1: 0.8095 - LR: 5.00e-05\n",
      "\tEpoch 60/100 - Train loss: 0.0668 - Val accuracy: 0.8571 - Val loss: 0.3337 - Val F1: 0.8095 - LR: 4.00e-05\n",
      "\tEpoch 70/100 - Train loss: 0.0549 - Val accuracy: 0.8571 - Val loss: 0.2848 - Val F1: 0.8095 - LR: 3.00e-05\n",
      "\tEpoch 80/100 - Train loss: 0.0478 - Val accuracy: 0.8571 - Val loss: 0.2698 - Val F1: 0.8095 - LR: 2.00e-05\n",
      "\tEpoch 90/100 - Train loss: 0.0434 - Val accuracy: 0.8571 - Val loss: 0.2641 - Val F1: 0.8095 - LR: 1.00e-05\n",
      "\tEpoch 100/100 - Train loss: 0.0419 - Val accuracy: 0.8571 - Val loss: 0.2623 - Val F1: 0.8095 - LR: 0.00e+00\n",
      "\tBest epoch: 100 - Best val accuracy: 0.8571 - Best val loss: 0.2623 - Best val F1: 0.8095\n",
      "\n",
      "Source class: WAL | Domain: 57 | Accuracy: 0.9250 | Loss: 0.2447 | F1: 0.9042\n",
      "\n",
      "Domain: 58\n",
      "x_dp_dom.shape: (38, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Training and evaluating on Dp data via cross-validation...\n",
      "\tEpoch 10/100 - Train loss: 0.5407 - Val accuracy: 0.6667 - Val loss: 1.0253 - Val F1: 0.5333 - LR: 9.00e-05\n",
      "\tEpoch 20/100 - Train loss: 0.3178 - Val accuracy: 0.6667 - Val loss: 0.9192 - Val F1: 0.5333 - LR: 8.00e-05\n",
      "\tEpoch 30/100 - Train loss: 0.2013 - Val accuracy: 0.6667 - Val loss: 0.7503 - Val F1: 0.5333 - LR: 7.00e-05\n",
      "\tEpoch 40/100 - Train loss: 0.1561 - Val accuracy: 0.8333 - Val loss: 0.5445 - Val F1: 0.7778 - LR: 6.00e-05\n",
      "\tEpoch 50/100 - Train loss: 0.1111 - Val accuracy: 0.8333 - Val loss: 0.4049 - Val F1: 0.7778 - LR: 5.00e-05\n",
      "\tEpoch 60/100 - Train loss: 0.0952 - Val accuracy: 1.0000 - Val loss: 0.3501 - Val F1: 1.0000 - LR: 4.00e-05\n",
      "\tEpoch 70/100 - Train loss: 0.0741 - Val accuracy: 1.0000 - Val loss: 0.3383 - Val F1: 1.0000 - LR: 3.00e-05\n",
      "\tEpoch 80/100 - Train loss: 0.0776 - Val accuracy: 1.0000 - Val loss: 0.3349 - Val F1: 1.0000 - LR: 2.00e-05\n",
      "\tEpoch 90/100 - Train loss: 0.0629 - Val accuracy: 1.0000 - Val loss: 0.3332 - Val F1: 1.0000 - LR: 1.00e-05\n",
      "\tEpoch 100/100 - Train loss: 0.0617 - Val accuracy: 1.0000 - Val loss: 0.3327 - Val F1: 1.0000 - LR: 0.00e+00\n",
      "\tBest epoch: 99 - Best val accuracy: 1.0000 - Best val loss: 0.3326 - Best val F1: 1.0000\n",
      "\n",
      "\tEpoch 10/100 - Train loss: 0.4400 - Val accuracy: 0.6667 - Val loss: 1.0238 - Val F1: 0.5333 - LR: 9.00e-05\n",
      "\tEpoch 20/100 - Train loss: 0.2836 - Val accuracy: 0.6667 - Val loss: 0.9535 - Val F1: 0.5333 - LR: 8.00e-05\n",
      "\tEpoch 30/100 - Train loss: 0.2109 - Val accuracy: 0.8333 - Val loss: 0.8581 - Val F1: 0.7778 - LR: 7.00e-05\n",
      "\tEpoch 40/100 - Train loss: 0.1517 - Val accuracy: 0.8333 - Val loss: 0.5594 - Val F1: 0.7778 - LR: 6.00e-05\n",
      "\tEpoch 50/100 - Train loss: 0.1130 - Val accuracy: 0.8333 - Val loss: 0.3407 - Val F1: 0.7778 - LR: 5.00e-05\n",
      "\tEpoch 60/100 - Train loss: 0.0946 - Val accuracy: 0.8333 - Val loss: 0.2824 - Val F1: 0.7778 - LR: 4.00e-05\n",
      "\tEpoch 70/100 - Train loss: 0.0775 - Val accuracy: 1.0000 - Val loss: 0.2642 - Val F1: 1.0000 - LR: 3.00e-05\n",
      "\tEpoch 80/100 - Train loss: 0.0721 - Val accuracy: 1.0000 - Val loss: 0.2588 - Val F1: 1.0000 - LR: 2.00e-05\n",
      "\tEpoch 90/100 - Train loss: 0.0627 - Val accuracy: 1.0000 - Val loss: 0.2557 - Val F1: 1.0000 - LR: 1.00e-05\n",
      "\tEpoch 100/100 - Train loss: 0.0636 - Val accuracy: 1.0000 - Val loss: 0.2546 - Val F1: 1.0000 - LR: 0.00e+00\n",
      "\tBest epoch: 100 - Best val accuracy: 1.0000 - Best val loss: 0.2546 - Best val F1: 1.0000\n",
      "\n",
      "\tEpoch 10/100 - Train loss: 0.5371 - Val accuracy: 0.6667 - Val loss: 1.0385 - Val F1: 0.5333 - LR: 9.00e-05\n",
      "\tEpoch 20/100 - Train loss: 0.3107 - Val accuracy: 0.6667 - Val loss: 0.9835 - Val F1: 0.5333 - LR: 8.00e-05\n",
      "\tEpoch 30/100 - Train loss: 0.2123 - Val accuracy: 0.6667 - Val loss: 0.8551 - Val F1: 0.5333 - LR: 7.00e-05\n",
      "\tEpoch 40/100 - Train loss: 0.1678 - Val accuracy: 0.8333 - Val loss: 0.5544 - Val F1: 0.7778 - LR: 6.00e-05\n",
      "\tEpoch 50/100 - Train loss: 0.1315 - Val accuracy: 0.8333 - Val loss: 0.3811 - Val F1: 0.7778 - LR: 5.00e-05\n",
      "\tEpoch 60/100 - Train loss: 0.1113 - Val accuracy: 0.8333 - Val loss: 0.3317 - Val F1: 0.7778 - LR: 4.00e-05\n",
      "\tEpoch 70/100 - Train loss: 0.0954 - Val accuracy: 0.8333 - Val loss: 0.3113 - Val F1: 0.7778 - LR: 3.00e-05\n",
      "\tEpoch 80/100 - Train loss: 0.0836 - Val accuracy: 0.8333 - Val loss: 0.3030 - Val F1: 0.7778 - LR: 2.00e-05\n",
      "\tEpoch 90/100 - Train loss: 0.0735 - Val accuracy: 0.8333 - Val loss: 0.3000 - Val F1: 0.7778 - LR: 1.00e-05\n",
      "\tEpoch 100/100 - Train loss: 0.0744 - Val accuracy: 0.8333 - Val loss: 0.2988 - Val F1: 0.7778 - LR: 0.00e+00\n",
      "\tBest epoch: 100 - Best val accuracy: 0.8333 - Best val loss: 0.2988 - Best val F1: 0.7778\n",
      "\n",
      "\tEpoch 10/100 - Train loss: 0.5169 - Val accuracy: 0.7143 - Val loss: 1.0211 - Val F1: 0.5952 - LR: 9.00e-05\n",
      "\tEpoch 20/100 - Train loss: 0.3148 - Val accuracy: 0.7143 - Val loss: 0.9863 - Val F1: 0.5952 - LR: 8.00e-05\n",
      "\tEpoch 30/100 - Train loss: 0.2118 - Val accuracy: 0.8571 - Val loss: 1.0024 - Val F1: 0.8095 - LR: 7.00e-05\n",
      "\tEpoch 40/100 - Train loss: 0.1729 - Val accuracy: 0.8571 - Val loss: 0.7988 - Val F1: 0.8095 - LR: 6.00e-05\n",
      "\tEpoch 50/100 - Train loss: 0.1210 - Val accuracy: 1.0000 - Val loss: 0.4579 - Val F1: 1.0000 - LR: 5.00e-05\n",
      "\tEpoch 60/100 - Train loss: 0.0975 - Val accuracy: 0.8571 - Val loss: 0.3262 - Val F1: 0.7922 - LR: 4.00e-05\n",
      "\tEpoch 70/100 - Train loss: 0.0815 - Val accuracy: 0.8571 - Val loss: 0.3012 - Val F1: 0.7922 - LR: 3.00e-05\n",
      "\tEpoch 80/100 - Train loss: 0.0756 - Val accuracy: 0.8571 - Val loss: 0.3011 - Val F1: 0.7922 - LR: 2.00e-05\n",
      "\tEpoch 90/100 - Train loss: 0.0650 - Val accuracy: 0.8571 - Val loss: 0.3022 - Val F1: 0.7922 - LR: 1.00e-05\n",
      "\tEpoch 100/100 - Train loss: 0.0629 - Val accuracy: 0.8571 - Val loss: 0.3037 - Val F1: 0.7922 - LR: 0.00e+00\n",
      "\tBest epoch: 74 - Best val accuracy: 0.8571 - Best val loss: 0.3002 - Best val F1: 0.7922\n",
      "\n",
      "\tEpoch 10/100 - Train loss: 0.5517 - Val accuracy: 0.7143 - Val loss: 1.0688 - Val F1: 0.5952 - LR: 9.00e-05\n",
      "\tEpoch 20/100 - Train loss: 0.3311 - Val accuracy: 0.7143 - Val loss: 0.9956 - Val F1: 0.5952 - LR: 8.00e-05\n",
      "\tEpoch 30/100 - Train loss: 0.2212 - Val accuracy: 0.8571 - Val loss: 0.9629 - Val F1: 0.8095 - LR: 7.00e-05\n",
      "\tEpoch 40/100 - Train loss: 0.1576 - Val accuracy: 0.8571 - Val loss: 0.7350 - Val F1: 0.8095 - LR: 6.00e-05\n",
      "\tEpoch 50/100 - Train loss: 0.1123 - Val accuracy: 0.8571 - Val loss: 0.4409 - Val F1: 0.8095 - LR: 5.00e-05\n",
      "\tEpoch 60/100 - Train loss: 0.0908 - Val accuracy: 0.8571 - Val loss: 0.3170 - Val F1: 0.8095 - LR: 4.00e-05\n",
      "\tEpoch 70/100 - Train loss: 0.0858 - Val accuracy: 0.8571 - Val loss: 0.2845 - Val F1: 0.8095 - LR: 3.00e-05\n",
      "\tEpoch 80/100 - Train loss: 0.0656 - Val accuracy: 0.8571 - Val loss: 0.2738 - Val F1: 0.8095 - LR: 2.00e-05\n",
      "\tEpoch 90/100 - Train loss: 0.0694 - Val accuracy: 0.8571 - Val loss: 0.2705 - Val F1: 0.8095 - LR: 1.00e-05\n",
      "\tEpoch 100/100 - Train loss: 0.0622 - Val accuracy: 0.8571 - Val loss: 0.2693 - Val F1: 0.8095 - LR: 0.00e+00\n",
      "\tBest epoch: 100 - Best val accuracy: 0.8571 - Best val loss: 0.2693 - Best val F1: 0.8095\n",
      "\n",
      "Source class: WAL | Domain: 58 | Accuracy: 0.8393 | Loss: 0.2744 | F1: 0.8048\n",
      "\n",
      "Domain: 59\n",
      "x_dp_dom.shape: (43, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Training and evaluating on Dp data via cross-validation...\n",
      "\tEpoch 10/100 - Train loss: 0.5231 - Val accuracy: 0.1429 - Val loss: 1.1566 - Val F1: 0.0357 - LR: 9.00e-05\n",
      "\tEpoch 20/100 - Train loss: 0.3149 - Val accuracy: 0.1429 - Val loss: 1.3077 - Val F1: 0.0357 - LR: 8.00e-05\n",
      "\tEpoch 30/100 - Train loss: 0.2188 - Val accuracy: 0.1429 - Val loss: 1.4906 - Val F1: 0.0357 - LR: 7.00e-05\n",
      "\tEpoch 40/100 - Train loss: 0.1653 - Val accuracy: 0.4286 - Val loss: 1.0623 - Val F1: 0.4286 - LR: 6.00e-05\n",
      "\tEpoch 50/100 - Train loss: 0.1331 - Val accuracy: 1.0000 - Val loss: 0.3349 - Val F1: 1.0000 - LR: 5.00e-05\n",
      "\tEpoch 60/100 - Train loss: 0.0877 - Val accuracy: 1.0000 - Val loss: 0.1475 - Val F1: 1.0000 - LR: 4.00e-05\n",
      "\tEpoch 70/100 - Train loss: 0.0744 - Val accuracy: 1.0000 - Val loss: 0.1044 - Val F1: 1.0000 - LR: 3.00e-05\n",
      "\tEpoch 80/100 - Train loss: 0.0692 - Val accuracy: 1.0000 - Val loss: 0.0889 - Val F1: 1.0000 - LR: 2.00e-05\n",
      "\tEpoch 90/100 - Train loss: 0.0651 - Val accuracy: 1.0000 - Val loss: 0.0821 - Val F1: 1.0000 - LR: 1.00e-05\n",
      "\tEpoch 100/100 - Train loss: 0.0572 - Val accuracy: 1.0000 - Val loss: 0.0796 - Val F1: 1.0000 - LR: 0.00e+00\n",
      "\tBest epoch: 100 - Best val accuracy: 1.0000 - Best val loss: 0.0796 - Best val F1: 1.0000\n",
      "\n",
      "\tEpoch 10/100 - Train loss: 0.5131 - Val accuracy: 0.1429 - Val loss: 1.0958 - Val F1: 0.0357 - LR: 9.00e-05\n",
      "\tEpoch 20/100 - Train loss: 0.3236 - Val accuracy: 0.1429 - Val loss: 1.2371 - Val F1: 0.0357 - LR: 8.00e-05\n",
      "\tEpoch 30/100 - Train loss: 0.2088 - Val accuracy: 0.1429 - Val loss: 1.4099 - Val F1: 0.0357 - LR: 7.00e-05\n",
      "\tEpoch 40/100 - Train loss: 0.1538 - Val accuracy: 0.2857 - Val loss: 1.2637 - Val F1: 0.1837 - LR: 6.00e-05\n",
      "\tEpoch 50/100 - Train loss: 0.1089 - Val accuracy: 1.0000 - Val loss: 0.5383 - Val F1: 1.0000 - LR: 5.00e-05\n",
      "\tEpoch 60/100 - Train loss: 0.0801 - Val accuracy: 1.0000 - Val loss: 0.1992 - Val F1: 1.0000 - LR: 4.00e-05\n",
      "\tEpoch 70/100 - Train loss: 0.0695 - Val accuracy: 1.0000 - Val loss: 0.1228 - Val F1: 1.0000 - LR: 3.00e-05\n",
      "\tEpoch 80/100 - Train loss: 0.0613 - Val accuracy: 1.0000 - Val loss: 0.1004 - Val F1: 1.0000 - LR: 2.00e-05\n",
      "\tEpoch 90/100 - Train loss: 0.0460 - Val accuracy: 1.0000 - Val loss: 0.0919 - Val F1: 1.0000 - LR: 1.00e-05\n",
      "\tEpoch 100/100 - Train loss: 0.0465 - Val accuracy: 1.0000 - Val loss: 0.0887 - Val F1: 1.0000 - LR: 0.00e+00\n",
      "\tBest epoch: 100 - Best val accuracy: 1.0000 - Best val loss: 0.0887 - Best val F1: 1.0000\n",
      "\n",
      "\tEpoch 10/100 - Train loss: 0.5959 - Val accuracy: 0.1429 - Val loss: 1.0794 - Val F1: 0.0357 - LR: 9.00e-05\n",
      "\tEpoch 20/100 - Train loss: 0.3383 - Val accuracy: 0.1429 - Val loss: 1.1726 - Val F1: 0.0357 - LR: 8.00e-05\n",
      "\tEpoch 30/100 - Train loss: 0.2089 - Val accuracy: 0.1429 - Val loss: 1.3172 - Val F1: 0.0357 - LR: 7.00e-05\n",
      "\tEpoch 40/100 - Train loss: 0.1470 - Val accuracy: 0.2857 - Val loss: 1.1081 - Val F1: 0.2789 - LR: 6.00e-05\n",
      "\tEpoch 50/100 - Train loss: 0.1137 - Val accuracy: 1.0000 - Val loss: 0.4903 - Val F1: 1.0000 - LR: 5.00e-05\n",
      "\tEpoch 60/100 - Train loss: 0.0766 - Val accuracy: 1.0000 - Val loss: 0.2176 - Val F1: 1.0000 - LR: 4.00e-05\n",
      "\tEpoch 70/100 - Train loss: 0.0618 - Val accuracy: 1.0000 - Val loss: 0.1456 - Val F1: 1.0000 - LR: 3.00e-05\n",
      "\tEpoch 80/100 - Train loss: 0.0582 - Val accuracy: 1.0000 - Val loss: 0.1213 - Val F1: 1.0000 - LR: 2.00e-05\n",
      "\tEpoch 90/100 - Train loss: 0.0510 - Val accuracy: 1.0000 - Val loss: 0.1113 - Val F1: 1.0000 - LR: 1.00e-05\n",
      "\tEpoch 100/100 - Train loss: 0.0461 - Val accuracy: 1.0000 - Val loss: 0.1074 - Val F1: 1.0000 - LR: 0.00e+00\n",
      "\tBest epoch: 100 - Best val accuracy: 1.0000 - Best val loss: 0.1074 - Best val F1: 1.0000\n",
      "\n",
      "\tEpoch 10/100 - Train loss: 0.5161 - Val accuracy: 0.7143 - Val loss: 1.0423 - Val F1: 0.5952 - LR: 9.00e-05\n",
      "\tEpoch 20/100 - Train loss: 0.2996 - Val accuracy: 0.1429 - Val loss: 1.1706 - Val F1: 0.0357 - LR: 8.00e-05\n",
      "\tEpoch 30/100 - Train loss: 0.1874 - Val accuracy: 0.2857 - Val loss: 1.3360 - Val F1: 0.1837 - LR: 7.00e-05\n",
      "\tEpoch 40/100 - Train loss: 0.1195 - Val accuracy: 0.2857 - Val loss: 1.2013 - Val F1: 0.1837 - LR: 6.00e-05\n",
      "\tEpoch 50/100 - Train loss: 0.0852 - Val accuracy: 0.8571 - Val loss: 0.6031 - Val F1: 0.8730 - LR: 5.00e-05\n",
      "\tEpoch 60/100 - Train loss: 0.0713 - Val accuracy: 1.0000 - Val loss: 0.2589 - Val F1: 1.0000 - LR: 4.00e-05\n",
      "\tEpoch 70/100 - Train loss: 0.0519 - Val accuracy: 1.0000 - Val loss: 0.1672 - Val F1: 1.0000 - LR: 3.00e-05\n",
      "\tEpoch 80/100 - Train loss: 0.0380 - Val accuracy: 1.0000 - Val loss: 0.1401 - Val F1: 1.0000 - LR: 2.00e-05\n",
      "\tEpoch 90/100 - Train loss: 0.0426 - Val accuracy: 1.0000 - Val loss: 0.1300 - Val F1: 1.0000 - LR: 1.00e-05\n",
      "\tEpoch 100/100 - Train loss: 0.0352 - Val accuracy: 1.0000 - Val loss: 0.1266 - Val F1: 1.0000 - LR: 0.00e+00\n",
      "\tBest epoch: 100 - Best val accuracy: 1.0000 - Best val loss: 0.1266 - Best val F1: 1.0000\n",
      "\n",
      "\tEpoch 10/100 - Train loss: 0.5571 - Val accuracy: 0.7143 - Val loss: 1.0484 - Val F1: 0.5952 - LR: 9.00e-05\n",
      "\tEpoch 20/100 - Train loss: 0.3070 - Val accuracy: 0.2857 - Val loss: 1.1890 - Val F1: 0.1286 - LR: 8.00e-05\n",
      "\tEpoch 30/100 - Train loss: 0.2092 - Val accuracy: 0.2857 - Val loss: 1.3756 - Val F1: 0.1286 - LR: 7.00e-05\n",
      "\tEpoch 40/100 - Train loss: 0.1405 - Val accuracy: 0.4286 - Val loss: 1.1691 - Val F1: 0.3810 - LR: 6.00e-05\n",
      "\tEpoch 50/100 - Train loss: 0.1037 - Val accuracy: 1.0000 - Val loss: 0.5190 - Val F1: 1.0000 - LR: 5.00e-05\n",
      "\tEpoch 60/100 - Train loss: 0.0827 - Val accuracy: 1.0000 - Val loss: 0.2357 - Val F1: 1.0000 - LR: 4.00e-05\n",
      "\tEpoch 70/100 - Train loss: 0.0666 - Val accuracy: 1.0000 - Val loss: 0.1527 - Val F1: 1.0000 - LR: 3.00e-05\n",
      "\tEpoch 80/100 - Train loss: 0.0533 - Val accuracy: 1.0000 - Val loss: 0.1230 - Val F1: 1.0000 - LR: 2.00e-05\n",
      "\tEpoch 90/100 - Train loss: 0.0555 - Val accuracy: 1.0000 - Val loss: 0.1107 - Val F1: 1.0000 - LR: 1.00e-05\n",
      "\tEpoch 100/100 - Train loss: 0.0483 - Val accuracy: 1.0000 - Val loss: 0.1063 - Val F1: 1.0000 - LR: 0.00e+00\n",
      "\tBest epoch: 100 - Best val accuracy: 1.0000 - Best val loss: 0.1063 - Best val F1: 1.0000\n",
      "\n",
      "Source class: WAL | Domain: 59 | Accuracy: 0.9750 | Loss: 0.1209 | F1: 0.9750\n",
      "\n",
      "Domain: 60\n",
      "x_dp_dom.shape: (47, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Training and evaluating on Dp data via cross-validation...\n",
      "\tEpoch 10/100 - Train loss: 0.6278 - Val accuracy: 0.6250 - Val loss: 1.0531 - Val F1: 0.4808 - LR: 9.00e-05\n",
      "\tEpoch 20/100 - Train loss: 0.4121 - Val accuracy: 0.2500 - Val loss: 1.1067 - Val F1: 0.1000 - LR: 8.00e-05\n",
      "\tEpoch 30/100 - Train loss: 0.2997 - Val accuracy: 0.2500 - Val loss: 1.2544 - Val F1: 0.1000 - LR: 7.00e-05\n",
      "\tEpoch 40/100 - Train loss: 0.2309 - Val accuracy: 0.2500 - Val loss: 1.2404 - Val F1: 0.1111 - LR: 6.00e-05\n",
      "\tEpoch 50/100 - Train loss: 0.1833 - Val accuracy: 0.6250 - Val loss: 0.7288 - Val F1: 0.6354 - LR: 5.00e-05\n",
      "\tEpoch 60/100 - Train loss: 0.1425 - Val accuracy: 0.8750 - Val loss: 0.3983 - Val F1: 0.8250 - LR: 4.00e-05\n",
      "\tEpoch 70/100 - Train loss: 0.1210 - Val accuracy: 0.8750 - Val loss: 0.3126 - Val F1: 0.8250 - LR: 3.00e-05\n",
      "\tEpoch 80/100 - Train loss: 0.1028 - Val accuracy: 0.8750 - Val loss: 0.2876 - Val F1: 0.8250 - LR: 2.00e-05\n",
      "\tEpoch 90/100 - Train loss: 0.0928 - Val accuracy: 0.8750 - Val loss: 0.2781 - Val F1: 0.8250 - LR: 1.00e-05\n",
      "\tEpoch 100/100 - Train loss: 0.0972 - Val accuracy: 0.8750 - Val loss: 0.2741 - Val F1: 0.8250 - LR: 0.00e+00\n",
      "\tBest epoch: 100 - Best val accuracy: 0.8750 - Best val loss: 0.2741 - Best val F1: 0.8250\n",
      "\n",
      "\tEpoch 10/100 - Train loss: 0.6264 - Val accuracy: 0.2500 - Val loss: 1.0972 - Val F1: 0.1000 - LR: 9.00e-05\n",
      "\tEpoch 20/100 - Train loss: 0.4545 - Val accuracy: 0.2500 - Val loss: 1.1618 - Val F1: 0.1000 - LR: 8.00e-05\n",
      "\tEpoch 30/100 - Train loss: 0.3390 - Val accuracy: 0.3750 - Val loss: 1.2667 - Val F1: 0.3750 - LR: 7.00e-05\n",
      "\tEpoch 40/100 - Train loss: 0.2662 - Val accuracy: 0.2500 - Val loss: 1.1056 - Val F1: 0.3083 - LR: 6.00e-05\n",
      "\tEpoch 50/100 - Train loss: 0.2271 - Val accuracy: 0.7500 - Val loss: 0.6246 - Val F1: 0.7500 - LR: 5.00e-05\n",
      "\tEpoch 60/100 - Train loss: 0.1763 - Val accuracy: 0.7500 - Val loss: 0.4098 - Val F1: 0.7500 - LR: 4.00e-05\n",
      "\tEpoch 70/100 - Train loss: 0.1545 - Val accuracy: 0.7500 - Val loss: 0.3664 - Val F1: 0.7500 - LR: 3.00e-05\n",
      "\tEpoch 80/100 - Train loss: 0.1326 - Val accuracy: 0.7500 - Val loss: 0.3561 - Val F1: 0.7500 - LR: 2.00e-05\n",
      "\tEpoch 90/100 - Train loss: 0.1311 - Val accuracy: 0.7500 - Val loss: 0.3550 - Val F1: 0.7500 - LR: 1.00e-05\n",
      "\tEpoch 100/100 - Train loss: 0.1257 - Val accuracy: 0.7500 - Val loss: 0.3552 - Val F1: 0.7500 - LR: 0.00e+00\n",
      "\tBest epoch: 93 - Best val accuracy: 0.7500 - Best val loss: 0.3549 - Best val F1: 0.7500\n",
      "\n",
      "\tEpoch 10/100 - Train loss: 0.6954 - Val accuracy: 0.2500 - Val loss: 1.1066 - Val F1: 0.1000 - LR: 9.00e-05\n",
      "\tEpoch 20/100 - Train loss: 0.4289 - Val accuracy: 0.2500 - Val loss: 1.1990 - Val F1: 0.1000 - LR: 8.00e-05\n",
      "\tEpoch 30/100 - Train loss: 0.3085 - Val accuracy: 0.2500 - Val loss: 1.3245 - Val F1: 0.1000 - LR: 7.00e-05\n",
      "\tEpoch 40/100 - Train loss: 0.2054 - Val accuracy: 0.3750 - Val loss: 1.2446 - Val F1: 0.3512 - LR: 6.00e-05\n",
      "\tEpoch 50/100 - Train loss: 0.1678 - Val accuracy: 0.7500 - Val loss: 0.6978 - Val F1: 0.7556 - LR: 5.00e-05\n",
      "\tEpoch 60/100 - Train loss: 0.1265 - Val accuracy: 0.8750 - Val loss: 0.3652 - Val F1: 0.8250 - LR: 4.00e-05\n",
      "\tEpoch 70/100 - Train loss: 0.1053 - Val accuracy: 0.8750 - Val loss: 0.3031 - Val F1: 0.8250 - LR: 3.00e-05\n",
      "\tEpoch 80/100 - Train loss: 0.0883 - Val accuracy: 0.8750 - Val loss: 0.2896 - Val F1: 0.8250 - LR: 2.00e-05\n",
      "\tEpoch 90/100 - Train loss: 0.0862 - Val accuracy: 0.8750 - Val loss: 0.2858 - Val F1: 0.8250 - LR: 1.00e-05\n",
      "\tEpoch 100/100 - Train loss: 0.0769 - Val accuracy: 0.8750 - Val loss: 0.2847 - Val F1: 0.8250 - LR: 0.00e+00\n",
      "\tBest epoch: 100 - Best val accuracy: 0.8750 - Best val loss: 0.2847 - Best val F1: 0.8250\n",
      "\n",
      "\tEpoch 10/100 - Train loss: 0.6639 - Val accuracy: 0.6250 - Val loss: 1.0547 - Val F1: 0.4808 - LR: 9.00e-05\n",
      "\tEpoch 20/100 - Train loss: 0.4488 - Val accuracy: 0.2500 - Val loss: 1.0944 - Val F1: 0.1000 - LR: 8.00e-05\n",
      "\tEpoch 30/100 - Train loss: 0.3187 - Val accuracy: 0.2500 - Val loss: 1.2264 - Val F1: 0.1000 - LR: 7.00e-05\n",
      "\tEpoch 40/100 - Train loss: 0.2446 - Val accuracy: 0.3750 - Val loss: 1.2501 - Val F1: 0.3583 - LR: 6.00e-05\n",
      "\tEpoch 50/100 - Train loss: 0.1924 - Val accuracy: 0.5000 - Val loss: 0.8481 - Val F1: 0.5687 - LR: 5.00e-05\n",
      "\tEpoch 60/100 - Train loss: 0.1505 - Val accuracy: 0.7500 - Val loss: 0.4676 - Val F1: 0.7500 - LR: 4.00e-05\n",
      "\tEpoch 70/100 - Train loss: 0.1354 - Val accuracy: 0.7500 - Val loss: 0.3839 - Val F1: 0.7500 - LR: 3.00e-05\n",
      "\tEpoch 80/100 - Train loss: 0.1153 - Val accuracy: 0.8750 - Val loss: 0.3726 - Val F1: 0.8250 - LR: 2.00e-05\n",
      "\tEpoch 90/100 - Train loss: 0.1101 - Val accuracy: 0.8750 - Val loss: 0.3707 - Val F1: 0.8250 - LR: 1.00e-05\n",
      "\tEpoch 100/100 - Train loss: 0.1122 - Val accuracy: 0.8750 - Val loss: 0.3712 - Val F1: 0.8250 - LR: 0.00e+00\n",
      "\tBest epoch: 93 - Best val accuracy: 0.8750 - Best val loss: 0.3706 - Best val F1: 0.8250\n",
      "\n",
      "\tEpoch 10/100 - Train loss: 0.6093 - Val accuracy: 0.6250 - Val loss: 1.0479 - Val F1: 0.4808 - LR: 9.00e-05\n",
      "\tEpoch 20/100 - Train loss: 0.4434 - Val accuracy: 0.3750 - Val loss: 1.1005 - Val F1: 0.3194 - LR: 8.00e-05\n",
      "\tEpoch 30/100 - Train loss: 0.3206 - Val accuracy: 0.2500 - Val loss: 1.2064 - Val F1: 0.1250 - LR: 7.00e-05\n",
      "\tEpoch 40/100 - Train loss: 0.2326 - Val accuracy: 0.3750 - Val loss: 1.0734 - Val F1: 0.3512 - LR: 6.00e-05\n",
      "\tEpoch 50/100 - Train loss: 0.1877 - Val accuracy: 0.8750 - Val loss: 0.6635 - Val F1: 0.8250 - LR: 5.00e-05\n",
      "\tEpoch 60/100 - Train loss: 0.1436 - Val accuracy: 0.8750 - Val loss: 0.4629 - Val F1: 0.8250 - LR: 4.00e-05\n",
      "\tEpoch 70/100 - Train loss: 0.1141 - Val accuracy: 0.8750 - Val loss: 0.4167 - Val F1: 0.8250 - LR: 3.00e-05\n",
      "\tEpoch 80/100 - Train loss: 0.1117 - Val accuracy: 0.8750 - Val loss: 0.4068 - Val F1: 0.8250 - LR: 2.00e-05\n",
      "\tEpoch 90/100 - Train loss: 0.1023 - Val accuracy: 0.8750 - Val loss: 0.4055 - Val F1: 0.8250 - LR: 1.00e-05\n",
      "\tEpoch 100/100 - Train loss: 0.0935 - Val accuracy: 0.8750 - Val loss: 0.4054 - Val F1: 0.8250 - LR: 0.00e+00\n",
      "\tBest epoch: 100 - Best val accuracy: 0.8750 - Best val loss: 0.4054 - Best val F1: 0.8250\n",
      "\n",
      "Source class: WAL | Domain: 60 | Accuracy: 0.8689 | Loss: 0.3400 | F1: 0.8661\n",
      "\n",
      "Domain: 61\n",
      "x_dp_dom.shape: (47, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Training and evaluating on Dp data via cross-validation...\n",
      "\tEpoch 10/100 - Train loss: 0.6110 - Val accuracy: 0.2500 - Val loss: 1.0805 - Val F1: 0.2411 - LR: 9.00e-05\n",
      "\tEpoch 20/100 - Train loss: 0.3583 - Val accuracy: 0.2500 - Val loss: 1.1776 - Val F1: 0.1000 - LR: 8.00e-05\n",
      "\tEpoch 30/100 - Train loss: 0.2389 - Val accuracy: 0.2500 - Val loss: 1.3837 - Val F1: 0.1000 - LR: 7.00e-05\n",
      "\tEpoch 40/100 - Train loss: 0.1606 - Val accuracy: 0.2500 - Val loss: 1.5079 - Val F1: 0.1111 - LR: 6.00e-05\n",
      "\tEpoch 50/100 - Train loss: 0.1209 - Val accuracy: 0.5000 - Val loss: 1.1644 - Val F1: 0.4554 - LR: 5.00e-05\n",
      "\tEpoch 60/100 - Train loss: 0.0841 - Val accuracy: 0.8750 - Val loss: 0.8978 - Val F1: 0.8182 - LR: 4.00e-05\n",
      "\tEpoch 70/100 - Train loss: 0.0856 - Val accuracy: 0.8750 - Val loss: 0.9335 - Val F1: 0.8182 - LR: 3.00e-05\n",
      "\tEpoch 80/100 - Train loss: 0.0711 - Val accuracy: 0.8750 - Val loss: 0.9807 - Val F1: 0.8182 - LR: 2.00e-05\n",
      "\tEpoch 90/100 - Train loss: 0.0617 - Val accuracy: 0.8750 - Val loss: 1.0033 - Val F1: 0.8182 - LR: 1.00e-05\n",
      "\tEpoch 100/100 - Train loss: 0.0574 - Val accuracy: 0.8750 - Val loss: 1.0125 - Val F1: 0.8182 - LR: 0.00e+00\n",
      "\tBest epoch: 61 - Best val accuracy: 0.8750 - Best val loss: 0.8957 - Best val F1: 0.8182\n",
      "\n",
      "\tEpoch 10/100 - Train loss: 0.6812 - Val accuracy: 0.5000 - Val loss: 1.0693 - Val F1: 0.4821 - LR: 9.00e-05\n",
      "\tEpoch 20/100 - Train loss: 0.4434 - Val accuracy: 0.2500 - Val loss: 1.1576 - Val F1: 0.1000 - LR: 8.00e-05\n",
      "\tEpoch 30/100 - Train loss: 0.2633 - Val accuracy: 0.2500 - Val loss: 1.4431 - Val F1: 0.1000 - LR: 7.00e-05\n",
      "\tEpoch 40/100 - Train loss: 0.1913 - Val accuracy: 0.2500 - Val loss: 1.7084 - Val F1: 0.1000 - LR: 6.00e-05\n",
      "\tEpoch 50/100 - Train loss: 0.1399 - Val accuracy: 0.2500 - Val loss: 1.4772 - Val F1: 0.1000 - LR: 5.00e-05\n",
      "\tEpoch 60/100 - Train loss: 0.1133 - Val accuracy: 0.7500 - Val loss: 0.7647 - Val F1: 0.7000 - LR: 4.00e-05\n",
      "\tEpoch 70/100 - Train loss: 0.0883 - Val accuracy: 0.7500 - Val loss: 0.5651 - Val F1: 0.7000 - LR: 3.00e-05\n",
      "\tEpoch 80/100 - Train loss: 0.0758 - Val accuracy: 0.8750 - Val loss: 0.5353 - Val F1: 0.8182 - LR: 2.00e-05\n",
      "\tEpoch 90/100 - Train loss: 0.0659 - Val accuracy: 0.8750 - Val loss: 0.5285 - Val F1: 0.8182 - LR: 1.00e-05\n",
      "\tEpoch 100/100 - Train loss: 0.0673 - Val accuracy: 0.8750 - Val loss: 0.5274 - Val F1: 0.8182 - LR: 0.00e+00\n",
      "\tBest epoch: 99 - Best val accuracy: 0.8750 - Best val loss: 0.5274 - Best val F1: 0.8182\n",
      "\n",
      "\tEpoch 10/100 - Train loss: 0.6078 - Val accuracy: 0.2500 - Val loss: 1.0928 - Val F1: 0.1000 - LR: 9.00e-05\n",
      "\tEpoch 20/100 - Train loss: 0.3878 - Val accuracy: 0.2500 - Val loss: 1.2258 - Val F1: 0.1000 - LR: 8.00e-05\n",
      "\tEpoch 30/100 - Train loss: 0.2639 - Val accuracy: 0.2500 - Val loss: 1.4805 - Val F1: 0.1111 - LR: 7.00e-05\n",
      "\tEpoch 40/100 - Train loss: 0.1958 - Val accuracy: 0.2500 - Val loss: 1.6697 - Val F1: 0.1111 - LR: 6.00e-05\n",
      "\tEpoch 50/100 - Train loss: 0.1573 - Val accuracy: 0.6250 - Val loss: 1.3863 - Val F1: 0.5833 - LR: 5.00e-05\n",
      "\tEpoch 60/100 - Train loss: 0.1285 - Val accuracy: 0.6250 - Val loss: 1.2289 - Val F1: 0.5833 - LR: 4.00e-05\n",
      "\tEpoch 70/100 - Train loss: 0.1037 - Val accuracy: 0.8750 - Val loss: 1.2105 - Val F1: 0.8182 - LR: 3.00e-05\n",
      "\tEpoch 80/100 - Train loss: 0.1009 - Val accuracy: 0.8750 - Val loss: 1.2218 - Val F1: 0.8182 - LR: 2.00e-05\n",
      "\tEpoch 90/100 - Train loss: 0.0905 - Val accuracy: 0.8750 - Val loss: 1.2322 - Val F1: 0.8182 - LR: 1.00e-05\n",
      "\tEpoch 100/100 - Train loss: 0.0883 - Val accuracy: 0.8750 - Val loss: 1.2383 - Val F1: 0.8182 - LR: 0.00e+00\n",
      "\tBest epoch: 7 - Best val accuracy: 0.6250 - Best val loss: 1.0870 - Best val F1: 0.4808\n",
      "\n",
      "\tEpoch 10/100 - Train loss: 0.7217 - Val accuracy: 0.6250 - Val loss: 1.0468 - Val F1: 0.4808 - LR: 9.00e-05\n",
      "\tEpoch 20/100 - Train loss: 0.4707 - Val accuracy: 0.2500 - Val loss: 1.0712 - Val F1: 0.1000 - LR: 8.00e-05\n",
      "\tEpoch 30/100 - Train loss: 0.3199 - Val accuracy: 0.2500 - Val loss: 1.2475 - Val F1: 0.1000 - LR: 7.00e-05\n",
      "\tEpoch 40/100 - Train loss: 0.2245 - Val accuracy: 0.2500 - Val loss: 1.2570 - Val F1: 0.1000 - LR: 6.00e-05\n",
      "\tEpoch 50/100 - Train loss: 0.1566 - Val accuracy: 0.7500 - Val loss: 0.7191 - Val F1: 0.7222 - LR: 5.00e-05\n",
      "\tEpoch 60/100 - Train loss: 0.1233 - Val accuracy: 0.8750 - Val loss: 0.3581 - Val F1: 0.8250 - LR: 4.00e-05\n",
      "\tEpoch 70/100 - Train loss: 0.0949 - Val accuracy: 0.8750 - Val loss: 0.2360 - Val F1: 0.8250 - LR: 3.00e-05\n",
      "\tEpoch 80/100 - Train loss: 0.0947 - Val accuracy: 1.0000 - Val loss: 0.1954 - Val F1: 1.0000 - LR: 2.00e-05\n",
      "\tEpoch 90/100 - Train loss: 0.0921 - Val accuracy: 1.0000 - Val loss: 0.1801 - Val F1: 1.0000 - LR: 1.00e-05\n",
      "\tEpoch 100/100 - Train loss: 0.0828 - Val accuracy: 1.0000 - Val loss: 0.1748 - Val F1: 1.0000 - LR: 0.00e+00\n",
      "\tBest epoch: 100 - Best val accuracy: 1.0000 - Best val loss: 0.1748 - Best val F1: 1.0000\n",
      "\n",
      "\tEpoch 10/100 - Train loss: 0.6081 - Val accuracy: 0.2500 - Val loss: 1.1010 - Val F1: 0.1000 - LR: 9.00e-05\n",
      "\tEpoch 20/100 - Train loss: 0.4156 - Val accuracy: 0.2500 - Val loss: 1.2112 - Val F1: 0.1000 - LR: 8.00e-05\n",
      "\tEpoch 30/100 - Train loss: 0.2371 - Val accuracy: 0.2500 - Val loss: 1.4790 - Val F1: 0.1000 - LR: 7.00e-05\n",
      "\tEpoch 40/100 - Train loss: 0.1550 - Val accuracy: 0.2500 - Val loss: 1.6076 - Val F1: 0.1000 - LR: 6.00e-05\n",
      "\tEpoch 50/100 - Train loss: 0.1184 - Val accuracy: 0.3750 - Val loss: 1.1035 - Val F1: 0.3194 - LR: 5.00e-05\n",
      "\tEpoch 60/100 - Train loss: 0.0825 - Val accuracy: 0.8750 - Val loss: 0.5502 - Val F1: 0.8250 - LR: 4.00e-05\n",
      "\tEpoch 70/100 - Train loss: 0.0693 - Val accuracy: 0.8750 - Val loss: 0.4015 - Val F1: 0.8250 - LR: 3.00e-05\n",
      "\tEpoch 80/100 - Train loss: 0.0568 - Val accuracy: 0.8750 - Val loss: 0.3720 - Val F1: 0.8250 - LR: 2.00e-05\n",
      "\tEpoch 90/100 - Train loss: 0.0620 - Val accuracy: 0.8750 - Val loss: 0.3646 - Val F1: 0.8250 - LR: 1.00e-05\n",
      "\tEpoch 100/100 - Train loss: 0.0582 - Val accuracy: 0.8750 - Val loss: 0.3622 - Val F1: 0.8250 - LR: 0.00e+00\n",
      "\tBest epoch: 100 - Best val accuracy: 0.8750 - Best val loss: 0.3622 - Best val F1: 0.8250\n",
      "\n",
      "Source class: WAL | Domain: 61 | Accuracy: 0.8911 | Loss: 0.4979 | F1: 0.8455\n",
      "\n",
      "Domain: 62\n",
      "x_dp_dom.shape: (47, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Training and evaluating on Dp data via cross-validation...\n",
      "\tEpoch 10/100 - Train loss: 0.5075 - Val accuracy: 0.6250 - Val loss: 1.0848 - Val F1: 0.4808 - LR: 9.00e-05\n",
      "\tEpoch 20/100 - Train loss: 0.3379 - Val accuracy: 0.2500 - Val loss: 1.1961 - Val F1: 0.1000 - LR: 8.00e-05\n",
      "\tEpoch 30/100 - Train loss: 0.2433 - Val accuracy: 0.2500 - Val loss: 1.4075 - Val F1: 0.1000 - LR: 7.00e-05\n",
      "\tEpoch 40/100 - Train loss: 0.1661 - Val accuracy: 0.2500 - Val loss: 1.5184 - Val F1: 0.1000 - LR: 6.00e-05\n",
      "\tEpoch 50/100 - Train loss: 0.1262 - Val accuracy: 0.3750 - Val loss: 1.1127 - Val F1: 0.3750 - LR: 5.00e-05\n",
      "\tEpoch 60/100 - Train loss: 0.0905 - Val accuracy: 0.8750 - Val loss: 0.4223 - Val F1: 0.8250 - LR: 4.00e-05\n",
      "\tEpoch 70/100 - Train loss: 0.0771 - Val accuracy: 0.8750 - Val loss: 0.2292 - Val F1: 0.8250 - LR: 3.00e-05\n",
      "\tEpoch 80/100 - Train loss: 0.0686 - Val accuracy: 0.8750 - Val loss: 0.1889 - Val F1: 0.8250 - LR: 2.00e-05\n",
      "\tEpoch 90/100 - Train loss: 0.0636 - Val accuracy: 0.8750 - Val loss: 0.1769 - Val F1: 0.8250 - LR: 1.00e-05\n",
      "\tEpoch 100/100 - Train loss: 0.0644 - Val accuracy: 0.8750 - Val loss: 0.1730 - Val F1: 0.8250 - LR: 0.00e+00\n",
      "\tBest epoch: 100 - Best val accuracy: 0.8750 - Best val loss: 0.1730 - Best val F1: 0.8250\n",
      "\n",
      "\tEpoch 10/100 - Train loss: 0.5595 - Val accuracy: 0.7500 - Val loss: 1.0959 - Val F1: 0.6932 - LR: 9.00e-05\n",
      "\tEpoch 20/100 - Train loss: 0.3183 - Val accuracy: 0.2500 - Val loss: 1.2993 - Val F1: 0.1000 - LR: 8.00e-05\n",
      "\tEpoch 30/100 - Train loss: 0.1898 - Val accuracy: 0.2500 - Val loss: 1.6597 - Val F1: 0.1000 - LR: 7.00e-05\n",
      "\tEpoch 40/100 - Train loss: 0.1351 - Val accuracy: 0.2500 - Val loss: 1.8137 - Val F1: 0.1250 - LR: 6.00e-05\n",
      "\tEpoch 50/100 - Train loss: 0.0918 - Val accuracy: 0.3750 - Val loss: 1.2740 - Val F1: 0.2417 - LR: 5.00e-05\n",
      "\tEpoch 60/100 - Train loss: 0.0737 - Val accuracy: 1.0000 - Val loss: 0.4233 - Val F1: 1.0000 - LR: 4.00e-05\n",
      "\tEpoch 70/100 - Train loss: 0.0564 - Val accuracy: 0.8750 - Val loss: 0.2195 - Val F1: 0.8750 - LR: 3.00e-05\n",
      "\tEpoch 80/100 - Train loss: 0.0508 - Val accuracy: 0.8750 - Val loss: 0.1867 - Val F1: 0.8750 - LR: 2.00e-05\n",
      "\tEpoch 90/100 - Train loss: 0.0441 - Val accuracy: 0.8750 - Val loss: 0.1771 - Val F1: 0.8750 - LR: 1.00e-05\n",
      "\tEpoch 100/100 - Train loss: 0.0427 - Val accuracy: 0.8750 - Val loss: 0.1746 - Val F1: 0.8750 - LR: 0.00e+00\n",
      "\tBest epoch: 100 - Best val accuracy: 0.8750 - Best val loss: 0.1746 - Best val F1: 0.8750\n",
      "\n",
      "\tEpoch 10/100 - Train loss: 0.5471 - Val accuracy: 0.1250 - Val loss: 1.1160 - Val F1: 0.0278 - LR: 9.00e-05\n",
      "\tEpoch 20/100 - Train loss: 0.3044 - Val accuracy: 0.1250 - Val loss: 1.2864 - Val F1: 0.0278 - LR: 8.00e-05\n",
      "\tEpoch 30/100 - Train loss: 0.1739 - Val accuracy: 0.1250 - Val loss: 1.5788 - Val F1: 0.0278 - LR: 7.00e-05\n",
      "\tEpoch 40/100 - Train loss: 0.1160 - Val accuracy: 0.1250 - Val loss: 1.6791 - Val F1: 0.0278 - LR: 6.00e-05\n",
      "\tEpoch 50/100 - Train loss: 0.0775 - Val accuracy: 0.3750 - Val loss: 1.0960 - Val F1: 0.2417 - LR: 5.00e-05\n",
      "\tEpoch 60/100 - Train loss: 0.0621 - Val accuracy: 1.0000 - Val loss: 0.3916 - Val F1: 1.0000 - LR: 4.00e-05\n",
      "\tEpoch 70/100 - Train loss: 0.0532 - Val accuracy: 1.0000 - Val loss: 0.1878 - Val F1: 1.0000 - LR: 3.00e-05\n",
      "\tEpoch 80/100 - Train loss: 0.0398 - Val accuracy: 1.0000 - Val loss: 0.1450 - Val F1: 1.0000 - LR: 2.00e-05\n",
      "\tEpoch 90/100 - Train loss: 0.0415 - Val accuracy: 1.0000 - Val loss: 0.1334 - Val F1: 1.0000 - LR: 1.00e-05\n",
      "\tEpoch 100/100 - Train loss: 0.0422 - Val accuracy: 1.0000 - Val loss: 0.1299 - Val F1: 1.0000 - LR: 0.00e+00\n",
      "\tBest epoch: 100 - Best val accuracy: 1.0000 - Best val loss: 0.1299 - Best val F1: 1.0000\n",
      "\n",
      "\tEpoch 10/100 - Train loss: 0.5387 - Val accuracy: 0.2500 - Val loss: 1.1041 - Val F1: 0.1000 - LR: 9.00e-05\n",
      "\tEpoch 20/100 - Train loss: 0.3294 - Val accuracy: 0.2500 - Val loss: 1.2094 - Val F1: 0.1000 - LR: 8.00e-05\n",
      "\tEpoch 30/100 - Train loss: 0.2600 - Val accuracy: 0.2500 - Val loss: 1.3955 - Val F1: 0.1000 - LR: 7.00e-05\n",
      "\tEpoch 40/100 - Train loss: 0.1921 - Val accuracy: 0.2500 - Val loss: 1.4837 - Val F1: 0.1000 - LR: 6.00e-05\n",
      "\tEpoch 50/100 - Train loss: 0.1453 - Val accuracy: 0.3750 - Val loss: 1.0346 - Val F1: 0.3194 - LR: 5.00e-05\n",
      "\tEpoch 60/100 - Train loss: 0.1136 - Val accuracy: 1.0000 - Val loss: 0.4028 - Val F1: 1.0000 - LR: 4.00e-05\n",
      "\tEpoch 70/100 - Train loss: 0.1018 - Val accuracy: 1.0000 - Val loss: 0.2341 - Val F1: 1.0000 - LR: 3.00e-05\n",
      "\tEpoch 80/100 - Train loss: 0.0868 - Val accuracy: 1.0000 - Val loss: 0.2017 - Val F1: 1.0000 - LR: 2.00e-05\n",
      "\tEpoch 90/100 - Train loss: 0.0787 - Val accuracy: 1.0000 - Val loss: 0.1921 - Val F1: 1.0000 - LR: 1.00e-05\n",
      "\tEpoch 100/100 - Train loss: 0.0876 - Val accuracy: 1.0000 - Val loss: 0.1888 - Val F1: 1.0000 - LR: 0.00e+00\n",
      "\tBest epoch: 100 - Best val accuracy: 1.0000 - Best val loss: 0.1888 - Best val F1: 1.0000\n",
      "\n",
      "\tEpoch 10/100 - Train loss: 0.6187 - Val accuracy: 0.6250 - Val loss: 1.0662 - Val F1: 0.4808 - LR: 9.00e-05\n",
      "\tEpoch 20/100 - Train loss: 0.3785 - Val accuracy: 0.2500 - Val loss: 1.1315 - Val F1: 0.1000 - LR: 8.00e-05\n",
      "\tEpoch 30/100 - Train loss: 0.2390 - Val accuracy: 0.2500 - Val loss: 1.3616 - Val F1: 0.1000 - LR: 7.00e-05\n",
      "\tEpoch 40/100 - Train loss: 0.1569 - Val accuracy: 0.2500 - Val loss: 1.4286 - Val F1: 0.1000 - LR: 6.00e-05\n",
      "\tEpoch 50/100 - Train loss: 0.1276 - Val accuracy: 0.5000 - Val loss: 0.9221 - Val F1: 0.4821 - LR: 5.00e-05\n",
      "\tEpoch 60/100 - Train loss: 0.1050 - Val accuracy: 0.8750 - Val loss: 0.3808 - Val F1: 0.8250 - LR: 4.00e-05\n",
      "\tEpoch 70/100 - Train loss: 0.0782 - Val accuracy: 0.8750 - Val loss: 0.2519 - Val F1: 0.8250 - LR: 3.00e-05\n",
      "\tEpoch 80/100 - Train loss: 0.0690 - Val accuracy: 0.8750 - Val loss: 0.2191 - Val F1: 0.8250 - LR: 2.00e-05\n",
      "\tEpoch 90/100 - Train loss: 0.0669 - Val accuracy: 0.8750 - Val loss: 0.2070 - Val F1: 0.8250 - LR: 1.00e-05\n",
      "\tEpoch 100/100 - Train loss: 0.0576 - Val accuracy: 0.8750 - Val loss: 0.2032 - Val F1: 0.8250 - LR: 0.00e+00\n",
      "\tBest epoch: 100 - Best val accuracy: 0.8750 - Best val loss: 0.2032 - Best val F1: 0.8250\n",
      "\n",
      "Source class: WAL | Domain: 62 | Accuracy: 0.9556 | Loss: 0.1744 | F1: 0.9452\n",
      "\n",
      "Domain: 63\n",
      "x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Training and evaluating on Dp data via cross-validation...\n",
      "\tEpoch 10/100 - Train loss: 0.7117 - Val accuracy: 0.7143 - Val loss: 1.0677 - Val F1: 0.5952 - LR: 9.00e-05\n",
      "\tEpoch 20/100 - Train loss: 0.4366 - Val accuracy: 0.1429 - Val loss: 1.1018 - Val F1: 0.0357 - LR: 8.00e-05\n",
      "\tEpoch 30/100 - Train loss: 0.3026 - Val accuracy: 0.1429 - Val loss: 1.2679 - Val F1: 0.0952 - LR: 7.00e-05\n",
      "\tEpoch 40/100 - Train loss: 0.1999 - Val accuracy: 0.1429 - Val loss: 1.3477 - Val F1: 0.0571 - LR: 6.00e-05\n",
      "\tEpoch 50/100 - Train loss: 0.1426 - Val accuracy: 0.5714 - Val loss: 1.0214 - Val F1: 0.5929 - LR: 5.00e-05\n",
      "\tEpoch 60/100 - Train loss: 0.1062 - Val accuracy: 0.7143 - Val loss: 0.6701 - Val F1: 0.7063 - LR: 4.00e-05\n",
      "\tEpoch 70/100 - Train loss: 0.0854 - Val accuracy: 0.7143 - Val loss: 0.5516 - Val F1: 0.7063 - LR: 3.00e-05\n",
      "\tEpoch 80/100 - Train loss: 0.0793 - Val accuracy: 0.7143 - Val loss: 0.5165 - Val F1: 0.7063 - LR: 2.00e-05\n",
      "\tEpoch 90/100 - Train loss: 0.0723 - Val accuracy: 0.7143 - Val loss: 0.5057 - Val F1: 0.7063 - LR: 1.00e-05\n",
      "\tEpoch 100/100 - Train loss: 0.0734 - Val accuracy: 0.7143 - Val loss: 0.5024 - Val F1: 0.7063 - LR: 0.00e+00\n",
      "\tBest epoch: 100 - Best val accuracy: 0.7143 - Best val loss: 0.5024 - Best val F1: 0.7063\n",
      "\n",
      "\tEpoch 10/100 - Train loss: 0.6518 - Val accuracy: 0.7143 - Val loss: 1.0311 - Val F1: 0.5952 - LR: 9.00e-05\n",
      "\tEpoch 20/100 - Train loss: 0.4501 - Val accuracy: 0.7143 - Val loss: 1.0158 - Val F1: 0.5952 - LR: 8.00e-05\n",
      "\tEpoch 30/100 - Train loss: 0.2838 - Val accuracy: 0.5714 - Val loss: 1.0560 - Val F1: 0.5929 - LR: 7.00e-05\n",
      "\tEpoch 40/100 - Train loss: 0.2138 - Val accuracy: 1.0000 - Val loss: 0.9325 - Val F1: 1.0000 - LR: 6.00e-05\n",
      "\tEpoch 50/100 - Train loss: 0.1360 - Val accuracy: 0.8571 - Val loss: 0.5617 - Val F1: 0.7922 - LR: 5.00e-05\n",
      "\tEpoch 60/100 - Train loss: 0.1181 - Val accuracy: 0.7143 - Val loss: 0.3957 - Val F1: 0.5952 - LR: 4.00e-05\n",
      "\tEpoch 70/100 - Train loss: 0.0946 - Val accuracy: 0.7143 - Val loss: 0.3823 - Val F1: 0.5952 - LR: 3.00e-05\n",
      "\tEpoch 80/100 - Train loss: 0.0883 - Val accuracy: 0.7143 - Val loss: 0.3853 - Val F1: 0.5952 - LR: 2.00e-05\n",
      "\tEpoch 90/100 - Train loss: 0.0693 - Val accuracy: 0.7143 - Val loss: 0.3877 - Val F1: 0.5952 - LR: 1.00e-05\n",
      "\tEpoch 100/100 - Train loss: 0.0690 - Val accuracy: 0.7143 - Val loss: 0.3898 - Val F1: 0.5952 - LR: 0.00e+00\n",
      "\tBest epoch: 68 - Best val accuracy: 0.7143 - Best val loss: 0.3817 - Best val F1: 0.5952\n",
      "\n",
      "\tEpoch 10/100 - Train loss: 0.6041 - Val accuracy: 0.1429 - Val loss: 1.0874 - Val F1: 0.0357 - LR: 9.00e-05\n",
      "\tEpoch 20/100 - Train loss: 0.4088 - Val accuracy: 0.1429 - Val loss: 1.1463 - Val F1: 0.0357 - LR: 8.00e-05\n",
      "\tEpoch 30/100 - Train loss: 0.2780 - Val accuracy: 0.2857 - Val loss: 1.2898 - Val F1: 0.1429 - LR: 7.00e-05\n",
      "\tEpoch 40/100 - Train loss: 0.2284 - Val accuracy: 0.2857 - Val loss: 1.2644 - Val F1: 0.1286 - LR: 6.00e-05\n",
      "\tEpoch 50/100 - Train loss: 0.1713 - Val accuracy: 0.8571 - Val loss: 0.7905 - Val F1: 0.8730 - LR: 5.00e-05\n",
      "\tEpoch 60/100 - Train loss: 0.1295 - Val accuracy: 1.0000 - Val loss: 0.4193 - Val F1: 1.0000 - LR: 4.00e-05\n",
      "\tEpoch 70/100 - Train loss: 0.0971 - Val accuracy: 1.0000 - Val loss: 0.3098 - Val F1: 1.0000 - LR: 3.00e-05\n",
      "\tEpoch 80/100 - Train loss: 0.0925 - Val accuracy: 0.8571 - Val loss: 0.2783 - Val F1: 0.7922 - LR: 2.00e-05\n",
      "\tEpoch 90/100 - Train loss: 0.0798 - Val accuracy: 0.8571 - Val loss: 0.2672 - Val F1: 0.7922 - LR: 1.00e-05\n",
      "\tEpoch 100/100 - Train loss: 0.0841 - Val accuracy: 0.8571 - Val loss: 0.2637 - Val F1: 0.7922 - LR: 0.00e+00\n",
      "\tBest epoch: 100 - Best val accuracy: 0.8571 - Best val loss: 0.2637 - Best val F1: 0.7922\n",
      "\n",
      "\tEpoch 10/100 - Train loss: 0.5629 - Val accuracy: 0.7143 - Val loss: 1.0671 - Val F1: 0.5952 - LR: 9.00e-05\n",
      "\tEpoch 20/100 - Train loss: 0.3447 - Val accuracy: 0.1429 - Val loss: 1.1724 - Val F1: 0.0357 - LR: 8.00e-05\n",
      "\tEpoch 30/100 - Train loss: 0.2397 - Val accuracy: 0.1429 - Val loss: 1.3875 - Val F1: 0.0357 - LR: 7.00e-05\n",
      "\tEpoch 40/100 - Train loss: 0.1720 - Val accuracy: 0.1429 - Val loss: 1.4258 - Val F1: 0.0357 - LR: 6.00e-05\n",
      "\tEpoch 50/100 - Train loss: 0.1463 - Val accuracy: 0.7143 - Val loss: 0.8110 - Val F1: 0.7500 - LR: 5.00e-05\n",
      "\tEpoch 60/100 - Train loss: 0.1211 - Val accuracy: 1.0000 - Val loss: 0.3066 - Val F1: 1.0000 - LR: 4.00e-05\n",
      "\tEpoch 70/100 - Train loss: 0.1014 - Val accuracy: 1.0000 - Val loss: 0.1883 - Val F1: 1.0000 - LR: 3.00e-05\n",
      "\tEpoch 80/100 - Train loss: 0.0902 - Val accuracy: 1.0000 - Val loss: 0.1595 - Val F1: 1.0000 - LR: 2.00e-05\n",
      "\tEpoch 90/100 - Train loss: 0.0933 - Val accuracy: 1.0000 - Val loss: 0.1486 - Val F1: 1.0000 - LR: 1.00e-05\n",
      "\tEpoch 100/100 - Train loss: 0.0814 - Val accuracy: 1.0000 - Val loss: 0.1445 - Val F1: 1.0000 - LR: 0.00e+00\n",
      "\tBest epoch: 100 - Best val accuracy: 1.0000 - Best val loss: 0.1445 - Best val F1: 1.0000\n",
      "\n",
      "\tEpoch 10/100 - Train loss: 0.5768 - Val accuracy: 0.1429 - Val loss: 1.1065 - Val F1: 0.0357 - LR: 9.00e-05\n",
      "\tEpoch 20/100 - Train loss: 0.3992 - Val accuracy: 0.1429 - Val loss: 1.1367 - Val F1: 0.0357 - LR: 8.00e-05\n",
      "\tEpoch 30/100 - Train loss: 0.2303 - Val accuracy: 0.1429 - Val loss: 1.2901 - Val F1: 0.0357 - LR: 7.00e-05\n",
      "\tEpoch 40/100 - Train loss: 0.1803 - Val accuracy: 0.1429 - Val loss: 1.2473 - Val F1: 0.0357 - LR: 6.00e-05\n",
      "\tEpoch 50/100 - Train loss: 0.1309 - Val accuracy: 0.7143 - Val loss: 0.8243 - Val F1: 0.7063 - LR: 5.00e-05\n",
      "\tEpoch 60/100 - Train loss: 0.1036 - Val accuracy: 0.7143 - Val loss: 0.5624 - Val F1: 0.7063 - LR: 4.00e-05\n",
      "\tEpoch 70/100 - Train loss: 0.0821 - Val accuracy: 0.7143 - Val loss: 0.4969 - Val F1: 0.7063 - LR: 3.00e-05\n",
      "\tEpoch 80/100 - Train loss: 0.0737 - Val accuracy: 0.7143 - Val loss: 0.4811 - Val F1: 0.7063 - LR: 2.00e-05\n",
      "\tEpoch 90/100 - Train loss: 0.0673 - Val accuracy: 0.7143 - Val loss: 0.4778 - Val F1: 0.7063 - LR: 1.00e-05\n",
      "\tEpoch 100/100 - Train loss: 0.0639 - Val accuracy: 0.7143 - Val loss: 0.4769 - Val F1: 0.7063 - LR: 0.00e+00\n",
      "\tBest epoch: 100 - Best val accuracy: 0.7143 - Best val loss: 0.4769 - Best val F1: 0.7063\n",
      "\n",
      "Source class: WAL | Domain: 63 | Accuracy: 0.8556 | Loss: 0.3175 | F1: 0.8428\n",
      "\n",
      "Domain: 64\n",
      "x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Training and evaluating on Dp data via cross-validation...\n",
      "\tEpoch 10/100 - Train loss: 0.6736 - Val accuracy: 0.7143 - Val loss: 1.0432 - Val F1: 0.5952 - LR: 9.00e-05\n",
      "\tEpoch 20/100 - Train loss: 0.4180 - Val accuracy: 0.2857 - Val loss: 1.0859 - Val F1: 0.2789 - LR: 8.00e-05\n",
      "\tEpoch 30/100 - Train loss: 0.2431 - Val accuracy: 0.1429 - Val loss: 1.2581 - Val F1: 0.0357 - LR: 7.00e-05\n",
      "\tEpoch 40/100 - Train loss: 0.1672 - Val accuracy: 0.2857 - Val loss: 1.2311 - Val F1: 0.1837 - LR: 6.00e-05\n",
      "\tEpoch 50/100 - Train loss: 0.1287 - Val accuracy: 1.0000 - Val loss: 0.6644 - Val F1: 1.0000 - LR: 5.00e-05\n",
      "\tEpoch 60/100 - Train loss: 0.0992 - Val accuracy: 1.0000 - Val loss: 0.2229 - Val F1: 1.0000 - LR: 4.00e-05\n",
      "\tEpoch 70/100 - Train loss: 0.0758 - Val accuracy: 1.0000 - Val loss: 0.1160 - Val F1: 1.0000 - LR: 3.00e-05\n",
      "\tEpoch 80/100 - Train loss: 0.0671 - Val accuracy: 1.0000 - Val loss: 0.0868 - Val F1: 1.0000 - LR: 2.00e-05\n",
      "\tEpoch 90/100 - Train loss: 0.0639 - Val accuracy: 1.0000 - Val loss: 0.0763 - Val F1: 1.0000 - LR: 1.00e-05\n",
      "\tEpoch 100/100 - Train loss: 0.0578 - Val accuracy: 1.0000 - Val loss: 0.0728 - Val F1: 1.0000 - LR: 0.00e+00\n",
      "\tBest epoch: 100 - Best val accuracy: 1.0000 - Best val loss: 0.0728 - Best val F1: 1.0000\n",
      "\n",
      "\tEpoch 10/100 - Train loss: 0.4838 - Val accuracy: 0.1429 - Val loss: 1.1195 - Val F1: 0.0357 - LR: 9.00e-05\n",
      "\tEpoch 20/100 - Train loss: 0.2755 - Val accuracy: 0.1429 - Val loss: 1.2675 - Val F1: 0.0357 - LR: 8.00e-05\n",
      "\tEpoch 30/100 - Train loss: 0.1968 - Val accuracy: 0.1429 - Val loss: 1.5080 - Val F1: 0.0357 - LR: 7.00e-05\n",
      "\tEpoch 40/100 - Train loss: 0.1331 - Val accuracy: 0.1429 - Val loss: 1.4938 - Val F1: 0.0357 - LR: 6.00e-05\n",
      "\tEpoch 50/100 - Train loss: 0.0947 - Val accuracy: 1.0000 - Val loss: 0.6421 - Val F1: 1.0000 - LR: 5.00e-05\n",
      "\tEpoch 60/100 - Train loss: 0.0806 - Val accuracy: 1.0000 - Val loss: 0.1839 - Val F1: 1.0000 - LR: 4.00e-05\n",
      "\tEpoch 70/100 - Train loss: 0.0615 - Val accuracy: 1.0000 - Val loss: 0.1082 - Val F1: 1.0000 - LR: 3.00e-05\n",
      "\tEpoch 80/100 - Train loss: 0.0561 - Val accuracy: 1.0000 - Val loss: 0.0892 - Val F1: 1.0000 - LR: 2.00e-05\n",
      "\tEpoch 90/100 - Train loss: 0.0485 - Val accuracy: 1.0000 - Val loss: 0.0824 - Val F1: 1.0000 - LR: 1.00e-05\n",
      "\tEpoch 100/100 - Train loss: 0.0539 - Val accuracy: 1.0000 - Val loss: 0.0806 - Val F1: 1.0000 - LR: 0.00e+00\n",
      "\tBest epoch: 100 - Best val accuracy: 1.0000 - Best val loss: 0.0806 - Best val F1: 1.0000\n",
      "\n",
      "\tEpoch 10/100 - Train loss: 0.5126 - Val accuracy: 0.1429 - Val loss: 1.1334 - Val F1: 0.0357 - LR: 9.00e-05\n",
      "\tEpoch 20/100 - Train loss: 0.3121 - Val accuracy: 0.1429 - Val loss: 1.2865 - Val F1: 0.0357 - LR: 8.00e-05\n",
      "\tEpoch 30/100 - Train loss: 0.2075 - Val accuracy: 0.1429 - Val loss: 1.5239 - Val F1: 0.0357 - LR: 7.00e-05\n",
      "\tEpoch 40/100 - Train loss: 0.1439 - Val accuracy: 0.1429 - Val loss: 1.3179 - Val F1: 0.0357 - LR: 6.00e-05\n",
      "\tEpoch 50/100 - Train loss: 0.1152 - Val accuracy: 1.0000 - Val loss: 0.4752 - Val F1: 1.0000 - LR: 5.00e-05\n",
      "\tEpoch 60/100 - Train loss: 0.0830 - Val accuracy: 1.0000 - Val loss: 0.1630 - Val F1: 1.0000 - LR: 4.00e-05\n",
      "\tEpoch 70/100 - Train loss: 0.0684 - Val accuracy: 1.0000 - Val loss: 0.0977 - Val F1: 1.0000 - LR: 3.00e-05\n",
      "\tEpoch 80/100 - Train loss: 0.0564 - Val accuracy: 1.0000 - Val loss: 0.0787 - Val F1: 1.0000 - LR: 2.00e-05\n",
      "\tEpoch 90/100 - Train loss: 0.0518 - Val accuracy: 1.0000 - Val loss: 0.0714 - Val F1: 1.0000 - LR: 1.00e-05\n",
      "\tEpoch 100/100 - Train loss: 0.0482 - Val accuracy: 1.0000 - Val loss: 0.0687 - Val F1: 1.0000 - LR: 0.00e+00\n",
      "\tBest epoch: 100 - Best val accuracy: 1.0000 - Best val loss: 0.0687 - Best val F1: 1.0000\n",
      "\n",
      "\tEpoch 10/100 - Train loss: 0.4749 - Val accuracy: 0.7143 - Val loss: 1.0578 - Val F1: 0.5952 - LR: 9.00e-05\n",
      "\tEpoch 20/100 - Train loss: 0.2853 - Val accuracy: 0.1429 - Val loss: 1.1649 - Val F1: 0.0357 - LR: 8.00e-05\n",
      "\tEpoch 30/100 - Train loss: 0.1793 - Val accuracy: 0.1429 - Val loss: 1.3768 - Val F1: 0.0357 - LR: 7.00e-05\n",
      "\tEpoch 40/100 - Train loss: 0.1242 - Val accuracy: 0.1429 - Val loss: 1.3188 - Val F1: 0.0357 - LR: 6.00e-05\n",
      "\tEpoch 50/100 - Train loss: 0.0857 - Val accuracy: 0.8571 - Val loss: 0.6137 - Val F1: 0.8095 - LR: 5.00e-05\n",
      "\tEpoch 60/100 - Train loss: 0.0716 - Val accuracy: 0.8571 - Val loss: 0.2397 - Val F1: 0.8095 - LR: 4.00e-05\n",
      "\tEpoch 70/100 - Train loss: 0.0681 - Val accuracy: 0.8571 - Val loss: 0.1670 - Val F1: 0.8095 - LR: 3.00e-05\n",
      "\tEpoch 80/100 - Train loss: 0.0515 - Val accuracy: 1.0000 - Val loss: 0.1471 - Val F1: 1.0000 - LR: 2.00e-05\n",
      "\tEpoch 90/100 - Train loss: 0.0503 - Val accuracy: 1.0000 - Val loss: 0.1392 - Val F1: 1.0000 - LR: 1.00e-05\n",
      "\tEpoch 100/100 - Train loss: 0.0383 - Val accuracy: 1.0000 - Val loss: 0.1367 - Val F1: 1.0000 - LR: 0.00e+00\n",
      "\tBest epoch: 100 - Best val accuracy: 1.0000 - Best val loss: 0.1367 - Best val F1: 1.0000\n",
      "\n",
      "\tEpoch 10/100 - Train loss: 0.5068 - Val accuracy: 0.1429 - Val loss: 1.1085 - Val F1: 0.0357 - LR: 9.00e-05\n",
      "\tEpoch 20/100 - Train loss: 0.3363 - Val accuracy: 0.1429 - Val loss: 1.1341 - Val F1: 0.0357 - LR: 8.00e-05\n",
      "\tEpoch 30/100 - Train loss: 0.2422 - Val accuracy: 0.1429 - Val loss: 1.2212 - Val F1: 0.0357 - LR: 7.00e-05\n",
      "\tEpoch 40/100 - Train loss: 0.1911 - Val accuracy: 0.7143 - Val loss: 0.9153 - Val F1: 0.7063 - LR: 6.00e-05\n",
      "\tEpoch 50/100 - Train loss: 0.1598 - Val accuracy: 0.8571 - Val loss: 0.3672 - Val F1: 0.8095 - LR: 5.00e-05\n",
      "\tEpoch 60/100 - Train loss: 0.1296 - Val accuracy: 1.0000 - Val loss: 0.2043 - Val F1: 1.0000 - LR: 4.00e-05\n",
      "\tEpoch 70/100 - Train loss: 0.1032 - Val accuracy: 1.0000 - Val loss: 0.1666 - Val F1: 1.0000 - LR: 3.00e-05\n",
      "\tEpoch 80/100 - Train loss: 0.0897 - Val accuracy: 1.0000 - Val loss: 0.1521 - Val F1: 1.0000 - LR: 2.00e-05\n",
      "\tEpoch 90/100 - Train loss: 0.0801 - Val accuracy: 1.0000 - Val loss: 0.1445 - Val F1: 1.0000 - LR: 1.00e-05\n",
      "\tEpoch 100/100 - Train loss: 0.0847 - Val accuracy: 1.0000 - Val loss: 0.1414 - Val F1: 1.0000 - LR: 0.00e+00\n",
      "\tBest epoch: 100 - Best val accuracy: 1.0000 - Best val loss: 0.1414 - Best val F1: 1.0000\n",
      "\n",
      "Source class: WAL | Domain: 64 | Accuracy: 0.9528 | Loss: 0.1756 | F1: 0.9356\n",
      "\n",
      "Domain: 65\n",
      "x_dp_dom.shape: (50, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Training and evaluating on Dp data via cross-validation...\n",
      "\tEpoch 10/100 - Train loss: 0.4969 - Val accuracy: 0.5000 - Val loss: 1.0754 - Val F1: 0.3333 - LR: 9.00e-05\n",
      "\tEpoch 20/100 - Train loss: 0.3030 - Val accuracy: 0.7500 - Val loss: 1.0386 - Val F1: 0.6667 - LR: 8.00e-05\n",
      "\tEpoch 30/100 - Train loss: 0.2212 - Val accuracy: 0.5000 - Val loss: 0.9375 - Val F1: 0.5000 - LR: 7.00e-05\n",
      "\tEpoch 40/100 - Train loss: 0.1470 - Val accuracy: 1.0000 - Val loss: 0.6843 - Val F1: 1.0000 - LR: 6.00e-05\n",
      "\tEpoch 50/100 - Train loss: 0.1010 - Val accuracy: 1.0000 - Val loss: 0.3324 - Val F1: 1.0000 - LR: 5.00e-05\n",
      "\tEpoch 60/100 - Train loss: 0.0753 - Val accuracy: 1.0000 - Val loss: 0.1447 - Val F1: 1.0000 - LR: 4.00e-05\n",
      "\tEpoch 70/100 - Train loss: 0.0621 - Val accuracy: 1.0000 - Val loss: 0.0902 - Val F1: 1.0000 - LR: 3.00e-05\n",
      "\tEpoch 80/100 - Train loss: 0.0512 - Val accuracy: 1.0000 - Val loss: 0.0722 - Val F1: 1.0000 - LR: 2.00e-05\n",
      "\tEpoch 90/100 - Train loss: 0.0515 - Val accuracy: 1.0000 - Val loss: 0.0643 - Val F1: 1.0000 - LR: 1.00e-05\n",
      "\tEpoch 100/100 - Train loss: 0.0437 - Val accuracy: 1.0000 - Val loss: 0.0612 - Val F1: 1.0000 - LR: 0.00e+00\n",
      "\tBest epoch: 100 - Best val accuracy: 1.0000 - Best val loss: 0.0612 - Best val F1: 1.0000\n",
      "\n",
      "\tEpoch 10/100 - Train loss: 0.5418 - Val accuracy: 0.5000 - Val loss: 1.0714 - Val F1: 0.3333 - LR: 9.00e-05\n",
      "\tEpoch 20/100 - Train loss: 0.3586 - Val accuracy: 0.6250 - Val loss: 1.0427 - Val F1: 0.5250 - LR: 8.00e-05\n",
      "\tEpoch 30/100 - Train loss: 0.2380 - Val accuracy: 0.7500 - Val loss: 0.9023 - Val F1: 0.6667 - LR: 7.00e-05\n",
      "\tEpoch 40/100 - Train loss: 0.1768 - Val accuracy: 0.7500 - Val loss: 0.6440 - Val F1: 0.6667 - LR: 6.00e-05\n",
      "\tEpoch 50/100 - Train loss: 0.1291 - Val accuracy: 1.0000 - Val loss: 0.4077 - Val F1: 1.0000 - LR: 5.00e-05\n",
      "\tEpoch 60/100 - Train loss: 0.0973 - Val accuracy: 1.0000 - Val loss: 0.2725 - Val F1: 1.0000 - LR: 4.00e-05\n",
      "\tEpoch 70/100 - Train loss: 0.0809 - Val accuracy: 1.0000 - Val loss: 0.2118 - Val F1: 1.0000 - LR: 3.00e-05\n",
      "\tEpoch 80/100 - Train loss: 0.0700 - Val accuracy: 1.0000 - Val loss: 0.1848 - Val F1: 1.0000 - LR: 2.00e-05\n",
      "\tEpoch 90/100 - Train loss: 0.0602 - Val accuracy: 1.0000 - Val loss: 0.1727 - Val F1: 1.0000 - LR: 1.00e-05\n",
      "\tEpoch 100/100 - Train loss: 0.0649 - Val accuracy: 1.0000 - Val loss: 0.1690 - Val F1: 1.0000 - LR: 0.00e+00\n",
      "\tBest epoch: 100 - Best val accuracy: 1.0000 - Best val loss: 0.1690 - Best val F1: 1.0000\n",
      "\n",
      "\tEpoch 10/100 - Train loss: 0.6923 - Val accuracy: 0.2500 - Val loss: 1.1244 - Val F1: 0.1000 - LR: 9.00e-05\n",
      "\tEpoch 20/100 - Train loss: 0.4234 - Val accuracy: 0.2500 - Val loss: 1.1484 - Val F1: 0.1000 - LR: 8.00e-05\n",
      "\tEpoch 30/100 - Train loss: 0.2807 - Val accuracy: 0.2500 - Val loss: 1.1529 - Val F1: 0.1000 - LR: 7.00e-05\n",
      "\tEpoch 40/100 - Train loss: 0.2062 - Val accuracy: 0.2500 - Val loss: 0.9461 - Val F1: 0.1000 - LR: 6.00e-05\n",
      "\tEpoch 50/100 - Train loss: 0.1423 - Val accuracy: 1.0000 - Val loss: 0.5139 - Val F1: 1.0000 - LR: 5.00e-05\n",
      "\tEpoch 60/100 - Train loss: 0.1146 - Val accuracy: 1.0000 - Val loss: 0.2908 - Val F1: 1.0000 - LR: 4.00e-05\n",
      "\tEpoch 70/100 - Train loss: 0.0863 - Val accuracy: 1.0000 - Val loss: 0.2170 - Val F1: 1.0000 - LR: 3.00e-05\n",
      "\tEpoch 80/100 - Train loss: 0.0698 - Val accuracy: 1.0000 - Val loss: 0.1862 - Val F1: 1.0000 - LR: 2.00e-05\n",
      "\tEpoch 90/100 - Train loss: 0.0714 - Val accuracy: 1.0000 - Val loss: 0.1722 - Val F1: 1.0000 - LR: 1.00e-05\n",
      "\tEpoch 100/100 - Train loss: 0.0594 - Val accuracy: 1.0000 - Val loss: 0.1670 - Val F1: 1.0000 - LR: 0.00e+00\n",
      "\tBest epoch: 100 - Best val accuracy: 1.0000 - Best val loss: 0.1670 - Best val F1: 1.0000\n",
      "\n",
      "\tEpoch 10/100 - Train loss: 0.5072 - Val accuracy: 0.2500 - Val loss: 1.0866 - Val F1: 0.1000 - LR: 9.00e-05\n",
      "\tEpoch 20/100 - Train loss: 0.3397 - Val accuracy: 0.2500 - Val loss: 1.0756 - Val F1: 0.1000 - LR: 8.00e-05\n",
      "\tEpoch 30/100 - Train loss: 0.2519 - Val accuracy: 0.2500 - Val loss: 1.0425 - Val F1: 0.1000 - LR: 7.00e-05\n",
      "\tEpoch 40/100 - Train loss: 0.1778 - Val accuracy: 0.8750 - Val loss: 0.7661 - Val F1: 0.8250 - LR: 6.00e-05\n",
      "\tEpoch 50/100 - Train loss: 0.1254 - Val accuracy: 1.0000 - Val loss: 0.3224 - Val F1: 1.0000 - LR: 5.00e-05\n",
      "\tEpoch 60/100 - Train loss: 0.0957 - Val accuracy: 1.0000 - Val loss: 0.1315 - Val F1: 1.0000 - LR: 4.00e-05\n",
      "\tEpoch 70/100 - Train loss: 0.0766 - Val accuracy: 1.0000 - Val loss: 0.0794 - Val F1: 1.0000 - LR: 3.00e-05\n",
      "\tEpoch 80/100 - Train loss: 0.0671 - Val accuracy: 1.0000 - Val loss: 0.0624 - Val F1: 1.0000 - LR: 2.00e-05\n",
      "\tEpoch 90/100 - Train loss: 0.0576 - Val accuracy: 1.0000 - Val loss: 0.0554 - Val F1: 1.0000 - LR: 1.00e-05\n",
      "\tEpoch 100/100 - Train loss: 0.0547 - Val accuracy: 1.0000 - Val loss: 0.0531 - Val F1: 1.0000 - LR: 0.00e+00\n",
      "\tBest epoch: 100 - Best val accuracy: 1.0000 - Best val loss: 0.0531 - Best val F1: 1.0000\n",
      "\n",
      "\tEpoch 10/100 - Train loss: 0.5947 - Val accuracy: 0.5000 - Val loss: 1.0763 - Val F1: 0.4821 - LR: 9.00e-05\n",
      "\tEpoch 20/100 - Train loss: 0.3605 - Val accuracy: 0.2500 - Val loss: 1.1300 - Val F1: 0.1000 - LR: 8.00e-05\n",
      "\tEpoch 30/100 - Train loss: 0.2430 - Val accuracy: 0.3750 - Val loss: 1.1690 - Val F1: 0.2857 - LR: 7.00e-05\n",
      "\tEpoch 40/100 - Train loss: 0.1676 - Val accuracy: 0.3750 - Val loss: 1.0242 - Val F1: 0.2857 - LR: 6.00e-05\n",
      "\tEpoch 50/100 - Train loss: 0.1114 - Val accuracy: 1.0000 - Val loss: 0.5699 - Val F1: 1.0000 - LR: 5.00e-05\n",
      "\tEpoch 60/100 - Train loss: 0.0888 - Val accuracy: 1.0000 - Val loss: 0.2257 - Val F1: 1.0000 - LR: 4.00e-05\n",
      "\tEpoch 70/100 - Train loss: 0.0724 - Val accuracy: 1.0000 - Val loss: 0.1182 - Val F1: 1.0000 - LR: 3.00e-05\n",
      "\tEpoch 80/100 - Train loss: 0.0620 - Val accuracy: 1.0000 - Val loss: 0.0842 - Val F1: 1.0000 - LR: 2.00e-05\n",
      "\tEpoch 90/100 - Train loss: 0.0526 - Val accuracy: 1.0000 - Val loss: 0.0714 - Val F1: 1.0000 - LR: 1.00e-05\n",
      "\tEpoch 100/100 - Train loss: 0.0540 - Val accuracy: 1.0000 - Val loss: 0.0670 - Val F1: 1.0000 - LR: 0.00e+00\n",
      "\tBest epoch: 100 - Best val accuracy: 1.0000 - Best val loss: 0.0670 - Best val F1: 1.0000\n",
      "\n",
      "Source class: WAL | Domain: 65 | Accuracy: 0.9600 | Loss: 0.1550 | F1: 0.9550\n",
      "\n",
      "Domain: 66\n",
      "x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Training and evaluating on Dp data via cross-validation...\n",
      "\tEpoch 10/100 - Train loss: 0.5102 - Val accuracy: 0.7143 - Val loss: 1.0374 - Val F1: 0.5952 - LR: 9.00e-05\n",
      "\tEpoch 20/100 - Train loss: 0.2664 - Val accuracy: 0.1429 - Val loss: 1.2054 - Val F1: 0.0357 - LR: 8.00e-05\n",
      "\tEpoch 30/100 - Train loss: 0.1776 - Val accuracy: 0.1429 - Val loss: 1.5416 - Val F1: 0.0357 - LR: 7.00e-05\n",
      "\tEpoch 40/100 - Train loss: 0.1277 - Val accuracy: 0.1429 - Val loss: 1.6488 - Val F1: 0.0357 - LR: 6.00e-05\n",
      "\tEpoch 50/100 - Train loss: 0.0887 - Val accuracy: 0.2857 - Val loss: 0.9731 - Val F1: 0.2789 - LR: 5.00e-05\n",
      "\tEpoch 60/100 - Train loss: 0.0680 - Val accuracy: 0.8571 - Val loss: 0.4271 - Val F1: 0.8095 - LR: 4.00e-05\n",
      "\tEpoch 70/100 - Train loss: 0.0650 - Val accuracy: 0.8571 - Val loss: 0.2978 - Val F1: 0.8095 - LR: 3.00e-05\n",
      "\tEpoch 80/100 - Train loss: 0.0481 - Val accuracy: 0.8571 - Val loss: 0.2641 - Val F1: 0.8095 - LR: 2.00e-05\n",
      "\tEpoch 90/100 - Train loss: 0.0501 - Val accuracy: 0.8571 - Val loss: 0.2521 - Val F1: 0.8095 - LR: 1.00e-05\n",
      "\tEpoch 100/100 - Train loss: 0.0447 - Val accuracy: 0.8571 - Val loss: 0.2479 - Val F1: 0.8095 - LR: 0.00e+00\n",
      "\tBest epoch: 100 - Best val accuracy: 0.8571 - Best val loss: 0.2479 - Best val F1: 0.8095\n",
      "\n",
      "\tEpoch 10/100 - Train loss: 0.5672 - Val accuracy: 0.7143 - Val loss: 1.0339 - Val F1: 0.5952 - LR: 9.00e-05\n",
      "\tEpoch 20/100 - Train loss: 0.3736 - Val accuracy: 0.7143 - Val loss: 1.0032 - Val F1: 0.5952 - LR: 8.00e-05\n",
      "\tEpoch 30/100 - Train loss: 0.2700 - Val accuracy: 0.5714 - Val loss: 1.0320 - Val F1: 0.5929 - LR: 7.00e-05\n",
      "\tEpoch 40/100 - Train loss: 0.2059 - Val accuracy: 0.5714 - Val loss: 0.9435 - Val F1: 0.5929 - LR: 6.00e-05\n",
      "\tEpoch 50/100 - Train loss: 0.1746 - Val accuracy: 0.8571 - Val loss: 0.5639 - Val F1: 0.8095 - LR: 5.00e-05\n",
      "\tEpoch 60/100 - Train loss: 0.1463 - Val accuracy: 0.8571 - Val loss: 0.3175 - Val F1: 0.8095 - LR: 4.00e-05\n",
      "\tEpoch 70/100 - Train loss: 0.1201 - Val accuracy: 1.0000 - Val loss: 0.2297 - Val F1: 1.0000 - LR: 3.00e-05\n",
      "\tEpoch 80/100 - Train loss: 0.1091 - Val accuracy: 1.0000 - Val loss: 0.1974 - Val F1: 1.0000 - LR: 2.00e-05\n",
      "\tEpoch 90/100 - Train loss: 0.0959 - Val accuracy: 1.0000 - Val loss: 0.1835 - Val F1: 1.0000 - LR: 1.00e-05\n",
      "\tEpoch 100/100 - Train loss: 0.0884 - Val accuracy: 1.0000 - Val loss: 0.1783 - Val F1: 1.0000 - LR: 0.00e+00\n",
      "\tBest epoch: 100 - Best val accuracy: 1.0000 - Best val loss: 0.1783 - Best val F1: 1.0000\n",
      "\n",
      "\tEpoch 10/100 - Train loss: 0.5705 - Val accuracy: 0.7143 - Val loss: 1.0623 - Val F1: 0.5952 - LR: 9.00e-05\n",
      "\tEpoch 20/100 - Train loss: 0.3553 - Val accuracy: 0.1429 - Val loss: 1.1646 - Val F1: 0.0357 - LR: 8.00e-05\n",
      "\tEpoch 30/100 - Train loss: 0.2290 - Val accuracy: 0.1429 - Val loss: 1.3669 - Val F1: 0.0357 - LR: 7.00e-05\n",
      "\tEpoch 40/100 - Train loss: 0.1653 - Val accuracy: 0.1429 - Val loss: 1.4129 - Val F1: 0.0714 - LR: 6.00e-05\n",
      "\tEpoch 50/100 - Train loss: 0.1206 - Val accuracy: 0.7143 - Val loss: 0.8814 - Val F1: 0.7302 - LR: 5.00e-05\n",
      "\tEpoch 60/100 - Train loss: 0.1067 - Val accuracy: 0.8571 - Val loss: 0.3906 - Val F1: 0.8095 - LR: 4.00e-05\n",
      "\tEpoch 70/100 - Train loss: 0.0708 - Val accuracy: 0.8571 - Val loss: 0.2689 - Val F1: 0.8095 - LR: 3.00e-05\n",
      "\tEpoch 80/100 - Train loss: 0.0593 - Val accuracy: 0.8571 - Val loss: 0.2448 - Val F1: 0.8095 - LR: 2.00e-05\n",
      "\tEpoch 90/100 - Train loss: 0.0587 - Val accuracy: 0.8571 - Val loss: 0.2383 - Val F1: 0.8095 - LR: 1.00e-05\n",
      "\tEpoch 100/100 - Train loss: 0.0631 - Val accuracy: 0.8571 - Val loss: 0.2367 - Val F1: 0.8095 - LR: 0.00e+00\n",
      "\tBest epoch: 100 - Best val accuracy: 0.8571 - Best val loss: 0.2367 - Best val F1: 0.8095\n",
      "\n",
      "\tEpoch 10/100 - Train loss: 0.6090 - Val accuracy: 0.1429 - Val loss: 1.0908 - Val F1: 0.0357 - LR: 9.00e-05\n",
      "\tEpoch 20/100 - Train loss: 0.3841 - Val accuracy: 0.1429 - Val loss: 1.1740 - Val F1: 0.0357 - LR: 8.00e-05\n",
      "\tEpoch 30/100 - Train loss: 0.2685 - Val accuracy: 0.1429 - Val loss: 1.4010 - Val F1: 0.0357 - LR: 7.00e-05\n",
      "\tEpoch 40/100 - Train loss: 0.2026 - Val accuracy: 0.1429 - Val loss: 1.4522 - Val F1: 0.0357 - LR: 6.00e-05\n",
      "\tEpoch 50/100 - Train loss: 0.1521 - Val accuracy: 0.5714 - Val loss: 0.9297 - Val F1: 0.6071 - LR: 5.00e-05\n",
      "\tEpoch 60/100 - Train loss: 0.1238 - Val accuracy: 0.8571 - Val loss: 0.4346 - Val F1: 0.8095 - LR: 4.00e-05\n",
      "\tEpoch 70/100 - Train loss: 0.1096 - Val accuracy: 0.8571 - Val loss: 0.3050 - Val F1: 0.8095 - LR: 3.00e-05\n",
      "\tEpoch 80/100 - Train loss: 0.0898 - Val accuracy: 0.8571 - Val loss: 0.2811 - Val F1: 0.8095 - LR: 2.00e-05\n",
      "\tEpoch 90/100 - Train loss: 0.0894 - Val accuracy: 0.8571 - Val loss: 0.2751 - Val F1: 0.8095 - LR: 1.00e-05\n",
      "\tEpoch 100/100 - Train loss: 0.0838 - Val accuracy: 0.8571 - Val loss: 0.2736 - Val F1: 0.8095 - LR: 0.00e+00\n",
      "\tBest epoch: 100 - Best val accuracy: 0.8571 - Best val loss: 0.2736 - Best val F1: 0.8095\n",
      "\n",
      "\tEpoch 10/100 - Train loss: 0.5532 - Val accuracy: 0.7143 - Val loss: 1.0361 - Val F1: 0.5952 - LR: 9.00e-05\n",
      "\tEpoch 20/100 - Train loss: 0.3397 - Val accuracy: 0.7143 - Val loss: 1.0396 - Val F1: 0.5952 - LR: 8.00e-05\n",
      "\tEpoch 30/100 - Train loss: 0.2133 - Val accuracy: 0.1429 - Val loss: 1.1412 - Val F1: 0.0357 - LR: 7.00e-05\n",
      "\tEpoch 40/100 - Train loss: 0.1604 - Val accuracy: 0.1429 - Val loss: 1.1941 - Val F1: 0.0357 - LR: 6.00e-05\n",
      "\tEpoch 50/100 - Train loss: 0.1175 - Val accuracy: 0.7143 - Val loss: 0.8235 - Val F1: 0.7063 - LR: 5.00e-05\n",
      "\tEpoch 60/100 - Train loss: 0.0923 - Val accuracy: 1.0000 - Val loss: 0.3737 - Val F1: 1.0000 - LR: 4.00e-05\n",
      "\tEpoch 70/100 - Train loss: 0.0764 - Val accuracy: 1.0000 - Val loss: 0.2229 - Val F1: 1.0000 - LR: 3.00e-05\n",
      "\tEpoch 80/100 - Train loss: 0.0661 - Val accuracy: 1.0000 - Val loss: 0.1822 - Val F1: 1.0000 - LR: 2.00e-05\n",
      "\tEpoch 90/100 - Train loss: 0.0557 - Val accuracy: 1.0000 - Val loss: 0.1685 - Val F1: 1.0000 - LR: 1.00e-05\n",
      "\tEpoch 100/100 - Train loss: 0.0583 - Val accuracy: 1.0000 - Val loss: 0.1635 - Val F1: 1.0000 - LR: 0.00e+00\n",
      "\tBest epoch: 100 - Best val accuracy: 1.0000 - Best val loss: 0.1635 - Best val F1: 1.0000\n",
      "\n",
      "Source class: WAL | Domain: 66 | Accuracy: 0.8361 | Loss: 0.2838 | F1: 0.7865\n",
      "\n",
      "Domain: 67\n",
      "x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Training and evaluating on Dp data via cross-validation...\n",
      "\tEpoch 10/100 - Train loss: 0.5108 - Val accuracy: 0.7143 - Val loss: 1.0625 - Val F1: 0.5952 - LR: 9.00e-05\n",
      "\tEpoch 20/100 - Train loss: 0.3117 - Val accuracy: 0.1429 - Val loss: 1.0834 - Val F1: 0.0357 - LR: 8.00e-05\n",
      "\tEpoch 30/100 - Train loss: 0.2379 - Val accuracy: 0.2857 - Val loss: 1.1061 - Val F1: 0.1837 - LR: 7.00e-05\n",
      "\tEpoch 40/100 - Train loss: 0.1885 - Val accuracy: 0.5714 - Val loss: 0.8723 - Val F1: 0.5748 - LR: 6.00e-05\n",
      "\tEpoch 50/100 - Train loss: 0.1291 - Val accuracy: 0.8571 - Val loss: 0.4688 - Val F1: 0.8730 - LR: 5.00e-05\n",
      "\tEpoch 60/100 - Train loss: 0.0969 - Val accuracy: 1.0000 - Val loss: 0.2766 - Val F1: 1.0000 - LR: 4.00e-05\n",
      "\tEpoch 70/100 - Train loss: 0.0773 - Val accuracy: 1.0000 - Val loss: 0.2198 - Val F1: 1.0000 - LR: 3.00e-05\n",
      "\tEpoch 80/100 - Train loss: 0.0664 - Val accuracy: 1.0000 - Val loss: 0.2011 - Val F1: 1.0000 - LR: 2.00e-05\n",
      "\tEpoch 90/100 - Train loss: 0.0589 - Val accuracy: 1.0000 - Val loss: 0.1918 - Val F1: 1.0000 - LR: 1.00e-05\n",
      "\tEpoch 100/100 - Train loss: 0.0554 - Val accuracy: 1.0000 - Val loss: 0.1865 - Val F1: 1.0000 - LR: 0.00e+00\n",
      "\tBest epoch: 100 - Best val accuracy: 1.0000 - Best val loss: 0.1865 - Best val F1: 1.0000\n",
      "\n",
      "\tEpoch 10/100 - Train loss: 0.6211 - Val accuracy: 0.7143 - Val loss: 1.0261 - Val F1: 0.5952 - LR: 9.00e-05\n",
      "\tEpoch 20/100 - Train loss: 0.3594 - Val accuracy: 0.7143 - Val loss: 0.9690 - Val F1: 0.5952 - LR: 8.00e-05\n",
      "\tEpoch 30/100 - Train loss: 0.2369 - Val accuracy: 0.7143 - Val loss: 0.9775 - Val F1: 0.7063 - LR: 7.00e-05\n",
      "\tEpoch 40/100 - Train loss: 0.1673 - Val accuracy: 0.7143 - Val loss: 0.8535 - Val F1: 0.7063 - LR: 6.00e-05\n",
      "\tEpoch 50/100 - Train loss: 0.1304 - Val accuracy: 0.8571 - Val loss: 0.4820 - Val F1: 0.8095 - LR: 5.00e-05\n",
      "\tEpoch 60/100 - Train loss: 0.1061 - Val accuracy: 0.8571 - Val loss: 0.2691 - Val F1: 0.8095 - LR: 4.00e-05\n",
      "\tEpoch 70/100 - Train loss: 0.0903 - Val accuracy: 0.8571 - Val loss: 0.2137 - Val F1: 0.8095 - LR: 3.00e-05\n",
      "\tEpoch 80/100 - Train loss: 0.0790 - Val accuracy: 0.8571 - Val loss: 0.1980 - Val F1: 0.8095 - LR: 2.00e-05\n",
      "\tEpoch 90/100 - Train loss: 0.0735 - Val accuracy: 0.8571 - Val loss: 0.1921 - Val F1: 0.8095 - LR: 1.00e-05\n",
      "\tEpoch 100/100 - Train loss: 0.0636 - Val accuracy: 0.8571 - Val loss: 0.1898 - Val F1: 0.8095 - LR: 0.00e+00\n",
      "\tBest epoch: 100 - Best val accuracy: 0.8571 - Best val loss: 0.1898 - Best val F1: 0.8095\n",
      "\n",
      "\tEpoch 10/100 - Train loss: 0.5903 - Val accuracy: 0.2857 - Val loss: 1.0878 - Val F1: 0.2789 - LR: 9.00e-05\n",
      "\tEpoch 20/100 - Train loss: 0.3683 - Val accuracy: 0.2857 - Val loss: 1.0755 - Val F1: 0.2789 - LR: 8.00e-05\n",
      "\tEpoch 30/100 - Train loss: 0.2334 - Val accuracy: 0.2857 - Val loss: 1.0747 - Val F1: 0.2789 - LR: 7.00e-05\n",
      "\tEpoch 40/100 - Train loss: 0.1729 - Val accuracy: 0.5714 - Val loss: 0.8419 - Val F1: 0.5748 - LR: 6.00e-05\n",
      "\tEpoch 50/100 - Train loss: 0.1196 - Val accuracy: 0.8571 - Val loss: 0.4629 - Val F1: 0.7922 - LR: 5.00e-05\n",
      "\tEpoch 60/100 - Train loss: 0.1005 - Val accuracy: 0.8571 - Val loss: 0.3492 - Val F1: 0.7922 - LR: 4.00e-05\n",
      "\tEpoch 70/100 - Train loss: 0.0757 - Val accuracy: 0.8571 - Val loss: 0.3596 - Val F1: 0.7922 - LR: 3.00e-05\n",
      "\tEpoch 80/100 - Train loss: 0.0690 - Val accuracy: 0.8571 - Val loss: 0.3745 - Val F1: 0.7922 - LR: 2.00e-05\n",
      "\tEpoch 90/100 - Train loss: 0.0617 - Val accuracy: 0.8571 - Val loss: 0.3800 - Val F1: 0.7922 - LR: 1.00e-05\n",
      "\tEpoch 100/100 - Train loss: 0.0628 - Val accuracy: 0.8571 - Val loss: 0.3830 - Val F1: 0.7922 - LR: 0.00e+00\n",
      "\tBest epoch: 62 - Best val accuracy: 0.8571 - Best val loss: 0.3477 - Best val F1: 0.7922\n",
      "\n",
      "\tEpoch 10/100 - Train loss: 0.5533 - Val accuracy: 0.2857 - Val loss: 1.0853 - Val F1: 0.2789 - LR: 9.00e-05\n",
      "\tEpoch 20/100 - Train loss: 0.3568 - Val accuracy: 0.1429 - Val loss: 1.1384 - Val F1: 0.0357 - LR: 8.00e-05\n",
      "\tEpoch 30/100 - Train loss: 0.2346 - Val accuracy: 0.1429 - Val loss: 1.2591 - Val F1: 0.0357 - LR: 7.00e-05\n",
      "\tEpoch 40/100 - Train loss: 0.1795 - Val accuracy: 0.2857 - Val loss: 1.1628 - Val F1: 0.2789 - LR: 6.00e-05\n",
      "\tEpoch 50/100 - Train loss: 0.1429 - Val accuracy: 0.8571 - Val loss: 0.6450 - Val F1: 0.8095 - LR: 5.00e-05\n",
      "\tEpoch 60/100 - Train loss: 0.1121 - Val accuracy: 0.8571 - Val loss: 0.3254 - Val F1: 0.8095 - LR: 4.00e-05\n",
      "\tEpoch 70/100 - Train loss: 0.1000 - Val accuracy: 0.8571 - Val loss: 0.2405 - Val F1: 0.8095 - LR: 3.00e-05\n",
      "\tEpoch 80/100 - Train loss: 0.0811 - Val accuracy: 0.8571 - Val loss: 0.2141 - Val F1: 0.8095 - LR: 2.00e-05\n",
      "\tEpoch 90/100 - Train loss: 0.0859 - Val accuracy: 0.8571 - Val loss: 0.2041 - Val F1: 0.8095 - LR: 1.00e-05\n",
      "\tEpoch 100/100 - Train loss: 0.0825 - Val accuracy: 0.8571 - Val loss: 0.2009 - Val F1: 0.8095 - LR: 0.00e+00\n",
      "\tBest epoch: 100 - Best val accuracy: 0.8571 - Best val loss: 0.2009 - Best val F1: 0.8095\n",
      "\n",
      "\tEpoch 10/100 - Train loss: 0.6208 - Val accuracy: 0.7143 - Val loss: 1.0864 - Val F1: 0.5952 - LR: 9.00e-05\n",
      "\tEpoch 20/100 - Train loss: 0.3798 - Val accuracy: 0.2857 - Val loss: 1.0873 - Val F1: 0.2789 - LR: 8.00e-05\n",
      "\tEpoch 30/100 - Train loss: 0.2603 - Val accuracy: 0.1429 - Val loss: 1.1702 - Val F1: 0.0357 - LR: 7.00e-05\n",
      "\tEpoch 40/100 - Train loss: 0.1760 - Val accuracy: 0.4286 - Val loss: 1.0787 - Val F1: 0.4653 - LR: 6.00e-05\n",
      "\tEpoch 50/100 - Train loss: 0.1203 - Val accuracy: 0.8571 - Val loss: 0.6421 - Val F1: 0.8730 - LR: 5.00e-05\n",
      "\tEpoch 60/100 - Train loss: 0.1079 - Val accuracy: 1.0000 - Val loss: 0.3198 - Val F1: 1.0000 - LR: 4.00e-05\n",
      "\tEpoch 70/100 - Train loss: 0.0835 - Val accuracy: 1.0000 - Val loss: 0.2020 - Val F1: 1.0000 - LR: 3.00e-05\n",
      "\tEpoch 80/100 - Train loss: 0.0684 - Val accuracy: 1.0000 - Val loss: 0.1597 - Val F1: 1.0000 - LR: 2.00e-05\n",
      "\tEpoch 90/100 - Train loss: 0.0640 - Val accuracy: 1.0000 - Val loss: 0.1426 - Val F1: 1.0000 - LR: 1.00e-05\n",
      "\tEpoch 100/100 - Train loss: 0.0639 - Val accuracy: 1.0000 - Val loss: 0.1362 - Val F1: 1.0000 - LR: 0.00e+00\n",
      "\tBest epoch: 100 - Best val accuracy: 1.0000 - Best val loss: 0.1362 - Best val F1: 1.0000\n",
      "\n",
      "Source class: WAL | Domain: 67 | Accuracy: 0.9778 | Loss: 0.1926 | F1: 0.9778\n",
      "\n",
      "Domain: 68\n",
      "x_dp_dom.shape: (43, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Training and evaluating on Dp data via cross-validation...\n",
      "\tEpoch 10/100 - Train loss: 0.5298 - Val accuracy: 0.7143 - Val loss: 1.0735 - Val F1: 0.5952 - LR: 9.00e-05\n",
      "\tEpoch 20/100 - Train loss: 0.3515 - Val accuracy: 0.1429 - Val loss: 1.2105 - Val F1: 0.0571 - LR: 8.00e-05\n",
      "\tEpoch 30/100 - Train loss: 0.2746 - Val accuracy: 0.1429 - Val loss: 1.4274 - Val F1: 0.0408 - LR: 7.00e-05\n",
      "\tEpoch 40/100 - Train loss: 0.2208 - Val accuracy: 0.1429 - Val loss: 1.3362 - Val F1: 0.0571 - LR: 6.00e-05\n",
      "\tEpoch 50/100 - Train loss: 0.1921 - Val accuracy: 0.8571 - Val loss: 0.6762 - Val F1: 0.8730 - LR: 5.00e-05\n",
      "\tEpoch 60/100 - Train loss: 0.1649 - Val accuracy: 1.0000 - Val loss: 0.3202 - Val F1: 1.0000 - LR: 4.00e-05\n",
      "\tEpoch 70/100 - Train loss: 0.1373 - Val accuracy: 1.0000 - Val loss: 0.2265 - Val F1: 1.0000 - LR: 3.00e-05\n",
      "\tEpoch 80/100 - Train loss: 0.1260 - Val accuracy: 1.0000 - Val loss: 0.1971 - Val F1: 1.0000 - LR: 2.00e-05\n",
      "\tEpoch 90/100 - Train loss: 0.1202 - Val accuracy: 1.0000 - Val loss: 0.1851 - Val F1: 1.0000 - LR: 1.00e-05\n",
      "\tEpoch 100/100 - Train loss: 0.1179 - Val accuracy: 1.0000 - Val loss: 0.1805 - Val F1: 1.0000 - LR: 0.00e+00\n",
      "\tBest epoch: 100 - Best val accuracy: 1.0000 - Best val loss: 0.1805 - Best val F1: 1.0000\n",
      "\n",
      "\tEpoch 10/100 - Train loss: 0.5696 - Val accuracy: 0.7143 - Val loss: 1.0627 - Val F1: 0.5952 - LR: 9.00e-05\n",
      "\tEpoch 20/100 - Train loss: 0.3536 - Val accuracy: 0.1429 - Val loss: 1.2013 - Val F1: 0.0357 - LR: 8.00e-05\n",
      "\tEpoch 30/100 - Train loss: 0.2325 - Val accuracy: 0.1429 - Val loss: 1.5188 - Val F1: 0.0408 - LR: 7.00e-05\n",
      "\tEpoch 40/100 - Train loss: 0.1602 - Val accuracy: 0.1429 - Val loss: 1.6139 - Val F1: 0.0357 - LR: 6.00e-05\n",
      "\tEpoch 50/100 - Train loss: 0.1302 - Val accuracy: 0.4286 - Val loss: 1.0385 - Val F1: 0.4558 - LR: 5.00e-05\n",
      "\tEpoch 60/100 - Train loss: 0.1046 - Val accuracy: 0.8571 - Val loss: 0.4788 - Val F1: 0.8095 - LR: 4.00e-05\n",
      "\tEpoch 70/100 - Train loss: 0.0846 - Val accuracy: 0.8571 - Val loss: 0.3123 - Val F1: 0.8095 - LR: 3.00e-05\n",
      "\tEpoch 80/100 - Train loss: 0.0730 - Val accuracy: 0.8571 - Val loss: 0.2661 - Val F1: 0.8095 - LR: 2.00e-05\n",
      "\tEpoch 90/100 - Train loss: 0.0576 - Val accuracy: 0.8571 - Val loss: 0.2502 - Val F1: 0.8095 - LR: 1.00e-05\n",
      "\tEpoch 100/100 - Train loss: 0.0681 - Val accuracy: 0.8571 - Val loss: 0.2441 - Val F1: 0.8095 - LR: 0.00e+00\n",
      "\tBest epoch: 100 - Best val accuracy: 0.8571 - Best val loss: 0.2441 - Best val F1: 0.8095\n",
      "\n",
      "\tEpoch 10/100 - Train loss: 0.5264 - Val accuracy: 0.1429 - Val loss: 1.0925 - Val F1: 0.0357 - LR: 9.00e-05\n",
      "\tEpoch 20/100 - Train loss: 0.3191 - Val accuracy: 0.1429 - Val loss: 1.2558 - Val F1: 0.0357 - LR: 8.00e-05\n",
      "\tEpoch 30/100 - Train loss: 0.2137 - Val accuracy: 0.2857 - Val loss: 1.5716 - Val F1: 0.1837 - LR: 7.00e-05\n",
      "\tEpoch 40/100 - Train loss: 0.1720 - Val accuracy: 0.2857 - Val loss: 1.5915 - Val F1: 0.1837 - LR: 6.00e-05\n",
      "\tEpoch 50/100 - Train loss: 0.1366 - Val accuracy: 0.7143 - Val loss: 0.7455 - Val F1: 0.7500 - LR: 5.00e-05\n",
      "\tEpoch 60/100 - Train loss: 0.1051 - Val accuracy: 1.0000 - Val loss: 0.2354 - Val F1: 1.0000 - LR: 4.00e-05\n",
      "\tEpoch 70/100 - Train loss: 0.0897 - Val accuracy: 1.0000 - Val loss: 0.1232 - Val F1: 1.0000 - LR: 3.00e-05\n",
      "\tEpoch 80/100 - Train loss: 0.0723 - Val accuracy: 1.0000 - Val loss: 0.0931 - Val F1: 1.0000 - LR: 2.00e-05\n",
      "\tEpoch 90/100 - Train loss: 0.0737 - Val accuracy: 1.0000 - Val loss: 0.0822 - Val F1: 1.0000 - LR: 1.00e-05\n",
      "\tEpoch 100/100 - Train loss: 0.0652 - Val accuracy: 1.0000 - Val loss: 0.0781 - Val F1: 1.0000 - LR: 0.00e+00\n",
      "\tBest epoch: 100 - Best val accuracy: 1.0000 - Best val loss: 0.0781 - Best val F1: 1.0000\n",
      "\n",
      "\tEpoch 10/100 - Train loss: 0.4706 - Val accuracy: 0.0000 - Val loss: 1.1092 - Val F1: 0.0000 - LR: 9.00e-05\n",
      "\tEpoch 20/100 - Train loss: 0.3193 - Val accuracy: 0.1429 - Val loss: 1.2673 - Val F1: 0.0357 - LR: 8.00e-05\n",
      "\tEpoch 30/100 - Train loss: 0.2232 - Val accuracy: 0.1429 - Val loss: 1.5390 - Val F1: 0.0357 - LR: 7.00e-05\n",
      "\tEpoch 40/100 - Train loss: 0.1583 - Val accuracy: 0.1429 - Val loss: 1.6618 - Val F1: 0.0357 - LR: 6.00e-05\n",
      "\tEpoch 50/100 - Train loss: 0.1172 - Val accuracy: 0.4286 - Val loss: 1.0054 - Val F1: 0.4558 - LR: 5.00e-05\n",
      "\tEpoch 60/100 - Train loss: 0.0968 - Val accuracy: 1.0000 - Val loss: 0.3635 - Val F1: 1.0000 - LR: 4.00e-05\n",
      "\tEpoch 70/100 - Train loss: 0.0784 - Val accuracy: 1.0000 - Val loss: 0.1957 - Val F1: 1.0000 - LR: 3.00e-05\n",
      "\tEpoch 80/100 - Train loss: 0.0650 - Val accuracy: 1.0000 - Val loss: 0.1551 - Val F1: 1.0000 - LR: 2.00e-05\n",
      "\tEpoch 90/100 - Train loss: 0.0594 - Val accuracy: 1.0000 - Val loss: 0.1409 - Val F1: 1.0000 - LR: 1.00e-05\n",
      "\tEpoch 100/100 - Train loss: 0.0580 - Val accuracy: 1.0000 - Val loss: 0.1358 - Val F1: 1.0000 - LR: 0.00e+00\n",
      "\tBest epoch: 100 - Best val accuracy: 1.0000 - Best val loss: 0.1358 - Best val F1: 1.0000\n",
      "\n",
      "\tEpoch 10/100 - Train loss: 0.4678 - Val accuracy: 0.1429 - Val loss: 1.1201 - Val F1: 0.0357 - LR: 9.00e-05\n",
      "\tEpoch 20/100 - Train loss: 0.2986 - Val accuracy: 0.1429 - Val loss: 1.2572 - Val F1: 0.0357 - LR: 8.00e-05\n",
      "\tEpoch 30/100 - Train loss: 0.2083 - Val accuracy: 0.1429 - Val loss: 1.4556 - Val F1: 0.0357 - LR: 7.00e-05\n",
      "\tEpoch 40/100 - Train loss: 0.1707 - Val accuracy: 0.1429 - Val loss: 1.4337 - Val F1: 0.0357 - LR: 6.00e-05\n",
      "\tEpoch 50/100 - Train loss: 0.1301 - Val accuracy: 0.5714 - Val loss: 0.8364 - Val F1: 0.5929 - LR: 5.00e-05\n",
      "\tEpoch 60/100 - Train loss: 0.0940 - Val accuracy: 1.0000 - Val loss: 0.3338 - Val F1: 1.0000 - LR: 4.00e-05\n",
      "\tEpoch 70/100 - Train loss: 0.0795 - Val accuracy: 1.0000 - Val loss: 0.1969 - Val F1: 1.0000 - LR: 3.00e-05\n",
      "\tEpoch 80/100 - Train loss: 0.0699 - Val accuracy: 1.0000 - Val loss: 0.1585 - Val F1: 1.0000 - LR: 2.00e-05\n",
      "\tEpoch 90/100 - Train loss: 0.0672 - Val accuracy: 1.0000 - Val loss: 0.1442 - Val F1: 1.0000 - LR: 1.00e-05\n",
      "\tEpoch 100/100 - Train loss: 0.0615 - Val accuracy: 1.0000 - Val loss: 0.1388 - Val F1: 1.0000 - LR: 0.00e+00\n",
      "\tBest epoch: 100 - Best val accuracy: 1.0000 - Best val loss: 0.1388 - Best val F1: 1.0000\n",
      "\n",
      "Source class: WAL | Domain: 68 | Accuracy: 0.9306 | Loss: 0.2143 | F1: 0.9194\n",
      "\n",
      "Domain: 69\n",
      "x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Training and evaluating on Dp data via cross-validation...\n",
      "\tEpoch 10/100 - Train loss: 0.6075 - Val accuracy: 0.7143 - Val loss: 1.0274 - Val F1: 0.5952 - LR: 9.00e-05\n",
      "\tEpoch 20/100 - Train loss: 0.3139 - Val accuracy: 0.7143 - Val loss: 0.9638 - Val F1: 0.5952 - LR: 8.00e-05\n",
      "\tEpoch 30/100 - Train loss: 0.1898 - Val accuracy: 0.7143 - Val loss: 0.8456 - Val F1: 0.5952 - LR: 7.00e-05\n",
      "\tEpoch 40/100 - Train loss: 0.1274 - Val accuracy: 0.8571 - Val loss: 0.5909 - Val F1: 0.8095 - LR: 6.00e-05\n",
      "\tEpoch 50/100 - Train loss: 0.0974 - Val accuracy: 1.0000 - Val loss: 0.3043 - Val F1: 1.0000 - LR: 5.00e-05\n",
      "\tEpoch 60/100 - Train loss: 0.0791 - Val accuracy: 1.0000 - Val loss: 0.1392 - Val F1: 1.0000 - LR: 4.00e-05\n",
      "\tEpoch 70/100 - Train loss: 0.0560 - Val accuracy: 1.0000 - Val loss: 0.0858 - Val F1: 1.0000 - LR: 3.00e-05\n",
      "\tEpoch 80/100 - Train loss: 0.0498 - Val accuracy: 1.0000 - Val loss: 0.0678 - Val F1: 1.0000 - LR: 2.00e-05\n",
      "\tEpoch 90/100 - Train loss: 0.0527 - Val accuracy: 1.0000 - Val loss: 0.0607 - Val F1: 1.0000 - LR: 1.00e-05\n",
      "\tEpoch 100/100 - Train loss: 0.0586 - Val accuracy: 1.0000 - Val loss: 0.0583 - Val F1: 1.0000 - LR: 0.00e+00\n",
      "\tBest epoch: 100 - Best val accuracy: 1.0000 - Best val loss: 0.0583 - Best val F1: 1.0000\n",
      "\n",
      "\tEpoch 10/100 - Train loss: 0.5543 - Val accuracy: 0.1429 - Val loss: 1.0811 - Val F1: 0.0357 - LR: 9.00e-05\n",
      "\tEpoch 20/100 - Train loss: 0.2712 - Val accuracy: 0.8571 - Val loss: 1.0140 - Val F1: 0.8095 - LR: 8.00e-05\n",
      "\tEpoch 30/100 - Train loss: 0.1560 - Val accuracy: 0.8571 - Val loss: 0.8152 - Val F1: 0.8095 - LR: 7.00e-05\n",
      "\tEpoch 40/100 - Train loss: 0.1105 - Val accuracy: 0.8571 - Val loss: 0.5728 - Val F1: 0.8095 - LR: 6.00e-05\n",
      "\tEpoch 50/100 - Train loss: 0.0712 - Val accuracy: 0.8571 - Val loss: 0.4032 - Val F1: 0.8095 - LR: 5.00e-05\n",
      "\tEpoch 60/100 - Train loss: 0.0520 - Val accuracy: 0.8571 - Val loss: 0.3164 - Val F1: 0.8095 - LR: 4.00e-05\n",
      "\tEpoch 70/100 - Train loss: 0.0378 - Val accuracy: 0.8571 - Val loss: 0.2750 - Val F1: 0.8095 - LR: 3.00e-05\n",
      "\tEpoch 80/100 - Train loss: 0.0355 - Val accuracy: 0.8571 - Val loss: 0.2591 - Val F1: 0.8095 - LR: 2.00e-05\n",
      "\tEpoch 90/100 - Train loss: 0.0342 - Val accuracy: 0.8571 - Val loss: 0.2528 - Val F1: 0.8095 - LR: 1.00e-05\n",
      "\tEpoch 100/100 - Train loss: 0.0340 - Val accuracy: 0.8571 - Val loss: 0.2513 - Val F1: 0.8095 - LR: 0.00e+00\n",
      "\tBest epoch: 100 - Best val accuracy: 0.8571 - Best val loss: 0.2513 - Best val F1: 0.8095\n",
      "\n",
      "\tEpoch 10/100 - Train loss: 0.4954 - Val accuracy: 0.7143 - Val loss: 1.0168 - Val F1: 0.5952 - LR: 9.00e-05\n",
      "\tEpoch 20/100 - Train loss: 0.2679 - Val accuracy: 0.7143 - Val loss: 0.9299 - Val F1: 0.5952 - LR: 8.00e-05\n",
      "\tEpoch 30/100 - Train loss: 0.1534 - Val accuracy: 0.8571 - Val loss: 0.7508 - Val F1: 0.8095 - LR: 7.00e-05\n",
      "\tEpoch 40/100 - Train loss: 0.1134 - Val accuracy: 0.8571 - Val loss: 0.4930 - Val F1: 0.8095 - LR: 6.00e-05\n",
      "\tEpoch 50/100 - Train loss: 0.0770 - Val accuracy: 1.0000 - Val loss: 0.2764 - Val F1: 1.0000 - LR: 5.00e-05\n",
      "\tEpoch 60/100 - Train loss: 0.0563 - Val accuracy: 1.0000 - Val loss: 0.2010 - Val F1: 1.0000 - LR: 4.00e-05\n",
      "\tEpoch 70/100 - Train loss: 0.0464 - Val accuracy: 0.8571 - Val loss: 0.1829 - Val F1: 0.8095 - LR: 3.00e-05\n",
      "\tEpoch 80/100 - Train loss: 0.0390 - Val accuracy: 0.8571 - Val loss: 0.1768 - Val F1: 0.8095 - LR: 2.00e-05\n",
      "\tEpoch 90/100 - Train loss: 0.0425 - Val accuracy: 0.8571 - Val loss: 0.1745 - Val F1: 0.8095 - LR: 1.00e-05\n",
      "\tEpoch 100/100 - Train loss: 0.0397 - Val accuracy: 0.8571 - Val loss: 0.1736 - Val F1: 0.8095 - LR: 0.00e+00\n",
      "\tBest epoch: 100 - Best val accuracy: 0.8571 - Best val loss: 0.1736 - Best val F1: 0.8095\n",
      "\n",
      "\tEpoch 10/100 - Train loss: 0.5226 - Val accuracy: 0.1429 - Val loss: 1.1091 - Val F1: 0.0952 - LR: 9.00e-05\n",
      "\tEpoch 20/100 - Train loss: 0.2812 - Val accuracy: 1.0000 - Val loss: 1.0466 - Val F1: 1.0000 - LR: 8.00e-05\n",
      "\tEpoch 30/100 - Train loss: 0.2012 - Val accuracy: 0.8571 - Val loss: 0.8874 - Val F1: 0.8095 - LR: 7.00e-05\n",
      "\tEpoch 40/100 - Train loss: 0.1635 - Val accuracy: 0.8571 - Val loss: 0.5343 - Val F1: 0.8095 - LR: 6.00e-05\n",
      "\tEpoch 50/100 - Train loss: 0.1133 - Val accuracy: 1.0000 - Val loss: 0.3108 - Val F1: 1.0000 - LR: 5.00e-05\n",
      "\tEpoch 60/100 - Train loss: 0.0955 - Val accuracy: 0.8571 - Val loss: 0.2389 - Val F1: 0.8095 - LR: 4.00e-05\n",
      "\tEpoch 70/100 - Train loss: 0.0726 - Val accuracy: 0.8571 - Val loss: 0.2158 - Val F1: 0.8095 - LR: 3.00e-05\n",
      "\tEpoch 80/100 - Train loss: 0.0578 - Val accuracy: 0.8571 - Val loss: 0.2066 - Val F1: 0.8095 - LR: 2.00e-05\n",
      "\tEpoch 90/100 - Train loss: 0.0668 - Val accuracy: 0.8571 - Val loss: 0.2020 - Val F1: 0.8095 - LR: 1.00e-05\n",
      "\tEpoch 100/100 - Train loss: 0.0535 - Val accuracy: 0.8571 - Val loss: 0.2002 - Val F1: 0.8095 - LR: 0.00e+00\n",
      "\tBest epoch: 100 - Best val accuracy: 0.8571 - Best val loss: 0.2002 - Best val F1: 0.8095\n",
      "\n",
      "\tEpoch 10/100 - Train loss: 0.5356 - Val accuracy: 0.7143 - Val loss: 0.9848 - Val F1: 0.5952 - LR: 9.00e-05\n",
      "\tEpoch 20/100 - Train loss: 0.3341 - Val accuracy: 0.7143 - Val loss: 0.8982 - Val F1: 0.5952 - LR: 8.00e-05\n",
      "\tEpoch 30/100 - Train loss: 0.2457 - Val accuracy: 0.8571 - Val loss: 0.7272 - Val F1: 0.8095 - LR: 7.00e-05\n",
      "\tEpoch 40/100 - Train loss: 0.2129 - Val accuracy: 0.8571 - Val loss: 0.4270 - Val F1: 0.8095 - LR: 6.00e-05\n",
      "\tEpoch 50/100 - Train loss: 0.1763 - Val accuracy: 1.0000 - Val loss: 0.2603 - Val F1: 1.0000 - LR: 5.00e-05\n",
      "\tEpoch 60/100 - Train loss: 0.1388 - Val accuracy: 1.0000 - Val loss: 0.2112 - Val F1: 1.0000 - LR: 4.00e-05\n",
      "\tEpoch 70/100 - Train loss: 0.1305 - Val accuracy: 0.8571 - Val loss: 0.1927 - Val F1: 0.8095 - LR: 3.00e-05\n",
      "\tEpoch 80/100 - Train loss: 0.1034 - Val accuracy: 0.8571 - Val loss: 0.1835 - Val F1: 0.8095 - LR: 2.00e-05\n",
      "\tEpoch 90/100 - Train loss: 0.1090 - Val accuracy: 0.8571 - Val loss: 0.1785 - Val F1: 0.8095 - LR: 1.00e-05\n",
      "\tEpoch 100/100 - Train loss: 0.0982 - Val accuracy: 0.8571 - Val loss: 0.1766 - Val F1: 0.8095 - LR: 0.00e+00\n",
      "\tBest epoch: 100 - Best val accuracy: 0.8571 - Best val loss: 0.1766 - Best val F1: 0.8095\n",
      "\n",
      "Source class: WAL | Domain: 69 | Accuracy: 0.9083 | Loss: 0.2244 | F1: 0.8972\n",
      "\n",
      "Domain: 70\n",
      "x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Training and evaluating on Dp data via cross-validation...\n",
      "\tEpoch 10/100 - Train loss: 0.4972 - Val accuracy: 0.7143 - Val loss: 1.0004 - Val F1: 0.5952 - LR: 9.00e-05\n",
      "\tEpoch 20/100 - Train loss: 0.3229 - Val accuracy: 0.7143 - Val loss: 0.9713 - Val F1: 0.5952 - LR: 8.00e-05\n",
      "\tEpoch 30/100 - Train loss: 0.2114 - Val accuracy: 1.0000 - Val loss: 0.9324 - Val F1: 1.0000 - LR: 7.00e-05\n",
      "\tEpoch 40/100 - Train loss: 0.1708 - Val accuracy: 1.0000 - Val loss: 0.6860 - Val F1: 1.0000 - LR: 6.00e-05\n",
      "\tEpoch 50/100 - Train loss: 0.1373 - Val accuracy: 1.0000 - Val loss: 0.3332 - Val F1: 1.0000 - LR: 5.00e-05\n",
      "\tEpoch 60/100 - Train loss: 0.1170 - Val accuracy: 1.0000 - Val loss: 0.1834 - Val F1: 1.0000 - LR: 4.00e-05\n",
      "\tEpoch 70/100 - Train loss: 0.1152 - Val accuracy: 1.0000 - Val loss: 0.1392 - Val F1: 1.0000 - LR: 3.00e-05\n",
      "\tEpoch 80/100 - Train loss: 0.1005 - Val accuracy: 1.0000 - Val loss: 0.1230 - Val F1: 1.0000 - LR: 2.00e-05\n",
      "\tEpoch 90/100 - Train loss: 0.0959 - Val accuracy: 1.0000 - Val loss: 0.1161 - Val F1: 1.0000 - LR: 1.00e-05\n",
      "\tEpoch 100/100 - Train loss: 0.0871 - Val accuracy: 1.0000 - Val loss: 0.1134 - Val F1: 1.0000 - LR: 0.00e+00\n",
      "\tBest epoch: 100 - Best val accuracy: 1.0000 - Best val loss: 0.1134 - Best val F1: 1.0000\n",
      "\n",
      "\tEpoch 10/100 - Train loss: 0.5582 - Val accuracy: 0.7143 - Val loss: 1.0024 - Val F1: 0.5952 - LR: 9.00e-05\n",
      "\tEpoch 20/100 - Train loss: 0.3522 - Val accuracy: 0.7143 - Val loss: 0.9407 - Val F1: 0.5952 - LR: 8.00e-05\n",
      "\tEpoch 30/100 - Train loss: 0.2205 - Val accuracy: 0.7143 - Val loss: 0.9651 - Val F1: 0.7063 - LR: 7.00e-05\n",
      "\tEpoch 40/100 - Train loss: 0.1798 - Val accuracy: 0.7143 - Val loss: 0.8026 - Val F1: 0.7063 - LR: 6.00e-05\n",
      "\tEpoch 50/100 - Train loss: 0.1470 - Val accuracy: 0.8571 - Val loss: 0.4643 - Val F1: 0.8095 - LR: 5.00e-05\n",
      "\tEpoch 60/100 - Train loss: 0.1305 - Val accuracy: 0.8571 - Val loss: 0.3296 - Val F1: 0.8095 - LR: 4.00e-05\n",
      "\tEpoch 70/100 - Train loss: 0.0964 - Val accuracy: 0.8571 - Val loss: 0.3026 - Val F1: 0.8095 - LR: 3.00e-05\n",
      "\tEpoch 80/100 - Train loss: 0.0815 - Val accuracy: 0.8571 - Val loss: 0.2983 - Val F1: 0.8095 - LR: 2.00e-05\n",
      "\tEpoch 90/100 - Train loss: 0.0844 - Val accuracy: 0.8571 - Val loss: 0.2969 - Val F1: 0.8095 - LR: 1.00e-05\n",
      "\tEpoch 100/100 - Train loss: 0.0815 - Val accuracy: 0.8571 - Val loss: 0.2959 - Val F1: 0.8095 - LR: 0.00e+00\n",
      "\tBest epoch: 100 - Best val accuracy: 0.8571 - Best val loss: 0.2959 - Best val F1: 0.8095\n",
      "\n",
      "\tEpoch 10/100 - Train loss: 0.6074 - Val accuracy: 0.1429 - Val loss: 1.0747 - Val F1: 0.0357 - LR: 9.00e-05\n",
      "\tEpoch 20/100 - Train loss: 0.3891 - Val accuracy: 0.5714 - Val loss: 1.0494 - Val F1: 0.5929 - LR: 8.00e-05\n",
      "\tEpoch 30/100 - Train loss: 0.2916 - Val accuracy: 0.4286 - Val loss: 1.0146 - Val F1: 0.4558 - LR: 7.00e-05\n",
      "\tEpoch 40/100 - Train loss: 0.2178 - Val accuracy: 0.8571 - Val loss: 0.7425 - Val F1: 0.8095 - LR: 6.00e-05\n",
      "\tEpoch 50/100 - Train loss: 0.1742 - Val accuracy: 0.8571 - Val loss: 0.4080 - Val F1: 0.8095 - LR: 5.00e-05\n",
      "\tEpoch 60/100 - Train loss: 0.1437 - Val accuracy: 0.7143 - Val loss: 0.3018 - Val F1: 0.7143 - LR: 4.00e-05\n",
      "\tEpoch 70/100 - Train loss: 0.1160 - Val accuracy: 0.7143 - Val loss: 0.2771 - Val F1: 0.7143 - LR: 3.00e-05\n",
      "\tEpoch 80/100 - Train loss: 0.1057 - Val accuracy: 0.7143 - Val loss: 0.2700 - Val F1: 0.7143 - LR: 2.00e-05\n",
      "\tEpoch 90/100 - Train loss: 0.0937 - Val accuracy: 0.8571 - Val loss: 0.2678 - Val F1: 0.8095 - LR: 1.00e-05\n",
      "\tEpoch 100/100 - Train loss: 0.0990 - Val accuracy: 0.8571 - Val loss: 0.2672 - Val F1: 0.8095 - LR: 0.00e+00\n",
      "\tBest epoch: 100 - Best val accuracy: 0.8571 - Best val loss: 0.2672 - Best val F1: 0.8095\n",
      "\n",
      "\tEpoch 10/100 - Train loss: 0.5362 - Val accuracy: 0.7143 - Val loss: 0.9911 - Val F1: 0.5952 - LR: 9.00e-05\n",
      "\tEpoch 20/100 - Train loss: 0.3405 - Val accuracy: 0.7143 - Val loss: 1.0386 - Val F1: 0.5952 - LR: 8.00e-05\n",
      "\tEpoch 30/100 - Train loss: 0.2764 - Val accuracy: 0.1429 - Val loss: 1.1131 - Val F1: 0.0357 - LR: 7.00e-05\n",
      "\tEpoch 40/100 - Train loss: 0.2246 - Val accuracy: 0.7143 - Val loss: 0.9036 - Val F1: 0.7063 - LR: 6.00e-05\n",
      "\tEpoch 50/100 - Train loss: 0.1911 - Val accuracy: 0.8571 - Val loss: 0.4508 - Val F1: 0.8095 - LR: 5.00e-05\n",
      "\tEpoch 60/100 - Train loss: 0.1666 - Val accuracy: 0.8571 - Val loss: 0.2835 - Val F1: 0.8095 - LR: 4.00e-05\n",
      "\tEpoch 70/100 - Train loss: 0.1444 - Val accuracy: 0.8571 - Val loss: 0.2459 - Val F1: 0.8095 - LR: 3.00e-05\n",
      "\tEpoch 80/100 - Train loss: 0.1330 - Val accuracy: 1.0000 - Val loss: 0.2328 - Val F1: 1.0000 - LR: 2.00e-05\n",
      "\tEpoch 90/100 - Train loss: 0.1303 - Val accuracy: 1.0000 - Val loss: 0.2269 - Val F1: 1.0000 - LR: 1.00e-05\n",
      "\tEpoch 100/100 - Train loss: 0.1250 - Val accuracy: 1.0000 - Val loss: 0.2248 - Val F1: 1.0000 - LR: 0.00e+00\n",
      "\tBest epoch: 100 - Best val accuracy: 1.0000 - Best val loss: 0.2248 - Best val F1: 1.0000\n",
      "\n",
      "\tEpoch 10/100 - Train loss: 0.5704 - Val accuracy: 0.7143 - Val loss: 1.0519 - Val F1: 0.5952 - LR: 9.00e-05\n",
      "\tEpoch 20/100 - Train loss: 0.3640 - Val accuracy: 0.2857 - Val loss: 1.0982 - Val F1: 0.2789 - LR: 8.00e-05\n",
      "\tEpoch 30/100 - Train loss: 0.2521 - Val accuracy: 0.1429 - Val loss: 1.1923 - Val F1: 0.0357 - LR: 7.00e-05\n",
      "\tEpoch 40/100 - Train loss: 0.1989 - Val accuracy: 0.2857 - Val loss: 1.0273 - Val F1: 0.2857 - LR: 6.00e-05\n",
      "\tEpoch 50/100 - Train loss: 0.1525 - Val accuracy: 0.7143 - Val loss: 0.5268 - Val F1: 0.7143 - LR: 5.00e-05\n",
      "\tEpoch 60/100 - Train loss: 0.1464 - Val accuracy: 0.8571 - Val loss: 0.3079 - Val F1: 0.8095 - LR: 4.00e-05\n",
      "\tEpoch 70/100 - Train loss: 0.1283 - Val accuracy: 0.8571 - Val loss: 0.2605 - Val F1: 0.8095 - LR: 3.00e-05\n",
      "\tEpoch 80/100 - Train loss: 0.1151 - Val accuracy: 0.8571 - Val loss: 0.2463 - Val F1: 0.8095 - LR: 2.00e-05\n",
      "\tEpoch 90/100 - Train loss: 0.1029 - Val accuracy: 1.0000 - Val loss: 0.2400 - Val F1: 1.0000 - LR: 1.00e-05\n",
      "\tEpoch 100/100 - Train loss: 0.1035 - Val accuracy: 1.0000 - Val loss: 0.2371 - Val F1: 1.0000 - LR: 0.00e+00\n",
      "\tBest epoch: 100 - Best val accuracy: 1.0000 - Best val loss: 0.2371 - Best val F1: 1.0000\n",
      "\n",
      "Source class: WAL | Domain: 70 | Accuracy: 0.8861 | Loss: 0.3082 | F1: 0.8861\n",
      "\n",
      "Domain: 71\n",
      "x_dp_dom.shape: (44, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Training and evaluating on Dp data via cross-validation...\n",
      "\tEpoch 10/100 - Train loss: 0.6294 - Val accuracy: 0.5714 - Val loss: 1.0799 - Val F1: 0.4156 - LR: 9.00e-05\n",
      "\tEpoch 20/100 - Train loss: 0.4074 - Val accuracy: 0.1429 - Val loss: 1.0929 - Val F1: 0.0357 - LR: 8.00e-05\n",
      "\tEpoch 30/100 - Train loss: 0.2597 - Val accuracy: 0.2857 - Val loss: 1.1859 - Val F1: 0.2313 - LR: 7.00e-05\n",
      "\tEpoch 40/100 - Train loss: 0.1740 - Val accuracy: 0.4286 - Val loss: 1.1545 - Val F1: 0.2857 - LR: 6.00e-05\n",
      "\tEpoch 50/100 - Train loss: 0.1242 - Val accuracy: 0.7143 - Val loss: 0.7386 - Val F1: 0.7048 - LR: 5.00e-05\n",
      "\tEpoch 60/100 - Train loss: 0.0977 - Val accuracy: 1.0000 - Val loss: 0.3325 - Val F1: 1.0000 - LR: 4.00e-05\n",
      "\tEpoch 70/100 - Train loss: 0.0790 - Val accuracy: 1.0000 - Val loss: 0.2396 - Val F1: 1.0000 - LR: 3.00e-05\n",
      "\tEpoch 80/100 - Train loss: 0.0751 - Val accuracy: 0.8571 - Val loss: 0.2317 - Val F1: 0.7937 - LR: 2.00e-05\n",
      "\tEpoch 90/100 - Train loss: 0.0663 - Val accuracy: 0.8571 - Val loss: 0.2321 - Val F1: 0.7937 - LR: 1.00e-05\n",
      "\tEpoch 100/100 - Train loss: 0.0603 - Val accuracy: 0.8571 - Val loss: 0.2336 - Val F1: 0.7937 - LR: 0.00e+00\n",
      "\tBest epoch: 82 - Best val accuracy: 0.8571 - Best val loss: 0.2317 - Best val F1: 0.7937\n",
      "\n",
      "\tEpoch 10/100 - Train loss: 0.5557 - Val accuracy: 0.5714 - Val loss: 1.0524 - Val F1: 0.4156 - LR: 9.00e-05\n",
      "\tEpoch 20/100 - Train loss: 0.3573 - Val accuracy: 0.2857 - Val loss: 1.0648 - Val F1: 0.1270 - LR: 8.00e-05\n",
      "\tEpoch 30/100 - Train loss: 0.2589 - Val accuracy: 0.2857 - Val loss: 1.0925 - Val F1: 0.1429 - LR: 7.00e-05\n",
      "\tEpoch 40/100 - Train loss: 0.1719 - Val accuracy: 0.4286 - Val loss: 0.9771 - Val F1: 0.3333 - LR: 6.00e-05\n",
      "\tEpoch 50/100 - Train loss: 0.1236 - Val accuracy: 1.0000 - Val loss: 0.4992 - Val F1: 1.0000 - LR: 5.00e-05\n",
      "\tEpoch 60/100 - Train loss: 0.1147 - Val accuracy: 1.0000 - Val loss: 0.2031 - Val F1: 1.0000 - LR: 4.00e-05\n",
      "\tEpoch 70/100 - Train loss: 0.0740 - Val accuracy: 1.0000 - Val loss: 0.1349 - Val F1: 1.0000 - LR: 3.00e-05\n",
      "\tEpoch 80/100 - Train loss: 0.0666 - Val accuracy: 1.0000 - Val loss: 0.1168 - Val F1: 1.0000 - LR: 2.00e-05\n",
      "\tEpoch 90/100 - Train loss: 0.0595 - Val accuracy: 1.0000 - Val loss: 0.1097 - Val F1: 1.0000 - LR: 1.00e-05\n",
      "\tEpoch 100/100 - Train loss: 0.0580 - Val accuracy: 1.0000 - Val loss: 0.1075 - Val F1: 1.0000 - LR: 0.00e+00\n",
      "\tBest epoch: 100 - Best val accuracy: 1.0000 - Best val loss: 0.1075 - Best val F1: 1.0000\n",
      "\n",
      "\tEpoch 10/100 - Train loss: 0.6404 - Val accuracy: 0.5714 - Val loss: 1.0678 - Val F1: 0.4156 - LR: 9.00e-05\n",
      "\tEpoch 20/100 - Train loss: 0.4520 - Val accuracy: 0.5714 - Val loss: 1.0743 - Val F1: 0.4156 - LR: 8.00e-05\n",
      "\tEpoch 30/100 - Train loss: 0.3183 - Val accuracy: 0.2857 - Val loss: 1.1082 - Val F1: 0.1429 - LR: 7.00e-05\n",
      "\tEpoch 40/100 - Train loss: 0.2204 - Val accuracy: 0.5714 - Val loss: 1.0173 - Val F1: 0.5143 - LR: 6.00e-05\n",
      "\tEpoch 50/100 - Train loss: 0.1680 - Val accuracy: 1.0000 - Val loss: 0.5944 - Val F1: 1.0000 - LR: 5.00e-05\n",
      "\tEpoch 60/100 - Train loss: 0.1368 - Val accuracy: 1.0000 - Val loss: 0.3119 - Val F1: 1.0000 - LR: 4.00e-05\n",
      "\tEpoch 70/100 - Train loss: 0.1097 - Val accuracy: 1.0000 - Val loss: 0.2460 - Val F1: 1.0000 - LR: 3.00e-05\n",
      "\tEpoch 80/100 - Train loss: 0.1066 - Val accuracy: 1.0000 - Val loss: 0.2279 - Val F1: 1.0000 - LR: 2.00e-05\n",
      "\tEpoch 90/100 - Train loss: 0.0880 - Val accuracy: 1.0000 - Val loss: 0.2196 - Val F1: 1.0000 - LR: 1.00e-05\n",
      "\tEpoch 100/100 - Train loss: 0.0869 - Val accuracy: 0.8571 - Val loss: 0.2168 - Val F1: 0.7937 - LR: 0.00e+00\n",
      "\tBest epoch: 100 - Best val accuracy: 0.8571 - Best val loss: 0.2168 - Best val F1: 0.7937\n",
      "\n",
      "\tEpoch 10/100 - Train loss: 0.5576 - Val accuracy: 0.7143 - Val loss: 1.0348 - Val F1: 0.5952 - LR: 9.00e-05\n",
      "\tEpoch 20/100 - Train loss: 0.3279 - Val accuracy: 0.1429 - Val loss: 1.1080 - Val F1: 0.0357 - LR: 8.00e-05\n",
      "\tEpoch 30/100 - Train loss: 0.1836 - Val accuracy: 0.2857 - Val loss: 1.2684 - Val F1: 0.1429 - LR: 7.00e-05\n",
      "\tEpoch 40/100 - Train loss: 0.1146 - Val accuracy: 0.2857 - Val loss: 1.1696 - Val F1: 0.1286 - LR: 6.00e-05\n",
      "\tEpoch 50/100 - Train loss: 0.0795 - Val accuracy: 1.0000 - Val loss: 0.5904 - Val F1: 1.0000 - LR: 5.00e-05\n",
      "\tEpoch 60/100 - Train loss: 0.0617 - Val accuracy: 1.0000 - Val loss: 0.1975 - Val F1: 1.0000 - LR: 4.00e-05\n",
      "\tEpoch 70/100 - Train loss: 0.0512 - Val accuracy: 1.0000 - Val loss: 0.1221 - Val F1: 1.0000 - LR: 3.00e-05\n",
      "\tEpoch 80/100 - Train loss: 0.0449 - Val accuracy: 1.0000 - Val loss: 0.1088 - Val F1: 1.0000 - LR: 2.00e-05\n",
      "\tEpoch 90/100 - Train loss: 0.0417 - Val accuracy: 1.0000 - Val loss: 0.1058 - Val F1: 1.0000 - LR: 1.00e-05\n",
      "\tEpoch 100/100 - Train loss: 0.0393 - Val accuracy: 1.0000 - Val loss: 0.1051 - Val F1: 1.0000 - LR: 0.00e+00\n",
      "\tBest epoch: 99 - Best val accuracy: 1.0000 - Best val loss: 0.1051 - Best val F1: 1.0000\n",
      "\n",
      "\tEpoch 10/100 - Train loss: 0.5427 - Val accuracy: 0.6250 - Val loss: 1.0395 - Val F1: 0.4808 - LR: 9.00e-05\n",
      "\tEpoch 20/100 - Train loss: 0.3020 - Val accuracy: 0.2500 - Val loss: 1.1123 - Val F1: 0.1000 - LR: 8.00e-05\n",
      "\tEpoch 30/100 - Train loss: 0.1592 - Val accuracy: 0.2500 - Val loss: 1.2667 - Val F1: 0.1000 - LR: 7.00e-05\n",
      "\tEpoch 40/100 - Train loss: 0.1129 - Val accuracy: 0.2500 - Val loss: 1.0798 - Val F1: 0.1000 - LR: 6.00e-05\n",
      "\tEpoch 50/100 - Train loss: 0.0636 - Val accuracy: 0.8750 - Val loss: 0.4918 - Val F1: 0.8250 - LR: 5.00e-05\n",
      "\tEpoch 60/100 - Train loss: 0.0510 - Val accuracy: 0.8750 - Val loss: 0.2491 - Val F1: 0.8250 - LR: 4.00e-05\n",
      "\tEpoch 70/100 - Train loss: 0.0441 - Val accuracy: 0.8750 - Val loss: 0.1830 - Val F1: 0.8250 - LR: 3.00e-05\n",
      "\tEpoch 80/100 - Train loss: 0.0395 - Val accuracy: 1.0000 - Val loss: 0.1594 - Val F1: 1.0000 - LR: 2.00e-05\n",
      "\tEpoch 90/100 - Train loss: 0.0344 - Val accuracy: 1.0000 - Val loss: 0.1499 - Val F1: 1.0000 - LR: 1.00e-05\n",
      "\tEpoch 100/100 - Train loss: 0.0364 - Val accuracy: 1.0000 - Val loss: 0.1467 - Val F1: 1.0000 - LR: 0.00e+00\n",
      "\tBest epoch: 100 - Best val accuracy: 1.0000 - Best val loss: 0.1467 - Best val F1: 1.0000\n",
      "\n",
      "Source class: WAL | Domain: 71 | Accuracy: 0.9056 | Loss: 0.2112 | F1: 0.8730\n",
      "\n",
      "Domain: 72\n",
      "x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Training and evaluating on Dp data via cross-validation...\n",
      "\tEpoch 10/100 - Train loss: 0.6310 - Val accuracy: 0.7143 - Val loss: 1.0662 - Val F1: 0.5952 - LR: 9.00e-05\n",
      "\tEpoch 20/100 - Train loss: 0.4043 - Val accuracy: 0.1429 - Val loss: 1.1299 - Val F1: 0.0357 - LR: 8.00e-05\n",
      "\tEpoch 30/100 - Train loss: 0.2614 - Val accuracy: 0.1429 - Val loss: 1.3355 - Val F1: 0.0357 - LR: 7.00e-05\n",
      "\tEpoch 40/100 - Train loss: 0.1937 - Val accuracy: 0.1429 - Val loss: 1.4797 - Val F1: 0.0357 - LR: 6.00e-05\n",
      "\tEpoch 50/100 - Train loss: 0.1642 - Val accuracy: 0.2857 - Val loss: 1.0344 - Val F1: 0.2789 - LR: 5.00e-05\n",
      "\tEpoch 60/100 - Train loss: 0.1082 - Val accuracy: 0.8571 - Val loss: 0.4508 - Val F1: 0.8095 - LR: 4.00e-05\n",
      "\tEpoch 70/100 - Train loss: 0.0972 - Val accuracy: 0.8571 - Val loss: 0.2839 - Val F1: 0.8095 - LR: 3.00e-05\n",
      "\tEpoch 80/100 - Train loss: 0.0824 - Val accuracy: 0.8571 - Val loss: 0.2412 - Val F1: 0.8095 - LR: 2.00e-05\n",
      "\tEpoch 90/100 - Train loss: 0.0837 - Val accuracy: 0.8571 - Val loss: 0.2271 - Val F1: 0.8095 - LR: 1.00e-05\n",
      "\tEpoch 100/100 - Train loss: 0.0841 - Val accuracy: 0.8571 - Val loss: 0.2218 - Val F1: 0.8095 - LR: 0.00e+00\n",
      "\tBest epoch: 100 - Best val accuracy: 0.8571 - Best val loss: 0.2218 - Best val F1: 0.8095\n",
      "\n",
      "\tEpoch 10/100 - Train loss: 0.5674 - Val accuracy: 0.1429 - Val loss: 1.0942 - Val F1: 0.0357 - LR: 9.00e-05\n",
      "\tEpoch 20/100 - Train loss: 0.3421 - Val accuracy: 0.1429 - Val loss: 1.1828 - Val F1: 0.0357 - LR: 8.00e-05\n",
      "\tEpoch 30/100 - Train loss: 0.2269 - Val accuracy: 0.1429 - Val loss: 1.3859 - Val F1: 0.0357 - LR: 7.00e-05\n",
      "\tEpoch 40/100 - Train loss: 0.1737 - Val accuracy: 0.1429 - Val loss: 1.3053 - Val F1: 0.0408 - LR: 6.00e-05\n",
      "\tEpoch 50/100 - Train loss: 0.1443 - Val accuracy: 1.0000 - Val loss: 0.6202 - Val F1: 1.0000 - LR: 5.00e-05\n",
      "\tEpoch 60/100 - Train loss: 0.1176 - Val accuracy: 1.0000 - Val loss: 0.2541 - Val F1: 1.0000 - LR: 4.00e-05\n",
      "\tEpoch 70/100 - Train loss: 0.0840 - Val accuracy: 1.0000 - Val loss: 0.1659 - Val F1: 1.0000 - LR: 3.00e-05\n",
      "\tEpoch 80/100 - Train loss: 0.0796 - Val accuracy: 1.0000 - Val loss: 0.1389 - Val F1: 1.0000 - LR: 2.00e-05\n",
      "\tEpoch 90/100 - Train loss: 0.0781 - Val accuracy: 1.0000 - Val loss: 0.1278 - Val F1: 1.0000 - LR: 1.00e-05\n",
      "\tEpoch 100/100 - Train loss: 0.0680 - Val accuracy: 1.0000 - Val loss: 0.1235 - Val F1: 1.0000 - LR: 0.00e+00\n",
      "\tBest epoch: 100 - Best val accuracy: 1.0000 - Best val loss: 0.1235 - Best val F1: 1.0000\n",
      "\n",
      "\tEpoch 10/100 - Train loss: 0.5170 - Val accuracy: 0.1429 - Val loss: 1.1346 - Val F1: 0.0357 - LR: 9.00e-05\n",
      "\tEpoch 20/100 - Train loss: 0.2962 - Val accuracy: 0.1429 - Val loss: 1.4089 - Val F1: 0.0357 - LR: 8.00e-05\n",
      "\tEpoch 30/100 - Train loss: 0.2194 - Val accuracy: 0.1429 - Val loss: 1.7282 - Val F1: 0.0357 - LR: 7.00e-05\n",
      "\tEpoch 40/100 - Train loss: 0.1697 - Val accuracy: 0.1429 - Val loss: 1.6488 - Val F1: 0.0357 - LR: 6.00e-05\n",
      "\tEpoch 50/100 - Train loss: 0.1216 - Val accuracy: 1.0000 - Val loss: 0.7442 - Val F1: 1.0000 - LR: 5.00e-05\n",
      "\tEpoch 60/100 - Train loss: 0.1013 - Val accuracy: 1.0000 - Val loss: 0.2347 - Val F1: 1.0000 - LR: 4.00e-05\n",
      "\tEpoch 70/100 - Train loss: 0.0860 - Val accuracy: 1.0000 - Val loss: 0.1441 - Val F1: 1.0000 - LR: 3.00e-05\n",
      "\tEpoch 80/100 - Train loss: 0.0642 - Val accuracy: 1.0000 - Val loss: 0.1189 - Val F1: 1.0000 - LR: 2.00e-05\n",
      "\tEpoch 90/100 - Train loss: 0.0617 - Val accuracy: 1.0000 - Val loss: 0.1094 - Val F1: 1.0000 - LR: 1.00e-05\n",
      "\tEpoch 100/100 - Train loss: 0.0548 - Val accuracy: 1.0000 - Val loss: 0.1059 - Val F1: 1.0000 - LR: 0.00e+00\n",
      "\tBest epoch: 100 - Best val accuracy: 1.0000 - Best val loss: 0.1059 - Best val F1: 1.0000\n",
      "\n",
      "\tEpoch 10/100 - Train loss: 0.4487 - Val accuracy: 0.7143 - Val loss: 1.0672 - Val F1: 0.5952 - LR: 9.00e-05\n",
      "\tEpoch 20/100 - Train loss: 0.2542 - Val accuracy: 0.1429 - Val loss: 1.2809 - Val F1: 0.0357 - LR: 8.00e-05\n",
      "\tEpoch 30/100 - Train loss: 0.1838 - Val accuracy: 0.1429 - Val loss: 1.5591 - Val F1: 0.0357 - LR: 7.00e-05\n",
      "\tEpoch 40/100 - Train loss: 0.1318 - Val accuracy: 0.1429 - Val loss: 1.4989 - Val F1: 0.0357 - LR: 6.00e-05\n",
      "\tEpoch 50/100 - Train loss: 0.0922 - Val accuracy: 0.7143 - Val loss: 0.6928 - Val F1: 0.7063 - LR: 5.00e-05\n",
      "\tEpoch 60/100 - Train loss: 0.0751 - Val accuracy: 0.8571 - Val loss: 0.2714 - Val F1: 0.8095 - LR: 4.00e-05\n",
      "\tEpoch 70/100 - Train loss: 0.0580 - Val accuracy: 1.0000 - Val loss: 0.1887 - Val F1: 1.0000 - LR: 3.00e-05\n",
      "\tEpoch 80/100 - Train loss: 0.0504 - Val accuracy: 1.0000 - Val loss: 0.1654 - Val F1: 1.0000 - LR: 2.00e-05\n",
      "\tEpoch 90/100 - Train loss: 0.0459 - Val accuracy: 1.0000 - Val loss: 0.1562 - Val F1: 1.0000 - LR: 1.00e-05\n",
      "\tEpoch 100/100 - Train loss: 0.0430 - Val accuracy: 1.0000 - Val loss: 0.1530 - Val F1: 1.0000 - LR: 0.00e+00\n",
      "\tBest epoch: 100 - Best val accuracy: 1.0000 - Best val loss: 0.1530 - Best val F1: 1.0000\n",
      "\n",
      "\tEpoch 10/100 - Train loss: 0.4752 - Val accuracy: 0.7143 - Val loss: 1.0262 - Val F1: 0.5952 - LR: 9.00e-05\n",
      "\tEpoch 20/100 - Train loss: 0.2814 - Val accuracy: 0.1429 - Val loss: 1.0963 - Val F1: 0.0357 - LR: 8.00e-05\n",
      "\tEpoch 30/100 - Train loss: 0.1836 - Val accuracy: 0.1429 - Val loss: 1.2501 - Val F1: 0.0357 - LR: 7.00e-05\n",
      "\tEpoch 40/100 - Train loss: 0.1262 - Val accuracy: 0.2857 - Val loss: 1.0077 - Val F1: 0.2789 - LR: 6.00e-05\n",
      "\tEpoch 50/100 - Train loss: 0.0951 - Val accuracy: 0.8571 - Val loss: 0.3736 - Val F1: 0.8095 - LR: 5.00e-05\n",
      "\tEpoch 60/100 - Train loss: 0.0758 - Val accuracy: 0.8571 - Val loss: 0.2088 - Val F1: 0.8095 - LR: 4.00e-05\n",
      "\tEpoch 70/100 - Train loss: 0.0552 - Val accuracy: 1.0000 - Val loss: 0.1682 - Val F1: 1.0000 - LR: 3.00e-05\n",
      "\tEpoch 80/100 - Train loss: 0.0506 - Val accuracy: 1.0000 - Val loss: 0.1518 - Val F1: 1.0000 - LR: 2.00e-05\n",
      "\tEpoch 90/100 - Train loss: 0.0483 - Val accuracy: 1.0000 - Val loss: 0.1441 - Val F1: 1.0000 - LR: 1.00e-05\n",
      "\tEpoch 100/100 - Train loss: 0.0489 - Val accuracy: 1.0000 - Val loss: 0.1414 - Val F1: 1.0000 - LR: 0.00e+00\n",
      "\tBest epoch: 100 - Best val accuracy: 1.0000 - Best val loss: 0.1414 - Best val F1: 1.0000\n",
      "\n",
      "Source class: WAL | Domain: 72 | Accuracy: 0.9083 | Loss: 0.2261 | F1: 0.8872\n",
      "\n",
      "Domain: 73\n",
      "x_dp_dom.shape: (41, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Training and evaluating on Dp data via cross-validation...\n",
      "\tEpoch 10/100 - Train loss: 0.5141 - Val accuracy: 0.7143 - Val loss: 1.0707 - Val F1: 0.5952 - LR: 9.00e-05\n",
      "\tEpoch 20/100 - Train loss: 0.3166 - Val accuracy: 0.1429 - Val loss: 1.2125 - Val F1: 0.0357 - LR: 8.00e-05\n",
      "\tEpoch 30/100 - Train loss: 0.2039 - Val accuracy: 0.1429 - Val loss: 1.4735 - Val F1: 0.0357 - LR: 7.00e-05\n",
      "\tEpoch 40/100 - Train loss: 0.1548 - Val accuracy: 0.1429 - Val loss: 1.5261 - Val F1: 0.0571 - LR: 6.00e-05\n",
      "\tEpoch 50/100 - Train loss: 0.1168 - Val accuracy: 0.5714 - Val loss: 0.9622 - Val F1: 0.6071 - LR: 5.00e-05\n",
      "\tEpoch 60/100 - Train loss: 0.0889 - Val accuracy: 0.8571 - Val loss: 0.4152 - Val F1: 0.8095 - LR: 4.00e-05\n",
      "\tEpoch 70/100 - Train loss: 0.0820 - Val accuracy: 1.0000 - Val loss: 0.2538 - Val F1: 1.0000 - LR: 3.00e-05\n",
      "\tEpoch 80/100 - Train loss: 0.0598 - Val accuracy: 1.0000 - Val loss: 0.2179 - Val F1: 1.0000 - LR: 2.00e-05\n",
      "\tEpoch 90/100 - Train loss: 0.0564 - Val accuracy: 1.0000 - Val loss: 0.2092 - Val F1: 1.0000 - LR: 1.00e-05\n",
      "\tEpoch 100/100 - Train loss: 0.0601 - Val accuracy: 1.0000 - Val loss: 0.2071 - Val F1: 1.0000 - LR: 0.00e+00\n",
      "\tBest epoch: 100 - Best val accuracy: 1.0000 - Best val loss: 0.2071 - Best val F1: 1.0000\n",
      "\n",
      "\tEpoch 10/100 - Train loss: 0.5959 - Val accuracy: 0.2857 - Val loss: 1.1080 - Val F1: 0.1286 - LR: 9.00e-05\n",
      "\tEpoch 20/100 - Train loss: 0.3738 - Val accuracy: 0.1429 - Val loss: 1.1632 - Val F1: 0.0357 - LR: 8.00e-05\n",
      "\tEpoch 30/100 - Train loss: 0.2738 - Val accuracy: 0.1429 - Val loss: 1.3030 - Val F1: 0.0357 - LR: 7.00e-05\n",
      "\tEpoch 40/100 - Train loss: 0.1862 - Val accuracy: 0.1429 - Val loss: 1.3089 - Val F1: 0.0571 - LR: 6.00e-05\n",
      "\tEpoch 50/100 - Train loss: 0.1513 - Val accuracy: 0.7143 - Val loss: 0.8691 - Val F1: 0.7500 - LR: 5.00e-05\n",
      "\tEpoch 60/100 - Train loss: 0.1183 - Val accuracy: 0.8571 - Val loss: 0.4776 - Val F1: 0.8095 - LR: 4.00e-05\n",
      "\tEpoch 70/100 - Train loss: 0.0950 - Val accuracy: 0.8571 - Val loss: 0.3555 - Val F1: 0.8095 - LR: 3.00e-05\n",
      "\tEpoch 80/100 - Train loss: 0.0828 - Val accuracy: 0.8571 - Val loss: 0.3189 - Val F1: 0.8095 - LR: 2.00e-05\n",
      "\tEpoch 90/100 - Train loss: 0.0808 - Val accuracy: 0.8571 - Val loss: 0.3054 - Val F1: 0.8095 - LR: 1.00e-05\n",
      "\tEpoch 100/100 - Train loss: 0.0790 - Val accuracy: 0.8571 - Val loss: 0.3006 - Val F1: 0.8095 - LR: 0.00e+00\n",
      "\tBest epoch: 100 - Best val accuracy: 0.8571 - Best val loss: 0.3006 - Best val F1: 0.8095\n",
      "\n",
      "\tEpoch 10/100 - Train loss: 0.6238 - Val accuracy: 0.7143 - Val loss: 1.0507 - Val F1: 0.5952 - LR: 9.00e-05\n",
      "\tEpoch 20/100 - Train loss: 0.4178 - Val accuracy: 0.1429 - Val loss: 1.1494 - Val F1: 0.0357 - LR: 8.00e-05\n",
      "\tEpoch 30/100 - Train loss: 0.2722 - Val accuracy: 0.1429 - Val loss: 1.4014 - Val F1: 0.0571 - LR: 7.00e-05\n",
      "\tEpoch 40/100 - Train loss: 0.1864 - Val accuracy: 0.1429 - Val loss: 1.5213 - Val F1: 0.0714 - LR: 6.00e-05\n",
      "\tEpoch 50/100 - Train loss: 0.1301 - Val accuracy: 0.4286 - Val loss: 1.0480 - Val F1: 0.3905 - LR: 5.00e-05\n",
      "\tEpoch 60/100 - Train loss: 0.0966 - Val accuracy: 1.0000 - Val loss: 0.4324 - Val F1: 1.0000 - LR: 4.00e-05\n",
      "\tEpoch 70/100 - Train loss: 0.1028 - Val accuracy: 1.0000 - Val loss: 0.2299 - Val F1: 1.0000 - LR: 3.00e-05\n",
      "\tEpoch 80/100 - Train loss: 0.0683 - Val accuracy: 1.0000 - Val loss: 0.1797 - Val F1: 1.0000 - LR: 2.00e-05\n",
      "\tEpoch 90/100 - Train loss: 0.0686 - Val accuracy: 1.0000 - Val loss: 0.1633 - Val F1: 1.0000 - LR: 1.00e-05\n",
      "\tEpoch 100/100 - Train loss: 0.0665 - Val accuracy: 1.0000 - Val loss: 0.1576 - Val F1: 1.0000 - LR: 0.00e+00\n",
      "\tBest epoch: 100 - Best val accuracy: 1.0000 - Best val loss: 0.1576 - Best val F1: 1.0000\n",
      "\n",
      "\tEpoch 10/100 - Train loss: 0.5362 - Val accuracy: 0.7143 - Val loss: 1.0414 - Val F1: 0.5952 - LR: 9.00e-05\n",
      "\tEpoch 20/100 - Train loss: 0.3215 - Val accuracy: 0.1429 - Val loss: 1.1177 - Val F1: 0.0357 - LR: 8.00e-05\n",
      "\tEpoch 30/100 - Train loss: 0.1994 - Val accuracy: 0.1429 - Val loss: 1.3093 - Val F1: 0.0357 - LR: 7.00e-05\n",
      "\tEpoch 40/100 - Train loss: 0.1254 - Val accuracy: 0.1429 - Val loss: 1.2760 - Val F1: 0.0357 - LR: 6.00e-05\n",
      "\tEpoch 50/100 - Train loss: 0.1028 - Val accuracy: 0.7143 - Val loss: 0.7149 - Val F1: 0.7063 - LR: 5.00e-05\n",
      "\tEpoch 60/100 - Train loss: 0.0767 - Val accuracy: 0.8571 - Val loss: 0.3170 - Val F1: 0.8095 - LR: 4.00e-05\n",
      "\tEpoch 70/100 - Train loss: 0.0649 - Val accuracy: 0.8571 - Val loss: 0.2337 - Val F1: 0.8095 - LR: 3.00e-05\n",
      "\tEpoch 80/100 - Train loss: 0.0614 - Val accuracy: 1.0000 - Val loss: 0.2146 - Val F1: 1.0000 - LR: 2.00e-05\n",
      "\tEpoch 90/100 - Train loss: 0.0507 - Val accuracy: 1.0000 - Val loss: 0.2076 - Val F1: 1.0000 - LR: 1.00e-05\n",
      "\tEpoch 100/100 - Train loss: 0.0409 - Val accuracy: 1.0000 - Val loss: 0.2053 - Val F1: 1.0000 - LR: 0.00e+00\n",
      "\tBest epoch: 100 - Best val accuracy: 1.0000 - Best val loss: 0.2053 - Best val F1: 1.0000\n",
      "\n",
      "\tEpoch 10/100 - Train loss: 0.5962 - Val accuracy: 0.7143 - Val loss: 1.0568 - Val F1: 0.7063 - LR: 9.00e-05\n",
      "\tEpoch 20/100 - Train loss: 0.4179 - Val accuracy: 0.1429 - Val loss: 1.0680 - Val F1: 0.0357 - LR: 8.00e-05\n",
      "\tEpoch 30/100 - Train loss: 0.2943 - Val accuracy: 0.1429 - Val loss: 1.1239 - Val F1: 0.0357 - LR: 7.00e-05\n",
      "\tEpoch 40/100 - Train loss: 0.2286 - Val accuracy: 0.4286 - Val loss: 0.9747 - Val F1: 0.4653 - LR: 6.00e-05\n",
      "\tEpoch 50/100 - Train loss: 0.1978 - Val accuracy: 0.8571 - Val loss: 0.5062 - Val F1: 0.8095 - LR: 5.00e-05\n",
      "\tEpoch 60/100 - Train loss: 0.1499 - Val accuracy: 0.8571 - Val loss: 0.2922 - Val F1: 0.8095 - LR: 4.00e-05\n",
      "\tEpoch 70/100 - Train loss: 0.1279 - Val accuracy: 0.8571 - Val loss: 0.2299 - Val F1: 0.8095 - LR: 3.00e-05\n",
      "\tEpoch 80/100 - Train loss: 0.1149 - Val accuracy: 0.8571 - Val loss: 0.2074 - Val F1: 0.8095 - LR: 2.00e-05\n",
      "\tEpoch 90/100 - Train loss: 0.0975 - Val accuracy: 0.8571 - Val loss: 0.1979 - Val F1: 0.8095 - LR: 1.00e-05\n",
      "\tEpoch 100/100 - Train loss: 0.1037 - Val accuracy: 0.8571 - Val loss: 0.1942 - Val F1: 0.8095 - LR: 0.00e+00\n",
      "\tBest epoch: 100 - Best val accuracy: 0.8571 - Best val loss: 0.1942 - Best val F1: 0.8095\n",
      "\n",
      "Source class: WAL | Domain: 73 | Accuracy: 0.8778 | Loss: 0.3028 | F1: 0.8541\n",
      "\n",
      "Domain: 74\n",
      "Domain: 75\n",
      "x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Training and evaluating on Dp data via cross-validation...\n",
      "\tEpoch 10/100 - Train loss: 0.4688 - Val accuracy: 0.7143 - Val loss: 1.0686 - Val F1: 0.5952 - LR: 9.00e-05\n",
      "\tEpoch 20/100 - Train loss: 0.2997 - Val accuracy: 0.1429 - Val loss: 1.1578 - Val F1: 0.0357 - LR: 8.00e-05\n",
      "\tEpoch 30/100 - Train loss: 0.2088 - Val accuracy: 0.1429 - Val loss: 1.3364 - Val F1: 0.0357 - LR: 7.00e-05\n",
      "\tEpoch 40/100 - Train loss: 0.1506 - Val accuracy: 0.1429 - Val loss: 1.3891 - Val F1: 0.0357 - LR: 6.00e-05\n",
      "\tEpoch 50/100 - Train loss: 0.1130 - Val accuracy: 0.5714 - Val loss: 0.9437 - Val F1: 0.5929 - LR: 5.00e-05\n",
      "\tEpoch 60/100 - Train loss: 0.0850 - Val accuracy: 0.8571 - Val loss: 0.4242 - Val F1: 0.8730 - LR: 4.00e-05\n",
      "\tEpoch 70/100 - Train loss: 0.0695 - Val accuracy: 0.8571 - Val loss: 0.2343 - Val F1: 0.8730 - LR: 3.00e-05\n",
      "\tEpoch 80/100 - Train loss: 0.0598 - Val accuracy: 1.0000 - Val loss: 0.1581 - Val F1: 1.0000 - LR: 2.00e-05\n",
      "\tEpoch 90/100 - Train loss: 0.0524 - Val accuracy: 1.0000 - Val loss: 0.1302 - Val F1: 1.0000 - LR: 1.00e-05\n",
      "\tEpoch 100/100 - Train loss: 0.0565 - Val accuracy: 1.0000 - Val loss: 0.1207 - Val F1: 1.0000 - LR: 0.00e+00\n",
      "\tBest epoch: 100 - Best val accuracy: 1.0000 - Best val loss: 0.1207 - Best val F1: 1.0000\n",
      "\n",
      "\tEpoch 10/100 - Train loss: 0.5561 - Val accuracy: 0.7143 - Val loss: 1.0738 - Val F1: 0.5952 - LR: 9.00e-05\n",
      "\tEpoch 20/100 - Train loss: 0.3317 - Val accuracy: 0.1429 - Val loss: 1.2138 - Val F1: 0.0357 - LR: 8.00e-05\n",
      "\tEpoch 30/100 - Train loss: 0.2213 - Val accuracy: 0.1429 - Val loss: 1.4942 - Val F1: 0.0357 - LR: 7.00e-05\n",
      "\tEpoch 40/100 - Train loss: 0.1868 - Val accuracy: 0.1429 - Val loss: 1.4699 - Val F1: 0.0357 - LR: 6.00e-05\n",
      "\tEpoch 50/100 - Train loss: 0.1258 - Val accuracy: 0.7143 - Val loss: 0.7221 - Val F1: 0.7063 - LR: 5.00e-05\n",
      "\tEpoch 60/100 - Train loss: 0.1097 - Val accuracy: 0.8571 - Val loss: 0.3350 - Val F1: 0.8095 - LR: 4.00e-05\n",
      "\tEpoch 70/100 - Train loss: 0.0867 - Val accuracy: 0.8571 - Val loss: 0.2463 - Val F1: 0.8095 - LR: 3.00e-05\n",
      "\tEpoch 80/100 - Train loss: 0.0751 - Val accuracy: 0.8571 - Val loss: 0.2241 - Val F1: 0.8095 - LR: 2.00e-05\n",
      "\tEpoch 90/100 - Train loss: 0.0747 - Val accuracy: 1.0000 - Val loss: 0.2159 - Val F1: 1.0000 - LR: 1.00e-05\n",
      "\tEpoch 100/100 - Train loss: 0.0704 - Val accuracy: 1.0000 - Val loss: 0.2131 - Val F1: 1.0000 - LR: 0.00e+00\n",
      "\tBest epoch: 100 - Best val accuracy: 1.0000 - Best val loss: 0.2131 - Best val F1: 1.0000\n",
      "\n",
      "\tEpoch 10/100 - Train loss: 0.5920 - Val accuracy: 0.7143 - Val loss: 1.0804 - Val F1: 0.5952 - LR: 9.00e-05\n",
      "\tEpoch 20/100 - Train loss: 0.3527 - Val accuracy: 0.1429 - Val loss: 1.1358 - Val F1: 0.0357 - LR: 8.00e-05\n",
      "\tEpoch 30/100 - Train loss: 0.2182 - Val accuracy: 0.1429 - Val loss: 1.2713 - Val F1: 0.0357 - LR: 7.00e-05\n",
      "\tEpoch 40/100 - Train loss: 0.1461 - Val accuracy: 0.1429 - Val loss: 1.0477 - Val F1: 0.0357 - LR: 6.00e-05\n",
      "\tEpoch 50/100 - Train loss: 0.0967 - Val accuracy: 1.0000 - Val loss: 0.4065 - Val F1: 1.0000 - LR: 5.00e-05\n",
      "\tEpoch 60/100 - Train loss: 0.0725 - Val accuracy: 1.0000 - Val loss: 0.1293 - Val F1: 1.0000 - LR: 4.00e-05\n",
      "\tEpoch 70/100 - Train loss: 0.0607 - Val accuracy: 1.0000 - Val loss: 0.0670 - Val F1: 1.0000 - LR: 3.00e-05\n",
      "\tEpoch 80/100 - Train loss: 0.0455 - Val accuracy: 1.0000 - Val loss: 0.0508 - Val F1: 1.0000 - LR: 2.00e-05\n",
      "\tEpoch 90/100 - Train loss: 0.0458 - Val accuracy: 1.0000 - Val loss: 0.0455 - Val F1: 1.0000 - LR: 1.00e-05\n",
      "\tEpoch 100/100 - Train loss: 0.0466 - Val accuracy: 1.0000 - Val loss: 0.0437 - Val F1: 1.0000 - LR: 0.00e+00\n",
      "\tBest epoch: 100 - Best val accuracy: 1.0000 - Best val loss: 0.0437 - Best val F1: 1.0000\n",
      "\n",
      "\tEpoch 10/100 - Train loss: 0.5967 - Val accuracy: 0.7143 - Val loss: 1.0440 - Val F1: 0.5952 - LR: 9.00e-05\n",
      "\tEpoch 20/100 - Train loss: 0.3639 - Val accuracy: 0.1429 - Val loss: 1.1098 - Val F1: 0.0357 - LR: 8.00e-05\n",
      "\tEpoch 30/100 - Train loss: 0.2427 - Val accuracy: 0.1429 - Val loss: 1.2404 - Val F1: 0.0357 - LR: 7.00e-05\n",
      "\tEpoch 40/100 - Train loss: 0.1756 - Val accuracy: 0.2857 - Val loss: 1.1220 - Val F1: 0.1837 - LR: 6.00e-05\n",
      "\tEpoch 50/100 - Train loss: 0.1366 - Val accuracy: 1.0000 - Val loss: 0.4651 - Val F1: 1.0000 - LR: 5.00e-05\n",
      "\tEpoch 60/100 - Train loss: 0.1048 - Val accuracy: 1.0000 - Val loss: 0.1701 - Val F1: 1.0000 - LR: 4.00e-05\n",
      "\tEpoch 70/100 - Train loss: 0.0905 - Val accuracy: 1.0000 - Val loss: 0.1130 - Val F1: 1.0000 - LR: 3.00e-05\n",
      "\tEpoch 80/100 - Train loss: 0.0759 - Val accuracy: 1.0000 - Val loss: 0.0979 - Val F1: 1.0000 - LR: 2.00e-05\n",
      "\tEpoch 90/100 - Train loss: 0.0681 - Val accuracy: 1.0000 - Val loss: 0.0922 - Val F1: 1.0000 - LR: 1.00e-05\n",
      "\tEpoch 100/100 - Train loss: 0.0667 - Val accuracy: 1.0000 - Val loss: 0.0901 - Val F1: 1.0000 - LR: 0.00e+00\n",
      "\tBest epoch: 100 - Best val accuracy: 1.0000 - Best val loss: 0.0901 - Best val F1: 1.0000\n",
      "\n",
      "\tEpoch 10/100 - Train loss: 0.6176 - Val accuracy: 0.1429 - Val loss: 1.0996 - Val F1: 0.0357 - LR: 9.00e-05\n",
      "\tEpoch 20/100 - Train loss: 0.3692 - Val accuracy: 0.1429 - Val loss: 1.1538 - Val F1: 0.0357 - LR: 8.00e-05\n",
      "\tEpoch 30/100 - Train loss: 0.2650 - Val accuracy: 0.1429 - Val loss: 1.2981 - Val F1: 0.0357 - LR: 7.00e-05\n",
      "\tEpoch 40/100 - Train loss: 0.1975 - Val accuracy: 0.4286 - Val loss: 1.1447 - Val F1: 0.3905 - LR: 6.00e-05\n",
      "\tEpoch 50/100 - Train loss: 0.1495 - Val accuracy: 1.0000 - Val loss: 0.5442 - Val F1: 1.0000 - LR: 5.00e-05\n",
      "\tEpoch 60/100 - Train loss: 0.1285 - Val accuracy: 1.0000 - Val loss: 0.2648 - Val F1: 1.0000 - LR: 4.00e-05\n",
      "\tEpoch 70/100 - Train loss: 0.1062 - Val accuracy: 1.0000 - Val loss: 0.1934 - Val F1: 1.0000 - LR: 3.00e-05\n",
      "\tEpoch 80/100 - Train loss: 0.0967 - Val accuracy: 1.0000 - Val loss: 0.1721 - Val F1: 1.0000 - LR: 2.00e-05\n",
      "\tEpoch 90/100 - Train loss: 0.0881 - Val accuracy: 1.0000 - Val loss: 0.1636 - Val F1: 1.0000 - LR: 1.00e-05\n",
      "\tEpoch 100/100 - Train loss: 0.0781 - Val accuracy: 1.0000 - Val loss: 0.1606 - Val F1: 1.0000 - LR: 0.00e+00\n",
      "\tBest epoch: 100 - Best val accuracy: 1.0000 - Best val loss: 0.1606 - Best val F1: 1.0000\n",
      "\n",
      "Source class: WAL | Domain: 75 | Accuracy: 0.9528 | Loss: 0.1852 | F1: 0.9528\n",
      "\n",
      "Mean accuracy: 0.9058\n",
      "Mean F1: 0.8911\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def compute_TSTR_Dp(dataset):\n",
    "    accs = []\n",
    "    f1s = []\n",
    "\n",
    "    for src_class in config[dataset]['class_names']:\n",
    "        if src_class != 'WAL':\n",
    "            continue\n",
    "\n",
    "        print(f\"Source class: {src_class}\\n\")\n",
    "\n",
    "        for domain in range(config[dataset]['num_df_domains'], config[dataset]['num_df_domains'] + config[dataset]['num_dp_domains']):\n",
    "            print(f\"Domain: {domain}\")\n",
    "\n",
    "            if domain == 74:\n",
    "              continue\n",
    "\n",
    "            # Load Dp data\n",
    "            x_dp_dom, y_dp_dom, k_dp_dom = get_data(dataset, 'dp', src_class, domain)\n",
    "            print(f'x_dp_dom.shape: {x_dp_dom.shape} | np.unique(y_dp_dom): {np.unique(y_dp_dom)}\\n')\n",
    "\n",
    "            # Train and evaluate via cross-validation on Dp data\n",
    "            print('Training and evaluating on Dp data via cross-validation...')\n",
    "            acc, loss, f1 = train_classifier_cv(x_dp_dom, y_dp_dom, dataset, num_epochs=num_epochs)\n",
    "            save_scores(src_class, domain, acc, loss, f1, 'Dp', dataset)\n",
    "            accs.append(acc)\n",
    "            f1s.append(f1)\n",
    "            print(f'Source class: {src_class} | Domain: {domain} | Accuracy: {acc:.4f} | Loss: {loss:.4f} | F1: {f1:.4f}\\n')\n",
    "\n",
    "    print(f\"Mean accuracy: {np.mean(accs):.4f}\")\n",
    "    print(f\"Mean F1: {np.mean(f1s):.4f}\\n\")\n",
    "\n",
    "\n",
    "\n",
    "compute_TSTR_Dp('realworld_mobiact')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "executionInfo": {
     "elapsed": 160,
     "status": "ok",
     "timestamp": 1732616877145,
     "user": {
      "displayName": "Pietro Cirino",
      "userId": "07315473796200699505"
     },
     "user_tz": -60
    },
    "id": "M7S9IU2VVAmx"
   },
   "outputs": [],
   "source": [
    "def compute_TSTR_Dpc(dataset):\n",
    "\n",
    "    raise NotImplementedError\n",
    "\n",
    "\n",
    "\n",
    "# compute_TSTR_Dpc('realworld_mobiact')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 649082,
     "status": "ok",
     "timestamp": 1732617526071,
     "user": {
      "displayName": "Pietro Cirino",
      "userId": "07315473796200699505"
     },
     "user_tz": -60
    },
    "id": "zhTuwDtYCPto",
    "outputId": "4f54e129-d682-444c-f6ee-ba3c66c75f61"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source class: WAL\n",
      "\n",
      "x_df.shape: (7958, 3, 128) | np.unique(y_df): [1 2 3]\n",
      "\n",
      "Training on Df data...\n",
      "\tEpoch 10/100 - Train loss: 0.0314 - Val accuracy: 0.9812 - Val loss: 0.0523 - Val F1: 0.9811 - LR: 9.00e-05\n",
      "\tEpoch 20/100 - Train loss: 0.0095 - Val accuracy: 0.9887 - Val loss: 0.0342 - Val F1: 0.9887 - LR: 8.00e-05\n",
      "\tEpoch 30/100 - Train loss: 0.0040 - Val accuracy: 0.9906 - Val loss: 0.0311 - Val F1: 0.9906 - LR: 7.00e-05\n",
      "\tEpoch 40/100 - Train loss: 0.0037 - Val accuracy: 0.9899 - Val loss: 0.0344 - Val F1: 0.9900 - LR: 6.00e-05\n",
      "\tEpoch 50/100 - Train loss: 0.0012 - Val accuracy: 0.9899 - Val loss: 0.0359 - Val F1: 0.9899 - LR: 5.00e-05\n",
      "\tEpoch 60/100 - Train loss: 0.0006 - Val accuracy: 0.9912 - Val loss: 0.0384 - Val F1: 0.9912 - LR: 4.00e-05\n",
      "\tEpoch 70/100 - Train loss: 0.0005 - Val accuracy: 0.9899 - Val loss: 0.0397 - Val F1: 0.9899 - LR: 3.00e-05\n",
      "\tEpoch 80/100 - Train loss: 0.0004 - Val accuracy: 0.9925 - Val loss: 0.0378 - Val F1: 0.9925 - LR: 2.00e-05\n",
      "\tEpoch 90/100 - Train loss: 0.0002 - Val accuracy: 0.9931 - Val loss: 0.0341 - Val F1: 0.9931 - LR: 1.00e-05\n",
      "\tEpoch 100/100 - Train loss: 0.0002 - Val accuracy: 0.9912 - Val loss: 0.0385 - Val F1: 0.9912 - LR: 0.00e+00\n",
      "\tBest epoch: 28 - Best val accuracy: 0.9899 - Best val loss: 0.0288 - Best val F1: 0.9900\n",
      "\n",
      "Domain: 15\n",
      "x_dp_dom.shape: (50, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 15 | Accuracy: 0.5600 | Loss: 9.7000 | F1: 0.4752\n",
      "\n",
      "Domain: 16\n",
      "x_dp_dom.shape: (54, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 16 | Accuracy: 0.2407 | Loss: 22.0374 | F1: 0.0934\n",
      "\n",
      "Domain: 17\n",
      "x_dp_dom.shape: (53, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 17 | Accuracy: 0.2264 | Loss: 22.1112 | F1: 0.0836\n",
      "\n",
      "Domain: 18\n",
      "x_dp_dom.shape: (54, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 18 | Accuracy: 0.1852 | Loss: 19.7290 | F1: 0.0789\n",
      "\n",
      "Domain: 19\n",
      "x_dp_dom.shape: (54, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 19 | Accuracy: 0.2407 | Loss: 20.7649 | F1: 0.0934\n",
      "\n",
      "Domain: 20\n",
      "x_dp_dom.shape: (51, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 20 | Accuracy: 0.2353 | Loss: 15.5057 | F1: 0.1397\n",
      "\n",
      "Domain: 21\n",
      "x_dp_dom.shape: (47, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 21 | Accuracy: 0.1489 | Loss: 25.5207 | F1: 0.0386\n",
      "\n",
      "Domain: 22\n",
      "x_dp_dom.shape: (54, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 22 | Accuracy: 0.3704 | Loss: 17.9669 | F1: 0.3238\n",
      "\n",
      "Domain: 23\n",
      "x_dp_dom.shape: (52, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 23 | Accuracy: 0.2692 | Loss: 7.1293 | F1: 0.2319\n",
      "\n",
      "Domain: 24\n",
      "x_dp_dom.shape: (51, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 24 | Accuracy: 0.2745 | Loss: 13.4457 | F1: 0.1431\n",
      "\n",
      "Domain: 25\n",
      "x_dp_dom.shape: (54, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 25 | Accuracy: 0.2407 | Loss: 18.7229 | F1: 0.0948\n",
      "\n",
      "Domain: 26\n",
      "x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 26 | Accuracy: 0.1667 | Loss: 22.3551 | F1: 0.0476\n",
      "\n",
      "Domain: 27\n",
      "x_dp_dom.shape: (54, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 27 | Accuracy: 0.3704 | Loss: 11.0742 | F1: 0.2746\n",
      "\n",
      "Domain: 28\n",
      "x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 28 | Accuracy: 0.1667 | Loss: 28.7639 | F1: 0.0476\n",
      "\n",
      "Domain: 29\n",
      "x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 29 | Accuracy: 0.1667 | Loss: 22.2054 | F1: 0.0486\n",
      "\n",
      "Domain: 30\n",
      "x_dp_dom.shape: (50, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 30 | Accuracy: 0.1200 | Loss: 21.2847 | F1: 0.0498\n",
      "\n",
      "Domain: 31\n",
      "x_dp_dom.shape: (43, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 31 | Accuracy: 0.1395 | Loss: 22.8630 | F1: 0.0454\n",
      "\n",
      "Domain: 32\n",
      "x_dp_dom.shape: (52, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 32 | Accuracy: 0.2115 | Loss: 19.7725 | F1: 0.0751\n",
      "\n",
      "Domain: 33\n",
      "x_dp_dom.shape: (44, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 33 | Accuracy: 0.1591 | Loss: 26.8186 | F1: 0.0437\n",
      "\n",
      "Domain: 34\n",
      "x_dp_dom.shape: (49, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 34 | Accuracy: 0.3469 | Loss: 14.4679 | F1: 0.3152\n",
      "\n",
      "Domain: 35\n",
      "x_dp_dom.shape: (48, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 35 | Accuracy: 0.1458 | Loss: 22.1187 | F1: 0.0371\n",
      "\n",
      "Domain: 36\n",
      "x_dp_dom.shape: (43, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 36 | Accuracy: 0.1628 | Loss: 24.8529 | F1: 0.0456\n",
      "\n",
      "Domain: 37\n",
      "x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 37 | Accuracy: 0.1429 | Loss: 20.0912 | F1: 0.0357\n",
      "\n",
      "Domain: 38\n",
      "x_dp_dom.shape: (47, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 38 | Accuracy: 0.2553 | Loss: 14.5677 | F1: 0.2398\n",
      "\n",
      "Domain: 39\n",
      "x_dp_dom.shape: (54, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 39 | Accuracy: 0.6296 | Loss: 4.7647 | F1: 0.5828\n",
      "\n",
      "Domain: 40\n",
      "x_dp_dom.shape: (44, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 40 | Accuracy: 0.1591 | Loss: 23.8895 | F1: 0.0437\n",
      "\n",
      "Domain: 41\n",
      "x_dp_dom.shape: (45, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 41 | Accuracy: 0.0444 | Loss: 24.8150 | F1: 0.0413\n",
      "\n",
      "Domain: 42\n",
      "x_dp_dom.shape: (46, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 42 | Accuracy: 0.1304 | Loss: 23.9841 | F1: 0.0373\n",
      "\n",
      "Domain: 43\n",
      "x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 43 | Accuracy: 0.2619 | Loss: 21.0432 | F1: 0.2929\n",
      "\n",
      "Domain: 44\n",
      "x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 44 | Accuracy: 0.1667 | Loss: 22.7739 | F1: 0.0476\n",
      "\n",
      "Domain: 45\n",
      "x_dp_dom.shape: (52, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 45 | Accuracy: 0.2115 | Loss: 20.2906 | F1: 0.0739\n",
      "\n",
      "Domain: 46\n",
      "x_dp_dom.shape: (48, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 46 | Accuracy: 0.1458 | Loss: 17.2416 | F1: 0.0371\n",
      "\n",
      "Domain: 47\n",
      "x_dp_dom.shape: (44, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 47 | Accuracy: 0.1591 | Loss: 22.4036 | F1: 0.0437\n",
      "\n",
      "Domain: 48\n",
      "x_dp_dom.shape: (48, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 48 | Accuracy: 0.1667 | Loss: 18.6821 | F1: 0.0476\n",
      "\n",
      "Domain: 49\n",
      "x_dp_dom.shape: (53, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 49 | Accuracy: 0.2264 | Loss: 18.2890 | F1: 0.0836\n",
      "\n",
      "Domain: 50\n",
      "x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 50 | Accuracy: 0.1667 | Loss: 21.0941 | F1: 0.0476\n",
      "\n",
      "Domain: 51\n",
      "x_dp_dom.shape: (46, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 51 | Accuracy: 0.1522 | Loss: 21.4470 | F1: 0.0517\n",
      "\n",
      "Domain: 52\n",
      "x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 52 | Accuracy: 0.1667 | Loss: 22.4149 | F1: 0.0476\n",
      "\n",
      "Domain: 53\n",
      "x_dp_dom.shape: (48, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 53 | Accuracy: 0.4583 | Loss: 13.4427 | F1: 0.4524\n",
      "\n",
      "Domain: 54\n",
      "x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 54 | Accuracy: 0.2619 | Loss: 17.8386 | F1: 0.1731\n",
      "\n",
      "Domain: 55\n",
      "x_dp_dom.shape: (49, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 55 | Accuracy: 0.1633 | Loss: 22.6670 | F1: 0.0458\n",
      "\n",
      "Domain: 56\n",
      "x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 56 | Accuracy: 0.1667 | Loss: 23.4445 | F1: 0.0476\n",
      "\n",
      "Domain: 57\n",
      "x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 57 | Accuracy: 0.1667 | Loss: 24.4011 | F1: 0.0476\n",
      "\n",
      "Domain: 58\n",
      "x_dp_dom.shape: (38, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 58 | Accuracy: 0.1316 | Loss: 16.0587 | F1: 0.0306\n",
      "\n",
      "Domain: 59\n",
      "x_dp_dom.shape: (43, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 59 | Accuracy: 0.1628 | Loss: 20.8697 | F1: 0.0456\n",
      "\n",
      "Domain: 60\n",
      "x_dp_dom.shape: (47, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 60 | Accuracy: 0.4043 | Loss: 10.1234 | F1: 0.3430\n",
      "\n",
      "Domain: 61\n",
      "x_dp_dom.shape: (47, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 61 | Accuracy: 0.1277 | Loss: 24.8623 | F1: 0.0337\n",
      "\n",
      "Domain: 62\n",
      "x_dp_dom.shape: (47, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 62 | Accuracy: 0.1489 | Loss: 25.2538 | F1: 0.0386\n",
      "\n",
      "Domain: 63\n",
      "x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 63 | Accuracy: 0.1667 | Loss: 22.8199 | F1: 0.0486\n",
      "\n",
      "Domain: 64\n",
      "x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 64 | Accuracy: 0.1667 | Loss: 24.6712 | F1: 0.0476\n",
      "\n",
      "Domain: 65\n",
      "x_dp_dom.shape: (50, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 65 | Accuracy: 0.7000 | Loss: 9.0137 | F1: 0.6276\n",
      "\n",
      "Domain: 66\n",
      "x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 66 | Accuracy: 0.6667 | Loss: 9.5369 | F1: 0.5490\n",
      "\n",
      "Domain: 67\n",
      "x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 67 | Accuracy: 0.1667 | Loss: 13.5314 | F1: 0.0476\n",
      "\n",
      "Domain: 68\n",
      "x_dp_dom.shape: (43, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 68 | Accuracy: 0.1628 | Loss: 25.5202 | F1: 0.0456\n",
      "\n",
      "Domain: 69\n",
      "x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 69 | Accuracy: 0.8333 | Loss: 6.2457 | F1: 0.7778\n",
      "\n",
      "Domain: 70\n",
      "x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 70 | Accuracy: 0.1667 | Loss: 13.4081 | F1: 0.1147\n",
      "\n",
      "Domain: 71\n",
      "x_dp_dom.shape: (44, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 71 | Accuracy: 0.1591 | Loss: 15.5513 | F1: 0.0518\n",
      "\n",
      "Domain: 72\n",
      "x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 72 | Accuracy: 0.1667 | Loss: 24.0788 | F1: 0.0476\n",
      "\n",
      "Domain: 73\n",
      "x_dp_dom.shape: (41, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 73 | Accuracy: 0.6829 | Loss: 8.2994 | F1: 0.5543\n",
      "\n",
      "Domain: 74\n",
      "x_dp_dom.shape: (35, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 74 | Accuracy: 0.0000 | Loss: 25.1908 | F1: 0.0000\n",
      "\n",
      "Domain: 75\n",
      "x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 75 | Accuracy: 0.1667 | Loss: 24.3676 | F1: 0.0476\n",
      "\n",
      "Mean accuracy for run 0: 0.2415\n",
      "Mean F1 for run 0: 0.1442\n",
      "\n",
      "Source class: WAL\n",
      "\n",
      "x_df.shape: (7958, 3, 128) | np.unique(y_df): [1 2 3]\n",
      "\n",
      "Training on Df data...\n",
      "\tEpoch 10/100 - Train loss: 0.0388 - Val accuracy: 0.9805 - Val loss: 0.0527 - Val F1: 0.9805 - LR: 9.00e-05\n",
      "\tEpoch 20/100 - Train loss: 0.0081 - Val accuracy: 0.9856 - Val loss: 0.0406 - Val F1: 0.9856 - LR: 8.00e-05\n",
      "\tEpoch 30/100 - Train loss: 0.0036 - Val accuracy: 0.9849 - Val loss: 0.0414 - Val F1: 0.9849 - LR: 7.00e-05\n",
      "\tEpoch 40/100 - Train loss: 0.0028 - Val accuracy: 0.9856 - Val loss: 0.0489 - Val F1: 0.9856 - LR: 6.00e-05\n",
      "\tEpoch 50/100 - Train loss: 0.0017 - Val accuracy: 0.9862 - Val loss: 0.0459 - Val F1: 0.9862 - LR: 5.00e-05\n",
      "\tEpoch 60/100 - Train loss: 0.0005 - Val accuracy: 0.9874 - Val loss: 0.0476 - Val F1: 0.9874 - LR: 4.00e-05\n",
      "\tEpoch 70/100 - Train loss: 0.0004 - Val accuracy: 0.9881 - Val loss: 0.0487 - Val F1: 0.9881 - LR: 3.00e-05\n",
      "\tEpoch 80/100 - Train loss: 0.0002 - Val accuracy: 0.9874 - Val loss: 0.0591 - Val F1: 0.9874 - LR: 2.00e-05\n",
      "\tEpoch 90/100 - Train loss: 0.0002 - Val accuracy: 0.9856 - Val loss: 0.0553 - Val F1: 0.9856 - LR: 1.00e-05\n",
      "\tEpoch 100/100 - Train loss: 0.0001 - Val accuracy: 0.9862 - Val loss: 0.0525 - Val F1: 0.9862 - LR: 0.00e+00\n",
      "\tBest epoch: 26 - Best val accuracy: 0.9849 - Best val loss: 0.0380 - Best val F1: 0.9849\n",
      "\n",
      "Domain: 15\n",
      "x_dp_dom.shape: (50, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 15 | Accuracy: 0.2400 | Loss: 10.5446 | F1: 0.1309\n",
      "\n",
      "Domain: 16\n",
      "x_dp_dom.shape: (54, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 16 | Accuracy: 0.2593 | Loss: 7.0113 | F1: 0.1963\n",
      "\n",
      "Domain: 17\n",
      "x_dp_dom.shape: (53, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 17 | Accuracy: 0.3208 | Loss: 9.3264 | F1: 0.2547\n",
      "\n",
      "Domain: 18\n",
      "x_dp_dom.shape: (54, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 18 | Accuracy: 0.2407 | Loss: 7.2858 | F1: 0.1605\n",
      "\n",
      "Domain: 19\n",
      "x_dp_dom.shape: (54, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 19 | Accuracy: 0.2407 | Loss: 10.9794 | F1: 0.1605\n",
      "\n",
      "Domain: 20\n",
      "x_dp_dom.shape: (51, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 20 | Accuracy: 0.5882 | Loss: 4.2220 | F1: 0.5989\n",
      "\n",
      "Domain: 21\n",
      "x_dp_dom.shape: (47, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 21 | Accuracy: 0.4255 | Loss: 3.1339 | F1: 0.4505\n",
      "\n",
      "Domain: 22\n",
      "x_dp_dom.shape: (54, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 22 | Accuracy: 0.2963 | Loss: 7.9694 | F1: 0.2530\n",
      "\n",
      "Domain: 23\n",
      "x_dp_dom.shape: (52, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 23 | Accuracy: 0.2692 | Loss: 11.1513 | F1: 0.2128\n",
      "\n",
      "Domain: 24\n",
      "x_dp_dom.shape: (51, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 24 | Accuracy: 0.4118 | Loss: 9.4937 | F1: 0.4217\n",
      "\n",
      "Domain: 25\n",
      "x_dp_dom.shape: (54, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 25 | Accuracy: 0.2407 | Loss: 10.1631 | F1: 0.1605\n",
      "\n",
      "Domain: 26\n",
      "x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 26 | Accuracy: 0.3571 | Loss: 4.4035 | F1: 0.3590\n",
      "\n",
      "Domain: 27\n",
      "x_dp_dom.shape: (54, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 27 | Accuracy: 0.5741 | Loss: 7.8944 | F1: 0.5362\n",
      "\n",
      "Domain: 28\n",
      "x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 28 | Accuracy: 0.3571 | Loss: 6.1481 | F1: 0.3977\n",
      "\n",
      "Domain: 29\n",
      "x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 29 | Accuracy: 0.1667 | Loss: 14.1255 | F1: 0.1111\n",
      "\n",
      "Domain: 30\n",
      "x_dp_dom.shape: (50, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 30 | Accuracy: 0.2800 | Loss: 8.9279 | F1: 0.2467\n",
      "\n",
      "Domain: 31\n",
      "x_dp_dom.shape: (43, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 31 | Accuracy: 0.2326 | Loss: 6.4494 | F1: 0.1593\n",
      "\n",
      "Domain: 32\n",
      "x_dp_dom.shape: (52, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 32 | Accuracy: 0.2500 | Loss: 9.3452 | F1: 0.1625\n",
      "\n",
      "Domain: 33\n",
      "x_dp_dom.shape: (44, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 33 | Accuracy: 0.2500 | Loss: 6.4902 | F1: 0.2321\n",
      "\n",
      "Domain: 34\n",
      "x_dp_dom.shape: (49, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 34 | Accuracy: 0.3265 | Loss: 7.1857 | F1: 0.3135\n",
      "\n",
      "Domain: 35\n",
      "x_dp_dom.shape: (48, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 35 | Accuracy: 0.6458 | Loss: 2.7591 | F1: 0.6699\n",
      "\n",
      "Domain: 36\n",
      "x_dp_dom.shape: (43, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 36 | Accuracy: 0.1860 | Loss: 7.6359 | F1: 0.1294\n",
      "\n",
      "Domain: 37\n",
      "x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 37 | Accuracy: 0.7619 | Loss: 4.3131 | F1: 0.7479\n",
      "\n",
      "Domain: 38\n",
      "x_dp_dom.shape: (47, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 38 | Accuracy: 0.2553 | Loss: 7.2379 | F1: 0.1571\n",
      "\n",
      "Domain: 39\n",
      "x_dp_dom.shape: (54, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 39 | Accuracy: 0.2778 | Loss: 13.0781 | F1: 0.1752\n",
      "\n",
      "Domain: 40\n",
      "x_dp_dom.shape: (44, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 40 | Accuracy: 0.5227 | Loss: 6.5900 | F1: 0.5430\n",
      "\n",
      "Domain: 41\n",
      "x_dp_dom.shape: (45, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 41 | Accuracy: 0.2000 | Loss: 9.8784 | F1: 0.1323\n",
      "\n",
      "Domain: 42\n",
      "x_dp_dom.shape: (46, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 42 | Accuracy: 0.3043 | Loss: 7.7062 | F1: 0.2171\n",
      "\n",
      "Domain: 43\n",
      "x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 43 | Accuracy: 0.1667 | Loss: 8.8301 | F1: 0.0933\n",
      "\n",
      "Domain: 44\n",
      "x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 44 | Accuracy: 0.1667 | Loss: 13.7194 | F1: 0.1111\n",
      "\n",
      "Domain: 45\n",
      "x_dp_dom.shape: (52, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 45 | Accuracy: 0.3654 | Loss: 4.4246 | F1: 0.3657\n",
      "\n",
      "Domain: 46\n",
      "x_dp_dom.shape: (48, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 46 | Accuracy: 0.2708 | Loss: 9.8449 | F1: 0.2134\n",
      "\n",
      "Domain: 47\n",
      "x_dp_dom.shape: (44, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 47 | Accuracy: 0.2500 | Loss: 7.2989 | F1: 0.1773\n",
      "\n",
      "Domain: 48\n",
      "x_dp_dom.shape: (48, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 48 | Accuracy: 0.3750 | Loss: 3.7472 | F1: 0.3654\n",
      "\n",
      "Domain: 49\n",
      "x_dp_dom.shape: (53, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 49 | Accuracy: 0.2453 | Loss: 9.0449 | F1: 0.1635\n",
      "\n",
      "Domain: 50\n",
      "x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 50 | Accuracy: 0.3571 | Loss: 4.4403 | F1: 0.3256\n",
      "\n",
      "Domain: 51\n",
      "x_dp_dom.shape: (46, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 51 | Accuracy: 0.2174 | Loss: 7.6356 | F1: 0.1457\n",
      "\n",
      "Domain: 52\n",
      "x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 52 | Accuracy: 0.2857 | Loss: 4.8160 | F1: 0.3131\n",
      "\n",
      "Domain: 53\n",
      "x_dp_dom.shape: (48, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 53 | Accuracy: 0.6042 | Loss: 3.1858 | F1: 0.6282\n",
      "\n",
      "Domain: 54\n",
      "x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 54 | Accuracy: 0.2857 | Loss: 7.9556 | F1: 0.3131\n",
      "\n",
      "Domain: 55\n",
      "x_dp_dom.shape: (49, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 55 | Accuracy: 0.2653 | Loss: 5.7665 | F1: 0.2029\n",
      "\n",
      "Domain: 56\n",
      "x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 56 | Accuracy: 0.3810 | Loss: 4.3489 | F1: 0.3962\n",
      "\n",
      "Domain: 57\n",
      "x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 57 | Accuracy: 0.3571 | Loss: 3.8418 | F1: 0.3420\n",
      "\n",
      "Domain: 58\n",
      "x_dp_dom.shape: (38, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 58 | Accuracy: 0.1316 | Loss: 17.7760 | F1: 0.0877\n",
      "\n",
      "Domain: 59\n",
      "x_dp_dom.shape: (43, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 59 | Accuracy: 0.1860 | Loss: 7.5706 | F1: 0.1294\n",
      "\n",
      "Domain: 60\n",
      "x_dp_dom.shape: (47, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 60 | Accuracy: 0.2979 | Loss: 9.4924 | F1: 0.2183\n",
      "\n",
      "Domain: 61\n",
      "x_dp_dom.shape: (47, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 61 | Accuracy: 0.2553 | Loss: 9.7561 | F1: 0.1362\n",
      "\n",
      "Domain: 62\n",
      "x_dp_dom.shape: (47, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 62 | Accuracy: 0.2553 | Loss: 10.2329 | F1: 0.1915\n",
      "\n",
      "Domain: 63\n",
      "x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 63 | Accuracy: 0.3095 | Loss: 9.0980 | F1: 0.2043\n",
      "\n",
      "Domain: 64\n",
      "x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 64 | Accuracy: 0.3095 | Loss: 8.8794 | F1: 0.2043\n",
      "\n",
      "Domain: 65\n",
      "x_dp_dom.shape: (50, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 65 | Accuracy: 0.2600 | Loss: 14.8397 | F1: 0.1073\n",
      "\n",
      "Domain: 66\n",
      "x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 66 | Accuracy: 0.1667 | Loss: 11.3614 | F1: 0.0864\n",
      "\n",
      "Domain: 67\n",
      "x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 67 | Accuracy: 0.6905 | Loss: 5.5618 | F1: 0.6978\n",
      "\n",
      "Domain: 68\n",
      "x_dp_dom.shape: (43, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 68 | Accuracy: 0.1860 | Loss: 7.8118 | F1: 0.1294\n",
      "\n",
      "Domain: 69\n",
      "x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 69 | Accuracy: 0.1667 | Loss: 11.2195 | F1: 0.1061\n",
      "\n",
      "Domain: 70\n",
      "x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 70 | Accuracy: 0.2143 | Loss: 7.9817 | F1: 0.1949\n",
      "\n",
      "Domain: 71\n",
      "x_dp_dom.shape: (44, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 71 | Accuracy: 0.2045 | Loss: 8.6180 | F1: 0.1473\n",
      "\n",
      "Domain: 72\n",
      "x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 72 | Accuracy: 0.1667 | Loss: 8.2812 | F1: 0.1111\n",
      "\n",
      "Domain: 73\n",
      "x_dp_dom.shape: (41, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 73 | Accuracy: 0.1707 | Loss: 8.5516 | F1: 0.0747\n",
      "\n",
      "Domain: 74\n",
      "x_dp_dom.shape: (35, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 74 | Accuracy: 0.1714 | Loss: 6.1814 | F1: 0.2328\n",
      "\n",
      "Domain: 75\n",
      "x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 75 | Accuracy: 0.1667 | Loss: 10.4402 | F1: 0.1111\n",
      "\n",
      "Mean accuracy for run 1: 0.3014\n",
      "Mean F1 for run 1: 0.2560\n",
      "\n",
      "Source class: WAL\n",
      "\n",
      "x_df.shape: (7958, 3, 128) | np.unique(y_df): [1 2 3]\n",
      "\n",
      "Training on Df data...\n",
      "\tEpoch 10/100 - Train loss: 0.0316 - Val accuracy: 0.9818 - Val loss: 0.0460 - Val F1: 0.9818 - LR: 9.00e-05\n",
      "\tEpoch 20/100 - Train loss: 0.0111 - Val accuracy: 0.9812 - Val loss: 0.0461 - Val F1: 0.9811 - LR: 8.00e-05\n",
      "\tEpoch 30/100 - Train loss: 0.0029 - Val accuracy: 0.9830 - Val loss: 0.0472 - Val F1: 0.9830 - LR: 7.00e-05\n",
      "\tEpoch 40/100 - Train loss: 0.0014 - Val accuracy: 0.9824 - Val loss: 0.0528 - Val F1: 0.9824 - LR: 6.00e-05\n",
      "\tEpoch 50/100 - Train loss: 0.0023 - Val accuracy: 0.9824 - Val loss: 0.0568 - Val F1: 0.9824 - LR: 5.00e-05\n",
      "\tEpoch 60/100 - Train loss: 0.0010 - Val accuracy: 0.9843 - Val loss: 0.0548 - Val F1: 0.9843 - LR: 4.00e-05\n",
      "\tEpoch 70/100 - Train loss: 0.0003 - Val accuracy: 0.9830 - Val loss: 0.0563 - Val F1: 0.9830 - LR: 3.00e-05\n",
      "\tEpoch 80/100 - Train loss: 0.0002 - Val accuracy: 0.9837 - Val loss: 0.0589 - Val F1: 0.9837 - LR: 2.00e-05\n",
      "\tEpoch 90/100 - Train loss: 0.0005 - Val accuracy: 0.9830 - Val loss: 0.0619 - Val F1: 0.9830 - LR: 1.00e-05\n",
      "\tEpoch 100/100 - Train loss: 0.0002 - Val accuracy: 0.9837 - Val loss: 0.0599 - Val F1: 0.9837 - LR: 0.00e+00\n",
      "\tBest epoch: 17 - Best val accuracy: 0.9812 - Best val loss: 0.0425 - Best val F1: 0.9811\n",
      "\n",
      "Domain: 15\n",
      "x_dp_dom.shape: (50, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 15 | Accuracy: 0.4400 | Loss: 3.2681 | F1: 0.3473\n",
      "\n",
      "Domain: 16\n",
      "x_dp_dom.shape: (54, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 16 | Accuracy: 0.2778 | Loss: 9.6543 | F1: 0.1701\n",
      "\n",
      "Domain: 17\n",
      "x_dp_dom.shape: (53, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 17 | Accuracy: 0.2453 | Loss: 13.5646 | F1: 0.1100\n",
      "\n",
      "Domain: 18\n",
      "x_dp_dom.shape: (54, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 18 | Accuracy: 0.4815 | Loss: 7.5015 | F1: 0.4447\n",
      "\n",
      "Domain: 19\n",
      "x_dp_dom.shape: (54, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 19 | Accuracy: 0.2407 | Loss: 10.3028 | F1: 0.1138\n",
      "\n",
      "Domain: 20\n",
      "x_dp_dom.shape: (51, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 20 | Accuracy: 0.3333 | Loss: 9.3880 | F1: 0.3117\n",
      "\n",
      "Domain: 21\n",
      "x_dp_dom.shape: (47, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 21 | Accuracy: 0.3191 | Loss: 6.5465 | F1: 0.2485\n",
      "\n",
      "Domain: 22\n",
      "x_dp_dom.shape: (54, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 22 | Accuracy: 0.3704 | Loss: 11.0304 | F1: 0.3135\n",
      "\n",
      "Domain: 23\n",
      "x_dp_dom.shape: (52, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 23 | Accuracy: 0.5962 | Loss: 7.9254 | F1: 0.5597\n",
      "\n",
      "Domain: 24\n",
      "x_dp_dom.shape: (51, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 24 | Accuracy: 0.6275 | Loss: 10.4556 | F1: 0.5921\n",
      "\n",
      "Domain: 25\n",
      "x_dp_dom.shape: (54, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 25 | Accuracy: 0.5370 | Loss: 7.1740 | F1: 0.5023\n",
      "\n",
      "Domain: 26\n",
      "x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 26 | Accuracy: 0.1905 | Loss: 13.2919 | F1: 0.1015\n",
      "\n",
      "Domain: 27\n",
      "x_dp_dom.shape: (54, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 27 | Accuracy: 0.2407 | Loss: 17.1923 | F1: 0.0934\n",
      "\n",
      "Domain: 28\n",
      "x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 28 | Accuracy: 0.3333 | Loss: 11.0537 | F1: 0.3250\n",
      "\n",
      "Domain: 29\n",
      "x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 29 | Accuracy: 0.3810 | Loss: 6.6285 | F1: 0.3827\n",
      "\n",
      "Domain: 30\n",
      "x_dp_dom.shape: (50, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 30 | Accuracy: 0.2200 | Loss: 14.3273 | F1: 0.0834\n",
      "\n",
      "Domain: 31\n",
      "x_dp_dom.shape: (43, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 31 | Accuracy: 0.2558 | Loss: 6.8469 | F1: 0.1832\n",
      "\n",
      "Domain: 32\n",
      "x_dp_dom.shape: (52, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 32 | Accuracy: 0.2885 | Loss: 18.1060 | F1: 0.1766\n",
      "\n",
      "Domain: 33\n",
      "x_dp_dom.shape: (44, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 33 | Accuracy: 0.5682 | Loss: 5.3311 | F1: 0.5623\n",
      "\n",
      "Domain: 34\n",
      "x_dp_dom.shape: (49, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 34 | Accuracy: 0.4898 | Loss: 5.8800 | F1: 0.4791\n",
      "\n",
      "Domain: 35\n",
      "x_dp_dom.shape: (48, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 35 | Accuracy: 0.2708 | Loss: 9.5536 | F1: 0.1956\n",
      "\n",
      "Domain: 36\n",
      "x_dp_dom.shape: (43, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 36 | Accuracy: 0.1860 | Loss: 12.3742 | F1: 0.0647\n",
      "\n",
      "Domain: 37\n",
      "x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 37 | Accuracy: 0.2143 | Loss: 12.0081 | F1: 0.1185\n",
      "\n",
      "Domain: 38\n",
      "x_dp_dom.shape: (47, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 38 | Accuracy: 0.5106 | Loss: 6.1000 | F1: 0.5037\n",
      "\n",
      "Domain: 39\n",
      "x_dp_dom.shape: (54, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 39 | Accuracy: 0.2407 | Loss: 13.6685 | F1: 0.1304\n",
      "\n",
      "Domain: 40\n",
      "x_dp_dom.shape: (44, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 40 | Accuracy: 0.2045 | Loss: 13.4667 | F1: 0.0708\n",
      "\n",
      "Domain: 41\n",
      "x_dp_dom.shape: (45, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 41 | Accuracy: 0.1778 | Loss: 19.6634 | F1: 0.0905\n",
      "\n",
      "Domain: 42\n",
      "x_dp_dom.shape: (46, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 42 | Accuracy: 0.2391 | Loss: 20.8183 | F1: 0.0923\n",
      "\n",
      "Domain: 43\n",
      "x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 43 | Accuracy: 0.4524 | Loss: 4.0298 | F1: 0.4567\n",
      "\n",
      "Domain: 44\n",
      "x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 44 | Accuracy: 0.1905 | Loss: 8.5004 | F1: 0.1043\n",
      "\n",
      "Domain: 45\n",
      "x_dp_dom.shape: (52, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 45 | Accuracy: 0.3077 | Loss: 7.0087 | F1: 0.2799\n",
      "\n",
      "Domain: 46\n",
      "x_dp_dom.shape: (48, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 46 | Accuracy: 0.7083 | Loss: 3.8862 | F1: 0.6760\n",
      "\n",
      "Domain: 47\n",
      "x_dp_dom.shape: (44, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 47 | Accuracy: 0.5909 | Loss: 4.8101 | F1: 0.5831\n",
      "\n",
      "Domain: 48\n",
      "x_dp_dom.shape: (48, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 48 | Accuracy: 0.8125 | Loss: 3.9786 | F1: 0.7545\n",
      "\n",
      "Domain: 49\n",
      "x_dp_dom.shape: (53, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 49 | Accuracy: 0.2453 | Loss: 10.3575 | F1: 0.1203\n",
      "\n",
      "Domain: 50\n",
      "x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 50 | Accuracy: 0.5000 | Loss: 4.0049 | F1: 0.5459\n",
      "\n",
      "Domain: 51\n",
      "x_dp_dom.shape: (46, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 51 | Accuracy: 0.7174 | Loss: 4.7045 | F1: 0.7226\n",
      "\n",
      "Domain: 52\n",
      "x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 52 | Accuracy: 0.1667 | Loss: 9.5654 | F1: 0.1061\n",
      "\n",
      "Domain: 53\n",
      "x_dp_dom.shape: (48, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 53 | Accuracy: 0.7500 | Loss: 4.8736 | F1: 0.7149\n",
      "\n",
      "Domain: 54\n",
      "x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 54 | Accuracy: 0.1667 | Loss: 11.3766 | F1: 0.0805\n",
      "\n",
      "Domain: 55\n",
      "x_dp_dom.shape: (49, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 55 | Accuracy: 0.4898 | Loss: 4.7793 | F1: 0.4866\n",
      "\n",
      "Domain: 56\n",
      "x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 56 | Accuracy: 0.7857 | Loss: 3.9152 | F1: 0.7434\n",
      "\n",
      "Domain: 57\n",
      "x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 57 | Accuracy: 0.5714 | Loss: 4.2501 | F1: 0.5790\n",
      "\n",
      "Domain: 58\n",
      "x_dp_dom.shape: (38, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 58 | Accuracy: 0.3421 | Loss: 7.0508 | F1: 0.4006\n",
      "\n",
      "Domain: 59\n",
      "x_dp_dom.shape: (43, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 59 | Accuracy: 0.6279 | Loss: 4.7130 | F1: 0.6195\n",
      "\n",
      "Domain: 60\n",
      "x_dp_dom.shape: (47, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 60 | Accuracy: 0.4043 | Loss: 7.5401 | F1: 0.3968\n",
      "\n",
      "Domain: 61\n",
      "x_dp_dom.shape: (47, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 61 | Accuracy: 0.2766 | Loss: 18.6380 | F1: 0.1429\n",
      "\n",
      "Domain: 62\n",
      "x_dp_dom.shape: (47, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 62 | Accuracy: 0.2553 | Loss: 9.6199 | F1: 0.1751\n",
      "\n",
      "Domain: 63\n",
      "x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 63 | Accuracy: 0.5238 | Loss: 5.0220 | F1: 0.5380\n",
      "\n",
      "Domain: 64\n",
      "x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 64 | Accuracy: 0.1667 | Loss: 8.5504 | F1: 0.0496\n",
      "\n",
      "Domain: 65\n",
      "x_dp_dom.shape: (50, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 65 | Accuracy: 0.4000 | Loss: 7.6393 | F1: 0.4171\n",
      "\n",
      "Domain: 66\n",
      "x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 66 | Accuracy: 0.4048 | Loss: 4.5292 | F1: 0.4548\n",
      "\n",
      "Domain: 67\n",
      "x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 67 | Accuracy: 0.2857 | Loss: 9.7235 | F1: 0.3081\n",
      "\n",
      "Domain: 68\n",
      "x_dp_dom.shape: (43, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 68 | Accuracy: 0.2558 | Loss: 10.2981 | F1: 0.1880\n",
      "\n",
      "Domain: 69\n",
      "x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 69 | Accuracy: 0.5000 | Loss: 5.5929 | F1: 0.5556\n",
      "\n",
      "Domain: 70\n",
      "x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 70 | Accuracy: 0.1667 | Loss: 13.7939 | F1: 0.0476\n",
      "\n",
      "Domain: 71\n",
      "x_dp_dom.shape: (44, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 71 | Accuracy: 0.5227 | Loss: 4.7070 | F1: 0.5512\n",
      "\n",
      "Domain: 72\n",
      "x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 72 | Accuracy: 0.5238 | Loss: 5.1465 | F1: 0.5429\n",
      "\n",
      "Domain: 73\n",
      "x_dp_dom.shape: (41, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 73 | Accuracy: 0.8537 | Loss: 0.8999 | F1: 0.8447\n",
      "\n",
      "Domain: 74\n",
      "x_dp_dom.shape: (35, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 74 | Accuracy: 0.4857 | Loss: 4.0661 | F1: 0.5371\n",
      "\n",
      "Domain: 75\n",
      "x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 75 | Accuracy: 0.3333 | Loss: 6.5155 | F1: 0.3600\n",
      "\n",
      "Mean accuracy for run 2: 0.3978\n",
      "Mean F1 for run 2: 0.3517\n",
      "\n",
      "Source class: WAL\n",
      "\n",
      "x_df.shape: (7958, 3, 128) | np.unique(y_df): [1 2 3]\n",
      "\n",
      "Training on Df data...\n",
      "\tEpoch 10/100 - Train loss: 0.0249 - Val accuracy: 0.9824 - Val loss: 0.0424 - Val F1: 0.9824 - LR: 9.00e-05\n",
      "\tEpoch 20/100 - Train loss: 0.0059 - Val accuracy: 0.9830 - Val loss: 0.0448 - Val F1: 0.9830 - LR: 8.00e-05\n",
      "\tEpoch 30/100 - Train loss: 0.0016 - Val accuracy: 0.9862 - Val loss: 0.0478 - Val F1: 0.9862 - LR: 7.00e-05\n",
      "\tEpoch 40/100 - Train loss: 0.0016 - Val accuracy: 0.9868 - Val loss: 0.0537 - Val F1: 0.9868 - LR: 6.00e-05\n",
      "\tEpoch 50/100 - Train loss: 0.0007 - Val accuracy: 0.9868 - Val loss: 0.0531 - Val F1: 0.9868 - LR: 5.00e-05\n",
      "\tEpoch 60/100 - Train loss: 0.0006 - Val accuracy: 0.9849 - Val loss: 0.0585 - Val F1: 0.9849 - LR: 4.00e-05\n",
      "\tEpoch 70/100 - Train loss: 0.0003 - Val accuracy: 0.9893 - Val loss: 0.0518 - Val F1: 0.9893 - LR: 3.00e-05\n",
      "\tEpoch 80/100 - Train loss: 0.0006 - Val accuracy: 0.9849 - Val loss: 0.0653 - Val F1: 0.9849 - LR: 2.00e-05\n",
      "\tEpoch 90/100 - Train loss: 0.0002 - Val accuracy: 0.9868 - Val loss: 0.0579 - Val F1: 0.9868 - LR: 1.00e-05\n",
      "\tEpoch 100/100 - Train loss: 0.0001 - Val accuracy: 0.9862 - Val loss: 0.0575 - Val F1: 0.9862 - LR: 0.00e+00\n",
      "\tBest epoch: 14 - Best val accuracy: 0.9849 - Best val loss: 0.0412 - Best val F1: 0.9849\n",
      "\n",
      "Domain: 15\n",
      "x_dp_dom.shape: (50, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 15 | Accuracy: 0.6600 | Loss: 2.4558 | F1: 0.5689\n",
      "\n",
      "Domain: 16\n",
      "x_dp_dom.shape: (54, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 16 | Accuracy: 0.5556 | Loss: 6.5449 | F1: 0.4272\n",
      "\n",
      "Domain: 17\n",
      "x_dp_dom.shape: (53, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 17 | Accuracy: 0.4906 | Loss: 6.9348 | F1: 0.3477\n",
      "\n",
      "Domain: 18\n",
      "x_dp_dom.shape: (54, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 18 | Accuracy: 0.5185 | Loss: 8.4725 | F1: 0.3541\n",
      "\n",
      "Domain: 19\n",
      "x_dp_dom.shape: (54, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 19 | Accuracy: 0.5185 | Loss: 7.1680 | F1: 0.3541\n",
      "\n",
      "Domain: 20\n",
      "x_dp_dom.shape: (51, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 20 | Accuracy: 0.3725 | Loss: 6.2070 | F1: 0.4179\n",
      "\n",
      "Domain: 21\n",
      "x_dp_dom.shape: (47, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 21 | Accuracy: 0.6383 | Loss: 5.1531 | F1: 0.5300\n",
      "\n",
      "Domain: 22\n",
      "x_dp_dom.shape: (54, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 22 | Accuracy: 0.5185 | Loss: 8.9687 | F1: 0.3541\n",
      "\n",
      "Domain: 23\n",
      "x_dp_dom.shape: (52, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 23 | Accuracy: 0.5385 | Loss: 10.7269 | F1: 0.3769\n",
      "\n",
      "Domain: 24\n",
      "x_dp_dom.shape: (51, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 24 | Accuracy: 0.1961 | Loss: 10.6759 | F1: 0.1800\n",
      "\n",
      "Domain: 25\n",
      "x_dp_dom.shape: (54, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 25 | Accuracy: 0.5185 | Loss: 6.7876 | F1: 0.3541\n",
      "\n",
      "Domain: 26\n",
      "x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 26 | Accuracy: 0.4524 | Loss: 6.6744 | F1: 0.4222\n",
      "\n",
      "Domain: 27\n",
      "x_dp_dom.shape: (54, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 27 | Accuracy: 0.5185 | Loss: 10.0199 | F1: 0.3541\n",
      "\n",
      "Domain: 28\n",
      "x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 28 | Accuracy: 0.6667 | Loss: 4.5787 | F1: 0.5411\n",
      "\n",
      "Domain: 29\n",
      "x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 29 | Accuracy: 0.6667 | Loss: 5.9329 | F1: 0.5333\n",
      "\n",
      "Domain: 30\n",
      "x_dp_dom.shape: (50, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 30 | Accuracy: 0.6000 | Loss: 6.1296 | F1: 0.5148\n",
      "\n",
      "Domain: 31\n",
      "x_dp_dom.shape: (43, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 31 | Accuracy: 0.6977 | Loss: 4.2566 | F1: 0.6576\n",
      "\n",
      "Domain: 32\n",
      "x_dp_dom.shape: (52, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 32 | Accuracy: 0.5385 | Loss: 7.3616 | F1: 0.3769\n",
      "\n",
      "Domain: 33\n",
      "x_dp_dom.shape: (44, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 33 | Accuracy: 0.6591 | Loss: 4.2900 | F1: 0.5428\n",
      "\n",
      "Domain: 34\n",
      "x_dp_dom.shape: (49, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 34 | Accuracy: 0.4286 | Loss: 6.2481 | F1: 0.3842\n",
      "\n",
      "Domain: 35\n",
      "x_dp_dom.shape: (48, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 35 | Accuracy: 0.5417 | Loss: 3.3960 | F1: 0.5163\n",
      "\n",
      "Domain: 36\n",
      "x_dp_dom.shape: (43, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 36 | Accuracy: 0.7907 | Loss: 3.6482 | F1: 0.7205\n",
      "\n",
      "Domain: 37\n",
      "x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 37 | Accuracy: 0.4762 | Loss: 6.3059 | F1: 0.4646\n",
      "\n",
      "Domain: 38\n",
      "x_dp_dom.shape: (47, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 38 | Accuracy: 0.6596 | Loss: 6.5373 | F1: 0.5759\n",
      "\n",
      "Domain: 39\n",
      "x_dp_dom.shape: (54, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 39 | Accuracy: 0.4074 | Loss: 9.3765 | F1: 0.4274\n",
      "\n",
      "Domain: 40\n",
      "x_dp_dom.shape: (44, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 40 | Accuracy: 0.6136 | Loss: 7.9406 | F1: 0.4840\n",
      "\n",
      "Domain: 41\n",
      "x_dp_dom.shape: (45, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 41 | Accuracy: 0.6444 | Loss: 6.4203 | F1: 0.5323\n",
      "\n",
      "Domain: 42\n",
      "x_dp_dom.shape: (46, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 42 | Accuracy: 0.6739 | Loss: 6.7498 | F1: 0.5944\n",
      "\n",
      "Domain: 43\n",
      "x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 43 | Accuracy: 0.6905 | Loss: 2.7700 | F1: 0.6350\n",
      "\n",
      "Domain: 44\n",
      "x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 44 | Accuracy: 0.6667 | Loss: 5.7588 | F1: 0.5333\n",
      "\n",
      "Domain: 45\n",
      "x_dp_dom.shape: (52, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 45 | Accuracy: 0.6154 | Loss: 3.8825 | F1: 0.5876\n",
      "\n",
      "Domain: 46\n",
      "x_dp_dom.shape: (48, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 46 | Accuracy: 0.5833 | Loss: 5.4351 | F1: 0.4298\n",
      "\n",
      "Domain: 47\n",
      "x_dp_dom.shape: (44, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 47 | Accuracy: 0.6364 | Loss: 5.6647 | F1: 0.4949\n",
      "\n",
      "Domain: 48\n",
      "x_dp_dom.shape: (48, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 48 | Accuracy: 0.5833 | Loss: 8.3456 | F1: 0.4298\n",
      "\n",
      "Domain: 49\n",
      "x_dp_dom.shape: (53, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 49 | Accuracy: 0.6226 | Loss: 3.8463 | F1: 0.5236\n",
      "\n",
      "Domain: 50\n",
      "x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 50 | Accuracy: 0.5476 | Loss: 6.3050 | F1: 0.4718\n",
      "\n",
      "Domain: 51\n",
      "x_dp_dom.shape: (46, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 51 | Accuracy: 0.5217 | Loss: 7.0552 | F1: 0.4518\n",
      "\n",
      "Domain: 52\n",
      "x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 52 | Accuracy: 0.5238 | Loss: 3.4812 | F1: 0.5185\n",
      "\n",
      "Domain: 53\n",
      "x_dp_dom.shape: (48, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 53 | Accuracy: 0.3750 | Loss: 5.9489 | F1: 0.3182\n",
      "\n",
      "Domain: 54\n",
      "x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 54 | Accuracy: 0.4048 | Loss: 6.0742 | F1: 0.3842\n",
      "\n",
      "Domain: 55\n",
      "x_dp_dom.shape: (49, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 55 | Accuracy: 0.5306 | Loss: 4.0930 | F1: 0.4804\n",
      "\n",
      "Domain: 56\n",
      "x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 56 | Accuracy: 0.6667 | Loss: 4.5920 | F1: 0.5333\n",
      "\n",
      "Domain: 57\n",
      "x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 57 | Accuracy: 0.6667 | Loss: 6.2854 | F1: 0.5333\n",
      "\n",
      "Domain: 58\n",
      "x_dp_dom.shape: (38, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 58 | Accuracy: 0.6579 | Loss: 9.0144 | F1: 0.5848\n",
      "\n",
      "Domain: 59\n",
      "x_dp_dom.shape: (43, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 59 | Accuracy: 0.6512 | Loss: 6.1812 | F1: 0.5136\n",
      "\n",
      "Domain: 60\n",
      "x_dp_dom.shape: (47, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 60 | Accuracy: 0.4894 | Loss: 2.1357 | F1: 0.5386\n",
      "\n",
      "Domain: 61\n",
      "x_dp_dom.shape: (47, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 61 | Accuracy: 0.6170 | Loss: 6.7139 | F1: 0.4881\n",
      "\n",
      "Domain: 62\n",
      "x_dp_dom.shape: (47, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 62 | Accuracy: 0.6170 | Loss: 3.7760 | F1: 0.4901\n",
      "\n",
      "Domain: 63\n",
      "x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 63 | Accuracy: 0.6905 | Loss: 5.6829 | F1: 0.5827\n",
      "\n",
      "Domain: 64\n",
      "x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 64 | Accuracy: 0.7619 | Loss: 3.3757 | F1: 0.6869\n",
      "\n",
      "Domain: 65\n",
      "x_dp_dom.shape: (50, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 65 | Accuracy: 0.0000 | Loss: 10.5423 | F1: 0.0000\n",
      "\n",
      "Domain: 66\n",
      "x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 66 | Accuracy: 0.3571 | Loss: 3.4578 | F1: 0.3222\n",
      "\n",
      "Domain: 67\n",
      "x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 67 | Accuracy: 0.2143 | Loss: 12.0154 | F1: 0.2353\n",
      "\n",
      "Domain: 68\n",
      "x_dp_dom.shape: (43, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 68 | Accuracy: 0.6512 | Loss: 6.4692 | F1: 0.5136\n",
      "\n",
      "Domain: 69\n",
      "x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 69 | Accuracy: 0.2619 | Loss: 6.1109 | F1: 0.3031\n",
      "\n",
      "Domain: 70\n",
      "x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 70 | Accuracy: 0.7381 | Loss: 4.3649 | F1: 0.6806\n",
      "\n",
      "Domain: 71\n",
      "x_dp_dom.shape: (44, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 71 | Accuracy: 0.6364 | Loss: 7.0978 | F1: 0.4949\n",
      "\n",
      "Domain: 72\n",
      "x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 72 | Accuracy: 0.6667 | Loss: 5.6927 | F1: 0.5333\n",
      "\n",
      "Domain: 73\n",
      "x_dp_dom.shape: (41, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 73 | Accuracy: 0.7317 | Loss: 0.7260 | F1: 0.7266\n",
      "\n",
      "Domain: 74\n",
      "x_dp_dom.shape: (35, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 74 | Accuracy: 0.8286 | Loss: 5.3232 | F1: 0.7725\n",
      "\n",
      "Domain: 75\n",
      "x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 75 | Accuracy: 0.5476 | Loss: 3.6985 | F1: 0.5073\n",
      "\n",
      "Mean accuracy for run 3: 0.5625\n",
      "Mean F1 for run 3: 0.4788\n",
      "\n",
      "Source class: WAL\n",
      "\n",
      "x_df.shape: (7958, 3, 128) | np.unique(y_df): [1 2 3]\n",
      "\n",
      "Training on Df data...\n",
      "\tEpoch 10/100 - Train loss: 0.0328 - Val accuracy: 0.9799 - Val loss: 0.0561 - Val F1: 0.9799 - LR: 9.00e-05\n",
      "\tEpoch 20/100 - Train loss: 0.0103 - Val accuracy: 0.9849 - Val loss: 0.0396 - Val F1: 0.9849 - LR: 8.00e-05\n",
      "\tEpoch 30/100 - Train loss: 0.0114 - Val accuracy: 0.9837 - Val loss: 0.0404 - Val F1: 0.9836 - LR: 7.00e-05\n",
      "\tEpoch 40/100 - Train loss: 0.0011 - Val accuracy: 0.9868 - Val loss: 0.0398 - Val F1: 0.9868 - LR: 6.00e-05\n",
      "\tEpoch 50/100 - Train loss: 0.0008 - Val accuracy: 0.9868 - Val loss: 0.0445 - Val F1: 0.9868 - LR: 5.00e-05\n",
      "\tEpoch 60/100 - Train loss: 0.0005 - Val accuracy: 0.9837 - Val loss: 0.0575 - Val F1: 0.9836 - LR: 4.00e-05\n",
      "\tEpoch 70/100 - Train loss: 0.0006 - Val accuracy: 0.9868 - Val loss: 0.0515 - Val F1: 0.9868 - LR: 3.00e-05\n",
      "\tEpoch 80/100 - Train loss: 0.0002 - Val accuracy: 0.9862 - Val loss: 0.0499 - Val F1: 0.9862 - LR: 2.00e-05\n",
      "\tEpoch 90/100 - Train loss: 0.0002 - Val accuracy: 0.9849 - Val loss: 0.0636 - Val F1: 0.9849 - LR: 1.00e-05\n",
      "\tEpoch 100/100 - Train loss: 0.0001 - Val accuracy: 0.9868 - Val loss: 0.0543 - Val F1: 0.9868 - LR: 0.00e+00\n",
      "\tBest epoch: 25 - Best val accuracy: 0.9856 - Best val loss: 0.0357 - Best val F1: 0.9856\n",
      "\n",
      "Domain: 15\n",
      "x_dp_dom.shape: (50, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 15 | Accuracy: 0.2400 | Loss: 7.5570 | F1: 0.1226\n",
      "\n",
      "Domain: 16\n",
      "x_dp_dom.shape: (54, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 16 | Accuracy: 0.7037 | Loss: 2.6457 | F1: 0.6448\n",
      "\n",
      "Domain: 17\n",
      "x_dp_dom.shape: (53, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 17 | Accuracy: 0.6792 | Loss: 2.9569 | F1: 0.6248\n",
      "\n",
      "Domain: 18\n",
      "x_dp_dom.shape: (54, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 18 | Accuracy: 0.6111 | Loss: 2.6412 | F1: 0.5793\n",
      "\n",
      "Domain: 19\n",
      "x_dp_dom.shape: (54, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 19 | Accuracy: 0.2407 | Loss: 5.3351 | F1: 0.1605\n",
      "\n",
      "Domain: 20\n",
      "x_dp_dom.shape: (51, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 20 | Accuracy: 0.7843 | Loss: 2.1348 | F1: 0.7135\n",
      "\n",
      "Domain: 21\n",
      "x_dp_dom.shape: (47, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 21 | Accuracy: 0.7660 | Loss: 0.8015 | F1: 0.7458\n",
      "\n",
      "Domain: 22\n",
      "x_dp_dom.shape: (54, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 22 | Accuracy: 0.4630 | Loss: 2.0129 | F1: 0.4650\n",
      "\n",
      "Domain: 23\n",
      "x_dp_dom.shape: (52, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 23 | Accuracy: 0.6346 | Loss: 1.9059 | F1: 0.6095\n",
      "\n",
      "Domain: 24\n",
      "x_dp_dom.shape: (51, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 24 | Accuracy: 0.7059 | Loss: 2.6041 | F1: 0.6440\n",
      "\n",
      "Domain: 25\n",
      "x_dp_dom.shape: (54, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 25 | Accuracy: 0.4074 | Loss: 4.3537 | F1: 0.4127\n",
      "\n",
      "Domain: 26\n",
      "x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 26 | Accuracy: 0.4524 | Loss: 2.9304 | F1: 0.5000\n",
      "\n",
      "Domain: 27\n",
      "x_dp_dom.shape: (54, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 27 | Accuracy: 0.7593 | Loss: 2.6379 | F1: 0.6741\n",
      "\n",
      "Domain: 28\n",
      "x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 28 | Accuracy: 0.7143 | Loss: 1.6092 | F1: 0.7064\n",
      "\n",
      "Domain: 29\n",
      "x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 29 | Accuracy: 0.1905 | Loss: 5.6012 | F1: 0.1551\n",
      "\n",
      "Domain: 30\n",
      "x_dp_dom.shape: (50, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 30 | Accuracy: 0.5800 | Loss: 3.4246 | F1: 0.5713\n",
      "\n",
      "Domain: 31\n",
      "x_dp_dom.shape: (43, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 31 | Accuracy: 0.4419 | Loss: 2.3654 | F1: 0.4868\n",
      "\n",
      "Domain: 32\n",
      "x_dp_dom.shape: (52, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 32 | Accuracy: 0.6923 | Loss: 3.0042 | F1: 0.6613\n",
      "\n",
      "Domain: 33\n",
      "x_dp_dom.shape: (44, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 33 | Accuracy: 0.6364 | Loss: 1.5688 | F1: 0.6618\n",
      "\n",
      "Domain: 34\n",
      "x_dp_dom.shape: (49, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 34 | Accuracy: 0.4082 | Loss: 4.5986 | F1: 0.4461\n",
      "\n",
      "Domain: 35\n",
      "x_dp_dom.shape: (48, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 35 | Accuracy: 0.8333 | Loss: 1.4153 | F1: 0.7798\n",
      "\n",
      "Domain: 36\n",
      "x_dp_dom.shape: (43, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 36 | Accuracy: 0.4186 | Loss: 3.0346 | F1: 0.4673\n",
      "\n",
      "Domain: 37\n",
      "x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 37 | Accuracy: 0.8571 | Loss: 2.1946 | F1: 0.8052\n",
      "\n",
      "Domain: 38\n",
      "x_dp_dom.shape: (47, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 38 | Accuracy: 0.6170 | Loss: 1.7703 | F1: 0.6403\n",
      "\n",
      "Domain: 39\n",
      "x_dp_dom.shape: (54, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 39 | Accuracy: 0.4074 | Loss: 5.8371 | F1: 0.3682\n",
      "\n",
      "Domain: 40\n",
      "x_dp_dom.shape: (44, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 40 | Accuracy: 0.7727 | Loss: 2.7566 | F1: 0.7275\n",
      "\n",
      "Domain: 41\n",
      "x_dp_dom.shape: (45, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 41 | Accuracy: 0.6444 | Loss: 2.9651 | F1: 0.5931\n",
      "\n",
      "Domain: 42\n",
      "x_dp_dom.shape: (46, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 42 | Accuracy: 0.8478 | Loss: 1.2113 | F1: 0.7901\n",
      "\n",
      "Domain: 43\n",
      "x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 43 | Accuracy: 0.5714 | Loss: 4.0287 | F1: 0.6039\n",
      "\n",
      "Domain: 44\n",
      "x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 44 | Accuracy: 0.3571 | Loss: 2.7078 | F1: 0.3934\n",
      "\n",
      "Domain: 45\n",
      "x_dp_dom.shape: (52, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 45 | Accuracy: 0.5962 | Loss: 2.5557 | F1: 0.5971\n",
      "\n",
      "Domain: 46\n",
      "x_dp_dom.shape: (48, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 46 | Accuracy: 0.2917 | Loss: 4.0187 | F1: 0.2712\n",
      "\n",
      "Domain: 47\n",
      "x_dp_dom.shape: (44, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 47 | Accuracy: 0.6136 | Loss: 1.2935 | F1: 0.6285\n",
      "\n",
      "Domain: 48\n",
      "x_dp_dom.shape: (48, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 48 | Accuracy: 0.8125 | Loss: 0.5160 | F1: 0.7976\n",
      "\n",
      "Domain: 49\n",
      "x_dp_dom.shape: (53, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 49 | Accuracy: 0.7358 | Loss: 3.1018 | F1: 0.6682\n",
      "\n",
      "Domain: 50\n",
      "x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 50 | Accuracy: 0.8095 | Loss: 0.6444 | F1: 0.7928\n",
      "\n",
      "Domain: 51\n",
      "x_dp_dom.shape: (46, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 51 | Accuracy: 0.6304 | Loss: 1.9575 | F1: 0.6353\n",
      "\n",
      "Domain: 52\n",
      "x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 52 | Accuracy: 0.5476 | Loss: 2.0677 | F1: 0.5866\n",
      "\n",
      "Domain: 53\n",
      "x_dp_dom.shape: (48, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 53 | Accuracy: 0.7917 | Loss: 1.5769 | F1: 0.7492\n",
      "\n",
      "Domain: 54\n",
      "x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 54 | Accuracy: 0.7143 | Loss: 2.4204 | F1: 0.7124\n",
      "\n",
      "Domain: 55\n",
      "x_dp_dom.shape: (49, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 55 | Accuracy: 0.8367 | Loss: 1.3997 | F1: 0.7743\n",
      "\n",
      "Domain: 56\n",
      "x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 56 | Accuracy: 0.6905 | Loss: 1.0057 | F1: 0.6831\n",
      "\n",
      "Domain: 57\n",
      "x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 57 | Accuracy: 0.8571 | Loss: 0.3373 | F1: 0.8687\n",
      "\n",
      "Domain: 58\n",
      "x_dp_dom.shape: (38, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 58 | Accuracy: 0.7632 | Loss: 0.7555 | F1: 0.7541\n",
      "\n",
      "Domain: 59\n",
      "x_dp_dom.shape: (43, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 59 | Accuracy: 0.8140 | Loss: 0.8067 | F1: 0.7414\n",
      "\n",
      "Domain: 60\n",
      "x_dp_dom.shape: (47, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 60 | Accuracy: 0.4255 | Loss: 7.2582 | F1: 0.3949\n",
      "\n",
      "Domain: 61\n",
      "x_dp_dom.shape: (47, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 61 | Accuracy: 0.6596 | Loss: 1.5511 | F1: 0.6708\n",
      "\n",
      "Domain: 62\n",
      "x_dp_dom.shape: (47, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 62 | Accuracy: 0.6809 | Loss: 1.3537 | F1: 0.6941\n",
      "\n",
      "Domain: 63\n",
      "x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 63 | Accuracy: 0.5714 | Loss: 0.9787 | F1: 0.5797\n",
      "\n",
      "Domain: 64\n",
      "x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 64 | Accuracy: 0.6190 | Loss: 1.4137 | F1: 0.6363\n",
      "\n",
      "Domain: 65\n",
      "x_dp_dom.shape: (50, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 65 | Accuracy: 0.2600 | Loss: 7.0640 | F1: 0.1207\n",
      "\n",
      "Domain: 66\n",
      "x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 66 | Accuracy: 0.1667 | Loss: 11.4544 | F1: 0.0631\n",
      "\n",
      "Domain: 67\n",
      "x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 67 | Accuracy: 0.8333 | Loss: 1.8652 | F1: 0.8082\n",
      "\n",
      "Domain: 68\n",
      "x_dp_dom.shape: (43, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 68 | Accuracy: 0.4186 | Loss: 1.7712 | F1: 0.4665\n",
      "\n",
      "Domain: 69\n",
      "x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 69 | Accuracy: 0.1905 | Loss: 6.6925 | F1: 0.1212\n",
      "\n",
      "Domain: 70\n",
      "x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 70 | Accuracy: 0.8333 | Loss: 1.9369 | F1: 0.7716\n",
      "\n",
      "Domain: 71\n",
      "x_dp_dom.shape: (44, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 71 | Accuracy: 0.4318 | Loss: 2.1144 | F1: 0.4805\n",
      "\n",
      "Domain: 72\n",
      "x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 72 | Accuracy: 0.8095 | Loss: 0.9209 | F1: 0.7439\n",
      "\n",
      "Domain: 73\n",
      "x_dp_dom.shape: (41, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 73 | Accuracy: 0.1707 | Loss: 8.5830 | F1: 0.0824\n",
      "\n",
      "Domain: 74\n",
      "x_dp_dom.shape: (35, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 74 | Accuracy: 0.7143 | Loss: 2.3260 | F1: 0.7407\n",
      "\n",
      "Domain: 75\n",
      "x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 75 | Accuracy: 0.8333 | Loss: 0.8040 | F1: 0.7778\n",
      "\n",
      "Mean accuracy for run 4: 0.5994\n",
      "Mean F1 for run 4: 0.5765\n",
      "\n",
      "Source class: WAL\n",
      "\n",
      "x_df.shape: (7958, 3, 128) | np.unique(y_df): [1 2 3]\n",
      "\n",
      "Training on Df data...\n",
      "\tEpoch 10/100 - Train loss: 0.0296 - Val accuracy: 0.9799 - Val loss: 0.0545 - Val F1: 0.9799 - LR: 9.00e-05\n",
      "\tEpoch 20/100 - Train loss: 0.0086 - Val accuracy: 0.9856 - Val loss: 0.0441 - Val F1: 0.9856 - LR: 8.00e-05\n",
      "\tEpoch 30/100 - Train loss: 0.0042 - Val accuracy: 0.9862 - Val loss: 0.0480 - Val F1: 0.9862 - LR: 7.00e-05\n",
      "\tEpoch 40/100 - Train loss: 0.0021 - Val accuracy: 0.9874 - Val loss: 0.0490 - Val F1: 0.9874 - LR: 6.00e-05\n",
      "\tEpoch 50/100 - Train loss: 0.0014 - Val accuracy: 0.9881 - Val loss: 0.0532 - Val F1: 0.9881 - LR: 5.00e-05\n",
      "\tEpoch 60/100 - Train loss: 0.0005 - Val accuracy: 0.9868 - Val loss: 0.0549 - Val F1: 0.9868 - LR: 4.00e-05\n",
      "\tEpoch 70/100 - Train loss: 0.0004 - Val accuracy: 0.9862 - Val loss: 0.0571 - Val F1: 0.9862 - LR: 3.00e-05\n",
      "\tEpoch 80/100 - Train loss: 0.0003 - Val accuracy: 0.9868 - Val loss: 0.0573 - Val F1: 0.9868 - LR: 2.00e-05\n",
      "\tEpoch 90/100 - Train loss: 0.0002 - Val accuracy: 0.9849 - Val loss: 0.0631 - Val F1: 0.9849 - LR: 1.00e-05\n",
      "\tEpoch 100/100 - Train loss: 0.0001 - Val accuracy: 0.9868 - Val loss: 0.0592 - Val F1: 0.9868 - LR: 0.00e+00\n",
      "\tBest epoch: 26 - Best val accuracy: 0.9843 - Best val loss: 0.0412 - Best val F1: 0.9843\n",
      "\n",
      "Domain: 15\n",
      "x_dp_dom.shape: (50, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 15 | Accuracy: 0.2400 | Loss: 21.1776 | F1: 0.0929\n",
      "\n",
      "Domain: 16\n",
      "x_dp_dom.shape: (54, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 16 | Accuracy: 0.5926 | Loss: 11.7412 | F1: 0.5496\n",
      "\n",
      "Domain: 17\n",
      "x_dp_dom.shape: (53, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 17 | Accuracy: 0.5094 | Loss: 13.0652 | F1: 0.4748\n",
      "\n",
      "Domain: 18\n",
      "x_dp_dom.shape: (54, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 18 | Accuracy: 0.7222 | Loss: 12.0864 | F1: 0.6520\n",
      "\n",
      "Domain: 19\n",
      "x_dp_dom.shape: (54, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 19 | Accuracy: 0.7037 | Loss: 11.6321 | F1: 0.6382\n",
      "\n",
      "Domain: 20\n",
      "x_dp_dom.shape: (51, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 20 | Accuracy: 0.5490 | Loss: 9.2565 | F1: 0.5574\n",
      "\n",
      "Domain: 21\n",
      "x_dp_dom.shape: (47, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 21 | Accuracy: 0.6809 | Loss: 7.8040 | F1: 0.6536\n",
      "\n",
      "Domain: 22\n",
      "x_dp_dom.shape: (54, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 22 | Accuracy: 0.7407 | Loss: 10.7683 | F1: 0.6656\n",
      "\n",
      "Domain: 23\n",
      "x_dp_dom.shape: (52, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 23 | Accuracy: 0.6923 | Loss: 9.5862 | F1: 0.6404\n",
      "\n",
      "Domain: 24\n",
      "x_dp_dom.shape: (51, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 24 | Accuracy: 0.3333 | Loss: 13.6286 | F1: 0.3285\n",
      "\n",
      "Domain: 25\n",
      "x_dp_dom.shape: (54, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 25 | Accuracy: 0.7222 | Loss: 12.1021 | F1: 0.6520\n",
      "\n",
      "Domain: 26\n",
      "x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 26 | Accuracy: 0.5000 | Loss: 7.7346 | F1: 0.5222\n",
      "\n",
      "Domain: 27\n",
      "x_dp_dom.shape: (54, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 27 | Accuracy: 0.2778 | Loss: 13.0960 | F1: 0.1654\n",
      "\n",
      "Domain: 28\n",
      "x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 28 | Accuracy: 0.8333 | Loss: 7.0542 | F1: 0.7778\n",
      "\n",
      "Domain: 29\n",
      "x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 29 | Accuracy: 0.8095 | Loss: 7.2915 | F1: 0.7606\n",
      "\n",
      "Domain: 30\n",
      "x_dp_dom.shape: (50, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 30 | Accuracy: 0.5400 | Loss: 8.8834 | F1: 0.5148\n",
      "\n",
      "Domain: 31\n",
      "x_dp_dom.shape: (43, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 31 | Accuracy: 0.7209 | Loss: 7.8287 | F1: 0.6936\n",
      "\n",
      "Domain: 32\n",
      "x_dp_dom.shape: (52, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 32 | Accuracy: 0.6346 | Loss: 7.9270 | F1: 0.5932\n",
      "\n",
      "Domain: 33\n",
      "x_dp_dom.shape: (44, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 33 | Accuracy: 0.8409 | Loss: 5.9203 | F1: 0.7836\n",
      "\n",
      "Domain: 34\n",
      "x_dp_dom.shape: (49, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 34 | Accuracy: 0.6122 | Loss: 7.7503 | F1: 0.5866\n",
      "\n",
      "Domain: 35\n",
      "x_dp_dom.shape: (48, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 35 | Accuracy: 0.7500 | Loss: 6.9900 | F1: 0.7115\n",
      "\n",
      "Domain: 36\n",
      "x_dp_dom.shape: (43, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 36 | Accuracy: 0.6977 | Loss: 7.3993 | F1: 0.6757\n",
      "\n",
      "Domain: 37\n",
      "x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 37 | Accuracy: 0.7857 | Loss: 5.3160 | F1: 0.7559\n",
      "\n",
      "Domain: 38\n",
      "x_dp_dom.shape: (47, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 38 | Accuracy: 0.8298 | Loss: 7.2287 | F1: 0.7764\n",
      "\n",
      "Domain: 39\n",
      "x_dp_dom.shape: (54, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 39 | Accuracy: 0.2778 | Loss: 20.6554 | F1: 0.1654\n",
      "\n",
      "Domain: 40\n",
      "x_dp_dom.shape: (44, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 40 | Accuracy: 0.7045 | Loss: 5.4334 | F1: 0.6788\n",
      "\n",
      "Domain: 41\n",
      "x_dp_dom.shape: (45, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 41 | Accuracy: 0.2444 | Loss: 10.4970 | F1: 0.1253\n",
      "\n",
      "Domain: 42\n",
      "x_dp_dom.shape: (46, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 42 | Accuracy: 0.3261 | Loss: 9.2954 | F1: 0.2514\n",
      "\n",
      "Domain: 43\n",
      "x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 43 | Accuracy: 0.5714 | Loss: 11.0059 | F1: 0.5766\n",
      "\n",
      "Domain: 44\n",
      "x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 44 | Accuracy: 0.8333 | Loss: 7.4811 | F1: 0.7778\n",
      "\n",
      "Domain: 45\n",
      "x_dp_dom.shape: (52, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 45 | Accuracy: 0.7692 | Loss: 8.7906 | F1: 0.6997\n",
      "\n",
      "Domain: 46\n",
      "x_dp_dom.shape: (48, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 46 | Accuracy: 0.8542 | Loss: 7.1212 | F1: 0.7967\n",
      "\n",
      "Domain: 47\n",
      "x_dp_dom.shape: (44, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 47 | Accuracy: 0.7273 | Loss: 7.7671 | F1: 0.6967\n",
      "\n",
      "Domain: 48\n",
      "x_dp_dom.shape: (48, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 48 | Accuracy: 0.8333 | Loss: 7.4603 | F1: 0.7708\n",
      "\n",
      "Domain: 49\n",
      "x_dp_dom.shape: (53, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 49 | Accuracy: 0.4528 | Loss: 10.2107 | F1: 0.4140\n",
      "\n",
      "Domain: 50\n",
      "x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 50 | Accuracy: 0.7619 | Loss: 6.0505 | F1: 0.7063\n",
      "\n",
      "Domain: 51\n",
      "x_dp_dom.shape: (46, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 51 | Accuracy: 0.8043 | Loss: 7.5799 | F1: 0.7391\n",
      "\n",
      "Domain: 52\n",
      "x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 52 | Accuracy: 0.8095 | Loss: 7.4488 | F1: 0.7606\n",
      "\n",
      "Domain: 53\n",
      "x_dp_dom.shape: (48, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 53 | Accuracy: 0.7292 | Loss: 7.6231 | F1: 0.7026\n",
      "\n",
      "Domain: 54\n",
      "x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 54 | Accuracy: 0.6429 | Loss: 5.3649 | F1: 0.6667\n",
      "\n",
      "Domain: 55\n",
      "x_dp_dom.shape: (49, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 55 | Accuracy: 0.8367 | Loss: 7.1630 | F1: 0.7743\n",
      "\n",
      "Domain: 56\n",
      "x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 56 | Accuracy: 0.8333 | Loss: 6.3084 | F1: 0.7778\n",
      "\n",
      "Domain: 57\n",
      "x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 57 | Accuracy: 0.8095 | Loss: 5.7755 | F1: 0.7606\n",
      "\n",
      "Domain: 58\n",
      "x_dp_dom.shape: (38, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 58 | Accuracy: 0.4737 | Loss: 6.1411 | F1: 0.5550\n",
      "\n",
      "Domain: 59\n",
      "x_dp_dom.shape: (43, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 59 | Accuracy: 0.8372 | Loss: 7.3545 | F1: 0.7806\n",
      "\n",
      "Domain: 60\n",
      "x_dp_dom.shape: (47, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 60 | Accuracy: 0.3404 | Loss: 13.2908 | F1: 0.2777\n",
      "\n",
      "Domain: 61\n",
      "x_dp_dom.shape: (47, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 61 | Accuracy: 0.3404 | Loss: 9.3857 | F1: 0.2603\n",
      "\n",
      "Domain: 62\n",
      "x_dp_dom.shape: (47, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 62 | Accuracy: 0.7872 | Loss: 6.1872 | F1: 0.7422\n",
      "\n",
      "Domain: 63\n",
      "x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 63 | Accuracy: 0.6905 | Loss: 8.0579 | F1: 0.6731\n",
      "\n",
      "Domain: 64\n",
      "x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 64 | Accuracy: 0.8333 | Loss: 7.5348 | F1: 0.7778\n",
      "\n",
      "Domain: 65\n",
      "x_dp_dom.shape: (50, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 65 | Accuracy: 0.6800 | Loss: 6.2025 | F1: 0.6410\n",
      "\n",
      "Domain: 66\n",
      "x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 66 | Accuracy: 0.1667 | Loss: 18.8704 | F1: 0.0476\n",
      "\n",
      "Domain: 67\n",
      "x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 67 | Accuracy: 0.6667 | Loss: 5.8028 | F1: 0.6825\n",
      "\n",
      "Domain: 68\n",
      "x_dp_dom.shape: (43, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 68 | Accuracy: 0.7209 | Loss: 7.3055 | F1: 0.6936\n",
      "\n",
      "Domain: 69\n",
      "x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 69 | Accuracy: 0.2381 | Loss: 14.1356 | F1: 0.1798\n",
      "\n",
      "Domain: 70\n",
      "x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 70 | Accuracy: 0.2619 | Loss: 9.9479 | F1: 0.2185\n",
      "\n",
      "Domain: 71\n",
      "x_dp_dom.shape: (44, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 71 | Accuracy: 0.8409 | Loss: 6.5313 | F1: 0.7836\n",
      "\n",
      "Domain: 72\n",
      "x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 72 | Accuracy: 0.8095 | Loss: 7.6001 | F1: 0.7606\n",
      "\n",
      "Domain: 73\n",
      "x_dp_dom.shape: (41, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 73 | Accuracy: 0.1707 | Loss: 12.7360 | F1: 0.0498\n",
      "\n",
      "Domain: 74\n",
      "x_dp_dom.shape: (35, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 74 | Accuracy: 0.8286 | Loss: 2.0862 | F1: 0.8020\n",
      "\n",
      "Domain: 75\n",
      "x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 75 | Accuracy: 0.8095 | Loss: 7.2701 | F1: 0.7606\n",
      "\n",
      "Mean accuracy for run 5: 0.6334\n",
      "Mean F1 for run 5: 0.5861\n",
      "\n",
      "Source class: WAL\n",
      "\n",
      "x_df.shape: (7958, 3, 128) | np.unique(y_df): [1 2 3]\n",
      "\n",
      "Training on Df data...\n",
      "\tEpoch 10/100 - Train loss: 0.0373 - Val accuracy: 0.9780 - Val loss: 0.0589 - Val F1: 0.9780 - LR: 9.00e-05\n",
      "\tEpoch 20/100 - Train loss: 0.0116 - Val accuracy: 0.9843 - Val loss: 0.0493 - Val F1: 0.9843 - LR: 8.00e-05\n",
      "\tEpoch 30/100 - Train loss: 0.0031 - Val accuracy: 0.9874 - Val loss: 0.0499 - Val F1: 0.9874 - LR: 7.00e-05\n",
      "\tEpoch 40/100 - Train loss: 0.0022 - Val accuracy: 0.9862 - Val loss: 0.0553 - Val F1: 0.9862 - LR: 6.00e-05\n",
      "\tEpoch 50/100 - Train loss: 0.0010 - Val accuracy: 0.9862 - Val loss: 0.0587 - Val F1: 0.9862 - LR: 5.00e-05\n",
      "\tEpoch 60/100 - Train loss: 0.0013 - Val accuracy: 0.9881 - Val loss: 0.0580 - Val F1: 0.9881 - LR: 4.00e-05\n",
      "\tEpoch 70/100 - Train loss: 0.0007 - Val accuracy: 0.9887 - Val loss: 0.0530 - Val F1: 0.9887 - LR: 3.00e-05\n",
      "\tEpoch 80/100 - Train loss: 0.0010 - Val accuracy: 0.9893 - Val loss: 0.0563 - Val F1: 0.9893 - LR: 2.00e-05\n",
      "\tEpoch 90/100 - Train loss: 0.0002 - Val accuracy: 0.9868 - Val loss: 0.0605 - Val F1: 0.9868 - LR: 1.00e-05\n",
      "\tEpoch 100/100 - Train loss: 0.0002 - Val accuracy: 0.9874 - Val loss: 0.0610 - Val F1: 0.9874 - LR: 0.00e+00\n",
      "\tBest epoch: 25 - Best val accuracy: 0.9868 - Best val loss: 0.0449 - Best val F1: 0.9868\n",
      "\n",
      "Domain: 15\n",
      "x_dp_dom.shape: (50, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 15 | Accuracy: 0.2000 | Loss: 13.9198 | F1: 0.0833\n",
      "\n",
      "Domain: 16\n",
      "x_dp_dom.shape: (54, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 16 | Accuracy: 0.5185 | Loss: 8.3578 | F1: 0.3541\n",
      "\n",
      "Domain: 17\n",
      "x_dp_dom.shape: (53, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 17 | Accuracy: 0.5283 | Loss: 7.7595 | F1: 0.3652\n",
      "\n",
      "Domain: 18\n",
      "x_dp_dom.shape: (54, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 18 | Accuracy: 0.5185 | Loss: 7.3737 | F1: 0.3541\n",
      "\n",
      "Domain: 19\n",
      "x_dp_dom.shape: (54, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 19 | Accuracy: 0.5185 | Loss: 7.1999 | F1: 0.3541\n",
      "\n",
      "Domain: 20\n",
      "x_dp_dom.shape: (51, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 20 | Accuracy: 0.5490 | Loss: 7.3392 | F1: 0.3892\n",
      "\n",
      "Domain: 21\n",
      "x_dp_dom.shape: (47, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 21 | Accuracy: 0.5957 | Loss: 5.9701 | F1: 0.4448\n",
      "\n",
      "Domain: 22\n",
      "x_dp_dom.shape: (54, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 22 | Accuracy: 0.5185 | Loss: 9.1785 | F1: 0.3541\n",
      "\n",
      "Domain: 23\n",
      "x_dp_dom.shape: (52, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 23 | Accuracy: 0.5385 | Loss: 10.0181 | F1: 0.3769\n",
      "\n",
      "Domain: 24\n",
      "x_dp_dom.shape: (51, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 24 | Accuracy: 0.4902 | Loss: 10.9955 | F1: 0.3612\n",
      "\n",
      "Domain: 25\n",
      "x_dp_dom.shape: (54, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 25 | Accuracy: 0.5185 | Loss: 6.4144 | F1: 0.3541\n",
      "\n",
      "Domain: 26\n",
      "x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 26 | Accuracy: 0.6667 | Loss: 5.2340 | F1: 0.5333\n",
      "\n",
      "Domain: 27\n",
      "x_dp_dom.shape: (54, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 27 | Accuracy: 0.5185 | Loss: 9.1178 | F1: 0.3541\n",
      "\n",
      "Domain: 28\n",
      "x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 28 | Accuracy: 0.6667 | Loss: 6.2785 | F1: 0.5333\n",
      "\n",
      "Domain: 29\n",
      "x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 29 | Accuracy: 0.6667 | Loss: 5.6828 | F1: 0.5333\n",
      "\n",
      "Domain: 30\n",
      "x_dp_dom.shape: (50, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 30 | Accuracy: 0.6200 | Loss: 6.8654 | F1: 0.5233\n",
      "\n",
      "Domain: 31\n",
      "x_dp_dom.shape: (43, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 31 | Accuracy: 0.7209 | Loss: 3.6545 | F1: 0.6713\n",
      "\n",
      "Domain: 32\n",
      "x_dp_dom.shape: (52, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 32 | Accuracy: 0.5385 | Loss: 9.5753 | F1: 0.3769\n",
      "\n",
      "Domain: 33\n",
      "x_dp_dom.shape: (44, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 33 | Accuracy: 0.6364 | Loss: 6.6947 | F1: 0.4949\n",
      "\n",
      "Domain: 34\n",
      "x_dp_dom.shape: (49, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 34 | Accuracy: 0.3878 | Loss: 9.1803 | F1: 0.3341\n",
      "\n",
      "Domain: 35\n",
      "x_dp_dom.shape: (48, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 35 | Accuracy: 0.5833 | Loss: 4.5111 | F1: 0.4298\n",
      "\n",
      "Domain: 36\n",
      "x_dp_dom.shape: (43, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 36 | Accuracy: 0.6512 | Loss: 4.6117 | F1: 0.5136\n",
      "\n",
      "Domain: 37\n",
      "x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 37 | Accuracy: 0.6667 | Loss: 6.8244 | F1: 0.5333\n",
      "\n",
      "Domain: 38\n",
      "x_dp_dom.shape: (47, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 38 | Accuracy: 0.6596 | Loss: 6.2564 | F1: 0.5759\n",
      "\n",
      "Domain: 39\n",
      "x_dp_dom.shape: (54, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 39 | Accuracy: 0.3889 | Loss: 9.6561 | F1: 0.4178\n",
      "\n",
      "Domain: 40\n",
      "x_dp_dom.shape: (44, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 40 | Accuracy: 0.6364 | Loss: 9.8522 | F1: 0.4949\n",
      "\n",
      "Domain: 41\n",
      "x_dp_dom.shape: (45, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 41 | Accuracy: 0.6889 | Loss: 6.6453 | F1: 0.6168\n",
      "\n",
      "Domain: 42\n",
      "x_dp_dom.shape: (46, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 42 | Accuracy: 0.6739 | Loss: 7.3557 | F1: 0.5826\n",
      "\n",
      "Domain: 43\n",
      "x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 43 | Accuracy: 0.5714 | Loss: 7.3989 | F1: 0.5416\n",
      "\n",
      "Domain: 44\n",
      "x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 44 | Accuracy: 0.6667 | Loss: 5.9588 | F1: 0.5333\n",
      "\n",
      "Domain: 45\n",
      "x_dp_dom.shape: (52, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 45 | Accuracy: 0.5385 | Loss: 4.7663 | F1: 0.3769\n",
      "\n",
      "Domain: 46\n",
      "x_dp_dom.shape: (48, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 46 | Accuracy: 0.5833 | Loss: 5.2873 | F1: 0.4298\n",
      "\n",
      "Domain: 47\n",
      "x_dp_dom.shape: (44, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 47 | Accuracy: 0.6364 | Loss: 6.4425 | F1: 0.4949\n",
      "\n",
      "Domain: 48\n",
      "x_dp_dom.shape: (48, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 48 | Accuracy: 0.5833 | Loss: 8.1239 | F1: 0.4298\n",
      "\n",
      "Domain: 49\n",
      "x_dp_dom.shape: (53, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 49 | Accuracy: 0.5283 | Loss: 6.4900 | F1: 0.3652\n",
      "\n",
      "Domain: 50\n",
      "x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 50 | Accuracy: 0.6667 | Loss: 7.6032 | F1: 0.5333\n",
      "\n",
      "Domain: 51\n",
      "x_dp_dom.shape: (46, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 51 | Accuracy: 0.6522 | Loss: 8.2891 | F1: 0.5446\n",
      "\n",
      "Domain: 52\n",
      "x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 52 | Accuracy: 0.6667 | Loss: 4.0415 | F1: 0.5333\n",
      "\n",
      "Domain: 53\n",
      "x_dp_dom.shape: (48, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 53 | Accuracy: 0.5833 | Loss: 7.0645 | F1: 0.4298\n",
      "\n",
      "Domain: 54\n",
      "x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 54 | Accuracy: 0.6667 | Loss: 6.3977 | F1: 0.5333\n",
      "\n",
      "Domain: 55\n",
      "x_dp_dom.shape: (49, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 55 | Accuracy: 0.5714 | Loss: 5.3774 | F1: 0.4156\n",
      "\n",
      "Domain: 56\n",
      "x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 56 | Accuracy: 0.6667 | Loss: 6.2569 | F1: 0.5333\n",
      "\n",
      "Domain: 57\n",
      "x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 57 | Accuracy: 0.6667 | Loss: 6.8961 | F1: 0.5333\n",
      "\n",
      "Domain: 58\n",
      "x_dp_dom.shape: (38, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 58 | Accuracy: 0.7368 | Loss: 8.8413 | F1: 0.6252\n",
      "\n",
      "Domain: 59\n",
      "x_dp_dom.shape: (43, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 59 | Accuracy: 0.6512 | Loss: 7.3654 | F1: 0.5136\n",
      "\n",
      "Domain: 60\n",
      "x_dp_dom.shape: (47, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 60 | Accuracy: 0.4681 | Loss: 3.4716 | F1: 0.4972\n",
      "\n",
      "Domain: 61\n",
      "x_dp_dom.shape: (47, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 61 | Accuracy: 0.6170 | Loss: 9.4165 | F1: 0.4881\n",
      "\n",
      "Domain: 62\n",
      "x_dp_dom.shape: (47, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 62 | Accuracy: 0.5957 | Loss: 5.5941 | F1: 0.4448\n",
      "\n",
      "Domain: 63\n",
      "x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 63 | Accuracy: 0.6667 | Loss: 6.0391 | F1: 0.5411\n",
      "\n",
      "Domain: 64\n",
      "x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 64 | Accuracy: 0.6667 | Loss: 3.2040 | F1: 0.5333\n",
      "\n",
      "Domain: 65\n",
      "x_dp_dom.shape: (50, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 65 | Accuracy: 0.0000 | Loss: 12.7827 | F1: 0.0000\n",
      "\n",
      "Domain: 66\n",
      "x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 66 | Accuracy: 0.1667 | Loss: 11.7886 | F1: 0.0496\n",
      "\n",
      "Domain: 67\n",
      "x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 67 | Accuracy: 0.6667 | Loss: 7.8994 | F1: 0.5333\n",
      "\n",
      "Domain: 68\n",
      "x_dp_dom.shape: (43, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 68 | Accuracy: 0.6512 | Loss: 7.2479 | F1: 0.5136\n",
      "\n",
      "Domain: 69\n",
      "x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 69 | Accuracy: 0.0000 | Loss: 17.6039 | F1: 0.0000\n",
      "\n",
      "Domain: 70\n",
      "x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 70 | Accuracy: 0.7381 | Loss: 5.9629 | F1: 0.6818\n",
      "\n",
      "Domain: 71\n",
      "x_dp_dom.shape: (44, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 71 | Accuracy: 0.6364 | Loss: 5.8389 | F1: 0.4949\n",
      "\n",
      "Domain: 72\n",
      "x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 72 | Accuracy: 0.6667 | Loss: 6.1626 | F1: 0.5333\n",
      "\n",
      "Domain: 73\n",
      "x_dp_dom.shape: (41, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 73 | Accuracy: 0.1463 | Loss: 10.6997 | F1: 0.0374\n",
      "\n",
      "Domain: 74\n",
      "x_dp_dom.shape: (35, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 74 | Accuracy: 0.8000 | Loss: 6.1226 | F1: 0.7111\n",
      "\n",
      "Domain: 75\n",
      "x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 75 | Accuracy: 0.6667 | Loss: 5.1519 | F1: 0.5333\n",
      "\n",
      "Mean accuracy for run 6: 0.5681\n",
      "Mean F1 for run 6: 0.4471\n",
      "\n",
      "Source class: WAL\n",
      "\n",
      "x_df.shape: (7958, 3, 128) | np.unique(y_df): [1 2 3]\n",
      "\n",
      "Training on Df data...\n",
      "\tEpoch 10/100 - Train loss: 0.0296 - Val accuracy: 0.9805 - Val loss: 0.0533 - Val F1: 0.9806 - LR: 9.00e-05\n",
      "\tEpoch 20/100 - Train loss: 0.0094 - Val accuracy: 0.9824 - Val loss: 0.0510 - Val F1: 0.9824 - LR: 8.00e-05\n",
      "\tEpoch 30/100 - Train loss: 0.0036 - Val accuracy: 0.9862 - Val loss: 0.0423 - Val F1: 0.9861 - LR: 7.00e-05\n",
      "\tEpoch 40/100 - Train loss: 0.0020 - Val accuracy: 0.9881 - Val loss: 0.0435 - Val F1: 0.9881 - LR: 6.00e-05\n",
      "\tEpoch 50/100 - Train loss: 0.0009 - Val accuracy: 0.9899 - Val loss: 0.0459 - Val F1: 0.9900 - LR: 5.00e-05\n",
      "\tEpoch 60/100 - Train loss: 0.0006 - Val accuracy: 0.9881 - Val loss: 0.0491 - Val F1: 0.9881 - LR: 4.00e-05\n",
      "\tEpoch 70/100 - Train loss: 0.0006 - Val accuracy: 0.9912 - Val loss: 0.0431 - Val F1: 0.9912 - LR: 3.00e-05\n",
      "\tEpoch 80/100 - Train loss: 0.0002 - Val accuracy: 0.9881 - Val loss: 0.0477 - Val F1: 0.9881 - LR: 2.00e-05\n",
      "\tEpoch 90/100 - Train loss: 0.0001 - Val accuracy: 0.9893 - Val loss: 0.0461 - Val F1: 0.9893 - LR: 1.00e-05\n",
      "\tEpoch 100/100 - Train loss: 0.0002 - Val accuracy: 0.9887 - Val loss: 0.0492 - Val F1: 0.9887 - LR: 0.00e+00\n",
      "\tBest epoch: 22 - Best val accuracy: 0.9862 - Best val loss: 0.0386 - Best val F1: 0.9862\n",
      "\n",
      "Domain: 15\n",
      "x_dp_dom.shape: (50, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 15 | Accuracy: 0.2000 | Loss: 14.8366 | F1: 0.0800\n",
      "\n",
      "Domain: 16\n",
      "x_dp_dom.shape: (54, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 16 | Accuracy: 0.8148 | Loss: 0.5933 | F1: 0.8044\n",
      "\n",
      "Domain: 17\n",
      "x_dp_dom.shape: (53, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 17 | Accuracy: 0.5849 | Loss: 1.9157 | F1: 0.6008\n",
      "\n",
      "Domain: 18\n",
      "x_dp_dom.shape: (54, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 18 | Accuracy: 0.7963 | Loss: 0.6808 | F1: 0.7519\n",
      "\n",
      "Domain: 19\n",
      "x_dp_dom.shape: (54, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 19 | Accuracy: 0.6667 | Loss: 0.6510 | F1: 0.6803\n",
      "\n",
      "Domain: 20\n",
      "x_dp_dom.shape: (51, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 20 | Accuracy: 0.7843 | Loss: 0.7503 | F1: 0.7646\n",
      "\n",
      "Domain: 21\n",
      "x_dp_dom.shape: (47, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 21 | Accuracy: 0.8723 | Loss: 0.3828 | F1: 0.8702\n",
      "\n",
      "Domain: 22\n",
      "x_dp_dom.shape: (54, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 22 | Accuracy: 0.3333 | Loss: 3.0097 | F1: 0.3001\n",
      "\n",
      "Domain: 23\n",
      "x_dp_dom.shape: (52, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 23 | Accuracy: 0.5192 | Loss: 1.5283 | F1: 0.5530\n",
      "\n",
      "Domain: 24\n",
      "x_dp_dom.shape: (51, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 24 | Accuracy: 0.6471 | Loss: 2.6477 | F1: 0.6041\n",
      "\n",
      "Domain: 25\n",
      "x_dp_dom.shape: (54, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 25 | Accuracy: 0.5926 | Loss: 0.9038 | F1: 0.6236\n",
      "\n",
      "Domain: 26\n",
      "x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 26 | Accuracy: 0.3571 | Loss: 2.0829 | F1: 0.4152\n",
      "\n",
      "Domain: 27\n",
      "x_dp_dom.shape: (54, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 27 | Accuracy: 0.5556 | Loss: 2.5472 | F1: 0.5170\n",
      "\n",
      "Domain: 28\n",
      "x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 28 | Accuracy: 0.4048 | Loss: 4.7928 | F1: 0.4228\n",
      "\n",
      "Domain: 29\n",
      "x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 29 | Accuracy: 0.5714 | Loss: 1.2516 | F1: 0.6093\n",
      "\n",
      "Domain: 30\n",
      "x_dp_dom.shape: (50, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 30 | Accuracy: 0.3000 | Loss: 7.1942 | F1: 0.2427\n",
      "\n",
      "Domain: 31\n",
      "x_dp_dom.shape: (43, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 31 | Accuracy: 0.6977 | Loss: 1.4356 | F1: 0.7058\n",
      "\n",
      "Domain: 32\n",
      "x_dp_dom.shape: (52, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 32 | Accuracy: 0.3077 | Loss: 9.2383 | F1: 0.3193\n",
      "\n",
      "Domain: 33\n",
      "x_dp_dom.shape: (44, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 33 | Accuracy: 0.7045 | Loss: 1.0012 | F1: 0.7192\n",
      "\n",
      "Domain: 34\n",
      "x_dp_dom.shape: (49, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 34 | Accuracy: 0.4694 | Loss: 4.0321 | F1: 0.4536\n",
      "\n",
      "Domain: 35\n",
      "x_dp_dom.shape: (48, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 35 | Accuracy: 0.6250 | Loss: 0.9402 | F1: 0.6207\n",
      "\n",
      "Domain: 36\n",
      "x_dp_dom.shape: (43, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 36 | Accuracy: 0.3023 | Loss: 1.8051 | F1: 0.2628\n",
      "\n",
      "Domain: 37\n",
      "x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 37 | Accuracy: 0.5714 | Loss: 2.3501 | F1: 0.5956\n",
      "\n",
      "Domain: 38\n",
      "x_dp_dom.shape: (47, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 38 | Accuracy: 0.6383 | Loss: 3.5113 | F1: 0.6546\n",
      "\n",
      "Domain: 39\n",
      "x_dp_dom.shape: (54, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 39 | Accuracy: 0.4074 | Loss: 7.4041 | F1: 0.3621\n",
      "\n",
      "Domain: 40\n",
      "x_dp_dom.shape: (44, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 40 | Accuracy: 0.2727 | Loss: 9.1947 | F1: 0.1968\n",
      "\n",
      "Domain: 41\n",
      "x_dp_dom.shape: (45, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 41 | Accuracy: 0.4222 | Loss: 4.7245 | F1: 0.4568\n",
      "\n",
      "Domain: 42\n",
      "x_dp_dom.shape: (46, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 42 | Accuracy: 0.2826 | Loss: 5.2006 | F1: 0.1823\n",
      "\n",
      "Domain: 43\n",
      "x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 43 | Accuracy: 0.5714 | Loss: 8.7676 | F1: 0.5972\n",
      "\n",
      "Domain: 44\n",
      "x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 44 | Accuracy: 0.2143 | Loss: 2.9003 | F1: 0.1404\n",
      "\n",
      "Domain: 45\n",
      "x_dp_dom.shape: (52, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 45 | Accuracy: 0.7692 | Loss: 0.6704 | F1: 0.7587\n",
      "\n",
      "Domain: 46\n",
      "x_dp_dom.shape: (48, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 46 | Accuracy: 0.2500 | Loss: 1.8851 | F1: 0.2150\n",
      "\n",
      "Domain: 47\n",
      "x_dp_dom.shape: (44, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 47 | Accuracy: 0.8182 | Loss: 0.6484 | F1: 0.8275\n",
      "\n",
      "Domain: 48\n",
      "x_dp_dom.shape: (48, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 48 | Accuracy: 0.7917 | Loss: 0.7636 | F1: 0.7647\n",
      "\n",
      "Domain: 49\n",
      "x_dp_dom.shape: (53, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 49 | Accuracy: 0.7736 | Loss: 1.3255 | F1: 0.7214\n",
      "\n",
      "Domain: 50\n",
      "x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 50 | Accuracy: 0.8333 | Loss: 0.4894 | F1: 0.8516\n",
      "\n",
      "Domain: 51\n",
      "x_dp_dom.shape: (46, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 51 | Accuracy: 0.8913 | Loss: 1.7504 | F1: 0.8822\n",
      "\n",
      "Domain: 52\n",
      "x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 52 | Accuracy: 0.8571 | Loss: 0.3995 | F1: 0.8609\n",
      "\n",
      "Domain: 53\n",
      "x_dp_dom.shape: (48, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 53 | Accuracy: 0.7708 | Loss: 0.6896 | F1: 0.7571\n",
      "\n",
      "Domain: 54\n",
      "x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 54 | Accuracy: 0.5714 | Loss: 3.3170 | F1: 0.6098\n",
      "\n",
      "Domain: 55\n",
      "x_dp_dom.shape: (49, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 55 | Accuracy: 0.8367 | Loss: 0.3662 | F1: 0.8323\n",
      "\n",
      "Domain: 56\n",
      "x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 56 | Accuracy: 0.8810 | Loss: 0.2876 | F1: 0.8744\n",
      "\n",
      "Domain: 57\n",
      "x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 57 | Accuracy: 0.5952 | Loss: 0.8377 | F1: 0.6452\n",
      "\n",
      "Domain: 58\n",
      "x_dp_dom.shape: (38, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 58 | Accuracy: 0.8158 | Loss: 2.5133 | F1: 0.7918\n",
      "\n",
      "Domain: 59\n",
      "x_dp_dom.shape: (43, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 59 | Accuracy: 0.8372 | Loss: 0.4140 | F1: 0.8010\n",
      "\n",
      "Domain: 60\n",
      "x_dp_dom.shape: (47, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 60 | Accuracy: 0.2340 | Loss: 18.5097 | F1: 0.0903\n",
      "\n",
      "Domain: 61\n",
      "x_dp_dom.shape: (47, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 61 | Accuracy: 0.4255 | Loss: 4.2517 | F1: 0.4412\n",
      "\n",
      "Domain: 62\n",
      "x_dp_dom.shape: (47, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 62 | Accuracy: 0.5319 | Loss: 1.3511 | F1: 0.5273\n",
      "\n",
      "Domain: 63\n",
      "x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 63 | Accuracy: 0.2381 | Loss: 2.9370 | F1: 0.2230\n",
      "\n",
      "Domain: 64\n",
      "x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 64 | Accuracy: 0.7619 | Loss: 0.6601 | F1: 0.7917\n",
      "\n",
      "Domain: 65\n",
      "x_dp_dom.shape: (50, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 65 | Accuracy: 0.2600 | Loss: 20.0022 | F1: 0.1073\n",
      "\n",
      "Domain: 66\n",
      "x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 66 | Accuracy: 0.1905 | Loss: 19.0618 | F1: 0.0946\n",
      "\n",
      "Domain: 67\n",
      "x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 67 | Accuracy: 0.8095 | Loss: 3.1374 | F1: 0.7606\n",
      "\n",
      "Domain: 68\n",
      "x_dp_dom.shape: (43, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 68 | Accuracy: 0.9302 | Loss: 0.1813 | F1: 0.9296\n",
      "\n",
      "Domain: 69\n",
      "x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 69 | Accuracy: 0.1905 | Loss: 15.2952 | F1: 0.1292\n",
      "\n",
      "Domain: 70\n",
      "x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 70 | Accuracy: 0.6667 | Loss: 4.2224 | F1: 0.6548\n",
      "\n",
      "Domain: 71\n",
      "x_dp_dom.shape: (44, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 71 | Accuracy: 0.7045 | Loss: 0.7518 | F1: 0.6793\n",
      "\n",
      "Domain: 72\n",
      "x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 72 | Accuracy: 0.7381 | Loss: 0.6246 | F1: 0.7255\n",
      "\n",
      "Domain: 73\n",
      "x_dp_dom.shape: (41, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 73 | Accuracy: 0.1707 | Loss: 23.9296 | F1: 0.0498\n",
      "\n",
      "Domain: 74\n",
      "x_dp_dom.shape: (35, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 74 | Accuracy: 0.4571 | Loss: 5.3584 | F1: 0.5005\n",
      "\n",
      "Domain: 75\n",
      "x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 75 | Accuracy: 0.3333 | Loss: 2.4488 | F1: 0.3491\n",
      "\n",
      "Mean accuracy for run 7: 0.5643\n",
      "Mean F1 for run 7: 0.5468\n",
      "\n",
      "Source class: WAL\n",
      "\n",
      "x_df.shape: (7958, 3, 128) | np.unique(y_df): [1 2 3]\n",
      "\n",
      "Training on Df data...\n",
      "\tEpoch 10/100 - Train loss: 0.0318 - Val accuracy: 0.9824 - Val loss: 0.0507 - Val F1: 0.9824 - LR: 9.00e-05\n",
      "\tEpoch 20/100 - Train loss: 0.0068 - Val accuracy: 0.9843 - Val loss: 0.0486 - Val F1: 0.9843 - LR: 8.00e-05\n",
      "\tEpoch 30/100 - Train loss: 0.0040 - Val accuracy: 0.9849 - Val loss: 0.0386 - Val F1: 0.9849 - LR: 7.00e-05\n",
      "\tEpoch 40/100 - Train loss: 0.0023 - Val accuracy: 0.9843 - Val loss: 0.0490 - Val F1: 0.9843 - LR: 6.00e-05\n",
      "\tEpoch 50/100 - Train loss: 0.0010 - Val accuracy: 0.9830 - Val loss: 0.0544 - Val F1: 0.9830 - LR: 5.00e-05\n",
      "\tEpoch 60/100 - Train loss: 0.0004 - Val accuracy: 0.9868 - Val loss: 0.0439 - Val F1: 0.9868 - LR: 4.00e-05\n",
      "\tEpoch 70/100 - Train loss: 0.0009 - Val accuracy: 0.9881 - Val loss: 0.0425 - Val F1: 0.9881 - LR: 3.00e-05\n",
      "\tEpoch 80/100 - Train loss: 0.0001 - Val accuracy: 0.9856 - Val loss: 0.0474 - Val F1: 0.9855 - LR: 2.00e-05\n",
      "\tEpoch 90/100 - Train loss: 0.0002 - Val accuracy: 0.9856 - Val loss: 0.0530 - Val F1: 0.9856 - LR: 1.00e-05\n",
      "\tEpoch 100/100 - Train loss: 0.0002 - Val accuracy: 0.9862 - Val loss: 0.0494 - Val F1: 0.9862 - LR: 0.00e+00\n",
      "\tBest epoch: 22 - Best val accuracy: 0.9862 - Best val loss: 0.0373 - Best val F1: 0.9862\n",
      "\n",
      "Domain: 15\n",
      "x_dp_dom.shape: (50, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 15 | Accuracy: 0.2400 | Loss: 13.9610 | F1: 0.1340\n",
      "\n",
      "Domain: 16\n",
      "x_dp_dom.shape: (54, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 16 | Accuracy: 0.3519 | Loss: 6.6565 | F1: 0.2511\n",
      "\n",
      "Domain: 17\n",
      "x_dp_dom.shape: (53, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 17 | Accuracy: 0.2830 | Loss: 7.0662 | F1: 0.1987\n",
      "\n",
      "Domain: 18\n",
      "x_dp_dom.shape: (54, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 18 | Accuracy: 0.3889 | Loss: 3.7096 | F1: 0.3329\n",
      "\n",
      "Domain: 19\n",
      "x_dp_dom.shape: (54, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 19 | Accuracy: 0.4074 | Loss: 9.8684 | F1: 0.2953\n",
      "\n",
      "Domain: 20\n",
      "x_dp_dom.shape: (51, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 20 | Accuracy: 0.3922 | Loss: 5.4156 | F1: 0.3233\n",
      "\n",
      "Domain: 21\n",
      "x_dp_dom.shape: (47, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 21 | Accuracy: 0.3191 | Loss: 7.2210 | F1: 0.2496\n",
      "\n",
      "Domain: 22\n",
      "x_dp_dom.shape: (54, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 22 | Accuracy: 0.3148 | Loss: 8.3874 | F1: 0.2126\n",
      "\n",
      "Domain: 23\n",
      "x_dp_dom.shape: (52, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 23 | Accuracy: 0.3654 | Loss: 9.5882 | F1: 0.2751\n",
      "\n",
      "Domain: 24\n",
      "x_dp_dom.shape: (51, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 24 | Accuracy: 0.3529 | Loss: 3.6638 | F1: 0.3363\n",
      "\n",
      "Domain: 25\n",
      "x_dp_dom.shape: (54, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 25 | Accuracy: 0.2407 | Loss: 8.2834 | F1: 0.1605\n",
      "\n",
      "Domain: 26\n",
      "x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 26 | Accuracy: 0.1905 | Loss: 13.1553 | F1: 0.0903\n",
      "\n",
      "Domain: 27\n",
      "x_dp_dom.shape: (54, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 27 | Accuracy: 0.3519 | Loss: 6.3285 | F1: 0.2511\n",
      "\n",
      "Domain: 28\n",
      "x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 28 | Accuracy: 0.2381 | Loss: 10.8371 | F1: 0.1507\n",
      "\n",
      "Domain: 29\n",
      "x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 29 | Accuracy: 0.3333 | Loss: 10.4253 | F1: 0.2222\n",
      "\n",
      "Domain: 30\n",
      "x_dp_dom.shape: (50, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 30 | Accuracy: 0.2600 | Loss: 11.6944 | F1: 0.1876\n",
      "\n",
      "Domain: 31\n",
      "x_dp_dom.shape: (43, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 31 | Accuracy: 0.3256 | Loss: 11.1821 | F1: 0.2227\n",
      "\n",
      "Domain: 32\n",
      "x_dp_dom.shape: (52, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 32 | Accuracy: 0.2692 | Loss: 8.4772 | F1: 0.1911\n",
      "\n",
      "Domain: 33\n",
      "x_dp_dom.shape: (44, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 33 | Accuracy: 0.2955 | Loss: 9.7710 | F1: 0.2131\n",
      "\n",
      "Domain: 34\n",
      "x_dp_dom.shape: (49, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 34 | Accuracy: 0.2449 | Loss: 9.2318 | F1: 0.1429\n",
      "\n",
      "Domain: 35\n",
      "x_dp_dom.shape: (48, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 35 | Accuracy: 0.3750 | Loss: 9.1666 | F1: 0.2879\n",
      "\n",
      "Domain: 36\n",
      "x_dp_dom.shape: (43, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 36 | Accuracy: 0.3256 | Loss: 10.6807 | F1: 0.2266\n",
      "\n",
      "Domain: 37\n",
      "x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 37 | Accuracy: 0.2143 | Loss: 7.0765 | F1: 0.1420\n",
      "\n",
      "Domain: 38\n",
      "x_dp_dom.shape: (47, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 38 | Accuracy: 0.2979 | Loss: 7.6509 | F1: 0.2342\n",
      "\n",
      "Domain: 39\n",
      "x_dp_dom.shape: (54, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 39 | Accuracy: 0.2778 | Loss: 10.5574 | F1: 0.1529\n",
      "\n",
      "Domain: 40\n",
      "x_dp_dom.shape: (44, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 40 | Accuracy: 0.1818 | Loss: 8.5653 | F1: 0.1364\n",
      "\n",
      "Domain: 41\n",
      "x_dp_dom.shape: (45, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 41 | Accuracy: 0.0667 | Loss: 11.3143 | F1: 0.0565\n",
      "\n",
      "Domain: 42\n",
      "x_dp_dom.shape: (46, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 42 | Accuracy: 0.3696 | Loss: 9.6760 | F1: 0.2733\n",
      "\n",
      "Domain: 43\n",
      "x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 43 | Accuracy: 0.0952 | Loss: 11.7525 | F1: 0.0563\n",
      "\n",
      "Domain: 44\n",
      "x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 44 | Accuracy: 0.3333 | Loss: 13.0450 | F1: 0.2222\n",
      "\n",
      "Domain: 45\n",
      "x_dp_dom.shape: (52, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 45 | Accuracy: 0.4231 | Loss: 8.4987 | F1: 0.3115\n",
      "\n",
      "Domain: 46\n",
      "x_dp_dom.shape: (48, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 46 | Accuracy: 0.3750 | Loss: 9.8424 | F1: 0.2917\n",
      "\n",
      "Domain: 47\n",
      "x_dp_dom.shape: (44, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 47 | Accuracy: 0.1818 | Loss: 9.0760 | F1: 0.0855\n",
      "\n",
      "Domain: 48\n",
      "x_dp_dom.shape: (48, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 48 | Accuracy: 0.6458 | Loss: 1.3266 | F1: 0.6882\n",
      "\n",
      "Domain: 49\n",
      "x_dp_dom.shape: (53, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 49 | Accuracy: 0.4151 | Loss: 7.7662 | F1: 0.3031\n",
      "\n",
      "Domain: 50\n",
      "x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 50 | Accuracy: 0.3571 | Loss: 5.0494 | F1: 0.3532\n",
      "\n",
      "Domain: 51\n",
      "x_dp_dom.shape: (46, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 51 | Accuracy: 0.2391 | Loss: 6.0715 | F1: 0.2344\n",
      "\n",
      "Domain: 52\n",
      "x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 52 | Accuracy: 0.3095 | Loss: 9.9662 | F1: 0.2043\n",
      "\n",
      "Domain: 53\n",
      "x_dp_dom.shape: (48, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 53 | Accuracy: 0.2708 | Loss: 5.0062 | F1: 0.2175\n",
      "\n",
      "Domain: 54\n",
      "x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 54 | Accuracy: 0.3095 | Loss: 12.4228 | F1: 0.2043\n",
      "\n",
      "Domain: 55\n",
      "x_dp_dom.shape: (49, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 55 | Accuracy: 0.3878 | Loss: 8.6542 | F1: 0.2930\n",
      "\n",
      "Domain: 56\n",
      "x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 56 | Accuracy: 0.2143 | Loss: 5.0845 | F1: 0.1373\n",
      "\n",
      "Domain: 57\n",
      "x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 57 | Accuracy: 0.1667 | Loss: 10.4444 | F1: 0.0476\n",
      "\n",
      "Domain: 58\n",
      "x_dp_dom.shape: (38, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 58 | Accuracy: 0.1316 | Loss: 16.1144 | F1: 0.0306\n",
      "\n",
      "Domain: 59\n",
      "x_dp_dom.shape: (43, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 59 | Accuracy: 0.4884 | Loss: 2.0844 | F1: 0.5284\n",
      "\n",
      "Domain: 60\n",
      "x_dp_dom.shape: (47, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 60 | Accuracy: 0.2340 | Loss: 15.3968 | F1: 0.1144\n",
      "\n",
      "Domain: 61\n",
      "x_dp_dom.shape: (47, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 61 | Accuracy: 0.3404 | Loss: 8.2207 | F1: 0.2636\n",
      "\n",
      "Domain: 62\n",
      "x_dp_dom.shape: (47, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 62 | Accuracy: 0.3830 | Loss: 9.2767 | F1: 0.2927\n",
      "\n",
      "Domain: 63\n",
      "x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 63 | Accuracy: 0.1905 | Loss: 10.8360 | F1: 0.0903\n",
      "\n",
      "Domain: 64\n",
      "x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 64 | Accuracy: 0.2857 | Loss: 6.5196 | F1: 0.1919\n",
      "\n",
      "Domain: 65\n",
      "x_dp_dom.shape: (50, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 65 | Accuracy: 0.3200 | Loss: 9.1723 | F1: 0.1885\n",
      "\n",
      "Domain: 66\n",
      "x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 66 | Accuracy: 0.1429 | Loss: 13.9510 | F1: 0.0667\n",
      "\n",
      "Domain: 67\n",
      "x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 67 | Accuracy: 0.2619 | Loss: 8.8661 | F1: 0.1714\n",
      "\n",
      "Domain: 68\n",
      "x_dp_dom.shape: (43, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 68 | Accuracy: 0.1860 | Loss: 7.4452 | F1: 0.0879\n",
      "\n",
      "Domain: 69\n",
      "x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 69 | Accuracy: 0.1905 | Loss: 10.8035 | F1: 0.0794\n",
      "\n",
      "Domain: 70\n",
      "x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 70 | Accuracy: 0.2381 | Loss: 5.7997 | F1: 0.1587\n",
      "\n",
      "Domain: 71\n",
      "x_dp_dom.shape: (44, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 71 | Accuracy: 0.3182 | Loss: 8.7071 | F1: 0.2296\n",
      "\n",
      "Domain: 72\n",
      "x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 72 | Accuracy: 0.1905 | Loss: 9.2796 | F1: 0.0903\n",
      "\n",
      "Domain: 73\n",
      "x_dp_dom.shape: (41, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 73 | Accuracy: 0.1707 | Loss: 17.4466 | F1: 0.0509\n",
      "\n",
      "Domain: 74\n",
      "x_dp_dom.shape: (35, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 74 | Accuracy: 0.0000 | Loss: 16.1134 | F1: 0.0000\n",
      "\n",
      "Domain: 75\n",
      "x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 75 | Accuracy: 0.2857 | Loss: 9.3218 | F1: 0.1919\n",
      "\n",
      "Mean accuracy for run 8: 0.2845\n",
      "Mean F1 for run 8: 0.2037\n",
      "\n",
      "Source class: WAL\n",
      "\n",
      "x_df.shape: (7958, 3, 128) | np.unique(y_df): [1 2 3]\n",
      "\n",
      "Training on Df data...\n",
      "\tEpoch 10/100 - Train loss: 0.0336 - Val accuracy: 0.9805 - Val loss: 0.0539 - Val F1: 0.9805 - LR: 9.00e-05\n",
      "\tEpoch 20/100 - Train loss: 0.0179 - Val accuracy: 0.9843 - Val loss: 0.0408 - Val F1: 0.9843 - LR: 8.00e-05\n",
      "\tEpoch 30/100 - Train loss: 0.0043 - Val accuracy: 0.9881 - Val loss: 0.0386 - Val F1: 0.9881 - LR: 7.00e-05\n",
      "\tEpoch 40/100 - Train loss: 0.0034 - Val accuracy: 0.9893 - Val loss: 0.0398 - Val F1: 0.9893 - LR: 6.00e-05\n",
      "\tEpoch 50/100 - Train loss: 0.0014 - Val accuracy: 0.9881 - Val loss: 0.0478 - Val F1: 0.9880 - LR: 5.00e-05\n",
      "\tEpoch 60/100 - Train loss: 0.0005 - Val accuracy: 0.9899 - Val loss: 0.0426 - Val F1: 0.9899 - LR: 4.00e-05\n",
      "\tEpoch 70/100 - Train loss: 0.0004 - Val accuracy: 0.9893 - Val loss: 0.0439 - Val F1: 0.9893 - LR: 3.00e-05\n",
      "\tEpoch 80/100 - Train loss: 0.0003 - Val accuracy: 0.9899 - Val loss: 0.0445 - Val F1: 0.9899 - LR: 2.00e-05\n",
      "\tEpoch 90/100 - Train loss: 0.0003 - Val accuracy: 0.9893 - Val loss: 0.0484 - Val F1: 0.9893 - LR: 1.00e-05\n",
      "\tEpoch 100/100 - Train loss: 0.0003 - Val accuracy: 0.9899 - Val loss: 0.0441 - Val F1: 0.9899 - LR: 0.00e+00\n",
      "\tBest epoch: 26 - Best val accuracy: 0.9893 - Best val loss: 0.0370 - Best val F1: 0.9893\n",
      "\n",
      "Domain: 15\n",
      "x_dp_dom.shape: (50, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 15 | Accuracy: 0.2400 | Loss: 21.6806 | F1: 0.0929\n",
      "\n",
      "Domain: 16\n",
      "x_dp_dom.shape: (54, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 16 | Accuracy: 0.4444 | Loss: 7.5385 | F1: 0.4043\n",
      "\n",
      "Domain: 17\n",
      "x_dp_dom.shape: (53, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 17 | Accuracy: 0.4340 | Loss: 8.7880 | F1: 0.3919\n",
      "\n",
      "Domain: 18\n",
      "x_dp_dom.shape: (54, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 18 | Accuracy: 0.7407 | Loss: 5.5925 | F1: 0.6605\n",
      "\n",
      "Domain: 19\n",
      "x_dp_dom.shape: (54, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 19 | Accuracy: 0.7037 | Loss: 6.8300 | F1: 0.6382\n",
      "\n",
      "Domain: 20\n",
      "x_dp_dom.shape: (51, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 20 | Accuracy: 0.7451 | Loss: 5.2088 | F1: 0.6879\n",
      "\n",
      "Domain: 21\n",
      "x_dp_dom.shape: (47, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 21 | Accuracy: 0.8085 | Loss: 3.5103 | F1: 0.7594\n",
      "\n",
      "Domain: 22\n",
      "x_dp_dom.shape: (54, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 22 | Accuracy: 0.7222 | Loss: 6.1665 | F1: 0.6378\n",
      "\n",
      "Domain: 23\n",
      "x_dp_dom.shape: (52, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 23 | Accuracy: 0.7308 | Loss: 6.1541 | F1: 0.6546\n",
      "\n",
      "Domain: 24\n",
      "x_dp_dom.shape: (51, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 24 | Accuracy: 0.7059 | Loss: 8.8804 | F1: 0.6407\n",
      "\n",
      "Domain: 25\n",
      "x_dp_dom.shape: (54, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 25 | Accuracy: 0.7407 | Loss: 6.4122 | F1: 0.6656\n",
      "\n",
      "Domain: 26\n",
      "x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 26 | Accuracy: 0.7619 | Loss: 3.9420 | F1: 0.7121\n",
      "\n",
      "Domain: 27\n",
      "x_dp_dom.shape: (54, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 27 | Accuracy: 0.4630 | Loss: 9.1922 | F1: 0.4249\n",
      "\n",
      "Domain: 28\n",
      "x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 28 | Accuracy: 0.8095 | Loss: 4.7181 | F1: 0.7606\n",
      "\n",
      "Domain: 29\n",
      "x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 29 | Accuracy: 0.8333 | Loss: 3.8278 | F1: 0.7665\n",
      "\n",
      "Domain: 30\n",
      "x_dp_dom.shape: (50, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 30 | Accuracy: 0.6200 | Loss: 7.5228 | F1: 0.5847\n",
      "\n",
      "Domain: 31\n",
      "x_dp_dom.shape: (43, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 31 | Accuracy: 0.4419 | Loss: 5.2311 | F1: 0.4277\n",
      "\n",
      "Domain: 32\n",
      "x_dp_dom.shape: (52, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 32 | Accuracy: 0.5577 | Loss: 9.4418 | F1: 0.5243\n",
      "\n",
      "Domain: 33\n",
      "x_dp_dom.shape: (44, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 33 | Accuracy: 0.6591 | Loss: 5.1067 | F1: 0.6419\n",
      "\n",
      "Domain: 34\n",
      "x_dp_dom.shape: (49, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 34 | Accuracy: 0.5918 | Loss: 6.7382 | F1: 0.5724\n",
      "\n",
      "Domain: 35\n",
      "x_dp_dom.shape: (48, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 35 | Accuracy: 0.8542 | Loss: 3.7345 | F1: 0.7967\n",
      "\n",
      "Domain: 36\n",
      "x_dp_dom.shape: (43, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 36 | Accuracy: 0.8140 | Loss: 4.3437 | F1: 0.7634\n",
      "\n",
      "Domain: 37\n",
      "x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 37 | Accuracy: 0.7381 | Loss: 4.3572 | F1: 0.7142\n",
      "\n",
      "Domain: 38\n",
      "x_dp_dom.shape: (47, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 38 | Accuracy: 0.8511 | Loss: 3.5929 | F1: 0.7865\n",
      "\n",
      "Domain: 39\n",
      "x_dp_dom.shape: (54, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 39 | Accuracy: 0.4074 | Loss: 17.4813 | F1: 0.3640\n",
      "\n",
      "Domain: 40\n",
      "x_dp_dom.shape: (44, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 40 | Accuracy: 0.3182 | Loss: 8.8925 | F1: 0.2695\n",
      "\n",
      "Domain: 41\n",
      "x_dp_dom.shape: (45, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 41 | Accuracy: 0.3333 | Loss: 6.9690 | F1: 0.3280\n",
      "\n",
      "Domain: 42\n",
      "x_dp_dom.shape: (46, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 42 | Accuracy: 0.8043 | Loss: 5.7816 | F1: 0.7559\n",
      "\n",
      "Domain: 43\n",
      "x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 43 | Accuracy: 0.6190 | Loss: 9.2496 | F1: 0.6168\n",
      "\n",
      "Domain: 44\n",
      "x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 44 | Accuracy: 0.8333 | Loss: 4.0512 | F1: 0.7778\n",
      "\n",
      "Domain: 45\n",
      "x_dp_dom.shape: (52, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 45 | Accuracy: 0.7885 | Loss: 5.3663 | F1: 0.7141\n",
      "\n",
      "Domain: 46\n",
      "x_dp_dom.shape: (48, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 46 | Accuracy: 0.8542 | Loss: 3.4609 | F1: 0.7967\n",
      "\n",
      "Domain: 47\n",
      "x_dp_dom.shape: (44, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 47 | Accuracy: 0.8182 | Loss: 3.9745 | F1: 0.7664\n",
      "\n",
      "Domain: 48\n",
      "x_dp_dom.shape: (48, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 48 | Accuracy: 0.8333 | Loss: 4.1170 | F1: 0.7587\n",
      "\n",
      "Domain: 49\n",
      "x_dp_dom.shape: (53, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 49 | Accuracy: 0.2830 | Loss: 10.2301 | F1: 0.1701\n",
      "\n",
      "Domain: 50\n",
      "x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 50 | Accuracy: 0.8095 | Loss: 4.5722 | F1: 0.7373\n",
      "\n",
      "Domain: 51\n",
      "x_dp_dom.shape: (46, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 51 | Accuracy: 0.8043 | Loss: 5.2959 | F1: 0.7391\n",
      "\n",
      "Domain: 52\n",
      "x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 52 | Accuracy: 0.7857 | Loss: 4.5515 | F1: 0.7434\n",
      "\n",
      "Domain: 53\n",
      "x_dp_dom.shape: (48, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 53 | Accuracy: 0.6875 | Loss: 4.4160 | F1: 0.6538\n",
      "\n",
      "Domain: 54\n",
      "x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 54 | Accuracy: 0.1667 | Loss: 13.2238 | F1: 0.0476\n",
      "\n",
      "Domain: 55\n",
      "x_dp_dom.shape: (49, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 55 | Accuracy: 0.6735 | Loss: 4.7346 | F1: 0.6404\n",
      "\n",
      "Domain: 56\n",
      "x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 56 | Accuracy: 0.8333 | Loss: 4.1422 | F1: 0.7624\n",
      "\n",
      "Domain: 57\n",
      "x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 57 | Accuracy: 0.5238 | Loss: 4.6390 | F1: 0.5033\n",
      "\n",
      "Domain: 58\n",
      "x_dp_dom.shape: (38, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 58 | Accuracy: 0.3421 | Loss: 9.9190 | F1: 0.3651\n",
      "\n",
      "Domain: 59\n",
      "x_dp_dom.shape: (43, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 59 | Accuracy: 0.8372 | Loss: 4.0469 | F1: 0.7806\n",
      "\n",
      "Domain: 60\n",
      "x_dp_dom.shape: (47, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 60 | Accuracy: 0.4255 | Loss: 14.7246 | F1: 0.3994\n",
      "\n",
      "Domain: 61\n",
      "x_dp_dom.shape: (47, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 61 | Accuracy: 0.3830 | Loss: 7.4896 | F1: 0.3259\n",
      "\n",
      "Domain: 62\n",
      "x_dp_dom.shape: (47, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 62 | Accuracy: 0.8085 | Loss: 4.1945 | F1: 0.7594\n",
      "\n",
      "Domain: 63\n",
      "x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 63 | Accuracy: 0.7857 | Loss: 3.8735 | F1: 0.7150\n",
      "\n",
      "Domain: 64\n",
      "x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 64 | Accuracy: 0.7619 | Loss: 4.0084 | F1: 0.7262\n",
      "\n",
      "Domain: 65\n",
      "x_dp_dom.shape: (50, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 65 | Accuracy: 0.2600 | Loss: 16.0414 | F1: 0.1146\n",
      "\n",
      "Domain: 66\n",
      "x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 66 | Accuracy: 0.1667 | Loss: 26.5908 | F1: 0.0486\n",
      "\n",
      "Domain: 67\n",
      "x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 67 | Accuracy: 0.5952 | Loss: 6.8299 | F1: 0.5970\n",
      "\n",
      "Domain: 68\n",
      "x_dp_dom.shape: (43, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 68 | Accuracy: 0.8372 | Loss: 4.0868 | F1: 0.7806\n",
      "\n",
      "Domain: 69\n",
      "x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 69 | Accuracy: 0.1667 | Loss: 19.3025 | F1: 0.0496\n",
      "\n",
      "Domain: 70\n",
      "x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 70 | Accuracy: 0.8333 | Loss: 5.6071 | F1: 0.7778\n",
      "\n",
      "Domain: 71\n",
      "x_dp_dom.shape: (44, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 71 | Accuracy: 0.8409 | Loss: 3.5609 | F1: 0.7693\n",
      "\n",
      "Domain: 72\n",
      "x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 72 | Accuracy: 0.8095 | Loss: 4.2752 | F1: 0.7606\n",
      "\n",
      "Domain: 73\n",
      "x_dp_dom.shape: (41, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 73 | Accuracy: 0.1707 | Loss: 20.9269 | F1: 0.0498\n",
      "\n",
      "Domain: 74\n",
      "x_dp_dom.shape: (35, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 74 | Accuracy: 0.8857 | Loss: 1.2182 | F1: 0.8724\n",
      "\n",
      "Domain: 75\n",
      "x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 75 | Accuracy: 0.7857 | Loss: 4.4623 | F1: 0.7434\n",
      "\n",
      "Mean accuracy for run 9: 0.6374\n",
      "Mean F1 for run 9: 0.5818\n",
      "\n",
      "Mean accuracy over 10 runs: 0.4790 +- 0.1477\n",
      "Mean F1 over 10 runs: 0.4173 +- 0.1590\n",
      "\n"
     ]
    }
   ],
   "source": [
    "n_runs = 10\n",
    "\n",
    "def compute_TSTR_Df(dataset):\n",
    "    accs = []\n",
    "    f1s = []\n",
    "\n",
    "    for i in range(n_runs):\n",
    "\n",
    "        accs_run = []\n",
    "        f1s_run = []\n",
    "\n",
    "        for src_class in config[dataset]['class_names']:\n",
    "            if src_class != 'WAL':\n",
    "                continue\n",
    "\n",
    "            print(f\"Source class: {src_class}\\n\")\n",
    "\n",
    "            # Load Df data\n",
    "            x_df, y_df, k_df = get_data(dataset, 'df', src_class)\n",
    "            print(f'x_df.shape: {x_df.shape} | np.unique(y_df): {np.unique(y_df)}\\n')\n",
    "\n",
    "            # Train on Df data\n",
    "            print('Training on Df data...')\n",
    "            df_model = train_only(x_df, y_df, dataset, num_epochs=num_epochs)\n",
    "\n",
    "            for domain in range(config[dataset]['num_df_domains'], config[dataset]['num_df_domains'] + config[dataset]['num_dp_domains']):\n",
    "                print(f\"Domain: {domain}\")\n",
    "\n",
    "                # Load Dp data\n",
    "                x_dp_dom, y_dp_dom, k_dp_dom = get_data(dataset, 'dp', src_class, domain)\n",
    "                print(f'x_dp_dom.shape: {x_dp_dom.shape} | np.unique(y_dp_dom): {np.unique(y_dp_dom)}\\n')\n",
    "\n",
    "                # Evaluate on Dp data\n",
    "                acc, loss, f1 = evaluate_model(df_model, get_dataloader(x_dp_dom, y_dp_dom))\n",
    "                save_scores(src_class, domain, acc, loss, f1, 'Df', dataset)\n",
    "                accs_run.append(acc)\n",
    "                f1s_run.append(f1)\n",
    "                print(f'Source class: {src_class} | Domain: {domain} | Accuracy: {acc:.4f} | Loss: {loss:.4f} | F1: {f1:.4f}\\n')\n",
    "\n",
    "        print(f\"Mean accuracy for run {i}: {np.mean(accs_run):.4f}\")\n",
    "        print(f\"Mean F1 for run {i}: {np.mean(f1s_run):.4f}\\n\")\n",
    "        accs.append(np.mean(accs_run))\n",
    "        f1s.append(np.mean(f1s_run))\n",
    "\n",
    "    print(f\"Mean accuracy over {n_runs} runs: {np.mean(accs):.4f} +- {np.std(accs):.4f}\")\n",
    "    print(f\"Mean F1 over {n_runs} runs: {np.mean(f1s):.4f} +- {np.std(f1s):.4f}\\n\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "compute_TSTR_Df('realworld_mobiact')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 744303,
     "status": "ok",
     "timestamp": 1732618270306,
     "user": {
      "displayName": "Pietro Cirino",
      "userId": "07315473796200699505"
     },
     "user_tz": -60
    },
    "id": "6X3sBMvtdTCl",
    "outputId": "1f7b1dcf-be4e-4a2a-8e03-fc8a8fa17acd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source class: WAL\n",
      "\n",
      "x_df.shape: (7958, 3, 128) | np.unique(y_df): [1 2 3]\n",
      "\n",
      "Training on Df data...\n",
      "\tEpoch 10/100 - Train loss: 0.1089 - Val accuracy: 0.7682 - Val loss: 0.5951 - Val F1: 0.7782 - LR: 9.00e-05\n",
      "\tEpoch 20/100 - Train loss: 0.0741 - Val accuracy: 0.8247 - Val loss: 0.4775 - Val F1: 0.8252 - LR: 8.00e-05\n",
      "\tEpoch 30/100 - Train loss: 0.0695 - Val accuracy: 0.7701 - Val loss: 0.6668 - Val F1: 0.7509 - LR: 7.00e-05\n",
      "\tEpoch 40/100 - Train loss: 0.0571 - Val accuracy: 0.7280 - Val loss: 1.0030 - Val F1: 0.6242 - LR: 6.00e-05\n",
      "\tEpoch 50/100 - Train loss: 0.0530 - Val accuracy: 0.7305 - Val loss: 1.1198 - Val F1: 0.6612 - LR: 5.00e-05\n",
      "\tEpoch 60/100 - Train loss: 0.0401 - Val accuracy: 0.7977 - Val loss: 0.6788 - Val F1: 0.7822 - LR: 4.00e-05\n",
      "\tEpoch 70/100 - Train loss: 0.0424 - Val accuracy: 0.6263 - Val loss: 1.7234 - Val F1: 0.5996 - LR: 3.00e-05\n",
      "\tEpoch 80/100 - Train loss: 0.0366 - Val accuracy: 0.7538 - Val loss: 1.0877 - Val F1: 0.7065 - LR: 2.00e-05\n",
      "\tEpoch 90/100 - Train loss: 0.0365 - Val accuracy: 0.7280 - Val loss: 1.4499 - Val F1: 0.6807 - LR: 1.00e-05\n",
      "\tEpoch 100/100 - Train loss: 0.0381 - Val accuracy: 0.7242 - Val loss: 1.3955 - Val F1: 0.6817 - LR: 0.00e+00\n",
      "\tBest epoch: 31 - Best val accuracy: 0.8373 - Best val loss: 0.3761 - Best val F1: 0.8293\n",
      "\n",
      "Domain: 15\n",
      "x_dp_dom.shape: (50, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 15 | Accuracy: 0.8000 | Loss: 2.6735 | F1: 0.7152\n",
      "\n",
      "Domain: 16\n",
      "x_dp_dom.shape: (54, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 16 | Accuracy: 0.7593 | Loss: 1.3105 | F1: 0.6790\n",
      "\n",
      "Domain: 17\n",
      "x_dp_dom.shape: (53, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 17 | Accuracy: 0.6981 | Loss: 2.4212 | F1: 0.6555\n",
      "\n",
      "Domain: 18\n",
      "x_dp_dom.shape: (54, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 18 | Accuracy: 0.6852 | Loss: 2.1259 | F1: 0.6277\n",
      "\n",
      "Domain: 19\n",
      "x_dp_dom.shape: (54, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 19 | Accuracy: 0.5370 | Loss: 2.6924 | F1: 0.5336\n",
      "\n",
      "Domain: 20\n",
      "x_dp_dom.shape: (51, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 20 | Accuracy: 0.8235 | Loss: 0.6183 | F1: 0.8079\n",
      "\n",
      "Domain: 21\n",
      "x_dp_dom.shape: (47, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 21 | Accuracy: 0.8723 | Loss: 1.0738 | F1: 0.8372\n",
      "\n",
      "Domain: 22\n",
      "x_dp_dom.shape: (54, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 22 | Accuracy: 0.7778 | Loss: 0.8506 | F1: 0.7334\n",
      "\n",
      "Domain: 23\n",
      "x_dp_dom.shape: (52, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 23 | Accuracy: 0.7885 | Loss: 0.8517 | F1: 0.7350\n",
      "\n",
      "Domain: 24\n",
      "x_dp_dom.shape: (51, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 24 | Accuracy: 0.6078 | Loss: 1.4137 | F1: 0.5859\n",
      "\n",
      "Domain: 25\n",
      "x_dp_dom.shape: (54, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 25 | Accuracy: 0.7222 | Loss: 2.1613 | F1: 0.6520\n",
      "\n",
      "Domain: 26\n",
      "x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 26 | Accuracy: 0.9762 | Loss: 0.1320 | F1: 0.9768\n",
      "\n",
      "Domain: 27\n",
      "x_dp_dom.shape: (54, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 27 | Accuracy: 0.7593 | Loss: 1.2854 | F1: 0.6790\n",
      "\n",
      "Domain: 28\n",
      "x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 28 | Accuracy: 0.8571 | Loss: 0.6381 | F1: 0.8250\n",
      "\n",
      "Domain: 29\n",
      "x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 29 | Accuracy: 0.3333 | Loss: 2.7321 | F1: 0.3778\n",
      "\n",
      "Domain: 30\n",
      "x_dp_dom.shape: (50, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 30 | Accuracy: 0.7000 | Loss: 1.8455 | F1: 0.6647\n",
      "\n",
      "Domain: 31\n",
      "x_dp_dom.shape: (43, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 31 | Accuracy: 0.7209 | Loss: 1.0103 | F1: 0.6854\n",
      "\n",
      "Domain: 32\n",
      "x_dp_dom.shape: (52, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 32 | Accuracy: 0.7885 | Loss: 1.1183 | F1: 0.7141\n",
      "\n",
      "Domain: 33\n",
      "x_dp_dom.shape: (44, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 33 | Accuracy: 0.8864 | Loss: 0.2778 | F1: 0.8671\n",
      "\n",
      "Domain: 34\n",
      "x_dp_dom.shape: (49, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 34 | Accuracy: 0.8163 | Loss: 0.6879 | F1: 0.8163\n",
      "\n",
      "Domain: 35\n",
      "x_dp_dom.shape: (48, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 35 | Accuracy: 0.8333 | Loss: 0.7112 | F1: 0.8261\n",
      "\n",
      "Domain: 36\n",
      "x_dp_dom.shape: (43, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 36 | Accuracy: 0.6279 | Loss: 0.7203 | F1: 0.6630\n",
      "\n",
      "Domain: 37\n",
      "x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 37 | Accuracy: 0.7619 | Loss: 0.8559 | F1: 0.7702\n",
      "\n",
      "Domain: 38\n",
      "x_dp_dom.shape: (47, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 38 | Accuracy: 0.7872 | Loss: 1.2631 | F1: 0.7262\n",
      "\n",
      "Domain: 39\n",
      "x_dp_dom.shape: (54, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 39 | Accuracy: 0.6852 | Loss: 1.4295 | F1: 0.6129\n",
      "\n",
      "Domain: 40\n",
      "x_dp_dom.shape: (44, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 40 | Accuracy: 0.8409 | Loss: 0.5171 | F1: 0.8471\n",
      "\n",
      "Domain: 41\n",
      "x_dp_dom.shape: (45, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 41 | Accuracy: 0.6889 | Loss: 2.3339 | F1: 0.6832\n",
      "\n",
      "Domain: 42\n",
      "x_dp_dom.shape: (46, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 42 | Accuracy: 0.8478 | Loss: 0.7511 | F1: 0.8395\n",
      "\n",
      "Domain: 43\n",
      "x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 43 | Accuracy: 0.8095 | Loss: 2.1000 | F1: 0.7625\n",
      "\n",
      "Domain: 44\n",
      "x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 44 | Accuracy: 0.8095 | Loss: 1.0210 | F1: 0.7920\n",
      "\n",
      "Domain: 45\n",
      "x_dp_dom.shape: (52, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 45 | Accuracy: 0.9231 | Loss: 0.1624 | F1: 0.9197\n",
      "\n",
      "Domain: 46\n",
      "x_dp_dom.shape: (48, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 46 | Accuracy: 0.8333 | Loss: 1.0384 | F1: 0.7861\n",
      "\n",
      "Domain: 47\n",
      "x_dp_dom.shape: (44, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 47 | Accuracy: 0.8409 | Loss: 0.5347 | F1: 0.8091\n",
      "\n",
      "Domain: 48\n",
      "x_dp_dom.shape: (48, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 48 | Accuracy: 0.8750 | Loss: 0.7294 | F1: 0.8467\n",
      "\n",
      "Domain: 49\n",
      "x_dp_dom.shape: (53, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 49 | Accuracy: 0.7925 | Loss: 0.6479 | F1: 0.7562\n",
      "\n",
      "Domain: 50\n",
      "x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 50 | Accuracy: 0.8333 | Loss: 0.4445 | F1: 0.7930\n",
      "\n",
      "Domain: 51\n",
      "x_dp_dom.shape: (46, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 51 | Accuracy: 0.8261 | Loss: 1.1073 | F1: 0.8086\n",
      "\n",
      "Domain: 52\n",
      "x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 52 | Accuracy: 0.8333 | Loss: 0.7965 | F1: 0.8082\n",
      "\n",
      "Domain: 53\n",
      "x_dp_dom.shape: (48, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 53 | Accuracy: 0.8333 | Loss: 0.4141 | F1: 0.7708\n",
      "\n",
      "Domain: 54\n",
      "x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 54 | Accuracy: 0.8333 | Loss: 0.4824 | F1: 0.7778\n",
      "\n",
      "Domain: 55\n",
      "x_dp_dom.shape: (49, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 55 | Accuracy: 0.7143 | Loss: 0.8480 | F1: 0.7192\n",
      "\n",
      "Domain: 56\n",
      "x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 56 | Accuracy: 0.8810 | Loss: 0.4450 | F1: 0.8774\n",
      "\n",
      "Domain: 57\n",
      "x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 57 | Accuracy: 0.9524 | Loss: 0.0914 | F1: 0.9494\n",
      "\n",
      "Domain: 58\n",
      "x_dp_dom.shape: (38, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 58 | Accuracy: 0.8947 | Loss: 0.3932 | F1: 0.8823\n",
      "\n",
      "Domain: 59\n",
      "x_dp_dom.shape: (43, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 59 | Accuracy: 0.9070 | Loss: 0.3794 | F1: 0.8977\n",
      "\n",
      "Domain: 60\n",
      "x_dp_dom.shape: (47, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 60 | Accuracy: 0.6809 | Loss: 1.8874 | F1: 0.6215\n",
      "\n",
      "Domain: 61\n",
      "x_dp_dom.shape: (47, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 61 | Accuracy: 0.8723 | Loss: 0.5388 | F1: 0.8633\n",
      "\n",
      "Domain: 62\n",
      "x_dp_dom.shape: (47, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 62 | Accuracy: 0.8936 | Loss: 0.3633 | F1: 0.8732\n",
      "\n",
      "Domain: 63\n",
      "x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 63 | Accuracy: 0.8810 | Loss: 0.5295 | F1: 0.8778\n",
      "\n",
      "Domain: 64\n",
      "x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 64 | Accuracy: 0.8810 | Loss: 0.4277 | F1: 0.8635\n",
      "\n",
      "Domain: 65\n",
      "x_dp_dom.shape: (50, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 65 | Accuracy: 0.8800 | Loss: 0.7134 | F1: 0.8560\n",
      "\n",
      "Domain: 66\n",
      "x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 66 | Accuracy: 0.7143 | Loss: 3.3225 | F1: 0.6231\n",
      "\n",
      "Domain: 67\n",
      "x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 67 | Accuracy: 0.8571 | Loss: 0.3896 | F1: 0.8150\n",
      "\n",
      "Domain: 68\n",
      "x_dp_dom.shape: (43, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 68 | Accuracy: 0.4651 | Loss: 1.4059 | F1: 0.5157\n",
      "\n",
      "Domain: 69\n",
      "x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 69 | Accuracy: 0.8333 | Loss: 0.9400 | F1: 0.7778\n",
      "\n",
      "Domain: 70\n",
      "x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 70 | Accuracy: 0.7619 | Loss: 1.2366 | F1: 0.7244\n",
      "\n",
      "Domain: 71\n",
      "x_dp_dom.shape: (44, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 71 | Accuracy: 0.8409 | Loss: 0.2669 | F1: 0.8516\n",
      "\n",
      "Domain: 72\n",
      "x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 72 | Accuracy: 0.5952 | Loss: 1.4700 | F1: 0.6329\n",
      "\n",
      "Domain: 73\n",
      "x_dp_dom.shape: (41, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 73 | Accuracy: 0.6829 | Loss: 3.2059 | F1: 0.5543\n",
      "\n",
      "Domain: 74\n",
      "x_dp_dom.shape: (35, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 74 | Accuracy: 0.7714 | Loss: 1.3886 | F1: 0.6968\n",
      "\n",
      "Domain: 75\n",
      "x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 75 | Accuracy: 0.8333 | Loss: 0.5749 | F1: 0.8073\n",
      "\n",
      "Mean accuracy for run 0: 0.7839\n",
      "Mean F1 for run 0: 0.7549\n",
      "\n",
      "Source class: WAL\n",
      "\n",
      "x_df.shape: (7958, 3, 128) | np.unique(y_df): [1 2 3]\n",
      "\n",
      "Training on Df data...\n",
      "\tEpoch 10/100 - Train loss: 0.1129 - Val accuracy: 0.8656 - Val loss: 0.3315 - Val F1: 0.8649 - LR: 9.00e-05\n",
      "\tEpoch 20/100 - Train loss: 0.0769 - Val accuracy: 0.7349 - Val loss: 1.1265 - Val F1: 0.6919 - LR: 8.00e-05\n",
      "\tEpoch 30/100 - Train loss: 0.0660 - Val accuracy: 0.7230 - Val loss: 1.9209 - Val F1: 0.6322 - LR: 7.00e-05\n",
      "\tEpoch 40/100 - Train loss: 0.0637 - Val accuracy: 0.7079 - Val loss: 1.9633 - Val F1: 0.6394 - LR: 6.00e-05\n",
      "\tEpoch 50/100 - Train loss: 0.0444 - Val accuracy: 0.7180 - Val loss: 2.3219 - Val F1: 0.6236 - LR: 5.00e-05\n",
      "\tEpoch 60/100 - Train loss: 0.0454 - Val accuracy: 0.7506 - Val loss: 1.8570 - Val F1: 0.6863 - LR: 4.00e-05\n",
      "\tEpoch 70/100 - Train loss: 0.0443 - Val accuracy: 0.7286 - Val loss: 2.5606 - Val F1: 0.6402 - LR: 3.00e-05\n",
      "\tEpoch 80/100 - Train loss: 0.0367 - Val accuracy: 0.7198 - Val loss: 2.6250 - Val F1: 0.6294 - LR: 2.00e-05\n",
      "\tEpoch 90/100 - Train loss: 0.0385 - Val accuracy: 0.7242 - Val loss: 3.0582 - Val F1: 0.6328 - LR: 1.00e-05\n",
      "\tEpoch 100/100 - Train loss: 0.0314 - Val accuracy: 0.7268 - Val loss: 2.9461 - Val F1: 0.6398 - LR: 0.00e+00\n",
      "\tBest epoch: 10 - Best val accuracy: 0.8656 - Best val loss: 0.3315 - Best val F1: 0.8649\n",
      "\n",
      "Domain: 15\n",
      "x_dp_dom.shape: (50, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 15 | Accuracy: 0.8000 | Loss: 1.6874 | F1: 0.7294\n",
      "\n",
      "Domain: 16\n",
      "x_dp_dom.shape: (54, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 16 | Accuracy: 0.7593 | Loss: 1.5012 | F1: 0.6790\n",
      "\n",
      "Domain: 17\n",
      "x_dp_dom.shape: (53, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 17 | Accuracy: 0.6604 | Loss: 3.2628 | F1: 0.6243\n",
      "\n",
      "Domain: 18\n",
      "x_dp_dom.shape: (54, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 18 | Accuracy: 0.6481 | Loss: 3.1204 | F1: 0.6090\n",
      "\n",
      "Domain: 19\n",
      "x_dp_dom.shape: (54, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 19 | Accuracy: 0.7222 | Loss: 2.7992 | F1: 0.6558\n",
      "\n",
      "Domain: 20\n",
      "x_dp_dom.shape: (51, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 20 | Accuracy: 0.7843 | Loss: 1.3804 | F1: 0.7231\n",
      "\n",
      "Domain: 21\n",
      "x_dp_dom.shape: (47, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 21 | Accuracy: 0.8511 | Loss: 1.0398 | F1: 0.7934\n",
      "\n",
      "Domain: 22\n",
      "x_dp_dom.shape: (54, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 22 | Accuracy: 0.7778 | Loss: 1.2798 | F1: 0.7380\n",
      "\n",
      "Domain: 23\n",
      "x_dp_dom.shape: (52, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 23 | Accuracy: 0.7500 | Loss: 1.5250 | F1: 0.6852\n",
      "\n",
      "Domain: 24\n",
      "x_dp_dom.shape: (51, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 24 | Accuracy: 0.6863 | Loss: 1.9842 | F1: 0.6333\n",
      "\n",
      "Domain: 25\n",
      "x_dp_dom.shape: (54, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 25 | Accuracy: 0.7222 | Loss: 2.7885 | F1: 0.6520\n",
      "\n",
      "Domain: 26\n",
      "x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 26 | Accuracy: 0.9286 | Loss: 0.2007 | F1: 0.9266\n",
      "\n",
      "Domain: 27\n",
      "x_dp_dom.shape: (54, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 27 | Accuracy: 0.7593 | Loss: 2.5725 | F1: 0.6790\n",
      "\n",
      "Domain: 28\n",
      "x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 28 | Accuracy: 0.7857 | Loss: 1.4970 | F1: 0.7531\n",
      "\n",
      "Domain: 29\n",
      "x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 29 | Accuracy: 0.7381 | Loss: 1.7312 | F1: 0.7214\n",
      "\n",
      "Domain: 30\n",
      "x_dp_dom.shape: (50, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 30 | Accuracy: 0.7200 | Loss: 1.0436 | F1: 0.6931\n",
      "\n",
      "Domain: 31\n",
      "x_dp_dom.shape: (43, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 31 | Accuracy: 0.8140 | Loss: 1.0414 | F1: 0.7687\n",
      "\n",
      "Domain: 32\n",
      "x_dp_dom.shape: (52, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 32 | Accuracy: 0.7308 | Loss: 1.8125 | F1: 0.6837\n",
      "\n",
      "Domain: 33\n",
      "x_dp_dom.shape: (44, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 33 | Accuracy: 0.8636 | Loss: 0.5176 | F1: 0.8597\n",
      "\n",
      "Domain: 34\n",
      "x_dp_dom.shape: (49, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 34 | Accuracy: 0.8571 | Loss: 0.7427 | F1: 0.8570\n",
      "\n",
      "Domain: 35\n",
      "x_dp_dom.shape: (48, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 35 | Accuracy: 0.7500 | Loss: 1.3264 | F1: 0.7217\n",
      "\n",
      "Domain: 36\n",
      "x_dp_dom.shape: (43, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 36 | Accuracy: 0.7442 | Loss: 1.2147 | F1: 0.7201\n",
      "\n",
      "Domain: 37\n",
      "x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 37 | Accuracy: 0.7381 | Loss: 1.1781 | F1: 0.7576\n",
      "\n",
      "Domain: 38\n",
      "x_dp_dom.shape: (47, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 38 | Accuracy: 0.7660 | Loss: 1.7957 | F1: 0.7322\n",
      "\n",
      "Domain: 39\n",
      "x_dp_dom.shape: (54, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 39 | Accuracy: 0.6852 | Loss: 1.8199 | F1: 0.6242\n",
      "\n",
      "Domain: 40\n",
      "x_dp_dom.shape: (44, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 40 | Accuracy: 0.7500 | Loss: 0.9862 | F1: 0.7273\n",
      "\n",
      "Domain: 41\n",
      "x_dp_dom.shape: (45, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 41 | Accuracy: 0.6222 | Loss: 2.3837 | F1: 0.6459\n",
      "\n",
      "Domain: 42\n",
      "x_dp_dom.shape: (46, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 42 | Accuracy: 0.6522 | Loss: 1.6535 | F1: 0.6565\n",
      "\n",
      "Domain: 43\n",
      "x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 43 | Accuracy: 0.8095 | Loss: 1.0340 | F1: 0.7657\n",
      "\n",
      "Domain: 44\n",
      "x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 44 | Accuracy: 0.8333 | Loss: 1.2074 | F1: 0.8082\n",
      "\n",
      "Domain: 45\n",
      "x_dp_dom.shape: (52, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 45 | Accuracy: 0.8462 | Loss: 0.7482 | F1: 0.8203\n",
      "\n",
      "Domain: 46\n",
      "x_dp_dom.shape: (48, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 46 | Accuracy: 0.8125 | Loss: 1.7500 | F1: 0.7629\n",
      "\n",
      "Domain: 47\n",
      "x_dp_dom.shape: (44, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 47 | Accuracy: 0.8409 | Loss: 0.8105 | F1: 0.8136\n",
      "\n",
      "Domain: 48\n",
      "x_dp_dom.shape: (48, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 48 | Accuracy: 0.8750 | Loss: 0.8443 | F1: 0.8467\n",
      "\n",
      "Domain: 49\n",
      "x_dp_dom.shape: (53, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 49 | Accuracy: 0.7358 | Loss: 1.8925 | F1: 0.6766\n",
      "\n",
      "Domain: 50\n",
      "x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 50 | Accuracy: 0.7857 | Loss: 0.6467 | F1: 0.7609\n",
      "\n",
      "Domain: 51\n",
      "x_dp_dom.shape: (46, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 51 | Accuracy: 0.8261 | Loss: 0.8796 | F1: 0.7833\n",
      "\n",
      "Domain: 52\n",
      "x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 52 | Accuracy: 0.8095 | Loss: 1.4245 | F1: 0.7606\n",
      "\n",
      "Domain: 53\n",
      "x_dp_dom.shape: (48, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 53 | Accuracy: 0.8333 | Loss: 0.7758 | F1: 0.7996\n",
      "\n",
      "Domain: 54\n",
      "x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 54 | Accuracy: 0.8571 | Loss: 0.8409 | F1: 0.8250\n",
      "\n",
      "Domain: 55\n",
      "x_dp_dom.shape: (49, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 55 | Accuracy: 0.7347 | Loss: 1.5328 | F1: 0.7183\n",
      "\n",
      "Domain: 56\n",
      "x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 56 | Accuracy: 0.8810 | Loss: 0.5213 | F1: 0.8550\n",
      "\n",
      "Domain: 57\n",
      "x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 57 | Accuracy: 1.0000 | Loss: 0.0407 | F1: 1.0000\n",
      "\n",
      "Domain: 58\n",
      "x_dp_dom.shape: (38, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 58 | Accuracy: 0.7895 | Loss: 0.5972 | F1: 0.7807\n",
      "\n",
      "Domain: 59\n",
      "x_dp_dom.shape: (43, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 59 | Accuracy: 0.7209 | Loss: 0.8624 | F1: 0.7167\n",
      "\n",
      "Domain: 60\n",
      "x_dp_dom.shape: (47, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 60 | Accuracy: 0.7872 | Loss: 1.3677 | F1: 0.7346\n",
      "\n",
      "Domain: 61\n",
      "x_dp_dom.shape: (47, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 61 | Accuracy: 0.9149 | Loss: 0.2853 | F1: 0.9152\n",
      "\n",
      "Domain: 62\n",
      "x_dp_dom.shape: (47, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 62 | Accuracy: 0.7872 | Loss: 1.2136 | F1: 0.7712\n",
      "\n",
      "Domain: 63\n",
      "x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 63 | Accuracy: 0.8810 | Loss: 0.7086 | F1: 0.8725\n",
      "\n",
      "Domain: 64\n",
      "x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 64 | Accuracy: 0.8571 | Loss: 0.6653 | F1: 0.8250\n",
      "\n",
      "Domain: 65\n",
      "x_dp_dom.shape: (50, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 65 | Accuracy: 0.8200 | Loss: 1.1227 | F1: 0.7981\n",
      "\n",
      "Domain: 66\n",
      "x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 66 | Accuracy: 0.8333 | Loss: 0.9994 | F1: 0.7778\n",
      "\n",
      "Domain: 67\n",
      "x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 67 | Accuracy: 0.8571 | Loss: 0.7764 | F1: 0.8440\n",
      "\n",
      "Domain: 68\n",
      "x_dp_dom.shape: (43, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 68 | Accuracy: 0.4651 | Loss: 2.0734 | F1: 0.5201\n",
      "\n",
      "Domain: 69\n",
      "x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 69 | Accuracy: 0.8095 | Loss: 1.1961 | F1: 0.7606\n",
      "\n",
      "Domain: 70\n",
      "x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 70 | Accuracy: 0.7857 | Loss: 0.7582 | F1: 0.7434\n",
      "\n",
      "Domain: 71\n",
      "x_dp_dom.shape: (44, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 71 | Accuracy: 0.8864 | Loss: 0.4177 | F1: 0.8633\n",
      "\n",
      "Domain: 72\n",
      "x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 72 | Accuracy: 0.7619 | Loss: 1.5204 | F1: 0.7400\n",
      "\n",
      "Domain: 73\n",
      "x_dp_dom.shape: (41, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 73 | Accuracy: 0.8537 | Loss: 1.0121 | F1: 0.8024\n",
      "\n",
      "Domain: 74\n",
      "x_dp_dom.shape: (35, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 74 | Accuracy: 0.8571 | Loss: 0.6327 | F1: 0.8228\n",
      "\n",
      "Domain: 75\n",
      "x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 75 | Accuracy: 0.7857 | Loss: 1.2837 | F1: 0.7480\n",
      "\n",
      "Mean accuracy for run 1: 0.7869\n",
      "Mean F1 for run 1: 0.7555\n",
      "\n",
      "Source class: WAL\n",
      "\n",
      "x_df.shape: (7958, 3, 128) | np.unique(y_df): [1 2 3]\n",
      "\n",
      "Training on Df data...\n",
      "\tEpoch 10/100 - Train loss: 0.1087 - Val accuracy: 0.7073 - Val loss: 1.0416 - Val F1: 0.5948 - LR: 9.00e-05\n",
      "\tEpoch 20/100 - Train loss: 0.0810 - Val accuracy: 0.7224 - Val loss: 1.9866 - Val F1: 0.6202 - LR: 8.00e-05\n",
      "\tEpoch 30/100 - Train loss: 0.0684 - Val accuracy: 0.7217 - Val loss: 2.0418 - Val F1: 0.6117 - LR: 7.00e-05\n",
      "\tEpoch 40/100 - Train loss: 0.0547 - Val accuracy: 0.7205 - Val loss: 3.8666 - Val F1: 0.6207 - LR: 6.00e-05\n",
      "\tEpoch 50/100 - Train loss: 0.0515 - Val accuracy: 0.7205 - Val loss: 3.9006 - Val F1: 0.6218 - LR: 5.00e-05\n",
      "\tEpoch 60/100 - Train loss: 0.0430 - Val accuracy: 0.7224 - Val loss: 4.3133 - Val F1: 0.6186 - LR: 4.00e-05\n",
      "\tEpoch 70/100 - Train loss: 0.0459 - Val accuracy: 0.7198 - Val loss: 4.9284 - Val F1: 0.6215 - LR: 3.00e-05\n",
      "\tEpoch 80/100 - Train loss: 0.0353 - Val accuracy: 0.7167 - Val loss: 6.0979 - Val F1: 0.6199 - LR: 2.00e-05\n",
      "\tEpoch 90/100 - Train loss: 0.0389 - Val accuracy: 0.7148 - Val loss: 5.5261 - Val F1: 0.6186 - LR: 1.00e-05\n",
      "\tEpoch 100/100 - Train loss: 0.0356 - Val accuracy: 0.7111 - Val loss: 6.9253 - Val F1: 0.6158 - LR: 0.00e+00\n",
      "\tBest epoch: 4 - Best val accuracy: 0.8637 - Best val loss: 0.3984 - Best val F1: 0.8654\n",
      "\n",
      "Domain: 15\n",
      "x_dp_dom.shape: (50, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 15 | Accuracy: 0.9800 | Loss: 0.0920 | F1: 0.9799\n",
      "\n",
      "Domain: 16\n",
      "x_dp_dom.shape: (54, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 16 | Accuracy: 0.7778 | Loss: 1.0324 | F1: 0.7384\n",
      "\n",
      "Domain: 17\n",
      "x_dp_dom.shape: (53, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 17 | Accuracy: 0.6792 | Loss: 2.2799 | F1: 0.6400\n",
      "\n",
      "Domain: 18\n",
      "x_dp_dom.shape: (54, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 18 | Accuracy: 0.6296 | Loss: 1.9567 | F1: 0.5971\n",
      "\n",
      "Domain: 19\n",
      "x_dp_dom.shape: (54, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 19 | Accuracy: 0.7407 | Loss: 1.1686 | F1: 0.6941\n",
      "\n",
      "Domain: 20\n",
      "x_dp_dom.shape: (51, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 20 | Accuracy: 0.8039 | Loss: 0.6515 | F1: 0.7796\n",
      "\n",
      "Domain: 21\n",
      "x_dp_dom.shape: (47, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 21 | Accuracy: 0.8511 | Loss: 0.6555 | F1: 0.8223\n",
      "\n",
      "Domain: 22\n",
      "x_dp_dom.shape: (54, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 22 | Accuracy: 0.8148 | Loss: 0.4262 | F1: 0.7954\n",
      "\n",
      "Domain: 23\n",
      "x_dp_dom.shape: (52, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 23 | Accuracy: 0.8077 | Loss: 0.7502 | F1: 0.7743\n",
      "\n",
      "Domain: 24\n",
      "x_dp_dom.shape: (51, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 24 | Accuracy: 0.7059 | Loss: 1.3765 | F1: 0.6440\n",
      "\n",
      "Domain: 25\n",
      "x_dp_dom.shape: (54, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 25 | Accuracy: 0.7222 | Loss: 1.8625 | F1: 0.6558\n",
      "\n",
      "Domain: 26\n",
      "x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 26 | Accuracy: 0.9524 | Loss: 0.2444 | F1: 0.9530\n",
      "\n",
      "Domain: 27\n",
      "x_dp_dom.shape: (54, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 27 | Accuracy: 0.7593 | Loss: 1.7659 | F1: 0.6790\n",
      "\n",
      "Domain: 28\n",
      "x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 28 | Accuracy: 0.7857 | Loss: 0.8347 | F1: 0.7759\n",
      "\n",
      "Domain: 29\n",
      "x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 29 | Accuracy: 0.8095 | Loss: 0.4856 | F1: 0.8164\n",
      "\n",
      "Domain: 30\n",
      "x_dp_dom.shape: (50, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 30 | Accuracy: 0.8800 | Loss: 0.3702 | F1: 0.8824\n",
      "\n",
      "Domain: 31\n",
      "x_dp_dom.shape: (43, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 31 | Accuracy: 0.8605 | Loss: 0.2614 | F1: 0.8685\n",
      "\n",
      "Domain: 32\n",
      "x_dp_dom.shape: (52, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 32 | Accuracy: 0.6923 | Loss: 1.4018 | F1: 0.6613\n",
      "\n",
      "Domain: 33\n",
      "x_dp_dom.shape: (44, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 33 | Accuracy: 0.9091 | Loss: 0.2048 | F1: 0.9079\n",
      "\n",
      "Domain: 34\n",
      "x_dp_dom.shape: (49, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 34 | Accuracy: 0.8571 | Loss: 0.5394 | F1: 0.8556\n",
      "\n",
      "Domain: 35\n",
      "x_dp_dom.shape: (48, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 35 | Accuracy: 0.5208 | Loss: 1.3663 | F1: 0.5634\n",
      "\n",
      "Domain: 36\n",
      "x_dp_dom.shape: (43, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 36 | Accuracy: 0.6744 | Loss: 1.0570 | F1: 0.7001\n",
      "\n",
      "Domain: 37\n",
      "x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 37 | Accuracy: 0.8333 | Loss: 0.9437 | F1: 0.7931\n",
      "\n",
      "Domain: 38\n",
      "x_dp_dom.shape: (47, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 38 | Accuracy: 0.8298 | Loss: 0.8411 | F1: 0.8024\n",
      "\n",
      "Domain: 39\n",
      "x_dp_dom.shape: (54, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 39 | Accuracy: 0.7407 | Loss: 1.0190 | F1: 0.6656\n",
      "\n",
      "Domain: 40\n",
      "x_dp_dom.shape: (44, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 40 | Accuracy: 0.8409 | Loss: 0.6687 | F1: 0.8407\n",
      "\n",
      "Domain: 41\n",
      "x_dp_dom.shape: (45, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 41 | Accuracy: 0.6889 | Loss: 2.0863 | F1: 0.7128\n",
      "\n",
      "Domain: 42\n",
      "x_dp_dom.shape: (46, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 42 | Accuracy: 0.8261 | Loss: 0.5735 | F1: 0.8331\n",
      "\n",
      "Domain: 43\n",
      "x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 43 | Accuracy: 0.9048 | Loss: 0.3015 | F1: 0.9078\n",
      "\n",
      "Domain: 44\n",
      "x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 44 | Accuracy: 0.9524 | Loss: 0.2683 | F1: 0.9514\n",
      "\n",
      "Domain: 45\n",
      "x_dp_dom.shape: (52, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 45 | Accuracy: 0.9038 | Loss: 0.2985 | F1: 0.8975\n",
      "\n",
      "Domain: 46\n",
      "x_dp_dom.shape: (48, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 46 | Accuracy: 0.8750 | Loss: 0.4492 | F1: 0.8576\n",
      "\n",
      "Domain: 47\n",
      "x_dp_dom.shape: (44, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 47 | Accuracy: 0.8182 | Loss: 0.4582 | F1: 0.8346\n",
      "\n",
      "Domain: 48\n",
      "x_dp_dom.shape: (48, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 48 | Accuracy: 0.9583 | Loss: 0.2152 | F1: 0.9570\n",
      "\n",
      "Domain: 49\n",
      "x_dp_dom.shape: (53, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 49 | Accuracy: 0.6981 | Loss: 1.2542 | F1: 0.6555\n",
      "\n",
      "Domain: 50\n",
      "x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 50 | Accuracy: 0.9048 | Loss: 0.2066 | F1: 0.9049\n",
      "\n",
      "Domain: 51\n",
      "x_dp_dom.shape: (46, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 51 | Accuracy: 0.8696 | Loss: 0.5103 | F1: 0.8628\n",
      "\n",
      "Domain: 52\n",
      "x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 52 | Accuracy: 0.8333 | Loss: 0.6572 | F1: 0.8082\n",
      "\n",
      "Domain: 53\n",
      "x_dp_dom.shape: (48, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 53 | Accuracy: 0.8542 | Loss: 0.3050 | F1: 0.8139\n",
      "\n",
      "Domain: 54\n",
      "x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 54 | Accuracy: 0.8810 | Loss: 0.3879 | F1: 0.8635\n",
      "\n",
      "Domain: 55\n",
      "x_dp_dom.shape: (49, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 55 | Accuracy: 0.7755 | Loss: 0.7472 | F1: 0.7711\n",
      "\n",
      "Domain: 56\n",
      "x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 56 | Accuracy: 0.9286 | Loss: 0.1505 | F1: 0.9254\n",
      "\n",
      "Domain: 57\n",
      "x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 57 | Accuracy: 0.9524 | Loss: 0.1791 | F1: 0.9492\n",
      "\n",
      "Domain: 58\n",
      "x_dp_dom.shape: (38, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 58 | Accuracy: 0.8684 | Loss: 0.3355 | F1: 0.8613\n",
      "\n",
      "Domain: 59\n",
      "x_dp_dom.shape: (43, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 59 | Accuracy: 0.8605 | Loss: 0.2559 | F1: 0.8710\n",
      "\n",
      "Domain: 60\n",
      "x_dp_dom.shape: (47, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 60 | Accuracy: 0.7872 | Loss: 1.2203 | F1: 0.7914\n",
      "\n",
      "Domain: 61\n",
      "x_dp_dom.shape: (47, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 61 | Accuracy: 0.7872 | Loss: 0.5000 | F1: 0.7878\n",
      "\n",
      "Domain: 62\n",
      "x_dp_dom.shape: (47, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 62 | Accuracy: 0.7447 | Loss: 0.5452 | F1: 0.7649\n",
      "\n",
      "Domain: 63\n",
      "x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 63 | Accuracy: 0.9286 | Loss: 0.3291 | F1: 0.9307\n",
      "\n",
      "Domain: 64\n",
      "x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 64 | Accuracy: 0.8810 | Loss: 0.3934 | F1: 0.8635\n",
      "\n",
      "Domain: 65\n",
      "x_dp_dom.shape: (50, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 65 | Accuracy: 0.9000 | Loss: 0.3909 | F1: 0.8888\n",
      "\n",
      "Domain: 66\n",
      "x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 66 | Accuracy: 0.8810 | Loss: 0.5236 | F1: 0.8635\n",
      "\n",
      "Domain: 67\n",
      "x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 67 | Accuracy: 0.9286 | Loss: 0.1883 | F1: 0.9251\n",
      "\n",
      "Domain: 68\n",
      "x_dp_dom.shape: (43, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 68 | Accuracy: 0.8605 | Loss: 0.3376 | F1: 0.8640\n",
      "\n",
      "Domain: 69\n",
      "x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 69 | Accuracy: 0.8810 | Loss: 0.2655 | F1: 0.8635\n",
      "\n",
      "Domain: 70\n",
      "x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 70 | Accuracy: 0.8810 | Loss: 0.2804 | F1: 0.8752\n",
      "\n",
      "Domain: 71\n",
      "x_dp_dom.shape: (44, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 71 | Accuracy: 0.9545 | Loss: 0.0961 | F1: 0.9565\n",
      "\n",
      "Domain: 72\n",
      "x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 72 | Accuracy: 0.5000 | Loss: 1.3575 | F1: 0.5427\n",
      "\n",
      "Domain: 73\n",
      "x_dp_dom.shape: (41, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 73 | Accuracy: 0.8049 | Loss: 0.3672 | F1: 0.7570\n",
      "\n",
      "Domain: 74\n",
      "x_dp_dom.shape: (35, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 74 | Accuracy: 0.8286 | Loss: 1.2087 | F1: 0.7824\n",
      "\n",
      "Domain: 75\n",
      "x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 75 | Accuracy: 0.8571 | Loss: 0.3782 | F1: 0.8453\n",
      "\n",
      "Mean accuracy for run 2: 0.8233\n",
      "Mean F1 for run 2: 0.8103\n",
      "\n",
      "Source class: WAL\n",
      "\n",
      "x_df.shape: (7958, 3, 128) | np.unique(y_df): [1 2 3]\n",
      "\n",
      "Training on Df data...\n",
      "\tEpoch 10/100 - Train loss: 0.0971 - Val accuracy: 0.7092 - Val loss: 0.9755 - Val F1: 0.5963 - LR: 9.00e-05\n",
      "\tEpoch 20/100 - Train loss: 0.0789 - Val accuracy: 0.4830 - Val loss: 2.1174 - Val F1: 0.3759 - LR: 8.00e-05\n",
      "\tEpoch 30/100 - Train loss: 0.0617 - Val accuracy: 0.7198 - Val loss: 1.3787 - Val F1: 0.6060 - LR: 7.00e-05\n",
      "\tEpoch 40/100 - Train loss: 0.0518 - Val accuracy: 0.7230 - Val loss: 1.5078 - Val F1: 0.6099 - LR: 6.00e-05\n",
      "\tEpoch 50/100 - Train loss: 0.0535 - Val accuracy: 0.7230 - Val loss: 1.9395 - Val F1: 0.6102 - LR: 5.00e-05\n",
      "\tEpoch 60/100 - Train loss: 0.0440 - Val accuracy: 0.7023 - Val loss: 2.2074 - Val F1: 0.5914 - LR: 4.00e-05\n",
      "\tEpoch 70/100 - Train loss: 0.0362 - Val accuracy: 0.7230 - Val loss: 2.4506 - Val F1: 0.6089 - LR: 3.00e-05\n",
      "\tEpoch 80/100 - Train loss: 0.0288 - Val accuracy: 0.7155 - Val loss: 2.5296 - Val F1: 0.6007 - LR: 2.00e-05\n",
      "\tEpoch 90/100 - Train loss: 0.0271 - Val accuracy: 0.7205 - Val loss: 2.7695 - Val F1: 0.6054 - LR: 1.00e-05\n",
      "\tEpoch 100/100 - Train loss: 0.0367 - Val accuracy: 0.7236 - Val loss: 2.2992 - Val F1: 0.6141 - LR: 0.00e+00\n",
      "\tBest epoch: 2 - Best val accuracy: 0.7399 - Best val loss: 0.5052 - Best val F1: 0.6628\n",
      "\n",
      "Domain: 15\n",
      "x_dp_dom.shape: (50, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 15 | Accuracy: 0.7800 | Loss: 2.4953 | F1: 0.7144\n",
      "\n",
      "Domain: 16\n",
      "x_dp_dom.shape: (54, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 16 | Accuracy: 0.7593 | Loss: 1.3573 | F1: 0.6790\n",
      "\n",
      "Domain: 17\n",
      "x_dp_dom.shape: (53, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 17 | Accuracy: 0.7736 | Loss: 2.2891 | F1: 0.6961\n",
      "\n",
      "Domain: 18\n",
      "x_dp_dom.shape: (54, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 18 | Accuracy: 0.7593 | Loss: 1.2136 | F1: 0.6790\n",
      "\n",
      "Domain: 19\n",
      "x_dp_dom.shape: (54, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 19 | Accuracy: 0.7407 | Loss: 1.9837 | F1: 0.6696\n",
      "\n",
      "Domain: 20\n",
      "x_dp_dom.shape: (51, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 20 | Accuracy: 0.7647 | Loss: 1.7370 | F1: 0.7078\n",
      "\n",
      "Domain: 21\n",
      "x_dp_dom.shape: (47, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 21 | Accuracy: 0.8511 | Loss: 0.5752 | F1: 0.7934\n",
      "\n",
      "Domain: 22\n",
      "x_dp_dom.shape: (54, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 22 | Accuracy: 0.8519 | Loss: 0.4026 | F1: 0.8364\n",
      "\n",
      "Domain: 23\n",
      "x_dp_dom.shape: (52, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 23 | Accuracy: 0.8462 | Loss: 0.5595 | F1: 0.8393\n",
      "\n",
      "Domain: 24\n",
      "x_dp_dom.shape: (51, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 24 | Accuracy: 0.6863 | Loss: 2.4153 | F1: 0.6333\n",
      "\n",
      "Domain: 25\n",
      "x_dp_dom.shape: (54, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 25 | Accuracy: 0.7407 | Loss: 2.0236 | F1: 0.6696\n",
      "\n",
      "Domain: 26\n",
      "x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 26 | Accuracy: 0.7381 | Loss: 0.7946 | F1: 0.7591\n",
      "\n",
      "Domain: 27\n",
      "x_dp_dom.shape: (54, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 27 | Accuracy: 0.7963 | Loss: 0.9784 | F1: 0.7519\n",
      "\n",
      "Domain: 28\n",
      "x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 28 | Accuracy: 0.8333 | Loss: 1.3374 | F1: 0.7778\n",
      "\n",
      "Domain: 29\n",
      "x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 29 | Accuracy: 0.8810 | Loss: 0.2724 | F1: 0.8751\n",
      "\n",
      "Domain: 30\n",
      "x_dp_dom.shape: (50, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 30 | Accuracy: 0.7400 | Loss: 2.4118 | F1: 0.7229\n",
      "\n",
      "Domain: 31\n",
      "x_dp_dom.shape: (43, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 31 | Accuracy: 0.8837 | Loss: 0.6128 | F1: 0.8770\n",
      "\n",
      "Domain: 32\n",
      "x_dp_dom.shape: (52, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 32 | Accuracy: 0.7885 | Loss: 1.7508 | F1: 0.7141\n",
      "\n",
      "Domain: 33\n",
      "x_dp_dom.shape: (44, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 33 | Accuracy: 0.8864 | Loss: 0.4983 | F1: 0.8862\n",
      "\n",
      "Domain: 34\n",
      "x_dp_dom.shape: (49, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 34 | Accuracy: 0.7347 | Loss: 1.2518 | F1: 0.7160\n",
      "\n",
      "Domain: 35\n",
      "x_dp_dom.shape: (48, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 35 | Accuracy: 0.7917 | Loss: 0.9590 | F1: 0.7459\n",
      "\n",
      "Domain: 36\n",
      "x_dp_dom.shape: (43, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 36 | Accuracy: 0.7442 | Loss: 1.1395 | F1: 0.7201\n",
      "\n",
      "Domain: 37\n",
      "x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 37 | Accuracy: 0.8095 | Loss: 1.2238 | F1: 0.7745\n",
      "\n",
      "Domain: 38\n",
      "x_dp_dom.shape: (47, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 38 | Accuracy: 0.8936 | Loss: 0.4785 | F1: 0.8732\n",
      "\n",
      "Domain: 39\n",
      "x_dp_dom.shape: (54, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 39 | Accuracy: 0.4444 | Loss: 2.1760 | F1: 0.4043\n",
      "\n",
      "Domain: 40\n",
      "x_dp_dom.shape: (44, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 40 | Accuracy: 0.7955 | Loss: 1.1970 | F1: 0.7557\n",
      "\n",
      "Domain: 41\n",
      "x_dp_dom.shape: (45, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 41 | Accuracy: 0.7111 | Loss: 1.8834 | F1: 0.6754\n",
      "\n",
      "Domain: 42\n",
      "x_dp_dom.shape: (46, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 42 | Accuracy: 0.8696 | Loss: 0.9398 | F1: 0.8531\n",
      "\n",
      "Domain: 43\n",
      "x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 43 | Accuracy: 0.8095 | Loss: 1.7553 | F1: 0.7606\n",
      "\n",
      "Domain: 44\n",
      "x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 44 | Accuracy: 0.8571 | Loss: 0.4425 | F1: 0.8440\n",
      "\n",
      "Domain: 45\n",
      "x_dp_dom.shape: (52, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 45 | Accuracy: 0.6538 | Loss: 1.3386 | F1: 0.6403\n",
      "\n",
      "Domain: 46\n",
      "x_dp_dom.shape: (48, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 46 | Accuracy: 0.8750 | Loss: 0.5054 | F1: 0.8582\n",
      "\n",
      "Domain: 47\n",
      "x_dp_dom.shape: (44, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 47 | Accuracy: 0.8182 | Loss: 0.6067 | F1: 0.7980\n",
      "\n",
      "Domain: 48\n",
      "x_dp_dom.shape: (48, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 48 | Accuracy: 0.8958 | Loss: 0.3578 | F1: 0.8783\n",
      "\n",
      "Domain: 49\n",
      "x_dp_dom.shape: (53, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 49 | Accuracy: 0.7358 | Loss: 1.8355 | F1: 0.6723\n",
      "\n",
      "Domain: 50\n",
      "x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 50 | Accuracy: 0.7857 | Loss: 0.6580 | F1: 0.7846\n",
      "\n",
      "Domain: 51\n",
      "x_dp_dom.shape: (46, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 51 | Accuracy: 0.8043 | Loss: 1.0093 | F1: 0.7827\n",
      "\n",
      "Domain: 52\n",
      "x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 52 | Accuracy: 0.8095 | Loss: 1.2987 | F1: 0.7657\n",
      "\n",
      "Domain: 53\n",
      "x_dp_dom.shape: (48, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 53 | Accuracy: 0.8125 | Loss: 0.9248 | F1: 0.7602\n",
      "\n",
      "Domain: 54\n",
      "x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 54 | Accuracy: 0.8095 | Loss: 1.4447 | F1: 0.7606\n",
      "\n",
      "Domain: 55\n",
      "x_dp_dom.shape: (49, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 55 | Accuracy: 0.4082 | Loss: 2.3904 | F1: 0.3890\n",
      "\n",
      "Domain: 56\n",
      "x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 56 | Accuracy: 0.8095 | Loss: 0.3427 | F1: 0.7503\n",
      "\n",
      "Domain: 57\n",
      "x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 57 | Accuracy: 0.7857 | Loss: 0.5218 | F1: 0.7809\n",
      "\n",
      "Domain: 58\n",
      "x_dp_dom.shape: (38, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 58 | Accuracy: 0.8158 | Loss: 0.7539 | F1: 0.7711\n",
      "\n",
      "Domain: 59\n",
      "x_dp_dom.shape: (43, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 59 | Accuracy: 0.5349 | Loss: 1.3265 | F1: 0.5837\n",
      "\n",
      "Domain: 60\n",
      "x_dp_dom.shape: (47, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 60 | Accuracy: 0.5106 | Loss: 4.9745 | F1: 0.4922\n",
      "\n",
      "Domain: 61\n",
      "x_dp_dom.shape: (47, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 61 | Accuracy: 0.6383 | Loss: 1.9549 | F1: 0.6157\n",
      "\n",
      "Domain: 62\n",
      "x_dp_dom.shape: (47, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 62 | Accuracy: 0.8723 | Loss: 0.7248 | F1: 0.8372\n",
      "\n",
      "Domain: 63\n",
      "x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 63 | Accuracy: 0.9286 | Loss: 0.3323 | F1: 0.9266\n",
      "\n",
      "Domain: 64\n",
      "x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 64 | Accuracy: 0.9286 | Loss: 0.2900 | F1: 0.9251\n",
      "\n",
      "Domain: 65\n",
      "x_dp_dom.shape: (50, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 65 | Accuracy: 0.6000 | Loss: 2.0159 | F1: 0.5701\n",
      "\n",
      "Domain: 66\n",
      "x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 66 | Accuracy: 0.7619 | Loss: 2.1679 | F1: 0.7262\n",
      "\n",
      "Domain: 67\n",
      "x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 67 | Accuracy: 0.8333 | Loss: 0.8214 | F1: 0.7665\n",
      "\n",
      "Domain: 68\n",
      "x_dp_dom.shape: (43, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 68 | Accuracy: 0.6279 | Loss: 1.1098 | F1: 0.6668\n",
      "\n",
      "Domain: 69\n",
      "x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 69 | Accuracy: 0.8333 | Loss: 0.8348 | F1: 0.7778\n",
      "\n",
      "Domain: 70\n",
      "x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 70 | Accuracy: 0.8333 | Loss: 1.5433 | F1: 0.7778\n",
      "\n",
      "Domain: 71\n",
      "x_dp_dom.shape: (44, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 71 | Accuracy: 1.0000 | Loss: 0.0278 | F1: 1.0000\n",
      "\n",
      "Domain: 72\n",
      "x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 72 | Accuracy: 0.6905 | Loss: 1.2517 | F1: 0.7103\n",
      "\n",
      "Domain: 73\n",
      "x_dp_dom.shape: (41, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 73 | Accuracy: 0.6341 | Loss: 2.9635 | F1: 0.6346\n",
      "\n",
      "Domain: 74\n",
      "x_dp_dom.shape: (35, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 74 | Accuracy: 0.7714 | Loss: 2.9268 | F1: 0.7200\n",
      "\n",
      "Domain: 75\n",
      "x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 75 | Accuracy: 0.7619 | Loss: 0.9270 | F1: 0.7262\n",
      "\n",
      "Mean accuracy for run 3: 0.7728\n",
      "Mean F1 for run 3: 0.7419\n",
      "\n",
      "Source class: WAL\n",
      "\n",
      "x_df.shape: (7958, 3, 128) | np.unique(y_df): [1 2 3]\n",
      "\n",
      "Training on Df data...\n",
      "\tEpoch 10/100 - Train loss: 0.1103 - Val accuracy: 0.7845 - Val loss: 0.5155 - Val F1: 0.7395 - LR: 9.00e-05\n",
      "\tEpoch 20/100 - Train loss: 0.0726 - Val accuracy: 0.7626 - Val loss: 0.5254 - Val F1: 0.7013 - LR: 8.00e-05\n",
      "\tEpoch 30/100 - Train loss: 0.0658 - Val accuracy: 0.8191 - Val loss: 0.4904 - Val F1: 0.8110 - LR: 7.00e-05\n",
      "\tEpoch 40/100 - Train loss: 0.0566 - Val accuracy: 0.7569 - Val loss: 0.5817 - Val F1: 0.6950 - LR: 6.00e-05\n",
      "\tEpoch 50/100 - Train loss: 0.0486 - Val accuracy: 0.7921 - Val loss: 0.8210 - Val F1: 0.7587 - LR: 5.00e-05\n",
      "\tEpoch 60/100 - Train loss: 0.0443 - Val accuracy: 0.7921 - Val loss: 0.6186 - Val F1: 0.7527 - LR: 4.00e-05\n",
      "\tEpoch 70/100 - Train loss: 0.0397 - Val accuracy: 0.8361 - Val loss: 0.5735 - Val F1: 0.8193 - LR: 3.00e-05\n",
      "\tEpoch 80/100 - Train loss: 0.0395 - Val accuracy: 0.8103 - Val loss: 0.5988 - Val F1: 0.7825 - LR: 2.00e-05\n",
      "\tEpoch 90/100 - Train loss: 0.0377 - Val accuracy: 0.8134 - Val loss: 0.6831 - Val F1: 0.7930 - LR: 1.00e-05\n",
      "\tEpoch 100/100 - Train loss: 0.0352 - Val accuracy: 0.8367 - Val loss: 0.5225 - Val F1: 0.8192 - LR: 0.00e+00\n",
      "\tBest epoch: 52 - Best val accuracy: 0.8788 - Best val loss: 0.3305 - Best val F1: 0.8748\n",
      "\n",
      "Domain: 15\n",
      "x_dp_dom.shape: (50, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 15 | Accuracy: 0.8000 | Loss: 2.0106 | F1: 0.7294\n",
      "\n",
      "Domain: 16\n",
      "x_dp_dom.shape: (54, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 16 | Accuracy: 0.7963 | Loss: 1.0519 | F1: 0.7519\n",
      "\n",
      "Domain: 17\n",
      "x_dp_dom.shape: (53, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 17 | Accuracy: 0.6415 | Loss: 2.2983 | F1: 0.6207\n",
      "\n",
      "Domain: 18\n",
      "x_dp_dom.shape: (54, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 18 | Accuracy: 0.7037 | Loss: 1.8228 | F1: 0.6456\n",
      "\n",
      "Domain: 19\n",
      "x_dp_dom.shape: (54, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 19 | Accuracy: 0.7222 | Loss: 1.4656 | F1: 0.6558\n",
      "\n",
      "Domain: 20\n",
      "x_dp_dom.shape: (51, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 20 | Accuracy: 0.7451 | Loss: 0.9086 | F1: 0.7240\n",
      "\n",
      "Domain: 21\n",
      "x_dp_dom.shape: (47, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 21 | Accuracy: 0.8723 | Loss: 0.7080 | F1: 0.8372\n",
      "\n",
      "Domain: 22\n",
      "x_dp_dom.shape: (54, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 22 | Accuracy: 0.8333 | Loss: 0.6250 | F1: 0.8203\n",
      "\n",
      "Domain: 23\n",
      "x_dp_dom.shape: (52, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 23 | Accuracy: 0.7885 | Loss: 0.6025 | F1: 0.7396\n",
      "\n",
      "Domain: 24\n",
      "x_dp_dom.shape: (51, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 24 | Accuracy: 0.7255 | Loss: 1.2068 | F1: 0.6544\n",
      "\n",
      "Domain: 25\n",
      "x_dp_dom.shape: (54, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 25 | Accuracy: 0.7222 | Loss: 1.8615 | F1: 0.6520\n",
      "\n",
      "Domain: 26\n",
      "x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 26 | Accuracy: 0.8810 | Loss: 0.2792 | F1: 0.8862\n",
      "\n",
      "Domain: 27\n",
      "x_dp_dom.shape: (54, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 27 | Accuracy: 0.7593 | Loss: 1.7894 | F1: 0.6790\n",
      "\n",
      "Domain: 28\n",
      "x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 28 | Accuracy: 0.7381 | Loss: 0.9627 | F1: 0.7214\n",
      "\n",
      "Domain: 29\n",
      "x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 29 | Accuracy: 0.7857 | Loss: 0.9161 | F1: 0.7759\n",
      "\n",
      "Domain: 30\n",
      "x_dp_dom.shape: (50, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 30 | Accuracy: 0.7800 | Loss: 1.2974 | F1: 0.7793\n",
      "\n",
      "Domain: 31\n",
      "x_dp_dom.shape: (43, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 31 | Accuracy: 0.8372 | Loss: 0.7193 | F1: 0.8108\n",
      "\n",
      "Domain: 32\n",
      "x_dp_dom.shape: (52, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 32 | Accuracy: 0.6538 | Loss: 1.2182 | F1: 0.6282\n",
      "\n",
      "Domain: 33\n",
      "x_dp_dom.shape: (44, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 33 | Accuracy: 0.8864 | Loss: 0.2215 | F1: 0.8885\n",
      "\n",
      "Domain: 34\n",
      "x_dp_dom.shape: (49, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 34 | Accuracy: 0.8980 | Loss: 0.3074 | F1: 0.8914\n",
      "\n",
      "Domain: 35\n",
      "x_dp_dom.shape: (48, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 35 | Accuracy: 0.8125 | Loss: 0.5636 | F1: 0.7929\n",
      "\n",
      "Domain: 36\n",
      "x_dp_dom.shape: (43, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 36 | Accuracy: 0.7442 | Loss: 0.6341 | F1: 0.7548\n",
      "\n",
      "Domain: 37\n",
      "x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 37 | Accuracy: 0.8333 | Loss: 0.5566 | F1: 0.8343\n",
      "\n",
      "Domain: 38\n",
      "x_dp_dom.shape: (47, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 38 | Accuracy: 0.8085 | Loss: 1.0274 | F1: 0.7930\n",
      "\n",
      "Domain: 39\n",
      "x_dp_dom.shape: (54, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 39 | Accuracy: 0.7222 | Loss: 1.6262 | F1: 0.6520\n",
      "\n",
      "Domain: 40\n",
      "x_dp_dom.shape: (44, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 40 | Accuracy: 0.4773 | Loss: 1.2848 | F1: 0.4894\n",
      "\n",
      "Domain: 41\n",
      "x_dp_dom.shape: (45, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 41 | Accuracy: 0.5111 | Loss: 1.6476 | F1: 0.5437\n",
      "\n",
      "Domain: 42\n",
      "x_dp_dom.shape: (46, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 42 | Accuracy: 0.6957 | Loss: 0.8752 | F1: 0.7166\n",
      "\n",
      "Domain: 43\n",
      "x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 43 | Accuracy: 0.8810 | Loss: 1.1856 | F1: 0.8635\n",
      "\n",
      "Domain: 44\n",
      "x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 44 | Accuracy: 0.8095 | Loss: 0.3929 | F1: 0.7864\n",
      "\n",
      "Domain: 45\n",
      "x_dp_dom.shape: (52, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 45 | Accuracy: 0.8269 | Loss: 0.3791 | F1: 0.8045\n",
      "\n",
      "Domain: 46\n",
      "x_dp_dom.shape: (48, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 46 | Accuracy: 0.8542 | Loss: 0.9010 | F1: 0.7967\n",
      "\n",
      "Domain: 47\n",
      "x_dp_dom.shape: (44, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 47 | Accuracy: 0.8636 | Loss: 0.4548 | F1: 0.8602\n",
      "\n",
      "Domain: 48\n",
      "x_dp_dom.shape: (48, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 48 | Accuracy: 0.8542 | Loss: 0.6996 | F1: 0.8139\n",
      "\n",
      "Domain: 49\n",
      "x_dp_dom.shape: (53, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 49 | Accuracy: 0.6604 | Loss: 1.1541 | F1: 0.6356\n",
      "\n",
      "Domain: 50\n",
      "x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 50 | Accuracy: 0.8571 | Loss: 0.2534 | F1: 0.8328\n",
      "\n",
      "Domain: 51\n",
      "x_dp_dom.shape: (46, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 51 | Accuracy: 0.8696 | Loss: 0.7977 | F1: 0.8645\n",
      "\n",
      "Domain: 52\n",
      "x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 52 | Accuracy: 0.8095 | Loss: 0.9237 | F1: 0.7657\n",
      "\n",
      "Domain: 53\n",
      "x_dp_dom.shape: (48, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 53 | Accuracy: 0.8542 | Loss: 0.4073 | F1: 0.8139\n",
      "\n",
      "Domain: 54\n",
      "x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 54 | Accuracy: 0.9048 | Loss: 0.4195 | F1: 0.8963\n",
      "\n",
      "Domain: 55\n",
      "x_dp_dom.shape: (49, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 55 | Accuracy: 0.6735 | Loss: 0.9883 | F1: 0.6954\n",
      "\n",
      "Domain: 56\n",
      "x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 56 | Accuracy: 0.8810 | Loss: 0.3678 | F1: 0.8550\n",
      "\n",
      "Domain: 57\n",
      "x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 57 | Accuracy: 0.7857 | Loss: 0.4126 | F1: 0.7707\n",
      "\n",
      "Domain: 58\n",
      "x_dp_dom.shape: (38, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 58 | Accuracy: 0.8421 | Loss: 0.3862 | F1: 0.8284\n",
      "\n",
      "Domain: 59\n",
      "x_dp_dom.shape: (43, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 59 | Accuracy: 0.8837 | Loss: 0.2001 | F1: 0.8911\n",
      "\n",
      "Domain: 60\n",
      "x_dp_dom.shape: (47, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 60 | Accuracy: 0.8298 | Loss: 1.6413 | F1: 0.7674\n",
      "\n",
      "Domain: 61\n",
      "x_dp_dom.shape: (47, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 61 | Accuracy: 0.8085 | Loss: 0.5099 | F1: 0.8154\n",
      "\n",
      "Domain: 62\n",
      "x_dp_dom.shape: (47, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 62 | Accuracy: 0.8085 | Loss: 0.5239 | F1: 0.8070\n",
      "\n",
      "Domain: 63\n",
      "x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 63 | Accuracy: 0.8571 | Loss: 0.5190 | F1: 0.8613\n",
      "\n",
      "Domain: 64\n",
      "x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 64 | Accuracy: 0.8810 | Loss: 0.3641 | F1: 0.8587\n",
      "\n",
      "Domain: 65\n",
      "x_dp_dom.shape: (50, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 65 | Accuracy: 0.8800 | Loss: 0.6162 | F1: 0.8612\n",
      "\n",
      "Domain: 66\n",
      "x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 66 | Accuracy: 0.8095 | Loss: 1.7196 | F1: 0.7667\n",
      "\n",
      "Domain: 67\n",
      "x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 67 | Accuracy: 0.8810 | Loss: 0.2674 | F1: 0.8787\n",
      "\n",
      "Domain: 68\n",
      "x_dp_dom.shape: (43, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 68 | Accuracy: 0.6744 | Loss: 0.8577 | F1: 0.7079\n",
      "\n",
      "Domain: 69\n",
      "x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 69 | Accuracy: 0.8810 | Loss: 0.4187 | F1: 0.8635\n",
      "\n",
      "Domain: 70\n",
      "x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 70 | Accuracy: 0.8571 | Loss: 0.5834 | F1: 0.8444\n",
      "\n",
      "Domain: 71\n",
      "x_dp_dom.shape: (44, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 71 | Accuracy: 0.9773 | Loss: 0.0494 | F1: 0.9770\n",
      "\n",
      "Domain: 72\n",
      "x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 72 | Accuracy: 0.5952 | Loss: 1.0265 | F1: 0.6379\n",
      "\n",
      "Domain: 73\n",
      "x_dp_dom.shape: (41, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 73 | Accuracy: 0.8293 | Loss: 1.5566 | F1: 0.7687\n",
      "\n",
      "Domain: 74\n",
      "x_dp_dom.shape: (35, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 74 | Accuracy: 0.8286 | Loss: 0.8709 | F1: 0.7914\n",
      "\n",
      "Domain: 75\n",
      "x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 75 | Accuracy: 0.8571 | Loss: 0.3211 | F1: 0.8440\n",
      "\n",
      "Mean accuracy for run 4: 0.7958\n",
      "Mean F1 for run 4: 0.7753\n",
      "\n",
      "Source class: WAL\n",
      "\n",
      "x_df.shape: (7958, 3, 128) | np.unique(y_df): [1 2 3]\n",
      "\n",
      "Training on Df data...\n",
      "\tEpoch 10/100 - Train loss: 0.1050 - Val accuracy: 0.6093 - Val loss: 1.8128 - Val F1: 0.5190 - LR: 9.00e-05\n",
      "\tEpoch 20/100 - Train loss: 0.0757 - Val accuracy: 0.7198 - Val loss: 1.6206 - Val F1: 0.6058 - LR: 8.00e-05\n",
      "\tEpoch 30/100 - Train loss: 0.0613 - Val accuracy: 0.7205 - Val loss: 1.7865 - Val F1: 0.6064 - LR: 7.00e-05\n",
      "\tEpoch 40/100 - Train loss: 0.0503 - Val accuracy: 0.7217 - Val loss: 2.2113 - Val F1: 0.6088 - LR: 6.00e-05\n",
      "\tEpoch 50/100 - Train loss: 0.0485 - Val accuracy: 0.7192 - Val loss: 2.8836 - Val F1: 0.6157 - LR: 5.00e-05\n",
      "\tEpoch 60/100 - Train loss: 0.0400 - Val accuracy: 0.7186 - Val loss: 3.0167 - Val F1: 0.6160 - LR: 4.00e-05\n",
      "\tEpoch 70/100 - Train loss: 0.0390 - Val accuracy: 0.7217 - Val loss: 2.6442 - Val F1: 0.6118 - LR: 3.00e-05\n",
      "\tEpoch 80/100 - Train loss: 0.0326 - Val accuracy: 0.7205 - Val loss: 2.2020 - Val F1: 0.6160 - LR: 2.00e-05\n",
      "\tEpoch 90/100 - Train loss: 0.0354 - Val accuracy: 0.7217 - Val loss: 2.6638 - Val F1: 0.6151 - LR: 1.00e-05\n",
      "\tEpoch 100/100 - Train loss: 0.0398 - Val accuracy: 0.7217 - Val loss: 2.8579 - Val F1: 0.6146 - LR: 0.00e+00\n",
      "\tBest epoch: 3 - Best val accuracy: 0.7010 - Best val loss: 0.6032 - Best val F1: 0.6254\n",
      "\n",
      "Domain: 15\n",
      "x_dp_dom.shape: (50, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 15 | Accuracy: 0.8000 | Loss: 1.9387 | F1: 0.7111\n",
      "\n",
      "Domain: 16\n",
      "x_dp_dom.shape: (54, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 16 | Accuracy: 0.7778 | Loss: 0.6505 | F1: 0.7176\n",
      "\n",
      "Domain: 17\n",
      "x_dp_dom.shape: (53, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 17 | Accuracy: 0.6226 | Loss: 2.6050 | F1: 0.6081\n",
      "\n",
      "Domain: 18\n",
      "x_dp_dom.shape: (54, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 18 | Accuracy: 0.7222 | Loss: 1.6778 | F1: 0.6598\n",
      "\n",
      "Domain: 19\n",
      "x_dp_dom.shape: (54, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 19 | Accuracy: 0.7037 | Loss: 2.2992 | F1: 0.6497\n",
      "\n",
      "Domain: 20\n",
      "x_dp_dom.shape: (51, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 20 | Accuracy: 0.7843 | Loss: 1.0508 | F1: 0.7482\n",
      "\n",
      "Domain: 21\n",
      "x_dp_dom.shape: (47, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 21 | Accuracy: 0.8723 | Loss: 0.4543 | F1: 0.8372\n",
      "\n",
      "Domain: 22\n",
      "x_dp_dom.shape: (54, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 22 | Accuracy: 0.8519 | Loss: 0.4576 | F1: 0.8435\n",
      "\n",
      "Domain: 23\n",
      "x_dp_dom.shape: (52, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 23 | Accuracy: 0.7308 | Loss: 0.8755 | F1: 0.7185\n",
      "\n",
      "Domain: 24\n",
      "x_dp_dom.shape: (51, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 24 | Accuracy: 0.6863 | Loss: 1.3133 | F1: 0.6300\n",
      "\n",
      "Domain: 25\n",
      "x_dp_dom.shape: (54, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 25 | Accuracy: 0.7407 | Loss: 1.6004 | F1: 0.6656\n",
      "\n",
      "Domain: 26\n",
      "x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 26 | Accuracy: 0.9286 | Loss: 0.2566 | F1: 0.9286\n",
      "\n",
      "Domain: 27\n",
      "x_dp_dom.shape: (54, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 27 | Accuracy: 0.6296 | Loss: 2.3858 | F1: 0.6049\n",
      "\n",
      "Domain: 28\n",
      "x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 28 | Accuracy: 0.8571 | Loss: 0.7167 | F1: 0.8440\n",
      "\n",
      "Domain: 29\n",
      "x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 29 | Accuracy: 0.8333 | Loss: 0.5635 | F1: 0.8254\n",
      "\n",
      "Domain: 30\n",
      "x_dp_dom.shape: (50, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 30 | Accuracy: 0.8000 | Loss: 1.4028 | F1: 0.7721\n",
      "\n",
      "Domain: 31\n",
      "x_dp_dom.shape: (43, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 31 | Accuracy: 0.8837 | Loss: 0.5094 | F1: 0.8734\n",
      "\n",
      "Domain: 32\n",
      "x_dp_dom.shape: (52, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 32 | Accuracy: 0.7308 | Loss: 1.1085 | F1: 0.6837\n",
      "\n",
      "Domain: 33\n",
      "x_dp_dom.shape: (44, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 33 | Accuracy: 0.8864 | Loss: 0.2255 | F1: 0.8863\n",
      "\n",
      "Domain: 34\n",
      "x_dp_dom.shape: (49, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 34 | Accuracy: 0.8571 | Loss: 1.0253 | F1: 0.8477\n",
      "\n",
      "Domain: 35\n",
      "x_dp_dom.shape: (48, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 35 | Accuracy: 0.7292 | Loss: 1.1318 | F1: 0.7204\n",
      "\n",
      "Domain: 36\n",
      "x_dp_dom.shape: (43, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 36 | Accuracy: 0.8140 | Loss: 0.7343 | F1: 0.8103\n",
      "\n",
      "Domain: 37\n",
      "x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 37 | Accuracy: 0.8571 | Loss: 0.6319 | F1: 0.8515\n",
      "\n",
      "Domain: 38\n",
      "x_dp_dom.shape: (47, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 38 | Accuracy: 0.8085 | Loss: 0.9576 | F1: 0.7700\n",
      "\n",
      "Domain: 39\n",
      "x_dp_dom.shape: (54, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 39 | Accuracy: 0.5000 | Loss: 1.9317 | F1: 0.4118\n",
      "\n",
      "Domain: 40\n",
      "x_dp_dom.shape: (44, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 40 | Accuracy: 0.8409 | Loss: 0.6231 | F1: 0.8405\n",
      "\n",
      "Domain: 41\n",
      "x_dp_dom.shape: (45, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 41 | Accuracy: 0.6444 | Loss: 3.0350 | F1: 0.6518\n",
      "\n",
      "Domain: 42\n",
      "x_dp_dom.shape: (46, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 42 | Accuracy: 0.7609 | Loss: 1.0278 | F1: 0.7487\n",
      "\n",
      "Domain: 43\n",
      "x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 43 | Accuracy: 0.8095 | Loss: 1.5372 | F1: 0.7704\n",
      "\n",
      "Domain: 44\n",
      "x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 44 | Accuracy: 0.9048 | Loss: 0.3105 | F1: 0.9029\n",
      "\n",
      "Domain: 45\n",
      "x_dp_dom.shape: (52, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 45 | Accuracy: 0.8269 | Loss: 0.6322 | F1: 0.7893\n",
      "\n",
      "Domain: 46\n",
      "x_dp_dom.shape: (48, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 46 | Accuracy: 0.8750 | Loss: 0.5226 | F1: 0.8398\n",
      "\n",
      "Domain: 47\n",
      "x_dp_dom.shape: (44, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 47 | Accuracy: 0.8409 | Loss: 0.4388 | F1: 0.8241\n",
      "\n",
      "Domain: 48\n",
      "x_dp_dom.shape: (48, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 48 | Accuracy: 0.9167 | Loss: 0.3764 | F1: 0.9064\n",
      "\n",
      "Domain: 49\n",
      "x_dp_dom.shape: (53, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 49 | Accuracy: 0.7358 | Loss: 1.6184 | F1: 0.6723\n",
      "\n",
      "Domain: 50\n",
      "x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 50 | Accuracy: 0.8333 | Loss: 0.3848 | F1: 0.8090\n",
      "\n",
      "Domain: 51\n",
      "x_dp_dom.shape: (46, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 51 | Accuracy: 0.8913 | Loss: 0.8600 | F1: 0.8758\n",
      "\n",
      "Domain: 52\n",
      "x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 52 | Accuracy: 0.8333 | Loss: 0.7710 | F1: 0.8082\n",
      "\n",
      "Domain: 53\n",
      "x_dp_dom.shape: (48, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 53 | Accuracy: 0.7917 | Loss: 0.6003 | F1: 0.7492\n",
      "\n",
      "Domain: 54\n",
      "x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 54 | Accuracy: 0.8810 | Loss: 0.3918 | F1: 0.8635\n",
      "\n",
      "Domain: 55\n",
      "x_dp_dom.shape: (49, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 55 | Accuracy: 0.8163 | Loss: 0.7929 | F1: 0.7890\n",
      "\n",
      "Domain: 56\n",
      "x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 56 | Accuracy: 0.9524 | Loss: 0.1457 | F1: 0.9523\n",
      "\n",
      "Domain: 57\n",
      "x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 57 | Accuracy: 0.9762 | Loss: 0.0720 | F1: 0.9755\n",
      "\n",
      "Domain: 58\n",
      "x_dp_dom.shape: (38, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 58 | Accuracy: 0.8158 | Loss: 0.7557 | F1: 0.7897\n",
      "\n",
      "Domain: 59\n",
      "x_dp_dom.shape: (43, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 59 | Accuracy: 0.9302 | Loss: 0.1857 | F1: 0.9299\n",
      "\n",
      "Domain: 60\n",
      "x_dp_dom.shape: (47, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 60 | Accuracy: 0.5957 | Loss: 2.4188 | F1: 0.4802\n",
      "\n",
      "Domain: 61\n",
      "x_dp_dom.shape: (47, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 61 | Accuracy: 0.8511 | Loss: 0.6235 | F1: 0.8347\n",
      "\n",
      "Domain: 62\n",
      "x_dp_dom.shape: (47, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 62 | Accuracy: 0.8511 | Loss: 0.4883 | F1: 0.8198\n",
      "\n",
      "Domain: 63\n",
      "x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 63 | Accuracy: 0.8810 | Loss: 0.4877 | F1: 0.8806\n",
      "\n",
      "Domain: 64\n",
      "x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 64 | Accuracy: 0.8810 | Loss: 0.1613 | F1: 0.8635\n",
      "\n",
      "Domain: 65\n",
      "x_dp_dom.shape: (50, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 65 | Accuracy: 0.8600 | Loss: 0.8617 | F1: 0.8389\n",
      "\n",
      "Domain: 66\n",
      "x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 66 | Accuracy: 0.8333 | Loss: 1.9129 | F1: 0.7778\n",
      "\n",
      "Domain: 67\n",
      "x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 67 | Accuracy: 0.9048 | Loss: 0.1958 | F1: 0.8922\n",
      "\n",
      "Domain: 68\n",
      "x_dp_dom.shape: (43, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 68 | Accuracy: 0.7907 | Loss: 0.7148 | F1: 0.8013\n",
      "\n",
      "Domain: 69\n",
      "x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 69 | Accuracy: 0.8810 | Loss: 0.5941 | F1: 0.8635\n",
      "\n",
      "Domain: 70\n",
      "x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 70 | Accuracy: 0.7857 | Loss: 1.2126 | F1: 0.7594\n",
      "\n",
      "Domain: 71\n",
      "x_dp_dom.shape: (44, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 71 | Accuracy: 0.9545 | Loss: 0.1001 | F1: 0.9565\n",
      "\n",
      "Domain: 72\n",
      "x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 72 | Accuracy: 0.7857 | Loss: 0.8064 | F1: 0.7531\n",
      "\n",
      "Domain: 73\n",
      "x_dp_dom.shape: (41, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 73 | Accuracy: 0.6829 | Loss: 2.7389 | F1: 0.5543\n",
      "\n",
      "Domain: 74\n",
      "x_dp_dom.shape: (35, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 74 | Accuracy: 0.8286 | Loss: 1.7766 | F1: 0.7702\n",
      "\n",
      "Domain: 75\n",
      "x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 75 | Accuracy: 0.8333 | Loss: 0.6633 | F1: 0.8073\n",
      "\n",
      "Mean accuracy for run 5: 0.8112\n",
      "Mean F1 for run 5: 0.7830\n",
      "\n",
      "Source class: WAL\n",
      "\n",
      "x_df.shape: (7958, 3, 128) | np.unique(y_df): [1 2 3]\n",
      "\n",
      "Training on Df data...\n",
      "\tEpoch 10/100 - Train loss: 0.1087 - Val accuracy: 0.4768 - Val loss: 1.4810 - Val F1: 0.4493 - LR: 9.00e-05\n",
      "\tEpoch 20/100 - Train loss: 0.0799 - Val accuracy: 0.7117 - Val loss: 1.4904 - Val F1: 0.6327 - LR: 8.00e-05\n",
      "\tEpoch 30/100 - Train loss: 0.0727 - Val accuracy: 0.6884 - Val loss: 1.9556 - Val F1: 0.6178 - LR: 7.00e-05\n",
      "\tEpoch 40/100 - Train loss: 0.0604 - Val accuracy: 0.7048 - Val loss: 2.3655 - Val F1: 0.6198 - LR: 6.00e-05\n",
      "\tEpoch 50/100 - Train loss: 0.0556 - Val accuracy: 0.6394 - Val loss: 2.7835 - Val F1: 0.5708 - LR: 5.00e-05\n",
      "\tEpoch 60/100 - Train loss: 0.0409 - Val accuracy: 0.6646 - Val loss: 3.0009 - Val F1: 0.5915 - LR: 4.00e-05\n",
      "\tEpoch 70/100 - Train loss: 0.0413 - Val accuracy: 0.6489 - Val loss: 2.5102 - Val F1: 0.5899 - LR: 3.00e-05\n",
      "\tEpoch 80/100 - Train loss: 0.0382 - Val accuracy: 0.6910 - Val loss: 3.3586 - Val F1: 0.6045 - LR: 2.00e-05\n",
      "\tEpoch 90/100 - Train loss: 0.0383 - Val accuracy: 0.6589 - Val loss: 3.8047 - Val F1: 0.5835 - LR: 1.00e-05\n",
      "\tEpoch 100/100 - Train loss: 0.0363 - Val accuracy: 0.6118 - Val loss: 3.4956 - Val F1: 0.5552 - LR: 0.00e+00\n",
      "\tBest epoch: 3 - Best val accuracy: 0.6947 - Best val loss: 0.6158 - Best val F1: 0.7104\n",
      "\n",
      "Domain: 15\n",
      "x_dp_dom.shape: (50, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 15 | Accuracy: 0.7200 | Loss: 4.2434 | F1: 0.6685\n",
      "\n",
      "Domain: 16\n",
      "x_dp_dom.shape: (54, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 16 | Accuracy: 0.7407 | Loss: 1.2982 | F1: 0.6941\n",
      "\n",
      "Domain: 17\n",
      "x_dp_dom.shape: (53, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 17 | Accuracy: 0.3962 | Loss: 3.4161 | F1: 0.4026\n",
      "\n",
      "Domain: 18\n",
      "x_dp_dom.shape: (54, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 18 | Accuracy: 0.6852 | Loss: 1.8438 | F1: 0.6391\n",
      "\n",
      "Domain: 19\n",
      "x_dp_dom.shape: (54, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 19 | Accuracy: 0.6667 | Loss: 2.1817 | F1: 0.6282\n",
      "\n",
      "Domain: 20\n",
      "x_dp_dom.shape: (51, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 20 | Accuracy: 0.7451 | Loss: 1.3316 | F1: 0.7020\n",
      "\n",
      "Domain: 21\n",
      "x_dp_dom.shape: (47, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 21 | Accuracy: 0.8298 | Loss: 0.7806 | F1: 0.7826\n",
      "\n",
      "Domain: 22\n",
      "x_dp_dom.shape: (54, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 22 | Accuracy: 0.8519 | Loss: 0.6042 | F1: 0.8432\n",
      "\n",
      "Domain: 23\n",
      "x_dp_dom.shape: (52, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 23 | Accuracy: 0.7885 | Loss: 0.9287 | F1: 0.7418\n",
      "\n",
      "Domain: 24\n",
      "x_dp_dom.shape: (51, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 24 | Accuracy: 0.6863 | Loss: 1.6331 | F1: 0.6333\n",
      "\n",
      "Domain: 25\n",
      "x_dp_dom.shape: (54, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 25 | Accuracy: 0.7407 | Loss: 2.1056 | F1: 0.6696\n",
      "\n",
      "Domain: 26\n",
      "x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 26 | Accuracy: 0.8571 | Loss: 0.3492 | F1: 0.8654\n",
      "\n",
      "Domain: 27\n",
      "x_dp_dom.shape: (54, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 27 | Accuracy: 0.7407 | Loss: 1.4969 | F1: 0.6696\n",
      "\n",
      "Domain: 28\n",
      "x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 28 | Accuracy: 0.8571 | Loss: 0.7174 | F1: 0.8250\n",
      "\n",
      "Domain: 29\n",
      "x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 29 | Accuracy: 0.2857 | Loss: 2.2245 | F1: 0.2463\n",
      "\n",
      "Domain: 30\n",
      "x_dp_dom.shape: (50, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 30 | Accuracy: 0.8000 | Loss: 2.2512 | F1: 0.7930\n",
      "\n",
      "Domain: 31\n",
      "x_dp_dom.shape: (43, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 31 | Accuracy: 0.9070 | Loss: 0.7318 | F1: 0.9045\n",
      "\n",
      "Domain: 32\n",
      "x_dp_dom.shape: (52, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 32 | Accuracy: 0.6731 | Loss: 1.4455 | F1: 0.6495\n",
      "\n",
      "Domain: 33\n",
      "x_dp_dom.shape: (44, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 33 | Accuracy: 0.9091 | Loss: 0.2588 | F1: 0.9062\n",
      "\n",
      "Domain: 34\n",
      "x_dp_dom.shape: (49, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 34 | Accuracy: 0.7959 | Loss: 0.7414 | F1: 0.7839\n",
      "\n",
      "Domain: 35\n",
      "x_dp_dom.shape: (48, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 35 | Accuracy: 0.6875 | Loss: 1.4765 | F1: 0.6995\n",
      "\n",
      "Domain: 36\n",
      "x_dp_dom.shape: (43, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 36 | Accuracy: 0.4884 | Loss: 1.4107 | F1: 0.5370\n",
      "\n",
      "Domain: 37\n",
      "x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 37 | Accuracy: 0.7857 | Loss: 0.7307 | F1: 0.7865\n",
      "\n",
      "Domain: 38\n",
      "x_dp_dom.shape: (47, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 38 | Accuracy: 0.8511 | Loss: 0.9660 | F1: 0.8225\n",
      "\n",
      "Domain: 39\n",
      "x_dp_dom.shape: (54, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 39 | Accuracy: 0.4074 | Loss: 6.1744 | F1: 0.3602\n",
      "\n",
      "Domain: 40\n",
      "x_dp_dom.shape: (44, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 40 | Accuracy: 0.7273 | Loss: 0.9194 | F1: 0.7450\n",
      "\n",
      "Domain: 41\n",
      "x_dp_dom.shape: (45, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 41 | Accuracy: 0.6000 | Loss: 2.5657 | F1: 0.6408\n",
      "\n",
      "Domain: 42\n",
      "x_dp_dom.shape: (46, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 42 | Accuracy: 0.8261 | Loss: 1.0231 | F1: 0.8294\n",
      "\n",
      "Domain: 43\n",
      "x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 43 | Accuracy: 0.7857 | Loss: 2.5734 | F1: 0.7720\n",
      "\n",
      "Domain: 44\n",
      "x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 44 | Accuracy: 0.8571 | Loss: 0.4433 | F1: 0.8549\n",
      "\n",
      "Domain: 45\n",
      "x_dp_dom.shape: (52, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 45 | Accuracy: 0.7308 | Loss: 0.9933 | F1: 0.7040\n",
      "\n",
      "Domain: 46\n",
      "x_dp_dom.shape: (48, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 46 | Accuracy: 0.8333 | Loss: 0.8424 | F1: 0.7861\n",
      "\n",
      "Domain: 47\n",
      "x_dp_dom.shape: (44, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 47 | Accuracy: 0.8864 | Loss: 0.3445 | F1: 0.8860\n",
      "\n",
      "Domain: 48\n",
      "x_dp_dom.shape: (48, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 48 | Accuracy: 0.9167 | Loss: 0.2681 | F1: 0.9087\n",
      "\n",
      "Domain: 49\n",
      "x_dp_dom.shape: (53, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 49 | Accuracy: 0.6226 | Loss: 1.6100 | F1: 0.6081\n",
      "\n",
      "Domain: 50\n",
      "x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 50 | Accuracy: 0.8810 | Loss: 0.3018 | F1: 0.8774\n",
      "\n",
      "Domain: 51\n",
      "x_dp_dom.shape: (46, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 51 | Accuracy: 0.8478 | Loss: 1.1306 | F1: 0.8435\n",
      "\n",
      "Domain: 52\n",
      "x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 52 | Accuracy: 0.6190 | Loss: 1.1614 | F1: 0.6501\n",
      "\n",
      "Domain: 53\n",
      "x_dp_dom.shape: (48, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 53 | Accuracy: 0.6042 | Loss: 1.1782 | F1: 0.6337\n",
      "\n",
      "Domain: 54\n",
      "x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 54 | Accuracy: 0.9048 | Loss: 0.1540 | F1: 0.9029\n",
      "\n",
      "Domain: 55\n",
      "x_dp_dom.shape: (49, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 55 | Accuracy: 0.5918 | Loss: 1.3256 | F1: 0.6185\n",
      "\n",
      "Domain: 56\n",
      "x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 56 | Accuracy: 0.9048 | Loss: 0.1803 | F1: 0.9048\n",
      "\n",
      "Domain: 57\n",
      "x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 57 | Accuracy: 0.9524 | Loss: 0.1438 | F1: 0.9492\n",
      "\n",
      "Domain: 58\n",
      "x_dp_dom.shape: (38, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 58 | Accuracy: 0.8421 | Loss: 0.5418 | F1: 0.8355\n",
      "\n",
      "Domain: 59\n",
      "x_dp_dom.shape: (43, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 59 | Accuracy: 0.8605 | Loss: 0.3247 | F1: 0.8710\n",
      "\n",
      "Domain: 60\n",
      "x_dp_dom.shape: (47, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 60 | Accuracy: 0.5745 | Loss: 6.0205 | F1: 0.5559\n",
      "\n",
      "Domain: 61\n",
      "x_dp_dom.shape: (47, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 61 | Accuracy: 0.8723 | Loss: 0.7675 | F1: 0.8787\n",
      "\n",
      "Domain: 62\n",
      "x_dp_dom.shape: (47, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 62 | Accuracy: 0.7021 | Loss: 0.9746 | F1: 0.7140\n",
      "\n",
      "Domain: 63\n",
      "x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 63 | Accuracy: 0.8810 | Loss: 0.4056 | F1: 0.8860\n",
      "\n",
      "Domain: 64\n",
      "x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 64 | Accuracy: 0.8333 | Loss: 0.4389 | F1: 0.7716\n",
      "\n",
      "Domain: 65\n",
      "x_dp_dom.shape: (50, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 65 | Accuracy: 0.4800 | Loss: 3.0445 | F1: 0.4689\n",
      "\n",
      "Domain: 66\n",
      "x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 66 | Accuracy: 0.7381 | Loss: 2.6979 | F1: 0.7087\n",
      "\n",
      "Domain: 67\n",
      "x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 67 | Accuracy: 0.8810 | Loss: 0.3398 | F1: 0.8818\n",
      "\n",
      "Domain: 68\n",
      "x_dp_dom.shape: (43, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 68 | Accuracy: 0.5581 | Loss: 1.0679 | F1: 0.5956\n",
      "\n",
      "Domain: 69\n",
      "x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 69 | Accuracy: 0.8333 | Loss: 0.5688 | F1: 0.8073\n",
      "\n",
      "Domain: 70\n",
      "x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 70 | Accuracy: 0.9048 | Loss: 1.1015 | F1: 0.8963\n",
      "\n",
      "Domain: 71\n",
      "x_dp_dom.shape: (44, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 71 | Accuracy: 0.8864 | Loss: 0.3245 | F1: 0.8957\n",
      "\n",
      "Domain: 72\n",
      "x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 72 | Accuracy: 0.8810 | Loss: 0.5360 | F1: 0.8635\n",
      "\n",
      "Domain: 73\n",
      "x_dp_dom.shape: (41, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 73 | Accuracy: 0.7317 | Loss: 3.2752 | F1: 0.7116\n",
      "\n",
      "Domain: 74\n",
      "x_dp_dom.shape: (35, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 74 | Accuracy: 0.8000 | Loss: 1.9311 | F1: 0.7679\n",
      "\n",
      "Domain: 75\n",
      "x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 75 | Accuracy: 0.8095 | Loss: 0.5009 | F1: 0.7920\n",
      "\n",
      "Mean accuracy for run 6: 0.7551\n",
      "Mean F1 for run 6: 0.7422\n",
      "\n",
      "Source class: WAL\n",
      "\n",
      "x_df.shape: (7958, 3, 128) | np.unique(y_df): [1 2 3]\n",
      "\n",
      "Training on Df data...\n",
      "\tEpoch 10/100 - Train loss: 0.1034 - Val accuracy: 0.7795 - Val loss: 0.6109 - Val F1: 0.7470 - LR: 9.00e-05\n",
      "\tEpoch 20/100 - Train loss: 0.0731 - Val accuracy: 0.7230 - Val loss: 1.9051 - Val F1: 0.6258 - LR: 8.00e-05\n",
      "\tEpoch 30/100 - Train loss: 0.0660 - Val accuracy: 0.7167 - Val loss: 2.2548 - Val F1: 0.6266 - LR: 7.00e-05\n",
      "\tEpoch 40/100 - Train loss: 0.0520 - Val accuracy: 0.7286 - Val loss: 1.9634 - Val F1: 0.6371 - LR: 6.00e-05\n",
      "\tEpoch 50/100 - Train loss: 0.0440 - Val accuracy: 0.7205 - Val loss: 3.1208 - Val F1: 0.6218 - LR: 5.00e-05\n",
      "\tEpoch 60/100 - Train loss: 0.0431 - Val accuracy: 0.7249 - Val loss: 2.5626 - Val F1: 0.6317 - LR: 4.00e-05\n",
      "\tEpoch 70/100 - Train loss: 0.0377 - Val accuracy: 0.6878 - Val loss: 3.0838 - Val F1: 0.6103 - LR: 3.00e-05\n",
      "\tEpoch 80/100 - Train loss: 0.0364 - Val accuracy: 0.7224 - Val loss: 3.3860 - Val F1: 0.6230 - LR: 2.00e-05\n",
      "\tEpoch 90/100 - Train loss: 0.0339 - Val accuracy: 0.7211 - Val loss: 3.6237 - Val F1: 0.6225 - LR: 1.00e-05\n",
      "\tEpoch 100/100 - Train loss: 0.0341 - Val accuracy: 0.7180 - Val loss: 3.5217 - Val F1: 0.6246 - LR: 0.00e+00\n",
      "\tBest epoch: 5 - Best val accuracy: 0.7337 - Best val loss: 0.6055 - Best val F1: 0.7239\n",
      "\n",
      "Domain: 15\n",
      "x_dp_dom.shape: (50, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 15 | Accuracy: 0.8000 | Loss: 2.3648 | F1: 0.7294\n",
      "\n",
      "Domain: 16\n",
      "x_dp_dom.shape: (54, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 16 | Accuracy: 0.5741 | Loss: 2.0162 | F1: 0.5623\n",
      "\n",
      "Domain: 17\n",
      "x_dp_dom.shape: (53, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 17 | Accuracy: 0.3019 | Loss: 3.4461 | F1: 0.2701\n",
      "\n",
      "Domain: 18\n",
      "x_dp_dom.shape: (54, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 18 | Accuracy: 0.2407 | Loss: 3.5120 | F1: 0.1605\n",
      "\n",
      "Domain: 19\n",
      "x_dp_dom.shape: (54, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 19 | Accuracy: 0.2407 | Loss: 3.2489 | F1: 0.1605\n",
      "\n",
      "Domain: 20\n",
      "x_dp_dom.shape: (51, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 20 | Accuracy: 0.6667 | Loss: 1.0020 | F1: 0.6675\n",
      "\n",
      "Domain: 21\n",
      "x_dp_dom.shape: (47, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 21 | Accuracy: 0.4043 | Loss: 1.5880 | F1: 0.4360\n",
      "\n",
      "Domain: 22\n",
      "x_dp_dom.shape: (54, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 22 | Accuracy: 0.7407 | Loss: 0.7655 | F1: 0.7407\n",
      "\n",
      "Domain: 23\n",
      "x_dp_dom.shape: (52, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 23 | Accuracy: 0.8077 | Loss: 0.6795 | F1: 0.7748\n",
      "\n",
      "Domain: 24\n",
      "x_dp_dom.shape: (51, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 24 | Accuracy: 0.6863 | Loss: 1.1622 | F1: 0.6333\n",
      "\n",
      "Domain: 25\n",
      "x_dp_dom.shape: (54, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 25 | Accuracy: 0.7037 | Loss: 1.9551 | F1: 0.6456\n",
      "\n",
      "Domain: 26\n",
      "x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 26 | Accuracy: 0.7857 | Loss: 0.7900 | F1: 0.8050\n",
      "\n",
      "Domain: 27\n",
      "x_dp_dom.shape: (54, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 27 | Accuracy: 0.6481 | Loss: 1.5798 | F1: 0.6168\n",
      "\n",
      "Domain: 28\n",
      "x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 28 | Accuracy: 0.6190 | Loss: 1.6158 | F1: 0.6501\n",
      "\n",
      "Domain: 29\n",
      "x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 29 | Accuracy: 0.2143 | Loss: 4.0779 | F1: 0.1722\n",
      "\n",
      "Domain: 30\n",
      "x_dp_dom.shape: (50, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 30 | Accuracy: 0.6200 | Loss: 1.8950 | F1: 0.6295\n",
      "\n",
      "Domain: 31\n",
      "x_dp_dom.shape: (43, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 31 | Accuracy: 0.3488 | Loss: 2.1414 | F1: 0.3760\n",
      "\n",
      "Domain: 32\n",
      "x_dp_dom.shape: (52, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 32 | Accuracy: 0.5385 | Loss: 1.3866 | F1: 0.5467\n",
      "\n",
      "Domain: 33\n",
      "x_dp_dom.shape: (44, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 33 | Accuracy: 0.6136 | Loss: 1.1872 | F1: 0.6532\n",
      "\n",
      "Domain: 34\n",
      "x_dp_dom.shape: (49, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 34 | Accuracy: 0.8571 | Loss: 0.8310 | F1: 0.8362\n",
      "\n",
      "Domain: 35\n",
      "x_dp_dom.shape: (48, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 35 | Accuracy: 0.3750 | Loss: 2.7751 | F1: 0.3902\n",
      "\n",
      "Domain: 36\n",
      "x_dp_dom.shape: (43, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 36 | Accuracy: 0.3721 | Loss: 2.6568 | F1: 0.4085\n",
      "\n",
      "Domain: 37\n",
      "x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 37 | Accuracy: 0.6429 | Loss: 1.1245 | F1: 0.6781\n",
      "\n",
      "Domain: 38\n",
      "x_dp_dom.shape: (47, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 38 | Accuracy: 0.6809 | Loss: 1.0802 | F1: 0.6941\n",
      "\n",
      "Domain: 39\n",
      "x_dp_dom.shape: (54, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 39 | Accuracy: 0.6111 | Loss: 1.3961 | F1: 0.5653\n",
      "\n",
      "Domain: 40\n",
      "x_dp_dom.shape: (44, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 40 | Accuracy: 0.8636 | Loss: 0.4031 | F1: 0.8713\n",
      "\n",
      "Domain: 41\n",
      "x_dp_dom.shape: (45, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 41 | Accuracy: 0.4444 | Loss: 2.9779 | F1: 0.5048\n",
      "\n",
      "Domain: 42\n",
      "x_dp_dom.shape: (46, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 42 | Accuracy: 0.4130 | Loss: 1.6572 | F1: 0.4078\n",
      "\n",
      "Domain: 43\n",
      "x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 43 | Accuracy: 0.6429 | Loss: 2.0605 | F1: 0.6710\n",
      "\n",
      "Domain: 44\n",
      "x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 44 | Accuracy: 0.5476 | Loss: 1.4259 | F1: 0.5977\n",
      "\n",
      "Domain: 45\n",
      "x_dp_dom.shape: (52, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 45 | Accuracy: 0.5769 | Loss: 1.7455 | F1: 0.5825\n",
      "\n",
      "Domain: 46\n",
      "x_dp_dom.shape: (48, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 46 | Accuracy: 0.7500 | Loss: 1.1248 | F1: 0.7395\n",
      "\n",
      "Domain: 47\n",
      "x_dp_dom.shape: (44, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 47 | Accuracy: 0.4773 | Loss: 1.6230 | F1: 0.5313\n",
      "\n",
      "Domain: 48\n",
      "x_dp_dom.shape: (48, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 48 | Accuracy: 0.8750 | Loss: 0.3236 | F1: 0.8500\n",
      "\n",
      "Domain: 49\n",
      "x_dp_dom.shape: (53, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 49 | Accuracy: 0.4151 | Loss: 2.3322 | F1: 0.4248\n",
      "\n",
      "Domain: 50\n",
      "x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 50 | Accuracy: 0.8095 | Loss: 0.4370 | F1: 0.8283\n",
      "\n",
      "Domain: 51\n",
      "x_dp_dom.shape: (46, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 51 | Accuracy: 0.8043 | Loss: 0.7006 | F1: 0.8004\n",
      "\n",
      "Domain: 52\n",
      "x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 52 | Accuracy: 0.7619 | Loss: 1.4966 | F1: 0.7400\n",
      "\n",
      "Domain: 53\n",
      "x_dp_dom.shape: (48, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 53 | Accuracy: 0.7708 | Loss: 0.7948 | F1: 0.7577\n",
      "\n",
      "Domain: 54\n",
      "x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 54 | Accuracy: 0.8333 | Loss: 0.4281 | F1: 0.8355\n",
      "\n",
      "Domain: 55\n",
      "x_dp_dom.shape: (49, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 55 | Accuracy: 0.3265 | Loss: 3.3785 | F1: 0.3135\n",
      "\n",
      "Domain: 56\n",
      "x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 56 | Accuracy: 0.9286 | Loss: 0.2198 | F1: 0.9309\n",
      "\n",
      "Domain: 57\n",
      "x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 57 | Accuracy: 0.8333 | Loss: 0.5922 | F1: 0.8492\n",
      "\n",
      "Domain: 58\n",
      "x_dp_dom.shape: (38, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 58 | Accuracy: 0.8158 | Loss: 0.5095 | F1: 0.8058\n",
      "\n",
      "Domain: 59\n",
      "x_dp_dom.shape: (43, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 59 | Accuracy: 0.3023 | Loss: 2.5177 | F1: 0.2869\n",
      "\n",
      "Domain: 60\n",
      "x_dp_dom.shape: (47, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 60 | Accuracy: 0.6809 | Loss: 2.5136 | F1: 0.6498\n",
      "\n",
      "Domain: 61\n",
      "x_dp_dom.shape: (47, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 61 | Accuracy: 0.5532 | Loss: 1.1530 | F1: 0.5816\n",
      "\n",
      "Domain: 62\n",
      "x_dp_dom.shape: (47, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 62 | Accuracy: 0.4681 | Loss: 1.6488 | F1: 0.5051\n",
      "\n",
      "Domain: 63\n",
      "x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 63 | Accuracy: 0.3571 | Loss: 1.9426 | F1: 0.3063\n",
      "\n",
      "Domain: 64\n",
      "x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 64 | Accuracy: 0.5000 | Loss: 1.7249 | F1: 0.5539\n",
      "\n",
      "Domain: 65\n",
      "x_dp_dom.shape: (50, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 65 | Accuracy: 0.6800 | Loss: 1.4047 | F1: 0.6792\n",
      "\n",
      "Domain: 66\n",
      "x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 66 | Accuracy: 0.8333 | Loss: 1.9951 | F1: 0.7778\n",
      "\n",
      "Domain: 67\n",
      "x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 67 | Accuracy: 0.5714 | Loss: 1.4558 | F1: 0.6117\n",
      "\n",
      "Domain: 68\n",
      "x_dp_dom.shape: (43, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 68 | Accuracy: 0.4651 | Loss: 1.4106 | F1: 0.4993\n",
      "\n",
      "Domain: 69\n",
      "x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 69 | Accuracy: 0.8333 | Loss: 0.8092 | F1: 0.7778\n",
      "\n",
      "Domain: 70\n",
      "x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 70 | Accuracy: 0.9286 | Loss: 0.5562 | F1: 0.9286\n",
      "\n",
      "Domain: 71\n",
      "x_dp_dom.shape: (44, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 71 | Accuracy: 0.5909 | Loss: 0.8530 | F1: 0.6278\n",
      "\n",
      "Domain: 72\n",
      "x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 72 | Accuracy: 0.1905 | Loss: 3.6933 | F1: 0.1571\n",
      "\n",
      "Domain: 73\n",
      "x_dp_dom.shape: (41, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 73 | Accuracy: 0.8293 | Loss: 1.6361 | F1: 0.7788\n",
      "\n",
      "Domain: 74\n",
      "x_dp_dom.shape: (35, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 74 | Accuracy: 0.7429 | Loss: 1.3073 | F1: 0.7051\n",
      "\n",
      "Domain: 75\n",
      "x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 75 | Accuracy: 0.3810 | Loss: 2.0683 | F1: 0.4304\n",
      "\n",
      "Mean accuracy for run 7: 0.6048\n",
      "Mean F1 for run 7: 0.6017\n",
      "\n",
      "Source class: WAL\n",
      "\n",
      "x_df.shape: (7958, 3, 128) | np.unique(y_df): [1 2 3]\n",
      "\n",
      "Training on Df data...\n",
      "\tEpoch 10/100 - Train loss: 0.1224 - Val accuracy: 0.6753 - Val loss: 1.0915 - Val F1: 0.6162 - LR: 9.00e-05\n",
      "\tEpoch 20/100 - Train loss: 0.0749 - Val accuracy: 0.7399 - Val loss: 1.0225 - Val F1: 0.6629 - LR: 8.00e-05\n",
      "\tEpoch 30/100 - Train loss: 0.0624 - Val accuracy: 0.7054 - Val loss: 1.2158 - Val F1: 0.5941 - LR: 7.00e-05\n",
      "\tEpoch 40/100 - Train loss: 0.0506 - Val accuracy: 0.7186 - Val loss: 1.8578 - Val F1: 0.6075 - LR: 6.00e-05\n",
      "\tEpoch 50/100 - Train loss: 0.0448 - Val accuracy: 0.7205 - Val loss: 2.3850 - Val F1: 0.6132 - LR: 5.00e-05\n",
      "\tEpoch 60/100 - Train loss: 0.0444 - Val accuracy: 0.7211 - Val loss: 1.8018 - Val F1: 0.6168 - LR: 4.00e-05\n",
      "\tEpoch 70/100 - Train loss: 0.0426 - Val accuracy: 0.7236 - Val loss: 2.6515 - Val F1: 0.6216 - LR: 3.00e-05\n",
      "\tEpoch 80/100 - Train loss: 0.0373 - Val accuracy: 0.7167 - Val loss: 2.3435 - Val F1: 0.6044 - LR: 2.00e-05\n",
      "\tEpoch 90/100 - Train loss: 0.0328 - Val accuracy: 0.7217 - Val loss: 2.5841 - Val F1: 0.6096 - LR: 1.00e-05\n",
      "\tEpoch 100/100 - Train loss: 0.0322 - Val accuracy: 0.7217 - Val loss: 2.6065 - Val F1: 0.6137 - LR: 0.00e+00\n",
      "\tBest epoch: 2 - Best val accuracy: 0.7111 - Best val loss: 0.7540 - Best val F1: 0.5971\n",
      "\n",
      "Domain: 15\n",
      "x_dp_dom.shape: (50, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 15 | Accuracy: 0.6400 | Loss: 5.0589 | F1: 0.6038\n",
      "\n",
      "Domain: 16\n",
      "x_dp_dom.shape: (54, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 16 | Accuracy: 0.7222 | Loss: 0.9806 | F1: 0.6598\n",
      "\n",
      "Domain: 17\n",
      "x_dp_dom.shape: (53, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 17 | Accuracy: 0.3585 | Loss: 3.6624 | F1: 0.3420\n",
      "\n",
      "Domain: 18\n",
      "x_dp_dom.shape: (54, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 18 | Accuracy: 0.6852 | Loss: 2.0979 | F1: 0.6525\n",
      "\n",
      "Domain: 19\n",
      "x_dp_dom.shape: (54, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 19 | Accuracy: 0.4259 | Loss: 2.4907 | F1: 0.4334\n",
      "\n",
      "Domain: 20\n",
      "x_dp_dom.shape: (51, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 20 | Accuracy: 0.6863 | Loss: 1.2983 | F1: 0.6742\n",
      "\n",
      "Domain: 21\n",
      "x_dp_dom.shape: (47, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 21 | Accuracy: 0.7021 | Loss: 0.6290 | F1: 0.7083\n",
      "\n",
      "Domain: 22\n",
      "x_dp_dom.shape: (54, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 22 | Accuracy: 0.8889 | Loss: 0.3192 | F1: 0.8885\n",
      "\n",
      "Domain: 23\n",
      "x_dp_dom.shape: (52, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 23 | Accuracy: 0.8077 | Loss: 0.7411 | F1: 0.7748\n",
      "\n",
      "Domain: 24\n",
      "x_dp_dom.shape: (51, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 24 | Accuracy: 0.6863 | Loss: 1.7999 | F1: 0.6269\n",
      "\n",
      "Domain: 25\n",
      "x_dp_dom.shape: (54, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 25 | Accuracy: 0.7222 | Loss: 1.7482 | F1: 0.6520\n",
      "\n",
      "Domain: 26\n",
      "x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 26 | Accuracy: 0.8095 | Loss: 0.9077 | F1: 0.8225\n",
      "\n",
      "Domain: 27\n",
      "x_dp_dom.shape: (54, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 27 | Accuracy: 0.5741 | Loss: 1.8487 | F1: 0.5757\n",
      "\n",
      "Domain: 28\n",
      "x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 28 | Accuracy: 0.7143 | Loss: 1.2947 | F1: 0.7124\n",
      "\n",
      "Domain: 29\n",
      "x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 29 | Accuracy: 0.3810 | Loss: 2.1378 | F1: 0.4249\n",
      "\n",
      "Domain: 30\n",
      "x_dp_dom.shape: (50, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 30 | Accuracy: 0.5400 | Loss: 3.3204 | F1: 0.5447\n",
      "\n",
      "Domain: 31\n",
      "x_dp_dom.shape: (43, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 31 | Accuracy: 0.7209 | Loss: 1.2784 | F1: 0.7483\n",
      "\n",
      "Domain: 32\n",
      "x_dp_dom.shape: (52, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 32 | Accuracy: 0.6538 | Loss: 1.7056 | F1: 0.6504\n",
      "\n",
      "Domain: 33\n",
      "x_dp_dom.shape: (44, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 33 | Accuracy: 0.8182 | Loss: 0.5137 | F1: 0.8116\n",
      "\n",
      "Domain: 34\n",
      "x_dp_dom.shape: (49, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 34 | Accuracy: 0.7143 | Loss: 1.6420 | F1: 0.7139\n",
      "\n",
      "Domain: 35\n",
      "x_dp_dom.shape: (48, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 35 | Accuracy: 0.7500 | Loss: 1.0832 | F1: 0.7217\n",
      "\n",
      "Domain: 36\n",
      "x_dp_dom.shape: (43, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 36 | Accuracy: 0.2093 | Loss: 3.0558 | F1: 0.1689\n",
      "\n",
      "Domain: 37\n",
      "x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 37 | Accuracy: 0.7143 | Loss: 1.4544 | F1: 0.7086\n",
      "\n",
      "Domain: 38\n",
      "x_dp_dom.shape: (47, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 38 | Accuracy: 0.8723 | Loss: 0.9671 | F1: 0.8372\n",
      "\n",
      "Domain: 39\n",
      "x_dp_dom.shape: (54, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 39 | Accuracy: 0.3889 | Loss: 3.8521 | F1: 0.3365\n",
      "\n",
      "Domain: 40\n",
      "x_dp_dom.shape: (44, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 40 | Accuracy: 0.6818 | Loss: 1.6032 | F1: 0.6990\n",
      "\n",
      "Domain: 41\n",
      "x_dp_dom.shape: (45, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 41 | Accuracy: 0.5333 | Loss: 3.2520 | F1: 0.5687\n",
      "\n",
      "Domain: 42\n",
      "x_dp_dom.shape: (46, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 42 | Accuracy: 0.4348 | Loss: 2.4712 | F1: 0.3931\n",
      "\n",
      "Domain: 43\n",
      "x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 43 | Accuracy: 0.6429 | Loss: 3.5529 | F1: 0.6420\n",
      "\n",
      "Domain: 44\n",
      "x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 44 | Accuracy: 0.8333 | Loss: 0.6354 | F1: 0.8254\n",
      "\n",
      "Domain: 45\n",
      "x_dp_dom.shape: (52, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 45 | Accuracy: 0.5385 | Loss: 1.1679 | F1: 0.5513\n",
      "\n",
      "Domain: 46\n",
      "x_dp_dom.shape: (48, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 46 | Accuracy: 0.8542 | Loss: 0.6132 | F1: 0.7967\n",
      "\n",
      "Domain: 47\n",
      "x_dp_dom.shape: (44, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 47 | Accuracy: 0.6364 | Loss: 0.7373 | F1: 0.6736\n",
      "\n",
      "Domain: 48\n",
      "x_dp_dom.shape: (48, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 48 | Accuracy: 0.8750 | Loss: 0.4945 | F1: 0.8630\n",
      "\n",
      "Domain: 49\n",
      "x_dp_dom.shape: (53, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 49 | Accuracy: 0.3396 | Loss: 3.3987 | F1: 0.3050\n",
      "\n",
      "Domain: 50\n",
      "x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 50 | Accuracy: 0.9286 | Loss: 0.1639 | F1: 0.9303\n",
      "\n",
      "Domain: 51\n",
      "x_dp_dom.shape: (46, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 51 | Accuracy: 0.8696 | Loss: 1.3019 | F1: 0.8533\n",
      "\n",
      "Domain: 52\n",
      "x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 52 | Accuracy: 0.8095 | Loss: 0.8966 | F1: 0.7657\n",
      "\n",
      "Domain: 53\n",
      "x_dp_dom.shape: (48, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 53 | Accuracy: 0.7292 | Loss: 0.9368 | F1: 0.7392\n",
      "\n",
      "Domain: 54\n",
      "x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 54 | Accuracy: 0.7857 | Loss: 0.9448 | F1: 0.7720\n",
      "\n",
      "Domain: 55\n",
      "x_dp_dom.shape: (49, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 55 | Accuracy: 0.6735 | Loss: 1.0468 | F1: 0.6733\n",
      "\n",
      "Domain: 56\n",
      "x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 56 | Accuracy: 0.9524 | Loss: 0.1238 | F1: 0.9530\n",
      "\n",
      "Domain: 57\n",
      "x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 57 | Accuracy: 0.8095 | Loss: 0.6157 | F1: 0.8283\n",
      "\n",
      "Domain: 58\n",
      "x_dp_dom.shape: (38, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 58 | Accuracy: 0.8684 | Loss: 0.3562 | F1: 0.8554\n",
      "\n",
      "Domain: 59\n",
      "x_dp_dom.shape: (43, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 59 | Accuracy: 0.9070 | Loss: 0.1974 | F1: 0.9115\n",
      "\n",
      "Domain: 60\n",
      "x_dp_dom.shape: (47, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 60 | Accuracy: 0.3617 | Loss: 6.8392 | F1: 0.3132\n",
      "\n",
      "Domain: 61\n",
      "x_dp_dom.shape: (47, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 61 | Accuracy: 0.4681 | Loss: 2.8784 | F1: 0.4605\n",
      "\n",
      "Domain: 62\n",
      "x_dp_dom.shape: (47, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 62 | Accuracy: 0.6596 | Loss: 0.9473 | F1: 0.6870\n",
      "\n",
      "Domain: 63\n",
      "x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 63 | Accuracy: 0.8810 | Loss: 0.4654 | F1: 0.8862\n",
      "\n",
      "Domain: 64\n",
      "x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 64 | Accuracy: 0.8571 | Loss: 0.2499 | F1: 0.8549\n",
      "\n",
      "Domain: 65\n",
      "x_dp_dom.shape: (50, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 65 | Accuracy: 0.6000 | Loss: 2.5338 | F1: 0.5701\n",
      "\n",
      "Domain: 66\n",
      "x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 66 | Accuracy: 0.6190 | Loss: 3.8123 | F1: 0.6168\n",
      "\n",
      "Domain: 67\n",
      "x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 67 | Accuracy: 0.9286 | Loss: 0.1726 | F1: 0.9286\n",
      "\n",
      "Domain: 68\n",
      "x_dp_dom.shape: (43, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 68 | Accuracy: 0.3256 | Loss: 2.4133 | F1: 0.3431\n",
      "\n",
      "Domain: 69\n",
      "x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 69 | Accuracy: 0.8333 | Loss: 0.5224 | F1: 0.8272\n",
      "\n",
      "Domain: 70\n",
      "x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 70 | Accuracy: 0.8333 | Loss: 1.6155 | F1: 0.8365\n",
      "\n",
      "Domain: 71\n",
      "x_dp_dom.shape: (44, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 71 | Accuracy: 0.9545 | Loss: 0.1302 | F1: 0.9565\n",
      "\n",
      "Domain: 72\n",
      "x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 72 | Accuracy: 0.6905 | Loss: 0.9252 | F1: 0.6978\n",
      "\n",
      "Domain: 73\n",
      "x_dp_dom.shape: (41, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 73 | Accuracy: 0.5122 | Loss: 4.8685 | F1: 0.5256\n",
      "\n",
      "Domain: 74\n",
      "x_dp_dom.shape: (35, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 74 | Accuracy: 0.8571 | Loss: 2.1256 | F1: 0.8358\n",
      "\n",
      "Domain: 75\n",
      "x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 75 | Accuracy: 0.4048 | Loss: 1.7915 | F1: 0.4523\n",
      "\n",
      "Mean accuracy for run 8: 0.6832\n",
      "Mean F1 for run 8: 0.6752\n",
      "\n",
      "Source class: WAL\n",
      "\n",
      "x_df.shape: (7958, 3, 128) | np.unique(y_df): [1 2 3]\n",
      "\n",
      "Training on Df data...\n",
      "\tEpoch 10/100 - Train loss: 0.1062 - Val accuracy: 0.8097 - Val loss: 0.4510 - Val F1: 0.7852 - LR: 9.00e-05\n",
      "\tEpoch 20/100 - Train loss: 0.0783 - Val accuracy: 0.7638 - Val loss: 0.7293 - Val F1: 0.7094 - LR: 8.00e-05\n",
      "\tEpoch 30/100 - Train loss: 0.0596 - Val accuracy: 0.7707 - Val loss: 0.6533 - Val F1: 0.7265 - LR: 7.00e-05\n",
      "\tEpoch 40/100 - Train loss: 0.0491 - Val accuracy: 0.7946 - Val loss: 0.6239 - Val F1: 0.7814 - LR: 6.00e-05\n",
      "\tEpoch 50/100 - Train loss: 0.0402 - Val accuracy: 0.8003 - Val loss: 0.5647 - Val F1: 0.7701 - LR: 5.00e-05\n",
      "\tEpoch 60/100 - Train loss: 0.0449 - Val accuracy: 0.7971 - Val loss: 0.6840 - Val F1: 0.7795 - LR: 4.00e-05\n",
      "\tEpoch 70/100 - Train loss: 0.0357 - Val accuracy: 0.8624 - Val loss: 0.3435 - Val F1: 0.8571 - LR: 3.00e-05\n",
      "\tEpoch 80/100 - Train loss: 0.0343 - Val accuracy: 0.8153 - Val loss: 0.6581 - Val F1: 0.7909 - LR: 2.00e-05\n",
      "\tEpoch 90/100 - Train loss: 0.0387 - Val accuracy: 0.7959 - Val loss: 0.8449 - Val F1: 0.7626 - LR: 1.00e-05\n",
      "\tEpoch 100/100 - Train loss: 0.0320 - Val accuracy: 0.8046 - Val loss: 0.6980 - Val F1: 0.7763 - LR: 0.00e+00\n",
      "\tBest epoch: 57 - Best val accuracy: 0.8800 - Best val loss: 0.2866 - Best val F1: 0.8766\n",
      "\n",
      "Domain: 15\n",
      "x_dp_dom.shape: (50, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 15 | Accuracy: 0.8000 | Loss: 1.0437 | F1: 0.7111\n",
      "\n",
      "Domain: 16\n",
      "x_dp_dom.shape: (54, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 16 | Accuracy: 0.5556 | Loss: 1.3269 | F1: 0.5603\n",
      "\n",
      "Domain: 17\n",
      "x_dp_dom.shape: (53, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 17 | Accuracy: 0.3396 | Loss: 3.4897 | F1: 0.3236\n",
      "\n",
      "Domain: 18\n",
      "x_dp_dom.shape: (54, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 18 | Accuracy: 0.3889 | Loss: 2.5406 | F1: 0.3821\n",
      "\n",
      "Domain: 19\n",
      "x_dp_dom.shape: (54, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 19 | Accuracy: 0.2778 | Loss: 2.5636 | F1: 0.2296\n",
      "\n",
      "Domain: 20\n",
      "x_dp_dom.shape: (51, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 20 | Accuracy: 0.8039 | Loss: 0.7378 | F1: 0.8010\n",
      "\n",
      "Domain: 21\n",
      "x_dp_dom.shape: (47, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 21 | Accuracy: 0.8085 | Loss: 0.4007 | F1: 0.7934\n",
      "\n",
      "Domain: 22\n",
      "x_dp_dom.shape: (54, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 22 | Accuracy: 0.9074 | Loss: 0.2217 | F1: 0.9077\n",
      "\n",
      "Domain: 23\n",
      "x_dp_dom.shape: (52, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 23 | Accuracy: 0.7308 | Loss: 0.7638 | F1: 0.7269\n",
      "\n",
      "Domain: 24\n",
      "x_dp_dom.shape: (51, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 24 | Accuracy: 0.6471 | Loss: 1.7335 | F1: 0.6105\n",
      "\n",
      "Domain: 25\n",
      "x_dp_dom.shape: (54, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 25 | Accuracy: 0.7037 | Loss: 1.6251 | F1: 0.6497\n",
      "\n",
      "Domain: 26\n",
      "x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 26 | Accuracy: 0.6905 | Loss: 1.1836 | F1: 0.7220\n",
      "\n",
      "Domain: 27\n",
      "x_dp_dom.shape: (54, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 27 | Accuracy: 0.7222 | Loss: 1.2068 | F1: 0.6958\n",
      "\n",
      "Domain: 28\n",
      "x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 28 | Accuracy: 0.6667 | Loss: 0.9840 | F1: 0.6931\n",
      "\n",
      "Domain: 29\n",
      "x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 29 | Accuracy: 0.2857 | Loss: 3.9095 | F1: 0.2183\n",
      "\n",
      "Domain: 30\n",
      "x_dp_dom.shape: (50, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 30 | Accuracy: 0.7000 | Loss: 0.9138 | F1: 0.6967\n",
      "\n",
      "Domain: 31\n",
      "x_dp_dom.shape: (43, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 31 | Accuracy: 0.6744 | Loss: 0.8593 | F1: 0.7059\n",
      "\n",
      "Domain: 32\n",
      "x_dp_dom.shape: (52, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 32 | Accuracy: 0.6154 | Loss: 1.0848 | F1: 0.6110\n",
      "\n",
      "Domain: 33\n",
      "x_dp_dom.shape: (44, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 33 | Accuracy: 0.8182 | Loss: 0.5538 | F1: 0.8347\n",
      "\n",
      "Domain: 34\n",
      "x_dp_dom.shape: (49, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 34 | Accuracy: 0.8163 | Loss: 0.8321 | F1: 0.8079\n",
      "\n",
      "Domain: 35\n",
      "x_dp_dom.shape: (48, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 35 | Accuracy: 0.3542 | Loss: 2.5066 | F1: 0.3216\n",
      "\n",
      "Domain: 36\n",
      "x_dp_dom.shape: (43, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 36 | Accuracy: 0.3488 | Loss: 2.0172 | F1: 0.3594\n",
      "\n",
      "Domain: 37\n",
      "x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 37 | Accuracy: 0.5952 | Loss: 1.3532 | F1: 0.6447\n",
      "\n",
      "Domain: 38\n",
      "x_dp_dom.shape: (47, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 38 | Accuracy: 0.8298 | Loss: 0.8493 | F1: 0.8006\n",
      "\n",
      "Domain: 39\n",
      "x_dp_dom.shape: (54, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 39 | Accuracy: 0.7778 | Loss: 0.6088 | F1: 0.7380\n",
      "\n",
      "Domain: 40\n",
      "x_dp_dom.shape: (44, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 40 | Accuracy: 0.5682 | Loss: 1.8806 | F1: 0.6165\n",
      "\n",
      "Domain: 41\n",
      "x_dp_dom.shape: (45, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 41 | Accuracy: 0.6444 | Loss: 1.9983 | F1: 0.6516\n",
      "\n",
      "Domain: 42\n",
      "x_dp_dom.shape: (46, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 42 | Accuracy: 0.5652 | Loss: 1.1366 | F1: 0.5833\n",
      "\n",
      "Domain: 43\n",
      "x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 43 | Accuracy: 0.7857 | Loss: 1.0097 | F1: 0.7744\n",
      "\n",
      "Domain: 44\n",
      "x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 44 | Accuracy: 0.6905 | Loss: 1.0841 | F1: 0.7213\n",
      "\n",
      "Domain: 45\n",
      "x_dp_dom.shape: (52, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 45 | Accuracy: 0.5962 | Loss: 0.8777 | F1: 0.6128\n",
      "\n",
      "Domain: 46\n",
      "x_dp_dom.shape: (48, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 46 | Accuracy: 0.8333 | Loss: 0.4746 | F1: 0.8109\n",
      "\n",
      "Domain: 47\n",
      "x_dp_dom.shape: (44, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 47 | Accuracy: 0.5682 | Loss: 1.2541 | F1: 0.6183\n",
      "\n",
      "Domain: 48\n",
      "x_dp_dom.shape: (48, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 48 | Accuracy: 0.8958 | Loss: 0.3476 | F1: 0.8951\n",
      "\n",
      "Domain: 49\n",
      "x_dp_dom.shape: (53, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 49 | Accuracy: 0.4528 | Loss: 1.9542 | F1: 0.4658\n",
      "\n",
      "Domain: 50\n",
      "x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 50 | Accuracy: 0.8810 | Loss: 0.4803 | F1: 0.8908\n",
      "\n",
      "Domain: 51\n",
      "x_dp_dom.shape: (46, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 51 | Accuracy: 0.8261 | Loss: 0.5242 | F1: 0.7993\n",
      "\n",
      "Domain: 52\n",
      "x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 52 | Accuracy: 0.7619 | Loss: 0.7274 | F1: 0.7400\n",
      "\n",
      "Domain: 53\n",
      "x_dp_dom.shape: (48, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 53 | Accuracy: 0.7917 | Loss: 0.5005 | F1: 0.8017\n",
      "\n",
      "Domain: 54\n",
      "x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 54 | Accuracy: 0.8810 | Loss: 0.3356 | F1: 0.8635\n",
      "\n",
      "Domain: 55\n",
      "x_dp_dom.shape: (49, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 55 | Accuracy: 0.3878 | Loss: 2.9565 | F1: 0.3603\n",
      "\n",
      "Domain: 56\n",
      "x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 56 | Accuracy: 0.8095 | Loss: 0.7868 | F1: 0.8283\n",
      "\n",
      "Domain: 57\n",
      "x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 57 | Accuracy: 0.6905 | Loss: 0.7418 | F1: 0.7182\n",
      "\n",
      "Domain: 58\n",
      "x_dp_dom.shape: (38, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 58 | Accuracy: 0.8947 | Loss: 0.2720 | F1: 0.8947\n",
      "\n",
      "Domain: 59\n",
      "x_dp_dom.shape: (43, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 59 | Accuracy: 0.6977 | Loss: 1.0140 | F1: 0.7281\n",
      "\n",
      "Domain: 60\n",
      "x_dp_dom.shape: (47, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 60 | Accuracy: 0.7660 | Loss: 0.9856 | F1: 0.7232\n",
      "\n",
      "Domain: 61\n",
      "x_dp_dom.shape: (47, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 61 | Accuracy: 0.7660 | Loss: 0.6041 | F1: 0.7807\n",
      "\n",
      "Domain: 62\n",
      "x_dp_dom.shape: (47, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 62 | Accuracy: 0.3191 | Loss: 2.3649 | F1: 0.2355\n",
      "\n",
      "Domain: 63\n",
      "x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 63 | Accuracy: 0.3810 | Loss: 2.1607 | F1: 0.3289\n",
      "\n",
      "Domain: 64\n",
      "x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 64 | Accuracy: 0.8810 | Loss: 0.2593 | F1: 0.8886\n",
      "\n",
      "Domain: 65\n",
      "x_dp_dom.shape: (50, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 65 | Accuracy: 0.8800 | Loss: 0.6082 | F1: 0.8582\n",
      "\n",
      "Domain: 66\n",
      "x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 66 | Accuracy: 0.7857 | Loss: 1.1151 | F1: 0.7132\n",
      "\n",
      "Domain: 67\n",
      "x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 67 | Accuracy: 0.6429 | Loss: 1.0169 | F1: 0.6810\n",
      "\n",
      "Domain: 68\n",
      "x_dp_dom.shape: (43, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 68 | Accuracy: 0.2791 | Loss: 1.9296 | F1: 0.2201\n",
      "\n",
      "Domain: 69\n",
      "x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 69 | Accuracy: 0.8571 | Loss: 0.3336 | F1: 0.8250\n",
      "\n",
      "Domain: 70\n",
      "x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 70 | Accuracy: 0.8095 | Loss: 0.4551 | F1: 0.7981\n",
      "\n",
      "Domain: 71\n",
      "x_dp_dom.shape: (44, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 71 | Accuracy: 0.6591 | Loss: 1.3676 | F1: 0.6849\n",
      "\n",
      "Domain: 72\n",
      "x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 72 | Accuracy: 0.2143 | Loss: 6.9005 | F1: 0.1408\n",
      "\n",
      "Domain: 73\n",
      "x_dp_dom.shape: (41, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 73 | Accuracy: 0.6829 | Loss: 1.1492 | F1: 0.5624\n",
      "\n",
      "Domain: 74\n",
      "x_dp_dom.shape: (35, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 74 | Accuracy: 0.8000 | Loss: 1.0476 | F1: 0.7766\n",
      "\n",
      "Domain: 75\n",
      "x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 75 | Accuracy: 0.5714 | Loss: 1.2577 | F1: 0.6135\n",
      "\n",
      "Mean accuracy for run 9: 0.6619\n",
      "Mean F1 for run 9: 0.6517\n",
      "\n",
      "Mean accuracy over 10 runs: 0.7479 +- 0.0689\n",
      "Mean F1 over 10 runs: 0.7291 +- 0.0620\n",
      "\n"
     ]
    }
   ],
   "source": [
    "n_runs = 10\n",
    "\n",
    "def compute_TSTR_Df_aug(dataset):\n",
    "    accs = []\n",
    "    f1s = []\n",
    "\n",
    "    for i in range(n_runs):\n",
    "\n",
    "        accs_run = []\n",
    "        f1s_run = []\n",
    "\n",
    "        for src_class in config[dataset]['class_names']:\n",
    "            if src_class != 'WAL':\n",
    "                continue\n",
    "\n",
    "            print(f\"Source class: {src_class}\\n\")\n",
    "\n",
    "            # Load Df data\n",
    "            x_df, y_df, k_df = get_data(dataset, 'df', src_class)\n",
    "            print(f'x_df.shape: {x_df.shape} | np.unique(y_df): {np.unique(y_df)}\\n')\n",
    "\n",
    "            # Train on Df data\n",
    "            print('Training on Df data...')\n",
    "            df_model = train_only(x_df, y_df, dataset, num_epochs=num_epochs, augment=True)\n",
    "\n",
    "            for domain in range(config[dataset]['num_df_domains'], config[dataset]['num_df_domains'] + config[dataset]['num_dp_domains']):\n",
    "                print(f\"Domain: {domain}\")\n",
    "\n",
    "                # Load Dp data\n",
    "                x_dp_dom, y_dp_dom, k_dp_dom = get_data(dataset, 'dp', src_class, domain)\n",
    "                print(f'x_dp_dom.shape: {x_dp_dom.shape} | np.unique(y_dp_dom): {np.unique(y_dp_dom)}\\n')\n",
    "\n",
    "                # Evaluate on Dp data\n",
    "                acc, loss, f1 = evaluate_model(df_model, get_dataloader(x_dp_dom, y_dp_dom))\n",
    "                save_scores(src_class, domain, acc, loss, f1, 'Df_aug', dataset)\n",
    "                accs_run.append(acc)\n",
    "                f1s_run.append(f1)\n",
    "                print(f'Source class: {src_class} | Domain: {domain} | Accuracy: {acc:.4f} | Loss: {loss:.4f} | F1: {f1:.4f}\\n')\n",
    "\n",
    "        print(f\"Mean accuracy for run {i}: {np.mean(accs_run):.4f}\")\n",
    "        print(f\"Mean F1 for run {i}: {np.mean(f1s_run):.4f}\\n\")\n",
    "        accs.append(np.mean(accs_run))\n",
    "        f1s.append(np.mean(f1s_run))\n",
    "\n",
    "    print(f\"Mean accuracy over {n_runs} runs: {np.mean(accs):.4f} +- {np.std(accs):.4f}\")\n",
    "    print(f\"Mean F1 over {n_runs} runs: {np.mean(f1s):.4f} +- {np.std(f1s):.4f}\\n\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "compute_TSTR_Df_aug('realworld_mobiact')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 661274,
     "status": "ok",
     "timestamp": 1732618931424,
     "user": {
      "displayName": "Pietro Cirino",
      "userId": "07315473796200699505"
     },
     "user_tz": -60
    },
    "id": "aDSS4eIiUHeq",
    "outputId": "ce368187-4eb5-46a3-e29f-0b1167f870a2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source class: WAL\n",
      "\n",
      "x_df.shape: (7958, 3, 128) | np.unique(y_df): [1 2 3]\n",
      "\n",
      "Training on Df data...\n",
      "\tEpoch 10/100 - Train loss: 0.0310 - Val accuracy: 0.9868 - Val loss: 0.0454 - Val F1: 0.9868 - LR: 9.00e-05\n",
      "\tEpoch 20/100 - Train loss: 0.0091 - Val accuracy: 0.9856 - Val loss: 0.0438 - Val F1: 0.9856 - LR: 8.00e-05\n",
      "\tEpoch 30/100 - Train loss: 0.0033 - Val accuracy: 0.9868 - Val loss: 0.0517 - Val F1: 0.9868 - LR: 7.00e-05\n",
      "\tEpoch 40/100 - Train loss: 0.0013 - Val accuracy: 0.9868 - Val loss: 0.0585 - Val F1: 0.9868 - LR: 6.00e-05\n",
      "\tEpoch 50/100 - Train loss: 0.0009 - Val accuracy: 0.9874 - Val loss: 0.0540 - Val F1: 0.9874 - LR: 5.00e-05\n",
      "\tEpoch 60/100 - Train loss: 0.0029 - Val accuracy: 0.9862 - Val loss: 0.0566 - Val F1: 0.9862 - LR: 4.00e-05\n",
      "\tEpoch 70/100 - Train loss: 0.0003 - Val accuracy: 0.9874 - Val loss: 0.0522 - Val F1: 0.9874 - LR: 3.00e-05\n",
      "\tEpoch 80/100 - Train loss: 0.0002 - Val accuracy: 0.9874 - Val loss: 0.0558 - Val F1: 0.9874 - LR: 2.00e-05\n",
      "\tEpoch 90/100 - Train loss: 0.0002 - Val accuracy: 0.9887 - Val loss: 0.0603 - Val F1: 0.9887 - LR: 1.00e-05\n",
      "\tEpoch 100/100 - Train loss: 0.0001 - Val accuracy: 0.9887 - Val loss: 0.0598 - Val F1: 0.9887 - LR: 0.00e+00\n",
      "\tBest epoch: 22 - Best val accuracy: 0.9874 - Best val loss: 0.0379 - Best val F1: 0.9874\n",
      "\n",
      "Domain: 15\n",
      "x_dp_dom.shape: (50, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 15 | Accuracy: 0.2400 | Loss: 19.6480 | F1: 0.0929\n",
      "\n",
      "Domain: 16\n",
      "x_dp_dom.shape: (54, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 16 | Accuracy: 0.7407 | Loss: 1.4643 | F1: 0.7257\n",
      "\n",
      "Domain: 17\n",
      "x_dp_dom.shape: (53, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 17 | Accuracy: 0.7736 | Loss: 2.0951 | F1: 0.6961\n",
      "\n",
      "Domain: 18\n",
      "x_dp_dom.shape: (54, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 18 | Accuracy: 0.6481 | Loss: 3.1420 | F1: 0.6144\n",
      "\n",
      "Domain: 19\n",
      "x_dp_dom.shape: (54, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 19 | Accuracy: 0.7963 | Loss: 1.4604 | F1: 0.7679\n",
      "\n",
      "Domain: 20\n",
      "x_dp_dom.shape: (51, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 20 | Accuracy: 0.6667 | Loss: 2.8067 | F1: 0.6610\n",
      "\n",
      "Domain: 21\n",
      "x_dp_dom.shape: (47, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 21 | Accuracy: 0.8723 | Loss: 1.1865 | F1: 0.8372\n",
      "\n",
      "Domain: 22\n",
      "x_dp_dom.shape: (54, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 22 | Accuracy: 0.7037 | Loss: 1.8810 | F1: 0.7203\n",
      "\n",
      "Domain: 23\n",
      "x_dp_dom.shape: (52, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 23 | Accuracy: 0.8269 | Loss: 1.0206 | F1: 0.8236\n",
      "\n",
      "Domain: 24\n",
      "x_dp_dom.shape: (51, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 24 | Accuracy: 0.7255 | Loss: 1.4069 | F1: 0.7410\n",
      "\n",
      "Domain: 25\n",
      "x_dp_dom.shape: (54, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 25 | Accuracy: 0.7037 | Loss: 2.9560 | F1: 0.6497\n",
      "\n",
      "Domain: 26\n",
      "x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 26 | Accuracy: 0.7619 | Loss: 1.0970 | F1: 0.7761\n",
      "\n",
      "Domain: 27\n",
      "x_dp_dom.shape: (54, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 27 | Accuracy: 0.6296 | Loss: 2.9591 | F1: 0.6225\n",
      "\n",
      "Domain: 28\n",
      "x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 28 | Accuracy: 0.8333 | Loss: 2.1386 | F1: 0.7778\n",
      "\n",
      "Domain: 29\n",
      "x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 29 | Accuracy: 0.7619 | Loss: 0.6205 | F1: 0.7778\n",
      "\n",
      "Domain: 30\n",
      "x_dp_dom.shape: (50, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 30 | Accuracy: 0.8000 | Loss: 3.5365 | F1: 0.7997\n",
      "\n",
      "Domain: 31\n",
      "x_dp_dom.shape: (43, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 31 | Accuracy: 0.8140 | Loss: 1.8209 | F1: 0.8180\n",
      "\n",
      "Domain: 32\n",
      "x_dp_dom.shape: (52, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 32 | Accuracy: 0.5577 | Loss: 1.9084 | F1: 0.5583\n",
      "\n",
      "Domain: 33\n",
      "x_dp_dom.shape: (44, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 33 | Accuracy: 0.8636 | Loss: 1.4519 | F1: 0.8489\n",
      "\n",
      "Domain: 34\n",
      "x_dp_dom.shape: (49, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 34 | Accuracy: 0.4898 | Loss: 7.7653 | F1: 0.5081\n",
      "\n",
      "Domain: 35\n",
      "x_dp_dom.shape: (48, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 35 | Accuracy: 0.8125 | Loss: 2.7030 | F1: 0.7629\n",
      "\n",
      "Domain: 36\n",
      "x_dp_dom.shape: (43, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 36 | Accuracy: 0.7674 | Loss: 2.8764 | F1: 0.7437\n",
      "\n",
      "Domain: 37\n",
      "x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 37 | Accuracy: 0.7857 | Loss: 1.4768 | F1: 0.8125\n",
      "\n",
      "Domain: 38\n",
      "x_dp_dom.shape: (47, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 38 | Accuracy: 0.7660 | Loss: 2.5449 | F1: 0.7494\n",
      "\n",
      "Domain: 39\n",
      "x_dp_dom.shape: (54, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 39 | Accuracy: 0.6111 | Loss: 11.4788 | F1: 0.6061\n",
      "\n",
      "Domain: 40\n",
      "x_dp_dom.shape: (44, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 40 | Accuracy: 0.7273 | Loss: 1.3848 | F1: 0.6884\n",
      "\n",
      "Domain: 41\n",
      "x_dp_dom.shape: (45, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 41 | Accuracy: 0.3111 | Loss: 7.0995 | F1: 0.3618\n",
      "\n",
      "Domain: 42\n",
      "x_dp_dom.shape: (46, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 42 | Accuracy: 0.9130 | Loss: 1.0298 | F1: 0.9167\n",
      "\n",
      "Domain: 43\n",
      "x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 43 | Accuracy: 0.5952 | Loss: 9.4185 | F1: 0.5884\n",
      "\n",
      "Domain: 44\n",
      "x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 44 | Accuracy: 0.9524 | Loss: 0.2056 | F1: 0.9542\n",
      "\n",
      "Domain: 45\n",
      "x_dp_dom.shape: (52, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 45 | Accuracy: 0.7500 | Loss: 1.8617 | F1: 0.6852\n",
      "\n",
      "Domain: 46\n",
      "x_dp_dom.shape: (48, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 46 | Accuracy: 0.8750 | Loss: 0.6048 | F1: 0.8576\n",
      "\n",
      "Domain: 47\n",
      "x_dp_dom.shape: (44, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 47 | Accuracy: 0.7273 | Loss: 1.9261 | F1: 0.7541\n",
      "\n",
      "Domain: 48\n",
      "x_dp_dom.shape: (48, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 48 | Accuracy: 0.7917 | Loss: 0.7417 | F1: 0.8079\n",
      "\n",
      "Domain: 49\n",
      "x_dp_dom.shape: (53, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 49 | Accuracy: 0.6981 | Loss: 3.6888 | F1: 0.6395\n",
      "\n",
      "Domain: 50\n",
      "x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 50 | Accuracy: 0.9048 | Loss: 0.3210 | F1: 0.9049\n",
      "\n",
      "Domain: 51\n",
      "x_dp_dom.shape: (46, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 51 | Accuracy: 0.7609 | Loss: 2.4313 | F1: 0.7409\n",
      "\n",
      "Domain: 52\n",
      "x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 52 | Accuracy: 0.8095 | Loss: 2.5772 | F1: 0.7606\n",
      "\n",
      "Domain: 53\n",
      "x_dp_dom.shape: (48, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 53 | Accuracy: 0.7500 | Loss: 1.4057 | F1: 0.7463\n",
      "\n",
      "Domain: 54\n",
      "x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 54 | Accuracy: 0.9286 | Loss: 0.1761 | F1: 0.9251\n",
      "\n",
      "Domain: 55\n",
      "x_dp_dom.shape: (49, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 55 | Accuracy: 0.8163 | Loss: 2.1656 | F1: 0.7581\n",
      "\n",
      "Domain: 56\n",
      "x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 56 | Accuracy: 0.4286 | Loss: 2.7356 | F1: 0.4741\n",
      "\n",
      "Domain: 57\n",
      "x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 57 | Accuracy: 0.9048 | Loss: 0.5246 | F1: 0.8963\n",
      "\n",
      "Domain: 58\n",
      "x_dp_dom.shape: (38, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 58 | Accuracy: 0.8421 | Loss: 0.7102 | F1: 0.7951\n",
      "\n",
      "Domain: 59\n",
      "x_dp_dom.shape: (43, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 59 | Accuracy: 0.7209 | Loss: 1.7115 | F1: 0.7459\n",
      "\n",
      "Domain: 60\n",
      "x_dp_dom.shape: (47, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 60 | Accuracy: 0.4043 | Loss: 16.6415 | F1: 0.3678\n",
      "\n",
      "Domain: 61\n",
      "x_dp_dom.shape: (47, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 61 | Accuracy: 0.7021 | Loss: 1.9284 | F1: 0.7273\n",
      "\n",
      "Domain: 62\n",
      "x_dp_dom.shape: (47, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 62 | Accuracy: 0.8511 | Loss: 2.5357 | F1: 0.7934\n",
      "\n",
      "Domain: 63\n",
      "x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 63 | Accuracy: 0.8571 | Loss: 0.7372 | F1: 0.8622\n",
      "\n",
      "Domain: 64\n",
      "x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 64 | Accuracy: 0.8571 | Loss: 0.9595 | F1: 0.8250\n",
      "\n",
      "Domain: 65\n",
      "x_dp_dom.shape: (50, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 65 | Accuracy: 0.3000 | Loss: 14.0777 | F1: 0.1763\n",
      "\n",
      "Domain: 66\n",
      "x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 66 | Accuracy: 0.1429 | Loss: 18.1383 | F1: 0.0417\n",
      "\n",
      "Domain: 67\n",
      "x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 67 | Accuracy: 0.8810 | Loss: 0.9561 | F1: 0.8527\n",
      "\n",
      "Domain: 68\n",
      "x_dp_dom.shape: (43, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 68 | Accuracy: 0.6279 | Loss: 2.3776 | F1: 0.6736\n",
      "\n",
      "Domain: 69\n",
      "x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 69 | Accuracy: 0.2381 | Loss: 15.4354 | F1: 0.1507\n",
      "\n",
      "Domain: 70\n",
      "x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 70 | Accuracy: 0.8810 | Loss: 2.0852 | F1: 0.8821\n",
      "\n",
      "Domain: 71\n",
      "x_dp_dom.shape: (44, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 71 | Accuracy: 0.7727 | Loss: 0.5380 | F1: 0.7951\n",
      "\n",
      "Domain: 72\n",
      "x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 72 | Accuracy: 0.5476 | Loss: 2.0736 | F1: 0.6093\n",
      "\n",
      "Domain: 73\n",
      "x_dp_dom.shape: (41, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 73 | Accuracy: 0.1707 | Loss: 17.4880 | F1: 0.0498\n",
      "\n",
      "Domain: 74\n",
      "x_dp_dom.shape: (35, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 74 | Accuracy: 0.7429 | Loss: 2.8733 | F1: 0.7617\n",
      "\n",
      "Domain: 75\n",
      "x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 75 | Accuracy: 0.8333 | Loss: 2.6608 | F1: 0.7778\n",
      "\n",
      "Mean accuracy for run 0: 0.7044\n",
      "Mean F1 for run 0: 0.6859\n",
      "\n",
      "Source class: WAL\n",
      "\n",
      "x_df.shape: (7958, 3, 128) | np.unique(y_df): [1 2 3]\n",
      "\n",
      "Training on Df data...\n",
      "\tEpoch 10/100 - Train loss: 0.0402 - Val accuracy: 0.9749 - Val loss: 0.0621 - Val F1: 0.9748 - LR: 9.00e-05\n",
      "\tEpoch 20/100 - Train loss: 0.0095 - Val accuracy: 0.9843 - Val loss: 0.0471 - Val F1: 0.9843 - LR: 8.00e-05\n",
      "\tEpoch 30/100 - Train loss: 0.0047 - Val accuracy: 0.9824 - Val loss: 0.0501 - Val F1: 0.9823 - LR: 7.00e-05\n",
      "\tEpoch 40/100 - Train loss: 0.0015 - Val accuracy: 0.9849 - Val loss: 0.0468 - Val F1: 0.9849 - LR: 6.00e-05\n",
      "\tEpoch 50/100 - Train loss: 0.0012 - Val accuracy: 0.9856 - Val loss: 0.0542 - Val F1: 0.9855 - LR: 5.00e-05\n",
      "\tEpoch 60/100 - Train loss: 0.0016 - Val accuracy: 0.9862 - Val loss: 0.0465 - Val F1: 0.9862 - LR: 4.00e-05\n",
      "\tEpoch 70/100 - Train loss: 0.0005 - Val accuracy: 0.9862 - Val loss: 0.0510 - Val F1: 0.9862 - LR: 3.00e-05\n",
      "\tEpoch 80/100 - Train loss: 0.0002 - Val accuracy: 0.9862 - Val loss: 0.0592 - Val F1: 0.9862 - LR: 2.00e-05\n",
      "\tEpoch 90/100 - Train loss: 0.0005 - Val accuracy: 0.9862 - Val loss: 0.0584 - Val F1: 0.9862 - LR: 1.00e-05\n",
      "\tEpoch 100/100 - Train loss: 0.0002 - Val accuracy: 0.9868 - Val loss: 0.0502 - Val F1: 0.9868 - LR: 0.00e+00\n",
      "\tBest epoch: 22 - Best val accuracy: 0.9837 - Best val loss: 0.0428 - Best val F1: 0.9837\n",
      "\n",
      "Domain: 15\n",
      "x_dp_dom.shape: (50, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 15 | Accuracy: 0.1000 | Loss: 17.7313 | F1: 0.0436\n",
      "\n",
      "Domain: 16\n",
      "x_dp_dom.shape: (54, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 16 | Accuracy: 0.7222 | Loss: 1.2570 | F1: 0.7350\n",
      "\n",
      "Domain: 17\n",
      "x_dp_dom.shape: (53, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 17 | Accuracy: 0.7358 | Loss: 2.1548 | F1: 0.7006\n",
      "\n",
      "Domain: 18\n",
      "x_dp_dom.shape: (54, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 18 | Accuracy: 0.5741 | Loss: 3.3660 | F1: 0.5713\n",
      "\n",
      "Domain: 19\n",
      "x_dp_dom.shape: (54, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 19 | Accuracy: 0.7593 | Loss: 1.1824 | F1: 0.7404\n",
      "\n",
      "Domain: 20\n",
      "x_dp_dom.shape: (51, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 20 | Accuracy: 0.6471 | Loss: 2.3904 | F1: 0.6632\n",
      "\n",
      "Domain: 21\n",
      "x_dp_dom.shape: (47, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 21 | Accuracy: 0.7447 | Loss: 1.4143 | F1: 0.7535\n",
      "\n",
      "Domain: 22\n",
      "x_dp_dom.shape: (54, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 22 | Accuracy: 0.7778 | Loss: 1.2432 | F1: 0.7888\n",
      "\n",
      "Domain: 23\n",
      "x_dp_dom.shape: (52, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 23 | Accuracy: 0.6731 | Loss: 1.9194 | F1: 0.6984\n",
      "\n",
      "Domain: 24\n",
      "x_dp_dom.shape: (51, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 24 | Accuracy: 0.8235 | Loss: 0.7772 | F1: 0.8281\n",
      "\n",
      "Domain: 25\n",
      "x_dp_dom.shape: (54, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 25 | Accuracy: 0.5926 | Loss: 3.8007 | F1: 0.5876\n",
      "\n",
      "Domain: 26\n",
      "x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 26 | Accuracy: 0.5952 | Loss: 1.8001 | F1: 0.6346\n",
      "\n",
      "Domain: 27\n",
      "x_dp_dom.shape: (54, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 27 | Accuracy: 0.7407 | Loss: 3.0714 | F1: 0.6706\n",
      "\n",
      "Domain: 28\n",
      "x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 28 | Accuracy: 0.8571 | Loss: 1.2572 | F1: 0.8250\n",
      "\n",
      "Domain: 29\n",
      "x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 29 | Accuracy: 0.3333 | Loss: 2.7981 | F1: 0.3292\n",
      "\n",
      "Domain: 30\n",
      "x_dp_dom.shape: (50, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 30 | Accuracy: 0.8000 | Loss: 2.6899 | F1: 0.8013\n",
      "\n",
      "Domain: 31\n",
      "x_dp_dom.shape: (43, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 31 | Accuracy: 0.9302 | Loss: 1.1394 | F1: 0.9299\n",
      "\n",
      "Domain: 32\n",
      "x_dp_dom.shape: (52, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 32 | Accuracy: 0.5000 | Loss: 4.4161 | F1: 0.5171\n",
      "\n",
      "Domain: 33\n",
      "x_dp_dom.shape: (44, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 33 | Accuracy: 0.9545 | Loss: 0.1751 | F1: 0.9545\n",
      "\n",
      "Domain: 34\n",
      "x_dp_dom.shape: (49, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 34 | Accuracy: 0.4286 | Loss: 6.6312 | F1: 0.4791\n",
      "\n",
      "Domain: 35\n",
      "x_dp_dom.shape: (48, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 35 | Accuracy: 0.7500 | Loss: 2.3262 | F1: 0.7423\n",
      "\n",
      "Domain: 36\n",
      "x_dp_dom.shape: (43, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 36 | Accuracy: 0.7442 | Loss: 2.5336 | F1: 0.7327\n",
      "\n",
      "Domain: 37\n",
      "x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 37 | Accuracy: 0.7143 | Loss: 1.4812 | F1: 0.7536\n",
      "\n",
      "Domain: 38\n",
      "x_dp_dom.shape: (47, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 38 | Accuracy: 0.5532 | Loss: 2.6929 | F1: 0.5717\n",
      "\n",
      "Domain: 39\n",
      "x_dp_dom.shape: (54, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 39 | Accuracy: 0.4815 | Loss: 10.4614 | F1: 0.4815\n",
      "\n",
      "Domain: 40\n",
      "x_dp_dom.shape: (44, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 40 | Accuracy: 0.7955 | Loss: 2.2880 | F1: 0.7609\n",
      "\n",
      "Domain: 41\n",
      "x_dp_dom.shape: (45, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 41 | Accuracy: 0.3778 | Loss: 5.2710 | F1: 0.4621\n",
      "\n",
      "Domain: 42\n",
      "x_dp_dom.shape: (46, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 42 | Accuracy: 0.8696 | Loss: 0.8342 | F1: 0.8533\n",
      "\n",
      "Domain: 43\n",
      "x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 43 | Accuracy: 0.5714 | Loss: 9.0151 | F1: 0.6320\n",
      "\n",
      "Domain: 44\n",
      "x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 44 | Accuracy: 0.8571 | Loss: 0.5872 | F1: 0.8566\n",
      "\n",
      "Domain: 45\n",
      "x_dp_dom.shape: (52, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 45 | Accuracy: 0.8077 | Loss: 1.2103 | F1: 0.8073\n",
      "\n",
      "Domain: 46\n",
      "x_dp_dom.shape: (48, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 46 | Accuracy: 0.4583 | Loss: 2.6021 | F1: 0.4723\n",
      "\n",
      "Domain: 47\n",
      "x_dp_dom.shape: (44, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 47 | Accuracy: 0.4545 | Loss: 2.8147 | F1: 0.5133\n",
      "\n",
      "Domain: 48\n",
      "x_dp_dom.shape: (48, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 48 | Accuracy: 0.5625 | Loss: 2.1393 | F1: 0.5671\n",
      "\n",
      "Domain: 49\n",
      "x_dp_dom.shape: (53, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 49 | Accuracy: 0.3962 | Loss: 3.0313 | F1: 0.4080\n",
      "\n",
      "Domain: 50\n",
      "x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 50 | Accuracy: 0.8095 | Loss: 0.5152 | F1: 0.8175\n",
      "\n",
      "Domain: 51\n",
      "x_dp_dom.shape: (46, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 51 | Accuracy: 0.8043 | Loss: 1.6253 | F1: 0.7937\n",
      "\n",
      "Domain: 52\n",
      "x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 52 | Accuracy: 0.8810 | Loss: 1.0702 | F1: 0.8635\n",
      "\n",
      "Domain: 53\n",
      "x_dp_dom.shape: (48, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 53 | Accuracy: 0.6875 | Loss: 1.9094 | F1: 0.7229\n",
      "\n",
      "Domain: 54\n",
      "x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 54 | Accuracy: 0.8095 | Loss: 2.1769 | F1: 0.7657\n",
      "\n",
      "Domain: 55\n",
      "x_dp_dom.shape: (49, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 55 | Accuracy: 0.8367 | Loss: 0.7670 | F1: 0.8316\n",
      "\n",
      "Domain: 56\n",
      "x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 56 | Accuracy: 0.5476 | Loss: 1.3744 | F1: 0.5892\n",
      "\n",
      "Domain: 57\n",
      "x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 57 | Accuracy: 0.9048 | Loss: 0.2712 | F1: 0.8963\n",
      "\n",
      "Domain: 58\n",
      "x_dp_dom.shape: (38, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 58 | Accuracy: 0.8684 | Loss: 0.9223 | F1: 0.8725\n",
      "\n",
      "Domain: 59\n",
      "x_dp_dom.shape: (43, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 59 | Accuracy: 0.5814 | Loss: 3.7897 | F1: 0.6119\n",
      "\n",
      "Domain: 60\n",
      "x_dp_dom.shape: (47, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 60 | Accuracy: 0.4043 | Loss: 14.2071 | F1: 0.3678\n",
      "\n",
      "Domain: 61\n",
      "x_dp_dom.shape: (47, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 61 | Accuracy: 0.5532 | Loss: 4.9136 | F1: 0.5817\n",
      "\n",
      "Domain: 62\n",
      "x_dp_dom.shape: (47, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 62 | Accuracy: 0.5319 | Loss: 3.2144 | F1: 0.5917\n",
      "\n",
      "Domain: 63\n",
      "x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 63 | Accuracy: 0.7381 | Loss: 0.9067 | F1: 0.7639\n",
      "\n",
      "Domain: 64\n",
      "x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 64 | Accuracy: 0.8810 | Loss: 0.3320 | F1: 0.8635\n",
      "\n",
      "Domain: 65\n",
      "x_dp_dom.shape: (50, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 65 | Accuracy: 0.2800 | Loss: 9.3058 | F1: 0.1450\n",
      "\n",
      "Domain: 66\n",
      "x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 66 | Accuracy: 0.1190 | Loss: 17.3700 | F1: 0.0355\n",
      "\n",
      "Domain: 67\n",
      "x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 67 | Accuracy: 0.8333 | Loss: 2.2800 | F1: 0.7778\n",
      "\n",
      "Domain: 68\n",
      "x_dp_dom.shape: (43, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 68 | Accuracy: 0.2558 | Loss: 5.4679 | F1: 0.2169\n",
      "\n",
      "Domain: 69\n",
      "x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 69 | Accuracy: 0.2857 | Loss: 9.2396 | F1: 0.1825\n",
      "\n",
      "Domain: 70\n",
      "x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 70 | Accuracy: 0.4286 | Loss: 3.4733 | F1: 0.4804\n",
      "\n",
      "Domain: 71\n",
      "x_dp_dom.shape: (44, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 71 | Accuracy: 0.8182 | Loss: 0.6017 | F1: 0.8402\n",
      "\n",
      "Domain: 72\n",
      "x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 72 | Accuracy: 0.3095 | Loss: 3.4749 | F1: 0.3211\n",
      "\n",
      "Domain: 73\n",
      "x_dp_dom.shape: (41, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 73 | Accuracy: 0.1707 | Loss: 20.0901 | F1: 0.0498\n",
      "\n",
      "Domain: 74\n",
      "x_dp_dom.shape: (35, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 74 | Accuracy: 0.8000 | Loss: 2.1360 | F1: 0.7344\n",
      "\n",
      "Domain: 75\n",
      "x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 75 | Accuracy: 0.8095 | Loss: 0.5785 | F1: 0.8081\n",
      "\n",
      "Mean accuracy for run 1: 0.6333\n",
      "Mean F1 for run 1: 0.6294\n",
      "\n",
      "Source class: WAL\n",
      "\n",
      "x_df.shape: (7958, 3, 128) | np.unique(y_df): [1 2 3]\n",
      "\n",
      "Training on Df data...\n",
      "\tEpoch 10/100 - Train loss: 0.0356 - Val accuracy: 0.9805 - Val loss: 0.0563 - Val F1: 0.9805 - LR: 9.00e-05\n",
      "\tEpoch 20/100 - Train loss: 0.0104 - Val accuracy: 0.9837 - Val loss: 0.0476 - Val F1: 0.9837 - LR: 8.00e-05\n",
      "\tEpoch 30/100 - Train loss: 0.0073 - Val accuracy: 0.9856 - Val loss: 0.0471 - Val F1: 0.9856 - LR: 7.00e-05\n",
      "\tEpoch 40/100 - Train loss: 0.0034 - Val accuracy: 0.9849 - Val loss: 0.0505 - Val F1: 0.9849 - LR: 6.00e-05\n",
      "\tEpoch 50/100 - Train loss: 0.0022 - Val accuracy: 0.9837 - Val loss: 0.0602 - Val F1: 0.9837 - LR: 5.00e-05\n",
      "\tEpoch 60/100 - Train loss: 0.0005 - Val accuracy: 0.9849 - Val loss: 0.0583 - Val F1: 0.9849 - LR: 4.00e-05\n",
      "\tEpoch 70/100 - Train loss: 0.0006 - Val accuracy: 0.9849 - Val loss: 0.0703 - Val F1: 0.9849 - LR: 3.00e-05\n",
      "\tEpoch 80/100 - Train loss: 0.0007 - Val accuracy: 0.9856 - Val loss: 0.0661 - Val F1: 0.9855 - LR: 2.00e-05\n",
      "\tEpoch 90/100 - Train loss: 0.0004 - Val accuracy: 0.9862 - Val loss: 0.0705 - Val F1: 0.9862 - LR: 1.00e-05\n",
      "\tEpoch 100/100 - Train loss: 0.0002 - Val accuracy: 0.9843 - Val loss: 0.0670 - Val F1: 0.9843 - LR: 0.00e+00\n",
      "\tBest epoch: 25 - Best val accuracy: 0.9843 - Best val loss: 0.0436 - Best val F1: 0.9843\n",
      "\n",
      "Domain: 15\n",
      "x_dp_dom.shape: (50, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 15 | Accuracy: 0.8000 | Loss: 3.6443 | F1: 0.7294\n",
      "\n",
      "Domain: 16\n",
      "x_dp_dom.shape: (54, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 16 | Accuracy: 0.4815 | Loss: 2.2030 | F1: 0.5017\n",
      "\n",
      "Domain: 17\n",
      "x_dp_dom.shape: (53, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 17 | Accuracy: 0.6981 | Loss: 2.7833 | F1: 0.6555\n",
      "\n",
      "Domain: 18\n",
      "x_dp_dom.shape: (54, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 18 | Accuracy: 0.4815 | Loss: 4.4754 | F1: 0.4815\n",
      "\n",
      "Domain: 19\n",
      "x_dp_dom.shape: (54, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 19 | Accuracy: 0.7593 | Loss: 2.4548 | F1: 0.7059\n",
      "\n",
      "Domain: 20\n",
      "x_dp_dom.shape: (51, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 20 | Accuracy: 0.7059 | Loss: 2.8999 | F1: 0.6651\n",
      "\n",
      "Domain: 21\n",
      "x_dp_dom.shape: (47, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 21 | Accuracy: 0.7234 | Loss: 2.0690 | F1: 0.7219\n",
      "\n",
      "Domain: 22\n",
      "x_dp_dom.shape: (54, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 22 | Accuracy: 0.9074 | Loss: 0.7462 | F1: 0.9062\n",
      "\n",
      "Domain: 23\n",
      "x_dp_dom.shape: (52, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 23 | Accuracy: 0.7500 | Loss: 1.3653 | F1: 0.7154\n",
      "\n",
      "Domain: 24\n",
      "x_dp_dom.shape: (51, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 24 | Accuracy: 0.7843 | Loss: 0.8597 | F1: 0.7913\n",
      "\n",
      "Domain: 25\n",
      "x_dp_dom.shape: (54, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 25 | Accuracy: 0.5000 | Loss: 3.9969 | F1: 0.5062\n",
      "\n",
      "Domain: 26\n",
      "x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 26 | Accuracy: 0.7857 | Loss: 1.6417 | F1: 0.7759\n",
      "\n",
      "Domain: 27\n",
      "x_dp_dom.shape: (54, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 27 | Accuracy: 0.7222 | Loss: 2.1998 | F1: 0.6838\n",
      "\n",
      "Domain: 28\n",
      "x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 28 | Accuracy: 0.8095 | Loss: 0.9868 | F1: 0.7931\n",
      "\n",
      "Domain: 29\n",
      "x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 29 | Accuracy: 0.6905 | Loss: 0.7499 | F1: 0.7113\n",
      "\n",
      "Domain: 30\n",
      "x_dp_dom.shape: (50, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 30 | Accuracy: 0.6400 | Loss: 2.9362 | F1: 0.6521\n",
      "\n",
      "Domain: 31\n",
      "x_dp_dom.shape: (43, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 31 | Accuracy: 0.8372 | Loss: 1.2997 | F1: 0.8108\n",
      "\n",
      "Domain: 32\n",
      "x_dp_dom.shape: (52, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 32 | Accuracy: 0.5385 | Loss: 4.2211 | F1: 0.5513\n",
      "\n",
      "Domain: 33\n",
      "x_dp_dom.shape: (44, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 33 | Accuracy: 0.8409 | Loss: 0.5715 | F1: 0.8471\n",
      "\n",
      "Domain: 34\n",
      "x_dp_dom.shape: (49, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 34 | Accuracy: 0.7143 | Loss: 0.8969 | F1: 0.7278\n",
      "\n",
      "Domain: 35\n",
      "x_dp_dom.shape: (48, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 35 | Accuracy: 0.7083 | Loss: 2.7324 | F1: 0.7071\n",
      "\n",
      "Domain: 36\n",
      "x_dp_dom.shape: (43, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 36 | Accuracy: 0.7907 | Loss: 2.6021 | F1: 0.7565\n",
      "\n",
      "Domain: 37\n",
      "x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 37 | Accuracy: 0.7143 | Loss: 0.9845 | F1: 0.7570\n",
      "\n",
      "Domain: 38\n",
      "x_dp_dom.shape: (47, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 38 | Accuracy: 0.5106 | Loss: 3.3924 | F1: 0.5571\n",
      "\n",
      "Domain: 39\n",
      "x_dp_dom.shape: (54, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 39 | Accuracy: 0.7407 | Loss: 0.7894 | F1: 0.7465\n",
      "\n",
      "Domain: 40\n",
      "x_dp_dom.shape: (44, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 40 | Accuracy: 0.7273 | Loss: 1.6698 | F1: 0.7182\n",
      "\n",
      "Domain: 41\n",
      "x_dp_dom.shape: (45, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 41 | Accuracy: 0.1778 | Loss: 8.0039 | F1: 0.1502\n",
      "\n",
      "Domain: 42\n",
      "x_dp_dom.shape: (46, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 42 | Accuracy: 0.4783 | Loss: 1.8624 | F1: 0.5157\n",
      "\n",
      "Domain: 43\n",
      "x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 43 | Accuracy: 0.7857 | Loss: 1.7678 | F1: 0.7754\n",
      "\n",
      "Domain: 44\n",
      "x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 44 | Accuracy: 0.8810 | Loss: 0.3736 | F1: 0.8635\n",
      "\n",
      "Domain: 45\n",
      "x_dp_dom.shape: (52, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 45 | Accuracy: 0.5962 | Loss: 3.2668 | F1: 0.5881\n",
      "\n",
      "Domain: 46\n",
      "x_dp_dom.shape: (48, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 46 | Accuracy: 0.4583 | Loss: 3.4850 | F1: 0.4972\n",
      "\n",
      "Domain: 47\n",
      "x_dp_dom.shape: (44, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 47 | Accuracy: 0.6591 | Loss: 1.3226 | F1: 0.7049\n",
      "\n",
      "Domain: 48\n",
      "x_dp_dom.shape: (48, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 48 | Accuracy: 0.8958 | Loss: 0.5594 | F1: 0.8987\n",
      "\n",
      "Domain: 49\n",
      "x_dp_dom.shape: (53, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 49 | Accuracy: 0.3396 | Loss: 4.8330 | F1: 0.3119\n",
      "\n",
      "Domain: 50\n",
      "x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 50 | Accuracy: 0.8571 | Loss: 0.4867 | F1: 0.8673\n",
      "\n",
      "Domain: 51\n",
      "x_dp_dom.shape: (46, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 51 | Accuracy: 0.7609 | Loss: 1.8886 | F1: 0.7270\n",
      "\n",
      "Domain: 52\n",
      "x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 52 | Accuracy: 0.8095 | Loss: 2.2653 | F1: 0.7606\n",
      "\n",
      "Domain: 53\n",
      "x_dp_dom.shape: (48, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 53 | Accuracy: 0.7917 | Loss: 1.0700 | F1: 0.7728\n",
      "\n",
      "Domain: 54\n",
      "x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 54 | Accuracy: 0.9048 | Loss: 0.7479 | F1: 0.8963\n",
      "\n",
      "Domain: 55\n",
      "x_dp_dom.shape: (49, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 55 | Accuracy: 0.6735 | Loss: 2.5845 | F1: 0.6733\n",
      "\n",
      "Domain: 56\n",
      "x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 56 | Accuracy: 0.8571 | Loss: 0.8574 | F1: 0.8453\n",
      "\n",
      "Domain: 57\n",
      "x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 57 | Accuracy: 0.8810 | Loss: 0.5448 | F1: 0.8635\n",
      "\n",
      "Domain: 58\n",
      "x_dp_dom.shape: (38, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 58 | Accuracy: 0.8158 | Loss: 1.9382 | F1: 0.7754\n",
      "\n",
      "Domain: 59\n",
      "x_dp_dom.shape: (43, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 59 | Accuracy: 0.7209 | Loss: 1.1786 | F1: 0.7567\n",
      "\n",
      "Domain: 60\n",
      "x_dp_dom.shape: (47, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 60 | Accuracy: 0.7872 | Loss: 3.8293 | F1: 0.7398\n",
      "\n",
      "Domain: 61\n",
      "x_dp_dom.shape: (47, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 61 | Accuracy: 0.3191 | Loss: 5.0255 | F1: 0.3007\n",
      "\n",
      "Domain: 62\n",
      "x_dp_dom.shape: (47, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 62 | Accuracy: 0.8511 | Loss: 2.4543 | F1: 0.7934\n",
      "\n",
      "Domain: 63\n",
      "x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 63 | Accuracy: 0.7857 | Loss: 1.2945 | F1: 0.7997\n",
      "\n",
      "Domain: 64\n",
      "x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 64 | Accuracy: 0.7381 | Loss: 2.5476 | F1: 0.7265\n",
      "\n",
      "Domain: 65\n",
      "x_dp_dom.shape: (50, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 65 | Accuracy: 0.8200 | Loss: 1.7223 | F1: 0.7818\n",
      "\n",
      "Domain: 66\n",
      "x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 66 | Accuracy: 0.8333 | Loss: 1.1725 | F1: 0.7595\n",
      "\n",
      "Domain: 67\n",
      "x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 67 | Accuracy: 0.8333 | Loss: 1.6312 | F1: 0.7716\n",
      "\n",
      "Domain: 68\n",
      "x_dp_dom.shape: (43, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 68 | Accuracy: 0.3953 | Loss: 3.1389 | F1: 0.4409\n",
      "\n",
      "Domain: 69\n",
      "x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 69 | Accuracy: 0.9048 | Loss: 0.7085 | F1: 0.8963\n",
      "\n",
      "Domain: 70\n",
      "x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 70 | Accuracy: 0.8095 | Loss: 1.4554 | F1: 0.7667\n",
      "\n",
      "Domain: 71\n",
      "x_dp_dom.shape: (44, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 71 | Accuracy: 0.6818 | Loss: 0.7382 | F1: 0.7112\n",
      "\n",
      "Domain: 72\n",
      "x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 72 | Accuracy: 0.2143 | Loss: 4.0298 | F1: 0.2304\n",
      "\n",
      "Domain: 73\n",
      "x_dp_dom.shape: (41, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 73 | Accuracy: 0.8293 | Loss: 2.2101 | F1: 0.7788\n",
      "\n",
      "Domain: 74\n",
      "x_dp_dom.shape: (35, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 74 | Accuracy: 0.8000 | Loss: 2.6007 | F1: 0.7679\n",
      "\n",
      "Domain: 75\n",
      "x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 75 | Accuracy: 0.7381 | Loss: 2.2740 | F1: 0.7265\n",
      "\n",
      "Mean accuracy for run 2: 0.7057\n",
      "Mean F1 for run 2: 0.6953\n",
      "\n",
      "Source class: WAL\n",
      "\n",
      "x_df.shape: (7958, 3, 128) | np.unique(y_df): [1 2 3]\n",
      "\n",
      "Training on Df data...\n",
      "\tEpoch 10/100 - Train loss: 0.0321 - Val accuracy: 0.9830 - Val loss: 0.0429 - Val F1: 0.9830 - LR: 9.00e-05\n",
      "\tEpoch 20/100 - Train loss: 0.0113 - Val accuracy: 0.9856 - Val loss: 0.0337 - Val F1: 0.9856 - LR: 8.00e-05\n",
      "\tEpoch 30/100 - Train loss: 0.0062 - Val accuracy: 0.9862 - Val loss: 0.0356 - Val F1: 0.9862 - LR: 7.00e-05\n",
      "\tEpoch 40/100 - Train loss: 0.0017 - Val accuracy: 0.9862 - Val loss: 0.0404 - Val F1: 0.9862 - LR: 6.00e-05\n",
      "\tEpoch 50/100 - Train loss: 0.0023 - Val accuracy: 0.9874 - Val loss: 0.0414 - Val F1: 0.9874 - LR: 5.00e-05\n",
      "\tEpoch 60/100 - Train loss: 0.0006 - Val accuracy: 0.9868 - Val loss: 0.0441 - Val F1: 0.9868 - LR: 4.00e-05\n",
      "\tEpoch 70/100 - Train loss: 0.0004 - Val accuracy: 0.9868 - Val loss: 0.0465 - Val F1: 0.9868 - LR: 3.00e-05\n",
      "\tEpoch 80/100 - Train loss: 0.0002 - Val accuracy: 0.9868 - Val loss: 0.0474 - Val F1: 0.9868 - LR: 2.00e-05\n",
      "\tEpoch 90/100 - Train loss: 0.0002 - Val accuracy: 0.9868 - Val loss: 0.0449 - Val F1: 0.9868 - LR: 1.00e-05\n",
      "\tEpoch 100/100 - Train loss: 0.0003 - Val accuracy: 0.9881 - Val loss: 0.0423 - Val F1: 0.9881 - LR: 0.00e+00\n",
      "\tBest epoch: 19 - Best val accuracy: 0.9862 - Best val loss: 0.0327 - Best val F1: 0.9862\n",
      "\n",
      "Domain: 15\n",
      "x_dp_dom.shape: (50, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 15 | Accuracy: 0.6400 | Loss: 6.1806 | F1: 0.6191\n",
      "\n",
      "Domain: 16\n",
      "x_dp_dom.shape: (54, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 16 | Accuracy: 0.7407 | Loss: 1.0303 | F1: 0.6941\n",
      "\n",
      "Domain: 17\n",
      "x_dp_dom.shape: (53, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 17 | Accuracy: 0.6792 | Loss: 2.5668 | F1: 0.6400\n",
      "\n",
      "Domain: 18\n",
      "x_dp_dom.shape: (54, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 18 | Accuracy: 0.7037 | Loss: 2.8394 | F1: 0.6456\n",
      "\n",
      "Domain: 19\n",
      "x_dp_dom.shape: (54, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 19 | Accuracy: 0.7778 | Loss: 1.4006 | F1: 0.7384\n",
      "\n",
      "Domain: 20\n",
      "x_dp_dom.shape: (51, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 20 | Accuracy: 0.7647 | Loss: 1.5379 | F1: 0.7466\n",
      "\n",
      "Domain: 21\n",
      "x_dp_dom.shape: (47, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 21 | Accuracy: 0.8085 | Loss: 2.0916 | F1: 0.7713\n",
      "\n",
      "Domain: 22\n",
      "x_dp_dom.shape: (54, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 22 | Accuracy: 0.8889 | Loss: 0.7148 | F1: 0.8826\n",
      "\n",
      "Domain: 23\n",
      "x_dp_dom.shape: (52, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 23 | Accuracy: 0.6538 | Loss: 2.8440 | F1: 0.6482\n",
      "\n",
      "Domain: 24\n",
      "x_dp_dom.shape: (51, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 24 | Accuracy: 0.6863 | Loss: 1.5050 | F1: 0.7075\n",
      "\n",
      "Domain: 25\n",
      "x_dp_dom.shape: (54, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 25 | Accuracy: 0.6296 | Loss: 3.0253 | F1: 0.6009\n",
      "\n",
      "Domain: 26\n",
      "x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 26 | Accuracy: 0.9286 | Loss: 0.2718 | F1: 0.9307\n",
      "\n",
      "Domain: 27\n",
      "x_dp_dom.shape: (54, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 27 | Accuracy: 0.7222 | Loss: 3.2723 | F1: 0.6611\n",
      "\n",
      "Domain: 28\n",
      "x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 28 | Accuracy: 0.8333 | Loss: 1.0520 | F1: 0.7778\n",
      "\n",
      "Domain: 29\n",
      "x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 29 | Accuracy: 0.2857 | Loss: 2.5462 | F1: 0.2183\n",
      "\n",
      "Domain: 30\n",
      "x_dp_dom.shape: (50, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 30 | Accuracy: 0.7400 | Loss: 2.2743 | F1: 0.7327\n",
      "\n",
      "Domain: 31\n",
      "x_dp_dom.shape: (43, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 31 | Accuracy: 0.8140 | Loss: 1.5699 | F1: 0.8111\n",
      "\n",
      "Domain: 32\n",
      "x_dp_dom.shape: (52, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 32 | Accuracy: 0.5962 | Loss: 1.2220 | F1: 0.6274\n",
      "\n",
      "Domain: 33\n",
      "x_dp_dom.shape: (44, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 33 | Accuracy: 0.9318 | Loss: 0.3140 | F1: 0.9310\n",
      "\n",
      "Domain: 34\n",
      "x_dp_dom.shape: (49, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 34 | Accuracy: 0.6531 | Loss: 3.8566 | F1: 0.6741\n",
      "\n",
      "Domain: 35\n",
      "x_dp_dom.shape: (48, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 35 | Accuracy: 0.8125 | Loss: 2.2532 | F1: 0.7751\n",
      "\n",
      "Domain: 36\n",
      "x_dp_dom.shape: (43, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 36 | Accuracy: 0.8140 | Loss: 1.9701 | F1: 0.7687\n",
      "\n",
      "Domain: 37\n",
      "x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 37 | Accuracy: 0.9286 | Loss: 0.2990 | F1: 0.9305\n",
      "\n",
      "Domain: 38\n",
      "x_dp_dom.shape: (47, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 38 | Accuracy: 0.7660 | Loss: 2.1187 | F1: 0.7582\n",
      "\n",
      "Domain: 39\n",
      "x_dp_dom.shape: (54, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 39 | Accuracy: 0.6296 | Loss: 4.0166 | F1: 0.6194\n",
      "\n",
      "Domain: 40\n",
      "x_dp_dom.shape: (44, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 40 | Accuracy: 0.7273 | Loss: 1.7694 | F1: 0.7273\n",
      "\n",
      "Domain: 41\n",
      "x_dp_dom.shape: (45, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 41 | Accuracy: 0.1778 | Loss: 7.8753 | F1: 0.1625\n",
      "\n",
      "Domain: 42\n",
      "x_dp_dom.shape: (46, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 42 | Accuracy: 0.7826 | Loss: 1.0265 | F1: 0.7981\n",
      "\n",
      "Domain: 43\n",
      "x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 43 | Accuracy: 0.6905 | Loss: 2.9424 | F1: 0.6649\n",
      "\n",
      "Domain: 44\n",
      "x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 44 | Accuracy: 0.9048 | Loss: 0.4192 | F1: 0.9098\n",
      "\n",
      "Domain: 45\n",
      "x_dp_dom.shape: (52, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 45 | Accuracy: 0.7885 | Loss: 1.8230 | F1: 0.7141\n",
      "\n",
      "Domain: 46\n",
      "x_dp_dom.shape: (48, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 46 | Accuracy: 0.8125 | Loss: 1.0096 | F1: 0.7751\n",
      "\n",
      "Domain: 47\n",
      "x_dp_dom.shape: (44, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 47 | Accuracy: 0.7500 | Loss: 1.6237 | F1: 0.7652\n",
      "\n",
      "Domain: 48\n",
      "x_dp_dom.shape: (48, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 48 | Accuracy: 0.8750 | Loss: 0.6227 | F1: 0.8713\n",
      "\n",
      "Domain: 49\n",
      "x_dp_dom.shape: (53, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 49 | Accuracy: 0.5283 | Loss: 3.0775 | F1: 0.5241\n",
      "\n",
      "Domain: 50\n",
      "x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 50 | Accuracy: 0.9762 | Loss: 0.1757 | F1: 0.9761\n",
      "\n",
      "Domain: 51\n",
      "x_dp_dom.shape: (46, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 51 | Accuracy: 0.7826 | Loss: 2.2870 | F1: 0.7410\n",
      "\n",
      "Domain: 52\n",
      "x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 52 | Accuracy: 0.8095 | Loss: 1.9442 | F1: 0.7606\n",
      "\n",
      "Domain: 53\n",
      "x_dp_dom.shape: (48, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 53 | Accuracy: 0.8125 | Loss: 0.8216 | F1: 0.8027\n",
      "\n",
      "Domain: 54\n",
      "x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 54 | Accuracy: 0.9286 | Loss: 0.1220 | F1: 0.9220\n",
      "\n",
      "Domain: 55\n",
      "x_dp_dom.shape: (49, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 55 | Accuracy: 0.7959 | Loss: 2.0051 | F1: 0.7419\n",
      "\n",
      "Domain: 56\n",
      "x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 56 | Accuracy: 0.7857 | Loss: 0.5054 | F1: 0.8049\n",
      "\n",
      "Domain: 57\n",
      "x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 57 | Accuracy: 0.9286 | Loss: 0.0966 | F1: 0.9282\n",
      "\n",
      "Domain: 58\n",
      "x_dp_dom.shape: (38, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 58 | Accuracy: 0.8158 | Loss: 0.9643 | F1: 0.8139\n",
      "\n",
      "Domain: 59\n",
      "x_dp_dom.shape: (43, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 59 | Accuracy: 0.6977 | Loss: 1.7012 | F1: 0.7267\n",
      "\n",
      "Domain: 60\n",
      "x_dp_dom.shape: (47, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 60 | Accuracy: 0.5745 | Loss: 5.7990 | F1: 0.5559\n",
      "\n",
      "Domain: 61\n",
      "x_dp_dom.shape: (47, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 61 | Accuracy: 0.6596 | Loss: 1.6727 | F1: 0.6968\n",
      "\n",
      "Domain: 62\n",
      "x_dp_dom.shape: (47, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 62 | Accuracy: 0.6809 | Loss: 2.5258 | F1: 0.6941\n",
      "\n",
      "Domain: 63\n",
      "x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 63 | Accuracy: 0.8810 | Loss: 0.8140 | F1: 0.8860\n",
      "\n",
      "Domain: 64\n",
      "x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 64 | Accuracy: 0.6905 | Loss: 1.7449 | F1: 0.6978\n",
      "\n",
      "Domain: 65\n",
      "x_dp_dom.shape: (50, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 65 | Accuracy: 0.6800 | Loss: 2.3793 | F1: 0.6614\n",
      "\n",
      "Domain: 66\n",
      "x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 66 | Accuracy: 0.5476 | Loss: 5.0502 | F1: 0.5575\n",
      "\n",
      "Domain: 67\n",
      "x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 67 | Accuracy: 0.8095 | Loss: 1.0190 | F1: 0.7989\n",
      "\n",
      "Domain: 68\n",
      "x_dp_dom.shape: (43, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 68 | Accuracy: 0.9070 | Loss: 0.1830 | F1: 0.9119\n",
      "\n",
      "Domain: 69\n",
      "x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 69 | Accuracy: 0.8333 | Loss: 1.2865 | F1: 0.8516\n",
      "\n",
      "Domain: 70\n",
      "x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 70 | Accuracy: 0.7381 | Loss: 1.8044 | F1: 0.7472\n",
      "\n",
      "Domain: 71\n",
      "x_dp_dom.shape: (44, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 71 | Accuracy: 0.7500 | Loss: 0.7055 | F1: 0.7588\n",
      "\n",
      "Domain: 72\n",
      "x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 72 | Accuracy: 0.6429 | Loss: 1.6943 | F1: 0.6810\n",
      "\n",
      "Domain: 73\n",
      "x_dp_dom.shape: (41, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 73 | Accuracy: 0.7561 | Loss: 3.8154 | F1: 0.7300\n",
      "\n",
      "Domain: 74\n",
      "x_dp_dom.shape: (35, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 74 | Accuracy: 0.8571 | Loss: 1.4800 | F1: 0.8359\n",
      "\n",
      "Domain: 75\n",
      "x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 75 | Accuracy: 0.8333 | Loss: 1.2302 | F1: 0.7778\n",
      "\n",
      "Mean accuracy for run 3: 0.7482\n",
      "Mean F1 for run 3: 0.7358\n",
      "\n",
      "Source class: WAL\n",
      "\n",
      "x_df.shape: (7958, 3, 128) | np.unique(y_df): [1 2 3]\n",
      "\n",
      "Training on Df data...\n",
      "\tEpoch 10/100 - Train loss: 0.0276 - Val accuracy: 0.9830 - Val loss: 0.0495 - Val F1: 0.9830 - LR: 9.00e-05\n",
      "\tEpoch 20/100 - Train loss: 0.0081 - Val accuracy: 0.9849 - Val loss: 0.0470 - Val F1: 0.9849 - LR: 8.00e-05\n",
      "\tEpoch 30/100 - Train loss: 0.0031 - Val accuracy: 0.9856 - Val loss: 0.0459 - Val F1: 0.9856 - LR: 7.00e-05\n",
      "\tEpoch 40/100 - Train loss: 0.0020 - Val accuracy: 0.9862 - Val loss: 0.0548 - Val F1: 0.9862 - LR: 6.00e-05\n",
      "\tEpoch 50/100 - Train loss: 0.0009 - Val accuracy: 0.9856 - Val loss: 0.0588 - Val F1: 0.9856 - LR: 5.00e-05\n",
      "\tEpoch 60/100 - Train loss: 0.0004 - Val accuracy: 0.9874 - Val loss: 0.0569 - Val F1: 0.9875 - LR: 4.00e-05\n",
      "\tEpoch 70/100 - Train loss: 0.0003 - Val accuracy: 0.9874 - Val loss: 0.0570 - Val F1: 0.9874 - LR: 3.00e-05\n",
      "\tEpoch 80/100 - Train loss: 0.0003 - Val accuracy: 0.9881 - Val loss: 0.0563 - Val F1: 0.9881 - LR: 2.00e-05\n",
      "\tEpoch 90/100 - Train loss: 0.0002 - Val accuracy: 0.9874 - Val loss: 0.0593 - Val F1: 0.9874 - LR: 1.00e-05\n",
      "\tEpoch 100/100 - Train loss: 0.0002 - Val accuracy: 0.9874 - Val loss: 0.0587 - Val F1: 0.9874 - LR: 0.00e+00\n",
      "\tBest epoch: 14 - Best val accuracy: 0.9849 - Best val loss: 0.0449 - Best val F1: 0.9849\n",
      "\n",
      "Domain: 15\n",
      "x_dp_dom.shape: (50, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 15 | Accuracy: 0.2400 | Loss: 17.8577 | F1: 0.0929\n",
      "\n",
      "Domain: 16\n",
      "x_dp_dom.shape: (54, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 16 | Accuracy: 0.4815 | Loss: 2.8701 | F1: 0.4846\n",
      "\n",
      "Domain: 17\n",
      "x_dp_dom.shape: (53, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 17 | Accuracy: 0.6415 | Loss: 2.2550 | F1: 0.6207\n",
      "\n",
      "Domain: 18\n",
      "x_dp_dom.shape: (54, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 18 | Accuracy: 0.7407 | Loss: 4.0122 | F1: 0.6696\n",
      "\n",
      "Domain: 19\n",
      "x_dp_dom.shape: (54, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 19 | Accuracy: 0.7407 | Loss: 1.8364 | F1: 0.7118\n",
      "\n",
      "Domain: 20\n",
      "x_dp_dom.shape: (51, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 20 | Accuracy: 0.6667 | Loss: 2.9328 | F1: 0.6322\n",
      "\n",
      "Domain: 21\n",
      "x_dp_dom.shape: (47, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 21 | Accuracy: 0.7021 | Loss: 2.0535 | F1: 0.7083\n",
      "\n",
      "Domain: 22\n",
      "x_dp_dom.shape: (54, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 22 | Accuracy: 0.7037 | Loss: 1.9444 | F1: 0.7163\n",
      "\n",
      "Domain: 23\n",
      "x_dp_dom.shape: (52, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 23 | Accuracy: 0.4231 | Loss: 3.5953 | F1: 0.4111\n",
      "\n",
      "Domain: 24\n",
      "x_dp_dom.shape: (51, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 24 | Accuracy: 0.7451 | Loss: 1.7369 | F1: 0.7519\n",
      "\n",
      "Domain: 25\n",
      "x_dp_dom.shape: (54, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 25 | Accuracy: 0.6667 | Loss: 3.4456 | F1: 0.6282\n",
      "\n",
      "Domain: 26\n",
      "x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 26 | Accuracy: 0.4762 | Loss: 3.7086 | F1: 0.4914\n",
      "\n",
      "Domain: 27\n",
      "x_dp_dom.shape: (54, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 27 | Accuracy: 0.7407 | Loss: 2.1450 | F1: 0.6941\n",
      "\n",
      "Domain: 28\n",
      "x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 28 | Accuracy: 0.9048 | Loss: 0.8309 | F1: 0.8963\n",
      "\n",
      "Domain: 29\n",
      "x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 29 | Accuracy: 0.5476 | Loss: 1.5882 | F1: 0.5617\n",
      "\n",
      "Domain: 30\n",
      "x_dp_dom.shape: (50, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 30 | Accuracy: 0.7600 | Loss: 3.9869 | F1: 0.7699\n",
      "\n",
      "Domain: 31\n",
      "x_dp_dom.shape: (43, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 31 | Accuracy: 0.8140 | Loss: 2.7926 | F1: 0.7918\n",
      "\n",
      "Domain: 32\n",
      "x_dp_dom.shape: (52, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 32 | Accuracy: 0.3846 | Loss: 3.9506 | F1: 0.3911\n",
      "\n",
      "Domain: 33\n",
      "x_dp_dom.shape: (44, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 33 | Accuracy: 0.4545 | Loss: 4.3369 | F1: 0.4624\n",
      "\n",
      "Domain: 34\n",
      "x_dp_dom.shape: (49, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 34 | Accuracy: 0.3673 | Loss: 6.4797 | F1: 0.3430\n",
      "\n",
      "Domain: 35\n",
      "x_dp_dom.shape: (48, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 35 | Accuracy: 0.8125 | Loss: 2.7270 | F1: 0.7688\n",
      "\n",
      "Domain: 36\n",
      "x_dp_dom.shape: (43, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 36 | Accuracy: 0.8372 | Loss: 2.2035 | F1: 0.7806\n",
      "\n",
      "Domain: 37\n",
      "x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 37 | Accuracy: 0.5000 | Loss: 2.4461 | F1: 0.5472\n",
      "\n",
      "Domain: 38\n",
      "x_dp_dom.shape: (47, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 38 | Accuracy: 0.5532 | Loss: 4.4136 | F1: 0.5501\n",
      "\n",
      "Domain: 39\n",
      "x_dp_dom.shape: (54, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 39 | Accuracy: 0.4259 | Loss: 8.1377 | F1: 0.3527\n",
      "\n",
      "Domain: 40\n",
      "x_dp_dom.shape: (44, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 40 | Accuracy: 0.7500 | Loss: 1.5800 | F1: 0.7238\n",
      "\n",
      "Domain: 41\n",
      "x_dp_dom.shape: (45, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 41 | Accuracy: 0.3778 | Loss: 8.7068 | F1: 0.4386\n",
      "\n",
      "Domain: 42\n",
      "x_dp_dom.shape: (46, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 42 | Accuracy: 0.3478 | Loss: 3.0432 | F1: 0.3144\n",
      "\n",
      "Domain: 43\n",
      "x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 43 | Accuracy: 0.5000 | Loss: 10.2135 | F1: 0.5270\n",
      "\n",
      "Domain: 44\n",
      "x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 44 | Accuracy: 0.9048 | Loss: 0.3342 | F1: 0.9029\n",
      "\n",
      "Domain: 45\n",
      "x_dp_dom.shape: (52, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 45 | Accuracy: 0.7115 | Loss: 2.5206 | F1: 0.6556\n",
      "\n",
      "Domain: 46\n",
      "x_dp_dom.shape: (48, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 46 | Accuracy: 0.7292 | Loss: 2.2086 | F1: 0.7267\n",
      "\n",
      "Domain: 47\n",
      "x_dp_dom.shape: (44, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 47 | Accuracy: 0.3636 | Loss: 4.0496 | F1: 0.3768\n",
      "\n",
      "Domain: 48\n",
      "x_dp_dom.shape: (48, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 48 | Accuracy: 0.3750 | Loss: 4.8489 | F1: 0.3041\n",
      "\n",
      "Domain: 49\n",
      "x_dp_dom.shape: (53, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 49 | Accuracy: 0.6226 | Loss: 3.4192 | F1: 0.5958\n",
      "\n",
      "Domain: 50\n",
      "x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 50 | Accuracy: 0.9762 | Loss: 0.1072 | F1: 0.9768\n",
      "\n",
      "Domain: 51\n",
      "x_dp_dom.shape: (46, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 51 | Accuracy: 0.7826 | Loss: 3.2334 | F1: 0.7542\n",
      "\n",
      "Domain: 52\n",
      "x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 52 | Accuracy: 0.7857 | Loss: 1.8263 | F1: 0.7480\n",
      "\n",
      "Domain: 53\n",
      "x_dp_dom.shape: (48, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 53 | Accuracy: 0.8333 | Loss: 1.0211 | F1: 0.8179\n",
      "\n",
      "Domain: 54\n",
      "x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 54 | Accuracy: 0.8333 | Loss: 1.2914 | F1: 0.7716\n",
      "\n",
      "Domain: 55\n",
      "x_dp_dom.shape: (49, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 55 | Accuracy: 0.7959 | Loss: 2.2051 | F1: 0.7531\n",
      "\n",
      "Domain: 56\n",
      "x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 56 | Accuracy: 0.2143 | Loss: 6.9747 | F1: 0.1506\n",
      "\n",
      "Domain: 57\n",
      "x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 57 | Accuracy: 0.8095 | Loss: 0.6561 | F1: 0.8181\n",
      "\n",
      "Domain: 58\n",
      "x_dp_dom.shape: (38, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 58 | Accuracy: 0.8421 | Loss: 1.2057 | F1: 0.7934\n",
      "\n",
      "Domain: 59\n",
      "x_dp_dom.shape: (43, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 59 | Accuracy: 0.3488 | Loss: 5.3605 | F1: 0.2984\n",
      "\n",
      "Domain: 60\n",
      "x_dp_dom.shape: (47, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 60 | Accuracy: 0.3617 | Loss: 13.0290 | F1: 0.3132\n",
      "\n",
      "Domain: 61\n",
      "x_dp_dom.shape: (47, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 61 | Accuracy: 0.5957 | Loss: 2.7718 | F1: 0.6380\n",
      "\n",
      "Domain: 62\n",
      "x_dp_dom.shape: (47, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 62 | Accuracy: 0.8298 | Loss: 2.6954 | F1: 0.7826\n",
      "\n",
      "Domain: 63\n",
      "x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 63 | Accuracy: 0.7381 | Loss: 1.0155 | F1: 0.7599\n",
      "\n",
      "Domain: 64\n",
      "x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 64 | Accuracy: 0.8333 | Loss: 2.8314 | F1: 0.7778\n",
      "\n",
      "Domain: 65\n",
      "x_dp_dom.shape: (50, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 65 | Accuracy: 0.2800 | Loss: 7.1217 | F1: 0.1477\n",
      "\n",
      "Domain: 66\n",
      "x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 66 | Accuracy: 0.1905 | Loss: 14.3647 | F1: 0.0946\n",
      "\n",
      "Domain: 67\n",
      "x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 67 | Accuracy: 0.8571 | Loss: 0.7982 | F1: 0.8097\n",
      "\n",
      "Domain: 68\n",
      "x_dp_dom.shape: (43, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 68 | Accuracy: 0.2791 | Loss: 3.1045 | F1: 0.3167\n",
      "\n",
      "Domain: 69\n",
      "x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 69 | Accuracy: 0.3095 | Loss: 4.7280 | F1: 0.2644\n",
      "\n",
      "Domain: 70\n",
      "x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 70 | Accuracy: 0.7381 | Loss: 2.5518 | F1: 0.7643\n",
      "\n",
      "Domain: 71\n",
      "x_dp_dom.shape: (44, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 71 | Accuracy: 0.5682 | Loss: 2.2544 | F1: 0.5816\n",
      "\n",
      "Domain: 72\n",
      "x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 72 | Accuracy: 0.1905 | Loss: 6.1045 | F1: 0.1259\n",
      "\n",
      "Domain: 73\n",
      "x_dp_dom.shape: (41, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 73 | Accuracy: 0.5610 | Loss: 7.7734 | F1: 0.5714\n",
      "\n",
      "Domain: 74\n",
      "x_dp_dom.shape: (35, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 74 | Accuracy: 0.7143 | Loss: 3.0601 | F1: 0.7450\n",
      "\n",
      "Domain: 75\n",
      "x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 75 | Accuracy: 0.7143 | Loss: 1.8345 | F1: 0.6985\n",
      "\n",
      "Mean accuracy for run 4: 0.6065\n",
      "Mean F1 for run 4: 0.5847\n",
      "\n",
      "Source class: WAL\n",
      "\n",
      "x_df.shape: (7958, 3, 128) | np.unique(y_df): [1 2 3]\n",
      "\n",
      "Training on Df data...\n",
      "\tEpoch 10/100 - Train loss: 0.0324 - Val accuracy: 0.9793 - Val loss: 0.0556 - Val F1: 0.9793 - LR: 9.00e-05\n",
      "\tEpoch 20/100 - Train loss: 0.0110 - Val accuracy: 0.9830 - Val loss: 0.0500 - Val F1: 0.9830 - LR: 8.00e-05\n",
      "\tEpoch 30/100 - Train loss: 0.0046 - Val accuracy: 0.9830 - Val loss: 0.0465 - Val F1: 0.9830 - LR: 7.00e-05\n",
      "\tEpoch 40/100 - Train loss: 0.0011 - Val accuracy: 0.9843 - Val loss: 0.0499 - Val F1: 0.9843 - LR: 6.00e-05\n",
      "\tEpoch 50/100 - Train loss: 0.0009 - Val accuracy: 0.9843 - Val loss: 0.0544 - Val F1: 0.9843 - LR: 5.00e-05\n",
      "\tEpoch 60/100 - Train loss: 0.0010 - Val accuracy: 0.9874 - Val loss: 0.0532 - Val F1: 0.9874 - LR: 4.00e-05\n",
      "\tEpoch 70/100 - Train loss: 0.0004 - Val accuracy: 0.9856 - Val loss: 0.0514 - Val F1: 0.9856 - LR: 3.00e-05\n",
      "\tEpoch 80/100 - Train loss: 0.0007 - Val accuracy: 0.9874 - Val loss: 0.0565 - Val F1: 0.9874 - LR: 2.00e-05\n",
      "\tEpoch 90/100 - Train loss: 0.0002 - Val accuracy: 0.9849 - Val loss: 0.0616 - Val F1: 0.9849 - LR: 1.00e-05\n",
      "\tEpoch 100/100 - Train loss: 0.0001 - Val accuracy: 0.9856 - Val loss: 0.0557 - Val F1: 0.9856 - LR: 0.00e+00\n",
      "\tBest epoch: 21 - Best val accuracy: 0.9843 - Best val loss: 0.0426 - Best val F1: 0.9843\n",
      "\n",
      "Domain: 15\n",
      "x_dp_dom.shape: (50, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 15 | Accuracy: 0.7800 | Loss: 2.9889 | F1: 0.7200\n",
      "\n",
      "Domain: 16\n",
      "x_dp_dom.shape: (54, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 16 | Accuracy: 0.7222 | Loss: 1.4953 | F1: 0.7214\n",
      "\n",
      "Domain: 17\n",
      "x_dp_dom.shape: (53, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 17 | Accuracy: 0.7170 | Loss: 3.0184 | F1: 0.6662\n",
      "\n",
      "Domain: 18\n",
      "x_dp_dom.shape: (54, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 18 | Accuracy: 0.7407 | Loss: 4.1464 | F1: 0.6696\n",
      "\n",
      "Domain: 19\n",
      "x_dp_dom.shape: (54, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 19 | Accuracy: 0.7407 | Loss: 2.3621 | F1: 0.6941\n",
      "\n",
      "Domain: 20\n",
      "x_dp_dom.shape: (51, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 20 | Accuracy: 0.6863 | Loss: 3.0404 | F1: 0.6596\n",
      "\n",
      "Domain: 21\n",
      "x_dp_dom.shape: (47, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 21 | Accuracy: 0.7872 | Loss: 2.4627 | F1: 0.7597\n",
      "\n",
      "Domain: 22\n",
      "x_dp_dom.shape: (54, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 22 | Accuracy: 0.8519 | Loss: 0.5370 | F1: 0.8377\n",
      "\n",
      "Domain: 23\n",
      "x_dp_dom.shape: (52, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 23 | Accuracy: 0.8077 | Loss: 1.4057 | F1: 0.7999\n",
      "\n",
      "Domain: 24\n",
      "x_dp_dom.shape: (51, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 24 | Accuracy: 0.4902 | Loss: 2.8281 | F1: 0.4525\n",
      "\n",
      "Domain: 25\n",
      "x_dp_dom.shape: (54, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 25 | Accuracy: 0.7593 | Loss: 3.1027 | F1: 0.6790\n",
      "\n",
      "Domain: 26\n",
      "x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 26 | Accuracy: 0.5238 | Loss: 3.4898 | F1: 0.5763\n",
      "\n",
      "Domain: 27\n",
      "x_dp_dom.shape: (54, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 27 | Accuracy: 0.7778 | Loss: 2.6806 | F1: 0.7176\n",
      "\n",
      "Domain: 28\n",
      "x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 28 | Accuracy: 0.8571 | Loss: 1.2474 | F1: 0.8250\n",
      "\n",
      "Domain: 29\n",
      "x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 29 | Accuracy: 0.9048 | Loss: 0.3118 | F1: 0.9117\n",
      "\n",
      "Domain: 30\n",
      "x_dp_dom.shape: (50, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 30 | Accuracy: 0.7400 | Loss: 1.9589 | F1: 0.7126\n",
      "\n",
      "Domain: 31\n",
      "x_dp_dom.shape: (43, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 31 | Accuracy: 0.8837 | Loss: 1.2016 | F1: 0.8787\n",
      "\n",
      "Domain: 32\n",
      "x_dp_dom.shape: (52, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 32 | Accuracy: 0.4808 | Loss: 2.7359 | F1: 0.4988\n",
      "\n",
      "Domain: 33\n",
      "x_dp_dom.shape: (44, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 33 | Accuracy: 0.8182 | Loss: 1.4804 | F1: 0.8128\n",
      "\n",
      "Domain: 34\n",
      "x_dp_dom.shape: (49, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 34 | Accuracy: 0.6531 | Loss: 2.8334 | F1: 0.6404\n",
      "\n",
      "Domain: 35\n",
      "x_dp_dom.shape: (48, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 35 | Accuracy: 0.7917 | Loss: 3.1533 | F1: 0.7459\n",
      "\n",
      "Domain: 36\n",
      "x_dp_dom.shape: (43, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 36 | Accuracy: 0.7907 | Loss: 2.4978 | F1: 0.7565\n",
      "\n",
      "Domain: 37\n",
      "x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 37 | Accuracy: 0.6429 | Loss: 2.7200 | F1: 0.6963\n",
      "\n",
      "Domain: 38\n",
      "x_dp_dom.shape: (47, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 38 | Accuracy: 0.5532 | Loss: 2.2082 | F1: 0.6167\n",
      "\n",
      "Domain: 39\n",
      "x_dp_dom.shape: (54, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 39 | Accuracy: 0.7037 | Loss: 0.9234 | F1: 0.7231\n",
      "\n",
      "Domain: 40\n",
      "x_dp_dom.shape: (44, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 40 | Accuracy: 0.8409 | Loss: 0.7498 | F1: 0.8415\n",
      "\n",
      "Domain: 41\n",
      "x_dp_dom.shape: (45, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 41 | Accuracy: 0.1111 | Loss: 9.9648 | F1: 0.1389\n",
      "\n",
      "Domain: 42\n",
      "x_dp_dom.shape: (46, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 42 | Accuracy: 0.8261 | Loss: 0.7744 | F1: 0.8439\n",
      "\n",
      "Domain: 43\n",
      "x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 43 | Accuracy: 0.5952 | Loss: 2.4251 | F1: 0.5952\n",
      "\n",
      "Domain: 44\n",
      "x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 44 | Accuracy: 0.8810 | Loss: 0.4441 | F1: 0.8821\n",
      "\n",
      "Domain: 45\n",
      "x_dp_dom.shape: (52, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 45 | Accuracy: 0.7692 | Loss: 3.0152 | F1: 0.6997\n",
      "\n",
      "Domain: 46\n",
      "x_dp_dom.shape: (48, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 46 | Accuracy: 0.8542 | Loss: 1.4360 | F1: 0.7967\n",
      "\n",
      "Domain: 47\n",
      "x_dp_dom.shape: (44, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 47 | Accuracy: 0.4318 | Loss: 3.1259 | F1: 0.5006\n",
      "\n",
      "Domain: 48\n",
      "x_dp_dom.shape: (48, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 48 | Accuracy: 0.5833 | Loss: 2.8850 | F1: 0.6232\n",
      "\n",
      "Domain: 49\n",
      "x_dp_dom.shape: (53, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 49 | Accuracy: 0.7547 | Loss: 3.2397 | F1: 0.6822\n",
      "\n",
      "Domain: 50\n",
      "x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 50 | Accuracy: 0.9048 | Loss: 0.3198 | F1: 0.9105\n",
      "\n",
      "Domain: 51\n",
      "x_dp_dom.shape: (46, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 51 | Accuracy: 0.7174 | Loss: 2.2132 | F1: 0.6921\n",
      "\n",
      "Domain: 52\n",
      "x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 52 | Accuracy: 0.8333 | Loss: 2.0454 | F1: 0.7778\n",
      "\n",
      "Domain: 53\n",
      "x_dp_dom.shape: (48, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 53 | Accuracy: 0.7708 | Loss: 1.9051 | F1: 0.7591\n",
      "\n",
      "Domain: 54\n",
      "x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 54 | Accuracy: 0.9286 | Loss: 0.2717 | F1: 0.9220\n",
      "\n",
      "Domain: 55\n",
      "x_dp_dom.shape: (49, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 55 | Accuracy: 0.7959 | Loss: 2.5085 | F1: 0.7419\n",
      "\n",
      "Domain: 56\n",
      "x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 56 | Accuracy: 0.2143 | Loss: 6.1764 | F1: 0.2302\n",
      "\n",
      "Domain: 57\n",
      "x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 57 | Accuracy: 0.9048 | Loss: 0.4278 | F1: 0.8973\n",
      "\n",
      "Domain: 58\n",
      "x_dp_dom.shape: (38, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 58 | Accuracy: 0.9211 | Loss: 0.2305 | F1: 0.9132\n",
      "\n",
      "Domain: 59\n",
      "x_dp_dom.shape: (43, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 59 | Accuracy: 0.1163 | Loss: 10.9785 | F1: 0.0842\n",
      "\n",
      "Domain: 60\n",
      "x_dp_dom.shape: (47, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 60 | Accuracy: 0.7660 | Loss: 2.2863 | F1: 0.7001\n",
      "\n",
      "Domain: 61\n",
      "x_dp_dom.shape: (47, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 61 | Accuracy: 0.6596 | Loss: 1.6383 | F1: 0.7011\n",
      "\n",
      "Domain: 62\n",
      "x_dp_dom.shape: (47, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 62 | Accuracy: 0.8511 | Loss: 2.5379 | F1: 0.7934\n",
      "\n",
      "Domain: 63\n",
      "x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 63 | Accuracy: 0.7143 | Loss: 1.5231 | F1: 0.7234\n",
      "\n",
      "Domain: 64\n",
      "x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 64 | Accuracy: 0.8095 | Loss: 2.9351 | F1: 0.7657\n",
      "\n",
      "Domain: 65\n",
      "x_dp_dom.shape: (50, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 65 | Accuracy: 0.9000 | Loss: 0.5374 | F1: 0.8918\n",
      "\n",
      "Domain: 66\n",
      "x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 66 | Accuracy: 0.6667 | Loss: 3.3851 | F1: 0.5744\n",
      "\n",
      "Domain: 67\n",
      "x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 67 | Accuracy: 0.8810 | Loss: 0.2826 | F1: 0.8709\n",
      "\n",
      "Domain: 68\n",
      "x_dp_dom.shape: (43, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 68 | Accuracy: 0.2326 | Loss: 6.1485 | F1: 0.2105\n",
      "\n",
      "Domain: 69\n",
      "x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 69 | Accuracy: 0.9286 | Loss: 0.2852 | F1: 0.9251\n",
      "\n",
      "Domain: 70\n",
      "x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 70 | Accuracy: 0.8095 | Loss: 1.2929 | F1: 0.8062\n",
      "\n",
      "Domain: 71\n",
      "x_dp_dom.shape: (44, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 71 | Accuracy: 0.5682 | Loss: 1.9886 | F1: 0.5986\n",
      "\n",
      "Domain: 72\n",
      "x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 72 | Accuracy: 0.2857 | Loss: 4.3688 | F1: 0.3383\n",
      "\n",
      "Domain: 73\n",
      "x_dp_dom.shape: (41, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 73 | Accuracy: 0.7073 | Loss: 2.1371 | F1: 0.6136\n",
      "\n",
      "Domain: 74\n",
      "x_dp_dom.shape: (35, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 74 | Accuracy: 0.8286 | Loss: 1.3956 | F1: 0.7950\n",
      "\n",
      "Domain: 75\n",
      "x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 75 | Accuracy: 0.8333 | Loss: 2.0744 | F1: 0.7778\n",
      "\n",
      "Mean accuracy for run 5: 0.7115\n",
      "Mean F1 for run 5: 0.6949\n",
      "\n",
      "Source class: WAL\n",
      "\n",
      "x_df.shape: (7958, 3, 128) | np.unique(y_df): [1 2 3]\n",
      "\n",
      "Training on Df data...\n",
      "\tEpoch 10/100 - Train loss: 0.0341 - Val accuracy: 0.9755 - Val loss: 0.0597 - Val F1: 0.9754 - LR: 9.00e-05\n",
      "\tEpoch 20/100 - Train loss: 0.0113 - Val accuracy: 0.9818 - Val loss: 0.0505 - Val F1: 0.9818 - LR: 8.00e-05\n",
      "\tEpoch 30/100 - Train loss: 0.0038 - Val accuracy: 0.9843 - Val loss: 0.0462 - Val F1: 0.9843 - LR: 7.00e-05\n",
      "\tEpoch 40/100 - Train loss: 0.0015 - Val accuracy: 0.9824 - Val loss: 0.0558 - Val F1: 0.9824 - LR: 6.00e-05\n",
      "\tEpoch 50/100 - Train loss: 0.0009 - Val accuracy: 0.9843 - Val loss: 0.0551 - Val F1: 0.9843 - LR: 5.00e-05\n",
      "\tEpoch 60/100 - Train loss: 0.0019 - Val accuracy: 0.9856 - Val loss: 0.0570 - Val F1: 0.9856 - LR: 4.00e-05\n",
      "\tEpoch 70/100 - Train loss: 0.0007 - Val accuracy: 0.9830 - Val loss: 0.0685 - Val F1: 0.9830 - LR: 3.00e-05\n",
      "\tEpoch 80/100 - Train loss: 0.0003 - Val accuracy: 0.9849 - Val loss: 0.0571 - Val F1: 0.9849 - LR: 2.00e-05\n",
      "\tEpoch 90/100 - Train loss: 0.0002 - Val accuracy: 0.9849 - Val loss: 0.0600 - Val F1: 0.9849 - LR: 1.00e-05\n",
      "\tEpoch 100/100 - Train loss: 0.0002 - Val accuracy: 0.9843 - Val loss: 0.0633 - Val F1: 0.9843 - LR: 0.00e+00\n",
      "\tBest epoch: 16 - Best val accuracy: 0.9837 - Best val loss: 0.0448 - Best val F1: 0.9837\n",
      "\n",
      "Domain: 15\n",
      "x_dp_dom.shape: (50, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 15 | Accuracy: 0.6400 | Loss: 6.2208 | F1: 0.6191\n",
      "\n",
      "Domain: 16\n",
      "x_dp_dom.shape: (54, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 16 | Accuracy: 0.4074 | Loss: 3.2609 | F1: 0.3794\n",
      "\n",
      "Domain: 17\n",
      "x_dp_dom.shape: (53, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 17 | Accuracy: 0.7170 | Loss: 2.8477 | F1: 0.6662\n",
      "\n",
      "Domain: 18\n",
      "x_dp_dom.shape: (54, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 18 | Accuracy: 0.2593 | Loss: 7.1002 | F1: 0.1762\n",
      "\n",
      "Domain: 19\n",
      "x_dp_dom.shape: (54, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 19 | Accuracy: 0.7407 | Loss: 2.0515 | F1: 0.6696\n",
      "\n",
      "Domain: 20\n",
      "x_dp_dom.shape: (51, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 20 | Accuracy: 0.6078 | Loss: 3.3120 | F1: 0.6124\n",
      "\n",
      "Domain: 21\n",
      "x_dp_dom.shape: (47, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 21 | Accuracy: 0.7021 | Loss: 1.9167 | F1: 0.7193\n",
      "\n",
      "Domain: 22\n",
      "x_dp_dom.shape: (54, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 22 | Accuracy: 0.7778 | Loss: 0.9708 | F1: 0.7889\n",
      "\n",
      "Domain: 23\n",
      "x_dp_dom.shape: (52, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 23 | Accuracy: 0.8077 | Loss: 1.3827 | F1: 0.8122\n",
      "\n",
      "Domain: 24\n",
      "x_dp_dom.shape: (51, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 24 | Accuracy: 0.3137 | Loss: 4.4585 | F1: 0.2527\n",
      "\n",
      "Domain: 25\n",
      "x_dp_dom.shape: (54, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 25 | Accuracy: 0.4259 | Loss: 5.2830 | F1: 0.4334\n",
      "\n",
      "Domain: 26\n",
      "x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 26 | Accuracy: 0.5000 | Loss: 3.1984 | F1: 0.5341\n",
      "\n",
      "Domain: 27\n",
      "x_dp_dom.shape: (54, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 27 | Accuracy: 0.4259 | Loss: 3.2927 | F1: 0.4471\n",
      "\n",
      "Domain: 28\n",
      "x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 28 | Accuracy: 0.7143 | Loss: 2.1074 | F1: 0.7304\n",
      "\n",
      "Domain: 29\n",
      "x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 29 | Accuracy: 0.7381 | Loss: 0.8223 | F1: 0.7637\n",
      "\n",
      "Domain: 30\n",
      "x_dp_dom.shape: (50, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 30 | Accuracy: 0.6400 | Loss: 2.5060 | F1: 0.6493\n",
      "\n",
      "Domain: 31\n",
      "x_dp_dom.shape: (43, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 31 | Accuracy: 0.7209 | Loss: 2.3713 | F1: 0.7316\n",
      "\n",
      "Domain: 32\n",
      "x_dp_dom.shape: (52, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 32 | Accuracy: 0.4615 | Loss: 4.6678 | F1: 0.4748\n",
      "\n",
      "Domain: 33\n",
      "x_dp_dom.shape: (44, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 33 | Accuracy: 0.6591 | Loss: 1.5621 | F1: 0.6945\n",
      "\n",
      "Domain: 34\n",
      "x_dp_dom.shape: (49, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 34 | Accuracy: 0.7143 | Loss: 1.6881 | F1: 0.7361\n",
      "\n",
      "Domain: 35\n",
      "x_dp_dom.shape: (48, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 35 | Accuracy: 0.3333 | Loss: 5.2782 | F1: 0.3263\n",
      "\n",
      "Domain: 36\n",
      "x_dp_dom.shape: (43, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 36 | Accuracy: 0.5116 | Loss: 3.9762 | F1: 0.5635\n",
      "\n",
      "Domain: 37\n",
      "x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 37 | Accuracy: 0.4762 | Loss: 5.1680 | F1: 0.4961\n",
      "\n",
      "Domain: 38\n",
      "x_dp_dom.shape: (47, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 38 | Accuracy: 0.4681 | Loss: 3.9494 | F1: 0.4890\n",
      "\n",
      "Domain: 39\n",
      "x_dp_dom.shape: (54, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 39 | Accuracy: 0.6111 | Loss: 3.8605 | F1: 0.6096\n",
      "\n",
      "Domain: 40\n",
      "x_dp_dom.shape: (44, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 40 | Accuracy: 0.6364 | Loss: 2.7456 | F1: 0.6662\n",
      "\n",
      "Domain: 41\n",
      "x_dp_dom.shape: (45, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 41 | Accuracy: 0.1778 | Loss: 10.6774 | F1: 0.1452\n",
      "\n",
      "Domain: 42\n",
      "x_dp_dom.shape: (46, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 42 | Accuracy: 0.7174 | Loss: 1.1302 | F1: 0.7544\n",
      "\n",
      "Domain: 43\n",
      "x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 43 | Accuracy: 0.3810 | Loss: 4.7157 | F1: 0.4195\n",
      "\n",
      "Domain: 44\n",
      "x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 44 | Accuracy: 0.9048 | Loss: 0.1915 | F1: 0.9069\n",
      "\n",
      "Domain: 45\n",
      "x_dp_dom.shape: (52, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 45 | Accuracy: 0.7115 | Loss: 3.3041 | F1: 0.6727\n",
      "\n",
      "Domain: 46\n",
      "x_dp_dom.shape: (48, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 46 | Accuracy: 0.5417 | Loss: 3.0130 | F1: 0.5833\n",
      "\n",
      "Domain: 47\n",
      "x_dp_dom.shape: (44, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 47 | Accuracy: 0.2727 | Loss: 5.4672 | F1: 0.2216\n",
      "\n",
      "Domain: 48\n",
      "x_dp_dom.shape: (48, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 48 | Accuracy: 0.3125 | Loss: 6.2229 | F1: 0.2362\n",
      "\n",
      "Domain: 49\n",
      "x_dp_dom.shape: (53, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 49 | Accuracy: 0.4906 | Loss: 4.5631 | F1: 0.4906\n",
      "\n",
      "Domain: 50\n",
      "x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 50 | Accuracy: 0.8810 | Loss: 0.9522 | F1: 0.8886\n",
      "\n",
      "Domain: 51\n",
      "x_dp_dom.shape: (46, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 51 | Accuracy: 0.6957 | Loss: 2.1567 | F1: 0.7242\n",
      "\n",
      "Domain: 52\n",
      "x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 52 | Accuracy: 0.7857 | Loss: 2.6951 | F1: 0.7480\n",
      "\n",
      "Domain: 53\n",
      "x_dp_dom.shape: (48, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 53 | Accuracy: 0.4583 | Loss: 1.9433 | F1: 0.5085\n",
      "\n",
      "Domain: 54\n",
      "x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 54 | Accuracy: 0.9048 | Loss: 0.5146 | F1: 0.8998\n",
      "\n",
      "Domain: 55\n",
      "x_dp_dom.shape: (49, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 55 | Accuracy: 0.7143 | Loss: 3.2974 | F1: 0.7057\n",
      "\n",
      "Domain: 56\n",
      "x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 56 | Accuracy: 0.1667 | Loss: 7.9938 | F1: 0.0796\n",
      "\n",
      "Domain: 57\n",
      "x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 57 | Accuracy: 0.5476 | Loss: 1.7902 | F1: 0.5945\n",
      "\n",
      "Domain: 58\n",
      "x_dp_dom.shape: (38, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 58 | Accuracy: 0.9211 | Loss: 0.6889 | F1: 0.9203\n",
      "\n",
      "Domain: 59\n",
      "x_dp_dom.shape: (43, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 59 | Accuracy: 0.2791 | Loss: 7.2871 | F1: 0.1943\n",
      "\n",
      "Domain: 60\n",
      "x_dp_dom.shape: (47, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 60 | Accuracy: 0.4894 | Loss: 5.0736 | F1: 0.4800\n",
      "\n",
      "Domain: 61\n",
      "x_dp_dom.shape: (47, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 61 | Accuracy: 0.3830 | Loss: 4.2569 | F1: 0.3637\n",
      "\n",
      "Domain: 62\n",
      "x_dp_dom.shape: (47, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 62 | Accuracy: 0.7234 | Loss: 2.8682 | F1: 0.7219\n",
      "\n",
      "Domain: 63\n",
      "x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 63 | Accuracy: 0.4048 | Loss: 2.5707 | F1: 0.4462\n",
      "\n",
      "Domain: 64\n",
      "x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 64 | Accuracy: 0.3571 | Loss: 3.6127 | F1: 0.4074\n",
      "\n",
      "Domain: 65\n",
      "x_dp_dom.shape: (50, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 65 | Accuracy: 0.8000 | Loss: 1.6360 | F1: 0.7688\n",
      "\n",
      "Domain: 66\n",
      "x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 66 | Accuracy: 0.6905 | Loss: 3.4017 | F1: 0.6574\n",
      "\n",
      "Domain: 67\n",
      "x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 67 | Accuracy: 0.8571 | Loss: 0.5251 | F1: 0.8549\n",
      "\n",
      "Domain: 68\n",
      "x_dp_dom.shape: (43, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 68 | Accuracy: 0.2093 | Loss: 10.4045 | F1: 0.1433\n",
      "\n",
      "Domain: 69\n",
      "x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 69 | Accuracy: 0.8810 | Loss: 0.4562 | F1: 0.8635\n",
      "\n",
      "Domain: 70\n",
      "x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 70 | Accuracy: 0.4762 | Loss: 2.1815 | F1: 0.5335\n",
      "\n",
      "Domain: 71\n",
      "x_dp_dom.shape: (44, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 71 | Accuracy: 0.6818 | Loss: 0.9481 | F1: 0.7132\n",
      "\n",
      "Domain: 72\n",
      "x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 72 | Accuracy: 0.2143 | Loss: 7.6537 | F1: 0.1408\n",
      "\n",
      "Domain: 73\n",
      "x_dp_dom.shape: (41, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 73 | Accuracy: 0.8537 | Loss: 2.6616 | F1: 0.8024\n",
      "\n",
      "Domain: 74\n",
      "x_dp_dom.shape: (35, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 74 | Accuracy: 0.6571 | Loss: 4.5435 | F1: 0.6691\n",
      "\n",
      "Domain: 75\n",
      "x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 75 | Accuracy: 0.6905 | Loss: 3.0156 | F1: 0.6978\n",
      "\n",
      "Mean accuracy for run 6: 0.5778\n",
      "Mean F1 for run 6: 0.5738\n",
      "\n",
      "Source class: WAL\n",
      "\n",
      "x_df.shape: (7958, 3, 128) | np.unique(y_df): [1 2 3]\n",
      "\n",
      "Training on Df data...\n",
      "\tEpoch 10/100 - Train loss: 0.0392 - Val accuracy: 0.9786 - Val loss: 0.0636 - Val F1: 0.9786 - LR: 9.00e-05\n",
      "\tEpoch 20/100 - Train loss: 0.0100 - Val accuracy: 0.9799 - Val loss: 0.0610 - Val F1: 0.9799 - LR: 8.00e-05\n",
      "\tEpoch 30/100 - Train loss: 0.0036 - Val accuracy: 0.9805 - Val loss: 0.0656 - Val F1: 0.9805 - LR: 7.00e-05\n",
      "\tEpoch 40/100 - Train loss: 0.0025 - Val accuracy: 0.9818 - Val loss: 0.0649 - Val F1: 0.9818 - LR: 6.00e-05\n",
      "\tEpoch 50/100 - Train loss: 0.0010 - Val accuracy: 0.9818 - Val loss: 0.0710 - Val F1: 0.9818 - LR: 5.00e-05\n",
      "\tEpoch 60/100 - Train loss: 0.0015 - Val accuracy: 0.9799 - Val loss: 0.0739 - Val F1: 0.9799 - LR: 4.00e-05\n",
      "\tEpoch 70/100 - Train loss: 0.0004 - Val accuracy: 0.9818 - Val loss: 0.0752 - Val F1: 0.9818 - LR: 3.00e-05\n",
      "\tEpoch 80/100 - Train loss: 0.0003 - Val accuracy: 0.9824 - Val loss: 0.0791 - Val F1: 0.9824 - LR: 2.00e-05\n",
      "\tEpoch 90/100 - Train loss: 0.0002 - Val accuracy: 0.9818 - Val loss: 0.0812 - Val F1: 0.9818 - LR: 1.00e-05\n",
      "\tEpoch 100/100 - Train loss: 0.0002 - Val accuracy: 0.9812 - Val loss: 0.0830 - Val F1: 0.9812 - LR: 0.00e+00\n",
      "\tBest epoch: 15 - Best val accuracy: 0.9805 - Best val loss: 0.0550 - Best val F1: 0.9805\n",
      "\n",
      "Domain: 15\n",
      "x_dp_dom.shape: (50, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 15 | Accuracy: 0.7600 | Loss: 3.5476 | F1: 0.7100\n",
      "\n",
      "Domain: 16\n",
      "x_dp_dom.shape: (54, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 16 | Accuracy: 0.6481 | Loss: 2.5620 | F1: 0.6290\n",
      "\n",
      "Domain: 17\n",
      "x_dp_dom.shape: (53, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 17 | Accuracy: 0.6226 | Loss: 3.2747 | F1: 0.6081\n",
      "\n",
      "Domain: 18\n",
      "x_dp_dom.shape: (54, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 18 | Accuracy: 0.7222 | Loss: 3.1921 | F1: 0.6558\n",
      "\n",
      "Domain: 19\n",
      "x_dp_dom.shape: (54, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 19 | Accuracy: 0.7407 | Loss: 2.5776 | F1: 0.6696\n",
      "\n",
      "Domain: 20\n",
      "x_dp_dom.shape: (51, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 20 | Accuracy: 0.7843 | Loss: 2.5332 | F1: 0.7182\n",
      "\n",
      "Domain: 21\n",
      "x_dp_dom.shape: (47, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 21 | Accuracy: 0.8298 | Loss: 2.2039 | F1: 0.7826\n",
      "\n",
      "Domain: 22\n",
      "x_dp_dom.shape: (54, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 22 | Accuracy: 0.8519 | Loss: 0.6057 | F1: 0.8559\n",
      "\n",
      "Domain: 23\n",
      "x_dp_dom.shape: (52, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 23 | Accuracy: 0.8462 | Loss: 0.9377 | F1: 0.8392\n",
      "\n",
      "Domain: 24\n",
      "x_dp_dom.shape: (51, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 24 | Accuracy: 0.7451 | Loss: 1.2942 | F1: 0.7538\n",
      "\n",
      "Domain: 25\n",
      "x_dp_dom.shape: (54, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 25 | Accuracy: 0.7222 | Loss: 3.7540 | F1: 0.6598\n",
      "\n",
      "Domain: 26\n",
      "x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 26 | Accuracy: 0.5238 | Loss: 3.4021 | F1: 0.5762\n",
      "\n",
      "Domain: 27\n",
      "x_dp_dom.shape: (54, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 27 | Accuracy: 0.5370 | Loss: 3.4677 | F1: 0.5376\n",
      "\n",
      "Domain: 28\n",
      "x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 28 | Accuracy: 0.4048 | Loss: 4.5900 | F1: 0.4620\n",
      "\n",
      "Domain: 29\n",
      "x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 29 | Accuracy: 0.6429 | Loss: 1.3570 | F1: 0.6676\n",
      "\n",
      "Domain: 30\n",
      "x_dp_dom.shape: (50, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 30 | Accuracy: 0.7400 | Loss: 1.3729 | F1: 0.7379\n",
      "\n",
      "Domain: 31\n",
      "x_dp_dom.shape: (43, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 31 | Accuracy: 0.8837 | Loss: 1.2920 | F1: 0.8653\n",
      "\n",
      "Domain: 32\n",
      "x_dp_dom.shape: (52, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 32 | Accuracy: 0.4038 | Loss: 5.2326 | F1: 0.3999\n",
      "\n",
      "Domain: 33\n",
      "x_dp_dom.shape: (44, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 33 | Accuracy: 0.8182 | Loss: 1.8007 | F1: 0.7664\n",
      "\n",
      "Domain: 34\n",
      "x_dp_dom.shape: (49, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 34 | Accuracy: 0.6735 | Loss: 2.3827 | F1: 0.6932\n",
      "\n",
      "Domain: 35\n",
      "x_dp_dom.shape: (48, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 35 | Accuracy: 0.8125 | Loss: 2.4241 | F1: 0.7751\n",
      "\n",
      "Domain: 36\n",
      "x_dp_dom.shape: (43, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 36 | Accuracy: 0.6744 | Loss: 3.3141 | F1: 0.6608\n",
      "\n",
      "Domain: 37\n",
      "x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 37 | Accuracy: 0.6190 | Loss: 2.1510 | F1: 0.6709\n",
      "\n",
      "Domain: 38\n",
      "x_dp_dom.shape: (47, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 38 | Accuracy: 0.6170 | Loss: 2.1354 | F1: 0.6401\n",
      "\n",
      "Domain: 39\n",
      "x_dp_dom.shape: (54, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 39 | Accuracy: 0.7222 | Loss: 1.2503 | F1: 0.7253\n",
      "\n",
      "Domain: 40\n",
      "x_dp_dom.shape: (44, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 40 | Accuracy: 0.6591 | Loss: 1.4329 | F1: 0.7060\n",
      "\n",
      "Domain: 41\n",
      "x_dp_dom.shape: (45, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 41 | Accuracy: 0.2444 | Loss: 7.1456 | F1: 0.2572\n",
      "\n",
      "Domain: 42\n",
      "x_dp_dom.shape: (46, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 42 | Accuracy: 0.2826 | Loss: 4.0263 | F1: 0.2448\n",
      "\n",
      "Domain: 43\n",
      "x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 43 | Accuracy: 0.8333 | Loss: 1.7492 | F1: 0.8027\n",
      "\n",
      "Domain: 44\n",
      "x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 44 | Accuracy: 0.9286 | Loss: 0.4690 | F1: 0.9251\n",
      "\n",
      "Domain: 45\n",
      "x_dp_dom.shape: (52, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 45 | Accuracy: 0.7885 | Loss: 2.9129 | F1: 0.7141\n",
      "\n",
      "Domain: 46\n",
      "x_dp_dom.shape: (48, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 46 | Accuracy: 0.8542 | Loss: 2.1748 | F1: 0.7967\n",
      "\n",
      "Domain: 47\n",
      "x_dp_dom.shape: (44, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 47 | Accuracy: 0.4318 | Loss: 3.0813 | F1: 0.4932\n",
      "\n",
      "Domain: 48\n",
      "x_dp_dom.shape: (48, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 48 | Accuracy: 0.2708 | Loss: 5.6689 | F1: 0.2803\n",
      "\n",
      "Domain: 49\n",
      "x_dp_dom.shape: (53, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 49 | Accuracy: 0.7547 | Loss: 3.1011 | F1: 0.6822\n",
      "\n",
      "Domain: 50\n",
      "x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 50 | Accuracy: 0.8095 | Loss: 0.6806 | F1: 0.7953\n",
      "\n",
      "Domain: 51\n",
      "x_dp_dom.shape: (46, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 51 | Accuracy: 0.7609 | Loss: 2.0484 | F1: 0.7121\n",
      "\n",
      "Domain: 52\n",
      "x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 52 | Accuracy: 0.8095 | Loss: 2.1041 | F1: 0.7606\n",
      "\n",
      "Domain: 53\n",
      "x_dp_dom.shape: (48, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 53 | Accuracy: 0.7917 | Loss: 1.5495 | F1: 0.7501\n",
      "\n",
      "Domain: 54\n",
      "x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 54 | Accuracy: 1.0000 | Loss: 0.0171 | F1: 1.0000\n",
      "\n",
      "Domain: 55\n",
      "x_dp_dom.shape: (49, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 55 | Accuracy: 0.8367 | Loss: 2.2820 | F1: 0.7743\n",
      "\n",
      "Domain: 56\n",
      "x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 56 | Accuracy: 0.2381 | Loss: 4.3620 | F1: 0.1904\n",
      "\n",
      "Domain: 57\n",
      "x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 57 | Accuracy: 0.6905 | Loss: 0.9524 | F1: 0.7301\n",
      "\n",
      "Domain: 58\n",
      "x_dp_dom.shape: (38, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 58 | Accuracy: 0.8684 | Loss: 1.7325 | F1: 0.8246\n",
      "\n",
      "Domain: 59\n",
      "x_dp_dom.shape: (43, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 59 | Accuracy: 0.2558 | Loss: 6.0423 | F1: 0.1783\n",
      "\n",
      "Domain: 60\n",
      "x_dp_dom.shape: (47, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 60 | Accuracy: 0.6596 | Loss: 2.7431 | F1: 0.6681\n",
      "\n",
      "Domain: 61\n",
      "x_dp_dom.shape: (47, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 61 | Accuracy: 0.4681 | Loss: 2.9291 | F1: 0.5071\n",
      "\n",
      "Domain: 62\n",
      "x_dp_dom.shape: (47, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 62 | Accuracy: 0.8511 | Loss: 2.5335 | F1: 0.7934\n",
      "\n",
      "Domain: 63\n",
      "x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 63 | Accuracy: 0.8333 | Loss: 1.3606 | F1: 0.8365\n",
      "\n",
      "Domain: 64\n",
      "x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 64 | Accuracy: 0.8095 | Loss: 2.8390 | F1: 0.7657\n",
      "\n",
      "Domain: 65\n",
      "x_dp_dom.shape: (50, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 65 | Accuracy: 0.8200 | Loss: 1.0886 | F1: 0.7999\n",
      "\n",
      "Domain: 66\n",
      "x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 66 | Accuracy: 0.7857 | Loss: 1.9925 | F1: 0.7434\n",
      "\n",
      "Domain: 67\n",
      "x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 67 | Accuracy: 0.8810 | Loss: 0.5144 | F1: 0.8864\n",
      "\n",
      "Domain: 68\n",
      "x_dp_dom.shape: (43, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 68 | Accuracy: 0.1860 | Loss: 7.3753 | F1: 0.1295\n",
      "\n",
      "Domain: 69\n",
      "x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 69 | Accuracy: 0.8571 | Loss: 1.2640 | F1: 0.8250\n",
      "\n",
      "Domain: 70\n",
      "x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 70 | Accuracy: 0.2381 | Loss: 5.0079 | F1: 0.2234\n",
      "\n",
      "Domain: 71\n",
      "x_dp_dom.shape: (44, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 71 | Accuracy: 0.9545 | Loss: 0.1468 | F1: 0.9516\n",
      "\n",
      "Domain: 72\n",
      "x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 72 | Accuracy: 0.3333 | Loss: 2.3402 | F1: 0.4139\n",
      "\n",
      "Domain: 73\n",
      "x_dp_dom.shape: (41, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 73 | Accuracy: 0.8293 | Loss: 1.7913 | F1: 0.7788\n",
      "\n",
      "Domain: 74\n",
      "x_dp_dom.shape: (35, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 74 | Accuracy: 0.6857 | Loss: 2.0993 | F1: 0.7458\n",
      "\n",
      "Domain: 75\n",
      "x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 75 | Accuracy: 0.7857 | Loss: 2.5742 | F1: 0.7531\n",
      "\n",
      "Mean accuracy for run 7: 0.6792\n",
      "Mean F1 for run 7: 0.6639\n",
      "\n",
      "Source class: WAL\n",
      "\n",
      "x_df.shape: (7958, 3, 128) | np.unique(y_df): [1 2 3]\n",
      "\n",
      "Training on Df data...\n",
      "\tEpoch 10/100 - Train loss: 0.0334 - Val accuracy: 0.9812 - Val loss: 0.0653 - Val F1: 0.9812 - LR: 9.00e-05\n",
      "\tEpoch 20/100 - Train loss: 0.0111 - Val accuracy: 0.9837 - Val loss: 0.0577 - Val F1: 0.9837 - LR: 8.00e-05\n",
      "\tEpoch 30/100 - Train loss: 0.0047 - Val accuracy: 0.9824 - Val loss: 0.0566 - Val F1: 0.9824 - LR: 7.00e-05\n",
      "\tEpoch 40/100 - Train loss: 0.0020 - Val accuracy: 0.9818 - Val loss: 0.0620 - Val F1: 0.9818 - LR: 6.00e-05\n",
      "\tEpoch 50/100 - Train loss: 0.0014 - Val accuracy: 0.9862 - Val loss: 0.0566 - Val F1: 0.9862 - LR: 5.00e-05\n",
      "\tEpoch 60/100 - Train loss: 0.0005 - Val accuracy: 0.9868 - Val loss: 0.0582 - Val F1: 0.9868 - LR: 4.00e-05\n",
      "\tEpoch 70/100 - Train loss: 0.0006 - Val accuracy: 0.9843 - Val loss: 0.0565 - Val F1: 0.9843 - LR: 3.00e-05\n",
      "\tEpoch 80/100 - Train loss: 0.0002 - Val accuracy: 0.9868 - Val loss: 0.0641 - Val F1: 0.9868 - LR: 2.00e-05\n",
      "\tEpoch 90/100 - Train loss: 0.0007 - Val accuracy: 0.9862 - Val loss: 0.0624 - Val F1: 0.9862 - LR: 1.00e-05\n",
      "\tEpoch 100/100 - Train loss: 0.0002 - Val accuracy: 0.9868 - Val loss: 0.0611 - Val F1: 0.9868 - LR: 0.00e+00\n",
      "\tBest epoch: 23 - Best val accuracy: 0.9868 - Best val loss: 0.0488 - Best val F1: 0.9868\n",
      "\n",
      "Domain: 15\n",
      "x_dp_dom.shape: (50, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 15 | Accuracy: 0.6400 | Loss: 8.1050 | F1: 0.6353\n",
      "\n",
      "Domain: 16\n",
      "x_dp_dom.shape: (54, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 16 | Accuracy: 0.5926 | Loss: 1.8935 | F1: 0.6237\n",
      "\n",
      "Domain: 17\n",
      "x_dp_dom.shape: (53, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 17 | Accuracy: 0.7736 | Loss: 2.4489 | F1: 0.6961\n",
      "\n",
      "Domain: 18\n",
      "x_dp_dom.shape: (54, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 18 | Accuracy: 0.3333 | Loss: 3.4216 | F1: 0.3198\n",
      "\n",
      "Domain: 19\n",
      "x_dp_dom.shape: (54, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 19 | Accuracy: 0.8704 | Loss: 0.6188 | F1: 0.8652\n",
      "\n",
      "Domain: 20\n",
      "x_dp_dom.shape: (51, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 20 | Accuracy: 0.7843 | Loss: 1.8083 | F1: 0.7491\n",
      "\n",
      "Domain: 21\n",
      "x_dp_dom.shape: (47, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 21 | Accuracy: 0.7447 | Loss: 1.1254 | F1: 0.7708\n",
      "\n",
      "Domain: 22\n",
      "x_dp_dom.shape: (54, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 22 | Accuracy: 0.8519 | Loss: 0.6900 | F1: 0.8531\n",
      "\n",
      "Domain: 23\n",
      "x_dp_dom.shape: (52, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 23 | Accuracy: 0.8269 | Loss: 1.0847 | F1: 0.8235\n",
      "\n",
      "Domain: 24\n",
      "x_dp_dom.shape: (51, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 24 | Accuracy: 0.7843 | Loss: 0.9187 | F1: 0.7891\n",
      "\n",
      "Domain: 25\n",
      "x_dp_dom.shape: (54, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 25 | Accuracy: 0.5185 | Loss: 2.9233 | F1: 0.5292\n",
      "\n",
      "Domain: 26\n",
      "x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 26 | Accuracy: 0.6667 | Loss: 1.6268 | F1: 0.6905\n",
      "\n",
      "Domain: 27\n",
      "x_dp_dom.shape: (54, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 27 | Accuracy: 0.8519 | Loss: 1.0547 | F1: 0.8364\n",
      "\n",
      "Domain: 28\n",
      "x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 28 | Accuracy: 0.8333 | Loss: 1.2645 | F1: 0.8090\n",
      "\n",
      "Domain: 29\n",
      "x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 29 | Accuracy: 0.6905 | Loss: 0.7697 | F1: 0.7182\n",
      "\n",
      "Domain: 30\n",
      "x_dp_dom.shape: (50, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 30 | Accuracy: 0.6800 | Loss: 3.1694 | F1: 0.6892\n",
      "\n",
      "Domain: 31\n",
      "x_dp_dom.shape: (43, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 31 | Accuracy: 0.8140 | Loss: 1.7266 | F1: 0.7939\n",
      "\n",
      "Domain: 32\n",
      "x_dp_dom.shape: (52, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 32 | Accuracy: 0.4808 | Loss: 2.3818 | F1: 0.5075\n",
      "\n",
      "Domain: 33\n",
      "x_dp_dom.shape: (44, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 33 | Accuracy: 0.6591 | Loss: 1.5248 | F1: 0.6803\n",
      "\n",
      "Domain: 34\n",
      "x_dp_dom.shape: (49, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 34 | Accuracy: 0.6122 | Loss: 4.0661 | F1: 0.6079\n",
      "\n",
      "Domain: 35\n",
      "x_dp_dom.shape: (48, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 35 | Accuracy: 0.7708 | Loss: 1.9413 | F1: 0.7479\n",
      "\n",
      "Domain: 36\n",
      "x_dp_dom.shape: (43, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 36 | Accuracy: 0.8140 | Loss: 1.8959 | F1: 0.7687\n",
      "\n",
      "Domain: 37\n",
      "x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 37 | Accuracy: 0.5952 | Loss: 2.2592 | F1: 0.6600\n",
      "\n",
      "Domain: 38\n",
      "x_dp_dom.shape: (47, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 38 | Accuracy: 0.8723 | Loss: 1.4461 | F1: 0.8666\n",
      "\n",
      "Domain: 39\n",
      "x_dp_dom.shape: (54, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 39 | Accuracy: 0.5000 | Loss: 2.7390 | F1: 0.5043\n",
      "\n",
      "Domain: 40\n",
      "x_dp_dom.shape: (44, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 40 | Accuracy: 0.7955 | Loss: 0.8182 | F1: 0.7930\n",
      "\n",
      "Domain: 41\n",
      "x_dp_dom.shape: (45, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 41 | Accuracy: 0.2000 | Loss: 8.2314 | F1: 0.2236\n",
      "\n",
      "Domain: 42\n",
      "x_dp_dom.shape: (46, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 42 | Accuracy: 0.8478 | Loss: 1.2318 | F1: 0.8617\n",
      "\n",
      "Domain: 43\n",
      "x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 43 | Accuracy: 0.5952 | Loss: 5.5860 | F1: 0.6441\n",
      "\n",
      "Domain: 44\n",
      "x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 44 | Accuracy: 0.9286 | Loss: 0.2214 | F1: 0.9309\n",
      "\n",
      "Domain: 45\n",
      "x_dp_dom.shape: (52, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 45 | Accuracy: 0.7885 | Loss: 1.3798 | F1: 0.7615\n",
      "\n",
      "Domain: 46\n",
      "x_dp_dom.shape: (48, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 46 | Accuracy: 0.6875 | Loss: 0.9616 | F1: 0.7088\n",
      "\n",
      "Domain: 47\n",
      "x_dp_dom.shape: (44, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 47 | Accuracy: 0.5227 | Loss: 2.9261 | F1: 0.5662\n",
      "\n",
      "Domain: 48\n",
      "x_dp_dom.shape: (48, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 48 | Accuracy: 0.5625 | Loss: 2.4832 | F1: 0.6086\n",
      "\n",
      "Domain: 49\n",
      "x_dp_dom.shape: (53, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 49 | Accuracy: 0.7547 | Loss: 2.8837 | F1: 0.6822\n",
      "\n",
      "Domain: 50\n",
      "x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 50 | Accuracy: 0.8333 | Loss: 1.3832 | F1: 0.8073\n",
      "\n",
      "Domain: 51\n",
      "x_dp_dom.shape: (46, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 51 | Accuracy: 0.7391 | Loss: 2.2723 | F1: 0.7339\n",
      "\n",
      "Domain: 52\n",
      "x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 52 | Accuracy: 0.7381 | Loss: 1.4160 | F1: 0.7247\n",
      "\n",
      "Domain: 53\n",
      "x_dp_dom.shape: (48, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 53 | Accuracy: 0.7708 | Loss: 1.5901 | F1: 0.7793\n",
      "\n",
      "Domain: 54\n",
      "x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 54 | Accuracy: 0.9762 | Loss: 0.0514 | F1: 0.9761\n",
      "\n",
      "Domain: 55\n",
      "x_dp_dom.shape: (49, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 55 | Accuracy: 0.6735 | Loss: 2.0687 | F1: 0.6747\n",
      "\n",
      "Domain: 56\n",
      "x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 56 | Accuracy: 0.3095 | Loss: 4.9509 | F1: 0.3705\n",
      "\n",
      "Domain: 57\n",
      "x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 57 | Accuracy: 0.8333 | Loss: 1.9543 | F1: 0.7778\n",
      "\n",
      "Domain: 58\n",
      "x_dp_dom.shape: (38, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 58 | Accuracy: 0.8684 | Loss: 0.5246 | F1: 0.8702\n",
      "\n",
      "Domain: 59\n",
      "x_dp_dom.shape: (43, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 59 | Accuracy: 0.4186 | Loss: 3.7100 | F1: 0.4258\n",
      "\n",
      "Domain: 60\n",
      "x_dp_dom.shape: (47, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 60 | Accuracy: 0.6809 | Loss: 6.2060 | F1: 0.6498\n",
      "\n",
      "Domain: 61\n",
      "x_dp_dom.shape: (47, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 61 | Accuracy: 0.4894 | Loss: 4.1578 | F1: 0.5025\n",
      "\n",
      "Domain: 62\n",
      "x_dp_dom.shape: (47, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 62 | Accuracy: 0.8511 | Loss: 2.0548 | F1: 0.7934\n",
      "\n",
      "Domain: 63\n",
      "x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 63 | Accuracy: 0.7143 | Loss: 2.1195 | F1: 0.7251\n",
      "\n",
      "Domain: 64\n",
      "x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 64 | Accuracy: 0.6667 | Loss: 1.0735 | F1: 0.6989\n",
      "\n",
      "Domain: 65\n",
      "x_dp_dom.shape: (50, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 65 | Accuracy: 0.8800 | Loss: 1.6234 | F1: 0.8612\n",
      "\n",
      "Domain: 66\n",
      "x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 66 | Accuracy: 0.5952 | Loss: 5.7902 | F1: 0.5970\n",
      "\n",
      "Domain: 67\n",
      "x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 67 | Accuracy: 0.8810 | Loss: 0.2167 | F1: 0.8772\n",
      "\n",
      "Domain: 68\n",
      "x_dp_dom.shape: (43, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 68 | Accuracy: 0.2791 | Loss: 5.5174 | F1: 0.2800\n",
      "\n",
      "Domain: 69\n",
      "x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 69 | Accuracy: 0.8333 | Loss: 0.7798 | F1: 0.8090\n",
      "\n",
      "Domain: 70\n",
      "x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 70 | Accuracy: 0.8095 | Loss: 1.8714 | F1: 0.8081\n",
      "\n",
      "Domain: 71\n",
      "x_dp_dom.shape: (44, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 71 | Accuracy: 0.7273 | Loss: 0.7302 | F1: 0.7590\n",
      "\n",
      "Domain: 72\n",
      "x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 72 | Accuracy: 0.0952 | Loss: 7.0583 | F1: 0.1048\n",
      "\n",
      "Domain: 73\n",
      "x_dp_dom.shape: (41, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 73 | Accuracy: 0.8293 | Loss: 4.7521 | F1: 0.7843\n",
      "\n",
      "Domain: 74\n",
      "x_dp_dom.shape: (35, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 74 | Accuracy: 0.8571 | Loss: 1.9802 | F1: 0.8436\n",
      "\n",
      "Domain: 75\n",
      "x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 75 | Accuracy: 0.7619 | Loss: 1.3086 | F1: 0.7423\n",
      "\n",
      "Mean accuracy for run 8: 0.6944\n",
      "Mean F1 for run 8: 0.6933\n",
      "\n",
      "Source class: WAL\n",
      "\n",
      "x_df.shape: (7958, 3, 128) | np.unique(y_df): [1 2 3]\n",
      "\n",
      "Training on Df data...\n",
      "\tEpoch 10/100 - Train loss: 0.0296 - Val accuracy: 0.9812 - Val loss: 0.0482 - Val F1: 0.9811 - LR: 9.00e-05\n",
      "\tEpoch 20/100 - Train loss: 0.0138 - Val accuracy: 0.9868 - Val loss: 0.0389 - Val F1: 0.9868 - LR: 8.00e-05\n",
      "\tEpoch 30/100 - Train loss: 0.0052 - Val accuracy: 0.9830 - Val loss: 0.0466 - Val F1: 0.9830 - LR: 7.00e-05\n",
      "\tEpoch 40/100 - Train loss: 0.0016 - Val accuracy: 0.9843 - Val loss: 0.0443 - Val F1: 0.9843 - LR: 6.00e-05\n",
      "\tEpoch 50/100 - Train loss: 0.0022 - Val accuracy: 0.9868 - Val loss: 0.0448 - Val F1: 0.9868 - LR: 5.00e-05\n",
      "\tEpoch 60/100 - Train loss: 0.0004 - Val accuracy: 0.9862 - Val loss: 0.0471 - Val F1: 0.9862 - LR: 4.00e-05\n",
      "\tEpoch 70/100 - Train loss: 0.0011 - Val accuracy: 0.9837 - Val loss: 0.0467 - Val F1: 0.9837 - LR: 3.00e-05\n",
      "\tEpoch 80/100 - Train loss: 0.0003 - Val accuracy: 0.9868 - Val loss: 0.0527 - Val F1: 0.9868 - LR: 2.00e-05\n",
      "\tEpoch 90/100 - Train loss: 0.0002 - Val accuracy: 0.9856 - Val loss: 0.0486 - Val F1: 0.9856 - LR: 1.00e-05\n",
      "\tEpoch 100/100 - Train loss: 0.0002 - Val accuracy: 0.9856 - Val loss: 0.0504 - Val F1: 0.9856 - LR: 0.00e+00\n",
      "\tBest epoch: 25 - Best val accuracy: 0.9868 - Best val loss: 0.0360 - Best val F1: 0.9868\n",
      "\n",
      "Domain: 15\n",
      "x_dp_dom.shape: (50, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 15 | Accuracy: 0.2000 | Loss: 13.4988 | F1: 0.0800\n",
      "\n",
      "Domain: 16\n",
      "x_dp_dom.shape: (54, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 16 | Accuracy: 0.4630 | Loss: 2.8729 | F1: 0.4792\n",
      "\n",
      "Domain: 17\n",
      "x_dp_dom.shape: (53, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 17 | Accuracy: 0.7736 | Loss: 2.4318 | F1: 0.6961\n",
      "\n",
      "Domain: 18\n",
      "x_dp_dom.shape: (54, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 18 | Accuracy: 0.6852 | Loss: 3.7932 | F1: 0.6313\n",
      "\n",
      "Domain: 19\n",
      "x_dp_dom.shape: (54, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 19 | Accuracy: 0.7963 | Loss: 1.4117 | F1: 0.7802\n",
      "\n",
      "Domain: 20\n",
      "x_dp_dom.shape: (51, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 20 | Accuracy: 0.5490 | Loss: 3.7146 | F1: 0.5459\n",
      "\n",
      "Domain: 21\n",
      "x_dp_dom.shape: (47, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 21 | Accuracy: 0.7234 | Loss: 2.6024 | F1: 0.7219\n",
      "\n",
      "Domain: 22\n",
      "x_dp_dom.shape: (54, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 22 | Accuracy: 0.7778 | Loss: 1.3494 | F1: 0.7764\n",
      "\n",
      "Domain: 23\n",
      "x_dp_dom.shape: (52, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 23 | Accuracy: 0.7500 | Loss: 1.8021 | F1: 0.7305\n",
      "\n",
      "Domain: 24\n",
      "x_dp_dom.shape: (51, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 24 | Accuracy: 0.6471 | Loss: 1.6290 | F1: 0.6590\n",
      "\n",
      "Domain: 25\n",
      "x_dp_dom.shape: (54, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 25 | Accuracy: 0.6111 | Loss: 3.1715 | F1: 0.5848\n",
      "\n",
      "Domain: 26\n",
      "x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 26 | Accuracy: 0.4048 | Loss: 3.7503 | F1: 0.4481\n",
      "\n",
      "Domain: 27\n",
      "x_dp_dom.shape: (54, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 27 | Accuracy: 0.7222 | Loss: 2.3294 | F1: 0.6617\n",
      "\n",
      "Domain: 28\n",
      "x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 28 | Accuracy: 0.7857 | Loss: 1.9011 | F1: 0.7531\n",
      "\n",
      "Domain: 29\n",
      "x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 29 | Accuracy: 0.7857 | Loss: 0.9802 | F1: 0.7909\n",
      "\n",
      "Domain: 30\n",
      "x_dp_dom.shape: (50, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 30 | Accuracy: 0.6800 | Loss: 3.8014 | F1: 0.6958\n",
      "\n",
      "Domain: 31\n",
      "x_dp_dom.shape: (43, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 31 | Accuracy: 0.7442 | Loss: 2.6969 | F1: 0.7162\n",
      "\n",
      "Domain: 32\n",
      "x_dp_dom.shape: (52, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 32 | Accuracy: 0.5769 | Loss: 2.2248 | F1: 0.5825\n",
      "\n",
      "Domain: 33\n",
      "x_dp_dom.shape: (44, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 33 | Accuracy: 0.7500 | Loss: 1.8853 | F1: 0.7503\n",
      "\n",
      "Domain: 34\n",
      "x_dp_dom.shape: (49, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 34 | Accuracy: 0.5102 | Loss: 3.3968 | F1: 0.5302\n",
      "\n",
      "Domain: 35\n",
      "x_dp_dom.shape: (48, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 35 | Accuracy: 0.8333 | Loss: 2.5291 | F1: 0.7798\n",
      "\n",
      "Domain: 36\n",
      "x_dp_dom.shape: (43, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 36 | Accuracy: 0.7674 | Loss: 2.8006 | F1: 0.7437\n",
      "\n",
      "Domain: 37\n",
      "x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 37 | Accuracy: 0.7143 | Loss: 1.8620 | F1: 0.7530\n",
      "\n",
      "Domain: 38\n",
      "x_dp_dom.shape: (47, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 38 | Accuracy: 0.4894 | Loss: 3.2545 | F1: 0.5159\n",
      "\n",
      "Domain: 39\n",
      "x_dp_dom.shape: (54, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 39 | Accuracy: 0.5741 | Loss: 3.0439 | F1: 0.5770\n",
      "\n",
      "Domain: 40\n",
      "x_dp_dom.shape: (44, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 40 | Accuracy: 0.7045 | Loss: 1.3794 | F1: 0.6796\n",
      "\n",
      "Domain: 41\n",
      "x_dp_dom.shape: (45, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 41 | Accuracy: 0.4000 | Loss: 5.3297 | F1: 0.4844\n",
      "\n",
      "Domain: 42\n",
      "x_dp_dom.shape: (46, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 42 | Accuracy: 0.8261 | Loss: 0.9081 | F1: 0.8333\n",
      "\n",
      "Domain: 43\n",
      "x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 43 | Accuracy: 0.5714 | Loss: 6.7834 | F1: 0.6206\n",
      "\n",
      "Domain: 44\n",
      "x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 44 | Accuracy: 0.9048 | Loss: 0.2115 | F1: 0.8922\n",
      "\n",
      "Domain: 45\n",
      "x_dp_dom.shape: (52, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 45 | Accuracy: 0.7308 | Loss: 2.8117 | F1: 0.6705\n",
      "\n",
      "Domain: 46\n",
      "x_dp_dom.shape: (48, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 46 | Accuracy: 0.8125 | Loss: 1.8831 | F1: 0.7629\n",
      "\n",
      "Domain: 47\n",
      "x_dp_dom.shape: (44, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 47 | Accuracy: 0.4545 | Loss: 3.4570 | F1: 0.5182\n",
      "\n",
      "Domain: 48\n",
      "x_dp_dom.shape: (48, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 48 | Accuracy: 0.4583 | Loss: 3.1206 | F1: 0.5065\n",
      "\n",
      "Domain: 49\n",
      "x_dp_dom.shape: (53, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 49 | Accuracy: 0.4906 | Loss: 3.9787 | F1: 0.4679\n",
      "\n",
      "Domain: 50\n",
      "x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 50 | Accuracy: 0.7143 | Loss: 1.6124 | F1: 0.7167\n",
      "\n",
      "Domain: 51\n",
      "x_dp_dom.shape: (46, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 51 | Accuracy: 0.6957 | Loss: 3.1639 | F1: 0.6732\n",
      "\n",
      "Domain: 52\n",
      "x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 52 | Accuracy: 0.8095 | Loss: 2.4328 | F1: 0.7606\n",
      "\n",
      "Domain: 53\n",
      "x_dp_dom.shape: (48, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 53 | Accuracy: 0.5000 | Loss: 2.8049 | F1: 0.5665\n",
      "\n",
      "Domain: 54\n",
      "x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 54 | Accuracy: 0.8571 | Loss: 0.8944 | F1: 0.8444\n",
      "\n",
      "Domain: 55\n",
      "x_dp_dom.shape: (49, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 55 | Accuracy: 0.5510 | Loss: 3.2829 | F1: 0.5838\n",
      "\n",
      "Domain: 56\n",
      "x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 56 | Accuracy: 0.1190 | Loss: 7.6270 | F1: 0.1197\n",
      "\n",
      "Domain: 57\n",
      "x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 57 | Accuracy: 0.6905 | Loss: 0.8264 | F1: 0.7275\n",
      "\n",
      "Domain: 58\n",
      "x_dp_dom.shape: (38, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 58 | Accuracy: 0.8684 | Loss: 1.8420 | F1: 0.8246\n",
      "\n",
      "Domain: 59\n",
      "x_dp_dom.shape: (43, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 59 | Accuracy: 0.3023 | Loss: 3.9547 | F1: 0.3140\n",
      "\n",
      "Domain: 60\n",
      "x_dp_dom.shape: (47, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 60 | Accuracy: 0.4043 | Loss: 8.2611 | F1: 0.3699\n",
      "\n",
      "Domain: 61\n",
      "x_dp_dom.shape: (47, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 61 | Accuracy: 0.4894 | Loss: 4.9167 | F1: 0.5190\n",
      "\n",
      "Domain: 62\n",
      "x_dp_dom.shape: (47, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 62 | Accuracy: 0.8511 | Loss: 2.5552 | F1: 0.7934\n",
      "\n",
      "Domain: 63\n",
      "x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 63 | Accuracy: 0.5238 | Loss: 3.3252 | F1: 0.5884\n",
      "\n",
      "Domain: 64\n",
      "x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 64 | Accuracy: 0.7381 | Loss: 2.8788 | F1: 0.7265\n",
      "\n",
      "Domain: 65\n",
      "x_dp_dom.shape: (50, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 65 | Accuracy: 0.7600 | Loss: 1.9962 | F1: 0.7657\n",
      "\n",
      "Domain: 66\n",
      "x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 66 | Accuracy: 0.1667 | Loss: 12.3143 | F1: 0.0476\n",
      "\n",
      "Domain: 67\n",
      "x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 67 | Accuracy: 0.7143 | Loss: 1.0645 | F1: 0.6407\n",
      "\n",
      "Domain: 68\n",
      "x_dp_dom.shape: (43, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 68 | Accuracy: 0.1628 | Loss: 7.1856 | F1: 0.1487\n",
      "\n",
      "Domain: 69\n",
      "x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 69 | Accuracy: 0.3095 | Loss: 4.0049 | F1: 0.2980\n",
      "\n",
      "Domain: 70\n",
      "x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 70 | Accuracy: 0.8333 | Loss: 1.8253 | F1: 0.8090\n",
      "\n",
      "Domain: 71\n",
      "x_dp_dom.shape: (44, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 71 | Accuracy: 0.6364 | Loss: 1.5272 | F1: 0.6691\n",
      "\n",
      "Domain: 72\n",
      "x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 72 | Accuracy: 0.1429 | Loss: 6.1305 | F1: 0.1000\n",
      "\n",
      "Domain: 73\n",
      "x_dp_dom.shape: (41, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 73 | Accuracy: 0.5366 | Loss: 5.6264 | F1: 0.5489\n",
      "\n",
      "Domain: 74\n",
      "x_dp_dom.shape: (35, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 74 | Accuracy: 0.7143 | Loss: 2.6814 | F1: 0.7018\n",
      "\n",
      "Domain: 75\n",
      "x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Source class: WAL | Domain: 75 | Accuracy: 0.7619 | Loss: 2.1011 | F1: 0.7350\n",
      "\n",
      "Mean accuracy for run 9: 0.6151\n",
      "Mean F1 for run 9: 0.6068\n",
      "\n",
      "Mean accuracy over 10 runs: 0.6676 +- 0.0527\n",
      "Mean F1 over 10 runs: 0.6564 +- 0.0517\n",
      "\n"
     ]
    }
   ],
   "source": [
    "n_runs = 10\n",
    "\n",
    "def compute_TSTR_Df_rot(dataset):\n",
    "    accs = []\n",
    "    f1s = []\n",
    "\n",
    "    for i in range(n_runs):\n",
    "\n",
    "        accs_run = []\n",
    "        f1s_run = []\n",
    "\n",
    "        for src_class in config[dataset]['class_names']:\n",
    "            if src_class != 'WAL':\n",
    "                continue\n",
    "\n",
    "            print(f\"Source class: {src_class}\\n\")\n",
    "\n",
    "            # Load Df data\n",
    "            x_df, y_df, k_df = get_data(dataset, 'df', src_class, rot=True)\n",
    "            print(f'x_df.shape: {x_df.shape} | np.unique(y_df): {np.unique(y_df)}\\n')\n",
    "\n",
    "            # Train on Df data\n",
    "            print('Training on Df data...')\n",
    "            df_model = train_only(x_df, y_df, dataset, num_epochs=num_epochs)\n",
    "\n",
    "            for domain in range(config[dataset]['num_df_domains'], config[dataset]['num_df_domains'] + config[dataset]['num_dp_domains']):\n",
    "                print(f\"Domain: {domain}\")\n",
    "\n",
    "                # Load Dp data\n",
    "                x_dp_dom, y_dp_dom, k_dp_dom = get_data(dataset, 'dp', src_class, domain)\n",
    "                print(f'x_dp_dom.shape: {x_dp_dom.shape} | np.unique(y_dp_dom): {np.unique(y_dp_dom)}\\n')\n",
    "\n",
    "                # Evaluate on Dp data\n",
    "                acc, loss, f1 = evaluate_model(df_model, get_dataloader(x_dp_dom, y_dp_dom))\n",
    "                save_scores(src_class, domain, acc, loss, f1, 'Df_rot', dataset)\n",
    "                accs_run.append(acc)\n",
    "                f1s_run.append(f1)\n",
    "                print(f'Source class: {src_class} | Domain: {domain} | Accuracy: {acc:.4f} | Loss: {loss:.4f} | F1: {f1:.4f}\\n')\n",
    "\n",
    "        print(f\"Mean accuracy for run {i}: {np.mean(accs_run):.4f}\")\n",
    "        print(f\"Mean F1 for run {i}: {np.mean(f1s_run):.4f}\\n\")\n",
    "        accs.append(np.mean(accs_run))\n",
    "        f1s.append(np.mean(f1s_run))\n",
    "\n",
    "    print(f\"Mean accuracy over {n_runs} runs: {np.mean(accs):.4f} +- {np.std(accs):.4f}\")\n",
    "    print(f\"Mean F1 over {n_runs} runs: {np.mean(f1s):.4f} +- {np.std(f1s):.4f}\\n\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "compute_TSTR_Df_rot('realworld_mobiact')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 520213,
     "status": "ok",
     "timestamp": 1732619451586,
     "user": {
      "displayName": "Pietro Cirino",
      "userId": "07315473796200699505"
     },
     "user_tz": -60
    },
    "id": "SmGQm1ZFCPto",
    "outputId": "0c4467e5-4000-4fd6-ed9d-c676f1428d17"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source class: WAL\n",
      "\n",
      "Domain: 15\n",
      "x_syn_dom.shape: (333, 3, 128) | np.unique(y_syn_dom): [1 2 3]\n",
      "x_dp_dom.shape: (50, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Training on synthetic data...\n",
      "\tEpoch 10/100 - Train loss: 0.1386 - Val accuracy: 0.9851 - Val loss: 0.1310 - Val F1: 0.9851 - LR: 9.00e-05\n",
      "\tEpoch 20/100 - Train loss: 0.0182 - Val accuracy: 0.9851 - Val loss: 0.0201 - Val F1: 0.9851 - LR: 8.00e-05\n",
      "\tEpoch 30/100 - Train loss: 0.0050 - Val accuracy: 1.0000 - Val loss: 0.0143 - Val F1: 1.0000 - LR: 7.00e-05\n",
      "\tEpoch 40/100 - Train loss: 0.0027 - Val accuracy: 0.9851 - Val loss: 0.0174 - Val F1: 0.9851 - LR: 6.00e-05\n",
      "\tEpoch 50/100 - Train loss: 0.0014 - Val accuracy: 1.0000 - Val loss: 0.0090 - Val F1: 1.0000 - LR: 5.00e-05\n",
      "\tEpoch 60/100 - Train loss: 0.0022 - Val accuracy: 1.0000 - Val loss: 0.0099 - Val F1: 1.0000 - LR: 4.00e-05\n",
      "\tEpoch 70/100 - Train loss: 0.0022 - Val accuracy: 0.9851 - Val loss: 0.0121 - Val F1: 0.9851 - LR: 3.00e-05\n",
      "\tEpoch 80/100 - Train loss: 0.0010 - Val accuracy: 1.0000 - Val loss: 0.0076 - Val F1: 1.0000 - LR: 2.00e-05\n",
      "\tEpoch 90/100 - Train loss: 0.0011 - Val accuracy: 1.0000 - Val loss: 0.0108 - Val F1: 1.0000 - LR: 1.00e-05\n",
      "\tEpoch 100/100 - Train loss: 0.0008 - Val accuracy: 1.0000 - Val loss: 0.0070 - Val F1: 1.0000 - LR: 0.00e+00\n",
      "\tBest epoch: 93 - Best val accuracy: 1.0000 - Best val loss: 0.0058 - Best val F1: 1.0000\n",
      "\n",
      "Source class: WAL | Domain: 15 | Accuracy: 0.8000 | Loss: 2.3618 | F1: 0.7152\n",
      "\n",
      "Domain: 16\n",
      "x_syn_dom.shape: (333, 3, 128) | np.unique(y_syn_dom): [1 2 3]\n",
      "x_dp_dom.shape: (54, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Training on synthetic data...\n",
      "\tEpoch 10/100 - Train loss: 0.1146 - Val accuracy: 0.9701 - Val loss: 0.1374 - Val F1: 0.9701 - LR: 9.00e-05\n",
      "\tEpoch 20/100 - Train loss: 0.0167 - Val accuracy: 1.0000 - Val loss: 0.0221 - Val F1: 1.0000 - LR: 8.00e-05\n",
      "\tEpoch 30/100 - Train loss: 0.0058 - Val accuracy: 1.0000 - Val loss: 0.0160 - Val F1: 1.0000 - LR: 7.00e-05\n",
      "\tEpoch 40/100 - Train loss: 0.0029 - Val accuracy: 0.9851 - Val loss: 0.0293 - Val F1: 0.9851 - LR: 6.00e-05\n",
      "\tEpoch 50/100 - Train loss: 0.0020 - Val accuracy: 1.0000 - Val loss: 0.0143 - Val F1: 1.0000 - LR: 5.00e-05\n",
      "\tEpoch 60/100 - Train loss: 0.0012 - Val accuracy: 0.9851 - Val loss: 0.0213 - Val F1: 0.9851 - LR: 4.00e-05\n",
      "\tEpoch 70/100 - Train loss: 0.0038 - Val accuracy: 1.0000 - Val loss: 0.0150 - Val F1: 1.0000 - LR: 3.00e-05\n",
      "\tEpoch 80/100 - Train loss: 0.0323 - Val accuracy: 0.9851 - Val loss: 0.0231 - Val F1: 0.9851 - LR: 2.00e-05\n",
      "\tEpoch 90/100 - Train loss: 0.0011 - Val accuracy: 0.9851 - Val loss: 0.0185 - Val F1: 0.9851 - LR: 1.00e-05\n",
      "\tEpoch 100/100 - Train loss: 0.0009 - Val accuracy: 0.9851 - Val loss: 0.0162 - Val F1: 0.9851 - LR: 0.00e+00\n",
      "\tBest epoch: 56 - Best val accuracy: 1.0000 - Best val loss: 0.0119 - Best val F1: 1.0000\n",
      "\n",
      "Source class: WAL | Domain: 16 | Accuracy: 0.9074 | Loss: 0.1977 | F1: 0.9039\n",
      "\n",
      "Domain: 17\n",
      "x_syn_dom.shape: (333, 3, 128) | np.unique(y_syn_dom): [1 2 3]\n",
      "x_dp_dom.shape: (53, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Training on synthetic data...\n",
      "\tEpoch 10/100 - Train loss: 0.0809 - Val accuracy: 0.9851 - Val loss: 0.0757 - Val F1: 0.9851 - LR: 9.00e-05\n",
      "\tEpoch 20/100 - Train loss: 0.0101 - Val accuracy: 0.9851 - Val loss: 0.0404 - Val F1: 0.9851 - LR: 8.00e-05\n",
      "\tEpoch 30/100 - Train loss: 0.0060 - Val accuracy: 0.9851 - Val loss: 0.0347 - Val F1: 0.9851 - LR: 7.00e-05\n",
      "\tEpoch 40/100 - Train loss: 0.0020 - Val accuracy: 0.9851 - Val loss: 0.0303 - Val F1: 0.9851 - LR: 6.00e-05\n",
      "\tEpoch 50/100 - Train loss: 0.0015 - Val accuracy: 0.9851 - Val loss: 0.0305 - Val F1: 0.9851 - LR: 5.00e-05\n",
      "\tEpoch 60/100 - Train loss: 0.0014 - Val accuracy: 0.9851 - Val loss: 0.0322 - Val F1: 0.9851 - LR: 4.00e-05\n",
      "\tEpoch 70/100 - Train loss: 0.0016 - Val accuracy: 0.9851 - Val loss: 0.0273 - Val F1: 0.9851 - LR: 3.00e-05\n",
      "\tEpoch 80/100 - Train loss: 0.0009 - Val accuracy: 0.9851 - Val loss: 0.0285 - Val F1: 0.9851 - LR: 2.00e-05\n",
      "\tEpoch 90/100 - Train loss: 0.0015 - Val accuracy: 0.9851 - Val loss: 0.0237 - Val F1: 0.9851 - LR: 1.00e-05\n",
      "\tEpoch 100/100 - Train loss: 0.0011 - Val accuracy: 0.9851 - Val loss: 0.0207 - Val F1: 0.9851 - LR: 0.00e+00\n",
      "\tBest epoch: 100 - Best val accuracy: 0.9851 - Best val loss: 0.0207 - Best val F1: 0.9851\n",
      "\n",
      "Source class: WAL | Domain: 17 | Accuracy: 0.5849 | Loss: 2.1117 | F1: 0.5552\n",
      "\n",
      "Domain: 18\n",
      "x_syn_dom.shape: (336, 3, 128) | np.unique(y_syn_dom): [1 2 3]\n",
      "x_dp_dom.shape: (54, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Training on synthetic data...\n",
      "\tEpoch 10/100 - Train loss: 0.0713 - Val accuracy: 1.0000 - Val loss: 0.0536 - Val F1: 1.0000 - LR: 9.00e-05\n",
      "\tEpoch 20/100 - Train loss: 0.0145 - Val accuracy: 1.0000 - Val loss: 0.0066 - Val F1: 1.0000 - LR: 8.00e-05\n",
      "\tEpoch 30/100 - Train loss: 0.0056 - Val accuracy: 1.0000 - Val loss: 0.0025 - Val F1: 1.0000 - LR: 7.00e-05\n",
      "\tEpoch 40/100 - Train loss: 0.0048 - Val accuracy: 1.0000 - Val loss: 0.0013 - Val F1: 1.0000 - LR: 6.00e-05\n",
      "\tEpoch 50/100 - Train loss: 0.0029 - Val accuracy: 1.0000 - Val loss: 0.0010 - Val F1: 1.0000 - LR: 5.00e-05\n",
      "\tEpoch 60/100 - Train loss: 0.0021 - Val accuracy: 1.0000 - Val loss: 0.0007 - Val F1: 1.0000 - LR: 4.00e-05\n",
      "\tEpoch 70/100 - Train loss: 0.0011 - Val accuracy: 1.0000 - Val loss: 0.0006 - Val F1: 1.0000 - LR: 3.00e-05\n",
      "\tEpoch 80/100 - Train loss: 0.0014 - Val accuracy: 1.0000 - Val loss: 0.0005 - Val F1: 1.0000 - LR: 2.00e-05\n",
      "\tEpoch 90/100 - Train loss: 0.0025 - Val accuracy: 1.0000 - Val loss: 0.0004 - Val F1: 1.0000 - LR: 1.00e-05\n",
      "\tEpoch 100/100 - Train loss: 0.0013 - Val accuracy: 1.0000 - Val loss: 0.0004 - Val F1: 1.0000 - LR: 0.00e+00\n",
      "\tBest epoch: 97 - Best val accuracy: 1.0000 - Best val loss: 0.0004 - Best val F1: 1.0000\n",
      "\n",
      "Source class: WAL | Domain: 18 | Accuracy: 0.8333 | Loss: 0.6762 | F1: 0.8311\n",
      "\n",
      "Domain: 19\n",
      "x_syn_dom.shape: (333, 3, 128) | np.unique(y_syn_dom): [1 2 3]\n",
      "x_dp_dom.shape: (54, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Training on synthetic data...\n",
      "\tEpoch 10/100 - Train loss: 0.0238 - Val accuracy: 0.9851 - Val loss: 0.0536 - Val F1: 0.9851 - LR: 9.00e-05\n",
      "\tEpoch 20/100 - Train loss: 0.0054 - Val accuracy: 0.9851 - Val loss: 0.0567 - Val F1: 0.9851 - LR: 8.00e-05\n",
      "\tEpoch 30/100 - Train loss: 0.0024 - Val accuracy: 0.9851 - Val loss: 0.0585 - Val F1: 0.9851 - LR: 7.00e-05\n",
      "\tEpoch 40/100 - Train loss: 0.0011 - Val accuracy: 0.9851 - Val loss: 0.0624 - Val F1: 0.9851 - LR: 6.00e-05\n",
      "\tEpoch 50/100 - Train loss: 0.0009 - Val accuracy: 0.9851 - Val loss: 0.0640 - Val F1: 0.9851 - LR: 5.00e-05\n",
      "\tEpoch 60/100 - Train loss: 0.0010 - Val accuracy: 0.9851 - Val loss: 0.0667 - Val F1: 0.9851 - LR: 4.00e-05\n",
      "\tEpoch 70/100 - Train loss: 0.0009 - Val accuracy: 0.9851 - Val loss: 0.0566 - Val F1: 0.9851 - LR: 3.00e-05\n",
      "\tEpoch 80/100 - Train loss: 0.0007 - Val accuracy: 0.9851 - Val loss: 0.0592 - Val F1: 0.9851 - LR: 2.00e-05\n",
      "\tEpoch 90/100 - Train loss: 0.0007 - Val accuracy: 0.9851 - Val loss: 0.0632 - Val F1: 0.9851 - LR: 1.00e-05\n",
      "\tEpoch 100/100 - Train loss: 0.0005 - Val accuracy: 0.9851 - Val loss: 0.0667 - Val F1: 0.9851 - LR: 0.00e+00\n",
      "\tBest epoch: 43 - Best val accuracy: 0.9851 - Best val loss: 0.0449 - Best val F1: 0.9851\n",
      "\n",
      "Source class: WAL | Domain: 19 | Accuracy: 0.7407 | Loss: 1.3125 | F1: 0.6706\n",
      "\n",
      "Domain: 20\n",
      "x_syn_dom.shape: (333, 3, 128) | np.unique(y_syn_dom): [1 2 3]\n",
      "x_dp_dom.shape: (51, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Training on synthetic data...\n",
      "\tEpoch 10/100 - Train loss: 0.0814 - Val accuracy: 1.0000 - Val loss: 0.0629 - Val F1: 1.0000 - LR: 9.00e-05\n",
      "\tEpoch 20/100 - Train loss: 0.0137 - Val accuracy: 1.0000 - Val loss: 0.0085 - Val F1: 1.0000 - LR: 8.00e-05\n",
      "\tEpoch 30/100 - Train loss: 0.0045 - Val accuracy: 1.0000 - Val loss: 0.0045 - Val F1: 1.0000 - LR: 7.00e-05\n",
      "\tEpoch 40/100 - Train loss: 0.0028 - Val accuracy: 1.0000 - Val loss: 0.0026 - Val F1: 1.0000 - LR: 6.00e-05\n",
      "\tEpoch 50/100 - Train loss: 0.0022 - Val accuracy: 1.0000 - Val loss: 0.0019 - Val F1: 1.0000 - LR: 5.00e-05\n",
      "\tEpoch 60/100 - Train loss: 0.0027 - Val accuracy: 1.0000 - Val loss: 0.0018 - Val F1: 1.0000 - LR: 4.00e-05\n",
      "\tEpoch 70/100 - Train loss: 0.0018 - Val accuracy: 1.0000 - Val loss: 0.0014 - Val F1: 1.0000 - LR: 3.00e-05\n",
      "\tEpoch 80/100 - Train loss: 0.0010 - Val accuracy: 1.0000 - Val loss: 0.0013 - Val F1: 1.0000 - LR: 2.00e-05\n",
      "\tEpoch 90/100 - Train loss: 0.0011 - Val accuracy: 1.0000 - Val loss: 0.0013 - Val F1: 1.0000 - LR: 1.00e-05\n",
      "\tEpoch 100/100 - Train loss: 0.0013 - Val accuracy: 1.0000 - Val loss: 0.0012 - Val F1: 1.0000 - LR: 0.00e+00\n",
      "\tBest epoch: 83 - Best val accuracy: 1.0000 - Best val loss: 0.0012 - Best val F1: 1.0000\n",
      "\n",
      "Source class: WAL | Domain: 20 | Accuracy: 0.6667 | Loss: 1.1078 | F1: 0.6485\n",
      "\n",
      "Domain: 21\n",
      "x_syn_dom.shape: (336, 3, 128) | np.unique(y_syn_dom): [1 2 3]\n",
      "x_dp_dom.shape: (47, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Training on synthetic data...\n",
      "\tEpoch 10/100 - Train loss: 0.0757 - Val accuracy: 0.9853 - Val loss: 0.0744 - Val F1: 0.9853 - LR: 9.00e-05\n",
      "\tEpoch 20/100 - Train loss: 0.0079 - Val accuracy: 1.0000 - Val loss: 0.0128 - Val F1: 1.0000 - LR: 8.00e-05\n",
      "\tEpoch 30/100 - Train loss: 0.0041 - Val accuracy: 1.0000 - Val loss: 0.0104 - Val F1: 1.0000 - LR: 7.00e-05\n",
      "\tEpoch 40/100 - Train loss: 0.0027 - Val accuracy: 1.0000 - Val loss: 0.0071 - Val F1: 1.0000 - LR: 6.00e-05\n",
      "\tEpoch 50/100 - Train loss: 0.0031 - Val accuracy: 1.0000 - Val loss: 0.0053 - Val F1: 1.0000 - LR: 5.00e-05\n",
      "\tEpoch 60/100 - Train loss: 0.0015 - Val accuracy: 1.0000 - Val loss: 0.0102 - Val F1: 1.0000 - LR: 4.00e-05\n",
      "\tEpoch 70/100 - Train loss: 0.0011 - Val accuracy: 0.9853 - Val loss: 0.0122 - Val F1: 0.9853 - LR: 3.00e-05\n",
      "\tEpoch 80/100 - Train loss: 0.0006 - Val accuracy: 1.0000 - Val loss: 0.0067 - Val F1: 1.0000 - LR: 2.00e-05\n",
      "\tEpoch 90/100 - Train loss: 0.0007 - Val accuracy: 1.0000 - Val loss: 0.0091 - Val F1: 1.0000 - LR: 1.00e-05\n",
      "\tEpoch 100/100 - Train loss: 0.0008 - Val accuracy: 1.0000 - Val loss: 0.0094 - Val F1: 1.0000 - LR: 0.00e+00\n",
      "\tBest epoch: 75 - Best val accuracy: 1.0000 - Best val loss: 0.0049 - Best val F1: 1.0000\n",
      "\n",
      "Source class: WAL | Domain: 21 | Accuracy: 0.8723 | Loss: 0.3843 | F1: 0.8372\n",
      "\n",
      "Domain: 22\n",
      "x_syn_dom.shape: (333, 3, 128) | np.unique(y_syn_dom): [1 2 3]\n",
      "x_dp_dom.shape: (54, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Training on synthetic data...\n",
      "\tEpoch 10/100 - Train loss: 0.0806 - Val accuracy: 0.9851 - Val loss: 0.0586 - Val F1: 0.9851 - LR: 9.00e-05\n",
      "\tEpoch 20/100 - Train loss: 0.0140 - Val accuracy: 1.0000 - Val loss: 0.0113 - Val F1: 1.0000 - LR: 8.00e-05\n",
      "\tEpoch 30/100 - Train loss: 0.0066 - Val accuracy: 1.0000 - Val loss: 0.0083 - Val F1: 1.0000 - LR: 7.00e-05\n",
      "\tEpoch 40/100 - Train loss: 0.0032 - Val accuracy: 1.0000 - Val loss: 0.0053 - Val F1: 1.0000 - LR: 6.00e-05\n",
      "\tEpoch 50/100 - Train loss: 0.0016 - Val accuracy: 1.0000 - Val loss: 0.0050 - Val F1: 1.0000 - LR: 5.00e-05\n",
      "\tEpoch 60/100 - Train loss: 0.0015 - Val accuracy: 1.0000 - Val loss: 0.0072 - Val F1: 1.0000 - LR: 4.00e-05\n",
      "\tEpoch 70/100 - Train loss: 0.0022 - Val accuracy: 1.0000 - Val loss: 0.0064 - Val F1: 1.0000 - LR: 3.00e-05\n",
      "\tEpoch 80/100 - Train loss: 0.0009 - Val accuracy: 1.0000 - Val loss: 0.0036 - Val F1: 1.0000 - LR: 2.00e-05\n",
      "\tEpoch 90/100 - Train loss: 0.0009 - Val accuracy: 1.0000 - Val loss: 0.0049 - Val F1: 1.0000 - LR: 1.00e-05\n",
      "\tEpoch 100/100 - Train loss: 0.0012 - Val accuracy: 1.0000 - Val loss: 0.0050 - Val F1: 1.0000 - LR: 0.00e+00\n",
      "\tBest epoch: 78 - Best val accuracy: 1.0000 - Best val loss: 0.0032 - Best val F1: 1.0000\n",
      "\n",
      "Source class: WAL | Domain: 22 | Accuracy: 0.8889 | Loss: 0.1817 | F1: 0.8862\n",
      "\n",
      "Domain: 23\n",
      "x_syn_dom.shape: (336, 3, 128) | np.unique(y_syn_dom): [1 2 3]\n",
      "x_dp_dom.shape: (52, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Training on synthetic data...\n",
      "\tEpoch 10/100 - Train loss: 0.0659 - Val accuracy: 0.9853 - Val loss: 0.0485 - Val F1: 0.9853 - LR: 9.00e-05\n",
      "\tEpoch 20/100 - Train loss: 0.0068 - Val accuracy: 0.9853 - Val loss: 0.0300 - Val F1: 0.9853 - LR: 8.00e-05\n",
      "\tEpoch 30/100 - Train loss: 0.0034 - Val accuracy: 0.9853 - Val loss: 0.0187 - Val F1: 0.9853 - LR: 7.00e-05\n",
      "\tEpoch 40/100 - Train loss: 0.0027 - Val accuracy: 1.0000 - Val loss: 0.0128 - Val F1: 1.0000 - LR: 6.00e-05\n",
      "\tEpoch 50/100 - Train loss: 0.0014 - Val accuracy: 1.0000 - Val loss: 0.0133 - Val F1: 1.0000 - LR: 5.00e-05\n",
      "\tEpoch 60/100 - Train loss: 0.0010 - Val accuracy: 1.0000 - Val loss: 0.0120 - Val F1: 1.0000 - LR: 4.00e-05\n",
      "\tEpoch 70/100 - Train loss: 0.0021 - Val accuracy: 1.0000 - Val loss: 0.0103 - Val F1: 1.0000 - LR: 3.00e-05\n",
      "\tEpoch 80/100 - Train loss: 0.0009 - Val accuracy: 1.0000 - Val loss: 0.0087 - Val F1: 1.0000 - LR: 2.00e-05\n",
      "\tEpoch 90/100 - Train loss: 0.0011 - Val accuracy: 1.0000 - Val loss: 0.0069 - Val F1: 1.0000 - LR: 1.00e-05\n",
      "\tEpoch 100/100 - Train loss: 0.0013 - Val accuracy: 1.0000 - Val loss: 0.0086 - Val F1: 1.0000 - LR: 0.00e+00\n",
      "\tBest epoch: 92 - Best val accuracy: 1.0000 - Best val loss: 0.0047 - Best val F1: 1.0000\n",
      "\n",
      "Source class: WAL | Domain: 23 | Accuracy: 0.8654 | Loss: 0.4977 | F1: 0.8647\n",
      "\n",
      "Domain: 24\n",
      "x_syn_dom.shape: (333, 3, 128) | np.unique(y_syn_dom): [1 2 3]\n",
      "x_dp_dom.shape: (51, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Training on synthetic data...\n",
      "\tEpoch 10/100 - Train loss: 0.0720 - Val accuracy: 1.0000 - Val loss: 0.0440 - Val F1: 1.0000 - LR: 9.00e-05\n",
      "\tEpoch 20/100 - Train loss: 0.0263 - Val accuracy: 1.0000 - Val loss: 0.0169 - Val F1: 1.0000 - LR: 8.00e-05\n",
      "\tEpoch 30/100 - Train loss: 0.0129 - Val accuracy: 1.0000 - Val loss: 0.0050 - Val F1: 1.0000 - LR: 7.00e-05\n",
      "\tEpoch 40/100 - Train loss: 0.0046 - Val accuracy: 1.0000 - Val loss: 0.0056 - Val F1: 1.0000 - LR: 6.00e-05\n",
      "\tEpoch 50/100 - Train loss: 0.0046 - Val accuracy: 1.0000 - Val loss: 0.0024 - Val F1: 1.0000 - LR: 5.00e-05\n",
      "\tEpoch 60/100 - Train loss: 0.0042 - Val accuracy: 1.0000 - Val loss: 0.0018 - Val F1: 1.0000 - LR: 4.00e-05\n",
      "\tEpoch 70/100 - Train loss: 0.0020 - Val accuracy: 1.0000 - Val loss: 0.0016 - Val F1: 1.0000 - LR: 3.00e-05\n",
      "\tEpoch 80/100 - Train loss: 0.0012 - Val accuracy: 1.0000 - Val loss: 0.0019 - Val F1: 1.0000 - LR: 2.00e-05\n",
      "\tEpoch 90/100 - Train loss: 0.0018 - Val accuracy: 1.0000 - Val loss: 0.0022 - Val F1: 1.0000 - LR: 1.00e-05\n",
      "\tEpoch 100/100 - Train loss: 0.0015 - Val accuracy: 1.0000 - Val loss: 0.0028 - Val F1: 1.0000 - LR: 0.00e+00\n",
      "\tBest epoch: 77 - Best val accuracy: 1.0000 - Best val loss: 0.0013 - Best val F1: 1.0000\n",
      "\n",
      "Source class: WAL | Domain: 24 | Accuracy: 0.7255 | Loss: 2.5104 | F1: 0.6579\n",
      "\n",
      "Domain: 25\n",
      "x_syn_dom.shape: (336, 3, 128) | np.unique(y_syn_dom): [1 2 3]\n",
      "x_dp_dom.shape: (54, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Training on synthetic data...\n",
      "\tEpoch 10/100 - Train loss: 0.0760 - Val accuracy: 1.0000 - Val loss: 0.0530 - Val F1: 1.0000 - LR: 9.00e-05\n",
      "\tEpoch 20/100 - Train loss: 0.0105 - Val accuracy: 1.0000 - Val loss: 0.0069 - Val F1: 1.0000 - LR: 8.00e-05\n",
      "\tEpoch 30/100 - Train loss: 0.0042 - Val accuracy: 1.0000 - Val loss: 0.0025 - Val F1: 1.0000 - LR: 7.00e-05\n",
      "\tEpoch 40/100 - Train loss: 0.0029 - Val accuracy: 1.0000 - Val loss: 0.0013 - Val F1: 1.0000 - LR: 6.00e-05\n",
      "\tEpoch 50/100 - Train loss: 0.0015 - Val accuracy: 1.0000 - Val loss: 0.0009 - Val F1: 1.0000 - LR: 5.00e-05\n",
      "\tEpoch 60/100 - Train loss: 0.0011 - Val accuracy: 1.0000 - Val loss: 0.0007 - Val F1: 1.0000 - LR: 4.00e-05\n",
      "\tEpoch 70/100 - Train loss: 0.0010 - Val accuracy: 1.0000 - Val loss: 0.0006 - Val F1: 1.0000 - LR: 3.00e-05\n",
      "\tEpoch 80/100 - Train loss: 0.0005 - Val accuracy: 1.0000 - Val loss: 0.0006 - Val F1: 1.0000 - LR: 2.00e-05\n",
      "\tEpoch 90/100 - Train loss: 0.0008 - Val accuracy: 1.0000 - Val loss: 0.0005 - Val F1: 1.0000 - LR: 1.00e-05\n",
      "\tEpoch 100/100 - Train loss: 0.0006 - Val accuracy: 1.0000 - Val loss: 0.0004 - Val F1: 1.0000 - LR: 0.00e+00\n",
      "\tBest epoch: 96 - Best val accuracy: 1.0000 - Best val loss: 0.0004 - Best val F1: 1.0000\n",
      "\n",
      "Source class: WAL | Domain: 25 | Accuracy: 0.7593 | Loss: 1.8314 | F1: 0.6790\n",
      "\n",
      "Domain: 26\n",
      "x_syn_dom.shape: (333, 3, 128) | np.unique(y_syn_dom): [1 2 3]\n",
      "x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Training on synthetic data...\n",
      "\tEpoch 10/100 - Train loss: 0.0330 - Val accuracy: 1.0000 - Val loss: 0.0176 - Val F1: 1.0000 - LR: 9.00e-05\n",
      "\tEpoch 20/100 - Train loss: 0.0093 - Val accuracy: 1.0000 - Val loss: 0.0080 - Val F1: 1.0000 - LR: 8.00e-05\n",
      "\tEpoch 30/100 - Train loss: 0.0049 - Val accuracy: 1.0000 - Val loss: 0.0071 - Val F1: 1.0000 - LR: 7.00e-05\n",
      "\tEpoch 40/100 - Train loss: 0.0032 - Val accuracy: 1.0000 - Val loss: 0.0056 - Val F1: 1.0000 - LR: 6.00e-05\n",
      "\tEpoch 50/100 - Train loss: 0.0016 - Val accuracy: 1.0000 - Val loss: 0.0039 - Val F1: 1.0000 - LR: 5.00e-05\n",
      "\tEpoch 60/100 - Train loss: 0.0009 - Val accuracy: 1.0000 - Val loss: 0.0039 - Val F1: 1.0000 - LR: 4.00e-05\n",
      "\tEpoch 70/100 - Train loss: 0.0010 - Val accuracy: 1.0000 - Val loss: 0.0041 - Val F1: 1.0000 - LR: 3.00e-05\n",
      "\tEpoch 80/100 - Train loss: 0.0004 - Val accuracy: 1.0000 - Val loss: 0.0038 - Val F1: 1.0000 - LR: 2.00e-05\n",
      "\tEpoch 90/100 - Train loss: 0.0008 - Val accuracy: 1.0000 - Val loss: 0.0044 - Val F1: 1.0000 - LR: 1.00e-05\n",
      "\tEpoch 100/100 - Train loss: 0.0006 - Val accuracy: 1.0000 - Val loss: 0.0072 - Val F1: 1.0000 - LR: 0.00e+00\n",
      "\tBest epoch: 85 - Best val accuracy: 1.0000 - Best val loss: 0.0024 - Best val F1: 1.0000\n",
      "\n",
      "Source class: WAL | Domain: 26 | Accuracy: 0.5714 | Loss: 1.8794 | F1: 0.6094\n",
      "\n",
      "Domain: 27\n",
      "x_syn_dom.shape: (333, 3, 128) | np.unique(y_syn_dom): [1 2 3]\n",
      "x_dp_dom.shape: (54, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Training on synthetic data...\n",
      "\tEpoch 10/100 - Train loss: 0.0594 - Val accuracy: 1.0000 - Val loss: 0.0478 - Val F1: 1.0000 - LR: 9.00e-05\n",
      "\tEpoch 20/100 - Train loss: 0.0062 - Val accuracy: 1.0000 - Val loss: 0.0115 - Val F1: 1.0000 - LR: 8.00e-05\n",
      "\tEpoch 30/100 - Train loss: 0.0041 - Val accuracy: 1.0000 - Val loss: 0.0060 - Val F1: 1.0000 - LR: 7.00e-05\n",
      "\tEpoch 40/100 - Train loss: 0.0019 - Val accuracy: 1.0000 - Val loss: 0.0036 - Val F1: 1.0000 - LR: 6.00e-05\n",
      "\tEpoch 50/100 - Train loss: 0.0019 - Val accuracy: 1.0000 - Val loss: 0.0039 - Val F1: 1.0000 - LR: 5.00e-05\n",
      "\tEpoch 60/100 - Train loss: 0.0015 - Val accuracy: 1.0000 - Val loss: 0.0036 - Val F1: 1.0000 - LR: 4.00e-05\n",
      "\tEpoch 70/100 - Train loss: 0.0013 - Val accuracy: 1.0000 - Val loss: 0.0038 - Val F1: 1.0000 - LR: 3.00e-05\n",
      "\tEpoch 80/100 - Train loss: 0.0008 - Val accuracy: 1.0000 - Val loss: 0.0021 - Val F1: 1.0000 - LR: 2.00e-05\n",
      "\tEpoch 90/100 - Train loss: 0.0004 - Val accuracy: 1.0000 - Val loss: 0.0016 - Val F1: 1.0000 - LR: 1.00e-05\n",
      "\tEpoch 100/100 - Train loss: 0.0016 - Val accuracy: 1.0000 - Val loss: 0.0020 - Val F1: 1.0000 - LR: 0.00e+00\n",
      "\tBest epoch: 89 - Best val accuracy: 1.0000 - Best val loss: 0.0014 - Best val F1: 1.0000\n",
      "\n",
      "Source class: WAL | Domain: 27 | Accuracy: 0.7778 | Loss: 1.1785 | F1: 0.7545\n",
      "\n",
      "Domain: 28\n",
      "x_syn_dom.shape: (333, 3, 128) | np.unique(y_syn_dom): [1 2 3]\n",
      "x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Training on synthetic data...\n",
      "\tEpoch 10/100 - Train loss: 0.0473 - Val accuracy: 1.0000 - Val loss: 0.0241 - Val F1: 1.0000 - LR: 9.00e-05\n",
      "\tEpoch 20/100 - Train loss: 0.0045 - Val accuracy: 1.0000 - Val loss: 0.0034 - Val F1: 1.0000 - LR: 8.00e-05\n",
      "\tEpoch 30/100 - Train loss: 0.0041 - Val accuracy: 1.0000 - Val loss: 0.0013 - Val F1: 1.0000 - LR: 7.00e-05\n",
      "\tEpoch 40/100 - Train loss: 0.0015 - Val accuracy: 1.0000 - Val loss: 0.0007 - Val F1: 1.0000 - LR: 6.00e-05\n",
      "\tEpoch 50/100 - Train loss: 0.0011 - Val accuracy: 1.0000 - Val loss: 0.0005 - Val F1: 1.0000 - LR: 5.00e-05\n",
      "\tEpoch 60/100 - Train loss: 0.0010 - Val accuracy: 1.0000 - Val loss: 0.0004 - Val F1: 1.0000 - LR: 4.00e-05\n",
      "\tEpoch 70/100 - Train loss: 0.0011 - Val accuracy: 1.0000 - Val loss: 0.0003 - Val F1: 1.0000 - LR: 3.00e-05\n",
      "\tEpoch 80/100 - Train loss: 0.0011 - Val accuracy: 1.0000 - Val loss: 0.0003 - Val F1: 1.0000 - LR: 2.00e-05\n",
      "\tEpoch 90/100 - Train loss: 0.0006 - Val accuracy: 1.0000 - Val loss: 0.0003 - Val F1: 1.0000 - LR: 1.00e-05\n",
      "\tEpoch 100/100 - Train loss: 0.0008 - Val accuracy: 1.0000 - Val loss: 0.0002 - Val F1: 1.0000 - LR: 0.00e+00\n",
      "\tBest epoch: 98 - Best val accuracy: 1.0000 - Best val loss: 0.0002 - Best val F1: 1.0000\n",
      "\n",
      "Source class: WAL | Domain: 28 | Accuracy: 0.8333 | Loss: 2.1390 | F1: 0.7778\n",
      "\n",
      "Domain: 29\n",
      "x_syn_dom.shape: (333, 3, 128) | np.unique(y_syn_dom): [1 2 3]\n",
      "x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Training on synthetic data...\n",
      "\tEpoch 10/100 - Train loss: 0.0502 - Val accuracy: 0.9851 - Val loss: 0.0709 - Val F1: 0.9851 - LR: 9.00e-05\n",
      "\tEpoch 20/100 - Train loss: 0.0076 - Val accuracy: 0.9851 - Val loss: 0.0468 - Val F1: 0.9851 - LR: 8.00e-05\n",
      "\tEpoch 30/100 - Train loss: 0.0023 - Val accuracy: 0.9851 - Val loss: 0.0409 - Val F1: 0.9851 - LR: 7.00e-05\n",
      "\tEpoch 40/100 - Train loss: 0.0015 - Val accuracy: 0.9851 - Val loss: 0.0373 - Val F1: 0.9851 - LR: 6.00e-05\n",
      "\tEpoch 50/100 - Train loss: 0.0013 - Val accuracy: 0.9851 - Val loss: 0.0372 - Val F1: 0.9851 - LR: 5.00e-05\n",
      "\tEpoch 60/100 - Train loss: 0.0011 - Val accuracy: 0.9851 - Val loss: 0.0392 - Val F1: 0.9851 - LR: 4.00e-05\n",
      "\tEpoch 70/100 - Train loss: 0.0009 - Val accuracy: 0.9851 - Val loss: 0.0269 - Val F1: 0.9851 - LR: 3.00e-05\n",
      "\tEpoch 80/100 - Train loss: 0.0024 - Val accuracy: 0.9851 - Val loss: 0.0287 - Val F1: 0.9851 - LR: 2.00e-05\n",
      "\tEpoch 90/100 - Train loss: 0.0005 - Val accuracy: 0.9851 - Val loss: 0.0330 - Val F1: 0.9851 - LR: 1.00e-05\n",
      "\tEpoch 100/100 - Train loss: 0.0035 - Val accuracy: 0.9851 - Val loss: 0.0336 - Val F1: 0.9851 - LR: 0.00e+00\n",
      "\tBest epoch: 55 - Best val accuracy: 0.9851 - Best val loss: 0.0259 - Best val F1: 0.9851\n",
      "\n",
      "Source class: WAL | Domain: 29 | Accuracy: 0.8095 | Loss: 1.4413 | F1: 0.7606\n",
      "\n",
      "Domain: 30\n",
      "x_syn_dom.shape: (333, 3, 128) | np.unique(y_syn_dom): [1 2 3]\n",
      "x_dp_dom.shape: (50, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Training on synthetic data...\n",
      "\tEpoch 10/100 - Train loss: 0.1027 - Val accuracy: 0.9851 - Val loss: 0.1299 - Val F1: 0.9851 - LR: 9.00e-05\n",
      "\tEpoch 20/100 - Train loss: 0.0243 - Val accuracy: 0.9552 - Val loss: 0.1206 - Val F1: 0.9550 - LR: 8.00e-05\n",
      "\tEpoch 30/100 - Train loss: 0.0082 - Val accuracy: 0.9552 - Val loss: 0.1366 - Val F1: 0.9550 - LR: 7.00e-05\n",
      "\tEpoch 40/100 - Train loss: 0.0129 - Val accuracy: 0.9851 - Val loss: 0.0780 - Val F1: 0.9851 - LR: 6.00e-05\n",
      "\tEpoch 50/100 - Train loss: 0.0026 - Val accuracy: 0.9701 - Val loss: 0.1108 - Val F1: 0.9701 - LR: 5.00e-05\n",
      "\tEpoch 60/100 - Train loss: 0.0034 - Val accuracy: 0.9701 - Val loss: 0.1280 - Val F1: 0.9701 - LR: 4.00e-05\n",
      "\tEpoch 70/100 - Train loss: 0.0029 - Val accuracy: 0.9701 - Val loss: 0.1259 - Val F1: 0.9701 - LR: 3.00e-05\n",
      "\tEpoch 80/100 - Train loss: 0.0019 - Val accuracy: 0.9701 - Val loss: 0.1328 - Val F1: 0.9701 - LR: 2.00e-05\n",
      "\tEpoch 90/100 - Train loss: 0.0007 - Val accuracy: 0.9701 - Val loss: 0.1288 - Val F1: 0.9701 - LR: 1.00e-05\n",
      "\tEpoch 100/100 - Train loss: 0.0029 - Val accuracy: 0.9701 - Val loss: 0.1265 - Val F1: 0.9701 - LR: 0.00e+00\n",
      "\tBest epoch: 40 - Best val accuracy: 0.9851 - Best val loss: 0.0780 - Best val F1: 0.9851\n",
      "\n",
      "Source class: WAL | Domain: 30 | Accuracy: 0.7000 | Loss: 2.4226 | F1: 0.6564\n",
      "\n",
      "Domain: 31\n",
      "x_syn_dom.shape: (333, 3, 128) | np.unique(y_syn_dom): [1 2 3]\n",
      "x_dp_dom.shape: (43, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Training on synthetic data...\n",
      "\tEpoch 10/100 - Train loss: 0.0283 - Val accuracy: 1.0000 - Val loss: 0.0087 - Val F1: 1.0000 - LR: 9.00e-05\n",
      "\tEpoch 20/100 - Train loss: 0.0066 - Val accuracy: 1.0000 - Val loss: 0.0025 - Val F1: 1.0000 - LR: 8.00e-05\n",
      "\tEpoch 30/100 - Train loss: 0.0063 - Val accuracy: 1.0000 - Val loss: 0.0012 - Val F1: 1.0000 - LR: 7.00e-05\n",
      "\tEpoch 40/100 - Train loss: 0.0037 - Val accuracy: 1.0000 - Val loss: 0.0008 - Val F1: 1.0000 - LR: 6.00e-05\n",
      "\tEpoch 50/100 - Train loss: 0.0024 - Val accuracy: 1.0000 - Val loss: 0.0007 - Val F1: 1.0000 - LR: 5.00e-05\n",
      "\tEpoch 60/100 - Train loss: 0.0015 - Val accuracy: 1.0000 - Val loss: 0.0006 - Val F1: 1.0000 - LR: 4.00e-05\n",
      "\tEpoch 70/100 - Train loss: 0.0029 - Val accuracy: 1.0000 - Val loss: 0.0009 - Val F1: 1.0000 - LR: 3.00e-05\n",
      "\tEpoch 80/100 - Train loss: 0.0017 - Val accuracy: 1.0000 - Val loss: 0.0011 - Val F1: 1.0000 - LR: 2.00e-05\n",
      "\tEpoch 90/100 - Train loss: 0.0011 - Val accuracy: 1.0000 - Val loss: 0.0008 - Val F1: 1.0000 - LR: 1.00e-05\n",
      "\tEpoch 100/100 - Train loss: 0.0007 - Val accuracy: 1.0000 - Val loss: 0.0009 - Val F1: 1.0000 - LR: 0.00e+00\n",
      "\tBest epoch: 89 - Best val accuracy: 1.0000 - Best val loss: 0.0003 - Best val F1: 1.0000\n",
      "\n",
      "Source class: WAL | Domain: 31 | Accuracy: 0.6512 | Loss: 2.3620 | F1: 0.5610\n",
      "\n",
      "Domain: 32\n",
      "x_syn_dom.shape: (333, 3, 128) | np.unique(y_syn_dom): [1 2 3]\n",
      "x_dp_dom.shape: (52, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Training on synthetic data...\n",
      "\tEpoch 10/100 - Train loss: 0.0356 - Val accuracy: 1.0000 - Val loss: 0.0282 - Val F1: 1.0000 - LR: 9.00e-05\n",
      "\tEpoch 20/100 - Train loss: 0.0100 - Val accuracy: 1.0000 - Val loss: 0.0047 - Val F1: 1.0000 - LR: 8.00e-05\n",
      "\tEpoch 30/100 - Train loss: 0.0055 - Val accuracy: 1.0000 - Val loss: 0.0023 - Val F1: 1.0000 - LR: 7.00e-05\n",
      "\tEpoch 40/100 - Train loss: 0.0032 - Val accuracy: 1.0000 - Val loss: 0.0022 - Val F1: 1.0000 - LR: 6.00e-05\n",
      "\tEpoch 50/100 - Train loss: 0.0011 - Val accuracy: 1.0000 - Val loss: 0.0008 - Val F1: 1.0000 - LR: 5.00e-05\n",
      "\tEpoch 60/100 - Train loss: 0.0035 - Val accuracy: 1.0000 - Val loss: 0.0006 - Val F1: 1.0000 - LR: 4.00e-05\n",
      "\tEpoch 70/100 - Train loss: 0.0009 - Val accuracy: 1.0000 - Val loss: 0.0006 - Val F1: 1.0000 - LR: 3.00e-05\n",
      "\tEpoch 80/100 - Train loss: 0.0010 - Val accuracy: 1.0000 - Val loss: 0.0004 - Val F1: 1.0000 - LR: 2.00e-05\n",
      "\tEpoch 90/100 - Train loss: 0.0010 - Val accuracy: 1.0000 - Val loss: 0.0004 - Val F1: 1.0000 - LR: 1.00e-05\n",
      "\tEpoch 100/100 - Train loss: 0.0007 - Val accuracy: 1.0000 - Val loss: 0.0005 - Val F1: 1.0000 - LR: 0.00e+00\n",
      "\tBest epoch: 94 - Best val accuracy: 1.0000 - Best val loss: 0.0004 - Best val F1: 1.0000\n",
      "\n",
      "Source class: WAL | Domain: 32 | Accuracy: 0.7308 | Loss: 1.0485 | F1: 0.6837\n",
      "\n",
      "Domain: 33\n",
      "x_syn_dom.shape: (336, 3, 128) | np.unique(y_syn_dom): [1 2 3]\n",
      "x_dp_dom.shape: (44, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Training on synthetic data...\n",
      "\tEpoch 10/100 - Train loss: 0.0401 - Val accuracy: 1.0000 - Val loss: 0.0396 - Val F1: 1.0000 - LR: 9.00e-05\n",
      "\tEpoch 20/100 - Train loss: 0.0071 - Val accuracy: 1.0000 - Val loss: 0.0047 - Val F1: 1.0000 - LR: 8.00e-05\n",
      "\tEpoch 30/100 - Train loss: 0.0034 - Val accuracy: 1.0000 - Val loss: 0.0019 - Val F1: 1.0000 - LR: 7.00e-05\n",
      "\tEpoch 40/100 - Train loss: 0.0022 - Val accuracy: 1.0000 - Val loss: 0.0012 - Val F1: 1.0000 - LR: 6.00e-05\n",
      "\tEpoch 50/100 - Train loss: 0.0014 - Val accuracy: 1.0000 - Val loss: 0.0008 - Val F1: 1.0000 - LR: 5.00e-05\n",
      "\tEpoch 60/100 - Train loss: 0.0008 - Val accuracy: 1.0000 - Val loss: 0.0006 - Val F1: 1.0000 - LR: 4.00e-05\n",
      "\tEpoch 70/100 - Train loss: 0.0012 - Val accuracy: 1.0000 - Val loss: 0.0006 - Val F1: 1.0000 - LR: 3.00e-05\n",
      "\tEpoch 80/100 - Train loss: 0.0007 - Val accuracy: 1.0000 - Val loss: 0.0004 - Val F1: 1.0000 - LR: 2.00e-05\n",
      "\tEpoch 90/100 - Train loss: 0.0010 - Val accuracy: 1.0000 - Val loss: 0.0004 - Val F1: 1.0000 - LR: 1.00e-05\n",
      "\tEpoch 100/100 - Train loss: 0.0007 - Val accuracy: 1.0000 - Val loss: 0.0004 - Val F1: 1.0000 - LR: 0.00e+00\n",
      "\tBest epoch: 93 - Best val accuracy: 1.0000 - Best val loss: 0.0004 - Best val F1: 1.0000\n",
      "\n",
      "Source class: WAL | Domain: 33 | Accuracy: 0.7500 | Loss: 0.8886 | F1: 0.7510\n",
      "\n",
      "Domain: 34\n",
      "x_syn_dom.shape: (336, 3, 128) | np.unique(y_syn_dom): [1 2 3]\n",
      "x_dp_dom.shape: (49, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Training on synthetic data...\n",
      "\tEpoch 10/100 - Train loss: 0.0371 - Val accuracy: 1.0000 - Val loss: 0.0253 - Val F1: 1.0000 - LR: 9.00e-05\n",
      "\tEpoch 20/100 - Train loss: 0.0103 - Val accuracy: 1.0000 - Val loss: 0.0070 - Val F1: 1.0000 - LR: 8.00e-05\n",
      "\tEpoch 30/100 - Train loss: 0.0089 - Val accuracy: 1.0000 - Val loss: 0.0026 - Val F1: 1.0000 - LR: 7.00e-05\n",
      "\tEpoch 40/100 - Train loss: 0.0029 - Val accuracy: 1.0000 - Val loss: 0.0023 - Val F1: 1.0000 - LR: 6.00e-05\n",
      "\tEpoch 50/100 - Train loss: 0.0059 - Val accuracy: 1.0000 - Val loss: 0.0013 - Val F1: 1.0000 - LR: 5.00e-05\n",
      "\tEpoch 60/100 - Train loss: 0.0016 - Val accuracy: 1.0000 - Val loss: 0.0015 - Val F1: 1.0000 - LR: 4.00e-05\n",
      "\tEpoch 70/100 - Train loss: 0.0017 - Val accuracy: 1.0000 - Val loss: 0.0010 - Val F1: 1.0000 - LR: 3.00e-05\n",
      "\tEpoch 80/100 - Train loss: 0.0011 - Val accuracy: 1.0000 - Val loss: 0.0010 - Val F1: 1.0000 - LR: 2.00e-05\n",
      "\tEpoch 90/100 - Train loss: 0.0017 - Val accuracy: 1.0000 - Val loss: 0.0014 - Val F1: 1.0000 - LR: 1.00e-05\n",
      "\tEpoch 100/100 - Train loss: 0.0011 - Val accuracy: 1.0000 - Val loss: 0.0012 - Val F1: 1.0000 - LR: 0.00e+00\n",
      "\tBest epoch: 83 - Best val accuracy: 1.0000 - Best val loss: 0.0008 - Best val F1: 1.0000\n",
      "\n",
      "Source class: WAL | Domain: 34 | Accuracy: 0.5714 | Loss: 3.8134 | F1: 0.4324\n",
      "\n",
      "Domain: 35\n",
      "x_syn_dom.shape: (333, 3, 128) | np.unique(y_syn_dom): [1 2 3]\n",
      "x_dp_dom.shape: (48, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Training on synthetic data...\n",
      "\tEpoch 10/100 - Train loss: 0.0433 - Val accuracy: 1.0000 - Val loss: 0.0249 - Val F1: 1.0000 - LR: 9.00e-05\n",
      "\tEpoch 20/100 - Train loss: 0.0070 - Val accuracy: 1.0000 - Val loss: 0.0037 - Val F1: 1.0000 - LR: 8.00e-05\n",
      "\tEpoch 30/100 - Train loss: 0.0036 - Val accuracy: 1.0000 - Val loss: 0.0016 - Val F1: 1.0000 - LR: 7.00e-05\n",
      "\tEpoch 40/100 - Train loss: 0.0013 - Val accuracy: 1.0000 - Val loss: 0.0010 - Val F1: 1.0000 - LR: 6.00e-05\n",
      "\tEpoch 50/100 - Train loss: 0.0023 - Val accuracy: 1.0000 - Val loss: 0.0007 - Val F1: 1.0000 - LR: 5.00e-05\n",
      "\tEpoch 60/100 - Train loss: 0.0013 - Val accuracy: 1.0000 - Val loss: 0.0005 - Val F1: 1.0000 - LR: 4.00e-05\n",
      "\tEpoch 70/100 - Train loss: 0.0021 - Val accuracy: 1.0000 - Val loss: 0.0004 - Val F1: 1.0000 - LR: 3.00e-05\n",
      "\tEpoch 80/100 - Train loss: 0.0008 - Val accuracy: 1.0000 - Val loss: 0.0003 - Val F1: 1.0000 - LR: 2.00e-05\n",
      "\tEpoch 90/100 - Train loss: 0.0006 - Val accuracy: 1.0000 - Val loss: 0.0003 - Val F1: 1.0000 - LR: 1.00e-05\n",
      "\tEpoch 100/100 - Train loss: 0.0007 - Val accuracy: 1.0000 - Val loss: 0.0003 - Val F1: 1.0000 - LR: 0.00e+00\n",
      "\tBest epoch: 100 - Best val accuracy: 1.0000 - Best val loss: 0.0003 - Best val F1: 1.0000\n",
      "\n",
      "Source class: WAL | Domain: 35 | Accuracy: 0.7083 | Loss: 1.7694 | F1: 0.6456\n",
      "\n",
      "Domain: 36\n",
      "x_syn_dom.shape: (336, 3, 128) | np.unique(y_syn_dom): [1 2 3]\n",
      "x_dp_dom.shape: (43, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Training on synthetic data...\n",
      "\tEpoch 10/100 - Train loss: 0.0321 - Val accuracy: 1.0000 - Val loss: 0.0386 - Val F1: 1.0000 - LR: 9.00e-05\n",
      "\tEpoch 20/100 - Train loss: 0.0128 - Val accuracy: 1.0000 - Val loss: 0.0133 - Val F1: 1.0000 - LR: 8.00e-05\n",
      "\tEpoch 30/100 - Train loss: 0.0034 - Val accuracy: 1.0000 - Val loss: 0.0083 - Val F1: 1.0000 - LR: 7.00e-05\n",
      "\tEpoch 40/100 - Train loss: 0.0014 - Val accuracy: 1.0000 - Val loss: 0.0101 - Val F1: 1.0000 - LR: 6.00e-05\n",
      "\tEpoch 50/100 - Train loss: 0.0062 - Val accuracy: 1.0000 - Val loss: 0.0083 - Val F1: 1.0000 - LR: 5.00e-05\n",
      "\tEpoch 60/100 - Train loss: 0.0012 - Val accuracy: 1.0000 - Val loss: 0.0064 - Val F1: 1.0000 - LR: 4.00e-05\n",
      "\tEpoch 70/100 - Train loss: 0.0028 - Val accuracy: 1.0000 - Val loss: 0.0047 - Val F1: 1.0000 - LR: 3.00e-05\n",
      "\tEpoch 80/100 - Train loss: 0.0011 - Val accuracy: 1.0000 - Val loss: 0.0022 - Val F1: 1.0000 - LR: 2.00e-05\n",
      "\tEpoch 90/100 - Train loss: 0.0011 - Val accuracy: 1.0000 - Val loss: 0.0034 - Val F1: 1.0000 - LR: 1.00e-05\n",
      "\tEpoch 100/100 - Train loss: 0.0016 - Val accuracy: 1.0000 - Val loss: 0.0050 - Val F1: 1.0000 - LR: 0.00e+00\n",
      "\tBest epoch: 77 - Best val accuracy: 1.0000 - Best val loss: 0.0019 - Best val F1: 1.0000\n",
      "\n",
      "Source class: WAL | Domain: 36 | Accuracy: 0.7674 | Loss: 1.0823 | F1: 0.7691\n",
      "\n",
      "Domain: 37\n",
      "x_syn_dom.shape: (336, 3, 128) | np.unique(y_syn_dom): [1 2 3]\n",
      "x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Training on synthetic data...\n",
      "\tEpoch 10/100 - Train loss: 0.0853 - Val accuracy: 1.0000 - Val loss: 0.0546 - Val F1: 1.0000 - LR: 9.00e-05\n",
      "\tEpoch 20/100 - Train loss: 0.0143 - Val accuracy: 1.0000 - Val loss: 0.0058 - Val F1: 1.0000 - LR: 8.00e-05\n",
      "\tEpoch 30/100 - Train loss: 0.0041 - Val accuracy: 1.0000 - Val loss: 0.0022 - Val F1: 1.0000 - LR: 7.00e-05\n",
      "\tEpoch 40/100 - Train loss: 0.0026 - Val accuracy: 1.0000 - Val loss: 0.0013 - Val F1: 1.0000 - LR: 6.00e-05\n",
      "\tEpoch 50/100 - Train loss: 0.0028 - Val accuracy: 1.0000 - Val loss: 0.0010 - Val F1: 1.0000 - LR: 5.00e-05\n",
      "\tEpoch 60/100 - Train loss: 0.0018 - Val accuracy: 1.0000 - Val loss: 0.0007 - Val F1: 1.0000 - LR: 4.00e-05\n",
      "\tEpoch 70/100 - Train loss: 0.0012 - Val accuracy: 1.0000 - Val loss: 0.0005 - Val F1: 1.0000 - LR: 3.00e-05\n",
      "\tEpoch 80/100 - Train loss: 0.0009 - Val accuracy: 1.0000 - Val loss: 0.0004 - Val F1: 1.0000 - LR: 2.00e-05\n",
      "\tEpoch 90/100 - Train loss: 0.0008 - Val accuracy: 1.0000 - Val loss: 0.0004 - Val F1: 1.0000 - LR: 1.00e-05\n",
      "\tEpoch 100/100 - Train loss: 0.0020 - Val accuracy: 1.0000 - Val loss: 0.0004 - Val F1: 1.0000 - LR: 0.00e+00\n",
      "\tBest epoch: 98 - Best val accuracy: 1.0000 - Best val loss: 0.0004 - Best val F1: 1.0000\n",
      "\n",
      "Source class: WAL | Domain: 37 | Accuracy: 0.9286 | Loss: 0.2873 | F1: 0.9274\n",
      "\n",
      "Domain: 38\n",
      "x_syn_dom.shape: (333, 3, 128) | np.unique(y_syn_dom): [1 2 3]\n",
      "x_dp_dom.shape: (47, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Training on synthetic data...\n",
      "\tEpoch 10/100 - Train loss: 0.0498 - Val accuracy: 1.0000 - Val loss: 0.0320 - Val F1: 1.0000 - LR: 9.00e-05\n",
      "\tEpoch 20/100 - Train loss: 0.0182 - Val accuracy: 1.0000 - Val loss: 0.0092 - Val F1: 1.0000 - LR: 8.00e-05\n",
      "\tEpoch 30/100 - Train loss: 0.0062 - Val accuracy: 1.0000 - Val loss: 0.0046 - Val F1: 1.0000 - LR: 7.00e-05\n",
      "\tEpoch 40/100 - Train loss: 0.0032 - Val accuracy: 1.0000 - Val loss: 0.0041 - Val F1: 1.0000 - LR: 6.00e-05\n",
      "\tEpoch 50/100 - Train loss: 0.0033 - Val accuracy: 1.0000 - Val loss: 0.0023 - Val F1: 1.0000 - LR: 5.00e-05\n",
      "\tEpoch 60/100 - Train loss: 0.0038 - Val accuracy: 1.0000 - Val loss: 0.0023 - Val F1: 1.0000 - LR: 4.00e-05\n",
      "\tEpoch 70/100 - Train loss: 0.0049 - Val accuracy: 1.0000 - Val loss: 0.0022 - Val F1: 1.0000 - LR: 3.00e-05\n",
      "\tEpoch 80/100 - Train loss: 0.0013 - Val accuracy: 1.0000 - Val loss: 0.0014 - Val F1: 1.0000 - LR: 2.00e-05\n",
      "\tEpoch 90/100 - Train loss: 0.0013 - Val accuracy: 1.0000 - Val loss: 0.0014 - Val F1: 1.0000 - LR: 1.00e-05\n",
      "\tEpoch 100/100 - Train loss: 0.0027 - Val accuracy: 1.0000 - Val loss: 0.0013 - Val F1: 1.0000 - LR: 0.00e+00\n",
      "\tBest epoch: 92 - Best val accuracy: 1.0000 - Best val loss: 0.0011 - Best val F1: 1.0000\n",
      "\n",
      "Source class: WAL | Domain: 38 | Accuracy: 0.3404 | Loss: 9.0834 | F1: 0.3284\n",
      "\n",
      "Domain: 39\n",
      "x_syn_dom.shape: (333, 3, 128) | np.unique(y_syn_dom): [1 2 3]\n",
      "x_dp_dom.shape: (54, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Training on synthetic data...\n",
      "\tEpoch 10/100 - Train loss: 0.0484 - Val accuracy: 1.0000 - Val loss: 0.0520 - Val F1: 1.0000 - LR: 9.00e-05\n",
      "\tEpoch 20/100 - Train loss: 0.0196 - Val accuracy: 1.0000 - Val loss: 0.0114 - Val F1: 1.0000 - LR: 8.00e-05\n",
      "\tEpoch 30/100 - Train loss: 0.0061 - Val accuracy: 1.0000 - Val loss: 0.0051 - Val F1: 1.0000 - LR: 7.00e-05\n",
      "\tEpoch 40/100 - Train loss: 0.0030 - Val accuracy: 1.0000 - Val loss: 0.0075 - Val F1: 1.0000 - LR: 6.00e-05\n",
      "\tEpoch 50/100 - Train loss: 0.0028 - Val accuracy: 1.0000 - Val loss: 0.0065 - Val F1: 1.0000 - LR: 5.00e-05\n",
      "\tEpoch 60/100 - Train loss: 0.0013 - Val accuracy: 1.0000 - Val loss: 0.0039 - Val F1: 1.0000 - LR: 4.00e-05\n",
      "\tEpoch 70/100 - Train loss: 0.0014 - Val accuracy: 1.0000 - Val loss: 0.0023 - Val F1: 1.0000 - LR: 3.00e-05\n",
      "\tEpoch 80/100 - Train loss: 0.0008 - Val accuracy: 1.0000 - Val loss: 0.0020 - Val F1: 1.0000 - LR: 2.00e-05\n",
      "\tEpoch 90/100 - Train loss: 0.0012 - Val accuracy: 1.0000 - Val loss: 0.0051 - Val F1: 1.0000 - LR: 1.00e-05\n",
      "\tEpoch 100/100 - Train loss: 0.0005 - Val accuracy: 1.0000 - Val loss: 0.0033 - Val F1: 1.0000 - LR: 0.00e+00\n",
      "\tBest epoch: 71 - Best val accuracy: 1.0000 - Best val loss: 0.0018 - Best val F1: 1.0000\n",
      "\n",
      "Source class: WAL | Domain: 39 | Accuracy: 0.4815 | Loss: 4.8014 | F1: 0.4024\n",
      "\n",
      "Domain: 40\n",
      "x_syn_dom.shape: (333, 3, 128) | np.unique(y_syn_dom): [1 2 3]\n",
      "x_dp_dom.shape: (44, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Training on synthetic data...\n",
      "\tEpoch 10/100 - Train loss: 0.0609 - Val accuracy: 1.0000 - Val loss: 0.0615 - Val F1: 1.0000 - LR: 9.00e-05\n",
      "\tEpoch 20/100 - Train loss: 0.0075 - Val accuracy: 1.0000 - Val loss: 0.0096 - Val F1: 1.0000 - LR: 8.00e-05\n",
      "\tEpoch 30/100 - Train loss: 0.0045 - Val accuracy: 1.0000 - Val loss: 0.0039 - Val F1: 1.0000 - LR: 7.00e-05\n",
      "\tEpoch 40/100 - Train loss: 0.0020 - Val accuracy: 1.0000 - Val loss: 0.0023 - Val F1: 1.0000 - LR: 6.00e-05\n",
      "\tEpoch 50/100 - Train loss: 0.0017 - Val accuracy: 1.0000 - Val loss: 0.0015 - Val F1: 1.0000 - LR: 5.00e-05\n",
      "\tEpoch 60/100 - Train loss: 0.0009 - Val accuracy: 1.0000 - Val loss: 0.0012 - Val F1: 1.0000 - LR: 4.00e-05\n",
      "\tEpoch 70/100 - Train loss: 0.0010 - Val accuracy: 1.0000 - Val loss: 0.0010 - Val F1: 1.0000 - LR: 3.00e-05\n",
      "\tEpoch 80/100 - Train loss: 0.0008 - Val accuracy: 1.0000 - Val loss: 0.0009 - Val F1: 1.0000 - LR: 2.00e-05\n",
      "\tEpoch 90/100 - Train loss: 0.0011 - Val accuracy: 1.0000 - Val loss: 0.0008 - Val F1: 1.0000 - LR: 1.00e-05\n",
      "\tEpoch 100/100 - Train loss: 0.0007 - Val accuracy: 1.0000 - Val loss: 0.0008 - Val F1: 1.0000 - LR: 0.00e+00\n",
      "\tBest epoch: 91 - Best val accuracy: 1.0000 - Best val loss: 0.0008 - Best val F1: 1.0000\n",
      "\n",
      "Source class: WAL | Domain: 40 | Accuracy: 0.7727 | Loss: 0.6601 | F1: 0.7915\n",
      "\n",
      "Domain: 41\n",
      "x_syn_dom.shape: (333, 3, 128) | np.unique(y_syn_dom): [1 2 3]\n",
      "x_dp_dom.shape: (45, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Training on synthetic data...\n",
      "\tEpoch 10/100 - Train loss: 0.0525 - Val accuracy: 0.9403 - Val loss: 0.1426 - Val F1: 0.9398 - LR: 9.00e-05\n",
      "\tEpoch 20/100 - Train loss: 0.0079 - Val accuracy: 0.9403 - Val loss: 0.1986 - Val F1: 0.9398 - LR: 8.00e-05\n",
      "\tEpoch 30/100 - Train loss: 0.0051 - Val accuracy: 0.9403 - Val loss: 0.1942 - Val F1: 0.9398 - LR: 7.00e-05\n",
      "\tEpoch 40/100 - Train loss: 0.0023 - Val accuracy: 0.9403 - Val loss: 0.2337 - Val F1: 0.9398 - LR: 6.00e-05\n",
      "\tEpoch 50/100 - Train loss: 0.0026 - Val accuracy: 0.9403 - Val loss: 0.2688 - Val F1: 0.9398 - LR: 5.00e-05\n",
      "\tEpoch 60/100 - Train loss: 0.0011 - Val accuracy: 0.9552 - Val loss: 0.2438 - Val F1: 0.9550 - LR: 4.00e-05\n",
      "\tEpoch 70/100 - Train loss: 0.0020 - Val accuracy: 0.9403 - Val loss: 0.2631 - Val F1: 0.9398 - LR: 3.00e-05\n",
      "\tEpoch 80/100 - Train loss: 0.0007 - Val accuracy: 0.9403 - Val loss: 0.2886 - Val F1: 0.9398 - LR: 2.00e-05\n",
      "\tEpoch 90/100 - Train loss: 0.0009 - Val accuracy: 0.9403 - Val loss: 0.2848 - Val F1: 0.9398 - LR: 1.00e-05\n",
      "\tEpoch 100/100 - Train loss: 0.0009 - Val accuracy: 0.9403 - Val loss: 0.2953 - Val F1: 0.9398 - LR: 0.00e+00\n",
      "\tBest epoch: 10 - Best val accuracy: 0.9403 - Best val loss: 0.1426 - Best val F1: 0.9398\n",
      "\n",
      "Source class: WAL | Domain: 41 | Accuracy: 0.5778 | Loss: 1.9759 | F1: 0.5213\n",
      "\n",
      "Domain: 42\n",
      "x_syn_dom.shape: (336, 3, 128) | np.unique(y_syn_dom): [1 2 3]\n",
      "x_dp_dom.shape: (46, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Training on synthetic data...\n",
      "\tEpoch 10/100 - Train loss: 0.0499 - Val accuracy: 1.0000 - Val loss: 0.0309 - Val F1: 1.0000 - LR: 9.00e-05\n",
      "\tEpoch 20/100 - Train loss: 0.0095 - Val accuracy: 1.0000 - Val loss: 0.0041 - Val F1: 1.0000 - LR: 8.00e-05\n",
      "\tEpoch 30/100 - Train loss: 0.0031 - Val accuracy: 1.0000 - Val loss: 0.0020 - Val F1: 1.0000 - LR: 7.00e-05\n",
      "\tEpoch 40/100 - Train loss: 0.0023 - Val accuracy: 1.0000 - Val loss: 0.0011 - Val F1: 1.0000 - LR: 6.00e-05\n",
      "\tEpoch 50/100 - Train loss: 0.0025 - Val accuracy: 1.0000 - Val loss: 0.0007 - Val F1: 1.0000 - LR: 5.00e-05\n",
      "\tEpoch 60/100 - Train loss: 0.0008 - Val accuracy: 1.0000 - Val loss: 0.0006 - Val F1: 1.0000 - LR: 4.00e-05\n",
      "\tEpoch 70/100 - Train loss: 0.0009 - Val accuracy: 1.0000 - Val loss: 0.0005 - Val F1: 1.0000 - LR: 3.00e-05\n",
      "\tEpoch 80/100 - Train loss: 0.0012 - Val accuracy: 1.0000 - Val loss: 0.0004 - Val F1: 1.0000 - LR: 2.00e-05\n",
      "\tEpoch 90/100 - Train loss: 0.0009 - Val accuracy: 1.0000 - Val loss: 0.0004 - Val F1: 1.0000 - LR: 1.00e-05\n",
      "\tEpoch 100/100 - Train loss: 0.0008 - Val accuracy: 1.0000 - Val loss: 0.0004 - Val F1: 1.0000 - LR: 0.00e+00\n",
      "\tBest epoch: 100 - Best val accuracy: 1.0000 - Best val loss: 0.0004 - Best val F1: 1.0000\n",
      "\n",
      "Source class: WAL | Domain: 42 | Accuracy: 0.6087 | Loss: 2.5156 | F1: 0.6154\n",
      "\n",
      "Domain: 43\n",
      "x_syn_dom.shape: (333, 3, 128) | np.unique(y_syn_dom): [1 2 3]\n",
      "x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Training on synthetic data...\n",
      "\tEpoch 10/100 - Train loss: 0.0255 - Val accuracy: 1.0000 - Val loss: 0.0094 - Val F1: 1.0000 - LR: 9.00e-05\n",
      "\tEpoch 20/100 - Train loss: 0.0086 - Val accuracy: 1.0000 - Val loss: 0.0030 - Val F1: 1.0000 - LR: 8.00e-05\n",
      "\tEpoch 30/100 - Train loss: 0.0050 - Val accuracy: 1.0000 - Val loss: 0.0016 - Val F1: 1.0000 - LR: 7.00e-05\n",
      "\tEpoch 40/100 - Train loss: 0.0021 - Val accuracy: 1.0000 - Val loss: 0.0009 - Val F1: 1.0000 - LR: 6.00e-05\n",
      "\tEpoch 50/100 - Train loss: 0.0024 - Val accuracy: 1.0000 - Val loss: 0.0007 - Val F1: 1.0000 - LR: 5.00e-05\n",
      "\tEpoch 60/100 - Train loss: 0.0071 - Val accuracy: 1.0000 - Val loss: 0.0007 - Val F1: 1.0000 - LR: 4.00e-05\n",
      "\tEpoch 70/100 - Train loss: 0.0013 - Val accuracy: 1.0000 - Val loss: 0.0005 - Val F1: 1.0000 - LR: 3.00e-05\n",
      "\tEpoch 80/100 - Train loss: 0.0009 - Val accuracy: 1.0000 - Val loss: 0.0004 - Val F1: 1.0000 - LR: 2.00e-05\n",
      "\tEpoch 90/100 - Train loss: 0.0072 - Val accuracy: 1.0000 - Val loss: 0.0004 - Val F1: 1.0000 - LR: 1.00e-05\n",
      "\tEpoch 100/100 - Train loss: 0.0019 - Val accuracy: 1.0000 - Val loss: 0.0004 - Val F1: 1.0000 - LR: 0.00e+00\n",
      "\tBest epoch: 100 - Best val accuracy: 1.0000 - Best val loss: 0.0004 - Best val F1: 1.0000\n",
      "\n",
      "Source class: WAL | Domain: 43 | Accuracy: 0.6905 | Loss: 1.4138 | F1: 0.5827\n",
      "\n",
      "Domain: 44\n",
      "x_syn_dom.shape: (333, 3, 128) | np.unique(y_syn_dom): [1 2 3]\n",
      "x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Training on synthetic data...\n",
      "\tEpoch 10/100 - Train loss: 0.1432 - Val accuracy: 0.9701 - Val loss: 0.1370 - Val F1: 0.9701 - LR: 9.00e-05\n",
      "\tEpoch 20/100 - Train loss: 0.0279 - Val accuracy: 1.0000 - Val loss: 0.0219 - Val F1: 1.0000 - LR: 8.00e-05\n",
      "\tEpoch 30/100 - Train loss: 0.0066 - Val accuracy: 1.0000 - Val loss: 0.0108 - Val F1: 1.0000 - LR: 7.00e-05\n",
      "\tEpoch 40/100 - Train loss: 0.0030 - Val accuracy: 1.0000 - Val loss: 0.0082 - Val F1: 1.0000 - LR: 6.00e-05\n",
      "\tEpoch 50/100 - Train loss: 0.0020 - Val accuracy: 1.0000 - Val loss: 0.0079 - Val F1: 1.0000 - LR: 5.00e-05\n",
      "\tEpoch 60/100 - Train loss: 0.0018 - Val accuracy: 1.0000 - Val loss: 0.0052 - Val F1: 1.0000 - LR: 4.00e-05\n",
      "\tEpoch 70/100 - Train loss: 0.0017 - Val accuracy: 1.0000 - Val loss: 0.0095 - Val F1: 1.0000 - LR: 3.00e-05\n",
      "\tEpoch 80/100 - Train loss: 0.0020 - Val accuracy: 1.0000 - Val loss: 0.0031 - Val F1: 1.0000 - LR: 2.00e-05\n",
      "\tEpoch 90/100 - Train loss: 0.0011 - Val accuracy: 1.0000 - Val loss: 0.0043 - Val F1: 1.0000 - LR: 1.00e-05\n",
      "\tEpoch 100/100 - Train loss: 0.0014 - Val accuracy: 1.0000 - Val loss: 0.0042 - Val F1: 1.0000 - LR: 0.00e+00\n",
      "\tBest epoch: 80 - Best val accuracy: 1.0000 - Best val loss: 0.0031 - Best val F1: 1.0000\n",
      "\n",
      "Source class: WAL | Domain: 44 | Accuracy: 0.8810 | Loss: 0.2044 | F1: 0.8803\n",
      "\n",
      "Domain: 45\n",
      "x_syn_dom.shape: (333, 3, 128) | np.unique(y_syn_dom): [1 2 3]\n",
      "x_dp_dom.shape: (52, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Training on synthetic data...\n",
      "\tEpoch 10/100 - Train loss: 0.0571 - Val accuracy: 0.9851 - Val loss: 0.0513 - Val F1: 0.9851 - LR: 9.00e-05\n",
      "\tEpoch 20/100 - Train loss: 0.0047 - Val accuracy: 1.0000 - Val loss: 0.0112 - Val F1: 1.0000 - LR: 8.00e-05\n",
      "\tEpoch 30/100 - Train loss: 0.0043 - Val accuracy: 1.0000 - Val loss: 0.0051 - Val F1: 1.0000 - LR: 7.00e-05\n",
      "\tEpoch 40/100 - Train loss: 0.0012 - Val accuracy: 1.0000 - Val loss: 0.0024 - Val F1: 1.0000 - LR: 6.00e-05\n",
      "\tEpoch 50/100 - Train loss: 0.0009 - Val accuracy: 1.0000 - Val loss: 0.0012 - Val F1: 1.0000 - LR: 5.00e-05\n",
      "\tEpoch 60/100 - Train loss: 0.0007 - Val accuracy: 1.0000 - Val loss: 0.0010 - Val F1: 1.0000 - LR: 4.00e-05\n",
      "\tEpoch 70/100 - Train loss: 0.0008 - Val accuracy: 1.0000 - Val loss: 0.0010 - Val F1: 1.0000 - LR: 3.00e-05\n",
      "\tEpoch 80/100 - Train loss: 0.0006 - Val accuracy: 1.0000 - Val loss: 0.0010 - Val F1: 1.0000 - LR: 2.00e-05\n",
      "\tEpoch 90/100 - Train loss: 0.0004 - Val accuracy: 1.0000 - Val loss: 0.0007 - Val F1: 1.0000 - LR: 1.00e-05\n",
      "\tEpoch 100/100 - Train loss: 0.0005 - Val accuracy: 1.0000 - Val loss: 0.0006 - Val F1: 1.0000 - LR: 0.00e+00\n",
      "\tBest epoch: 83 - Best val accuracy: 1.0000 - Best val loss: 0.0005 - Best val F1: 1.0000\n",
      "\n",
      "Source class: WAL | Domain: 45 | Accuracy: 0.8462 | Loss: 0.4599 | F1: 0.8203\n",
      "\n",
      "Domain: 46\n",
      "x_syn_dom.shape: (336, 3, 128) | np.unique(y_syn_dom): [1 2 3]\n",
      "x_dp_dom.shape: (48, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Training on synthetic data...\n",
      "\tEpoch 10/100 - Train loss: 0.0612 - Val accuracy: 1.0000 - Val loss: 0.0469 - Val F1: 1.0000 - LR: 9.00e-05\n",
      "\tEpoch 20/100 - Train loss: 0.0075 - Val accuracy: 1.0000 - Val loss: 0.0078 - Val F1: 1.0000 - LR: 8.00e-05\n",
      "\tEpoch 30/100 - Train loss: 0.0031 - Val accuracy: 1.0000 - Val loss: 0.0030 - Val F1: 1.0000 - LR: 7.00e-05\n",
      "\tEpoch 40/100 - Train loss: 0.0052 - Val accuracy: 1.0000 - Val loss: 0.0019 - Val F1: 1.0000 - LR: 6.00e-05\n",
      "\tEpoch 50/100 - Train loss: 0.0044 - Val accuracy: 1.0000 - Val loss: 0.0021 - Val F1: 1.0000 - LR: 5.00e-05\n",
      "\tEpoch 60/100 - Train loss: 0.0015 - Val accuracy: 1.0000 - Val loss: 0.0009 - Val F1: 1.0000 - LR: 4.00e-05\n",
      "\tEpoch 70/100 - Train loss: 0.0013 - Val accuracy: 1.0000 - Val loss: 0.0013 - Val F1: 1.0000 - LR: 3.00e-05\n",
      "\tEpoch 80/100 - Train loss: 0.0007 - Val accuracy: 1.0000 - Val loss: 0.0010 - Val F1: 1.0000 - LR: 2.00e-05\n",
      "\tEpoch 90/100 - Train loss: 0.0011 - Val accuracy: 1.0000 - Val loss: 0.0006 - Val F1: 1.0000 - LR: 1.00e-05\n",
      "\tEpoch 100/100 - Train loss: 0.0012 - Val accuracy: 1.0000 - Val loss: 0.0006 - Val F1: 1.0000 - LR: 0.00e+00\n",
      "\tBest epoch: 95 - Best val accuracy: 1.0000 - Best val loss: 0.0005 - Best val F1: 1.0000\n",
      "\n",
      "Source class: WAL | Domain: 46 | Accuracy: 0.9375 | Loss: 0.1861 | F1: 0.9363\n",
      "\n",
      "Domain: 47\n",
      "x_syn_dom.shape: (333, 3, 128) | np.unique(y_syn_dom): [1 2 3]\n",
      "x_dp_dom.shape: (44, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Training on synthetic data...\n",
      "\tEpoch 10/100 - Train loss: 0.0333 - Val accuracy: 0.9851 - Val loss: 0.0473 - Val F1: 0.9851 - LR: 9.00e-05\n",
      "\tEpoch 20/100 - Train loss: 0.0053 - Val accuracy: 0.9851 - Val loss: 0.0390 - Val F1: 0.9851 - LR: 8.00e-05\n",
      "\tEpoch 30/100 - Train loss: 0.0047 - Val accuracy: 0.9851 - Val loss: 0.0329 - Val F1: 0.9851 - LR: 7.00e-05\n",
      "\tEpoch 40/100 - Train loss: 0.0016 - Val accuracy: 0.9851 - Val loss: 0.0470 - Val F1: 0.9851 - LR: 6.00e-05\n",
      "\tEpoch 50/100 - Train loss: 0.0009 - Val accuracy: 0.9851 - Val loss: 0.0327 - Val F1: 0.9851 - LR: 5.00e-05\n",
      "\tEpoch 60/100 - Train loss: 0.0014 - Val accuracy: 0.9851 - Val loss: 0.0340 - Val F1: 0.9851 - LR: 4.00e-05\n",
      "\tEpoch 70/100 - Train loss: 0.0005 - Val accuracy: 0.9851 - Val loss: 0.0392 - Val F1: 0.9851 - LR: 3.00e-05\n",
      "\tEpoch 80/100 - Train loss: 0.0004 - Val accuracy: 0.9851 - Val loss: 0.0397 - Val F1: 0.9851 - LR: 2.00e-05\n",
      "\tEpoch 90/100 - Train loss: 0.0009 - Val accuracy: 0.9851 - Val loss: 0.0424 - Val F1: 0.9851 - LR: 1.00e-05\n",
      "\tEpoch 100/100 - Train loss: 0.0006 - Val accuracy: 0.9851 - Val loss: 0.0454 - Val F1: 0.9851 - LR: 0.00e+00\n",
      "\tBest epoch: 25 - Best val accuracy: 0.9851 - Best val loss: 0.0248 - Best val F1: 0.9851\n",
      "\n",
      "Source class: WAL | Domain: 47 | Accuracy: 0.7955 | Loss: 0.6431 | F1: 0.7859\n",
      "\n",
      "Domain: 48\n",
      "x_syn_dom.shape: (333, 3, 128) | np.unique(y_syn_dom): [1 2 3]\n",
      "x_dp_dom.shape: (48, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Training on synthetic data...\n",
      "\tEpoch 10/100 - Train loss: 0.1185 - Val accuracy: 0.9851 - Val loss: 0.0897 - Val F1: 0.9851 - LR: 9.00e-05\n",
      "\tEpoch 20/100 - Train loss: 0.0171 - Val accuracy: 0.9851 - Val loss: 0.0528 - Val F1: 0.9851 - LR: 8.00e-05\n",
      "\tEpoch 30/100 - Train loss: 0.0067 - Val accuracy: 0.9851 - Val loss: 0.0530 - Val F1: 0.9851 - LR: 7.00e-05\n",
      "\tEpoch 40/100 - Train loss: 0.0024 - Val accuracy: 0.9851 - Val loss: 0.0613 - Val F1: 0.9851 - LR: 6.00e-05\n",
      "\tEpoch 50/100 - Train loss: 0.0036 - Val accuracy: 0.9851 - Val loss: 0.0507 - Val F1: 0.9851 - LR: 5.00e-05\n",
      "\tEpoch 60/100 - Train loss: 0.0016 - Val accuracy: 0.9851 - Val loss: 0.0615 - Val F1: 0.9851 - LR: 4.00e-05\n",
      "\tEpoch 70/100 - Train loss: 0.0036 - Val accuracy: 0.9851 - Val loss: 0.0651 - Val F1: 0.9851 - LR: 3.00e-05\n",
      "\tEpoch 80/100 - Train loss: 0.0011 - Val accuracy: 0.9851 - Val loss: 0.0692 - Val F1: 0.9851 - LR: 2.00e-05\n",
      "\tEpoch 90/100 - Train loss: 0.0011 - Val accuracy: 0.9851 - Val loss: 0.0530 - Val F1: 0.9851 - LR: 1.00e-05\n",
      "\tEpoch 100/100 - Train loss: 0.0014 - Val accuracy: 0.9851 - Val loss: 0.0603 - Val F1: 0.9851 - LR: 0.00e+00\n",
      "\tBest epoch: 21 - Best val accuracy: 0.9851 - Best val loss: 0.0498 - Best val F1: 0.9851\n",
      "\n",
      "Source class: WAL | Domain: 48 | Accuracy: 0.8333 | Loss: 0.7160 | F1: 0.7666\n",
      "\n",
      "Domain: 49\n",
      "x_syn_dom.shape: (333, 3, 128) | np.unique(y_syn_dom): [1 2 3]\n",
      "x_dp_dom.shape: (53, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Training on synthetic data...\n",
      "\tEpoch 10/100 - Train loss: 0.0640 - Val accuracy: 1.0000 - Val loss: 0.0534 - Val F1: 1.0000 - LR: 9.00e-05\n",
      "\tEpoch 20/100 - Train loss: 0.0060 - Val accuracy: 1.0000 - Val loss: 0.0083 - Val F1: 1.0000 - LR: 8.00e-05\n",
      "\tEpoch 30/100 - Train loss: 0.0034 - Val accuracy: 1.0000 - Val loss: 0.0038 - Val F1: 1.0000 - LR: 7.00e-05\n",
      "\tEpoch 40/100 - Train loss: 0.0020 - Val accuracy: 1.0000 - Val loss: 0.0026 - Val F1: 1.0000 - LR: 6.00e-05\n",
      "\tEpoch 50/100 - Train loss: 0.0009 - Val accuracy: 1.0000 - Val loss: 0.0023 - Val F1: 1.0000 - LR: 5.00e-05\n",
      "\tEpoch 60/100 - Train loss: 0.0008 - Val accuracy: 1.0000 - Val loss: 0.0018 - Val F1: 1.0000 - LR: 4.00e-05\n",
      "\tEpoch 70/100 - Train loss: 0.0009 - Val accuracy: 1.0000 - Val loss: 0.0016 - Val F1: 1.0000 - LR: 3.00e-05\n",
      "\tEpoch 80/100 - Train loss: 0.0009 - Val accuracy: 1.0000 - Val loss: 0.0015 - Val F1: 1.0000 - LR: 2.00e-05\n",
      "\tEpoch 90/100 - Train loss: 0.0007 - Val accuracy: 1.0000 - Val loss: 0.0016 - Val F1: 1.0000 - LR: 1.00e-05\n",
      "\tEpoch 100/100 - Train loss: 0.0006 - Val accuracy: 1.0000 - Val loss: 0.0013 - Val F1: 1.0000 - LR: 0.00e+00\n",
      "\tBest epoch: 92 - Best val accuracy: 1.0000 - Best val loss: 0.0012 - Best val F1: 1.0000\n",
      "\n",
      "Source class: WAL | Domain: 49 | Accuracy: 0.7925 | Loss: 0.6891 | F1: 0.7355\n",
      "\n",
      "Domain: 50\n",
      "x_syn_dom.shape: (333, 3, 128) | np.unique(y_syn_dom): [1 2 3]\n",
      "x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Training on synthetic data...\n",
      "\tEpoch 10/100 - Train loss: 0.0507 - Val accuracy: 1.0000 - Val loss: 0.0248 - Val F1: 1.0000 - LR: 9.00e-05\n",
      "\tEpoch 20/100 - Train loss: 0.0069 - Val accuracy: 1.0000 - Val loss: 0.0076 - Val F1: 1.0000 - LR: 8.00e-05\n",
      "\tEpoch 30/100 - Train loss: 0.0106 - Val accuracy: 1.0000 - Val loss: 0.0052 - Val F1: 1.0000 - LR: 7.00e-05\n",
      "\tEpoch 40/100 - Train loss: 0.0034 - Val accuracy: 1.0000 - Val loss: 0.0015 - Val F1: 1.0000 - LR: 6.00e-05\n",
      "\tEpoch 50/100 - Train loss: 0.0012 - Val accuracy: 1.0000 - Val loss: 0.0020 - Val F1: 1.0000 - LR: 5.00e-05\n",
      "\tEpoch 60/100 - Train loss: 0.0007 - Val accuracy: 1.0000 - Val loss: 0.0026 - Val F1: 1.0000 - LR: 4.00e-05\n",
      "\tEpoch 70/100 - Train loss: 0.0010 - Val accuracy: 1.0000 - Val loss: 0.0026 - Val F1: 1.0000 - LR: 3.00e-05\n",
      "\tEpoch 80/100 - Train loss: 0.0005 - Val accuracy: 1.0000 - Val loss: 0.0020 - Val F1: 1.0000 - LR: 2.00e-05\n",
      "\tEpoch 90/100 - Train loss: 0.0007 - Val accuracy: 1.0000 - Val loss: 0.0017 - Val F1: 1.0000 - LR: 1.00e-05\n",
      "\tEpoch 100/100 - Train loss: 0.0020 - Val accuracy: 1.0000 - Val loss: 0.0019 - Val F1: 1.0000 - LR: 0.00e+00\n",
      "\tBest epoch: 64 - Best val accuracy: 1.0000 - Best val loss: 0.0011 - Best val F1: 1.0000\n",
      "\n",
      "Source class: WAL | Domain: 50 | Accuracy: 0.8571 | Loss: 0.5733 | F1: 0.8097\n",
      "\n",
      "Domain: 51\n",
      "x_syn_dom.shape: (333, 3, 128) | np.unique(y_syn_dom): [1 2 3]\n",
      "x_dp_dom.shape: (46, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Training on synthetic data...\n",
      "\tEpoch 10/100 - Train loss: 0.0955 - Val accuracy: 0.9851 - Val loss: 0.0609 - Val F1: 0.9851 - LR: 9.00e-05\n",
      "\tEpoch 20/100 - Train loss: 0.0198 - Val accuracy: 1.0000 - Val loss: 0.0098 - Val F1: 1.0000 - LR: 8.00e-05\n",
      "\tEpoch 30/100 - Train loss: 0.0073 - Val accuracy: 1.0000 - Val loss: 0.0060 - Val F1: 1.0000 - LR: 7.00e-05\n",
      "\tEpoch 40/100 - Train loss: 0.0029 - Val accuracy: 1.0000 - Val loss: 0.0047 - Val F1: 1.0000 - LR: 6.00e-05\n",
      "\tEpoch 50/100 - Train loss: 0.0027 - Val accuracy: 1.0000 - Val loss: 0.0025 - Val F1: 1.0000 - LR: 5.00e-05\n",
      "\tEpoch 60/100 - Train loss: 0.0038 - Val accuracy: 1.0000 - Val loss: 0.0022 - Val F1: 1.0000 - LR: 4.00e-05\n",
      "\tEpoch 70/100 - Train loss: 0.0014 - Val accuracy: 1.0000 - Val loss: 0.0022 - Val F1: 1.0000 - LR: 3.00e-05\n",
      "\tEpoch 80/100 - Train loss: 0.0024 - Val accuracy: 1.0000 - Val loss: 0.0020 - Val F1: 1.0000 - LR: 2.00e-05\n",
      "\tEpoch 90/100 - Train loss: 0.0016 - Val accuracy: 1.0000 - Val loss: 0.0025 - Val F1: 1.0000 - LR: 1.00e-05\n",
      "\tEpoch 100/100 - Train loss: 0.0023 - Val accuracy: 1.0000 - Val loss: 0.0016 - Val F1: 1.0000 - LR: 0.00e+00\n",
      "\tBest epoch: 72 - Best val accuracy: 1.0000 - Best val loss: 0.0013 - Best val F1: 1.0000\n",
      "\n",
      "Source class: WAL | Domain: 51 | Accuracy: 0.7826 | Loss: 1.3848 | F1: 0.7318\n",
      "\n",
      "Domain: 52\n",
      "x_syn_dom.shape: (333, 3, 128) | np.unique(y_syn_dom): [1 2 3]\n",
      "x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Training on synthetic data...\n",
      "\tEpoch 10/100 - Train loss: 0.0517 - Val accuracy: 1.0000 - Val loss: 0.0292 - Val F1: 1.0000 - LR: 9.00e-05\n",
      "\tEpoch 20/100 - Train loss: 0.0124 - Val accuracy: 1.0000 - Val loss: 0.0097 - Val F1: 1.0000 - LR: 8.00e-05\n",
      "\tEpoch 30/100 - Train loss: 0.0033 - Val accuracy: 1.0000 - Val loss: 0.0041 - Val F1: 1.0000 - LR: 7.00e-05\n",
      "\tEpoch 40/100 - Train loss: 0.0012 - Val accuracy: 1.0000 - Val loss: 0.0043 - Val F1: 1.0000 - LR: 6.00e-05\n",
      "\tEpoch 50/100 - Train loss: 0.0013 - Val accuracy: 1.0000 - Val loss: 0.0029 - Val F1: 1.0000 - LR: 5.00e-05\n",
      "\tEpoch 60/100 - Train loss: 0.0015 - Val accuracy: 1.0000 - Val loss: 0.0034 - Val F1: 1.0000 - LR: 4.00e-05\n",
      "\tEpoch 70/100 - Train loss: 0.0008 - Val accuracy: 1.0000 - Val loss: 0.0029 - Val F1: 1.0000 - LR: 3.00e-05\n",
      "\tEpoch 80/100 - Train loss: 0.0012 - Val accuracy: 1.0000 - Val loss: 0.0011 - Val F1: 1.0000 - LR: 2.00e-05\n",
      "\tEpoch 90/100 - Train loss: 0.0007 - Val accuracy: 1.0000 - Val loss: 0.0014 - Val F1: 1.0000 - LR: 1.00e-05\n",
      "\tEpoch 100/100 - Train loss: 0.0008 - Val accuracy: 1.0000 - Val loss: 0.0016 - Val F1: 1.0000 - LR: 0.00e+00\n",
      "\tBest epoch: 78 - Best val accuracy: 1.0000 - Best val loss: 0.0011 - Best val F1: 1.0000\n",
      "\n",
      "Source class: WAL | Domain: 52 | Accuracy: 0.8095 | Loss: 1.1425 | F1: 0.7606\n",
      "\n",
      "Domain: 53\n",
      "x_syn_dom.shape: (333, 3, 128) | np.unique(y_syn_dom): [1 2 3]\n",
      "x_dp_dom.shape: (48, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Training on synthetic data...\n",
      "\tEpoch 10/100 - Train loss: 0.0378 - Val accuracy: 1.0000 - Val loss: 0.0257 - Val F1: 1.0000 - LR: 9.00e-05\n",
      "\tEpoch 20/100 - Train loss: 0.0063 - Val accuracy: 1.0000 - Val loss: 0.0051 - Val F1: 1.0000 - LR: 8.00e-05\n",
      "\tEpoch 30/100 - Train loss: 0.0046 - Val accuracy: 1.0000 - Val loss: 0.0025 - Val F1: 1.0000 - LR: 7.00e-05\n",
      "\tEpoch 40/100 - Train loss: 0.0026 - Val accuracy: 1.0000 - Val loss: 0.0014 - Val F1: 1.0000 - LR: 6.00e-05\n",
      "\tEpoch 50/100 - Train loss: 0.0016 - Val accuracy: 1.0000 - Val loss: 0.0011 - Val F1: 1.0000 - LR: 5.00e-05\n",
      "\tEpoch 60/100 - Train loss: 0.0012 - Val accuracy: 1.0000 - Val loss: 0.0008 - Val F1: 1.0000 - LR: 4.00e-05\n",
      "\tEpoch 70/100 - Train loss: 0.0011 - Val accuracy: 1.0000 - Val loss: 0.0010 - Val F1: 1.0000 - LR: 3.00e-05\n",
      "\tEpoch 80/100 - Train loss: 0.0008 - Val accuracy: 1.0000 - Val loss: 0.0006 - Val F1: 1.0000 - LR: 2.00e-05\n",
      "\tEpoch 90/100 - Train loss: 0.0012 - Val accuracy: 1.0000 - Val loss: 0.0006 - Val F1: 1.0000 - LR: 1.00e-05\n",
      "\tEpoch 100/100 - Train loss: 0.0125 - Val accuracy: 1.0000 - Val loss: 0.0006 - Val F1: 1.0000 - LR: 0.00e+00\n",
      "\tBest epoch: 97 - Best val accuracy: 1.0000 - Best val loss: 0.0005 - Best val F1: 1.0000\n",
      "\n",
      "Source class: WAL | Domain: 53 | Accuracy: 0.8125 | Loss: 2.1901 | F1: 0.7392\n",
      "\n",
      "Domain: 54\n",
      "x_syn_dom.shape: (333, 3, 128) | np.unique(y_syn_dom): [1 2 3]\n",
      "x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Training on synthetic data...\n",
      "\tEpoch 10/100 - Train loss: 0.0420 - Val accuracy: 1.0000 - Val loss: 0.0387 - Val F1: 1.0000 - LR: 9.00e-05\n",
      "\tEpoch 20/100 - Train loss: 0.0064 - Val accuracy: 1.0000 - Val loss: 0.0082 - Val F1: 1.0000 - LR: 8.00e-05\n",
      "\tEpoch 30/100 - Train loss: 0.0043 - Val accuracy: 1.0000 - Val loss: 0.0041 - Val F1: 1.0000 - LR: 7.00e-05\n",
      "\tEpoch 40/100 - Train loss: 0.0032 - Val accuracy: 1.0000 - Val loss: 0.0028 - Val F1: 1.0000 - LR: 6.00e-05\n",
      "\tEpoch 50/100 - Train loss: 0.0011 - Val accuracy: 1.0000 - Val loss: 0.0019 - Val F1: 1.0000 - LR: 5.00e-05\n",
      "\tEpoch 60/100 - Train loss: 0.0012 - Val accuracy: 1.0000 - Val loss: 0.0015 - Val F1: 1.0000 - LR: 4.00e-05\n",
      "\tEpoch 70/100 - Train loss: 0.0011 - Val accuracy: 1.0000 - Val loss: 0.0013 - Val F1: 1.0000 - LR: 3.00e-05\n",
      "\tEpoch 80/100 - Train loss: 0.0009 - Val accuracy: 1.0000 - Val loss: 0.0012 - Val F1: 1.0000 - LR: 2.00e-05\n",
      "\tEpoch 90/100 - Train loss: 0.0005 - Val accuracy: 1.0000 - Val loss: 0.0012 - Val F1: 1.0000 - LR: 1.00e-05\n",
      "\tEpoch 100/100 - Train loss: 0.0007 - Val accuracy: 1.0000 - Val loss: 0.0012 - Val F1: 1.0000 - LR: 0.00e+00\n",
      "\tBest epoch: 99 - Best val accuracy: 1.0000 - Best val loss: 0.0011 - Best val F1: 1.0000\n",
      "\n",
      "Source class: WAL | Domain: 54 | Accuracy: 0.3810 | Loss: 3.6696 | F1: 0.4102\n",
      "\n",
      "Domain: 55\n",
      "x_syn_dom.shape: (333, 3, 128) | np.unique(y_syn_dom): [1 2 3]\n",
      "x_dp_dom.shape: (49, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Training on synthetic data...\n",
      "\tEpoch 10/100 - Train loss: 0.0362 - Val accuracy: 0.9851 - Val loss: 0.0529 - Val F1: 0.9851 - LR: 9.00e-05\n",
      "\tEpoch 20/100 - Train loss: 0.0065 - Val accuracy: 0.9851 - Val loss: 0.0417 - Val F1: 0.9851 - LR: 8.00e-05\n",
      "\tEpoch 30/100 - Train loss: 0.0023 - Val accuracy: 0.9851 - Val loss: 0.0378 - Val F1: 0.9851 - LR: 7.00e-05\n",
      "\tEpoch 40/100 - Train loss: 0.0017 - Val accuracy: 0.9851 - Val loss: 0.0311 - Val F1: 0.9851 - LR: 6.00e-05\n",
      "\tEpoch 50/100 - Train loss: 0.0006 - Val accuracy: 0.9851 - Val loss: 0.0289 - Val F1: 0.9851 - LR: 5.00e-05\n",
      "\tEpoch 60/100 - Train loss: 0.0007 - Val accuracy: 0.9851 - Val loss: 0.0341 - Val F1: 0.9851 - LR: 4.00e-05\n",
      "\tEpoch 70/100 - Train loss: 0.0008 - Val accuracy: 0.9851 - Val loss: 0.0285 - Val F1: 0.9851 - LR: 3.00e-05\n",
      "\tEpoch 80/100 - Train loss: 0.0011 - Val accuracy: 0.9851 - Val loss: 0.0347 - Val F1: 0.9851 - LR: 2.00e-05\n",
      "\tEpoch 90/100 - Train loss: 0.0005 - Val accuracy: 0.9851 - Val loss: 0.0277 - Val F1: 0.9851 - LR: 1.00e-05\n",
      "\tEpoch 100/100 - Train loss: 0.0004 - Val accuracy: 0.9851 - Val loss: 0.0298 - Val F1: 0.9851 - LR: 0.00e+00\n",
      "\tBest epoch: 64 - Best val accuracy: 0.9851 - Best val loss: 0.0171 - Best val F1: 0.9851\n",
      "\n",
      "Source class: WAL | Domain: 55 | Accuracy: 0.8367 | Loss: 1.0960 | F1: 0.7743\n",
      "\n",
      "Domain: 56\n",
      "x_syn_dom.shape: (333, 3, 128) | np.unique(y_syn_dom): [1 2 3]\n",
      "x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Training on synthetic data...\n",
      "\tEpoch 10/100 - Train loss: 0.0495 - Val accuracy: 0.9851 - Val loss: 0.0629 - Val F1: 0.9851 - LR: 9.00e-05\n",
      "\tEpoch 20/100 - Train loss: 0.0105 - Val accuracy: 0.9851 - Val loss: 0.0424 - Val F1: 0.9851 - LR: 8.00e-05\n",
      "\tEpoch 30/100 - Train loss: 0.0042 - Val accuracy: 0.9851 - Val loss: 0.0314 - Val F1: 0.9851 - LR: 7.00e-05\n",
      "\tEpoch 40/100 - Train loss: 0.0021 - Val accuracy: 0.9851 - Val loss: 0.0334 - Val F1: 0.9851 - LR: 6.00e-05\n",
      "\tEpoch 50/100 - Train loss: 0.0021 - Val accuracy: 0.9851 - Val loss: 0.0226 - Val F1: 0.9851 - LR: 5.00e-05\n",
      "\tEpoch 60/100 - Train loss: 0.0012 - Val accuracy: 0.9851 - Val loss: 0.0357 - Val F1: 0.9851 - LR: 4.00e-05\n",
      "\tEpoch 70/100 - Train loss: 0.0009 - Val accuracy: 0.9851 - Val loss: 0.0316 - Val F1: 0.9851 - LR: 3.00e-05\n",
      "\tEpoch 80/100 - Train loss: 0.0015 - Val accuracy: 0.9851 - Val loss: 0.0236 - Val F1: 0.9851 - LR: 2.00e-05\n",
      "\tEpoch 90/100 - Train loss: 0.0013 - Val accuracy: 0.9851 - Val loss: 0.0223 - Val F1: 0.9851 - LR: 1.00e-05\n",
      "\tEpoch 100/100 - Train loss: 0.0008 - Val accuracy: 0.9851 - Val loss: 0.0286 - Val F1: 0.9851 - LR: 0.00e+00\n",
      "\tBest epoch: 82 - Best val accuracy: 0.9851 - Best val loss: 0.0192 - Best val F1: 0.9851\n",
      "\n",
      "Source class: WAL | Domain: 56 | Accuracy: 0.8333 | Loss: 0.5682 | F1: 0.7870\n",
      "\n",
      "Domain: 57\n",
      "x_syn_dom.shape: (333, 3, 128) | np.unique(y_syn_dom): [1 2 3]\n",
      "x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Training on synthetic data...\n",
      "\tEpoch 10/100 - Train loss: 0.0843 - Val accuracy: 0.9403 - Val loss: 0.1862 - Val F1: 0.9398 - LR: 9.00e-05\n",
      "\tEpoch 20/100 - Train loss: 0.0107 - Val accuracy: 0.9851 - Val loss: 0.0605 - Val F1: 0.9851 - LR: 8.00e-05\n",
      "\tEpoch 30/100 - Train loss: 0.0071 - Val accuracy: 0.9851 - Val loss: 0.0452 - Val F1: 0.9851 - LR: 7.00e-05\n",
      "\tEpoch 40/100 - Train loss: 0.0027 - Val accuracy: 0.9851 - Val loss: 0.0361 - Val F1: 0.9851 - LR: 6.00e-05\n",
      "\tEpoch 50/100 - Train loss: 0.0010 - Val accuracy: 0.9851 - Val loss: 0.0366 - Val F1: 0.9851 - LR: 5.00e-05\n",
      "\tEpoch 60/100 - Train loss: 0.0024 - Val accuracy: 0.9851 - Val loss: 0.0382 - Val F1: 0.9851 - LR: 4.00e-05\n",
      "\tEpoch 70/100 - Train loss: 0.0023 - Val accuracy: 0.9851 - Val loss: 0.0228 - Val F1: 0.9851 - LR: 3.00e-05\n",
      "\tEpoch 80/100 - Train loss: 0.0007 - Val accuracy: 0.9851 - Val loss: 0.0279 - Val F1: 0.9851 - LR: 2.00e-05\n",
      "\tEpoch 90/100 - Train loss: 0.0012 - Val accuracy: 0.9851 - Val loss: 0.0292 - Val F1: 0.9851 - LR: 1.00e-05\n",
      "\tEpoch 100/100 - Train loss: 0.0021 - Val accuracy: 0.9851 - Val loss: 0.0335 - Val F1: 0.9851 - LR: 0.00e+00\n",
      "\tBest epoch: 64 - Best val accuracy: 0.9851 - Best val loss: 0.0194 - Best val F1: 0.9851\n",
      "\n",
      "Source class: WAL | Domain: 57 | Accuracy: 0.9048 | Loss: 0.1806 | F1: 0.8883\n",
      "\n",
      "Domain: 58\n",
      "x_syn_dom.shape: (333, 3, 128) | np.unique(y_syn_dom): [1 2 3]\n",
      "x_dp_dom.shape: (38, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Training on synthetic data...\n",
      "\tEpoch 10/100 - Train loss: 0.0529 - Val accuracy: 0.9851 - Val loss: 0.0602 - Val F1: 0.9851 - LR: 9.00e-05\n",
      "\tEpoch 20/100 - Train loss: 0.0115 - Val accuracy: 0.9851 - Val loss: 0.0362 - Val F1: 0.9851 - LR: 8.00e-05\n",
      "\tEpoch 30/100 - Train loss: 0.0044 - Val accuracy: 0.9851 - Val loss: 0.0350 - Val F1: 0.9851 - LR: 7.00e-05\n",
      "\tEpoch 40/100 - Train loss: 0.0024 - Val accuracy: 0.9851 - Val loss: 0.0335 - Val F1: 0.9851 - LR: 6.00e-05\n",
      "\tEpoch 50/100 - Train loss: 0.0012 - Val accuracy: 0.9851 - Val loss: 0.0413 - Val F1: 0.9851 - LR: 5.00e-05\n",
      "\tEpoch 60/100 - Train loss: 0.0016 - Val accuracy: 0.9851 - Val loss: 0.0397 - Val F1: 0.9851 - LR: 4.00e-05\n",
      "\tEpoch 70/100 - Train loss: 0.0009 - Val accuracy: 0.9851 - Val loss: 0.0380 - Val F1: 0.9851 - LR: 3.00e-05\n",
      "\tEpoch 80/100 - Train loss: 0.0016 - Val accuracy: 0.9851 - Val loss: 0.0380 - Val F1: 0.9851 - LR: 2.00e-05\n",
      "\tEpoch 90/100 - Train loss: 0.0007 - Val accuracy: 0.9851 - Val loss: 0.0480 - Val F1: 0.9851 - LR: 1.00e-05\n",
      "\tEpoch 100/100 - Train loss: 0.0005 - Val accuracy: 0.9851 - Val loss: 0.0448 - Val F1: 0.9851 - LR: 0.00e+00\n",
      "\tBest epoch: 24 - Best val accuracy: 0.9851 - Best val loss: 0.0275 - Best val F1: 0.9851\n",
      "\n",
      "Source class: WAL | Domain: 58 | Accuracy: 0.7368 | Loss: 0.8592 | F1: 0.6655\n",
      "\n",
      "Domain: 59\n",
      "x_syn_dom.shape: (333, 3, 128) | np.unique(y_syn_dom): [1 2 3]\n",
      "x_dp_dom.shape: (43, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Training on synthetic data...\n",
      "\tEpoch 10/100 - Train loss: 0.0398 - Val accuracy: 0.9851 - Val loss: 0.0475 - Val F1: 0.9851 - LR: 9.00e-05\n",
      "\tEpoch 20/100 - Train loss: 0.0060 - Val accuracy: 0.9851 - Val loss: 0.0159 - Val F1: 0.9851 - LR: 8.00e-05\n",
      "\tEpoch 30/100 - Train loss: 0.0024 - Val accuracy: 1.0000 - Val loss: 0.0094 - Val F1: 1.0000 - LR: 7.00e-05\n",
      "\tEpoch 40/100 - Train loss: 0.0022 - Val accuracy: 1.0000 - Val loss: 0.0034 - Val F1: 1.0000 - LR: 6.00e-05\n",
      "\tEpoch 50/100 - Train loss: 0.0025 - Val accuracy: 1.0000 - Val loss: 0.0101 - Val F1: 1.0000 - LR: 5.00e-05\n",
      "\tEpoch 60/100 - Train loss: 0.0025 - Val accuracy: 1.0000 - Val loss: 0.0025 - Val F1: 1.0000 - LR: 4.00e-05\n",
      "\tEpoch 70/100 - Train loss: 0.0008 - Val accuracy: 1.0000 - Val loss: 0.0030 - Val F1: 1.0000 - LR: 3.00e-05\n",
      "\tEpoch 80/100 - Train loss: 0.0005 - Val accuracy: 1.0000 - Val loss: 0.0032 - Val F1: 1.0000 - LR: 2.00e-05\n",
      "\tEpoch 90/100 - Train loss: 0.0007 - Val accuracy: 1.0000 - Val loss: 0.0032 - Val F1: 1.0000 - LR: 1.00e-05\n",
      "\tEpoch 100/100 - Train loss: 0.0005 - Val accuracy: 1.0000 - Val loss: 0.0026 - Val F1: 1.0000 - LR: 0.00e+00\n",
      "\tBest epoch: 89 - Best val accuracy: 1.0000 - Best val loss: 0.0019 - Best val F1: 1.0000\n",
      "\n",
      "Source class: WAL | Domain: 59 | Accuracy: 0.9767 | Loss: 0.0809 | F1: 0.9765\n",
      "\n",
      "Domain: 60\n",
      "x_syn_dom.shape: (333, 3, 128) | np.unique(y_syn_dom): [1 2 3]\n",
      "x_dp_dom.shape: (47, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Training on synthetic data...\n",
      "\tEpoch 10/100 - Train loss: 0.0216 - Val accuracy: 0.9851 - Val loss: 0.0255 - Val F1: 0.9851 - LR: 9.00e-05\n",
      "\tEpoch 20/100 - Train loss: 0.0225 - Val accuracy: 0.9851 - Val loss: 0.0167 - Val F1: 0.9851 - LR: 8.00e-05\n",
      "\tEpoch 30/100 - Train loss: 0.0095 - Val accuracy: 1.0000 - Val loss: 0.0074 - Val F1: 1.0000 - LR: 7.00e-05\n",
      "\tEpoch 40/100 - Train loss: 0.0029 - Val accuracy: 1.0000 - Val loss: 0.0063 - Val F1: 1.0000 - LR: 6.00e-05\n",
      "\tEpoch 50/100 - Train loss: 0.0014 - Val accuracy: 0.9851 - Val loss: 0.0137 - Val F1: 0.9851 - LR: 5.00e-05\n",
      "\tEpoch 60/100 - Train loss: 0.0081 - Val accuracy: 1.0000 - Val loss: 0.0076 - Val F1: 1.0000 - LR: 4.00e-05\n",
      "\tEpoch 70/100 - Train loss: 0.0012 - Val accuracy: 1.0000 - Val loss: 0.0066 - Val F1: 1.0000 - LR: 3.00e-05\n",
      "\tEpoch 80/100 - Train loss: 0.0010 - Val accuracy: 1.0000 - Val loss: 0.0081 - Val F1: 1.0000 - LR: 2.00e-05\n",
      "\tEpoch 90/100 - Train loss: 0.0021 - Val accuracy: 1.0000 - Val loss: 0.0072 - Val F1: 1.0000 - LR: 1.00e-05\n",
      "\tEpoch 100/100 - Train loss: 0.0024 - Val accuracy: 1.0000 - Val loss: 0.0108 - Val F1: 1.0000 - LR: 0.00e+00\n",
      "\tBest epoch: 62 - Best val accuracy: 1.0000 - Best val loss: 0.0039 - Best val F1: 1.0000\n",
      "\n",
      "Source class: WAL | Domain: 60 | Accuracy: 0.5957 | Loss: 0.9387 | F1: 0.4508\n",
      "\n",
      "Domain: 61\n",
      "x_syn_dom.shape: (333, 3, 128) | np.unique(y_syn_dom): [1 2 3]\n",
      "x_dp_dom.shape: (47, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Training on synthetic data...\n",
      "\tEpoch 10/100 - Train loss: 0.0324 - Val accuracy: 1.0000 - Val loss: 0.0260 - Val F1: 1.0000 - LR: 9.00e-05\n",
      "\tEpoch 20/100 - Train loss: 0.0063 - Val accuracy: 1.0000 - Val loss: 0.0050 - Val F1: 1.0000 - LR: 8.00e-05\n",
      "\tEpoch 30/100 - Train loss: 0.0030 - Val accuracy: 1.0000 - Val loss: 0.0021 - Val F1: 1.0000 - LR: 7.00e-05\n",
      "\tEpoch 40/100 - Train loss: 0.0023 - Val accuracy: 1.0000 - Val loss: 0.0012 - Val F1: 1.0000 - LR: 6.00e-05\n",
      "\tEpoch 50/100 - Train loss: 0.0019 - Val accuracy: 1.0000 - Val loss: 0.0008 - Val F1: 1.0000 - LR: 5.00e-05\n",
      "\tEpoch 60/100 - Train loss: 0.0029 - Val accuracy: 1.0000 - Val loss: 0.0007 - Val F1: 1.0000 - LR: 4.00e-05\n",
      "\tEpoch 70/100 - Train loss: 0.0011 - Val accuracy: 1.0000 - Val loss: 0.0004 - Val F1: 1.0000 - LR: 3.00e-05\n",
      "\tEpoch 80/100 - Train loss: 0.0010 - Val accuracy: 1.0000 - Val loss: 0.0004 - Val F1: 1.0000 - LR: 2.00e-05\n",
      "\tEpoch 90/100 - Train loss: 0.0006 - Val accuracy: 1.0000 - Val loss: 0.0004 - Val F1: 1.0000 - LR: 1.00e-05\n",
      "\tEpoch 100/100 - Train loss: 0.0006 - Val accuracy: 1.0000 - Val loss: 0.0003 - Val F1: 1.0000 - LR: 0.00e+00\n",
      "\tBest epoch: 92 - Best val accuracy: 1.0000 - Best val loss: 0.0003 - Best val F1: 1.0000\n",
      "\n",
      "Source class: WAL | Domain: 61 | Accuracy: 0.4255 | Loss: 2.3330 | F1: 0.4675\n",
      "\n",
      "Domain: 62\n",
      "x_syn_dom.shape: (333, 3, 128) | np.unique(y_syn_dom): [1 2 3]\n",
      "x_dp_dom.shape: (47, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Training on synthetic data...\n",
      "\tEpoch 10/100 - Train loss: 0.0545 - Val accuracy: 1.0000 - Val loss: 0.0485 - Val F1: 1.0000 - LR: 9.00e-05\n",
      "\tEpoch 20/100 - Train loss: 0.0082 - Val accuracy: 1.0000 - Val loss: 0.0058 - Val F1: 1.0000 - LR: 8.00e-05\n",
      "\tEpoch 30/100 - Train loss: 0.0032 - Val accuracy: 1.0000 - Val loss: 0.0023 - Val F1: 1.0000 - LR: 7.00e-05\n",
      "\tEpoch 40/100 - Train loss: 0.0030 - Val accuracy: 1.0000 - Val loss: 0.0013 - Val F1: 1.0000 - LR: 6.00e-05\n",
      "\tEpoch 50/100 - Train loss: 0.0011 - Val accuracy: 1.0000 - Val loss: 0.0009 - Val F1: 1.0000 - LR: 5.00e-05\n",
      "\tEpoch 60/100 - Train loss: 0.0010 - Val accuracy: 1.0000 - Val loss: 0.0007 - Val F1: 1.0000 - LR: 4.00e-05\n",
      "\tEpoch 70/100 - Train loss: 0.0006 - Val accuracy: 1.0000 - Val loss: 0.0007 - Val F1: 1.0000 - LR: 3.00e-05\n",
      "\tEpoch 80/100 - Train loss: 0.0007 - Val accuracy: 1.0000 - Val loss: 0.0005 - Val F1: 1.0000 - LR: 2.00e-05\n",
      "\tEpoch 90/100 - Train loss: 0.0006 - Val accuracy: 1.0000 - Val loss: 0.0005 - Val F1: 1.0000 - LR: 1.00e-05\n",
      "\tEpoch 100/100 - Train loss: 0.0008 - Val accuracy: 1.0000 - Val loss: 0.0004 - Val F1: 1.0000 - LR: 0.00e+00\n",
      "\tBest epoch: 96 - Best val accuracy: 1.0000 - Best val loss: 0.0004 - Best val F1: 1.0000\n",
      "\n",
      "Source class: WAL | Domain: 62 | Accuracy: 0.9574 | Loss: 0.0897 | F1: 0.9555\n",
      "\n",
      "Domain: 63\n",
      "x_syn_dom.shape: (333, 3, 128) | np.unique(y_syn_dom): [1 2 3]\n",
      "x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Training on synthetic data...\n",
      "\tEpoch 10/100 - Train loss: 0.0575 - Val accuracy: 1.0000 - Val loss: 0.0432 - Val F1: 1.0000 - LR: 9.00e-05\n",
      "\tEpoch 20/100 - Train loss: 0.0054 - Val accuracy: 1.0000 - Val loss: 0.0049 - Val F1: 1.0000 - LR: 8.00e-05\n",
      "\tEpoch 30/100 - Train loss: 0.0030 - Val accuracy: 1.0000 - Val loss: 0.0019 - Val F1: 1.0000 - LR: 7.00e-05\n",
      "\tEpoch 40/100 - Train loss: 0.0044 - Val accuracy: 1.0000 - Val loss: 0.0011 - Val F1: 1.0000 - LR: 6.00e-05\n",
      "\tEpoch 50/100 - Train loss: 0.0013 - Val accuracy: 1.0000 - Val loss: 0.0008 - Val F1: 1.0000 - LR: 5.00e-05\n",
      "\tEpoch 60/100 - Train loss: 0.0006 - Val accuracy: 1.0000 - Val loss: 0.0007 - Val F1: 1.0000 - LR: 4.00e-05\n",
      "\tEpoch 70/100 - Train loss: 0.0010 - Val accuracy: 1.0000 - Val loss: 0.0004 - Val F1: 1.0000 - LR: 3.00e-05\n",
      "\tEpoch 80/100 - Train loss: 0.0009 - Val accuracy: 1.0000 - Val loss: 0.0004 - Val F1: 1.0000 - LR: 2.00e-05\n",
      "\tEpoch 90/100 - Train loss: 0.0031 - Val accuracy: 1.0000 - Val loss: 0.0003 - Val F1: 1.0000 - LR: 1.00e-05\n",
      "\tEpoch 100/100 - Train loss: 0.0008 - Val accuracy: 1.0000 - Val loss: 0.0003 - Val F1: 1.0000 - LR: 0.00e+00\n",
      "\tBest epoch: 91 - Best val accuracy: 1.0000 - Best val loss: 0.0003 - Best val F1: 1.0000\n",
      "\n",
      "Source class: WAL | Domain: 63 | Accuracy: 0.7619 | Loss: 1.0220 | F1: 0.7426\n",
      "\n",
      "Domain: 64\n",
      "x_syn_dom.shape: (336, 3, 128) | np.unique(y_syn_dom): [1 2 3]\n",
      "x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Training on synthetic data...\n",
      "\tEpoch 10/100 - Train loss: 0.0336 - Val accuracy: 1.0000 - Val loss: 0.0233 - Val F1: 1.0000 - LR: 9.00e-05\n",
      "\tEpoch 20/100 - Train loss: 0.0081 - Val accuracy: 1.0000 - Val loss: 0.0034 - Val F1: 1.0000 - LR: 8.00e-05\n",
      "\tEpoch 30/100 - Train loss: 0.0030 - Val accuracy: 1.0000 - Val loss: 0.0015 - Val F1: 1.0000 - LR: 7.00e-05\n",
      "\tEpoch 40/100 - Train loss: 0.0016 - Val accuracy: 1.0000 - Val loss: 0.0007 - Val F1: 1.0000 - LR: 6.00e-05\n",
      "\tEpoch 50/100 - Train loss: 0.0014 - Val accuracy: 1.0000 - Val loss: 0.0005 - Val F1: 1.0000 - LR: 5.00e-05\n",
      "\tEpoch 60/100 - Train loss: 0.0010 - Val accuracy: 1.0000 - Val loss: 0.0004 - Val F1: 1.0000 - LR: 4.00e-05\n",
      "\tEpoch 70/100 - Train loss: 0.0007 - Val accuracy: 1.0000 - Val loss: 0.0003 - Val F1: 1.0000 - LR: 3.00e-05\n",
      "\tEpoch 80/100 - Train loss: 0.0006 - Val accuracy: 1.0000 - Val loss: 0.0003 - Val F1: 1.0000 - LR: 2.00e-05\n",
      "\tEpoch 90/100 - Train loss: 0.0005 - Val accuracy: 1.0000 - Val loss: 0.0003 - Val F1: 1.0000 - LR: 1.00e-05\n",
      "\tEpoch 100/100 - Train loss: 0.0028 - Val accuracy: 1.0000 - Val loss: 0.0003 - Val F1: 1.0000 - LR: 0.00e+00\n",
      "\tBest epoch: 91 - Best val accuracy: 1.0000 - Best val loss: 0.0002 - Best val F1: 1.0000\n",
      "\n",
      "Source class: WAL | Domain: 64 | Accuracy: 0.9048 | Loss: 0.4280 | F1: 0.8963\n",
      "\n",
      "Domain: 65\n",
      "x_syn_dom.shape: (333, 3, 128) | np.unique(y_syn_dom): [1 2 3]\n",
      "x_dp_dom.shape: (50, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Training on synthetic data...\n",
      "\tEpoch 10/100 - Train loss: 0.1095 - Val accuracy: 0.9851 - Val loss: 0.0908 - Val F1: 0.9851 - LR: 9.00e-05\n",
      "\tEpoch 20/100 - Train loss: 0.0103 - Val accuracy: 0.9851 - Val loss: 0.0393 - Val F1: 0.9851 - LR: 8.00e-05\n",
      "\tEpoch 30/100 - Train loss: 0.0039 - Val accuracy: 0.9851 - Val loss: 0.0341 - Val F1: 0.9851 - LR: 7.00e-05\n",
      "\tEpoch 40/100 - Train loss: 0.0016 - Val accuracy: 0.9851 - Val loss: 0.0370 - Val F1: 0.9851 - LR: 6.00e-05\n",
      "\tEpoch 50/100 - Train loss: 0.0016 - Val accuracy: 0.9851 - Val loss: 0.0293 - Val F1: 0.9851 - LR: 5.00e-05\n",
      "\tEpoch 60/100 - Train loss: 0.0016 - Val accuracy: 0.9851 - Val loss: 0.0376 - Val F1: 0.9851 - LR: 4.00e-05\n",
      "\tEpoch 70/100 - Train loss: 0.0010 - Val accuracy: 0.9851 - Val loss: 0.0312 - Val F1: 0.9851 - LR: 3.00e-05\n",
      "\tEpoch 80/100 - Train loss: 0.0014 - Val accuracy: 0.9851 - Val loss: 0.0374 - Val F1: 0.9851 - LR: 2.00e-05\n",
      "\tEpoch 90/100 - Train loss: 0.0009 - Val accuracy: 0.9851 - Val loss: 0.0364 - Val F1: 0.9851 - LR: 1.00e-05\n",
      "\tEpoch 100/100 - Train loss: 0.0030 - Val accuracy: 0.9851 - Val loss: 0.0262 - Val F1: 0.9851 - LR: 0.00e+00\n",
      "\tBest epoch: 66 - Best val accuracy: 0.9851 - Best val loss: 0.0209 - Best val F1: 0.9851\n",
      "\n",
      "Source class: WAL | Domain: 65 | Accuracy: 0.9600 | Loss: 0.6047 | F1: 0.9582\n",
      "\n",
      "Domain: 66\n",
      "x_syn_dom.shape: (333, 3, 128) | np.unique(y_syn_dom): [1 2 3]\n",
      "x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Training on synthetic data...\n",
      "\tEpoch 10/100 - Train loss: 0.0336 - Val accuracy: 1.0000 - Val loss: 0.0241 - Val F1: 1.0000 - LR: 9.00e-05\n",
      "\tEpoch 20/100 - Train loss: 0.0064 - Val accuracy: 1.0000 - Val loss: 0.0057 - Val F1: 1.0000 - LR: 8.00e-05\n",
      "\tEpoch 30/100 - Train loss: 0.0032 - Val accuracy: 1.0000 - Val loss: 0.0023 - Val F1: 1.0000 - LR: 7.00e-05\n",
      "\tEpoch 40/100 - Train loss: 0.0016 - Val accuracy: 1.0000 - Val loss: 0.0017 - Val F1: 1.0000 - LR: 6.00e-05\n",
      "\tEpoch 50/100 - Train loss: 0.0011 - Val accuracy: 1.0000 - Val loss: 0.0013 - Val F1: 1.0000 - LR: 5.00e-05\n",
      "\tEpoch 60/100 - Train loss: 0.0022 - Val accuracy: 1.0000 - Val loss: 0.0010 - Val F1: 1.0000 - LR: 4.00e-05\n",
      "\tEpoch 70/100 - Train loss: 0.0010 - Val accuracy: 1.0000 - Val loss: 0.0011 - Val F1: 1.0000 - LR: 3.00e-05\n",
      "\tEpoch 80/100 - Train loss: 0.0010 - Val accuracy: 1.0000 - Val loss: 0.0008 - Val F1: 1.0000 - LR: 2.00e-05\n",
      "\tEpoch 90/100 - Train loss: 0.0078 - Val accuracy: 1.0000 - Val loss: 0.0008 - Val F1: 1.0000 - LR: 1.00e-05\n",
      "\tEpoch 100/100 - Train loss: 0.0006 - Val accuracy: 1.0000 - Val loss: 0.0008 - Val F1: 1.0000 - LR: 0.00e+00\n",
      "\tBest epoch: 97 - Best val accuracy: 1.0000 - Best val loss: 0.0005 - Best val F1: 1.0000\n",
      "\n",
      "Source class: WAL | Domain: 66 | Accuracy: 0.7143 | Loss: 7.7453 | F1: 0.6231\n",
      "\n",
      "Domain: 67\n",
      "x_syn_dom.shape: (333, 3, 128) | np.unique(y_syn_dom): [1 2 3]\n",
      "x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Training on synthetic data...\n",
      "\tEpoch 10/100 - Train loss: 0.0784 - Val accuracy: 0.9701 - Val loss: 0.1594 - Val F1: 0.9701 - LR: 9.00e-05\n",
      "\tEpoch 20/100 - Train loss: 0.0107 - Val accuracy: 0.9701 - Val loss: 0.1350 - Val F1: 0.9701 - LR: 8.00e-05\n",
      "\tEpoch 30/100 - Train loss: 0.0048 - Val accuracy: 0.9701 - Val loss: 0.1877 - Val F1: 0.9701 - LR: 7.00e-05\n",
      "\tEpoch 40/100 - Train loss: 0.0022 - Val accuracy: 0.9701 - Val loss: 0.1774 - Val F1: 0.9701 - LR: 6.00e-05\n",
      "\tEpoch 50/100 - Train loss: 0.0020 - Val accuracy: 0.9701 - Val loss: 0.1828 - Val F1: 0.9701 - LR: 5.00e-05\n",
      "\tEpoch 60/100 - Train loss: 0.0010 - Val accuracy: 0.9701 - Val loss: 0.1868 - Val F1: 0.9701 - LR: 4.00e-05\n",
      "\tEpoch 70/100 - Train loss: 0.0013 - Val accuracy: 0.9701 - Val loss: 0.2141 - Val F1: 0.9701 - LR: 3.00e-05\n",
      "\tEpoch 80/100 - Train loss: 0.0008 - Val accuracy: 0.9701 - Val loss: 0.2238 - Val F1: 0.9701 - LR: 2.00e-05\n",
      "\tEpoch 90/100 - Train loss: 0.0016 - Val accuracy: 0.9701 - Val loss: 0.2207 - Val F1: 0.9701 - LR: 1.00e-05\n",
      "\tEpoch 100/100 - Train loss: 0.0010 - Val accuracy: 0.9701 - Val loss: 0.2280 - Val F1: 0.9701 - LR: 0.00e+00\n",
      "\tBest epoch: 17 - Best val accuracy: 0.9701 - Best val loss: 0.1147 - Best val F1: 0.9701\n",
      "\n",
      "Source class: WAL | Domain: 67 | Accuracy: 0.7857 | Loss: 0.6050 | F1: 0.7754\n",
      "\n",
      "Domain: 68\n",
      "x_syn_dom.shape: (333, 3, 128) | np.unique(y_syn_dom): [1 2 3]\n",
      "x_dp_dom.shape: (43, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Training on synthetic data...\n",
      "\tEpoch 10/100 - Train loss: 0.0738 - Val accuracy: 0.9851 - Val loss: 0.0453 - Val F1: 0.9851 - LR: 9.00e-05\n",
      "\tEpoch 20/100 - Train loss: 0.0132 - Val accuracy: 1.0000 - Val loss: 0.0196 - Val F1: 1.0000 - LR: 8.00e-05\n",
      "\tEpoch 30/100 - Train loss: 0.0052 - Val accuracy: 1.0000 - Val loss: 0.0096 - Val F1: 1.0000 - LR: 7.00e-05\n",
      "\tEpoch 40/100 - Train loss: 0.0026 - Val accuracy: 1.0000 - Val loss: 0.0083 - Val F1: 1.0000 - LR: 6.00e-05\n",
      "\tEpoch 50/100 - Train loss: 0.0035 - Val accuracy: 1.0000 - Val loss: 0.0055 - Val F1: 1.0000 - LR: 5.00e-05\n",
      "\tEpoch 60/100 - Train loss: 0.0015 - Val accuracy: 1.0000 - Val loss: 0.0061 - Val F1: 1.0000 - LR: 4.00e-05\n",
      "\tEpoch 70/100 - Train loss: 0.0015 - Val accuracy: 1.0000 - Val loss: 0.0056 - Val F1: 1.0000 - LR: 3.00e-05\n",
      "\tEpoch 80/100 - Train loss: 0.0009 - Val accuracy: 1.0000 - Val loss: 0.0049 - Val F1: 1.0000 - LR: 2.00e-05\n",
      "\tEpoch 90/100 - Train loss: 0.0007 - Val accuracy: 1.0000 - Val loss: 0.0050 - Val F1: 1.0000 - LR: 1.00e-05\n",
      "\tEpoch 100/100 - Train loss: 0.0013 - Val accuracy: 1.0000 - Val loss: 0.0043 - Val F1: 1.0000 - LR: 0.00e+00\n",
      "\tBest epoch: 73 - Best val accuracy: 1.0000 - Best val loss: 0.0031 - Best val F1: 1.0000\n",
      "\n",
      "Source class: WAL | Domain: 68 | Accuracy: 0.8372 | Loss: 1.0622 | F1: 0.7806\n",
      "\n",
      "Domain: 69\n",
      "x_syn_dom.shape: (333, 3, 128) | np.unique(y_syn_dom): [1 2 3]\n",
      "x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Training on synthetic data...\n",
      "\tEpoch 10/100 - Train loss: 0.0509 - Val accuracy: 1.0000 - Val loss: 0.0431 - Val F1: 1.0000 - LR: 9.00e-05\n",
      "\tEpoch 20/100 - Train loss: 0.0085 - Val accuracy: 1.0000 - Val loss: 0.0050 - Val F1: 1.0000 - LR: 8.00e-05\n",
      "\tEpoch 30/100 - Train loss: 0.0042 - Val accuracy: 1.0000 - Val loss: 0.0018 - Val F1: 1.0000 - LR: 7.00e-05\n",
      "\tEpoch 40/100 - Train loss: 0.0011 - Val accuracy: 1.0000 - Val loss: 0.0010 - Val F1: 1.0000 - LR: 6.00e-05\n",
      "\tEpoch 50/100 - Train loss: 0.0026 - Val accuracy: 1.0000 - Val loss: 0.0007 - Val F1: 1.0000 - LR: 5.00e-05\n",
      "\tEpoch 60/100 - Train loss: 0.0024 - Val accuracy: 1.0000 - Val loss: 0.0006 - Val F1: 1.0000 - LR: 4.00e-05\n",
      "\tEpoch 70/100 - Train loss: 0.0007 - Val accuracy: 1.0000 - Val loss: 0.0005 - Val F1: 1.0000 - LR: 3.00e-05\n",
      "\tEpoch 80/100 - Train loss: 0.0012 - Val accuracy: 1.0000 - Val loss: 0.0004 - Val F1: 1.0000 - LR: 2.00e-05\n",
      "\tEpoch 90/100 - Train loss: 0.0021 - Val accuracy: 1.0000 - Val loss: 0.0004 - Val F1: 1.0000 - LR: 1.00e-05\n",
      "\tEpoch 100/100 - Train loss: 0.0173 - Val accuracy: 1.0000 - Val loss: 0.0003 - Val F1: 1.0000 - LR: 0.00e+00\n",
      "\tBest epoch: 100 - Best val accuracy: 1.0000 - Best val loss: 0.0003 - Best val F1: 1.0000\n",
      "\n",
      "Source class: WAL | Domain: 69 | Accuracy: 0.7619 | Loss: 1.0238 | F1: 0.7569\n",
      "\n",
      "Domain: 70\n",
      "x_syn_dom.shape: (333, 3, 128) | np.unique(y_syn_dom): [1 2 3]\n",
      "x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Training on synthetic data...\n",
      "\tEpoch 10/100 - Train loss: 0.0833 - Val accuracy: 1.0000 - Val loss: 0.0557 - Val F1: 1.0000 - LR: 9.00e-05\n",
      "\tEpoch 20/100 - Train loss: 0.0168 - Val accuracy: 1.0000 - Val loss: 0.0097 - Val F1: 1.0000 - LR: 8.00e-05\n",
      "\tEpoch 30/100 - Train loss: 0.0124 - Val accuracy: 1.0000 - Val loss: 0.0048 - Val F1: 1.0000 - LR: 7.00e-05\n",
      "\tEpoch 40/100 - Train loss: 0.0036 - Val accuracy: 1.0000 - Val loss: 0.0023 - Val F1: 1.0000 - LR: 6.00e-05\n",
      "\tEpoch 50/100 - Train loss: 0.0029 - Val accuracy: 1.0000 - Val loss: 0.0015 - Val F1: 1.0000 - LR: 5.00e-05\n",
      "\tEpoch 60/100 - Train loss: 0.0018 - Val accuracy: 1.0000 - Val loss: 0.0013 - Val F1: 1.0000 - LR: 4.00e-05\n",
      "\tEpoch 70/100 - Train loss: 0.0011 - Val accuracy: 1.0000 - Val loss: 0.0008 - Val F1: 1.0000 - LR: 3.00e-05\n",
      "\tEpoch 80/100 - Train loss: 0.0033 - Val accuracy: 1.0000 - Val loss: 0.0009 - Val F1: 1.0000 - LR: 2.00e-05\n",
      "\tEpoch 90/100 - Train loss: 0.0008 - Val accuracy: 1.0000 - Val loss: 0.0007 - Val F1: 1.0000 - LR: 1.00e-05\n",
      "\tEpoch 100/100 - Train loss: 0.0008 - Val accuracy: 1.0000 - Val loss: 0.0008 - Val F1: 1.0000 - LR: 0.00e+00\n",
      "\tBest epoch: 92 - Best val accuracy: 1.0000 - Best val loss: 0.0006 - Best val F1: 1.0000\n",
      "\n",
      "Source class: WAL | Domain: 70 | Accuracy: 0.7381 | Loss: 3.0123 | F1: 0.6688\n",
      "\n",
      "Domain: 71\n",
      "x_syn_dom.shape: (333, 3, 128) | np.unique(y_syn_dom): [1 2 3]\n",
      "x_dp_dom.shape: (44, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Training on synthetic data...\n",
      "\tEpoch 10/100 - Train loss: 0.0554 - Val accuracy: 0.9851 - Val loss: 0.0668 - Val F1: 0.9851 - LR: 9.00e-05\n",
      "\tEpoch 20/100 - Train loss: 0.0071 - Val accuracy: 1.0000 - Val loss: 0.0115 - Val F1: 1.0000 - LR: 8.00e-05\n",
      "\tEpoch 30/100 - Train loss: 0.0036 - Val accuracy: 1.0000 - Val loss: 0.0045 - Val F1: 1.0000 - LR: 7.00e-05\n",
      "\tEpoch 40/100 - Train loss: 0.0034 - Val accuracy: 1.0000 - Val loss: 0.0022 - Val F1: 1.0000 - LR: 6.00e-05\n",
      "\tEpoch 50/100 - Train loss: 0.0022 - Val accuracy: 1.0000 - Val loss: 0.0022 - Val F1: 1.0000 - LR: 5.00e-05\n",
      "\tEpoch 60/100 - Train loss: 0.0032 - Val accuracy: 1.0000 - Val loss: 0.0029 - Val F1: 1.0000 - LR: 4.00e-05\n",
      "\tEpoch 70/100 - Train loss: 0.0008 - Val accuracy: 1.0000 - Val loss: 0.0012 - Val F1: 1.0000 - LR: 3.00e-05\n",
      "\tEpoch 80/100 - Train loss: 0.0008 - Val accuracy: 1.0000 - Val loss: 0.0011 - Val F1: 1.0000 - LR: 2.00e-05\n",
      "\tEpoch 90/100 - Train loss: 0.0006 - Val accuracy: 1.0000 - Val loss: 0.0013 - Val F1: 1.0000 - LR: 1.00e-05\n",
      "\tEpoch 100/100 - Train loss: 0.0007 - Val accuracy: 1.0000 - Val loss: 0.0010 - Val F1: 1.0000 - LR: 0.00e+00\n",
      "\tBest epoch: 64 - Best val accuracy: 1.0000 - Best val loss: 0.0009 - Best val F1: 1.0000\n",
      "\n",
      "Source class: WAL | Domain: 71 | Accuracy: 0.9318 | Loss: 0.1606 | F1: 0.9243\n",
      "\n",
      "Domain: 72\n",
      "x_syn_dom.shape: (333, 3, 128) | np.unique(y_syn_dom): [1 2 3]\n",
      "x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Training on synthetic data...\n",
      "\tEpoch 10/100 - Train loss: 0.0516 - Val accuracy: 0.9701 - Val loss: 0.0564 - Val F1: 0.9701 - LR: 9.00e-05\n",
      "\tEpoch 20/100 - Train loss: 0.0061 - Val accuracy: 0.9701 - Val loss: 0.0293 - Val F1: 0.9701 - LR: 8.00e-05\n",
      "\tEpoch 30/100 - Train loss: 0.0029 - Val accuracy: 1.0000 - Val loss: 0.0156 - Val F1: 1.0000 - LR: 7.00e-05\n",
      "\tEpoch 40/100 - Train loss: 0.0015 - Val accuracy: 1.0000 - Val loss: 0.0123 - Val F1: 1.0000 - LR: 6.00e-05\n",
      "\tEpoch 50/100 - Train loss: 0.0016 - Val accuracy: 1.0000 - Val loss: 0.0043 - Val F1: 1.0000 - LR: 5.00e-05\n",
      "\tEpoch 60/100 - Train loss: 0.0009 - Val accuracy: 1.0000 - Val loss: 0.0057 - Val F1: 1.0000 - LR: 4.00e-05\n",
      "\tEpoch 70/100 - Train loss: 0.0005 - Val accuracy: 1.0000 - Val loss: 0.0045 - Val F1: 1.0000 - LR: 3.00e-05\n",
      "\tEpoch 80/100 - Train loss: 0.0009 - Val accuracy: 1.0000 - Val loss: 0.0044 - Val F1: 1.0000 - LR: 2.00e-05\n",
      "\tEpoch 90/100 - Train loss: 0.0009 - Val accuracy: 1.0000 - Val loss: 0.0027 - Val F1: 1.0000 - LR: 1.00e-05\n",
      "\tEpoch 100/100 - Train loss: 0.0011 - Val accuracy: 1.0000 - Val loss: 0.0032 - Val F1: 1.0000 - LR: 0.00e+00\n",
      "\tBest epoch: 90 - Best val accuracy: 1.0000 - Best val loss: 0.0027 - Best val F1: 1.0000\n",
      "\n",
      "Source class: WAL | Domain: 72 | Accuracy: 0.8333 | Loss: 0.4995 | F1: 0.8253\n",
      "\n",
      "Domain: 73\n",
      "x_syn_dom.shape: (333, 3, 128) | np.unique(y_syn_dom): [1 2 3]\n",
      "x_dp_dom.shape: (41, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Training on synthetic data...\n",
      "\tEpoch 10/100 - Train loss: 0.0303 - Val accuracy: 1.0000 - Val loss: 0.0122 - Val F1: 1.0000 - LR: 9.00e-05\n",
      "\tEpoch 20/100 - Train loss: 0.0085 - Val accuracy: 1.0000 - Val loss: 0.0030 - Val F1: 1.0000 - LR: 8.00e-05\n",
      "\tEpoch 30/100 - Train loss: 0.0046 - Val accuracy: 1.0000 - Val loss: 0.0013 - Val F1: 1.0000 - LR: 7.00e-05\n",
      "\tEpoch 40/100 - Train loss: 0.0049 - Val accuracy: 1.0000 - Val loss: 0.0009 - Val F1: 1.0000 - LR: 6.00e-05\n",
      "\tEpoch 50/100 - Train loss: 0.0015 - Val accuracy: 1.0000 - Val loss: 0.0007 - Val F1: 1.0000 - LR: 5.00e-05\n",
      "\tEpoch 60/100 - Train loss: 0.0014 - Val accuracy: 1.0000 - Val loss: 0.0004 - Val F1: 1.0000 - LR: 4.00e-05\n",
      "\tEpoch 70/100 - Train loss: 0.0014 - Val accuracy: 1.0000 - Val loss: 0.0003 - Val F1: 1.0000 - LR: 3.00e-05\n",
      "\tEpoch 80/100 - Train loss: 0.0007 - Val accuracy: 1.0000 - Val loss: 0.0003 - Val F1: 1.0000 - LR: 2.00e-05\n",
      "\tEpoch 90/100 - Train loss: 0.0006 - Val accuracy: 1.0000 - Val loss: 0.0002 - Val F1: 1.0000 - LR: 1.00e-05\n",
      "\tEpoch 100/100 - Train loss: 0.0011 - Val accuracy: 1.0000 - Val loss: 0.0003 - Val F1: 1.0000 - LR: 0.00e+00\n",
      "\tBest epoch: 89 - Best val accuracy: 1.0000 - Best val loss: 0.0002 - Best val F1: 1.0000\n",
      "\n",
      "Source class: WAL | Domain: 73 | Accuracy: 0.7317 | Loss: 2.6738 | F1: 0.7067\n",
      "\n",
      "Domain: 74\n",
      "x_syn_dom.shape: (333, 3, 128) | np.unique(y_syn_dom): [1 2 3]\n",
      "x_dp_dom.shape: (35, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Training on synthetic data...\n",
      "\tEpoch 10/100 - Train loss: 0.0508 - Val accuracy: 0.9851 - Val loss: 0.0380 - Val F1: 0.9851 - LR: 9.00e-05\n",
      "\tEpoch 20/100 - Train loss: 0.0078 - Val accuracy: 1.0000 - Val loss: 0.0122 - Val F1: 1.0000 - LR: 8.00e-05\n",
      "\tEpoch 30/100 - Train loss: 0.0041 - Val accuracy: 1.0000 - Val loss: 0.0046 - Val F1: 1.0000 - LR: 7.00e-05\n",
      "\tEpoch 40/100 - Train loss: 0.0016 - Val accuracy: 1.0000 - Val loss: 0.0043 - Val F1: 1.0000 - LR: 6.00e-05\n",
      "\tEpoch 50/100 - Train loss: 0.0014 - Val accuracy: 1.0000 - Val loss: 0.0027 - Val F1: 1.0000 - LR: 5.00e-05\n",
      "\tEpoch 60/100 - Train loss: 0.0011 - Val accuracy: 1.0000 - Val loss: 0.0017 - Val F1: 1.0000 - LR: 4.00e-05\n",
      "\tEpoch 70/100 - Train loss: 0.0010 - Val accuracy: 1.0000 - Val loss: 0.0014 - Val F1: 1.0000 - LR: 3.00e-05\n",
      "\tEpoch 80/100 - Train loss: 0.0009 - Val accuracy: 1.0000 - Val loss: 0.0013 - Val F1: 1.0000 - LR: 2.00e-05\n",
      "\tEpoch 90/100 - Train loss: 0.0006 - Val accuracy: 1.0000 - Val loss: 0.0013 - Val F1: 1.0000 - LR: 1.00e-05\n",
      "\tEpoch 100/100 - Train loss: 0.0008 - Val accuracy: 1.0000 - Val loss: 0.0019 - Val F1: 1.0000 - LR: 0.00e+00\n",
      "\tBest epoch: 69 - Best val accuracy: 1.0000 - Best val loss: 0.0012 - Best val F1: 1.0000\n",
      "\n",
      "Source class: WAL | Domain: 74 | Accuracy: 0.8571 | Loss: 1.1905 | F1: 0.8161\n",
      "\n",
      "Domain: 75\n",
      "x_syn_dom.shape: (333, 3, 128) | np.unique(y_syn_dom): [1 2 3]\n",
      "x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Training on synthetic data...\n",
      "\tEpoch 10/100 - Train loss: 0.0443 - Val accuracy: 1.0000 - Val loss: 0.0306 - Val F1: 1.0000 - LR: 9.00e-05\n",
      "\tEpoch 20/100 - Train loss: 0.0069 - Val accuracy: 1.0000 - Val loss: 0.0037 - Val F1: 1.0000 - LR: 8.00e-05\n",
      "\tEpoch 30/100 - Train loss: 0.0024 - Val accuracy: 1.0000 - Val loss: 0.0016 - Val F1: 1.0000 - LR: 7.00e-05\n",
      "\tEpoch 40/100 - Train loss: 0.0022 - Val accuracy: 1.0000 - Val loss: 0.0010 - Val F1: 1.0000 - LR: 6.00e-05\n",
      "\tEpoch 50/100 - Train loss: 0.0026 - Val accuracy: 1.0000 - Val loss: 0.0006 - Val F1: 1.0000 - LR: 5.00e-05\n",
      "\tEpoch 60/100 - Train loss: 0.0030 - Val accuracy: 1.0000 - Val loss: 0.0004 - Val F1: 1.0000 - LR: 4.00e-05\n",
      "\tEpoch 70/100 - Train loss: 0.0008 - Val accuracy: 1.0000 - Val loss: 0.0004 - Val F1: 1.0000 - LR: 3.00e-05\n",
      "\tEpoch 80/100 - Train loss: 0.0008 - Val accuracy: 1.0000 - Val loss: 0.0003 - Val F1: 1.0000 - LR: 2.00e-05\n",
      "\tEpoch 90/100 - Train loss: 0.0005 - Val accuracy: 1.0000 - Val loss: 0.0003 - Val F1: 1.0000 - LR: 1.00e-05\n",
      "\tEpoch 100/100 - Train loss: 0.0007 - Val accuracy: 1.0000 - Val loss: 0.0003 - Val F1: 1.0000 - LR: 0.00e+00\n",
      "\tBest epoch: 100 - Best val accuracy: 1.0000 - Best val loss: 0.0003 - Best val F1: 1.0000\n",
      "\n",
      "Source class: WAL | Domain: 75 | Accuracy: 0.8095 | Loss: 0.6738 | F1: 0.7926\n",
      "\n",
      "Mean accuracy: 0.7629\n",
      "Mean F1: 0.7283\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def compute_TSTR_Syn(dataset):\n",
    "    accs = []\n",
    "    f1s = []\n",
    "\n",
    "    for src_class in config[dataset]['class_names']:\n",
    "        if src_class != 'WAL':\n",
    "            continue\n",
    "\n",
    "        print(f\"Source class: {src_class}\\n\")\n",
    "\n",
    "        for domain in range(config[dataset]['num_df_domains'], config[dataset]['num_df_domains'] + config[dataset]['num_dp_domains']):\n",
    "            print(f\"Domain: {domain}\")\n",
    "\n",
    "            # Load synthetic data\n",
    "            x_syn_dom, y_syn_dom, k_syn_dom = get_syn_data(dataset, syn_name, src_class, domain)\n",
    "            print(f'x_syn_dom.shape: {x_syn_dom.shape} | np.unique(y_syn_dom): {np.unique(y_syn_dom)}')\n",
    "\n",
    "            # Load Dp data\n",
    "            x_dp_dom, y_dp_dom, k_dp_dom = get_data(dataset, 'dp', src_class, domain)\n",
    "            print(f'x_dp_dom.shape: {x_dp_dom.shape} | np.unique(y_dp_dom): {np.unique(y_dp_dom)}\\n')\n",
    "\n",
    "            # Train on synthetic data and evaluate on Dp data\n",
    "            print('Training on synthetic data...')\n",
    "            acc, loss, f1 = train_and_test(x_syn_dom, y_syn_dom, x_dp_dom, y_dp_dom, dataset, num_epochs=num_epochs)\n",
    "            save_scores(src_class, domain, acc, loss, f1, 'Syn', dataset)\n",
    "            accs.append(acc)\n",
    "            f1s.append(f1)\n",
    "            print(f'Source class: {src_class} | Domain: {domain} | Accuracy: {acc:.4f} | Loss: {loss:.4f} | F1: {f1:.4f}\\n')\n",
    "\n",
    "    print(f\"Mean accuracy: {np.mean(accs):.4f}\")\n",
    "    print(f\"Mean F1: {np.mean(f1s):.4f}\\n\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "compute_TSTR_Syn('realworld_mobiact')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 626880,
     "status": "ok",
     "timestamp": 1732620078443,
     "user": {
      "displayName": "Pietro Cirino",
      "userId": "07315473796200699505"
     },
     "user_tz": -60
    },
    "id": "zVi4YsGo_J1z",
    "outputId": "e539c2bd-c095-4ce4-d645-828ce608ac7c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source class: WAL\n",
      "\n",
      "Domain: 15\n",
      "x_syn_dom.shape: (333, 3, 128) | np.unique(y_syn_dom): [1 2 3]\n",
      "x_dp_dom.shape: (50, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Training on synthetic data...\n",
      "\tEpoch 10/100 - Train loss: 0.3227 - Val accuracy: 0.3433 - Val loss: 3.9059 - Val F1: 0.1755 - LR: 9.00e-05\n",
      "\tEpoch 20/100 - Train loss: 0.0871 - Val accuracy: 0.3433 - Val loss: 4.1578 - Val F1: 0.1755 - LR: 8.00e-05\n",
      "\tEpoch 30/100 - Train loss: 0.0436 - Val accuracy: 0.3433 - Val loss: 5.2888 - Val F1: 0.1755 - LR: 7.00e-05\n",
      "\tEpoch 40/100 - Train loss: 0.0457 - Val accuracy: 0.3433 - Val loss: 3.5049 - Val F1: 0.1755 - LR: 6.00e-05\n",
      "\tEpoch 50/100 - Train loss: 0.0337 - Val accuracy: 0.3433 - Val loss: 5.6195 - Val F1: 0.1755 - LR: 5.00e-05\n",
      "\tEpoch 60/100 - Train loss: 0.0213 - Val accuracy: 0.3433 - Val loss: 6.1638 - Val F1: 0.1755 - LR: 4.00e-05\n",
      "\tEpoch 70/100 - Train loss: 0.0337 - Val accuracy: 0.3433 - Val loss: 4.6334 - Val F1: 0.1755 - LR: 3.00e-05\n",
      "\tEpoch 80/100 - Train loss: 0.0129 - Val accuracy: 0.3433 - Val loss: 3.1103 - Val F1: 0.1755 - LR: 2.00e-05\n",
      "\tEpoch 90/100 - Train loss: 0.0111 - Val accuracy: 0.3433 - Val loss: 3.6169 - Val F1: 0.1755 - LR: 1.00e-05\n",
      "\tEpoch 100/100 - Train loss: 0.0190 - Val accuracy: 0.3433 - Val loss: 5.2945 - Val F1: 0.1755 - LR: 0.00e+00\n",
      "\tBest epoch: 2 - Best val accuracy: 0.3284 - Best val loss: 1.0703 - Best val F1: 0.1623\n",
      "\n",
      "Source class: WAL | Domain: 15 | Accuracy: 0.5600 | Loss: 3.1421 | F1: 0.4545\n",
      "\n",
      "Domain: 16\n",
      "x_syn_dom.shape: (333, 3, 128) | np.unique(y_syn_dom): [1 2 3]\n",
      "x_dp_dom.shape: (54, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Training on synthetic data...\n",
      "\tEpoch 10/100 - Train loss: 0.3098 - Val accuracy: 0.3433 - Val loss: 2.4336 - Val F1: 0.1774 - LR: 9.00e-05\n",
      "\tEpoch 20/100 - Train loss: 0.1035 - Val accuracy: 0.3582 - Val loss: 3.0308 - Val F1: 0.2060 - LR: 8.00e-05\n",
      "\tEpoch 30/100 - Train loss: 0.0564 - Val accuracy: 0.3433 - Val loss: 6.6595 - Val F1: 0.1774 - LR: 7.00e-05\n",
      "\tEpoch 40/100 - Train loss: 0.0537 - Val accuracy: 0.3433 - Val loss: 8.3720 - Val F1: 0.1774 - LR: 6.00e-05\n",
      "\tEpoch 50/100 - Train loss: 0.0249 - Val accuracy: 0.3582 - Val loss: 5.6776 - Val F1: 0.2060 - LR: 5.00e-05\n",
      "\tEpoch 60/100 - Train loss: 0.0121 - Val accuracy: 0.3433 - Val loss: 7.8040 - Val F1: 0.1774 - LR: 4.00e-05\n",
      "\tEpoch 70/100 - Train loss: 0.0149 - Val accuracy: 0.3433 - Val loss: 7.3448 - Val F1: 0.1774 - LR: 3.00e-05\n",
      "\tEpoch 80/100 - Train loss: 0.0124 - Val accuracy: 0.3433 - Val loss: 7.1730 - Val F1: 0.1774 - LR: 2.00e-05\n",
      "\tEpoch 90/100 - Train loss: 0.0262 - Val accuracy: 0.3433 - Val loss: 5.9327 - Val F1: 0.1774 - LR: 1.00e-05\n",
      "\tEpoch 100/100 - Train loss: 0.0287 - Val accuracy: 0.3433 - Val loss: 6.3977 - Val F1: 0.1794 - LR: 0.00e+00\n",
      "\tBest epoch: 2 - Best val accuracy: 0.5522 - Best val loss: 0.9545 - Best val F1: 0.5479\n",
      "\n",
      "Source class: WAL | Domain: 16 | Accuracy: 0.5185 | Loss: 4.7523 | F1: 0.3821\n",
      "\n",
      "Domain: 17\n",
      "x_syn_dom.shape: (333, 3, 128) | np.unique(y_syn_dom): [1 2 3]\n",
      "x_dp_dom.shape: (53, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Training on synthetic data...\n",
      "\tEpoch 10/100 - Train loss: 0.2620 - Val accuracy: 0.3433 - Val loss: 3.4317 - Val F1: 0.1755 - LR: 9.00e-05\n",
      "\tEpoch 20/100 - Train loss: 0.0631 - Val accuracy: 0.3731 - Val loss: 3.5193 - Val F1: 0.2344 - LR: 8.00e-05\n",
      "\tEpoch 30/100 - Train loss: 0.0272 - Val accuracy: 0.3433 - Val loss: 3.0994 - Val F1: 0.1755 - LR: 7.00e-05\n",
      "\tEpoch 40/100 - Train loss: 0.0215 - Val accuracy: 0.4776 - Val loss: 1.1877 - Val F1: 0.4143 - LR: 6.00e-05\n",
      "\tEpoch 50/100 - Train loss: 0.0199 - Val accuracy: 0.4776 - Val loss: 1.1685 - Val F1: 0.3846 - LR: 5.00e-05\n",
      "\tEpoch 60/100 - Train loss: 0.0139 - Val accuracy: 0.7612 - Val loss: 0.5259 - Val F1: 0.7220 - LR: 4.00e-05\n",
      "\tEpoch 70/100 - Train loss: 0.0322 - Val accuracy: 0.3433 - Val loss: 3.0303 - Val F1: 0.1755 - LR: 3.00e-05\n",
      "\tEpoch 80/100 - Train loss: 0.0147 - Val accuracy: 0.4627 - Val loss: 1.5042 - Val F1: 0.3644 - LR: 2.00e-05\n",
      "\tEpoch 90/100 - Train loss: 0.0106 - Val accuracy: 0.3433 - Val loss: 2.6495 - Val F1: 0.1755 - LR: 1.00e-05\n",
      "\tEpoch 100/100 - Train loss: 0.0204 - Val accuracy: 0.3433 - Val loss: 2.9079 - Val F1: 0.1755 - LR: 0.00e+00\n",
      "\tBest epoch: 76 - Best val accuracy: 0.8507 - Best val loss: 0.3523 - Best val F1: 0.8435\n",
      "\n",
      "Source class: WAL | Domain: 17 | Accuracy: 0.9245 | Loss: 0.3234 | F1: 0.9238\n",
      "\n",
      "Domain: 18\n",
      "x_syn_dom.shape: (336, 3, 128) | np.unique(y_syn_dom): [1 2 3]\n",
      "x_dp_dom.shape: (54, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Training on synthetic data...\n",
      "\tEpoch 10/100 - Train loss: 0.2301 - Val accuracy: 0.3382 - Val loss: 3.3939 - Val F1: 0.1710 - LR: 9.00e-05\n",
      "\tEpoch 20/100 - Train loss: 0.1035 - Val accuracy: 0.3382 - Val loss: 1.7996 - Val F1: 0.2021 - LR: 8.00e-05\n",
      "\tEpoch 30/100 - Train loss: 0.0235 - Val accuracy: 0.3382 - Val loss: 1.9737 - Val F1: 0.1748 - LR: 7.00e-05\n",
      "\tEpoch 40/100 - Train loss: 0.0187 - Val accuracy: 0.5441 - Val loss: 1.0691 - Val F1: 0.4537 - LR: 6.00e-05\n",
      "\tEpoch 50/100 - Train loss: 0.0117 - Val accuracy: 0.5882 - Val loss: 0.8923 - Val F1: 0.4923 - LR: 5.00e-05\n",
      "\tEpoch 60/100 - Train loss: 0.0129 - Val accuracy: 0.6618 - Val loss: 0.6437 - Val F1: 0.5317 - LR: 4.00e-05\n",
      "\tEpoch 70/100 - Train loss: 0.0139 - Val accuracy: 0.4706 - Val loss: 1.1032 - Val F1: 0.3776 - LR: 3.00e-05\n",
      "\tEpoch 80/100 - Train loss: 0.0064 - Val accuracy: 0.4412 - Val loss: 1.4936 - Val F1: 0.3414 - LR: 2.00e-05\n",
      "\tEpoch 90/100 - Train loss: 0.0088 - Val accuracy: 0.4265 - Val loss: 1.6147 - Val F1: 0.3217 - LR: 1.00e-05\n",
      "\tEpoch 100/100 - Train loss: 0.0181 - Val accuracy: 0.4706 - Val loss: 1.4679 - Val F1: 0.3776 - LR: 0.00e+00\n",
      "\tBest epoch: 42 - Best val accuracy: 0.9412 - Best val loss: 0.3027 - Best val F1: 0.9408\n",
      "\n",
      "Source class: WAL | Domain: 18 | Accuracy: 0.6852 | Loss: 0.7368 | F1: 0.5947\n",
      "\n",
      "Domain: 19\n",
      "x_syn_dom.shape: (333, 3, 128) | np.unique(y_syn_dom): [1 2 3]\n",
      "x_dp_dom.shape: (54, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Training on synthetic data...\n",
      "\tEpoch 10/100 - Train loss: 0.1423 - Val accuracy: 0.3433 - Val loss: 5.7709 - Val F1: 0.1755 - LR: 9.00e-05\n",
      "\tEpoch 20/100 - Train loss: 0.0268 - Val accuracy: 0.3433 - Val loss: 7.3993 - Val F1: 0.1755 - LR: 8.00e-05\n",
      "\tEpoch 30/100 - Train loss: 0.0194 - Val accuracy: 0.3433 - Val loss: 6.9632 - Val F1: 0.1755 - LR: 7.00e-05\n",
      "\tEpoch 40/100 - Train loss: 0.0037 - Val accuracy: 0.3433 - Val loss: 9.2746 - Val F1: 0.1755 - LR: 6.00e-05\n",
      "\tEpoch 50/100 - Train loss: 0.0100 - Val accuracy: 0.3433 - Val loss: 8.4970 - Val F1: 0.1755 - LR: 5.00e-05\n",
      "\tEpoch 60/100 - Train loss: 0.0032 - Val accuracy: 0.3433 - Val loss: 8.0500 - Val F1: 0.1755 - LR: 4.00e-05\n",
      "\tEpoch 70/100 - Train loss: 0.0045 - Val accuracy: 0.3433 - Val loss: 9.4296 - Val F1: 0.1755 - LR: 3.00e-05\n",
      "\tEpoch 80/100 - Train loss: 0.0084 - Val accuracy: 0.3433 - Val loss: 9.6783 - Val F1: 0.1755 - LR: 2.00e-05\n",
      "\tEpoch 90/100 - Train loss: 0.0015 - Val accuracy: 0.3433 - Val loss: 9.9065 - Val F1: 0.1755 - LR: 1.00e-05\n",
      "\tEpoch 100/100 - Train loss: 0.0014 - Val accuracy: 0.3433 - Val loss: 8.5811 - Val F1: 0.1755 - LR: 0.00e+00\n",
      "\tBest epoch: 3 - Best val accuracy: 0.3881 - Best val loss: 0.7835 - Best val F1: 0.2849\n",
      "\n",
      "Source class: WAL | Domain: 19 | Accuracy: 0.5185 | Loss: 5.0506 | F1: 0.3541\n",
      "\n",
      "Domain: 20\n",
      "x_syn_dom.shape: (333, 3, 128) | np.unique(y_syn_dom): [1 2 3]\n",
      "x_dp_dom.shape: (51, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Training on synthetic data...\n",
      "\tEpoch 10/100 - Train loss: 0.2503 - Val accuracy: 0.3582 - Val loss: 1.4113 - Val F1: 0.2161 - LR: 9.00e-05\n",
      "\tEpoch 20/100 - Train loss: 0.0860 - Val accuracy: 0.3731 - Val loss: 1.5175 - Val F1: 0.2451 - LR: 8.00e-05\n",
      "\tEpoch 30/100 - Train loss: 0.0300 - Val accuracy: 0.3582 - Val loss: 1.8385 - Val F1: 0.2131 - LR: 7.00e-05\n",
      "\tEpoch 40/100 - Train loss: 0.0164 - Val accuracy: 0.3433 - Val loss: 3.3709 - Val F1: 0.1755 - LR: 6.00e-05\n",
      "\tEpoch 50/100 - Train loss: 0.0106 - Val accuracy: 0.4776 - Val loss: 1.5573 - Val F1: 0.3821 - LR: 5.00e-05\n",
      "\tEpoch 60/100 - Train loss: 0.0114 - Val accuracy: 0.3582 - Val loss: 2.5554 - Val F1: 0.2068 - LR: 4.00e-05\n",
      "\tEpoch 70/100 - Train loss: 0.0104 - Val accuracy: 0.4776 - Val loss: 1.9211 - Val F1: 0.3821 - LR: 3.00e-05\n",
      "\tEpoch 80/100 - Train loss: 0.0059 - Val accuracy: 0.3582 - Val loss: 2.9875 - Val F1: 0.2060 - LR: 2.00e-05\n",
      "\tEpoch 90/100 - Train loss: 0.0040 - Val accuracy: 0.3582 - Val loss: 3.3300 - Val F1: 0.2060 - LR: 1.00e-05\n",
      "\tEpoch 100/100 - Train loss: 0.0047 - Val accuracy: 0.4925 - Val loss: 1.6393 - Val F1: 0.3989 - LR: 0.00e+00\n",
      "\tBest epoch: 3 - Best val accuracy: 0.7761 - Best val loss: 0.6690 - Best val F1: 0.7612\n",
      "\n",
      "Source class: WAL | Domain: 20 | Accuracy: 0.7255 | Loss: 0.9929 | F1: 0.6424\n",
      "\n",
      "Domain: 21\n",
      "x_syn_dom.shape: (336, 3, 128) | np.unique(y_syn_dom): [1 2 3]\n",
      "x_dp_dom.shape: (47, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Training on synthetic data...\n",
      "\tEpoch 10/100 - Train loss: 0.2128 - Val accuracy: 0.3382 - Val loss: 4.3186 - Val F1: 0.1710 - LR: 9.00e-05\n",
      "\tEpoch 20/100 - Train loss: 0.0654 - Val accuracy: 0.3382 - Val loss: 4.3940 - Val F1: 0.1710 - LR: 8.00e-05\n",
      "\tEpoch 30/100 - Train loss: 0.0310 - Val accuracy: 0.3382 - Val loss: 5.7231 - Val F1: 0.1710 - LR: 7.00e-05\n",
      "\tEpoch 40/100 - Train loss: 0.0148 - Val accuracy: 0.3382 - Val loss: 3.8477 - Val F1: 0.1710 - LR: 6.00e-05\n",
      "\tEpoch 50/100 - Train loss: 0.0112 - Val accuracy: 0.3382 - Val loss: 7.2119 - Val F1: 0.1710 - LR: 5.00e-05\n",
      "\tEpoch 60/100 - Train loss: 0.0058 - Val accuracy: 0.3382 - Val loss: 7.5988 - Val F1: 0.1710 - LR: 4.00e-05\n",
      "\tEpoch 70/100 - Train loss: 0.0116 - Val accuracy: 0.3382 - Val loss: 5.5201 - Val F1: 0.1710 - LR: 3.00e-05\n",
      "\tEpoch 80/100 - Train loss: 0.0024 - Val accuracy: 0.3382 - Val loss: 6.1858 - Val F1: 0.1710 - LR: 2.00e-05\n",
      "\tEpoch 90/100 - Train loss: 0.0049 - Val accuracy: 0.3382 - Val loss: 6.7114 - Val F1: 0.1710 - LR: 1.00e-05\n",
      "\tEpoch 100/100 - Train loss: 0.0138 - Val accuracy: 0.3382 - Val loss: 7.6913 - Val F1: 0.1710 - LR: 0.00e+00\n",
      "\tBest epoch: 2 - Best val accuracy: 0.3382 - Best val loss: 1.0149 - Best val F1: 0.1937\n",
      "\n",
      "Source class: WAL | Domain: 21 | Accuracy: 0.5957 | Loss: 4.3621 | F1: 0.4448\n",
      "\n",
      "Domain: 22\n",
      "x_syn_dom.shape: (333, 3, 128) | np.unique(y_syn_dom): [1 2 3]\n",
      "x_dp_dom.shape: (54, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Training on synthetic data...\n",
      "\tEpoch 10/100 - Train loss: 0.1795 - Val accuracy: 0.9701 - Val loss: 0.3521 - Val F1: 0.9701 - LR: 9.00e-05\n",
      "\tEpoch 20/100 - Train loss: 0.0591 - Val accuracy: 0.6716 - Val loss: 0.9233 - Val F1: 0.5622 - LR: 8.00e-05\n",
      "\tEpoch 30/100 - Train loss: 0.0359 - Val accuracy: 0.6716 - Val loss: 1.0384 - Val F1: 0.5622 - LR: 7.00e-05\n",
      "\tEpoch 40/100 - Train loss: 0.0085 - Val accuracy: 0.6716 - Val loss: 1.2598 - Val F1: 0.5622 - LR: 6.00e-05\n",
      "\tEpoch 50/100 - Train loss: 0.0131 - Val accuracy: 0.6716 - Val loss: 0.8708 - Val F1: 0.5406 - LR: 5.00e-05\n",
      "\tEpoch 60/100 - Train loss: 0.0045 - Val accuracy: 0.6716 - Val loss: 1.9006 - Val F1: 0.5622 - LR: 4.00e-05\n",
      "\tEpoch 70/100 - Train loss: 0.0039 - Val accuracy: 0.6716 - Val loss: 1.2640 - Val F1: 0.5606 - LR: 3.00e-05\n",
      "\tEpoch 80/100 - Train loss: 0.0037 - Val accuracy: 0.6716 - Val loss: 1.3264 - Val F1: 0.5465 - LR: 2.00e-05\n",
      "\tEpoch 90/100 - Train loss: 0.0071 - Val accuracy: 0.6716 - Val loss: 1.8697 - Val F1: 0.5622 - LR: 1.00e-05\n",
      "\tEpoch 100/100 - Train loss: 0.0083 - Val accuracy: 0.6716 - Val loss: 1.4434 - Val F1: 0.5465 - LR: 0.00e+00\n",
      "\tBest epoch: 18 - Best val accuracy: 0.9851 - Best val loss: 0.2507 - Best val F1: 0.9851\n",
      "\n",
      "Source class: WAL | Domain: 22 | Accuracy: 0.7222 | Loss: 0.9686 | F1: 0.6233\n",
      "\n",
      "Domain: 23\n",
      "x_syn_dom.shape: (336, 3, 128) | np.unique(y_syn_dom): [1 2 3]\n",
      "x_dp_dom.shape: (52, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Training on synthetic data...\n",
      "\tEpoch 10/100 - Train loss: 0.2224 - Val accuracy: 0.3382 - Val loss: 1.7067 - Val F1: 0.1875 - LR: 9.00e-05\n",
      "\tEpoch 20/100 - Train loss: 0.0588 - Val accuracy: 0.7206 - Val loss: 0.5629 - Val F1: 0.6860 - LR: 8.00e-05\n",
      "\tEpoch 30/100 - Train loss: 0.0433 - Val accuracy: 0.7059 - Val loss: 0.4688 - Val F1: 0.6236 - LR: 7.00e-05\n",
      "\tEpoch 40/100 - Train loss: 0.0163 - Val accuracy: 0.6912 - Val loss: 0.5927 - Val F1: 0.6001 - LR: 6.00e-05\n",
      "\tEpoch 50/100 - Train loss: 0.0210 - Val accuracy: 0.6618 - Val loss: 0.7974 - Val F1: 0.5451 - LR: 5.00e-05\n",
      "\tEpoch 60/100 - Train loss: 0.0147 - Val accuracy: 0.6765 - Val loss: 0.6483 - Val F1: 0.5679 - LR: 4.00e-05\n",
      "\tEpoch 70/100 - Train loss: 0.0278 - Val accuracy: 0.6618 - Val loss: 1.1450 - Val F1: 0.5326 - LR: 3.00e-05\n",
      "\tEpoch 80/100 - Train loss: 0.0151 - Val accuracy: 0.6618 - Val loss: 1.0260 - Val F1: 0.5273 - LR: 2.00e-05\n",
      "\tEpoch 90/100 - Train loss: 0.0138 - Val accuracy: 0.6618 - Val loss: 1.3985 - Val F1: 0.5451 - LR: 1.00e-05\n",
      "\tEpoch 100/100 - Train loss: 0.0098 - Val accuracy: 0.6618 - Val loss: 1.1268 - Val F1: 0.5451 - LR: 0.00e+00\n",
      "\tBest epoch: 55 - Best val accuracy: 0.8824 - Best val loss: 0.2127 - Best val F1: 0.8769\n",
      "\n",
      "Source class: WAL | Domain: 23 | Accuracy: 0.7692 | Loss: 0.7238 | F1: 0.6818\n",
      "\n",
      "Domain: 24\n",
      "x_syn_dom.shape: (333, 3, 128) | np.unique(y_syn_dom): [1 2 3]\n",
      "x_dp_dom.shape: (51, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Training on synthetic data...\n",
      "\tEpoch 10/100 - Train loss: 0.2280 - Val accuracy: 0.5373 - Val loss: 1.2173 - Val F1: 0.4344 - LR: 9.00e-05\n",
      "\tEpoch 20/100 - Train loss: 0.0997 - Val accuracy: 0.9552 - Val loss: 0.2561 - Val F1: 0.9550 - LR: 8.00e-05\n",
      "\tEpoch 30/100 - Train loss: 0.0500 - Val accuracy: 0.7015 - Val loss: 0.5294 - Val F1: 0.6238 - LR: 7.00e-05\n",
      "\tEpoch 40/100 - Train loss: 0.0293 - Val accuracy: 0.6716 - Val loss: 0.8526 - Val F1: 0.5622 - LR: 6.00e-05\n",
      "\tEpoch 50/100 - Train loss: 0.0196 - Val accuracy: 0.9403 - Val loss: 0.2148 - Val F1: 0.9403 - LR: 5.00e-05\n",
      "\tEpoch 60/100 - Train loss: 0.0241 - Val accuracy: 0.7910 - Val loss: 0.3921 - Val F1: 0.7675 - LR: 4.00e-05\n",
      "\tEpoch 70/100 - Train loss: 0.0098 - Val accuracy: 0.8806 - Val loss: 0.2703 - Val F1: 0.8783 - LR: 3.00e-05\n",
      "\tEpoch 80/100 - Train loss: 0.0107 - Val accuracy: 0.7463 - Val loss: 0.4694 - Val F1: 0.7017 - LR: 2.00e-05\n",
      "\tEpoch 90/100 - Train loss: 0.0215 - Val accuracy: 0.6269 - Val loss: 0.8694 - Val F1: 0.5203 - LR: 1.00e-05\n",
      "\tEpoch 100/100 - Train loss: 0.0222 - Val accuracy: 0.7313 - Val loss: 0.5540 - Val F1: 0.6773 - LR: 0.00e+00\n",
      "\tBest epoch: 68 - Best val accuracy: 0.9552 - Best val loss: 0.1575 - Best val F1: 0.9550\n",
      "\n",
      "Source class: WAL | Domain: 24 | Accuracy: 0.8235 | Loss: 0.3227 | F1: 0.8133\n",
      "\n",
      "Domain: 25\n",
      "x_syn_dom.shape: (336, 3, 128) | np.unique(y_syn_dom): [1 2 3]\n",
      "x_dp_dom.shape: (54, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Training on synthetic data...\n",
      "\tEpoch 10/100 - Train loss: 0.1446 - Val accuracy: 0.9853 - Val loss: 0.2545 - Val F1: 0.9853 - LR: 9.00e-05\n",
      "\tEpoch 20/100 - Train loss: 0.0467 - Val accuracy: 1.0000 - Val loss: 0.1530 - Val F1: 1.0000 - LR: 8.00e-05\n",
      "\tEpoch 30/100 - Train loss: 0.0238 - Val accuracy: 0.7647 - Val loss: 0.3186 - Val F1: 0.7278 - LR: 7.00e-05\n",
      "\tEpoch 40/100 - Train loss: 0.0055 - Val accuracy: 0.7059 - Val loss: 0.5347 - Val F1: 0.6714 - LR: 6.00e-05\n",
      "\tEpoch 50/100 - Train loss: 0.0076 - Val accuracy: 1.0000 - Val loss: 0.1337 - Val F1: 1.0000 - LR: 5.00e-05\n",
      "\tEpoch 60/100 - Train loss: 0.0060 - Val accuracy: 0.9853 - Val loss: 0.1086 - Val F1: 0.9853 - LR: 4.00e-05\n",
      "\tEpoch 70/100 - Train loss: 0.0032 - Val accuracy: 0.9559 - Val loss: 0.1323 - Val F1: 0.9556 - LR: 3.00e-05\n",
      "\tEpoch 80/100 - Train loss: 0.0020 - Val accuracy: 0.9706 - Val loss: 0.1357 - Val F1: 0.9705 - LR: 2.00e-05\n",
      "\tEpoch 90/100 - Train loss: 0.0039 - Val accuracy: 0.9412 - Val loss: 0.1800 - Val F1: 0.9406 - LR: 1.00e-05\n",
      "\tEpoch 100/100 - Train loss: 0.0032 - Val accuracy: 0.8382 - Val loss: 0.3413 - Val F1: 0.8290 - LR: 0.00e+00\n",
      "\tBest epoch: 79 - Best val accuracy: 1.0000 - Best val loss: 0.0726 - Best val F1: 1.0000\n",
      "\n",
      "Source class: WAL | Domain: 25 | Accuracy: 0.7593 | Loss: 1.8923 | F1: 0.6790\n",
      "\n",
      "Domain: 26\n",
      "x_syn_dom.shape: (333, 3, 128) | np.unique(y_syn_dom): [1 2 3]\n",
      "x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Training on synthetic data...\n",
      "\tEpoch 10/100 - Train loss: 0.1331 - Val accuracy: 0.9851 - Val loss: 0.2858 - Val F1: 0.9851 - LR: 9.00e-05\n",
      "\tEpoch 20/100 - Train loss: 0.0468 - Val accuracy: 0.6567 - Val loss: 0.6741 - Val F1: 0.5660 - LR: 8.00e-05\n",
      "\tEpoch 30/100 - Train loss: 0.0672 - Val accuracy: 0.7164 - Val loss: 0.4989 - Val F1: 0.6732 - LR: 7.00e-05\n",
      "\tEpoch 40/100 - Train loss: 0.0135 - Val accuracy: 0.7313 - Val loss: 0.4987 - Val F1: 0.6773 - LR: 6.00e-05\n",
      "\tEpoch 50/100 - Train loss: 0.0090 - Val accuracy: 0.6716 - Val loss: 1.1054 - Val F1: 0.5800 - LR: 5.00e-05\n",
      "\tEpoch 60/100 - Train loss: 0.0071 - Val accuracy: 0.7761 - Val loss: 0.4274 - Val F1: 0.7467 - LR: 4.00e-05\n",
      "\tEpoch 70/100 - Train loss: 0.0108 - Val accuracy: 0.6866 - Val loss: 0.6862 - Val F1: 0.5941 - LR: 3.00e-05\n",
      "\tEpoch 80/100 - Train loss: 0.0047 - Val accuracy: 0.6866 - Val loss: 0.5922 - Val F1: 0.5941 - LR: 2.00e-05\n",
      "\tEpoch 90/100 - Train loss: 0.0030 - Val accuracy: 0.6866 - Val loss: 0.6083 - Val F1: 0.5941 - LR: 1.00e-05\n",
      "\tEpoch 100/100 - Train loss: 0.0051 - Val accuracy: 0.6866 - Val loss: 0.9593 - Val F1: 0.5941 - LR: 0.00e+00\n",
      "\tBest epoch: 57 - Best val accuracy: 0.9851 - Best val loss: 0.1127 - Best val F1: 0.9851\n",
      "\n",
      "Source class: WAL | Domain: 26 | Accuracy: 0.8095 | Loss: 0.7982 | F1: 0.7606\n",
      "\n",
      "Domain: 27\n",
      "x_syn_dom.shape: (333, 3, 128) | np.unique(y_syn_dom): [1 2 3]\n",
      "x_dp_dom.shape: (54, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Training on synthetic data...\n",
      "\tEpoch 10/100 - Train loss: 0.2253 - Val accuracy: 0.3433 - Val loss: 2.8348 - Val F1: 0.2078 - LR: 9.00e-05\n",
      "\tEpoch 20/100 - Train loss: 0.0851 - Val accuracy: 0.5373 - Val loss: 3.3815 - Val F1: 0.4369 - LR: 8.00e-05\n",
      "\tEpoch 30/100 - Train loss: 0.0385 - Val accuracy: 0.4478 - Val loss: 3.7773 - Val F1: 0.3490 - LR: 7.00e-05\n",
      "\tEpoch 40/100 - Train loss: 0.0522 - Val accuracy: 0.6567 - Val loss: 3.1968 - Val F1: 0.5481 - LR: 6.00e-05\n",
      "\tEpoch 50/100 - Train loss: 0.0310 - Val accuracy: 0.6567 - Val loss: 2.9614 - Val F1: 0.5481 - LR: 5.00e-05\n",
      "\tEpoch 60/100 - Train loss: 0.0179 - Val accuracy: 0.6269 - Val loss: 3.4293 - Val F1: 0.5203 - LR: 4.00e-05\n",
      "\tEpoch 70/100 - Train loss: 0.0051 - Val accuracy: 0.6418 - Val loss: 3.2477 - Val F1: 0.5342 - LR: 3.00e-05\n",
      "\tEpoch 80/100 - Train loss: 0.0078 - Val accuracy: 0.6418 - Val loss: 2.9469 - Val F1: 0.5342 - LR: 2.00e-05\n",
      "\tEpoch 90/100 - Train loss: 0.0094 - Val accuracy: 0.6418 - Val loss: 2.5238 - Val F1: 0.5342 - LR: 1.00e-05\n",
      "\tEpoch 100/100 - Train loss: 0.0062 - Val accuracy: 0.4478 - Val loss: 2.8226 - Val F1: 0.3490 - LR: 0.00e+00\n",
      "\tBest epoch: 3 - Best val accuracy: 0.6716 - Best val loss: 0.6930 - Best val F1: 0.5622\n",
      "\n",
      "Source class: WAL | Domain: 27 | Accuracy: 0.6296 | Loss: 1.5789 | F1: 0.5430\n",
      "\n",
      "Domain: 28\n",
      "x_syn_dom.shape: (333, 3, 128) | np.unique(y_syn_dom): [1 2 3]\n",
      "x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Training on synthetic data...\n",
      "\tEpoch 10/100 - Train loss: 0.1980 - Val accuracy: 0.3433 - Val loss: 4.3209 - Val F1: 0.1755 - LR: 9.00e-05\n",
      "\tEpoch 20/100 - Train loss: 0.0734 - Val accuracy: 0.3433 - Val loss: 5.5269 - Val F1: 0.1755 - LR: 8.00e-05\n",
      "\tEpoch 30/100 - Train loss: 0.0248 - Val accuracy: 0.3433 - Val loss: 3.7239 - Val F1: 0.1755 - LR: 7.00e-05\n",
      "\tEpoch 40/100 - Train loss: 0.0140 - Val accuracy: 0.6269 - Val loss: 2.8253 - Val F1: 0.5227 - LR: 6.00e-05\n",
      "\tEpoch 50/100 - Train loss: 0.0097 - Val accuracy: 0.6567 - Val loss: 3.2395 - Val F1: 0.5457 - LR: 5.00e-05\n",
      "\tEpoch 60/100 - Train loss: 0.0081 - Val accuracy: 0.3881 - Val loss: 4.3101 - Val F1: 0.2603 - LR: 4.00e-05\n",
      "\tEpoch 70/100 - Train loss: 0.0056 - Val accuracy: 0.6716 - Val loss: 3.0647 - Val F1: 0.5477 - LR: 3.00e-05\n",
      "\tEpoch 80/100 - Train loss: 0.0108 - Val accuracy: 0.6716 - Val loss: 3.2843 - Val F1: 0.5436 - LR: 2.00e-05\n",
      "\tEpoch 90/100 - Train loss: 0.0093 - Val accuracy: 0.6418 - Val loss: 3.9847 - Val F1: 0.5343 - LR: 1.00e-05\n",
      "\tEpoch 100/100 - Train loss: 0.0076 - Val accuracy: 0.6567 - Val loss: 3.5880 - Val F1: 0.5422 - LR: 0.00e+00\n",
      "\tBest epoch: 2 - Best val accuracy: 0.3284 - Best val loss: 1.1035 - Best val F1: 0.1642\n",
      "\n",
      "Source class: WAL | Domain: 28 | Accuracy: 0.6905 | Loss: 2.3303 | F1: 0.5827\n",
      "\n",
      "Domain: 29\n",
      "x_syn_dom.shape: (333, 3, 128) | np.unique(y_syn_dom): [1 2 3]\n",
      "x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Training on synthetic data...\n",
      "\tEpoch 10/100 - Train loss: 0.0984 - Val accuracy: 0.3582 - Val loss: 3.7468 - Val F1: 0.2357 - LR: 9.00e-05\n",
      "\tEpoch 20/100 - Train loss: 0.0319 - Val accuracy: 0.6716 - Val loss: 2.3433 - Val F1: 0.5622 - LR: 8.00e-05\n",
      "\tEpoch 30/100 - Train loss: 0.0208 - Val accuracy: 0.5224 - Val loss: 2.9173 - Val F1: 0.4227 - LR: 7.00e-05\n",
      "\tEpoch 40/100 - Train loss: 0.0081 - Val accuracy: 0.6567 - Val loss: 2.5028 - Val F1: 0.5481 - LR: 6.00e-05\n",
      "\tEpoch 50/100 - Train loss: 0.0134 - Val accuracy: 0.4627 - Val loss: 2.5266 - Val F1: 0.3642 - LR: 5.00e-05\n",
      "\tEpoch 60/100 - Train loss: 0.0095 - Val accuracy: 0.5224 - Val loss: 3.2317 - Val F1: 0.4227 - LR: 4.00e-05\n",
      "\tEpoch 70/100 - Train loss: 0.0025 - Val accuracy: 0.8060 - Val loss: 0.3777 - Val F1: 0.7957 - LR: 3.00e-05\n",
      "\tEpoch 80/100 - Train loss: 0.0049 - Val accuracy: 0.4030 - Val loss: 1.8281 - Val F1: 0.2850 - LR: 2.00e-05\n",
      "\tEpoch 90/100 - Train loss: 0.0168 - Val accuracy: 0.4030 - Val loss: 1.4389 - Val F1: 0.2899 - LR: 1.00e-05\n",
      "\tEpoch 100/100 - Train loss: 0.0052 - Val accuracy: 0.6119 - Val loss: 1.2935 - Val F1: 0.5065 - LR: 0.00e+00\n",
      "\tBest epoch: 70 - Best val accuracy: 0.8060 - Best val loss: 0.3777 - Best val F1: 0.7957\n",
      "\n",
      "Source class: WAL | Domain: 29 | Accuracy: 0.8333 | Loss: 1.1512 | F1: 0.7778\n",
      "\n",
      "Domain: 30\n",
      "x_syn_dom.shape: (333, 3, 128) | np.unique(y_syn_dom): [1 2 3]\n",
      "x_dp_dom.shape: (50, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Training on synthetic data...\n",
      "\tEpoch 10/100 - Train loss: 0.3394 - Val accuracy: 0.4478 - Val loss: 0.8131 - Val F1: 0.3591 - LR: 9.00e-05\n",
      "\tEpoch 20/100 - Train loss: 0.1094 - Val accuracy: 0.7612 - Val loss: 0.3967 - Val F1: 0.7145 - LR: 8.00e-05\n",
      "\tEpoch 30/100 - Train loss: 0.0606 - Val accuracy: 0.7164 - Val loss: 0.8255 - Val F1: 0.6514 - LR: 7.00e-05\n",
      "\tEpoch 40/100 - Train loss: 0.0397 - Val accuracy: 0.6866 - Val loss: 0.8187 - Val F1: 0.5941 - LR: 6.00e-05\n",
      "\tEpoch 50/100 - Train loss: 0.0210 - Val accuracy: 0.7164 - Val loss: 0.7363 - Val F1: 0.6514 - LR: 5.00e-05\n",
      "\tEpoch 60/100 - Train loss: 0.0152 - Val accuracy: 0.7164 - Val loss: 1.0475 - Val F1: 0.6514 - LR: 4.00e-05\n",
      "\tEpoch 70/100 - Train loss: 0.0200 - Val accuracy: 0.7164 - Val loss: 0.9899 - Val F1: 0.6514 - LR: 3.00e-05\n",
      "\tEpoch 80/100 - Train loss: 0.0139 - Val accuracy: 0.7164 - Val loss: 1.1725 - Val F1: 0.6514 - LR: 2.00e-05\n",
      "\tEpoch 90/100 - Train loss: 0.0105 - Val accuracy: 0.7015 - Val loss: 1.3020 - Val F1: 0.6238 - LR: 1.00e-05\n",
      "\tEpoch 100/100 - Train loss: 0.0361 - Val accuracy: 0.7015 - Val loss: 1.0810 - Val F1: 0.6238 - LR: 0.00e+00\n",
      "\tBest epoch: 17 - Best val accuracy: 0.8507 - Best val loss: 0.3622 - Best val F1: 0.8386\n",
      "\n",
      "Source class: WAL | Domain: 30 | Accuracy: 0.7600 | Loss: 0.5964 | F1: 0.6913\n",
      "\n",
      "Domain: 31\n",
      "x_syn_dom.shape: (333, 3, 128) | np.unique(y_syn_dom): [1 2 3]\n",
      "x_dp_dom.shape: (43, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Training on synthetic data...\n",
      "\tEpoch 10/100 - Train loss: 0.1397 - Val accuracy: 0.8657 - Val loss: 0.3204 - Val F1: 0.8551 - LR: 9.00e-05\n",
      "\tEpoch 20/100 - Train loss: 0.0527 - Val accuracy: 0.8507 - Val loss: 0.2945 - Val F1: 0.8383 - LR: 8.00e-05\n",
      "\tEpoch 30/100 - Train loss: 0.0477 - Val accuracy: 0.9552 - Val loss: 0.2005 - Val F1: 0.9550 - LR: 7.00e-05\n",
      "\tEpoch 40/100 - Train loss: 0.0181 - Val accuracy: 0.9851 - Val loss: 0.1724 - Val F1: 0.9851 - LR: 6.00e-05\n",
      "\tEpoch 50/100 - Train loss: 0.0113 - Val accuracy: 0.7910 - Val loss: 0.3502 - Val F1: 0.7646 - LR: 5.00e-05\n",
      "\tEpoch 60/100 - Train loss: 0.0127 - Val accuracy: 0.9403 - Val loss: 0.2254 - Val F1: 0.9397 - LR: 4.00e-05\n",
      "\tEpoch 70/100 - Train loss: 0.0210 - Val accuracy: 0.9552 - Val loss: 0.1389 - Val F1: 0.9550 - LR: 3.00e-05\n",
      "\tEpoch 80/100 - Train loss: 0.0211 - Val accuracy: 0.9403 - Val loss: 0.1860 - Val F1: 0.9398 - LR: 2.00e-05\n",
      "\tEpoch 90/100 - Train loss: 0.0234 - Val accuracy: 0.9403 - Val loss: 0.1702 - Val F1: 0.9397 - LR: 1.00e-05\n",
      "\tEpoch 100/100 - Train loss: 0.0074 - Val accuracy: 0.7761 - Val loss: 0.4089 - Val F1: 0.7467 - LR: 0.00e+00\n",
      "\tBest epoch: 67 - Best val accuracy: 0.9552 - Best val loss: 0.1277 - Best val F1: 0.9550\n",
      "\n",
      "Source class: WAL | Domain: 31 | Accuracy: 0.8372 | Loss: 0.8171 | F1: 0.8165\n",
      "\n",
      "Domain: 32\n",
      "x_syn_dom.shape: (333, 3, 128) | np.unique(y_syn_dom): [1 2 3]\n",
      "x_dp_dom.shape: (52, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Training on synthetic data...\n",
      "\tEpoch 10/100 - Train loss: 0.2741 - Val accuracy: 0.3433 - Val loss: 6.6827 - Val F1: 0.1755 - LR: 9.00e-05\n",
      "\tEpoch 20/100 - Train loss: 0.0951 - Val accuracy: 0.3433 - Val loss: 6.0692 - Val F1: 0.1755 - LR: 8.00e-05\n",
      "\tEpoch 30/100 - Train loss: 0.0345 - Val accuracy: 0.3433 - Val loss: 6.5563 - Val F1: 0.1755 - LR: 7.00e-05\n",
      "\tEpoch 40/100 - Train loss: 0.0189 - Val accuracy: 0.3433 - Val loss: 5.7618 - Val F1: 0.1755 - LR: 6.00e-05\n",
      "\tEpoch 50/100 - Train loss: 0.0317 - Val accuracy: 0.3582 - Val loss: 3.4679 - Val F1: 0.2129 - LR: 5.00e-05\n",
      "\tEpoch 60/100 - Train loss: 0.0079 - Val accuracy: 0.3433 - Val loss: 4.7257 - Val F1: 0.1755 - LR: 4.00e-05\n",
      "\tEpoch 70/100 - Train loss: 0.0041 - Val accuracy: 0.3582 - Val loss: 3.8973 - Val F1: 0.2089 - LR: 3.00e-05\n",
      "\tEpoch 80/100 - Train loss: 0.0083 - Val accuracy: 0.3433 - Val loss: 4.5423 - Val F1: 0.1755 - LR: 2.00e-05\n",
      "\tEpoch 90/100 - Train loss: 0.0070 - Val accuracy: 0.3433 - Val loss: 6.0729 - Val F1: 0.1755 - LR: 1.00e-05\n",
      "\tEpoch 100/100 - Train loss: 0.0071 - Val accuracy: 0.4328 - Val loss: 2.8907 - Val F1: 0.3268 - LR: 0.00e+00\n",
      "\tBest epoch: 1 - Best val accuracy: 0.3284 - Best val loss: 1.1228 - Best val F1: 0.1623\n",
      "\n",
      "Source class: WAL | Domain: 32 | Accuracy: 0.5385 | Loss: 2.0944 | F1: 0.4370\n",
      "\n",
      "Domain: 33\n",
      "x_syn_dom.shape: (336, 3, 128) | np.unique(y_syn_dom): [1 2 3]\n",
      "x_dp_dom.shape: (44, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Training on synthetic data...\n",
      "\tEpoch 10/100 - Train loss: 0.1674 - Val accuracy: 0.3382 - Val loss: 3.0356 - Val F1: 0.1710 - LR: 9.00e-05\n",
      "\tEpoch 20/100 - Train loss: 0.0464 - Val accuracy: 0.3382 - Val loss: 2.3083 - Val F1: 0.1748 - LR: 8.00e-05\n",
      "\tEpoch 30/100 - Train loss: 0.0223 - Val accuracy: 0.4706 - Val loss: 1.6556 - Val F1: 0.3776 - LR: 7.00e-05\n",
      "\tEpoch 40/100 - Train loss: 0.0104 - Val accuracy: 0.5294 - Val loss: 1.2763 - Val F1: 0.4357 - LR: 6.00e-05\n",
      "\tEpoch 50/100 - Train loss: 0.0111 - Val accuracy: 0.5735 - Val loss: 0.8203 - Val F1: 0.4996 - LR: 5.00e-05\n",
      "\tEpoch 60/100 - Train loss: 0.0094 - Val accuracy: 0.6176 - Val loss: 0.6924 - Val F1: 0.5999 - LR: 4.00e-05\n",
      "\tEpoch 70/100 - Train loss: 0.0028 - Val accuracy: 0.5147 - Val loss: 2.0999 - Val F1: 0.4253 - LR: 3.00e-05\n",
      "\tEpoch 80/100 - Train loss: 0.0043 - Val accuracy: 0.5000 - Val loss: 1.2984 - Val F1: 0.4126 - LR: 2.00e-05\n",
      "\tEpoch 90/100 - Train loss: 0.0052 - Val accuracy: 0.6029 - Val loss: 1.0019 - Val F1: 0.5002 - LR: 1.00e-05\n",
      "\tEpoch 100/100 - Train loss: 0.0055 - Val accuracy: 0.5294 - Val loss: 1.5827 - Val F1: 0.4398 - LR: 0.00e+00\n",
      "\tBest epoch: 85 - Best val accuracy: 0.6912 - Best val loss: 0.4594 - Best val F1: 0.6344\n",
      "\n",
      "Source class: WAL | Domain: 33 | Accuracy: 0.8182 | Loss: 0.6060 | F1: 0.7475\n",
      "\n",
      "Domain: 34\n",
      "x_syn_dom.shape: (336, 3, 128) | np.unique(y_syn_dom): [1 2 3]\n",
      "x_dp_dom.shape: (49, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Training on synthetic data...\n",
      "\tEpoch 10/100 - Train loss: 0.1019 - Val accuracy: 0.4412 - Val loss: 0.8855 - Val F1: 0.3791 - LR: 9.00e-05\n",
      "\tEpoch 20/100 - Train loss: 0.0475 - Val accuracy: 0.5441 - Val loss: 1.0123 - Val F1: 0.4537 - LR: 8.00e-05\n",
      "\tEpoch 30/100 - Train loss: 0.0214 - Val accuracy: 0.3529 - Val loss: 3.1462 - Val F1: 0.2010 - LR: 7.00e-05\n",
      "\tEpoch 40/100 - Train loss: 0.0108 - Val accuracy: 0.3529 - Val loss: 4.2728 - Val F1: 0.2010 - LR: 6.00e-05\n",
      "\tEpoch 50/100 - Train loss: 0.0071 - Val accuracy: 0.3529 - Val loss: 3.6571 - Val F1: 0.2010 - LR: 5.00e-05\n",
      "\tEpoch 60/100 - Train loss: 0.0137 - Val accuracy: 0.3529 - Val loss: 3.1600 - Val F1: 0.2010 - LR: 4.00e-05\n",
      "\tEpoch 70/100 - Train loss: 0.0074 - Val accuracy: 0.3529 - Val loss: 3.6227 - Val F1: 0.2010 - LR: 3.00e-05\n",
      "\tEpoch 80/100 - Train loss: 0.0071 - Val accuracy: 0.4265 - Val loss: 2.6180 - Val F1: 0.3217 - LR: 2.00e-05\n",
      "\tEpoch 90/100 - Train loss: 0.0089 - Val accuracy: 0.5735 - Val loss: 1.6296 - Val F1: 0.4799 - LR: 1.00e-05\n",
      "\tEpoch 100/100 - Train loss: 0.0041 - Val accuracy: 0.4412 - Val loss: 2.4064 - Val F1: 0.3414 - LR: 0.00e+00\n",
      "\tBest epoch: 6 - Best val accuracy: 0.5588 - Best val loss: 0.6391 - Best val F1: 0.5248\n",
      "\n",
      "Source class: WAL | Domain: 34 | Accuracy: 0.6327 | Loss: 2.6242 | F1: 0.5319\n",
      "\n",
      "Domain: 35\n",
      "x_syn_dom.shape: (333, 3, 128) | np.unique(y_syn_dom): [1 2 3]\n",
      "x_dp_dom.shape: (48, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Training on synthetic data...\n",
      "\tEpoch 10/100 - Train loss: 0.2661 - Val accuracy: 0.3433 - Val loss: 1.3553 - Val F1: 0.1755 - LR: 9.00e-05\n",
      "\tEpoch 20/100 - Train loss: 0.0818 - Val accuracy: 0.6716 - Val loss: 0.9257 - Val F1: 0.5400 - LR: 8.00e-05\n",
      "\tEpoch 30/100 - Train loss: 0.0494 - Val accuracy: 0.4627 - Val loss: 1.6427 - Val F1: 0.3677 - LR: 7.00e-05\n",
      "\tEpoch 40/100 - Train loss: 0.0198 - Val accuracy: 0.6716 - Val loss: 1.2347 - Val F1: 0.5445 - LR: 6.00e-05\n",
      "\tEpoch 50/100 - Train loss: 0.0121 - Val accuracy: 0.6716 - Val loss: 1.8394 - Val F1: 0.5402 - LR: 5.00e-05\n",
      "\tEpoch 60/100 - Train loss: 0.0112 - Val accuracy: 0.5672 - Val loss: 1.8164 - Val F1: 0.4768 - LR: 4.00e-05\n",
      "\tEpoch 70/100 - Train loss: 0.0041 - Val accuracy: 0.3433 - Val loss: 3.1800 - Val F1: 0.1755 - LR: 3.00e-05\n",
      "\tEpoch 80/100 - Train loss: 0.0182 - Val accuracy: 0.5075 - Val loss: 2.1419 - Val F1: 0.4188 - LR: 2.00e-05\n",
      "\tEpoch 90/100 - Train loss: 0.0043 - Val accuracy: 0.4627 - Val loss: 2.1551 - Val F1: 0.3677 - LR: 1.00e-05\n",
      "\tEpoch 100/100 - Train loss: 0.0036 - Val accuracy: 0.4925 - Val loss: 2.2511 - Val F1: 0.4026 - LR: 0.00e+00\n",
      "\tBest epoch: 13 - Best val accuracy: 0.7015 - Best val loss: 0.5752 - Best val F1: 0.6075\n",
      "\n",
      "Source class: WAL | Domain: 35 | Accuracy: 0.8542 | Loss: 1.0136 | F1: 0.7894\n",
      "\n",
      "Domain: 36\n",
      "x_syn_dom.shape: (336, 3, 128) | np.unique(y_syn_dom): [1 2 3]\n",
      "x_dp_dom.shape: (43, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Training on synthetic data...\n",
      "\tEpoch 10/100 - Train loss: 0.1870 - Val accuracy: 0.4412 - Val loss: 1.2468 - Val F1: 0.3360 - LR: 9.00e-05\n",
      "\tEpoch 20/100 - Train loss: 0.0377 - Val accuracy: 0.4559 - Val loss: 1.3363 - Val F1: 0.3498 - LR: 8.00e-05\n",
      "\tEpoch 30/100 - Train loss: 0.0299 - Val accuracy: 0.6618 - Val loss: 2.4775 - Val F1: 0.5532 - LR: 7.00e-05\n",
      "\tEpoch 40/100 - Train loss: 0.0154 - Val accuracy: 0.3824 - Val loss: 1.2901 - Val F1: 0.2625 - LR: 6.00e-05\n",
      "\tEpoch 50/100 - Train loss: 0.0090 - Val accuracy: 0.3529 - Val loss: 2.1775 - Val F1: 0.2019 - LR: 5.00e-05\n",
      "\tEpoch 60/100 - Train loss: 0.0124 - Val accuracy: 0.3382 - Val loss: 2.8198 - Val F1: 0.1710 - LR: 4.00e-05\n",
      "\tEpoch 70/100 - Train loss: 0.0095 - Val accuracy: 0.3529 - Val loss: 2.4201 - Val F1: 0.2010 - LR: 3.00e-05\n",
      "\tEpoch 80/100 - Train loss: 0.0536 - Val accuracy: 0.8824 - Val loss: 0.2582 - Val F1: 0.8772 - LR: 2.00e-05\n",
      "\tEpoch 90/100 - Train loss: 0.0058 - Val accuracy: 0.3382 - Val loss: 3.3163 - Val F1: 0.1710 - LR: 1.00e-05\n",
      "\tEpoch 100/100 - Train loss: 0.0037 - Val accuracy: 0.3676 - Val loss: 1.8041 - Val F1: 0.2297 - LR: 0.00e+00\n",
      "\tBest epoch: 80 - Best val accuracy: 0.8824 - Best val loss: 0.2582 - Best val F1: 0.8772\n",
      "\n",
      "Source class: WAL | Domain: 36 | Accuracy: 0.6512 | Loss: 0.8918 | F1: 0.5136\n",
      "\n",
      "Domain: 37\n",
      "x_syn_dom.shape: (336, 3, 128) | np.unique(y_syn_dom): [1 2 3]\n",
      "x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Training on synthetic data...\n",
      "\tEpoch 10/100 - Train loss: 0.2345 - Val accuracy: 0.3382 - Val loss: 2.4959 - Val F1: 0.1710 - LR: 9.00e-05\n",
      "\tEpoch 20/100 - Train loss: 0.0554 - Val accuracy: 0.3382 - Val loss: 2.9556 - Val F1: 0.1710 - LR: 8.00e-05\n",
      "\tEpoch 30/100 - Train loss: 0.0335 - Val accuracy: 0.3382 - Val loss: 3.3866 - Val F1: 0.1710 - LR: 7.00e-05\n",
      "\tEpoch 40/100 - Train loss: 0.0096 - Val accuracy: 0.3382 - Val loss: 3.9290 - Val F1: 0.1710 - LR: 6.00e-05\n",
      "\tEpoch 50/100 - Train loss: 0.0165 - Val accuracy: 0.3382 - Val loss: 4.3288 - Val F1: 0.1710 - LR: 5.00e-05\n",
      "\tEpoch 60/100 - Train loss: 0.0081 - Val accuracy: 0.3824 - Val loss: 1.3972 - Val F1: 0.2706 - LR: 4.00e-05\n",
      "\tEpoch 70/100 - Train loss: 0.0055 - Val accuracy: 0.3382 - Val loss: 1.9235 - Val F1: 0.1995 - LR: 3.00e-05\n",
      "\tEpoch 80/100 - Train loss: 0.0075 - Val accuracy: 0.3382 - Val loss: 4.3580 - Val F1: 0.1710 - LR: 2.00e-05\n",
      "\tEpoch 90/100 - Train loss: 0.0146 - Val accuracy: 0.3382 - Val loss: 4.4417 - Val F1: 0.1710 - LR: 1.00e-05\n",
      "\tEpoch 100/100 - Train loss: 0.0122 - Val accuracy: 0.3382 - Val loss: 5.0436 - Val F1: 0.1710 - LR: 0.00e+00\n",
      "\tBest epoch: 3 - Best val accuracy: 0.6765 - Best val loss: 0.6876 - Best val F1: 0.5670\n",
      "\n",
      "Source class: WAL | Domain: 37 | Accuracy: 0.6667 | Loss: 3.1028 | F1: 0.5333\n",
      "\n",
      "Domain: 38\n",
      "x_syn_dom.shape: (333, 3, 128) | np.unique(y_syn_dom): [1 2 3]\n",
      "x_dp_dom.shape: (47, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Training on synthetic data...\n",
      "\tEpoch 10/100 - Train loss: 0.1391 - Val accuracy: 0.6716 - Val loss: 0.5318 - Val F1: 0.5397 - LR: 9.00e-05\n",
      "\tEpoch 20/100 - Train loss: 0.0575 - Val accuracy: 0.6716 - Val loss: 0.6696 - Val F1: 0.5567 - LR: 8.00e-05\n",
      "\tEpoch 30/100 - Train loss: 0.0356 - Val accuracy: 0.6716 - Val loss: 0.6645 - Val F1: 0.5815 - LR: 7.00e-05\n",
      "\tEpoch 40/100 - Train loss: 0.0481 - Val accuracy: 0.6716 - Val loss: 0.6341 - Val F1: 0.5400 - LR: 6.00e-05\n",
      "\tEpoch 50/100 - Train loss: 0.0273 - Val accuracy: 0.6716 - Val loss: 0.6249 - Val F1: 0.5477 - LR: 5.00e-05\n",
      "\tEpoch 60/100 - Train loss: 0.0171 - Val accuracy: 0.6716 - Val loss: 0.7202 - Val F1: 0.5567 - LR: 4.00e-05\n",
      "\tEpoch 70/100 - Train loss: 0.0246 - Val accuracy: 0.7015 - Val loss: 0.5992 - Val F1: 0.6128 - LR: 3.00e-05\n",
      "\tEpoch 80/100 - Train loss: 0.0097 - Val accuracy: 0.6866 - Val loss: 0.6238 - Val F1: 0.5856 - LR: 2.00e-05\n",
      "\tEpoch 90/100 - Train loss: 0.0203 - Val accuracy: 0.6716 - Val loss: 0.7255 - Val F1: 0.5477 - LR: 1.00e-05\n",
      "\tEpoch 100/100 - Train loss: 0.0110 - Val accuracy: 0.7015 - Val loss: 0.6036 - Val F1: 0.6128 - LR: 0.00e+00\n",
      "\tBest epoch: 65 - Best val accuracy: 0.8358 - Best val loss: 0.3664 - Best val F1: 0.8224\n",
      "\n",
      "Source class: WAL | Domain: 38 | Accuracy: 0.8085 | Loss: 0.7653 | F1: 0.8010\n",
      "\n",
      "Domain: 39\n",
      "x_syn_dom.shape: (333, 3, 128) | np.unique(y_syn_dom): [1 2 3]\n",
      "x_dp_dom.shape: (54, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Training on synthetic data...\n",
      "\tEpoch 10/100 - Train loss: 0.3018 - Val accuracy: 0.3582 - Val loss: 1.7090 - Val F1: 0.2145 - LR: 9.00e-05\n",
      "\tEpoch 20/100 - Train loss: 0.1286 - Val accuracy: 0.7015 - Val loss: 0.4858 - Val F1: 0.6415 - LR: 8.00e-05\n",
      "\tEpoch 30/100 - Train loss: 0.0169 - Val accuracy: 0.5373 - Val loss: 2.1314 - Val F1: 0.4369 - LR: 7.00e-05\n",
      "\tEpoch 40/100 - Train loss: 0.0235 - Val accuracy: 0.4030 - Val loss: 2.4155 - Val F1: 0.2815 - LR: 6.00e-05\n",
      "\tEpoch 50/100 - Train loss: 0.0084 - Val accuracy: 0.5075 - Val loss: 3.1345 - Val F1: 0.3963 - LR: 5.00e-05\n",
      "\tEpoch 60/100 - Train loss: 0.0332 - Val accuracy: 0.6716 - Val loss: 3.2062 - Val F1: 0.5622 - LR: 4.00e-05\n",
      "\tEpoch 70/100 - Train loss: 0.0150 - Val accuracy: 0.3433 - Val loss: 2.8822 - Val F1: 0.1755 - LR: 3.00e-05\n",
      "\tEpoch 80/100 - Train loss: 0.0216 - Val accuracy: 0.3433 - Val loss: 3.2127 - Val F1: 0.1755 - LR: 2.00e-05\n",
      "\tEpoch 90/100 - Train loss: 0.0085 - Val accuracy: 0.3433 - Val loss: 2.8219 - Val F1: 0.1755 - LR: 1.00e-05\n",
      "\tEpoch 100/100 - Train loss: 0.0061 - Val accuracy: 0.3433 - Val loss: 2.0419 - Val F1: 0.1755 - LR: 0.00e+00\n",
      "\tBest epoch: 20 - Best val accuracy: 0.7015 - Best val loss: 0.4858 - Best val F1: 0.6415\n",
      "\n",
      "Source class: WAL | Domain: 39 | Accuracy: 0.5370 | Loss: 1.3446 | F1: 0.3929\n",
      "\n",
      "Domain: 40\n",
      "x_syn_dom.shape: (333, 3, 128) | np.unique(y_syn_dom): [1 2 3]\n",
      "x_dp_dom.shape: (44, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Training on synthetic data...\n",
      "\tEpoch 10/100 - Train loss: 0.3112 - Val accuracy: 0.3433 - Val loss: 3.9486 - Val F1: 0.1755 - LR: 9.00e-05\n",
      "\tEpoch 20/100 - Train loss: 0.1029 - Val accuracy: 0.3433 - Val loss: 4.9000 - Val F1: 0.1774 - LR: 8.00e-05\n",
      "\tEpoch 30/100 - Train loss: 0.0282 - Val accuracy: 0.3433 - Val loss: 5.2701 - Val F1: 0.1755 - LR: 7.00e-05\n",
      "\tEpoch 40/100 - Train loss: 0.0263 - Val accuracy: 0.3433 - Val loss: 5.4969 - Val F1: 0.1755 - LR: 6.00e-05\n",
      "\tEpoch 50/100 - Train loss: 0.0311 - Val accuracy: 0.3433 - Val loss: 3.6702 - Val F1: 0.1836 - LR: 5.00e-05\n",
      "\tEpoch 60/100 - Train loss: 0.0089 - Val accuracy: 0.3433 - Val loss: 4.3607 - Val F1: 0.1755 - LR: 4.00e-05\n",
      "\tEpoch 70/100 - Train loss: 0.0038 - Val accuracy: 0.3433 - Val loss: 5.1156 - Val F1: 0.1755 - LR: 3.00e-05\n",
      "\tEpoch 80/100 - Train loss: 0.0072 - Val accuracy: 0.3433 - Val loss: 5.2875 - Val F1: 0.1755 - LR: 2.00e-05\n",
      "\tEpoch 90/100 - Train loss: 0.0106 - Val accuracy: 0.3433 - Val loss: 5.1231 - Val F1: 0.1755 - LR: 1.00e-05\n",
      "\tEpoch 100/100 - Train loss: 0.0048 - Val accuracy: 0.3433 - Val loss: 4.7352 - Val F1: 0.1755 - LR: 0.00e+00\n",
      "\tBest epoch: 3 - Best val accuracy: 0.5224 - Best val loss: 0.8801 - Best val F1: 0.4227\n",
      "\n",
      "Source class: WAL | Domain: 40 | Accuracy: 0.6364 | Loss: 3.9972 | F1: 0.4949\n",
      "\n",
      "Domain: 41\n",
      "x_syn_dom.shape: (333, 3, 128) | np.unique(y_syn_dom): [1 2 3]\n",
      "x_dp_dom.shape: (45, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Training on synthetic data...\n",
      "\tEpoch 10/100 - Train loss: 0.1963 - Val accuracy: 0.7761 - Val loss: 0.4392 - Val F1: 0.7467 - LR: 9.00e-05\n",
      "\tEpoch 20/100 - Train loss: 0.0709 - Val accuracy: 0.7463 - Val loss: 0.5590 - Val F1: 0.6984 - LR: 8.00e-05\n",
      "\tEpoch 30/100 - Train loss: 0.0459 - Val accuracy: 0.6716 - Val loss: 1.6292 - Val F1: 0.5622 - LR: 7.00e-05\n",
      "\tEpoch 40/100 - Train loss: 0.0090 - Val accuracy: 0.6716 - Val loss: 1.4900 - Val F1: 0.5622 - LR: 6.00e-05\n",
      "\tEpoch 50/100 - Train loss: 0.0086 - Val accuracy: 0.6716 - Val loss: 1.7482 - Val F1: 0.5622 - LR: 5.00e-05\n",
      "\tEpoch 60/100 - Train loss: 0.0112 - Val accuracy: 0.6716 - Val loss: 1.7652 - Val F1: 0.5622 - LR: 4.00e-05\n",
      "\tEpoch 70/100 - Train loss: 0.0127 - Val accuracy: 0.6716 - Val loss: 2.0095 - Val F1: 0.5622 - LR: 3.00e-05\n",
      "\tEpoch 80/100 - Train loss: 0.0089 - Val accuracy: 0.6716 - Val loss: 2.0855 - Val F1: 0.5622 - LR: 2.00e-05\n",
      "\tEpoch 90/100 - Train loss: 0.0042 - Val accuracy: 0.6716 - Val loss: 2.1504 - Val F1: 0.5622 - LR: 1.00e-05\n",
      "\tEpoch 100/100 - Train loss: 0.0183 - Val accuracy: 0.6716 - Val loss: 2.0311 - Val F1: 0.5622 - LR: 0.00e+00\n",
      "\tBest epoch: 9 - Best val accuracy: 0.9104 - Best val loss: 0.3921 - Best val F1: 0.9088\n",
      "\n",
      "Source class: WAL | Domain: 41 | Accuracy: 0.7333 | Loss: 1.3424 | F1: 0.6691\n",
      "\n",
      "Domain: 42\n",
      "x_syn_dom.shape: (336, 3, 128) | np.unique(y_syn_dom): [1 2 3]\n",
      "x_dp_dom.shape: (46, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Training on synthetic data...\n",
      "\tEpoch 10/100 - Train loss: 0.1619 - Val accuracy: 0.3382 - Val loss: 3.6360 - Val F1: 0.1710 - LR: 9.00e-05\n",
      "\tEpoch 20/100 - Train loss: 0.0444 - Val accuracy: 0.3382 - Val loss: 4.2779 - Val F1: 0.1710 - LR: 8.00e-05\n",
      "\tEpoch 30/100 - Train loss: 0.0253 - Val accuracy: 0.3382 - Val loss: 4.1539 - Val F1: 0.1710 - LR: 7.00e-05\n",
      "\tEpoch 40/100 - Train loss: 0.0134 - Val accuracy: 0.3382 - Val loss: 3.0815 - Val F1: 0.1729 - LR: 6.00e-05\n",
      "\tEpoch 50/100 - Train loss: 0.0113 - Val accuracy: 0.3382 - Val loss: 4.3873 - Val F1: 0.1729 - LR: 5.00e-05\n",
      "\tEpoch 60/100 - Train loss: 0.0080 - Val accuracy: 0.3382 - Val loss: 2.8383 - Val F1: 0.1729 - LR: 4.00e-05\n",
      "\tEpoch 70/100 - Train loss: 0.0094 - Val accuracy: 0.3382 - Val loss: 2.9381 - Val F1: 0.1710 - LR: 3.00e-05\n",
      "\tEpoch 80/100 - Train loss: 0.0061 - Val accuracy: 0.3382 - Val loss: 3.6993 - Val F1: 0.1729 - LR: 2.00e-05\n",
      "\tEpoch 90/100 - Train loss: 0.0048 - Val accuracy: 0.3382 - Val loss: 3.3910 - Val F1: 0.1729 - LR: 1.00e-05\n",
      "\tEpoch 100/100 - Train loss: 0.0100 - Val accuracy: 0.3382 - Val loss: 2.8433 - Val F1: 0.1729 - LR: 0.00e+00\n",
      "\tBest epoch: 3 - Best val accuracy: 0.6765 - Best val loss: 0.6202 - Best val F1: 0.5670\n",
      "\n",
      "Source class: WAL | Domain: 42 | Accuracy: 0.6087 | Loss: 1.7834 | F1: 0.4606\n",
      "\n",
      "Domain: 43\n",
      "x_syn_dom.shape: (333, 3, 128) | np.unique(y_syn_dom): [1 2 3]\n",
      "x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Training on synthetic data...\n",
      "\tEpoch 10/100 - Train loss: 0.0916 - Val accuracy: 0.8507 - Val loss: 0.3676 - Val F1: 0.8485 - LR: 9.00e-05\n",
      "\tEpoch 20/100 - Train loss: 0.0304 - Val accuracy: 1.0000 - Val loss: 0.1005 - Val F1: 1.0000 - LR: 8.00e-05\n",
      "\tEpoch 30/100 - Train loss: 0.0321 - Val accuracy: 0.9552 - Val loss: 0.1407 - Val F1: 0.9550 - LR: 7.00e-05\n",
      "\tEpoch 40/100 - Train loss: 0.0287 - Val accuracy: 0.9701 - Val loss: 0.1302 - Val F1: 0.9701 - LR: 6.00e-05\n",
      "\tEpoch 50/100 - Train loss: 0.0063 - Val accuracy: 0.8507 - Val loss: 0.3146 - Val F1: 0.8450 - LR: 5.00e-05\n",
      "\tEpoch 60/100 - Train loss: 0.0123 - Val accuracy: 0.9104 - Val loss: 0.2121 - Val F1: 0.9088 - LR: 4.00e-05\n",
      "\tEpoch 70/100 - Train loss: 0.0179 - Val accuracy: 0.9254 - Val loss: 0.1538 - Val F1: 0.9242 - LR: 3.00e-05\n",
      "\tEpoch 80/100 - Train loss: 0.0050 - Val accuracy: 0.9701 - Val loss: 0.1024 - Val F1: 0.9701 - LR: 2.00e-05\n",
      "\tEpoch 90/100 - Train loss: 0.0102 - Val accuracy: 1.0000 - Val loss: 0.0983 - Val F1: 1.0000 - LR: 1.00e-05\n",
      "\tEpoch 100/100 - Train loss: 0.0117 - Val accuracy: 0.9104 - Val loss: 0.1692 - Val F1: 0.9085 - LR: 0.00e+00\n",
      "\tBest epoch: 99 - Best val accuracy: 1.0000 - Best val loss: 0.0641 - Best val F1: 1.0000\n",
      "\n",
      "Source class: WAL | Domain: 43 | Accuracy: 0.7143 | Loss: 1.7520 | F1: 0.6402\n",
      "\n",
      "Domain: 44\n",
      "x_syn_dom.shape: (333, 3, 128) | np.unique(y_syn_dom): [1 2 3]\n",
      "x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Training on synthetic data...\n",
      "\tEpoch 10/100 - Train loss: 0.3285 - Val accuracy: 0.3433 - Val loss: 3.1622 - Val F1: 0.1755 - LR: 9.00e-05\n",
      "\tEpoch 20/100 - Train loss: 0.0938 - Val accuracy: 0.3433 - Val loss: 4.5995 - Val F1: 0.1755 - LR: 8.00e-05\n",
      "\tEpoch 30/100 - Train loss: 0.0329 - Val accuracy: 0.3433 - Val loss: 4.1631 - Val F1: 0.1755 - LR: 7.00e-05\n",
      "\tEpoch 40/100 - Train loss: 0.0297 - Val accuracy: 0.5373 - Val loss: 1.2469 - Val F1: 0.4919 - LR: 6.00e-05\n",
      "\tEpoch 50/100 - Train loss: 0.0070 - Val accuracy: 0.3433 - Val loss: 3.9201 - Val F1: 0.1755 - LR: 5.00e-05\n",
      "\tEpoch 60/100 - Train loss: 0.0342 - Val accuracy: 0.3582 - Val loss: 2.8978 - Val F1: 0.2080 - LR: 4.00e-05\n",
      "\tEpoch 70/100 - Train loss: 0.0370 - Val accuracy: 0.4925 - Val loss: 1.1697 - Val F1: 0.4238 - LR: 3.00e-05\n",
      "\tEpoch 80/100 - Train loss: 0.0121 - Val accuracy: 0.4478 - Val loss: 1.9821 - Val F1: 0.3457 - LR: 2.00e-05\n",
      "\tEpoch 90/100 - Train loss: 0.0284 - Val accuracy: 0.4030 - Val loss: 2.4184 - Val F1: 0.2853 - LR: 1.00e-05\n",
      "\tEpoch 100/100 - Train loss: 0.0084 - Val accuracy: 0.4179 - Val loss: 2.1840 - Val F1: 0.3175 - LR: 0.00e+00\n",
      "\tBest epoch: 3 - Best val accuracy: 0.5075 - Best val loss: 0.8186 - Best val F1: 0.4021\n",
      "\n",
      "Source class: WAL | Domain: 44 | Accuracy: 0.7619 | Loss: 0.4310 | F1: 0.7114\n",
      "\n",
      "Domain: 45\n",
      "x_syn_dom.shape: (333, 3, 128) | np.unique(y_syn_dom): [1 2 3]\n",
      "x_dp_dom.shape: (52, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Training on synthetic data...\n",
      "\tEpoch 10/100 - Train loss: 0.2252 - Val accuracy: 0.3433 - Val loss: 3.5397 - Val F1: 0.1755 - LR: 9.00e-05\n",
      "\tEpoch 20/100 - Train loss: 0.0377 - Val accuracy: 0.3433 - Val loss: 2.4754 - Val F1: 0.1755 - LR: 8.00e-05\n",
      "\tEpoch 30/100 - Train loss: 0.0164 - Val accuracy: 0.3433 - Val loss: 3.3078 - Val F1: 0.1755 - LR: 7.00e-05\n",
      "\tEpoch 40/100 - Train loss: 0.0205 - Val accuracy: 0.3731 - Val loss: 1.2351 - Val F1: 0.2438 - LR: 6.00e-05\n",
      "\tEpoch 50/100 - Train loss: 0.0109 - Val accuracy: 0.3433 - Val loss: 1.6981 - Val F1: 0.1755 - LR: 5.00e-05\n",
      "\tEpoch 60/100 - Train loss: 0.0092 - Val accuracy: 0.5224 - Val loss: 1.1587 - Val F1: 0.4302 - LR: 4.00e-05\n",
      "\tEpoch 70/100 - Train loss: 0.0142 - Val accuracy: 0.3433 - Val loss: 1.9532 - Val F1: 0.1755 - LR: 3.00e-05\n",
      "\tEpoch 80/100 - Train loss: 0.0120 - Val accuracy: 0.3582 - Val loss: 1.9126 - Val F1: 0.2060 - LR: 2.00e-05\n",
      "\tEpoch 90/100 - Train loss: 0.0087 - Val accuracy: 0.3433 - Val loss: 2.3821 - Val F1: 0.1755 - LR: 1.00e-05\n",
      "\tEpoch 100/100 - Train loss: 0.0067 - Val accuracy: 0.3433 - Val loss: 3.1279 - Val F1: 0.1755 - LR: 0.00e+00\n",
      "\tBest epoch: 93 - Best val accuracy: 0.7313 - Best val loss: 0.5067 - Best val F1: 0.7023\n",
      "\n",
      "Source class: WAL | Domain: 45 | Accuracy: 0.5577 | Loss: 1.7790 | F1: 0.4174\n",
      "\n",
      "Domain: 46\n",
      "x_syn_dom.shape: (336, 3, 128) | np.unique(y_syn_dom): [1 2 3]\n",
      "x_dp_dom.shape: (48, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Training on synthetic data...\n",
      "\tEpoch 10/100 - Train loss: 0.1664 - Val accuracy: 0.3382 - Val loss: 6.7253 - Val F1: 0.1710 - LR: 9.00e-05\n",
      "\tEpoch 20/100 - Train loss: 0.0337 - Val accuracy: 0.3382 - Val loss: 8.2917 - Val F1: 0.1710 - LR: 8.00e-05\n",
      "\tEpoch 30/100 - Train loss: 0.0413 - Val accuracy: 0.3382 - Val loss: 9.4346 - Val F1: 0.1710 - LR: 7.00e-05\n",
      "\tEpoch 40/100 - Train loss: 0.0099 - Val accuracy: 0.3382 - Val loss: 10.1291 - Val F1: 0.1710 - LR: 6.00e-05\n",
      "\tEpoch 50/100 - Train loss: 0.0035 - Val accuracy: 0.3382 - Val loss: 10.1445 - Val F1: 0.1710 - LR: 5.00e-05\n",
      "\tEpoch 60/100 - Train loss: 0.0116 - Val accuracy: 0.3382 - Val loss: 9.8623 - Val F1: 0.1710 - LR: 4.00e-05\n",
      "\tEpoch 70/100 - Train loss: 0.0021 - Val accuracy: 0.3382 - Val loss: 9.0543 - Val F1: 0.1710 - LR: 3.00e-05\n",
      "\tEpoch 80/100 - Train loss: 0.0069 - Val accuracy: 0.3382 - Val loss: 9.0268 - Val F1: 0.1710 - LR: 2.00e-05\n",
      "\tEpoch 90/100 - Train loss: 0.0037 - Val accuracy: 0.3382 - Val loss: 11.2966 - Val F1: 0.1710 - LR: 1.00e-05\n",
      "\tEpoch 100/100 - Train loss: 0.0084 - Val accuracy: 0.3382 - Val loss: 8.1560 - Val F1: 0.1710 - LR: 0.00e+00\n",
      "\tBest epoch: 2 - Best val accuracy: 0.3235 - Best val loss: 1.0585 - Best val F1: 0.1736\n",
      "\n",
      "Source class: WAL | Domain: 46 | Accuracy: 0.5833 | Loss: 3.5216 | F1: 0.4298\n",
      "\n",
      "Domain: 47\n",
      "x_syn_dom.shape: (333, 3, 128) | np.unique(y_syn_dom): [1 2 3]\n",
      "x_dp_dom.shape: (44, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Training on synthetic data...\n",
      "\tEpoch 10/100 - Train loss: 0.1922 - Val accuracy: 0.3433 - Val loss: 6.0163 - Val F1: 0.1755 - LR: 9.00e-05\n",
      "\tEpoch 20/100 - Train loss: 0.0562 - Val accuracy: 0.3881 - Val loss: 4.2690 - Val F1: 0.2590 - LR: 8.00e-05\n",
      "\tEpoch 30/100 - Train loss: 0.0232 - Val accuracy: 0.3433 - Val loss: 4.1328 - Val F1: 0.1755 - LR: 7.00e-05\n",
      "\tEpoch 40/100 - Train loss: 0.0219 - Val accuracy: 0.3433 - Val loss: 5.6143 - Val F1: 0.1755 - LR: 6.00e-05\n",
      "\tEpoch 50/100 - Train loss: 0.0183 - Val accuracy: 0.3433 - Val loss: 5.2607 - Val F1: 0.1755 - LR: 5.00e-05\n",
      "\tEpoch 60/100 - Train loss: 0.0170 - Val accuracy: 0.3433 - Val loss: 4.9879 - Val F1: 0.1755 - LR: 4.00e-05\n",
      "\tEpoch 70/100 - Train loss: 0.0065 - Val accuracy: 0.3433 - Val loss: 5.5510 - Val F1: 0.1755 - LR: 3.00e-05\n",
      "\tEpoch 80/100 - Train loss: 0.0070 - Val accuracy: 0.3433 - Val loss: 4.5519 - Val F1: 0.1755 - LR: 2.00e-05\n",
      "\tEpoch 90/100 - Train loss: 0.0038 - Val accuracy: 0.3433 - Val loss: 5.2873 - Val F1: 0.1755 - LR: 1.00e-05\n",
      "\tEpoch 100/100 - Train loss: 0.0021 - Val accuracy: 0.3433 - Val loss: 5.8070 - Val F1: 0.1755 - LR: 0.00e+00\n",
      "\tBest epoch: 3 - Best val accuracy: 0.5373 - Best val loss: 0.8078 - Best val F1: 0.4323\n",
      "\n",
      "Source class: WAL | Domain: 47 | Accuracy: 0.6818 | Loss: 3.1677 | F1: 0.5801\n",
      "\n",
      "Domain: 48\n",
      "x_syn_dom.shape: (333, 3, 128) | np.unique(y_syn_dom): [1 2 3]\n",
      "x_dp_dom.shape: (48, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Training on synthetic data...\n",
      "\tEpoch 10/100 - Train loss: 0.1461 - Val accuracy: 0.3881 - Val loss: 1.3079 - Val F1: 0.2717 - LR: 9.00e-05\n",
      "\tEpoch 20/100 - Train loss: 0.0912 - Val accuracy: 0.6418 - Val loss: 1.2529 - Val F1: 0.5401 - LR: 8.00e-05\n",
      "\tEpoch 30/100 - Train loss: 0.0205 - Val accuracy: 0.4179 - Val loss: 0.9327 - Val F1: 0.3252 - LR: 7.00e-05\n",
      "\tEpoch 40/100 - Train loss: 0.0240 - Val accuracy: 0.5970 - Val loss: 0.7350 - Val F1: 0.5773 - LR: 6.00e-05\n",
      "\tEpoch 50/100 - Train loss: 0.0455 - Val accuracy: 0.6418 - Val loss: 0.5977 - Val F1: 0.6053 - LR: 5.00e-05\n",
      "\tEpoch 60/100 - Train loss: 0.0235 - Val accuracy: 0.8060 - Val loss: 0.4831 - Val F1: 0.8042 - LR: 4.00e-05\n",
      "\tEpoch 70/100 - Train loss: 0.0286 - Val accuracy: 0.6418 - Val loss: 0.7848 - Val F1: 0.5466 - LR: 3.00e-05\n",
      "\tEpoch 80/100 - Train loss: 0.0112 - Val accuracy: 0.6567 - Val loss: 0.6585 - Val F1: 0.5762 - LR: 2.00e-05\n",
      "\tEpoch 90/100 - Train loss: 0.0078 - Val accuracy: 0.6418 - Val loss: 1.0631 - Val F1: 0.5466 - LR: 1.00e-05\n",
      "\tEpoch 100/100 - Train loss: 0.0095 - Val accuracy: 0.7164 - Val loss: 0.5233 - Val F1: 0.6778 - LR: 0.00e+00\n",
      "\tBest epoch: 67 - Best val accuracy: 0.9403 - Best val loss: 0.2805 - Best val F1: 0.9403\n",
      "\n",
      "Source class: WAL | Domain: 48 | Accuracy: 0.8125 | Loss: 0.6072 | F1: 0.7900\n",
      "\n",
      "Domain: 49\n",
      "x_syn_dom.shape: (333, 3, 128) | np.unique(y_syn_dom): [1 2 3]\n",
      "x_dp_dom.shape: (53, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Training on synthetic data...\n",
      "\tEpoch 10/100 - Train loss: 0.2358 - Val accuracy: 0.3433 - Val loss: 4.3495 - Val F1: 0.1755 - LR: 9.00e-05\n",
      "\tEpoch 20/100 - Train loss: 0.0520 - Val accuracy: 0.3433 - Val loss: 4.7138 - Val F1: 0.1774 - LR: 8.00e-05\n",
      "\tEpoch 30/100 - Train loss: 0.0308 - Val accuracy: 0.4925 - Val loss: 2.4393 - Val F1: 0.3939 - LR: 7.00e-05\n",
      "\tEpoch 40/100 - Train loss: 0.0115 - Val accuracy: 0.3582 - Val loss: 2.6590 - Val F1: 0.2412 - LR: 6.00e-05\n",
      "\tEpoch 50/100 - Train loss: 0.0145 - Val accuracy: 0.4328 - Val loss: 2.4629 - Val F1: 0.3335 - LR: 5.00e-05\n",
      "\tEpoch 60/100 - Train loss: 0.0092 - Val accuracy: 0.3582 - Val loss: 2.9503 - Val F1: 0.2283 - LR: 4.00e-05\n",
      "\tEpoch 70/100 - Train loss: 0.0144 - Val accuracy: 0.6716 - Val loss: 1.8475 - Val F1: 0.5622 - LR: 3.00e-05\n",
      "\tEpoch 80/100 - Train loss: 0.0083 - Val accuracy: 0.6269 - Val loss: 2.0888 - Val F1: 0.5203 - LR: 2.00e-05\n",
      "\tEpoch 90/100 - Train loss: 0.0136 - Val accuracy: 0.5373 - Val loss: 1.7682 - Val F1: 0.4369 - LR: 1.00e-05\n",
      "\tEpoch 100/100 - Train loss: 0.0046 - Val accuracy: 0.4776 - Val loss: 2.3319 - Val F1: 0.3792 - LR: 0.00e+00\n",
      "\tBest epoch: 3 - Best val accuracy: 0.6716 - Best val loss: 0.5873 - Best val F1: 0.5622\n",
      "\n",
      "Source class: WAL | Domain: 49 | Accuracy: 0.7736 | Loss: 1.2108 | F1: 0.7143\n",
      "\n",
      "Domain: 50\n",
      "x_syn_dom.shape: (333, 3, 128) | np.unique(y_syn_dom): [1 2 3]\n",
      "x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Training on synthetic data...\n",
      "\tEpoch 10/100 - Train loss: 0.1260 - Val accuracy: 0.3433 - Val loss: 2.3878 - Val F1: 0.1858 - LR: 9.00e-05\n",
      "\tEpoch 20/100 - Train loss: 0.0373 - Val accuracy: 0.3433 - Val loss: 4.2488 - Val F1: 0.1755 - LR: 8.00e-05\n",
      "\tEpoch 30/100 - Train loss: 0.0395 - Val accuracy: 0.3433 - Val loss: 6.0134 - Val F1: 0.1755 - LR: 7.00e-05\n",
      "\tEpoch 40/100 - Train loss: 0.0236 - Val accuracy: 0.3582 - Val loss: 2.7057 - Val F1: 0.2332 - LR: 6.00e-05\n",
      "\tEpoch 50/100 - Train loss: 0.0584 - Val accuracy: 0.3582 - Val loss: 2.9980 - Val F1: 0.2161 - LR: 5.00e-05\n",
      "\tEpoch 60/100 - Train loss: 0.0176 - Val accuracy: 0.3433 - Val loss: 5.9519 - Val F1: 0.1755 - LR: 4.00e-05\n",
      "\tEpoch 70/100 - Train loss: 0.0085 - Val accuracy: 0.3433 - Val loss: 5.3114 - Val F1: 0.1755 - LR: 3.00e-05\n",
      "\tEpoch 80/100 - Train loss: 0.0130 - Val accuracy: 0.3433 - Val loss: 6.4440 - Val F1: 0.1755 - LR: 2.00e-05\n",
      "\tEpoch 90/100 - Train loss: 0.0056 - Val accuracy: 0.3433 - Val loss: 6.3487 - Val F1: 0.1755 - LR: 1.00e-05\n",
      "\tEpoch 100/100 - Train loss: 0.0058 - Val accuracy: 0.3433 - Val loss: 4.3100 - Val F1: 0.1794 - LR: 0.00e+00\n",
      "\tBest epoch: 3 - Best val accuracy: 0.6716 - Best val loss: 0.7206 - Best val F1: 0.5622\n",
      "\n",
      "Source class: WAL | Domain: 50 | Accuracy: 0.7143 | Loss: 2.2654 | F1: 0.6299\n",
      "\n",
      "Domain: 51\n",
      "x_syn_dom.shape: (333, 3, 128) | np.unique(y_syn_dom): [1 2 3]\n",
      "x_dp_dom.shape: (46, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Training on synthetic data...\n",
      "\tEpoch 10/100 - Train loss: 0.2665 - Val accuracy: 0.4627 - Val loss: 1.8132 - Val F1: 0.3619 - LR: 9.00e-05\n",
      "\tEpoch 20/100 - Train loss: 0.0929 - Val accuracy: 0.4179 - Val loss: 2.6680 - Val F1: 0.3151 - LR: 8.00e-05\n",
      "\tEpoch 30/100 - Train loss: 0.0424 - Val accuracy: 0.5821 - Val loss: 1.7789 - Val F1: 0.4788 - LR: 7.00e-05\n",
      "\tEpoch 40/100 - Train loss: 0.0338 - Val accuracy: 0.6269 - Val loss: 1.7216 - Val F1: 0.5203 - LR: 6.00e-05\n",
      "\tEpoch 50/100 - Train loss: 0.0285 - Val accuracy: 0.4478 - Val loss: 1.5827 - Val F1: 0.3490 - LR: 5.00e-05\n",
      "\tEpoch 60/100 - Train loss: 0.0490 - Val accuracy: 0.7313 - Val loss: 0.6400 - Val F1: 0.7050 - LR: 4.00e-05\n",
      "\tEpoch 70/100 - Train loss: 0.0119 - Val accuracy: 0.4478 - Val loss: 1.5194 - Val F1: 0.3814 - LR: 3.00e-05\n",
      "\tEpoch 80/100 - Train loss: 0.0166 - Val accuracy: 0.4030 - Val loss: 1.6885 - Val F1: 0.2988 - LR: 2.00e-05\n",
      "\tEpoch 90/100 - Train loss: 0.0232 - Val accuracy: 0.7164 - Val loss: 0.6032 - Val F1: 0.7004 - LR: 1.00e-05\n",
      "\tEpoch 100/100 - Train loss: 0.0290 - Val accuracy: 0.4925 - Val loss: 1.2726 - Val F1: 0.4334 - LR: 0.00e+00\n",
      "\tBest epoch: 91 - Best val accuracy: 0.8507 - Best val loss: 0.3291 - Best val F1: 0.8493\n",
      "\n",
      "Source class: WAL | Domain: 51 | Accuracy: 0.7174 | Loss: 1.5506 | F1: 0.6316\n",
      "\n",
      "Domain: 52\n",
      "x_syn_dom.shape: (333, 3, 128) | np.unique(y_syn_dom): [1 2 3]\n",
      "x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Training on synthetic data...\n",
      "\tEpoch 10/100 - Train loss: 0.2045 - Val accuracy: 0.4328 - Val loss: 0.7382 - Val F1: 0.3612 - LR: 9.00e-05\n",
      "\tEpoch 20/100 - Train loss: 0.0421 - Val accuracy: 0.5075 - Val loss: 1.0468 - Val F1: 0.4188 - LR: 8.00e-05\n",
      "\tEpoch 30/100 - Train loss: 0.0289 - Val accuracy: 0.6269 - Val loss: 1.1533 - Val F1: 0.5267 - LR: 7.00e-05\n",
      "\tEpoch 40/100 - Train loss: 0.0121 - Val accuracy: 0.6418 - Val loss: 0.7343 - Val F1: 0.5383 - LR: 6.00e-05\n",
      "\tEpoch 50/100 - Train loss: 0.0088 - Val accuracy: 0.4030 - Val loss: 1.4083 - Val F1: 0.2847 - LR: 5.00e-05\n",
      "\tEpoch 60/100 - Train loss: 0.0283 - Val accuracy: 0.6716 - Val loss: 0.9500 - Val F1: 0.5436 - LR: 4.00e-05\n",
      "\tEpoch 70/100 - Train loss: 0.0033 - Val accuracy: 0.6716 - Val loss: 1.0597 - Val F1: 0.5477 - LR: 3.00e-05\n",
      "\tEpoch 80/100 - Train loss: 0.0026 - Val accuracy: 0.6716 - Val loss: 1.2457 - Val F1: 0.5422 - LR: 2.00e-05\n",
      "\tEpoch 90/100 - Train loss: 0.0028 - Val accuracy: 0.6716 - Val loss: 1.4260 - Val F1: 0.5503 - LR: 1.00e-05\n",
      "\tEpoch 100/100 - Train loss: 0.0064 - Val accuracy: 0.6716 - Val loss: 1.0350 - Val F1: 0.5436 - LR: 0.00e+00\n",
      "\tBest epoch: 38 - Best val accuracy: 0.7612 - Best val loss: 0.3809 - Best val F1: 0.7140\n",
      "\n",
      "Source class: WAL | Domain: 52 | Accuracy: 0.8333 | Loss: 0.5170 | F1: 0.7665\n",
      "\n",
      "Domain: 53\n",
      "x_syn_dom.shape: (333, 3, 128) | np.unique(y_syn_dom): [1 2 3]\n",
      "x_dp_dom.shape: (48, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Training on synthetic data...\n",
      "\tEpoch 10/100 - Train loss: 0.1616 - Val accuracy: 0.3881 - Val loss: 1.6315 - Val F1: 0.2849 - LR: 9.00e-05\n",
      "\tEpoch 20/100 - Train loss: 0.0754 - Val accuracy: 0.5522 - Val loss: 0.8493 - Val F1: 0.4826 - LR: 8.00e-05\n",
      "\tEpoch 30/100 - Train loss: 0.0292 - Val accuracy: 0.6418 - Val loss: 0.5896 - Val F1: 0.6274 - LR: 7.00e-05\n",
      "\tEpoch 40/100 - Train loss: 0.0174 - Val accuracy: 0.5522 - Val loss: 0.8403 - Val F1: 0.5222 - LR: 6.00e-05\n",
      "\tEpoch 50/100 - Train loss: 0.0277 - Val accuracy: 0.7015 - Val loss: 0.5295 - Val F1: 0.6676 - LR: 5.00e-05\n",
      "\tEpoch 60/100 - Train loss: 0.0191 - Val accuracy: 0.5970 - Val loss: 0.9515 - Val F1: 0.5384 - LR: 4.00e-05\n",
      "\tEpoch 70/100 - Train loss: 0.0169 - Val accuracy: 0.7612 - Val loss: 0.4597 - Val F1: 0.7440 - LR: 3.00e-05\n",
      "\tEpoch 80/100 - Train loss: 0.0061 - Val accuracy: 0.6119 - Val loss: 0.7914 - Val F1: 0.5906 - LR: 2.00e-05\n",
      "\tEpoch 90/100 - Train loss: 0.0086 - Val accuracy: 0.7761 - Val loss: 0.5031 - Val F1: 0.7703 - LR: 1.00e-05\n",
      "\tEpoch 100/100 - Train loss: 0.0157 - Val accuracy: 0.7463 - Val loss: 0.4987 - Val F1: 0.7394 - LR: 0.00e+00\n",
      "\tBest epoch: 71 - Best val accuracy: 0.8955 - Best val loss: 0.2956 - Best val F1: 0.8932\n",
      "\n",
      "Source class: WAL | Domain: 53 | Accuracy: 0.8333 | Loss: 1.4819 | F1: 0.7708\n",
      "\n",
      "Domain: 54\n",
      "x_syn_dom.shape: (333, 3, 128) | np.unique(y_syn_dom): [1 2 3]\n",
      "x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Training on synthetic data...\n",
      "\tEpoch 10/100 - Train loss: 0.2697 - Val accuracy: 0.3433 - Val loss: 5.2231 - Val F1: 0.1755 - LR: 9.00e-05\n",
      "\tEpoch 20/100 - Train loss: 0.0587 - Val accuracy: 0.3433 - Val loss: 6.9277 - Val F1: 0.1755 - LR: 8.00e-05\n",
      "\tEpoch 30/100 - Train loss: 0.0483 - Val accuracy: 0.3433 - Val loss: 7.2221 - Val F1: 0.1755 - LR: 7.00e-05\n",
      "\tEpoch 40/100 - Train loss: 0.0126 - Val accuracy: 0.3433 - Val loss: 6.9754 - Val F1: 0.1755 - LR: 6.00e-05\n",
      "\tEpoch 50/100 - Train loss: 0.0116 - Val accuracy: 0.3433 - Val loss: 7.9142 - Val F1: 0.1755 - LR: 5.00e-05\n",
      "\tEpoch 60/100 - Train loss: 0.0165 - Val accuracy: 0.3433 - Val loss: 7.1581 - Val F1: 0.1755 - LR: 4.00e-05\n",
      "\tEpoch 70/100 - Train loss: 0.0053 - Val accuracy: 0.3433 - Val loss: 8.2010 - Val F1: 0.1755 - LR: 3.00e-05\n",
      "\tEpoch 80/100 - Train loss: 0.0082 - Val accuracy: 0.3433 - Val loss: 7.7630 - Val F1: 0.1755 - LR: 2.00e-05\n",
      "\tEpoch 90/100 - Train loss: 0.0058 - Val accuracy: 0.3433 - Val loss: 8.6474 - Val F1: 0.1755 - LR: 1.00e-05\n",
      "\tEpoch 100/100 - Train loss: 0.0101 - Val accuracy: 0.3433 - Val loss: 7.8817 - Val F1: 0.1755 - LR: 0.00e+00\n",
      "\tBest epoch: 2 - Best val accuracy: 0.5522 - Best val loss: 0.9837 - Best val F1: 0.4979\n",
      "\n",
      "Source class: WAL | Domain: 54 | Accuracy: 0.6667 | Loss: 4.2151 | F1: 0.5333\n",
      "\n",
      "Domain: 55\n",
      "x_syn_dom.shape: (333, 3, 128) | np.unique(y_syn_dom): [1 2 3]\n",
      "x_dp_dom.shape: (49, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Training on synthetic data...\n",
      "\tEpoch 10/100 - Train loss: 0.2221 - Val accuracy: 0.3433 - Val loss: 4.2184 - Val F1: 0.1755 - LR: 9.00e-05\n",
      "\tEpoch 20/100 - Train loss: 0.0283 - Val accuracy: 0.6716 - Val loss: 1.3058 - Val F1: 0.5622 - LR: 8.00e-05\n",
      "\tEpoch 30/100 - Train loss: 0.0284 - Val accuracy: 0.4776 - Val loss: 2.3340 - Val F1: 0.3792 - LR: 7.00e-05\n",
      "\tEpoch 40/100 - Train loss: 0.0127 - Val accuracy: 0.6567 - Val loss: 1.2293 - Val F1: 0.5481 - LR: 6.00e-05\n",
      "\tEpoch 50/100 - Train loss: 0.0065 - Val accuracy: 0.4627 - Val loss: 2.6827 - Val F1: 0.3642 - LR: 5.00e-05\n",
      "\tEpoch 60/100 - Train loss: 0.0118 - Val accuracy: 0.6716 - Val loss: 2.8911 - Val F1: 0.5622 - LR: 4.00e-05\n",
      "\tEpoch 70/100 - Train loss: 0.0045 - Val accuracy: 0.6716 - Val loss: 1.9224 - Val F1: 0.5622 - LR: 3.00e-05\n",
      "\tEpoch 80/100 - Train loss: 0.0047 - Val accuracy: 0.3731 - Val loss: 3.1154 - Val F1: 0.2544 - LR: 2.00e-05\n",
      "\tEpoch 90/100 - Train loss: 0.0046 - Val accuracy: 0.6716 - Val loss: 1.8804 - Val F1: 0.5622 - LR: 1.00e-05\n",
      "\tEpoch 100/100 - Train loss: 0.0034 - Val accuracy: 0.6716 - Val loss: 1.6328 - Val F1: 0.5622 - LR: 0.00e+00\n",
      "\tBest epoch: 35 - Best val accuracy: 0.9851 - Best val loss: 0.0747 - Best val F1: 0.9851\n",
      "\n",
      "Source class: WAL | Domain: 55 | Accuracy: 0.7755 | Loss: 0.4870 | F1: 0.7389\n",
      "\n",
      "Domain: 56\n",
      "x_syn_dom.shape: (333, 3, 128) | np.unique(y_syn_dom): [1 2 3]\n",
      "x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Training on synthetic data...\n",
      "\tEpoch 10/100 - Train loss: 0.1824 - Val accuracy: 0.3433 - Val loss: 1.8230 - Val F1: 0.1926 - LR: 9.00e-05\n",
      "\tEpoch 20/100 - Train loss: 0.0903 - Val accuracy: 0.3881 - Val loss: 1.0135 - Val F1: 0.2821 - LR: 8.00e-05\n",
      "\tEpoch 30/100 - Train loss: 0.0209 - Val accuracy: 0.6716 - Val loss: 0.8278 - Val F1: 0.5436 - LR: 7.00e-05\n",
      "\tEpoch 40/100 - Train loss: 0.0105 - Val accuracy: 0.3433 - Val loss: 2.2033 - Val F1: 0.1755 - LR: 6.00e-05\n",
      "\tEpoch 50/100 - Train loss: 0.0075 - Val accuracy: 0.5373 - Val loss: 1.4270 - Val F1: 0.4449 - LR: 5.00e-05\n",
      "\tEpoch 60/100 - Train loss: 0.0084 - Val accuracy: 0.5224 - Val loss: 1.4098 - Val F1: 0.4302 - LR: 4.00e-05\n",
      "\tEpoch 70/100 - Train loss: 0.0133 - Val accuracy: 0.6567 - Val loss: 1.0915 - Val F1: 0.5457 - LR: 3.00e-05\n",
      "\tEpoch 80/100 - Train loss: 0.0051 - Val accuracy: 0.3433 - Val loss: 2.7266 - Val F1: 0.1755 - LR: 2.00e-05\n",
      "\tEpoch 90/100 - Train loss: 0.0043 - Val accuracy: 0.6418 - Val loss: 1.3729 - Val F1: 0.5343 - LR: 1.00e-05\n",
      "\tEpoch 100/100 - Train loss: 0.0234 - Val accuracy: 0.6716 - Val loss: 1.1482 - Val F1: 0.5455 - LR: 0.00e+00\n",
      "\tBest epoch: 21 - Best val accuracy: 0.8806 - Best val loss: 0.3998 - Best val F1: 0.8724\n",
      "\n",
      "Source class: WAL | Domain: 56 | Accuracy: 0.8095 | Loss: 0.5471 | F1: 0.7372\n",
      "\n",
      "Domain: 57\n",
      "x_syn_dom.shape: (333, 3, 128) | np.unique(y_syn_dom): [1 2 3]\n",
      "x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Training on synthetic data...\n",
      "\tEpoch 10/100 - Train loss: 0.1863 - Val accuracy: 0.3433 - Val loss: 5.5637 - Val F1: 0.1755 - LR: 9.00e-05\n",
      "\tEpoch 20/100 - Train loss: 0.0545 - Val accuracy: 0.3433 - Val loss: 5.0414 - Val F1: 0.1755 - LR: 8.00e-05\n",
      "\tEpoch 30/100 - Train loss: 0.0271 - Val accuracy: 0.3433 - Val loss: 6.6157 - Val F1: 0.1755 - LR: 7.00e-05\n",
      "\tEpoch 40/100 - Train loss: 0.0145 - Val accuracy: 0.3433 - Val loss: 5.6917 - Val F1: 0.1755 - LR: 6.00e-05\n",
      "\tEpoch 50/100 - Train loss: 0.0069 - Val accuracy: 0.3433 - Val loss: 7.9895 - Val F1: 0.1755 - LR: 5.00e-05\n",
      "\tEpoch 60/100 - Train loss: 0.0111 - Val accuracy: 0.3433 - Val loss: 5.0908 - Val F1: 0.1755 - LR: 4.00e-05\n",
      "\tEpoch 70/100 - Train loss: 0.0089 - Val accuracy: 0.3433 - Val loss: 6.5195 - Val F1: 0.1755 - LR: 3.00e-05\n",
      "\tEpoch 80/100 - Train loss: 0.0021 - Val accuracy: 0.3433 - Val loss: 8.5763 - Val F1: 0.1755 - LR: 2.00e-05\n",
      "\tEpoch 90/100 - Train loss: 0.0043 - Val accuracy: 0.3433 - Val loss: 7.2903 - Val F1: 0.1755 - LR: 1.00e-05\n",
      "\tEpoch 100/100 - Train loss: 0.0060 - Val accuracy: 0.3433 - Val loss: 6.7902 - Val F1: 0.1755 - LR: 0.00e+00\n",
      "\tBest epoch: 3 - Best val accuracy: 0.5075 - Best val loss: 0.8166 - Best val F1: 0.4060\n",
      "\n",
      "Source class: WAL | Domain: 57 | Accuracy: 0.6667 | Loss: 4.2010 | F1: 0.5333\n",
      "\n",
      "Domain: 58\n",
      "x_syn_dom.shape: (333, 3, 128) | np.unique(y_syn_dom): [1 2 3]\n",
      "x_dp_dom.shape: (38, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Training on synthetic data...\n",
      "\tEpoch 10/100 - Train loss: 0.2136 - Val accuracy: 0.3433 - Val loss: 5.7170 - Val F1: 0.1755 - LR: 9.00e-05\n",
      "\tEpoch 20/100 - Train loss: 0.0582 - Val accuracy: 0.3433 - Val loss: 3.0720 - Val F1: 0.1755 - LR: 8.00e-05\n",
      "\tEpoch 30/100 - Train loss: 0.0401 - Val accuracy: 0.5522 - Val loss: 1.9266 - Val F1: 0.4590 - LR: 7.00e-05\n",
      "\tEpoch 40/100 - Train loss: 0.0186 - Val accuracy: 0.3582 - Val loss: 2.9363 - Val F1: 0.2060 - LR: 6.00e-05\n",
      "\tEpoch 50/100 - Train loss: 0.0301 - Val accuracy: 0.5821 - Val loss: 1.9260 - Val F1: 0.4857 - LR: 5.00e-05\n",
      "\tEpoch 60/100 - Train loss: 0.0446 - Val accuracy: 0.6716 - Val loss: 1.8273 - Val F1: 0.5406 - LR: 4.00e-05\n",
      "\tEpoch 70/100 - Train loss: 0.0424 - Val accuracy: 0.6716 - Val loss: 2.1643 - Val F1: 0.5436 - LR: 3.00e-05\n",
      "\tEpoch 80/100 - Train loss: 0.0170 - Val accuracy: 0.6716 - Val loss: 2.2448 - Val F1: 0.5398 - LR: 2.00e-05\n",
      "\tEpoch 90/100 - Train loss: 0.0208 - Val accuracy: 0.6418 - Val loss: 2.2787 - Val F1: 0.5248 - LR: 1.00e-05\n",
      "\tEpoch 100/100 - Train loss: 0.0130 - Val accuracy: 0.6716 - Val loss: 1.9074 - Val F1: 0.5516 - LR: 0.00e+00\n",
      "\tBest epoch: 2 - Best val accuracy: 0.5224 - Best val loss: 0.9053 - Best val F1: 0.4770\n",
      "\n",
      "Source class: WAL | Domain: 58 | Accuracy: 0.7368 | Loss: 1.4422 | F1: 0.6447\n",
      "\n",
      "Domain: 59\n",
      "x_syn_dom.shape: (333, 3, 128) | np.unique(y_syn_dom): [1 2 3]\n",
      "x_dp_dom.shape: (43, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Training on synthetic data...\n",
      "\tEpoch 10/100 - Train loss: 0.1933 - Val accuracy: 0.3433 - Val loss: 5.1237 - Val F1: 0.1755 - LR: 9.00e-05\n",
      "\tEpoch 20/100 - Train loss: 0.1103 - Val accuracy: 0.3433 - Val loss: 8.0326 - Val F1: 0.1755 - LR: 8.00e-05\n",
      "\tEpoch 30/100 - Train loss: 0.0139 - Val accuracy: 0.3433 - Val loss: 6.3790 - Val F1: 0.1755 - LR: 7.00e-05\n",
      "\tEpoch 40/100 - Train loss: 0.0183 - Val accuracy: 0.3433 - Val loss: 6.4109 - Val F1: 0.1755 - LR: 6.00e-05\n",
      "\tEpoch 50/100 - Train loss: 0.0234 - Val accuracy: 0.3433 - Val loss: 7.0667 - Val F1: 0.1755 - LR: 5.00e-05\n",
      "\tEpoch 60/100 - Train loss: 0.0056 - Val accuracy: 0.3433 - Val loss: 8.9658 - Val F1: 0.1755 - LR: 4.00e-05\n",
      "\tEpoch 70/100 - Train loss: 0.0049 - Val accuracy: 0.3433 - Val loss: 3.5617 - Val F1: 0.1755 - LR: 3.00e-05\n",
      "\tEpoch 80/100 - Train loss: 0.0081 - Val accuracy: 0.3433 - Val loss: 6.4859 - Val F1: 0.1755 - LR: 2.00e-05\n",
      "\tEpoch 90/100 - Train loss: 0.0047 - Val accuracy: 0.3433 - Val loss: 5.4660 - Val F1: 0.1755 - LR: 1.00e-05\n",
      "\tEpoch 100/100 - Train loss: 0.0067 - Val accuracy: 0.3433 - Val loss: 4.1834 - Val F1: 0.1755 - LR: 0.00e+00\n",
      "\tBest epoch: 1 - Best val accuracy: 0.3284 - Best val loss: 1.1205 - Best val F1: 0.1623\n",
      "\n",
      "Source class: WAL | Domain: 59 | Accuracy: 0.6512 | Loss: 2.6148 | F1: 0.5136\n",
      "\n",
      "Domain: 60\n",
      "x_syn_dom.shape: (333, 3, 128) | np.unique(y_syn_dom): [1 2 3]\n",
      "x_dp_dom.shape: (47, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Training on synthetic data...\n",
      "\tEpoch 10/100 - Train loss: 0.1428 - Val accuracy: 0.7463 - Val loss: 0.4035 - Val F1: 0.7017 - LR: 9.00e-05\n",
      "\tEpoch 20/100 - Train loss: 0.0232 - Val accuracy: 0.9254 - Val loss: 0.2409 - Val F1: 0.9253 - LR: 8.00e-05\n",
      "\tEpoch 30/100 - Train loss: 0.0252 - Val accuracy: 0.9701 - Val loss: 0.1444 - Val F1: 0.9701 - LR: 7.00e-05\n",
      "\tEpoch 40/100 - Train loss: 0.0473 - Val accuracy: 0.9552 - Val loss: 0.1383 - Val F1: 0.9550 - LR: 6.00e-05\n",
      "\tEpoch 50/100 - Train loss: 0.0225 - Val accuracy: 0.9701 - Val loss: 0.1421 - Val F1: 0.9701 - LR: 5.00e-05\n",
      "\tEpoch 60/100 - Train loss: 0.0167 - Val accuracy: 0.9701 - Val loss: 0.1319 - Val F1: 0.9701 - LR: 4.00e-05\n",
      "\tEpoch 70/100 - Train loss: 0.0274 - Val accuracy: 0.9254 - Val loss: 0.1801 - Val F1: 0.9244 - LR: 3.00e-05\n",
      "\tEpoch 80/100 - Train loss: 0.0110 - Val accuracy: 0.8955 - Val loss: 0.2751 - Val F1: 0.8928 - LR: 2.00e-05\n",
      "\tEpoch 90/100 - Train loss: 0.0080 - Val accuracy: 0.7910 - Val loss: 0.3957 - Val F1: 0.7675 - LR: 1.00e-05\n",
      "\tEpoch 100/100 - Train loss: 0.0070 - Val accuracy: 0.9104 - Val loss: 0.2433 - Val F1: 0.9088 - LR: 0.00e+00\n",
      "\tBest epoch: 59 - Best val accuracy: 0.9851 - Best val loss: 0.1176 - Best val F1: 0.9851\n",
      "\n",
      "Source class: WAL | Domain: 60 | Accuracy: 0.8085 | Loss: 1.2011 | F1: 0.7565\n",
      "\n",
      "Domain: 61\n",
      "x_syn_dom.shape: (333, 3, 128) | np.unique(y_syn_dom): [1 2 3]\n",
      "x_dp_dom.shape: (47, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Training on synthetic data...\n",
      "\tEpoch 10/100 - Train loss: 0.2093 - Val accuracy: 0.3433 - Val loss: 6.0381 - Val F1: 0.1755 - LR: 9.00e-05\n",
      "\tEpoch 20/100 - Train loss: 0.0832 - Val accuracy: 0.3433 - Val loss: 4.2204 - Val F1: 0.1755 - LR: 8.00e-05\n",
      "\tEpoch 30/100 - Train loss: 0.0653 - Val accuracy: 0.3433 - Val loss: 2.8782 - Val F1: 0.2105 - LR: 7.00e-05\n",
      "\tEpoch 40/100 - Train loss: 0.0184 - Val accuracy: 0.3731 - Val loss: 2.3967 - Val F1: 0.2678 - LR: 6.00e-05\n",
      "\tEpoch 50/100 - Train loss: 0.0215 - Val accuracy: 0.3731 - Val loss: 1.1303 - Val F1: 0.2678 - LR: 5.00e-05\n",
      "\tEpoch 60/100 - Train loss: 0.0137 - Val accuracy: 0.3433 - Val loss: 2.0903 - Val F1: 0.1926 - LR: 4.00e-05\n",
      "\tEpoch 70/100 - Train loss: 0.0071 - Val accuracy: 0.3582 - Val loss: 1.3033 - Val F1: 0.2541 - LR: 3.00e-05\n",
      "\tEpoch 80/100 - Train loss: 0.0075 - Val accuracy: 0.3582 - Val loss: 1.5548 - Val F1: 0.2363 - LR: 2.00e-05\n",
      "\tEpoch 90/100 - Train loss: 0.0086 - Val accuracy: 0.3433 - Val loss: 2.6856 - Val F1: 0.1774 - LR: 1.00e-05\n",
      "\tEpoch 100/100 - Train loss: 0.0062 - Val accuracy: 0.3433 - Val loss: 2.6269 - Val F1: 0.1774 - LR: 0.00e+00\n",
      "\tBest epoch: 78 - Best val accuracy: 0.7015 - Best val loss: 0.4894 - Best val F1: 0.6803\n",
      "\n",
      "Source class: WAL | Domain: 61 | Accuracy: 0.6383 | Loss: 1.8990 | F1: 0.5300\n",
      "\n",
      "Domain: 62\n",
      "x_syn_dom.shape: (333, 3, 128) | np.unique(y_syn_dom): [1 2 3]\n",
      "x_dp_dom.shape: (47, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Training on synthetic data...\n",
      "\tEpoch 10/100 - Train loss: 0.2814 - Val accuracy: 0.3433 - Val loss: 4.5629 - Val F1: 0.1755 - LR: 9.00e-05\n",
      "\tEpoch 20/100 - Train loss: 0.0824 - Val accuracy: 0.3433 - Val loss: 5.5119 - Val F1: 0.1755 - LR: 8.00e-05\n",
      "\tEpoch 30/100 - Train loss: 0.0311 - Val accuracy: 0.3433 - Val loss: 5.3840 - Val F1: 0.1755 - LR: 7.00e-05\n",
      "\tEpoch 40/100 - Train loss: 0.0151 - Val accuracy: 0.3433 - Val loss: 6.5178 - Val F1: 0.1755 - LR: 6.00e-05\n",
      "\tEpoch 50/100 - Train loss: 0.0529 - Val accuracy: 0.3433 - Val loss: 6.2196 - Val F1: 0.1755 - LR: 5.00e-05\n",
      "\tEpoch 60/100 - Train loss: 0.0071 - Val accuracy: 0.3433 - Val loss: 6.6467 - Val F1: 0.1755 - LR: 4.00e-05\n",
      "\tEpoch 70/100 - Train loss: 0.0082 - Val accuracy: 0.3433 - Val loss: 5.6063 - Val F1: 0.1755 - LR: 3.00e-05\n",
      "\tEpoch 80/100 - Train loss: 0.0027 - Val accuracy: 0.3433 - Val loss: 5.6866 - Val F1: 0.1755 - LR: 2.00e-05\n",
      "\tEpoch 90/100 - Train loss: 0.0061 - Val accuracy: 0.3433 - Val loss: 6.5710 - Val F1: 0.1755 - LR: 1.00e-05\n",
      "\tEpoch 100/100 - Train loss: 0.0123 - Val accuracy: 0.3433 - Val loss: 6.5538 - Val F1: 0.1755 - LR: 0.00e+00\n",
      "\tBest epoch: 1 - Best val accuracy: 0.3284 - Best val loss: 1.1204 - Best val F1: 0.1623\n",
      "\n",
      "Source class: WAL | Domain: 62 | Accuracy: 0.5957 | Loss: 4.2711 | F1: 0.4448\n",
      "\n",
      "Domain: 63\n",
      "x_syn_dom.shape: (333, 3, 128) | np.unique(y_syn_dom): [1 2 3]\n",
      "x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Training on synthetic data...\n",
      "\tEpoch 10/100 - Train loss: 0.2522 - Val accuracy: 0.3433 - Val loss: 1.9418 - Val F1: 0.1836 - LR: 9.00e-05\n",
      "\tEpoch 20/100 - Train loss: 0.0776 - Val accuracy: 0.3433 - Val loss: 3.5237 - Val F1: 0.1755 - LR: 8.00e-05\n",
      "\tEpoch 30/100 - Train loss: 0.0240 - Val accuracy: 0.3433 - Val loss: 2.3830 - Val F1: 0.1755 - LR: 7.00e-05\n",
      "\tEpoch 40/100 - Train loss: 0.0159 - Val accuracy: 0.7313 - Val loss: 0.5486 - Val F1: 0.6622 - LR: 6.00e-05\n",
      "\tEpoch 50/100 - Train loss: 0.0088 - Val accuracy: 0.3433 - Val loss: 2.6976 - Val F1: 0.1755 - LR: 5.00e-05\n",
      "\tEpoch 60/100 - Train loss: 0.0098 - Val accuracy: 0.3582 - Val loss: 2.2427 - Val F1: 0.2060 - LR: 4.00e-05\n",
      "\tEpoch 70/100 - Train loss: 0.0113 - Val accuracy: 0.3433 - Val loss: 4.8583 - Val F1: 0.1755 - LR: 3.00e-05\n",
      "\tEpoch 80/100 - Train loss: 0.0121 - Val accuracy: 0.3433 - Val loss: 3.0116 - Val F1: 0.1755 - LR: 2.00e-05\n",
      "\tEpoch 90/100 - Train loss: 0.0115 - Val accuracy: 0.6716 - Val loss: 0.9664 - Val F1: 0.5422 - LR: 1.00e-05\n",
      "\tEpoch 100/100 - Train loss: 0.0081 - Val accuracy: 0.3433 - Val loss: 4.0448 - Val F1: 0.1755 - LR: 0.00e+00\n",
      "\tBest epoch: 40 - Best val accuracy: 0.7313 - Best val loss: 0.5486 - Best val F1: 0.6622\n",
      "\n",
      "Source class: WAL | Domain: 63 | Accuracy: 0.6905 | Loss: 2.8426 | F1: 0.5827\n",
      "\n",
      "Domain: 64\n",
      "x_syn_dom.shape: (336, 3, 128) | np.unique(y_syn_dom): [1 2 3]\n",
      "x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Training on synthetic data...\n",
      "\tEpoch 10/100 - Train loss: 0.1744 - Val accuracy: 0.3382 - Val loss: 1.4612 - Val F1: 0.2021 - LR: 9.00e-05\n",
      "\tEpoch 20/100 - Train loss: 0.0243 - Val accuracy: 0.7206 - Val loss: 0.4237 - Val F1: 0.6469 - LR: 8.00e-05\n",
      "\tEpoch 30/100 - Train loss: 0.0184 - Val accuracy: 0.3382 - Val loss: 1.9273 - Val F1: 0.1710 - LR: 7.00e-05\n",
      "\tEpoch 40/100 - Train loss: 0.0100 - Val accuracy: 0.6471 - Val loss: 1.0726 - Val F1: 0.5383 - LR: 6.00e-05\n",
      "\tEpoch 50/100 - Train loss: 0.0087 - Val accuracy: 0.6471 - Val loss: 1.1974 - Val F1: 0.5383 - LR: 5.00e-05\n",
      "\tEpoch 60/100 - Train loss: 0.0030 - Val accuracy: 0.4118 - Val loss: 1.8427 - Val F1: 0.3007 - LR: 4.00e-05\n",
      "\tEpoch 70/100 - Train loss: 0.0056 - Val accuracy: 0.3382 - Val loss: 4.2280 - Val F1: 0.1710 - LR: 3.00e-05\n",
      "\tEpoch 80/100 - Train loss: 0.0028 - Val accuracy: 0.6618 - Val loss: 1.3043 - Val F1: 0.5490 - LR: 2.00e-05\n",
      "\tEpoch 90/100 - Train loss: 0.0230 - Val accuracy: 0.5882 - Val loss: 1.6630 - Val F1: 0.4923 - LR: 1.00e-05\n",
      "\tEpoch 100/100 - Train loss: 0.0024 - Val accuracy: 0.3971 - Val loss: 2.1096 - Val F1: 0.2784 - LR: 0.00e+00\n",
      "\tBest epoch: 20 - Best val accuracy: 0.7206 - Best val loss: 0.4237 - Best val F1: 0.6469\n",
      "\n",
      "Source class: WAL | Domain: 64 | Accuracy: 0.7619 | Loss: 0.9479 | F1: 0.6869\n",
      "\n",
      "Domain: 65\n",
      "x_syn_dom.shape: (333, 3, 128) | np.unique(y_syn_dom): [1 2 3]\n",
      "x_dp_dom.shape: (50, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Training on synthetic data...\n",
      "\tEpoch 10/100 - Train loss: 0.1956 - Val accuracy: 0.5373 - Val loss: 1.1556 - Val F1: 0.4274 - LR: 9.00e-05\n",
      "\tEpoch 20/100 - Train loss: 0.0339 - Val accuracy: 0.4179 - Val loss: 1.0472 - Val F1: 0.3053 - LR: 8.00e-05\n",
      "\tEpoch 30/100 - Train loss: 0.0354 - Val accuracy: 0.4627 - Val loss: 1.2886 - Val F1: 0.3644 - LR: 7.00e-05\n",
      "\tEpoch 40/100 - Train loss: 0.0366 - Val accuracy: 0.3731 - Val loss: 1.4852 - Val F1: 0.2342 - LR: 6.00e-05\n",
      "\tEpoch 50/100 - Train loss: 0.0069 - Val accuracy: 0.3433 - Val loss: 2.9032 - Val F1: 0.1755 - LR: 5.00e-05\n",
      "\tEpoch 60/100 - Train loss: 0.0099 - Val accuracy: 0.3433 - Val loss: 2.5699 - Val F1: 0.1755 - LR: 4.00e-05\n",
      "\tEpoch 70/100 - Train loss: 0.0055 - Val accuracy: 0.3881 - Val loss: 1.7329 - Val F1: 0.2594 - LR: 3.00e-05\n",
      "\tEpoch 80/100 - Train loss: 0.0073 - Val accuracy: 0.3433 - Val loss: 3.7442 - Val F1: 0.1755 - LR: 2.00e-05\n",
      "\tEpoch 90/100 - Train loss: 0.0111 - Val accuracy: 0.3433 - Val loss: 3.4719 - Val F1: 0.1755 - LR: 1.00e-05\n",
      "\tEpoch 100/100 - Train loss: 0.0040 - Val accuracy: 0.3731 - Val loss: 2.2667 - Val F1: 0.2342 - LR: 0.00e+00\n",
      "\tBest epoch: 4 - Best val accuracy: 0.6716 - Best val loss: 0.5377 - Best val F1: 0.5622\n",
      "\n",
      "Source class: WAL | Domain: 65 | Accuracy: 0.5600 | Loss: 2.9282 | F1: 0.4021\n",
      "\n",
      "Domain: 66\n",
      "x_syn_dom.shape: (333, 3, 128) | np.unique(y_syn_dom): [1 2 3]\n",
      "x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Training on synthetic data...\n",
      "\tEpoch 10/100 - Train loss: 0.1865 - Val accuracy: 0.3433 - Val loss: 5.7481 - Val F1: 0.1755 - LR: 9.00e-05\n",
      "\tEpoch 20/100 - Train loss: 0.0683 - Val accuracy: 0.3433 - Val loss: 3.5265 - Val F1: 0.1774 - LR: 8.00e-05\n",
      "\tEpoch 30/100 - Train loss: 0.0379 - Val accuracy: 0.3433 - Val loss: 4.2128 - Val F1: 0.1774 - LR: 7.00e-05\n",
      "\tEpoch 40/100 - Train loss: 0.0642 - Val accuracy: 0.3433 - Val loss: 3.3210 - Val F1: 0.1903 - LR: 6.00e-05\n",
      "\tEpoch 50/100 - Train loss: 0.0226 - Val accuracy: 0.3433 - Val loss: 3.5027 - Val F1: 0.1755 - LR: 5.00e-05\n",
      "\tEpoch 60/100 - Train loss: 0.0184 - Val accuracy: 0.3582 - Val loss: 2.5639 - Val F1: 0.2060 - LR: 4.00e-05\n",
      "\tEpoch 70/100 - Train loss: 0.0069 - Val accuracy: 0.3433 - Val loss: 6.0850 - Val F1: 0.1755 - LR: 3.00e-05\n",
      "\tEpoch 80/100 - Train loss: 0.0129 - Val accuracy: 0.4478 - Val loss: 2.2379 - Val F1: 0.3488 - LR: 2.00e-05\n",
      "\tEpoch 90/100 - Train loss: 0.0074 - Val accuracy: 0.3433 - Val loss: 4.2357 - Val F1: 0.1755 - LR: 1.00e-05\n",
      "\tEpoch 100/100 - Train loss: 0.0111 - Val accuracy: 0.3433 - Val loss: 5.4373 - Val F1: 0.1755 - LR: 0.00e+00\n",
      "\tBest epoch: 1 - Best val accuracy: 0.2687 - Best val loss: 1.1339 - Best val F1: 0.1391\n",
      "\n",
      "Source class: WAL | Domain: 66 | Accuracy: 0.7857 | Loss: 1.2054 | F1: 0.7314\n",
      "\n",
      "Domain: 67\n",
      "x_syn_dom.shape: (333, 3, 128) | np.unique(y_syn_dom): [1 2 3]\n",
      "x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Training on synthetic data...\n",
      "\tEpoch 10/100 - Train loss: 0.2009 - Val accuracy: 0.3582 - Val loss: 2.4019 - Val F1: 0.2101 - LR: 9.00e-05\n",
      "\tEpoch 20/100 - Train loss: 0.0520 - Val accuracy: 0.6716 - Val loss: 1.2956 - Val F1: 0.5622 - LR: 8.00e-05\n",
      "\tEpoch 30/100 - Train loss: 0.0404 - Val accuracy: 0.3731 - Val loss: 1.7522 - Val F1: 0.2647 - LR: 7.00e-05\n",
      "\tEpoch 40/100 - Train loss: 0.0150 - Val accuracy: 0.3881 - Val loss: 2.6377 - Val F1: 0.2648 - LR: 6.00e-05\n",
      "\tEpoch 50/100 - Train loss: 0.0135 - Val accuracy: 0.3731 - Val loss: 2.3438 - Val F1: 0.2594 - LR: 5.00e-05\n",
      "\tEpoch 60/100 - Train loss: 0.0136 - Val accuracy: 0.6567 - Val loss: 2.7342 - Val F1: 0.5481 - LR: 4.00e-05\n",
      "\tEpoch 70/100 - Train loss: 0.0111 - Val accuracy: 0.6716 - Val loss: 2.4579 - Val F1: 0.5622 - LR: 3.00e-05\n",
      "\tEpoch 80/100 - Train loss: 0.0068 - Val accuracy: 0.6716 - Val loss: 2.3062 - Val F1: 0.5622 - LR: 2.00e-05\n",
      "\tEpoch 90/100 - Train loss: 0.0140 - Val accuracy: 0.6866 - Val loss: 2.4188 - Val F1: 0.5941 - LR: 1.00e-05\n",
      "\tEpoch 100/100 - Train loss: 0.0077 - Val accuracy: 0.4776 - Val loss: 2.9082 - Val F1: 0.3792 - LR: 0.00e+00\n",
      "\tBest epoch: 19 - Best val accuracy: 0.6716 - Best val loss: 0.8686 - Best val F1: 0.5622\n",
      "\n",
      "Source class: WAL | Domain: 67 | Accuracy: 0.6905 | Loss: 1.2076 | F1: 0.6244\n",
      "\n",
      "Domain: 68\n",
      "x_syn_dom.shape: (333, 3, 128) | np.unique(y_syn_dom): [1 2 3]\n",
      "x_dp_dom.shape: (43, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Training on synthetic data...\n",
      "\tEpoch 10/100 - Train loss: 0.2216 - Val accuracy: 0.6567 - Val loss: 1.3560 - Val F1: 0.5481 - LR: 9.00e-05\n",
      "\tEpoch 20/100 - Train loss: 0.0545 - Val accuracy: 0.6567 - Val loss: 1.7181 - Val F1: 0.5481 - LR: 8.00e-05\n",
      "\tEpoch 30/100 - Train loss: 0.0287 - Val accuracy: 0.4627 - Val loss: 1.2440 - Val F1: 0.3737 - LR: 7.00e-05\n",
      "\tEpoch 40/100 - Train loss: 0.0160 - Val accuracy: 0.7015 - Val loss: 0.5583 - Val F1: 0.7000 - LR: 6.00e-05\n",
      "\tEpoch 50/100 - Train loss: 0.0155 - Val accuracy: 0.7910 - Val loss: 0.4384 - Val F1: 0.7963 - LR: 5.00e-05\n",
      "\tEpoch 60/100 - Train loss: 0.0123 - Val accuracy: 0.7164 - Val loss: 0.8177 - Val F1: 0.6514 - LR: 4.00e-05\n",
      "\tEpoch 70/100 - Train loss: 0.0090 - Val accuracy: 0.6567 - Val loss: 0.8172 - Val F1: 0.6050 - LR: 3.00e-05\n",
      "\tEpoch 80/100 - Train loss: 0.0102 - Val accuracy: 0.7164 - Val loss: 0.5532 - Val F1: 0.6660 - LR: 2.00e-05\n",
      "\tEpoch 90/100 - Train loss: 0.0058 - Val accuracy: 0.7313 - Val loss: 0.6264 - Val F1: 0.6773 - LR: 1.00e-05\n",
      "\tEpoch 100/100 - Train loss: 0.0075 - Val accuracy: 0.6418 - Val loss: 0.8344 - Val F1: 0.6053 - LR: 0.00e+00\n",
      "\tBest epoch: 53 - Best val accuracy: 0.9254 - Best val loss: 0.2084 - Best val F1: 0.9262\n",
      "\n",
      "Source class: WAL | Domain: 68 | Accuracy: 0.8372 | Loss: 0.5924 | F1: 0.8371\n",
      "\n",
      "Domain: 69\n",
      "x_syn_dom.shape: (333, 3, 128) | np.unique(y_syn_dom): [1 2 3]\n",
      "x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Training on synthetic data...\n",
      "\tEpoch 10/100 - Train loss: 0.2438 - Val accuracy: 0.3433 - Val loss: 6.0503 - Val F1: 0.1755 - LR: 9.00e-05\n",
      "\tEpoch 20/100 - Train loss: 0.0615 - Val accuracy: 0.3433 - Val loss: 7.1961 - Val F1: 0.1755 - LR: 8.00e-05\n",
      "\tEpoch 30/100 - Train loss: 0.0397 - Val accuracy: 0.3433 - Val loss: 5.8767 - Val F1: 0.1755 - LR: 7.00e-05\n",
      "\tEpoch 40/100 - Train loss: 0.0188 - Val accuracy: 0.3582 - Val loss: 4.1862 - Val F1: 0.2218 - LR: 6.00e-05\n",
      "\tEpoch 50/100 - Train loss: 0.0193 - Val accuracy: 0.3881 - Val loss: 4.2912 - Val F1: 0.2747 - LR: 5.00e-05\n",
      "\tEpoch 60/100 - Train loss: 0.0228 - Val accuracy: 0.3731 - Val loss: 5.1639 - Val F1: 0.2500 - LR: 4.00e-05\n",
      "\tEpoch 70/100 - Train loss: 0.0113 - Val accuracy: 0.3731 - Val loss: 5.2826 - Val F1: 0.2411 - LR: 3.00e-05\n",
      "\tEpoch 80/100 - Train loss: 0.0221 - Val accuracy: 0.3731 - Val loss: 4.6009 - Val F1: 0.2522 - LR: 2.00e-05\n",
      "\tEpoch 90/100 - Train loss: 0.0038 - Val accuracy: 0.3881 - Val loss: 4.7433 - Val F1: 0.2652 - LR: 1.00e-05\n",
      "\tEpoch 100/100 - Train loss: 0.0087 - Val accuracy: 0.4179 - Val loss: 4.5008 - Val F1: 0.3128 - LR: 0.00e+00\n",
      "\tBest epoch: 3 - Best val accuracy: 0.3582 - Best val loss: 1.0571 - Best val F1: 0.2218\n",
      "\n",
      "Source class: WAL | Domain: 69 | Accuracy: 0.8333 | Loss: 2.3491 | F1: 0.7778\n",
      "\n",
      "Domain: 70\n",
      "x_syn_dom.shape: (333, 3, 128) | np.unique(y_syn_dom): [1 2 3]\n",
      "x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Training on synthetic data...\n",
      "\tEpoch 10/100 - Train loss: 0.2398 - Val accuracy: 0.3881 - Val loss: 1.7237 - Val F1: 0.2849 - LR: 9.00e-05\n",
      "\tEpoch 20/100 - Train loss: 0.0989 - Val accuracy: 0.5672 - Val loss: 2.2847 - Val F1: 0.4649 - LR: 8.00e-05\n",
      "\tEpoch 30/100 - Train loss: 0.0236 - Val accuracy: 0.6716 - Val loss: 3.5746 - Val F1: 0.5622 - LR: 7.00e-05\n",
      "\tEpoch 40/100 - Train loss: 0.0183 - Val accuracy: 0.6716 - Val loss: 3.0322 - Val F1: 0.5622 - LR: 6.00e-05\n",
      "\tEpoch 50/100 - Train loss: 0.0269 - Val accuracy: 0.6716 - Val loss: 3.1233 - Val F1: 0.5622 - LR: 5.00e-05\n",
      "\tEpoch 60/100 - Train loss: 0.0684 - Val accuracy: 0.6716 - Val loss: 3.4808 - Val F1: 0.5622 - LR: 4.00e-05\n",
      "\tEpoch 70/100 - Train loss: 0.0139 - Val accuracy: 0.6716 - Val loss: 3.0102 - Val F1: 0.5622 - LR: 3.00e-05\n",
      "\tEpoch 80/100 - Train loss: 0.0384 - Val accuracy: 0.6567 - Val loss: 3.9260 - Val F1: 0.5513 - LR: 2.00e-05\n",
      "\tEpoch 90/100 - Train loss: 0.0188 - Val accuracy: 0.6567 - Val loss: 4.2143 - Val F1: 0.5513 - LR: 1.00e-05\n",
      "\tEpoch 100/100 - Train loss: 0.0374 - Val accuracy: 0.6567 - Val loss: 3.4159 - Val F1: 0.5513 - LR: 0.00e+00\n",
      "\tBest epoch: 3 - Best val accuracy: 0.5522 - Best val loss: 0.7752 - Best val F1: 0.4509\n",
      "\n",
      "Source class: WAL | Domain: 70 | Accuracy: 0.6667 | Loss: 1.0964 | F1: 0.6213\n",
      "\n",
      "Domain: 71\n",
      "x_syn_dom.shape: (333, 3, 128) | np.unique(y_syn_dom): [1 2 3]\n",
      "x_dp_dom.shape: (44, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Training on synthetic data...\n",
      "\tEpoch 10/100 - Train loss: 0.2094 - Val accuracy: 0.3433 - Val loss: 2.5612 - Val F1: 0.1755 - LR: 9.00e-05\n",
      "\tEpoch 20/100 - Train loss: 0.0733 - Val accuracy: 0.6269 - Val loss: 0.7798 - Val F1: 0.5267 - LR: 8.00e-05\n",
      "\tEpoch 30/100 - Train loss: 0.0341 - Val accuracy: 0.4179 - Val loss: 2.0230 - Val F1: 0.3074 - LR: 7.00e-05\n",
      "\tEpoch 40/100 - Train loss: 0.0187 - Val accuracy: 0.6119 - Val loss: 1.5744 - Val F1: 0.5148 - LR: 6.00e-05\n",
      "\tEpoch 50/100 - Train loss: 0.0120 - Val accuracy: 0.6119 - Val loss: 1.5945 - Val F1: 0.5148 - LR: 5.00e-05\n",
      "\tEpoch 60/100 - Train loss: 0.0146 - Val accuracy: 0.5970 - Val loss: 1.9996 - Val F1: 0.5026 - LR: 4.00e-05\n",
      "\tEpoch 70/100 - Train loss: 0.0121 - Val accuracy: 0.5821 - Val loss: 1.9783 - Val F1: 0.4899 - LR: 3.00e-05\n",
      "\tEpoch 80/100 - Train loss: 0.0118 - Val accuracy: 0.4030 - Val loss: 2.4841 - Val F1: 0.2847 - LR: 2.00e-05\n",
      "\tEpoch 90/100 - Train loss: 0.0092 - Val accuracy: 0.6418 - Val loss: 1.5259 - Val F1: 0.5383 - LR: 1.00e-05\n",
      "\tEpoch 100/100 - Train loss: 0.0069 - Val accuracy: 0.6716 - Val loss: 1.0725 - Val F1: 0.5503 - LR: 0.00e+00\n",
      "\tBest epoch: 22 - Best val accuracy: 0.7313 - Best val loss: 0.4811 - Best val F1: 0.6988\n",
      "\n",
      "Source class: WAL | Domain: 71 | Accuracy: 0.8409 | Loss: 1.0276 | F1: 0.7702\n",
      "\n",
      "Domain: 72\n",
      "x_syn_dom.shape: (333, 3, 128) | np.unique(y_syn_dom): [1 2 3]\n",
      "x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Training on synthetic data...\n",
      "\tEpoch 10/100 - Train loss: 0.2063 - Val accuracy: 0.4776 - Val loss: 1.6720 - Val F1: 0.3792 - LR: 9.00e-05\n",
      "\tEpoch 20/100 - Train loss: 0.0551 - Val accuracy: 0.6716 - Val loss: 1.5597 - Val F1: 0.5622 - LR: 8.00e-05\n",
      "\tEpoch 30/100 - Train loss: 0.0345 - Val accuracy: 0.7164 - Val loss: 0.5209 - Val F1: 0.6514 - LR: 7.00e-05\n",
      "\tEpoch 40/100 - Train loss: 0.0319 - Val accuracy: 0.9254 - Val loss: 0.2016 - Val F1: 0.9253 - LR: 6.00e-05\n",
      "\tEpoch 50/100 - Train loss: 0.0079 - Val accuracy: 0.7761 - Val loss: 0.3034 - Val F1: 0.7612 - LR: 5.00e-05\n",
      "\tEpoch 60/100 - Train loss: 0.0058 - Val accuracy: 0.9254 - Val loss: 0.2615 - Val F1: 0.9244 - LR: 4.00e-05\n",
      "\tEpoch 70/100 - Train loss: 0.0056 - Val accuracy: 0.9403 - Val loss: 0.1904 - Val F1: 0.9398 - LR: 3.00e-05\n",
      "\tEpoch 80/100 - Train loss: 0.0078 - Val accuracy: 0.9403 - Val loss: 0.2034 - Val F1: 0.9398 - LR: 2.00e-05\n",
      "\tEpoch 90/100 - Train loss: 0.0084 - Val accuracy: 0.6866 - Val loss: 0.9153 - Val F1: 0.5941 - LR: 1.00e-05\n",
      "\tEpoch 100/100 - Train loss: 0.0031 - Val accuracy: 0.9254 - Val loss: 0.2466 - Val F1: 0.9244 - LR: 0.00e+00\n",
      "\tBest epoch: 59 - Best val accuracy: 0.9552 - Best val loss: 0.1437 - Best val F1: 0.9552\n",
      "\n",
      "Source class: WAL | Domain: 72 | Accuracy: 0.8333 | Loss: 0.3065 | F1: 0.8090\n",
      "\n",
      "Domain: 73\n",
      "x_syn_dom.shape: (333, 3, 128) | np.unique(y_syn_dom): [1 2 3]\n",
      "x_dp_dom.shape: (41, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Training on synthetic data...\n",
      "\tEpoch 10/100 - Train loss: 0.1033 - Val accuracy: 0.8060 - Val loss: 0.3912 - Val F1: 0.7818 - LR: 9.00e-05\n",
      "\tEpoch 20/100 - Train loss: 0.0316 - Val accuracy: 0.8060 - Val loss: 0.3372 - Val F1: 0.7840 - LR: 8.00e-05\n",
      "\tEpoch 30/100 - Train loss: 0.0305 - Val accuracy: 0.7761 - Val loss: 0.4761 - Val F1: 0.7428 - LR: 7.00e-05\n",
      "\tEpoch 40/100 - Train loss: 0.0107 - Val accuracy: 0.7164 - Val loss: 0.8072 - Val F1: 0.6435 - LR: 6.00e-05\n",
      "\tEpoch 50/100 - Train loss: 0.0104 - Val accuracy: 0.7164 - Val loss: 0.9694 - Val F1: 0.6435 - LR: 5.00e-05\n",
      "\tEpoch 60/100 - Train loss: 0.0066 - Val accuracy: 0.7164 - Val loss: 0.8082 - Val F1: 0.6409 - LR: 4.00e-05\n",
      "\tEpoch 70/100 - Train loss: 0.0107 - Val accuracy: 0.7313 - Val loss: 0.6868 - Val F1: 0.6698 - LR: 3.00e-05\n",
      "\tEpoch 80/100 - Train loss: 0.0063 - Val accuracy: 0.8060 - Val loss: 0.4251 - Val F1: 0.7818 - LR: 2.00e-05\n",
      "\tEpoch 90/100 - Train loss: 0.0033 - Val accuracy: 0.7313 - Val loss: 0.7295 - Val F1: 0.6698 - LR: 1.00e-05\n",
      "\tEpoch 100/100 - Train loss: 0.0089 - Val accuracy: 0.7164 - Val loss: 0.8770 - Val F1: 0.6435 - LR: 0.00e+00\n",
      "\tBest epoch: 38 - Best val accuracy: 0.9552 - Best val loss: 0.1479 - Best val F1: 0.9544\n",
      "\n",
      "Source class: WAL | Domain: 73 | Accuracy: 0.8293 | Loss: 0.9506 | F1: 0.7788\n",
      "\n",
      "Domain: 74\n",
      "x_syn_dom.shape: (333, 3, 128) | np.unique(y_syn_dom): [1 2 3]\n",
      "x_dp_dom.shape: (35, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Training on synthetic data...\n",
      "\tEpoch 10/100 - Train loss: 0.1564 - Val accuracy: 0.3433 - Val loss: 8.3361 - Val F1: 0.1755 - LR: 9.00e-05\n",
      "\tEpoch 20/100 - Train loss: 0.0235 - Val accuracy: 0.3433 - Val loss: 7.8044 - Val F1: 0.1755 - LR: 8.00e-05\n",
      "\tEpoch 30/100 - Train loss: 0.0146 - Val accuracy: 0.3433 - Val loss: 10.1256 - Val F1: 0.1755 - LR: 7.00e-05\n",
      "\tEpoch 40/100 - Train loss: 0.0107 - Val accuracy: 0.3433 - Val loss: 8.1526 - Val F1: 0.1755 - LR: 6.00e-05\n",
      "\tEpoch 50/100 - Train loss: 0.0032 - Val accuracy: 0.3433 - Val loss: 9.6007 - Val F1: 0.1755 - LR: 5.00e-05\n",
      "\tEpoch 60/100 - Train loss: 0.0130 - Val accuracy: 0.3433 - Val loss: 10.3787 - Val F1: 0.1755 - LR: 4.00e-05\n",
      "\tEpoch 70/100 - Train loss: 0.0069 - Val accuracy: 0.3433 - Val loss: 10.5062 - Val F1: 0.1755 - LR: 3.00e-05\n",
      "\tEpoch 80/100 - Train loss: 0.0029 - Val accuracy: 0.3433 - Val loss: 11.0883 - Val F1: 0.1755 - LR: 2.00e-05\n",
      "\tEpoch 90/100 - Train loss: 0.0045 - Val accuracy: 0.3433 - Val loss: 8.6738 - Val F1: 0.1755 - LR: 1.00e-05\n",
      "\tEpoch 100/100 - Train loss: 0.0027 - Val accuracy: 0.3433 - Val loss: 10.0117 - Val F1: 0.1755 - LR: 0.00e+00\n",
      "\tBest epoch: 2 - Best val accuracy: 0.3284 - Best val loss: 1.0142 - Best val F1: 0.1623\n",
      "\n",
      "Source class: WAL | Domain: 74 | Accuracy: 0.8000 | Loss: 4.7751 | F1: 0.7111\n",
      "\n",
      "Domain: 75\n",
      "x_syn_dom.shape: (333, 3, 128) | np.unique(y_syn_dom): [1 2 3]\n",
      "x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Training on synthetic data...\n",
      "\tEpoch 10/100 - Train loss: 0.2970 - Val accuracy: 0.6716 - Val loss: 1.1848 - Val F1: 0.5622 - LR: 9.00e-05\n",
      "\tEpoch 20/100 - Train loss: 0.0905 - Val accuracy: 0.6716 - Val loss: 2.2574 - Val F1: 0.5622 - LR: 8.00e-05\n",
      "\tEpoch 30/100 - Train loss: 0.0271 - Val accuracy: 0.6716 - Val loss: 1.2890 - Val F1: 0.5622 - LR: 7.00e-05\n",
      "\tEpoch 40/100 - Train loss: 0.0188 - Val accuracy: 0.9851 - Val loss: 0.1785 - Val F1: 0.9851 - LR: 6.00e-05\n",
      "\tEpoch 50/100 - Train loss: 0.0125 - Val accuracy: 0.7015 - Val loss: 0.5164 - Val F1: 0.6238 - LR: 5.00e-05\n",
      "\tEpoch 60/100 - Train loss: 0.0066 - Val accuracy: 0.6866 - Val loss: 0.7032 - Val F1: 0.5941 - LR: 4.00e-05\n",
      "\tEpoch 70/100 - Train loss: 0.0088 - Val accuracy: 0.9403 - Val loss: 0.1760 - Val F1: 0.9402 - LR: 3.00e-05\n",
      "\tEpoch 80/100 - Train loss: 0.0046 - Val accuracy: 0.9701 - Val loss: 0.1337 - Val F1: 0.9701 - LR: 2.00e-05\n",
      "\tEpoch 90/100 - Train loss: 0.0070 - Val accuracy: 0.8657 - Val loss: 0.2572 - Val F1: 0.8622 - LR: 1.00e-05\n",
      "\tEpoch 100/100 - Train loss: 0.0025 - Val accuracy: 0.9403 - Val loss: 0.1593 - Val F1: 0.9402 - LR: 0.00e+00\n",
      "\tBest epoch: 93 - Best val accuracy: 0.9701 - Best val loss: 0.1254 - Best val F1: 0.9701\n",
      "\n",
      "Source class: WAL | Domain: 75 | Accuracy: 0.8095 | Loss: 0.3393 | F1: 0.8056\n",
      "\n",
      "Mean accuracy: 0.7200\n",
      "Mean F1: 0.6359\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def compute_TSTR_Syn_aug(dataset):\n",
    "    accs = []\n",
    "    f1s = []\n",
    "\n",
    "    for src_class in config[dataset]['class_names']:\n",
    "        if src_class != 'WAL':\n",
    "            continue\n",
    "\n",
    "        print(f\"Source class: {src_class}\\n\")\n",
    "\n",
    "        for domain in range(config[dataset]['num_df_domains'], config[dataset]['num_df_domains'] + config[dataset]['num_dp_domains']):\n",
    "            print(f\"Domain: {domain}\")\n",
    "\n",
    "            # Load synthetic data\n",
    "            x_syn_dom, y_syn_dom, k_syn_dom = get_syn_data(dataset, syn_name, src_class, domain)\n",
    "            print(f'x_syn_dom.shape: {x_syn_dom.shape} | np.unique(y_syn_dom): {np.unique(y_syn_dom)}')\n",
    "\n",
    "            # Load Dp data\n",
    "            x_dp_dom, y_dp_dom, k_dp_dom = get_data(dataset, 'dp', src_class, domain)\n",
    "            print(f'x_dp_dom.shape: {x_dp_dom.shape} | np.unique(y_dp_dom): {np.unique(y_dp_dom)}\\n')\n",
    "\n",
    "            # Train on synthetic data and evaluate on Dp data\n",
    "            print('Training on synthetic data...')\n",
    "            acc, loss, f1 = train_and_test(x_syn_dom, y_syn_dom, x_dp_dom, y_dp_dom, dataset, num_epochs=num_epochs, augment=True)\n",
    "            save_scores(src_class, domain, acc, loss, f1, 'Syn_aug', dataset)\n",
    "            accs.append(acc)\n",
    "            f1s.append(f1)\n",
    "            print(f'Source class: {src_class} | Domain: {domain} | Accuracy: {acc:.4f} | Loss: {loss:.4f} | F1: {f1:.4f}\\n')\n",
    "\n",
    "    print(f\"Mean accuracy: {np.mean(accs):.4f}\")\n",
    "    print(f\"Mean F1: {np.mean(f1s):.4f}\\n\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "compute_TSTR_Syn_aug('realworld_mobiact')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1732620078444,
     "user": {
      "displayName": "Pietro Cirino",
      "userId": "07315473796200699505"
     },
     "user_tz": -60
    },
    "id": "KKvjK_PAMxLm"
   },
   "outputs": [],
   "source": [
    "# def compute_TSTR_Syn_all(dataset):\n",
    "#     accs = []\n",
    "\n",
    "#     for src_class in config[dataset]['class_names']:\n",
    "#         if src_class != 'WAL':\n",
    "#             continue\n",
    "\n",
    "#         print(f\"Source class: {src_class}\\n\")\n",
    "\n",
    "#         # Load synthetic data\n",
    "#         x_syn, y_syn, k_syn = get_syn_data(dataset, syn_name, src_class)\n",
    "#         print(f'x_syn.shape: {x_syn.shape} | np.unique(y_syn): {np.unique(y_syn)}')\n",
    "\n",
    "#         # Load Dp data\n",
    "#         x_dp, y_dp, k_dp = get_data(dataset, 'dp', src_class)\n",
    "#         print(f'x_dp.shape: {x_dp.shape} | np.unique(y_dp): {np.unique(y_dp)}\\n')\n",
    "\n",
    "#         # Train on synthetic data and evaluate on Dp data\n",
    "#         print('Training on synthetic data...')\n",
    "#         acc, loss = train_and_test(x_syn, y_syn, x_dp, y_dp, dataset, num_epochs=num_epochs)\n",
    "#         save_scores(src_class, 100, acc, loss, 'Syn_all', dataset)\n",
    "#         accs.append(acc)\n",
    "#         print(f'Source class: {src_class} | Domain: All | Accuracy: {acc:.4f} | Loss: {loss:.4f}\\n')\n",
    "\n",
    "#     print(f\"Mean accuracy: {np.mean(accs):.4f}\\n\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# compute_TSTR_Syn_all('realworld_mobiact')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 395519,
     "status": "ok",
     "timestamp": 1732620473959,
     "user": {
      "displayName": "Pietro Cirino",
      "userId": "07315473796200699505"
     },
     "user_tz": -60
    },
    "id": "LA71th1bCPto",
    "outputId": "3cbdefb1-744b-4fc5-eb0f-c01fc4368f5c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source class: WAL\n",
      "\n",
      "x_df.shape: (7958, 3, 128) | np.unique(y_df): [1 2 3]\n",
      "\n",
      "Training on Df data...\n",
      "\tEpoch 10/100 - Train loss: 0.0261 - Val accuracy: 0.9849 - Val loss: 0.0419 - Val F1: 0.9849 - LR: 9.00e-05\n",
      "\tEpoch 20/100 - Train loss: 0.0108 - Val accuracy: 0.9868 - Val loss: 0.0473 - Val F1: 0.9868 - LR: 8.00e-05\n",
      "\tEpoch 30/100 - Train loss: 0.0032 - Val accuracy: 0.9874 - Val loss: 0.0387 - Val F1: 0.9874 - LR: 7.00e-05\n",
      "\tEpoch 40/100 - Train loss: 0.0022 - Val accuracy: 0.9856 - Val loss: 0.0448 - Val F1: 0.9855 - LR: 6.00e-05\n",
      "\tEpoch 50/100 - Train loss: 0.0012 - Val accuracy: 0.9874 - Val loss: 0.0447 - Val F1: 0.9874 - LR: 5.00e-05\n",
      "\tEpoch 60/100 - Train loss: 0.0005 - Val accuracy: 0.9874 - Val loss: 0.0471 - Val F1: 0.9874 - LR: 4.00e-05\n",
      "\tEpoch 70/100 - Train loss: 0.0006 - Val accuracy: 0.9874 - Val loss: 0.0486 - Val F1: 0.9874 - LR: 3.00e-05\n",
      "\tEpoch 80/100 - Train loss: 0.0003 - Val accuracy: 0.9874 - Val loss: 0.0463 - Val F1: 0.9874 - LR: 2.00e-05\n",
      "\tEpoch 90/100 - Train loss: 0.0002 - Val accuracy: 0.9887 - Val loss: 0.0453 - Val F1: 0.9887 - LR: 1.00e-05\n",
      "\tEpoch 100/100 - Train loss: 0.0002 - Val accuracy: 0.9874 - Val loss: 0.0438 - Val F1: 0.9874 - LR: 0.00e+00\n",
      "\tBest epoch: 28 - Best val accuracy: 0.9856 - Best val loss: 0.0342 - Best val F1: 0.9855\n",
      "\n",
      "Domain: 15\n",
      "x_syn_dom.shape: (333, 3, 128) | np.unique(y_syn_dom): [1 2 3]\n",
      "x_dp_dom.shape: (50, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Fine-tuning on synthetic data...\n",
      "\tEpoch 10/100 - Train loss: 1.0411 - Val accuracy: 0.7164 - Val loss: 0.9241 - Val F1: 0.6856 - LR: 9.00e-06\n",
      "\tEpoch 20/100 - Train loss: 0.7804 - Val accuracy: 0.8060 - Val loss: 0.6553 - Val F1: 0.7915 - LR: 8.00e-06\n",
      "\tEpoch 30/100 - Train loss: 0.7469 - Val accuracy: 0.8209 - Val loss: 0.5260 - Val F1: 0.8094 - LR: 7.00e-06\n",
      "\tEpoch 40/100 - Train loss: 0.5708 - Val accuracy: 0.8358 - Val loss: 0.4664 - Val F1: 0.8279 - LR: 6.00e-06\n",
      "\tEpoch 50/100 - Train loss: 0.4107 - Val accuracy: 0.8358 - Val loss: 0.4298 - Val F1: 0.8279 - LR: 5.00e-06\n",
      "\tEpoch 60/100 - Train loss: 0.3912 - Val accuracy: 0.8507 - Val loss: 0.4232 - Val F1: 0.8461 - LR: 4.00e-06\n",
      "\tEpoch 70/100 - Train loss: 0.7219 - Val accuracy: 0.8358 - Val loss: 0.4417 - Val F1: 0.8295 - LR: 3.00e-06\n",
      "\tEpoch 80/100 - Train loss: 0.4292 - Val accuracy: 0.8358 - Val loss: 0.4123 - Val F1: 0.8295 - LR: 2.00e-06\n",
      "\tEpoch 90/100 - Train loss: 0.4630 - Val accuracy: 0.8358 - Val loss: 0.4213 - Val F1: 0.8295 - LR: 1.00e-06\n",
      "\tEpoch 100/100 - Train loss: 0.3175 - Val accuracy: 0.8358 - Val loss: 0.4019 - Val F1: 0.8295 - LR: 0.00e+00\n",
      "\tBest epoch: 86 - Best val accuracy: 0.8657 - Best val loss: 0.3539 - Best val F1: 0.8635\n",
      "\n",
      "Source class: WAL | Domain: 15 | Accuracy: 0.8000 | Loss: 4.0540 | F1: 0.7152\n",
      "\n",
      "Domain: 16\n",
      "x_syn_dom.shape: (333, 3, 128) | np.unique(y_syn_dom): [1 2 3]\n",
      "x_dp_dom.shape: (54, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Fine-tuning on synthetic data...\n",
      "\tEpoch 10/100 - Train loss: 0.8373 - Val accuracy: 0.7612 - Val loss: 0.9019 - Val F1: 0.7430 - LR: 9.00e-06\n",
      "\tEpoch 20/100 - Train loss: 0.5887 - Val accuracy: 0.7910 - Val loss: 0.6651 - Val F1: 0.7834 - LR: 8.00e-06\n",
      "\tEpoch 30/100 - Train loss: 0.5974 - Val accuracy: 0.8209 - Val loss: 0.5970 - Val F1: 0.8182 - LR: 7.00e-06\n",
      "\tEpoch 40/100 - Train loss: 0.5270 - Val accuracy: 0.8209 - Val loss: 0.5664 - Val F1: 0.8202 - LR: 6.00e-06\n",
      "\tEpoch 50/100 - Train loss: 0.5304 - Val accuracy: 0.8358 - Val loss: 0.5409 - Val F1: 0.8341 - LR: 5.00e-06\n",
      "\tEpoch 60/100 - Train loss: 0.5183 - Val accuracy: 0.8209 - Val loss: 0.5021 - Val F1: 0.8202 - LR: 4.00e-06\n",
      "\tEpoch 70/100 - Train loss: 0.4029 - Val accuracy: 0.8507 - Val loss: 0.4805 - Val F1: 0.8513 - LR: 3.00e-06\n",
      "\tEpoch 80/100 - Train loss: 0.4830 - Val accuracy: 0.8358 - Val loss: 0.4580 - Val F1: 0.8337 - LR: 2.00e-06\n",
      "\tEpoch 90/100 - Train loss: 0.5377 - Val accuracy: 0.8358 - Val loss: 0.4591 - Val F1: 0.8337 - LR: 1.00e-06\n",
      "\tEpoch 100/100 - Train loss: 0.4978 - Val accuracy: 0.8209 - Val loss: 0.4745 - Val F1: 0.8175 - LR: 0.00e+00\n",
      "\tBest epoch: 99 - Best val accuracy: 0.8507 - Best val loss: 0.4386 - Best val F1: 0.8495\n",
      "\n",
      "Source class: WAL | Domain: 16 | Accuracy: 0.5741 | Loss: 1.4924 | F1: 0.5937\n",
      "\n",
      "Domain: 17\n",
      "x_syn_dom.shape: (333, 3, 128) | np.unique(y_syn_dom): [1 2 3]\n",
      "x_dp_dom.shape: (53, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Fine-tuning on synthetic data...\n",
      "\tEpoch 10/100 - Train loss: 0.7534 - Val accuracy: 0.7910 - Val loss: 1.0244 - Val F1: 0.7769 - LR: 9.00e-06\n",
      "\tEpoch 20/100 - Train loss: 0.5220 - Val accuracy: 0.8060 - Val loss: 0.8384 - Val F1: 0.7950 - LR: 8.00e-06\n",
      "\tEpoch 30/100 - Train loss: 0.4746 - Val accuracy: 0.8060 - Val loss: 0.7149 - Val F1: 0.7989 - LR: 7.00e-06\n",
      "\tEpoch 40/100 - Train loss: 0.4379 - Val accuracy: 0.8358 - Val loss: 0.6889 - Val F1: 0.8322 - LR: 6.00e-06\n",
      "\tEpoch 50/100 - Train loss: 0.3716 - Val accuracy: 0.8358 - Val loss: 0.6533 - Val F1: 0.8322 - LR: 5.00e-06\n",
      "\tEpoch 60/100 - Train loss: 0.4076 - Val accuracy: 0.8358 - Val loss: 0.6519 - Val F1: 0.8322 - LR: 4.00e-06\n",
      "\tEpoch 70/100 - Train loss: 0.6488 - Val accuracy: 0.8358 - Val loss: 0.6425 - Val F1: 0.8322 - LR: 3.00e-06\n",
      "\tEpoch 80/100 - Train loss: 0.3058 - Val accuracy: 0.8358 - Val loss: 0.6228 - Val F1: 0.8322 - LR: 2.00e-06\n",
      "\tEpoch 90/100 - Train loss: 0.4774 - Val accuracy: 0.8358 - Val loss: 0.6128 - Val F1: 0.8322 - LR: 1.00e-06\n",
      "\tEpoch 100/100 - Train loss: 0.4567 - Val accuracy: 0.8358 - Val loss: 0.6046 - Val F1: 0.8322 - LR: 0.00e+00\n",
      "\tBest epoch: 82 - Best val accuracy: 0.8358 - Best val loss: 0.6002 - Best val F1: 0.8322\n",
      "\n",
      "Source class: WAL | Domain: 17 | Accuracy: 0.2453 | Loss: 5.4786 | F1: 0.1678\n",
      "\n",
      "Domain: 18\n",
      "x_syn_dom.shape: (336, 3, 128) | np.unique(y_syn_dom): [1 2 3]\n",
      "x_dp_dom.shape: (54, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Fine-tuning on synthetic data...\n",
      "\tEpoch 10/100 - Train loss: 1.1705 - Val accuracy: 0.7206 - Val loss: 0.9073 - Val F1: 0.7054 - LR: 9.00e-06\n",
      "\tEpoch 20/100 - Train loss: 0.8652 - Val accuracy: 0.7794 - Val loss: 0.6596 - Val F1: 0.7750 - LR: 8.00e-06\n",
      "\tEpoch 30/100 - Train loss: 0.7259 - Val accuracy: 0.7794 - Val loss: 0.5212 - Val F1: 0.7755 - LR: 7.00e-06\n",
      "\tEpoch 40/100 - Train loss: 0.6495 - Val accuracy: 0.8088 - Val loss: 0.4401 - Val F1: 0.8062 - LR: 6.00e-06\n",
      "\tEpoch 50/100 - Train loss: 0.8255 - Val accuracy: 0.8088 - Val loss: 0.4031 - Val F1: 0.8076 - LR: 5.00e-06\n",
      "\tEpoch 60/100 - Train loss: 0.7156 - Val accuracy: 0.8529 - Val loss: 0.3542 - Val F1: 0.8508 - LR: 4.00e-06\n",
      "\tEpoch 70/100 - Train loss: 0.5974 - Val accuracy: 0.8824 - Val loss: 0.3205 - Val F1: 0.8802 - LR: 3.00e-06\n",
      "\tEpoch 80/100 - Train loss: 0.4733 - Val accuracy: 0.8676 - Val loss: 0.3220 - Val F1: 0.8678 - LR: 2.00e-06\n",
      "\tEpoch 90/100 - Train loss: 0.6545 - Val accuracy: 0.8971 - Val loss: 0.2989 - Val F1: 0.8968 - LR: 1.00e-06\n",
      "\tEpoch 100/100 - Train loss: 0.5499 - Val accuracy: 0.8971 - Val loss: 0.3025 - Val F1: 0.8968 - LR: 0.00e+00\n",
      "\tBest epoch: 96 - Best val accuracy: 0.8971 - Best val loss: 0.2978 - Best val F1: 0.8968\n",
      "\n",
      "Source class: WAL | Domain: 18 | Accuracy: 0.7407 | Loss: 1.8351 | F1: 0.6941\n",
      "\n",
      "Domain: 19\n",
      "x_syn_dom.shape: (333, 3, 128) | np.unique(y_syn_dom): [1 2 3]\n",
      "x_dp_dom.shape: (54, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Fine-tuning on synthetic data...\n",
      "\tEpoch 10/100 - Train loss: 0.8902 - Val accuracy: 0.7015 - Val loss: 1.2903 - Val F1: 0.6480 - LR: 9.00e-06\n",
      "\tEpoch 20/100 - Train loss: 0.7106 - Val accuracy: 0.8358 - Val loss: 0.6590 - Val F1: 0.8224 - LR: 8.00e-06\n",
      "\tEpoch 30/100 - Train loss: 0.5247 - Val accuracy: 0.8657 - Val loss: 0.5684 - Val F1: 0.8601 - LR: 7.00e-06\n",
      "\tEpoch 40/100 - Train loss: 0.4437 - Val accuracy: 0.8806 - Val loss: 0.4877 - Val F1: 0.8733 - LR: 6.00e-06\n",
      "\tEpoch 50/100 - Train loss: 0.3901 - Val accuracy: 0.8955 - Val loss: 0.4696 - Val F1: 0.8928 - LR: 5.00e-06\n",
      "\tEpoch 60/100 - Train loss: 0.3263 - Val accuracy: 0.8955 - Val loss: 0.5260 - Val F1: 0.8928 - LR: 4.00e-06\n",
      "\tEpoch 70/100 - Train loss: 0.3118 - Val accuracy: 0.8955 - Val loss: 0.4513 - Val F1: 0.8928 - LR: 3.00e-06\n",
      "\tEpoch 80/100 - Train loss: 0.3152 - Val accuracy: 0.8955 - Val loss: 0.4199 - Val F1: 0.8928 - LR: 2.00e-06\n",
      "\tEpoch 90/100 - Train loss: 0.3177 - Val accuracy: 0.8955 - Val loss: 0.4321 - Val F1: 0.8928 - LR: 1.00e-06\n",
      "\tEpoch 100/100 - Train loss: 0.4515 - Val accuracy: 0.9254 - Val loss: 0.3717 - Val F1: 0.9244 - LR: 0.00e+00\n",
      "\tBest epoch: 100 - Best val accuracy: 0.9254 - Best val loss: 0.3717 - Best val F1: 0.9244\n",
      "\n",
      "Source class: WAL | Domain: 19 | Accuracy: 0.5556 | Loss: 1.1839 | F1: 0.5423\n",
      "\n",
      "Domain: 20\n",
      "x_syn_dom.shape: (333, 3, 128) | np.unique(y_syn_dom): [1 2 3]\n",
      "x_dp_dom.shape: (51, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Fine-tuning on synthetic data...\n",
      "\tEpoch 10/100 - Train loss: 0.6821 - Val accuracy: 0.8955 - Val loss: 0.4951 - Val F1: 0.8941 - LR: 9.00e-06\n",
      "\tEpoch 20/100 - Train loss: 0.5937 - Val accuracy: 0.9104 - Val loss: 0.3566 - Val F1: 0.9090 - LR: 8.00e-06\n",
      "\tEpoch 30/100 - Train loss: 0.4042 - Val accuracy: 0.9104 - Val loss: 0.3031 - Val F1: 0.9090 - LR: 7.00e-06\n",
      "\tEpoch 40/100 - Train loss: 0.5576 - Val accuracy: 0.9254 - Val loss: 0.2529 - Val F1: 0.9247 - LR: 6.00e-06\n",
      "\tEpoch 50/100 - Train loss: 0.3375 - Val accuracy: 0.9254 - Val loss: 0.2409 - Val F1: 0.9247 - LR: 5.00e-06\n",
      "\tEpoch 60/100 - Train loss: 0.3727 - Val accuracy: 0.9254 - Val loss: 0.2086 - Val F1: 0.9247 - LR: 4.00e-06\n",
      "\tEpoch 70/100 - Train loss: 0.4202 - Val accuracy: 0.9403 - Val loss: 0.2098 - Val F1: 0.9400 - LR: 3.00e-06\n",
      "\tEpoch 80/100 - Train loss: 0.3583 - Val accuracy: 0.9403 - Val loss: 0.2024 - Val F1: 0.9400 - LR: 2.00e-06\n",
      "\tEpoch 90/100 - Train loss: 0.3028 - Val accuracy: 0.9403 - Val loss: 0.2007 - Val F1: 0.9400 - LR: 1.00e-06\n",
      "\tEpoch 100/100 - Train loss: 0.3533 - Val accuracy: 0.9403 - Val loss: 0.1946 - Val F1: 0.9400 - LR: 0.00e+00\n",
      "\tBest epoch: 91 - Best val accuracy: 0.9403 - Best val loss: 0.1877 - Best val F1: 0.9400\n",
      "\n",
      "Source class: WAL | Domain: 20 | Accuracy: 0.7647 | Loss: 0.8943 | F1: 0.7769\n",
      "\n",
      "Domain: 21\n",
      "x_syn_dom.shape: (336, 3, 128) | np.unique(y_syn_dom): [1 2 3]\n",
      "x_dp_dom.shape: (47, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Fine-tuning on synthetic data...\n",
      "\tEpoch 10/100 - Train loss: 0.7705 - Val accuracy: 0.8676 - Val loss: 0.5095 - Val F1: 0.8647 - LR: 9.00e-06\n",
      "\tEpoch 20/100 - Train loss: 0.5269 - Val accuracy: 0.9265 - Val loss: 0.3227 - Val F1: 0.9257 - LR: 8.00e-06\n",
      "\tEpoch 30/100 - Train loss: 0.4637 - Val accuracy: 0.9118 - Val loss: 0.2366 - Val F1: 0.9112 - LR: 7.00e-06\n",
      "\tEpoch 40/100 - Train loss: 0.5552 - Val accuracy: 0.9265 - Val loss: 0.2474 - Val F1: 0.9257 - LR: 6.00e-06\n",
      "\tEpoch 50/100 - Train loss: 0.3732 - Val accuracy: 0.9265 - Val loss: 0.2108 - Val F1: 0.9257 - LR: 5.00e-06\n",
      "\tEpoch 60/100 - Train loss: 0.3724 - Val accuracy: 0.9265 - Val loss: 0.1914 - Val F1: 0.9257 - LR: 4.00e-06\n",
      "\tEpoch 70/100 - Train loss: 0.5459 - Val accuracy: 0.9118 - Val loss: 0.1795 - Val F1: 0.9112 - LR: 3.00e-06\n",
      "\tEpoch 80/100 - Train loss: 0.4829 - Val accuracy: 0.9265 - Val loss: 0.1783 - Val F1: 0.9257 - LR: 2.00e-06\n",
      "\tEpoch 90/100 - Train loss: 0.6327 - Val accuracy: 0.9265 - Val loss: 0.1773 - Val F1: 0.9257 - LR: 1.00e-06\n",
      "\tEpoch 100/100 - Train loss: 0.4193 - Val accuracy: 0.9265 - Val loss: 0.1709 - Val F1: 0.9257 - LR: 0.00e+00\n",
      "\tBest epoch: 95 - Best val accuracy: 0.9118 - Best val loss: 0.1621 - Best val F1: 0.9112\n",
      "\n",
      "Source class: WAL | Domain: 21 | Accuracy: 0.6809 | Loss: 0.8914 | F1: 0.7233\n",
      "\n",
      "Domain: 22\n",
      "x_syn_dom.shape: (333, 3, 128) | np.unique(y_syn_dom): [1 2 3]\n",
      "x_dp_dom.shape: (54, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Fine-tuning on synthetic data...\n",
      "\tEpoch 10/100 - Train loss: 0.8763 - Val accuracy: 0.8358 - Val loss: 0.6985 - Val F1: 0.8190 - LR: 9.00e-06\n",
      "\tEpoch 20/100 - Train loss: 0.8200 - Val accuracy: 0.8358 - Val loss: 0.5387 - Val F1: 0.8302 - LR: 8.00e-06\n",
      "\tEpoch 30/100 - Train loss: 0.5759 - Val accuracy: 0.8507 - Val loss: 0.4467 - Val F1: 0.8477 - LR: 7.00e-06\n",
      "\tEpoch 40/100 - Train loss: 0.4518 - Val accuracy: 0.8507 - Val loss: 0.3937 - Val F1: 0.8477 - LR: 6.00e-06\n",
      "\tEpoch 50/100 - Train loss: 0.6231 - Val accuracy: 0.8507 - Val loss: 0.3667 - Val F1: 0.8477 - LR: 5.00e-06\n",
      "\tEpoch 60/100 - Train loss: 0.5209 - Val accuracy: 0.8507 - Val loss: 0.3218 - Val F1: 0.8477 - LR: 4.00e-06\n",
      "\tEpoch 70/100 - Train loss: 0.5037 - Val accuracy: 0.8507 - Val loss: 0.3112 - Val F1: 0.8477 - LR: 3.00e-06\n",
      "\tEpoch 80/100 - Train loss: 0.5212 - Val accuracy: 0.8507 - Val loss: 0.2996 - Val F1: 0.8477 - LR: 2.00e-06\n",
      "\tEpoch 90/100 - Train loss: 0.4692 - Val accuracy: 0.8507 - Val loss: 0.2900 - Val F1: 0.8477 - LR: 1.00e-06\n",
      "\tEpoch 100/100 - Train loss: 0.4617 - Val accuracy: 0.8657 - Val loss: 0.3004 - Val F1: 0.8622 - LR: 0.00e+00\n",
      "\tBest epoch: 81 - Best val accuracy: 0.8806 - Best val loss: 0.2866 - Best val F1: 0.8791\n",
      "\n",
      "Source class: WAL | Domain: 22 | Accuracy: 0.6296 | Loss: 1.5272 | F1: 0.6529\n",
      "\n",
      "Domain: 23\n",
      "x_syn_dom.shape: (336, 3, 128) | np.unique(y_syn_dom): [1 2 3]\n",
      "x_dp_dom.shape: (52, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Fine-tuning on synthetic data...\n",
      "\tEpoch 10/100 - Train loss: 1.0119 - Val accuracy: 0.7794 - Val loss: 1.0279 - Val F1: 0.7616 - LR: 9.00e-06\n",
      "\tEpoch 20/100 - Train loss: 0.8934 - Val accuracy: 0.7647 - Val loss: 0.8654 - Val F1: 0.7485 - LR: 8.00e-06\n",
      "\tEpoch 30/100 - Train loss: 0.6479 - Val accuracy: 0.7647 - Val loss: 0.7976 - Val F1: 0.7552 - LR: 7.00e-06\n",
      "\tEpoch 40/100 - Train loss: 0.5776 - Val accuracy: 0.7941 - Val loss: 0.7984 - Val F1: 0.7819 - LR: 6.00e-06\n",
      "\tEpoch 50/100 - Train loss: 0.7395 - Val accuracy: 0.7941 - Val loss: 0.7293 - Val F1: 0.7819 - LR: 5.00e-06\n",
      "\tEpoch 60/100 - Train loss: 0.5879 - Val accuracy: 0.7941 - Val loss: 0.7165 - Val F1: 0.7819 - LR: 4.00e-06\n",
      "\tEpoch 70/100 - Train loss: 0.6333 - Val accuracy: 0.7941 - Val loss: 0.7007 - Val F1: 0.7846 - LR: 3.00e-06\n",
      "\tEpoch 80/100 - Train loss: 0.5929 - Val accuracy: 0.7941 - Val loss: 0.7014 - Val F1: 0.7846 - LR: 2.00e-06\n",
      "\tEpoch 90/100 - Train loss: 0.5252 - Val accuracy: 0.8235 - Val loss: 0.6707 - Val F1: 0.8185 - LR: 1.00e-06\n",
      "\tEpoch 100/100 - Train loss: 0.4937 - Val accuracy: 0.7941 - Val loss: 0.6898 - Val F1: 0.7846 - LR: 0.00e+00\n",
      "\tBest epoch: 87 - Best val accuracy: 0.8088 - Best val loss: 0.6341 - Best val F1: 0.8047\n",
      "\n",
      "Source class: WAL | Domain: 23 | Accuracy: 0.7692 | Loss: 1.0581 | F1: 0.7800\n",
      "\n",
      "Domain: 24\n",
      "x_syn_dom.shape: (333, 3, 128) | np.unique(y_syn_dom): [1 2 3]\n",
      "x_dp_dom.shape: (51, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Fine-tuning on synthetic data...\n",
      "\tEpoch 10/100 - Train loss: 1.0668 - Val accuracy: 0.7761 - Val loss: 0.8211 - Val F1: 0.7513 - LR: 9.00e-06\n",
      "\tEpoch 20/100 - Train loss: 0.6269 - Val accuracy: 0.8507 - Val loss: 0.3506 - Val F1: 0.8418 - LR: 8.00e-06\n",
      "\tEpoch 30/100 - Train loss: 0.4941 - Val accuracy: 0.9403 - Val loss: 0.1965 - Val F1: 0.9398 - LR: 7.00e-06\n",
      "\tEpoch 40/100 - Train loss: 0.6771 - Val accuracy: 0.9403 - Val loss: 0.1365 - Val F1: 0.9398 - LR: 6.00e-06\n",
      "\tEpoch 50/100 - Train loss: 0.3645 - Val accuracy: 0.9403 - Val loss: 0.1391 - Val F1: 0.9398 - LR: 5.00e-06\n",
      "\tEpoch 60/100 - Train loss: 0.5250 - Val accuracy: 0.9403 - Val loss: 0.1128 - Val F1: 0.9398 - LR: 4.00e-06\n",
      "\tEpoch 70/100 - Train loss: 0.4152 - Val accuracy: 0.9403 - Val loss: 0.1634 - Val F1: 0.9398 - LR: 3.00e-06\n",
      "\tEpoch 80/100 - Train loss: 0.4573 - Val accuracy: 0.9403 - Val loss: 0.1288 - Val F1: 0.9398 - LR: 2.00e-06\n",
      "\tEpoch 90/100 - Train loss: 0.5367 - Val accuracy: 0.9403 - Val loss: 0.1306 - Val F1: 0.9398 - LR: 1.00e-06\n",
      "\tEpoch 100/100 - Train loss: 0.4703 - Val accuracy: 0.9403 - Val loss: 0.1230 - Val F1: 0.9398 - LR: 0.00e+00\n",
      "\tBest epoch: 82 - Best val accuracy: 0.9701 - Best val loss: 0.0989 - Best val F1: 0.9701\n",
      "\n",
      "Source class: WAL | Domain: 24 | Accuracy: 0.9020 | Loss: 0.2474 | F1: 0.9034\n",
      "\n",
      "Domain: 25\n",
      "x_syn_dom.shape: (336, 3, 128) | np.unique(y_syn_dom): [1 2 3]\n",
      "x_dp_dom.shape: (54, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Fine-tuning on synthetic data...\n",
      "\tEpoch 10/100 - Train loss: 0.5338 - Val accuracy: 0.8676 - Val loss: 0.4973 - Val F1: 0.8654 - LR: 9.00e-06\n",
      "\tEpoch 20/100 - Train loss: 0.5480 - Val accuracy: 0.8971 - Val loss: 0.3222 - Val F1: 0.8976 - LR: 8.00e-06\n",
      "\tEpoch 30/100 - Train loss: 0.2850 - Val accuracy: 0.9118 - Val loss: 0.2711 - Val F1: 0.9119 - LR: 7.00e-06\n",
      "\tEpoch 40/100 - Train loss: 0.2595 - Val accuracy: 0.9265 - Val loss: 0.2230 - Val F1: 0.9268 - LR: 6.00e-06\n",
      "\tEpoch 50/100 - Train loss: 0.5508 - Val accuracy: 0.9265 - Val loss: 0.2261 - Val F1: 0.9268 - LR: 5.00e-06\n",
      "\tEpoch 60/100 - Train loss: 0.2865 - Val accuracy: 0.9265 - Val loss: 0.2194 - Val F1: 0.9268 - LR: 4.00e-06\n",
      "\tEpoch 70/100 - Train loss: 0.2335 - Val accuracy: 0.9412 - Val loss: 0.1993 - Val F1: 0.9411 - LR: 3.00e-06\n",
      "\tEpoch 80/100 - Train loss: 0.2656 - Val accuracy: 0.9412 - Val loss: 0.1964 - Val F1: 0.9411 - LR: 2.00e-06\n",
      "\tEpoch 90/100 - Train loss: 0.2915 - Val accuracy: 0.9412 - Val loss: 0.1835 - Val F1: 0.9411 - LR: 1.00e-06\n",
      "\tEpoch 100/100 - Train loss: 0.2835 - Val accuracy: 0.9412 - Val loss: 0.1864 - Val F1: 0.9411 - LR: 0.00e+00\n",
      "\tBest epoch: 91 - Best val accuracy: 0.9412 - Best val loss: 0.1818 - Best val F1: 0.9411\n",
      "\n",
      "Source class: WAL | Domain: 25 | Accuracy: 0.7593 | Loss: 2.3073 | F1: 0.6790\n",
      "\n",
      "Domain: 26\n",
      "x_syn_dom.shape: (333, 3, 128) | np.unique(y_syn_dom): [1 2 3]\n",
      "x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Fine-tuning on synthetic data...\n",
      "\tEpoch 10/100 - Train loss: 0.9856 - Val accuracy: 0.7463 - Val loss: 0.8277 - Val F1: 0.7177 - LR: 9.00e-06\n",
      "\tEpoch 20/100 - Train loss: 0.7328 - Val accuracy: 0.8209 - Val loss: 0.5638 - Val F1: 0.8083 - LR: 8.00e-06\n",
      "\tEpoch 30/100 - Train loss: 0.6531 - Val accuracy: 0.8358 - Val loss: 0.4841 - Val F1: 0.8263 - LR: 7.00e-06\n",
      "\tEpoch 40/100 - Train loss: 0.5560 - Val accuracy: 0.8507 - Val loss: 0.4130 - Val F1: 0.8439 - LR: 6.00e-06\n",
      "\tEpoch 50/100 - Train loss: 0.5139 - Val accuracy: 0.8806 - Val loss: 0.3779 - Val F1: 0.8749 - LR: 5.00e-06\n",
      "\tEpoch 60/100 - Train loss: 0.5192 - Val accuracy: 0.8806 - Val loss: 0.3453 - Val F1: 0.8749 - LR: 4.00e-06\n",
      "\tEpoch 70/100 - Train loss: 0.5245 - Val accuracy: 0.8806 - Val loss: 0.3381 - Val F1: 0.8767 - LR: 3.00e-06\n",
      "\tEpoch 80/100 - Train loss: 0.4966 - Val accuracy: 0.8806 - Val loss: 0.3247 - Val F1: 0.8767 - LR: 2.00e-06\n",
      "\tEpoch 90/100 - Train loss: 0.5805 - Val accuracy: 0.8806 - Val loss: 0.3262 - Val F1: 0.8767 - LR: 1.00e-06\n",
      "\tEpoch 100/100 - Train loss: 0.4740 - Val accuracy: 0.8806 - Val loss: 0.3322 - Val F1: 0.8767 - LR: 0.00e+00\n",
      "\tBest epoch: 96 - Best val accuracy: 0.8955 - Best val loss: 0.2972 - Best val F1: 0.8918\n",
      "\n",
      "Source class: WAL | Domain: 26 | Accuracy: 0.8333 | Loss: 0.4882 | F1: 0.8399\n",
      "\n",
      "Domain: 27\n",
      "x_syn_dom.shape: (333, 3, 128) | np.unique(y_syn_dom): [1 2 3]\n",
      "x_dp_dom.shape: (54, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Fine-tuning on synthetic data...\n",
      "\tEpoch 10/100 - Train loss: 0.3343 - Val accuracy: 0.8955 - Val loss: 0.3389 - Val F1: 0.8953 - LR: 9.00e-06\n",
      "\tEpoch 20/100 - Train loss: 0.2353 - Val accuracy: 0.8955 - Val loss: 0.2973 - Val F1: 0.8953 - LR: 8.00e-06\n",
      "\tEpoch 30/100 - Train loss: 0.1875 - Val accuracy: 0.9104 - Val loss: 0.2499 - Val F1: 0.9105 - LR: 7.00e-06\n",
      "\tEpoch 40/100 - Train loss: 0.2147 - Val accuracy: 0.9254 - Val loss: 0.2322 - Val F1: 0.9256 - LR: 6.00e-06\n",
      "\tEpoch 50/100 - Train loss: 0.2791 - Val accuracy: 0.9254 - Val loss: 0.2118 - Val F1: 0.9256 - LR: 5.00e-06\n",
      "\tEpoch 60/100 - Train loss: 0.1930 - Val accuracy: 0.9104 - Val loss: 0.2241 - Val F1: 0.9105 - LR: 4.00e-06\n",
      "\tEpoch 70/100 - Train loss: 0.2149 - Val accuracy: 0.9104 - Val loss: 0.2298 - Val F1: 0.9105 - LR: 3.00e-06\n",
      "\tEpoch 80/100 - Train loss: 0.1801 - Val accuracy: 0.9254 - Val loss: 0.1972 - Val F1: 0.9256 - LR: 2.00e-06\n",
      "\tEpoch 90/100 - Train loss: 0.1638 - Val accuracy: 0.9254 - Val loss: 0.2182 - Val F1: 0.9250 - LR: 1.00e-06\n",
      "\tEpoch 100/100 - Train loss: 0.2604 - Val accuracy: 0.9254 - Val loss: 0.1832 - Val F1: 0.9256 - LR: 0.00e+00\n",
      "\tBest epoch: 99 - Best val accuracy: 0.9254 - Best val loss: 0.1791 - Best val F1: 0.9256\n",
      "\n",
      "Source class: WAL | Domain: 27 | Accuracy: 0.4074 | Loss: 3.0887 | F1: 0.3841\n",
      "\n",
      "Domain: 28\n",
      "x_syn_dom.shape: (333, 3, 128) | np.unique(y_syn_dom): [1 2 3]\n",
      "x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Fine-tuning on synthetic data...\n",
      "\tEpoch 10/100 - Train loss: 0.3512 - Val accuracy: 0.9701 - Val loss: 0.0743 - Val F1: 0.9701 - LR: 9.00e-06\n",
      "\tEpoch 20/100 - Train loss: 0.2639 - Val accuracy: 0.9851 - Val loss: 0.0592 - Val F1: 0.9851 - LR: 8.00e-06\n",
      "\tEpoch 30/100 - Train loss: 0.2170 - Val accuracy: 0.9701 - Val loss: 0.0623 - Val F1: 0.9701 - LR: 7.00e-06\n",
      "\tEpoch 40/100 - Train loss: 0.2917 - Val accuracy: 0.9851 - Val loss: 0.0513 - Val F1: 0.9851 - LR: 6.00e-06\n",
      "\tEpoch 50/100 - Train loss: 0.3162 - Val accuracy: 0.9851 - Val loss: 0.0482 - Val F1: 0.9851 - LR: 5.00e-06\n",
      "\tEpoch 60/100 - Train loss: 0.1960 - Val accuracy: 1.0000 - Val loss: 0.0453 - Val F1: 1.0000 - LR: 4.00e-06\n",
      "\tEpoch 70/100 - Train loss: 0.2979 - Val accuracy: 0.9851 - Val loss: 0.0495 - Val F1: 0.9851 - LR: 3.00e-06\n",
      "\tEpoch 80/100 - Train loss: 0.2086 - Val accuracy: 1.0000 - Val loss: 0.0459 - Val F1: 1.0000 - LR: 2.00e-06\n",
      "\tEpoch 90/100 - Train loss: 0.2711 - Val accuracy: 1.0000 - Val loss: 0.0440 - Val F1: 1.0000 - LR: 1.00e-06\n",
      "\tEpoch 100/100 - Train loss: 0.1634 - Val accuracy: 0.9851 - Val loss: 0.0491 - Val F1: 0.9851 - LR: 0.00e+00\n",
      "\tBest epoch: 93 - Best val accuracy: 1.0000 - Best val loss: 0.0421 - Best val F1: 1.0000\n",
      "\n",
      "Source class: WAL | Domain: 28 | Accuracy: 0.7381 | Loss: 1.5959 | F1: 0.7204\n",
      "\n",
      "Domain: 29\n",
      "x_syn_dom.shape: (333, 3, 128) | np.unique(y_syn_dom): [1 2 3]\n",
      "x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Fine-tuning on synthetic data...\n",
      "\tEpoch 10/100 - Train loss: 0.4830 - Val accuracy: 0.8806 - Val loss: 0.3873 - Val F1: 0.8797 - LR: 9.00e-06\n",
      "\tEpoch 20/100 - Train loss: 0.5383 - Val accuracy: 0.8955 - Val loss: 0.3114 - Val F1: 0.8948 - LR: 8.00e-06\n",
      "\tEpoch 30/100 - Train loss: 0.4004 - Val accuracy: 0.9254 - Val loss: 0.2763 - Val F1: 0.9251 - LR: 7.00e-06\n",
      "\tEpoch 40/100 - Train loss: 0.3078 - Val accuracy: 0.9403 - Val loss: 0.2493 - Val F1: 0.9402 - LR: 6.00e-06\n",
      "\tEpoch 50/100 - Train loss: 0.3203 - Val accuracy: 0.9701 - Val loss: 0.2307 - Val F1: 0.9701 - LR: 5.00e-06\n",
      "\tEpoch 60/100 - Train loss: 0.3454 - Val accuracy: 0.9851 - Val loss: 0.2189 - Val F1: 0.9851 - LR: 4.00e-06\n",
      "\tEpoch 70/100 - Train loss: 0.2544 - Val accuracy: 0.9851 - Val loss: 0.2089 - Val F1: 0.9851 - LR: 3.00e-06\n",
      "\tEpoch 80/100 - Train loss: 0.2313 - Val accuracy: 0.9851 - Val loss: 0.2041 - Val F1: 0.9851 - LR: 2.00e-06\n",
      "\tEpoch 90/100 - Train loss: 0.2824 - Val accuracy: 0.9851 - Val loss: 0.2010 - Val F1: 0.9851 - LR: 1.00e-06\n",
      "\tEpoch 100/100 - Train loss: 0.2571 - Val accuracy: 0.9851 - Val loss: 0.1999 - Val F1: 0.9851 - LR: 0.00e+00\n",
      "\tBest epoch: 87 - Best val accuracy: 0.9851 - Best val loss: 0.1979 - Best val F1: 0.9851\n",
      "\n",
      "Source class: WAL | Domain: 29 | Accuracy: 0.3095 | Loss: 5.2906 | F1: 0.2345\n",
      "\n",
      "Domain: 30\n",
      "x_syn_dom.shape: (333, 3, 128) | np.unique(y_syn_dom): [1 2 3]\n",
      "x_dp_dom.shape: (50, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Fine-tuning on synthetic data...\n",
      "\tEpoch 10/100 - Train loss: 0.7435 - Val accuracy: 0.8209 - Val loss: 0.8932 - Val F1: 0.8040 - LR: 9.00e-06\n",
      "\tEpoch 20/100 - Train loss: 0.4921 - Val accuracy: 0.8358 - Val loss: 0.7162 - Val F1: 0.8299 - LR: 8.00e-06\n",
      "\tEpoch 30/100 - Train loss: 0.4530 - Val accuracy: 0.8507 - Val loss: 0.6103 - Val F1: 0.8494 - LR: 7.00e-06\n",
      "\tEpoch 40/100 - Train loss: 0.5913 - Val accuracy: 0.8507 - Val loss: 0.5434 - Val F1: 0.8488 - LR: 6.00e-06\n",
      "\tEpoch 50/100 - Train loss: 0.3312 - Val accuracy: 0.8806 - Val loss: 0.4612 - Val F1: 0.8772 - LR: 5.00e-06\n",
      "\tEpoch 60/100 - Train loss: 0.2999 - Val accuracy: 0.8806 - Val loss: 0.4177 - Val F1: 0.8772 - LR: 4.00e-06\n",
      "\tEpoch 70/100 - Train loss: 0.2954 - Val accuracy: 0.8657 - Val loss: 0.3838 - Val F1: 0.8625 - LR: 3.00e-06\n",
      "\tEpoch 80/100 - Train loss: 0.3195 - Val accuracy: 0.8657 - Val loss: 0.3592 - Val F1: 0.8625 - LR: 2.00e-06\n",
      "\tEpoch 90/100 - Train loss: 0.4611 - Val accuracy: 0.8806 - Val loss: 0.3599 - Val F1: 0.8784 - LR: 1.00e-06\n",
      "\tEpoch 100/100 - Train loss: 0.2497 - Val accuracy: 0.8657 - Val loss: 0.3552 - Val F1: 0.8635 - LR: 0.00e+00\n",
      "\tBest epoch: 96 - Best val accuracy: 0.8657 - Best val loss: 0.3479 - Best val F1: 0.8625\n",
      "\n",
      "Source class: WAL | Domain: 30 | Accuracy: 0.7600 | Loss: 0.8950 | F1: 0.6972\n",
      "\n",
      "Domain: 31\n",
      "x_syn_dom.shape: (333, 3, 128) | np.unique(y_syn_dom): [1 2 3]\n",
      "x_dp_dom.shape: (43, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Fine-tuning on synthetic data...\n",
      "\tEpoch 10/100 - Train loss: 0.2862 - Val accuracy: 0.9552 - Val loss: 0.0928 - Val F1: 0.9544 - LR: 9.00e-06\n",
      "\tEpoch 20/100 - Train loss: 0.2267 - Val accuracy: 0.9701 - Val loss: 0.0637 - Val F1: 0.9701 - LR: 8.00e-06\n",
      "\tEpoch 30/100 - Train loss: 0.4671 - Val accuracy: 1.0000 - Val loss: 0.0322 - Val F1: 1.0000 - LR: 7.00e-06\n",
      "\tEpoch 40/100 - Train loss: 0.1599 - Val accuracy: 1.0000 - Val loss: 0.0320 - Val F1: 1.0000 - LR: 6.00e-06\n",
      "\tEpoch 50/100 - Train loss: 0.2650 - Val accuracy: 1.0000 - Val loss: 0.0352 - Val F1: 1.0000 - LR: 5.00e-06\n",
      "\tEpoch 60/100 - Train loss: 0.1274 - Val accuracy: 1.0000 - Val loss: 0.0290 - Val F1: 1.0000 - LR: 4.00e-06\n",
      "\tEpoch 70/100 - Train loss: 0.1378 - Val accuracy: 1.0000 - Val loss: 0.0206 - Val F1: 1.0000 - LR: 3.00e-06\n",
      "\tEpoch 80/100 - Train loss: 0.2462 - Val accuracy: 1.0000 - Val loss: 0.0315 - Val F1: 1.0000 - LR: 2.00e-06\n",
      "\tEpoch 90/100 - Train loss: 0.1707 - Val accuracy: 1.0000 - Val loss: 0.0210 - Val F1: 1.0000 - LR: 1.00e-06\n",
      "\tEpoch 100/100 - Train loss: 0.0921 - Val accuracy: 1.0000 - Val loss: 0.0209 - Val F1: 1.0000 - LR: 0.00e+00\n",
      "\tBest epoch: 85 - Best val accuracy: 1.0000 - Best val loss: 0.0194 - Best val F1: 1.0000\n",
      "\n",
      "Source class: WAL | Domain: 31 | Accuracy: 0.8372 | Loss: 3.1208 | F1: 0.7632\n",
      "\n",
      "Domain: 32\n",
      "x_syn_dom.shape: (333, 3, 128) | np.unique(y_syn_dom): [1 2 3]\n",
      "x_dp_dom.shape: (52, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Fine-tuning on synthetic data...\n",
      "\tEpoch 10/100 - Train loss: 0.8263 - Val accuracy: 0.7164 - Val loss: 1.0315 - Val F1: 0.6852 - LR: 9.00e-06\n",
      "\tEpoch 20/100 - Train loss: 0.6825 - Val accuracy: 0.7910 - Val loss: 0.8137 - Val F1: 0.7770 - LR: 8.00e-06\n",
      "\tEpoch 30/100 - Train loss: 0.6233 - Val accuracy: 0.8209 - Val loss: 0.7380 - Val F1: 0.8130 - LR: 7.00e-06\n",
      "\tEpoch 40/100 - Train loss: 0.4654 - Val accuracy: 0.8507 - Val loss: 0.6695 - Val F1: 0.8446 - LR: 6.00e-06\n",
      "\tEpoch 50/100 - Train loss: 0.5741 - Val accuracy: 0.8507 - Val loss: 0.6648 - Val F1: 0.8483 - LR: 5.00e-06\n",
      "\tEpoch 60/100 - Train loss: 0.4581 - Val accuracy: 0.8657 - Val loss: 0.6184 - Val F1: 0.8656 - LR: 4.00e-06\n",
      "\tEpoch 70/100 - Train loss: 0.6149 - Val accuracy: 0.8806 - Val loss: 0.6056 - Val F1: 0.8796 - LR: 3.00e-06\n",
      "\tEpoch 80/100 - Train loss: 0.4771 - Val accuracy: 0.8806 - Val loss: 0.5857 - Val F1: 0.8796 - LR: 2.00e-06\n",
      "\tEpoch 90/100 - Train loss: 0.6412 - Val accuracy: 0.8806 - Val loss: 0.5933 - Val F1: 0.8796 - LR: 1.00e-06\n",
      "\tEpoch 100/100 - Train loss: 0.4242 - Val accuracy: 0.8806 - Val loss: 0.5596 - Val F1: 0.8796 - LR: 0.00e+00\n",
      "\tBest epoch: 100 - Best val accuracy: 0.8806 - Best val loss: 0.5596 - Best val F1: 0.8796\n",
      "\n",
      "Source class: WAL | Domain: 32 | Accuracy: 0.7115 | Loss: 1.4770 | F1: 0.6595\n",
      "\n",
      "Domain: 33\n",
      "x_syn_dom.shape: (336, 3, 128) | np.unique(y_syn_dom): [1 2 3]\n",
      "x_dp_dom.shape: (44, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Fine-tuning on synthetic data...\n",
      "\tEpoch 10/100 - Train loss: 0.9909 - Val accuracy: 0.7941 - Val loss: 0.6431 - Val F1: 0.7802 - LR: 9.00e-06\n",
      "\tEpoch 20/100 - Train loss: 0.7661 - Val accuracy: 0.8529 - Val loss: 0.4676 - Val F1: 0.8399 - LR: 8.00e-06\n",
      "\tEpoch 30/100 - Train loss: 0.5558 - Val accuracy: 0.8824 - Val loss: 0.3827 - Val F1: 0.8751 - LR: 7.00e-06\n",
      "\tEpoch 40/100 - Train loss: 0.6766 - Val accuracy: 0.8382 - Val loss: 0.3151 - Val F1: 0.8337 - LR: 6.00e-06\n",
      "\tEpoch 50/100 - Train loss: 0.4661 - Val accuracy: 0.8529 - Val loss: 0.2862 - Val F1: 0.8491 - LR: 5.00e-06\n",
      "\tEpoch 60/100 - Train loss: 0.4112 - Val accuracy: 0.8824 - Val loss: 0.2623 - Val F1: 0.8822 - LR: 4.00e-06\n",
      "\tEpoch 70/100 - Train loss: 0.4041 - Val accuracy: 0.8824 - Val loss: 0.2512 - Val F1: 0.8822 - LR: 3.00e-06\n",
      "\tEpoch 80/100 - Train loss: 0.5036 - Val accuracy: 0.8824 - Val loss: 0.2528 - Val F1: 0.8822 - LR: 2.00e-06\n",
      "\tEpoch 90/100 - Train loss: 0.4735 - Val accuracy: 0.8676 - Val loss: 0.2503 - Val F1: 0.8656 - LR: 1.00e-06\n",
      "\tEpoch 100/100 - Train loss: 0.3322 - Val accuracy: 0.8824 - Val loss: 0.2418 - Val F1: 0.8822 - LR: 0.00e+00\n",
      "\tBest epoch: 93 - Best val accuracy: 0.8824 - Best val loss: 0.2367 - Best val F1: 0.8824\n",
      "\n",
      "Source class: WAL | Domain: 33 | Accuracy: 0.8409 | Loss: 0.2735 | F1: 0.8426\n",
      "\n",
      "Domain: 34\n",
      "x_syn_dom.shape: (336, 3, 128) | np.unique(y_syn_dom): [1 2 3]\n",
      "x_dp_dom.shape: (49, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Fine-tuning on synthetic data...\n",
      "\tEpoch 10/100 - Train loss: 0.2504 - Val accuracy: 0.9265 - Val loss: 0.1577 - Val F1: 0.9271 - LR: 9.00e-06\n",
      "\tEpoch 20/100 - Train loss: 0.3043 - Val accuracy: 0.9412 - Val loss: 0.1421 - Val F1: 0.9415 - LR: 8.00e-06\n",
      "\tEpoch 30/100 - Train loss: 0.2545 - Val accuracy: 0.9412 - Val loss: 0.1287 - Val F1: 0.9415 - LR: 7.00e-06\n",
      "\tEpoch 40/100 - Train loss: 0.2541 - Val accuracy: 0.9559 - Val loss: 0.1228 - Val F1: 0.9558 - LR: 6.00e-06\n",
      "\tEpoch 50/100 - Train loss: 0.1815 - Val accuracy: 0.9412 - Val loss: 0.1195 - Val F1: 0.9417 - LR: 5.00e-06\n",
      "\tEpoch 60/100 - Train loss: 0.1900 - Val accuracy: 0.9559 - Val loss: 0.1095 - Val F1: 0.9558 - LR: 4.00e-06\n",
      "\tEpoch 70/100 - Train loss: 0.2869 - Val accuracy: 0.9559 - Val loss: 0.1090 - Val F1: 0.9562 - LR: 3.00e-06\n",
      "\tEpoch 80/100 - Train loss: 0.1678 - Val accuracy: 0.9706 - Val loss: 0.1014 - Val F1: 0.9706 - LR: 2.00e-06\n",
      "\tEpoch 90/100 - Train loss: 0.1539 - Val accuracy: 0.9559 - Val loss: 0.1091 - Val F1: 0.9562 - LR: 1.00e-06\n",
      "\tEpoch 100/100 - Train loss: 0.1734 - Val accuracy: 0.9706 - Val loss: 0.1077 - Val F1: 0.9706 - LR: 0.00e+00\n",
      "\tBest epoch: 92 - Best val accuracy: 0.9706 - Best val loss: 0.0972 - Best val F1: 0.9706\n",
      "\n",
      "Source class: WAL | Domain: 34 | Accuracy: 0.8367 | Loss: 4.4164 | F1: 0.7743\n",
      "\n",
      "Domain: 35\n",
      "x_syn_dom.shape: (333, 3, 128) | np.unique(y_syn_dom): [1 2 3]\n",
      "x_dp_dom.shape: (48, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Fine-tuning on synthetic data...\n",
      "\tEpoch 10/100 - Train loss: 1.1503 - Val accuracy: 0.7612 - Val loss: 1.4877 - Val F1: 0.7248 - LR: 9.00e-06\n",
      "\tEpoch 20/100 - Train loss: 0.8346 - Val accuracy: 0.8060 - Val loss: 0.9998 - Val F1: 0.7975 - LR: 8.00e-06\n",
      "\tEpoch 30/100 - Train loss: 0.6743 - Val accuracy: 0.8060 - Val loss: 0.8640 - Val F1: 0.8034 - LR: 7.00e-06\n",
      "\tEpoch 40/100 - Train loss: 0.6944 - Val accuracy: 0.8060 - Val loss: 0.8163 - Val F1: 0.8034 - LR: 6.00e-06\n",
      "\tEpoch 50/100 - Train loss: 0.7650 - Val accuracy: 0.8060 - Val loss: 0.8067 - Val F1: 0.8034 - LR: 5.00e-06\n",
      "\tEpoch 60/100 - Train loss: 0.4621 - Val accuracy: 0.8060 - Val loss: 0.7513 - Val F1: 0.8034 - LR: 4.00e-06\n",
      "\tEpoch 70/100 - Train loss: 0.5645 - Val accuracy: 0.8060 - Val loss: 0.7491 - Val F1: 0.8034 - LR: 3.00e-06\n",
      "\tEpoch 80/100 - Train loss: 0.4998 - Val accuracy: 0.8209 - Val loss: 0.7323 - Val F1: 0.8194 - LR: 2.00e-06\n",
      "\tEpoch 90/100 - Train loss: 0.5200 - Val accuracy: 0.8060 - Val loss: 0.7288 - Val F1: 0.8034 - LR: 1.00e-06\n",
      "\tEpoch 100/100 - Train loss: 0.7848 - Val accuracy: 0.8209 - Val loss: 0.7148 - Val F1: 0.8205 - LR: 0.00e+00\n",
      "\tBest epoch: 96 - Best val accuracy: 0.8209 - Best val loss: 0.6995 - Best val F1: 0.8205\n",
      "\n",
      "Source class: WAL | Domain: 35 | Accuracy: 0.4792 | Loss: 2.5733 | F1: 0.5204\n",
      "\n",
      "Domain: 36\n",
      "x_syn_dom.shape: (336, 3, 128) | np.unique(y_syn_dom): [1 2 3]\n",
      "x_dp_dom.shape: (43, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Fine-tuning on synthetic data...\n",
      "\tEpoch 10/100 - Train loss: 0.8784 - Val accuracy: 0.7647 - Val loss: 1.0328 - Val F1: 0.7456 - LR: 9.00e-06\n",
      "\tEpoch 20/100 - Train loss: 0.5751 - Val accuracy: 0.7941 - Val loss: 0.7272 - Val F1: 0.7838 - LR: 8.00e-06\n",
      "\tEpoch 30/100 - Train loss: 0.4978 - Val accuracy: 0.8235 - Val loss: 0.5742 - Val F1: 0.8145 - LR: 7.00e-06\n",
      "\tEpoch 40/100 - Train loss: 0.6754 - Val accuracy: 0.8529 - Val loss: 0.4781 - Val F1: 0.8451 - LR: 6.00e-06\n",
      "\tEpoch 50/100 - Train loss: 0.4843 - Val accuracy: 0.8382 - Val loss: 0.5123 - Val F1: 0.8323 - LR: 5.00e-06\n",
      "\tEpoch 60/100 - Train loss: 0.6710 - Val accuracy: 0.8676 - Val loss: 0.4198 - Val F1: 0.8649 - LR: 4.00e-06\n",
      "\tEpoch 70/100 - Train loss: 0.4873 - Val accuracy: 0.8676 - Val loss: 0.3870 - Val F1: 0.8649 - LR: 3.00e-06\n",
      "\tEpoch 80/100 - Train loss: 0.3250 - Val accuracy: 0.8676 - Val loss: 0.4031 - Val F1: 0.8649 - LR: 2.00e-06\n",
      "\tEpoch 90/100 - Train loss: 0.5258 - Val accuracy: 0.8529 - Val loss: 0.4379 - Val F1: 0.8461 - LR: 1.00e-06\n",
      "\tEpoch 100/100 - Train loss: 0.4232 - Val accuracy: 0.8676 - Val loss: 0.3593 - Val F1: 0.8649 - LR: 0.00e+00\n",
      "\tBest epoch: 95 - Best val accuracy: 0.8676 - Best val loss: 0.3498 - Best val F1: 0.8649\n",
      "\n",
      "Source class: WAL | Domain: 36 | Accuracy: 0.5814 | Loss: 1.5640 | F1: 0.6197\n",
      "\n",
      "Domain: 37\n",
      "x_syn_dom.shape: (336, 3, 128) | np.unique(y_syn_dom): [1 2 3]\n",
      "x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Fine-tuning on synthetic data...\n",
      "\tEpoch 10/100 - Train loss: 0.7732 - Val accuracy: 0.7794 - Val loss: 0.9434 - Val F1: 0.7591 - LR: 9.00e-06\n",
      "\tEpoch 20/100 - Train loss: 0.6530 - Val accuracy: 0.8529 - Val loss: 0.5497 - Val F1: 0.8440 - LR: 8.00e-06\n",
      "\tEpoch 30/100 - Train loss: 0.4562 - Val accuracy: 0.8676 - Val loss: 0.4432 - Val F1: 0.8582 - LR: 7.00e-06\n",
      "\tEpoch 40/100 - Train loss: 0.5203 - Val accuracy: 0.8824 - Val loss: 0.3450 - Val F1: 0.8759 - LR: 6.00e-06\n",
      "\tEpoch 50/100 - Train loss: 0.3914 - Val accuracy: 0.8824 - Val loss: 0.3392 - Val F1: 0.8759 - LR: 5.00e-06\n",
      "\tEpoch 60/100 - Train loss: 0.5033 - Val accuracy: 0.8824 - Val loss: 0.3256 - Val F1: 0.8759 - LR: 4.00e-06\n",
      "\tEpoch 70/100 - Train loss: 0.5942 - Val accuracy: 0.8971 - Val loss: 0.3217 - Val F1: 0.8933 - LR: 3.00e-06\n",
      "\tEpoch 80/100 - Train loss: 0.4230 - Val accuracy: 0.9412 - Val loss: 0.2627 - Val F1: 0.9399 - LR: 2.00e-06\n",
      "\tEpoch 90/100 - Train loss: 0.4545 - Val accuracy: 0.9265 - Val loss: 0.2742 - Val F1: 0.9246 - LR: 1.00e-06\n",
      "\tEpoch 100/100 - Train loss: 0.3513 - Val accuracy: 0.8971 - Val loss: 0.2896 - Val F1: 0.8933 - LR: 0.00e+00\n",
      "\tBest epoch: 86 - Best val accuracy: 0.9412 - Best val loss: 0.2503 - Best val F1: 0.9399\n",
      "\n",
      "Source class: WAL | Domain: 37 | Accuracy: 0.9286 | Loss: 0.3342 | F1: 0.9274\n",
      "\n",
      "Domain: 38\n",
      "x_syn_dom.shape: (333, 3, 128) | np.unique(y_syn_dom): [1 2 3]\n",
      "x_dp_dom.shape: (47, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Fine-tuning on synthetic data...\n",
      "\tEpoch 10/100 - Train loss: 0.9262 - Val accuracy: 0.8060 - Val loss: 0.5970 - Val F1: 0.8032 - LR: 9.00e-06\n",
      "\tEpoch 20/100 - Train loss: 0.7038 - Val accuracy: 0.8060 - Val loss: 0.5194 - Val F1: 0.8032 - LR: 8.00e-06\n",
      "\tEpoch 30/100 - Train loss: 0.8283 - Val accuracy: 0.8209 - Val loss: 0.4889 - Val F1: 0.8194 - LR: 7.00e-06\n",
      "\tEpoch 40/100 - Train loss: 0.6519 - Val accuracy: 0.8358 - Val loss: 0.4542 - Val F1: 0.8351 - LR: 6.00e-06\n",
      "\tEpoch 50/100 - Train loss: 0.6769 - Val accuracy: 0.8657 - Val loss: 0.3939 - Val F1: 0.8645 - LR: 5.00e-06\n",
      "\tEpoch 60/100 - Train loss: 0.6971 - Val accuracy: 0.8657 - Val loss: 0.3871 - Val F1: 0.8655 - LR: 4.00e-06\n",
      "\tEpoch 70/100 - Train loss: 0.7128 - Val accuracy: 0.8806 - Val loss: 0.3839 - Val F1: 0.8802 - LR: 3.00e-06\n",
      "\tEpoch 80/100 - Train loss: 0.5011 - Val accuracy: 0.8806 - Val loss: 0.3623 - Val F1: 0.8802 - LR: 2.00e-06\n",
      "\tEpoch 90/100 - Train loss: 0.5916 - Val accuracy: 0.8806 - Val loss: 0.3573 - Val F1: 0.8802 - LR: 1.00e-06\n",
      "\tEpoch 100/100 - Train loss: 0.5321 - Val accuracy: 0.8806 - Val loss: 0.3624 - Val F1: 0.8802 - LR: 0.00e+00\n",
      "\tBest epoch: 96 - Best val accuracy: 0.8806 - Best val loss: 0.3401 - Best val F1: 0.8802\n",
      "\n",
      "Source class: WAL | Domain: 38 | Accuracy: 0.7660 | Loss: 1.6816 | F1: 0.6989\n",
      "\n",
      "Domain: 39\n",
      "x_syn_dom.shape: (333, 3, 128) | np.unique(y_syn_dom): [1 2 3]\n",
      "x_dp_dom.shape: (54, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Fine-tuning on synthetic data...\n",
      "\tEpoch 10/100 - Train loss: 1.0388 - Val accuracy: 0.7164 - Val loss: 0.8998 - Val F1: 0.7059 - LR: 9.00e-06\n",
      "\tEpoch 20/100 - Train loss: 0.6608 - Val accuracy: 0.7164 - Val loss: 0.7430 - Val F1: 0.7096 - LR: 8.00e-06\n",
      "\tEpoch 30/100 - Train loss: 0.6985 - Val accuracy: 0.7313 - Val loss: 0.6938 - Val F1: 0.7262 - LR: 7.00e-06\n",
      "\tEpoch 40/100 - Train loss: 0.5056 - Val accuracy: 0.7463 - Val loss: 0.6574 - Val F1: 0.7451 - LR: 6.00e-06\n",
      "\tEpoch 50/100 - Train loss: 0.4973 - Val accuracy: 0.7463 - Val loss: 0.6306 - Val F1: 0.7451 - LR: 5.00e-06\n",
      "\tEpoch 60/100 - Train loss: 0.5585 - Val accuracy: 0.7612 - Val loss: 0.6044 - Val F1: 0.7592 - LR: 4.00e-06\n",
      "\tEpoch 70/100 - Train loss: 0.6015 - Val accuracy: 0.7612 - Val loss: 0.5878 - Val F1: 0.7592 - LR: 3.00e-06\n",
      "\tEpoch 80/100 - Train loss: 0.4140 - Val accuracy: 0.7761 - Val loss: 0.5767 - Val F1: 0.7751 - LR: 2.00e-06\n",
      "\tEpoch 90/100 - Train loss: 0.5261 - Val accuracy: 0.7612 - Val loss: 0.5719 - Val F1: 0.7592 - LR: 1.00e-06\n",
      "\tEpoch 100/100 - Train loss: 0.5114 - Val accuracy: 0.7612 - Val loss: 0.5755 - Val F1: 0.7592 - LR: 0.00e+00\n",
      "\tBest epoch: 96 - Best val accuracy: 0.7612 - Best val loss: 0.5661 - Best val F1: 0.7592\n",
      "\n",
      "Source class: WAL | Domain: 39 | Accuracy: 0.5185 | Loss: 4.5648 | F1: 0.4208\n",
      "\n",
      "Domain: 40\n",
      "x_syn_dom.shape: (333, 3, 128) | np.unique(y_syn_dom): [1 2 3]\n",
      "x_dp_dom.shape: (44, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Fine-tuning on synthetic data...\n",
      "\tEpoch 10/100 - Train loss: 0.7492 - Val accuracy: 0.7761 - Val loss: 0.6126 - Val F1: 0.7710 - LR: 9.00e-06\n",
      "\tEpoch 20/100 - Train loss: 0.5967 - Val accuracy: 0.7910 - Val loss: 0.4929 - Val F1: 0.7873 - LR: 8.00e-06\n",
      "\tEpoch 30/100 - Train loss: 0.6447 - Val accuracy: 0.8060 - Val loss: 0.4315 - Val F1: 0.8042 - LR: 7.00e-06\n",
      "\tEpoch 40/100 - Train loss: 0.5142 - Val accuracy: 0.8060 - Val loss: 0.3856 - Val F1: 0.8055 - LR: 6.00e-06\n",
      "\tEpoch 50/100 - Train loss: 0.4974 - Val accuracy: 0.8657 - Val loss: 0.3556 - Val F1: 0.8645 - LR: 5.00e-06\n",
      "\tEpoch 60/100 - Train loss: 0.4873 - Val accuracy: 0.8657 - Val loss: 0.3360 - Val F1: 0.8645 - LR: 4.00e-06\n",
      "\tEpoch 70/100 - Train loss: 0.4030 - Val accuracy: 0.8657 - Val loss: 0.3250 - Val F1: 0.8645 - LR: 3.00e-06\n",
      "\tEpoch 80/100 - Train loss: 0.4672 - Val accuracy: 0.8955 - Val loss: 0.3134 - Val F1: 0.8945 - LR: 2.00e-06\n",
      "\tEpoch 90/100 - Train loss: 0.4754 - Val accuracy: 0.8955 - Val loss: 0.3056 - Val F1: 0.8945 - LR: 1.00e-06\n",
      "\tEpoch 100/100 - Train loss: 0.4253 - Val accuracy: 0.8955 - Val loss: 0.3085 - Val F1: 0.8945 - LR: 0.00e+00\n",
      "\tBest epoch: 93 - Best val accuracy: 0.8806 - Best val loss: 0.3032 - Best val F1: 0.8795\n",
      "\n",
      "Source class: WAL | Domain: 40 | Accuracy: 0.6818 | Loss: 1.6744 | F1: 0.7172\n",
      "\n",
      "Domain: 41\n",
      "x_syn_dom.shape: (333, 3, 128) | np.unique(y_syn_dom): [1 2 3]\n",
      "x_dp_dom.shape: (45, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Fine-tuning on synthetic data...\n",
      "\tEpoch 10/100 - Train loss: 0.1355 - Val accuracy: 0.9403 - Val loss: 0.6145 - Val F1: 0.9389 - LR: 9.00e-06\n",
      "\tEpoch 20/100 - Train loss: 0.1132 - Val accuracy: 0.9254 - Val loss: 0.5923 - Val F1: 0.9241 - LR: 8.00e-06\n",
      "\tEpoch 30/100 - Train loss: 0.1141 - Val accuracy: 0.9254 - Val loss: 0.5929 - Val F1: 0.9241 - LR: 7.00e-06\n",
      "\tEpoch 40/100 - Train loss: 0.0836 - Val accuracy: 0.9254 - Val loss: 0.5994 - Val F1: 0.9241 - LR: 6.00e-06\n",
      "\tEpoch 50/100 - Train loss: 0.1979 - Val accuracy: 0.9254 - Val loss: 0.5845 - Val F1: 0.9241 - LR: 5.00e-06\n",
      "\tEpoch 60/100 - Train loss: 0.1105 - Val accuracy: 0.9254 - Val loss: 0.5803 - Val F1: 0.9241 - LR: 4.00e-06\n",
      "\tEpoch 70/100 - Train loss: 0.0789 - Val accuracy: 0.9254 - Val loss: 0.5859 - Val F1: 0.9241 - LR: 3.00e-06\n",
      "\tEpoch 80/100 - Train loss: 0.0718 - Val accuracy: 0.9254 - Val loss: 0.5851 - Val F1: 0.9241 - LR: 2.00e-06\n",
      "\tEpoch 90/100 - Train loss: 0.1305 - Val accuracy: 0.9254 - Val loss: 0.5820 - Val F1: 0.9241 - LR: 1.00e-06\n",
      "\tEpoch 100/100 - Train loss: 0.0929 - Val accuracy: 0.9254 - Val loss: 0.5799 - Val F1: 0.9241 - LR: 0.00e+00\n",
      "\tBest epoch: 1 - Best val accuracy: 0.9552 - Best val loss: 0.5674 - Best val F1: 0.9544\n",
      "\n",
      "Source class: WAL | Domain: 41 | Accuracy: 0.7333 | Loss: 3.8625 | F1: 0.6898\n",
      "\n",
      "Domain: 42\n",
      "x_syn_dom.shape: (336, 3, 128) | np.unique(y_syn_dom): [1 2 3]\n",
      "x_dp_dom.shape: (46, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Fine-tuning on synthetic data...\n",
      "\tEpoch 10/100 - Train loss: 0.3331 - Val accuracy: 0.9118 - Val loss: 0.1912 - Val F1: 0.9107 - LR: 9.00e-06\n",
      "\tEpoch 20/100 - Train loss: 0.2996 - Val accuracy: 0.9412 - Val loss: 0.1726 - Val F1: 0.9412 - LR: 8.00e-06\n",
      "\tEpoch 30/100 - Train loss: 0.3156 - Val accuracy: 0.9412 - Val loss: 0.1537 - Val F1: 0.9412 - LR: 7.00e-06\n",
      "\tEpoch 40/100 - Train loss: 0.2627 - Val accuracy: 0.9412 - Val loss: 0.1405 - Val F1: 0.9412 - LR: 6.00e-06\n",
      "\tEpoch 50/100 - Train loss: 0.2497 - Val accuracy: 0.9412 - Val loss: 0.1339 - Val F1: 0.9412 - LR: 5.00e-06\n",
      "\tEpoch 60/100 - Train loss: 0.1969 - Val accuracy: 0.9412 - Val loss: 0.1288 - Val F1: 0.9412 - LR: 4.00e-06\n",
      "\tEpoch 70/100 - Train loss: 0.1909 - Val accuracy: 0.9412 - Val loss: 0.1230 - Val F1: 0.9412 - LR: 3.00e-06\n",
      "\tEpoch 80/100 - Train loss: 0.2624 - Val accuracy: 0.9412 - Val loss: 0.1251 - Val F1: 0.9412 - LR: 2.00e-06\n",
      "\tEpoch 90/100 - Train loss: 0.2245 - Val accuracy: 0.9559 - Val loss: 0.1275 - Val F1: 0.9559 - LR: 1.00e-06\n",
      "\tEpoch 100/100 - Train loss: 0.1740 - Val accuracy: 0.9412 - Val loss: 0.1199 - Val F1: 0.9412 - LR: 0.00e+00\n",
      "\tBest epoch: 100 - Best val accuracy: 0.9412 - Best val loss: 0.1199 - Best val F1: 0.9412\n",
      "\n",
      "Source class: WAL | Domain: 42 | Accuracy: 0.5652 | Loss: 2.5024 | F1: 0.5978\n",
      "\n",
      "Domain: 43\n",
      "x_syn_dom.shape: (333, 3, 128) | np.unique(y_syn_dom): [1 2 3]\n",
      "x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Fine-tuning on synthetic data...\n",
      "\tEpoch 10/100 - Train loss: 0.4528 - Val accuracy: 0.8955 - Val loss: 0.4000 - Val F1: 0.8945 - LR: 9.00e-06\n",
      "\tEpoch 20/100 - Train loss: 0.2322 - Val accuracy: 0.9104 - Val loss: 0.3758 - Val F1: 0.9104 - LR: 8.00e-06\n",
      "\tEpoch 30/100 - Train loss: 0.3186 - Val accuracy: 0.9104 - Val loss: 0.3592 - Val F1: 0.9104 - LR: 7.00e-06\n",
      "\tEpoch 40/100 - Train loss: 0.4247 - Val accuracy: 0.9104 - Val loss: 0.3308 - Val F1: 0.9104 - LR: 6.00e-06\n",
      "\tEpoch 50/100 - Train loss: 0.1633 - Val accuracy: 0.9104 - Val loss: 0.3240 - Val F1: 0.9104 - LR: 5.00e-06\n",
      "\tEpoch 60/100 - Train loss: 0.2269 - Val accuracy: 0.9254 - Val loss: 0.2846 - Val F1: 0.9253 - LR: 4.00e-06\n",
      "\tEpoch 70/100 - Train loss: 0.2223 - Val accuracy: 0.9403 - Val loss: 0.2783 - Val F1: 0.9402 - LR: 3.00e-06\n",
      "\tEpoch 80/100 - Train loss: 0.1519 - Val accuracy: 0.9254 - Val loss: 0.2767 - Val F1: 0.9253 - LR: 2.00e-06\n",
      "\tEpoch 90/100 - Train loss: 0.1696 - Val accuracy: 0.9403 - Val loss: 0.2568 - Val F1: 0.9402 - LR: 1.00e-06\n",
      "\tEpoch 100/100 - Train loss: 0.2326 - Val accuracy: 0.9104 - Val loss: 0.2792 - Val F1: 0.9104 - LR: 0.00e+00\n",
      "\tBest epoch: 97 - Best val accuracy: 0.9403 - Best val loss: 0.2364 - Best val F1: 0.9402\n",
      "\n",
      "Source class: WAL | Domain: 43 | Accuracy: 0.7381 | Loss: 2.8187 | F1: 0.6745\n",
      "\n",
      "Domain: 44\n",
      "x_syn_dom.shape: (333, 3, 128) | np.unique(y_syn_dom): [1 2 3]\n",
      "x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Fine-tuning on synthetic data...\n",
      "\tEpoch 10/100 - Train loss: 1.5491 - Val accuracy: 0.7164 - Val loss: 1.1842 - Val F1: 0.7155 - LR: 9.00e-06\n",
      "\tEpoch 20/100 - Train loss: 1.1721 - Val accuracy: 0.7015 - Val loss: 1.1230 - Val F1: 0.6987 - LR: 8.00e-06\n",
      "\tEpoch 30/100 - Train loss: 1.0599 - Val accuracy: 0.7015 - Val loss: 1.0288 - Val F1: 0.6984 - LR: 7.00e-06\n",
      "\tEpoch 40/100 - Train loss: 0.7760 - Val accuracy: 0.7164 - Val loss: 0.9670 - Val F1: 0.7133 - LR: 6.00e-06\n",
      "\tEpoch 50/100 - Train loss: 0.8319 - Val accuracy: 0.7313 - Val loss: 0.8639 - Val F1: 0.7313 - LR: 5.00e-06\n",
      "\tEpoch 60/100 - Train loss: 0.7572 - Val accuracy: 0.7015 - Val loss: 0.8912 - Val F1: 0.6984 - LR: 4.00e-06\n",
      "\tEpoch 70/100 - Train loss: 0.7638 - Val accuracy: 0.7015 - Val loss: 0.8623 - Val F1: 0.6984 - LR: 3.00e-06\n",
      "\tEpoch 80/100 - Train loss: 0.8040 - Val accuracy: 0.7015 - Val loss: 0.8218 - Val F1: 0.6984 - LR: 2.00e-06\n",
      "\tEpoch 90/100 - Train loss: 0.7398 - Val accuracy: 0.7313 - Val loss: 0.8147 - Val F1: 0.7313 - LR: 1.00e-06\n",
      "\tEpoch 100/100 - Train loss: 0.6637 - Val accuracy: 0.7164 - Val loss: 0.7892 - Val F1: 0.7163 - LR: 0.00e+00\n",
      "\tBest epoch: 77 - Best val accuracy: 0.7463 - Best val loss: 0.7592 - Best val F1: 0.7461\n",
      "\n",
      "Source class: WAL | Domain: 44 | Accuracy: 0.8333 | Loss: 0.4971 | F1: 0.8415\n",
      "\n",
      "Domain: 45\n",
      "x_syn_dom.shape: (333, 3, 128) | np.unique(y_syn_dom): [1 2 3]\n",
      "x_dp_dom.shape: (52, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Fine-tuning on synthetic data...\n",
      "\tEpoch 10/100 - Train loss: 0.3652 - Val accuracy: 0.8507 - Val loss: 0.3812 - Val F1: 0.8409 - LR: 9.00e-06\n",
      "\tEpoch 20/100 - Train loss: 0.3074 - Val accuracy: 0.8806 - Val loss: 0.2840 - Val F1: 0.8755 - LR: 8.00e-06\n",
      "\tEpoch 30/100 - Train loss: 0.2595 - Val accuracy: 0.9104 - Val loss: 0.2138 - Val F1: 0.9085 - LR: 7.00e-06\n",
      "\tEpoch 40/100 - Train loss: 0.2413 - Val accuracy: 0.9104 - Val loss: 0.2155 - Val F1: 0.9085 - LR: 6.00e-06\n",
      "\tEpoch 50/100 - Train loss: 0.2304 - Val accuracy: 0.9104 - Val loss: 0.1822 - Val F1: 0.9085 - LR: 5.00e-06\n",
      "\tEpoch 60/100 - Train loss: 0.1638 - Val accuracy: 0.9104 - Val loss: 0.1949 - Val F1: 0.9085 - LR: 4.00e-06\n",
      "\tEpoch 70/100 - Train loss: 0.2008 - Val accuracy: 0.9104 - Val loss: 0.1918 - Val F1: 0.9085 - LR: 3.00e-06\n",
      "\tEpoch 80/100 - Train loss: 0.1740 - Val accuracy: 0.9254 - Val loss: 0.1591 - Val F1: 0.9241 - LR: 2.00e-06\n",
      "\tEpoch 90/100 - Train loss: 0.2092 - Val accuracy: 0.9254 - Val loss: 0.1722 - Val F1: 0.9241 - LR: 1.00e-06\n",
      "\tEpoch 100/100 - Train loss: 0.2072 - Val accuracy: 0.9104 - Val loss: 0.1724 - Val F1: 0.9085 - LR: 0.00e+00\n",
      "\tBest epoch: 99 - Best val accuracy: 0.9254 - Best val loss: 0.1576 - Best val F1: 0.9241\n",
      "\n",
      "Source class: WAL | Domain: 45 | Accuracy: 0.7308 | Loss: 0.5656 | F1: 0.7354\n",
      "\n",
      "Domain: 46\n",
      "x_syn_dom.shape: (336, 3, 128) | np.unique(y_syn_dom): [1 2 3]\n",
      "x_dp_dom.shape: (48, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Fine-tuning on synthetic data...\n",
      "\tEpoch 10/100 - Train loss: 0.6381 - Val accuracy: 0.8529 - Val loss: 0.7304 - Val F1: 0.8485 - LR: 9.00e-06\n",
      "\tEpoch 20/100 - Train loss: 0.4643 - Val accuracy: 0.8824 - Val loss: 0.4702 - Val F1: 0.8790 - LR: 8.00e-06\n",
      "\tEpoch 30/100 - Train loss: 0.5410 - Val accuracy: 0.8676 - Val loss: 0.3935 - Val F1: 0.8649 - LR: 7.00e-06\n",
      "\tEpoch 40/100 - Train loss: 0.2926 - Val accuracy: 0.8676 - Val loss: 0.3717 - Val F1: 0.8649 - LR: 6.00e-06\n",
      "\tEpoch 50/100 - Train loss: 0.5478 - Val accuracy: 0.8676 - Val loss: 0.3767 - Val F1: 0.8649 - LR: 5.00e-06\n",
      "\tEpoch 60/100 - Train loss: 0.2739 - Val accuracy: 0.8824 - Val loss: 0.3706 - Val F1: 0.8790 - LR: 4.00e-06\n",
      "\tEpoch 70/100 - Train loss: 0.3268 - Val accuracy: 0.8824 - Val loss: 0.3751 - Val F1: 0.8790 - LR: 3.00e-06\n",
      "\tEpoch 80/100 - Train loss: 0.2867 - Val accuracy: 0.8971 - Val loss: 0.3596 - Val F1: 0.8949 - LR: 2.00e-06\n",
      "\tEpoch 90/100 - Train loss: 0.4059 - Val accuracy: 0.8971 - Val loss: 0.3544 - Val F1: 0.8949 - LR: 1.00e-06\n",
      "\tEpoch 100/100 - Train loss: 0.3253 - Val accuracy: 0.8971 - Val loss: 0.3537 - Val F1: 0.8949 - LR: 0.00e+00\n",
      "\tBest epoch: 99 - Best val accuracy: 0.8971 - Best val loss: 0.3176 - Best val F1: 0.8960\n",
      "\n",
      "Source class: WAL | Domain: 46 | Accuracy: 0.9375 | Loss: 0.1265 | F1: 0.9418\n",
      "\n",
      "Domain: 47\n",
      "x_syn_dom.shape: (333, 3, 128) | np.unique(y_syn_dom): [1 2 3]\n",
      "x_dp_dom.shape: (44, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Fine-tuning on synthetic data...\n",
      "\tEpoch 10/100 - Train loss: 0.7298 - Val accuracy: 0.7313 - Val loss: 0.8406 - Val F1: 0.7071 - LR: 9.00e-06\n",
      "\tEpoch 20/100 - Train loss: 0.5477 - Val accuracy: 0.8358 - Val loss: 0.5642 - Val F1: 0.8343 - LR: 8.00e-06\n",
      "\tEpoch 30/100 - Train loss: 0.4424 - Val accuracy: 0.8806 - Val loss: 0.4466 - Val F1: 0.8772 - LR: 7.00e-06\n",
      "\tEpoch 40/100 - Train loss: 0.4098 - Val accuracy: 0.8806 - Val loss: 0.4048 - Val F1: 0.8775 - LR: 6.00e-06\n",
      "\tEpoch 50/100 - Train loss: 0.5418 - Val accuracy: 0.8955 - Val loss: 0.3940 - Val F1: 0.8918 - LR: 5.00e-06\n",
      "\tEpoch 60/100 - Train loss: 0.4107 - Val accuracy: 0.9104 - Val loss: 0.3649 - Val F1: 0.9079 - LR: 4.00e-06\n",
      "\tEpoch 70/100 - Train loss: 0.4578 - Val accuracy: 0.9104 - Val loss: 0.3527 - Val F1: 0.9079 - LR: 3.00e-06\n",
      "\tEpoch 80/100 - Train loss: 0.3240 - Val accuracy: 0.8955 - Val loss: 0.3536 - Val F1: 0.8918 - LR: 2.00e-06\n",
      "\tEpoch 90/100 - Train loss: 0.3189 - Val accuracy: 0.8955 - Val loss: 0.3741 - Val F1: 0.8941 - LR: 1.00e-06\n",
      "\tEpoch 100/100 - Train loss: 0.2886 - Val accuracy: 0.9104 - Val loss: 0.3610 - Val F1: 0.9085 - LR: 0.00e+00\n",
      "\tBest epoch: 97 - Best val accuracy: 0.9104 - Best val loss: 0.3328 - Best val F1: 0.9079\n",
      "\n",
      "Source class: WAL | Domain: 47 | Accuracy: 0.8864 | Loss: 0.4273 | F1: 0.8850\n",
      "\n",
      "Domain: 48\n",
      "x_syn_dom.shape: (333, 3, 128) | np.unique(y_syn_dom): [1 2 3]\n",
      "x_dp_dom.shape: (48, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Fine-tuning on synthetic data...\n",
      "\tEpoch 10/100 - Train loss: 0.4173 - Val accuracy: 0.8955 - Val loss: 0.6935 - Val F1: 0.8942 - LR: 9.00e-06\n",
      "\tEpoch 20/100 - Train loss: 0.3394 - Val accuracy: 0.8955 - Val loss: 0.6344 - Val F1: 0.8950 - LR: 8.00e-06\n",
      "\tEpoch 30/100 - Train loss: 0.3148 - Val accuracy: 0.8955 - Val loss: 0.6015 - Val F1: 0.8950 - LR: 7.00e-06\n",
      "\tEpoch 40/100 - Train loss: 0.3499 - Val accuracy: 0.8955 - Val loss: 0.5770 - Val F1: 0.8950 - LR: 6.00e-06\n",
      "\tEpoch 50/100 - Train loss: 0.3586 - Val accuracy: 0.8955 - Val loss: 0.5690 - Val F1: 0.8950 - LR: 5.00e-06\n",
      "\tEpoch 60/100 - Train loss: 0.2527 - Val accuracy: 0.9104 - Val loss: 0.5556 - Val F1: 0.9103 - LR: 4.00e-06\n",
      "\tEpoch 70/100 - Train loss: 0.3104 - Val accuracy: 0.9104 - Val loss: 0.5417 - Val F1: 0.9103 - LR: 3.00e-06\n",
      "\tEpoch 80/100 - Train loss: 0.2285 - Val accuracy: 0.9104 - Val loss: 0.5231 - Val F1: 0.9103 - LR: 2.00e-06\n",
      "\tEpoch 90/100 - Train loss: 0.2145 - Val accuracy: 0.9104 - Val loss: 0.5282 - Val F1: 0.9103 - LR: 1.00e-06\n",
      "\tEpoch 100/100 - Train loss: 0.2321 - Val accuracy: 0.8955 - Val loss: 0.5372 - Val F1: 0.8950 - LR: 0.00e+00\n",
      "\tBest epoch: 77 - Best val accuracy: 0.9104 - Best val loss: 0.5186 - Best val F1: 0.9103\n",
      "\n",
      "Source class: WAL | Domain: 48 | Accuracy: 0.8333 | Loss: 1.1707 | F1: 0.7899\n",
      "\n",
      "Domain: 49\n",
      "x_syn_dom.shape: (333, 3, 128) | np.unique(y_syn_dom): [1 2 3]\n",
      "x_dp_dom.shape: (53, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Fine-tuning on synthetic data...\n",
      "\tEpoch 10/100 - Train loss: 0.6015 - Val accuracy: 0.7463 - Val loss: 0.6879 - Val F1: 0.7243 - LR: 9.00e-06\n",
      "\tEpoch 20/100 - Train loss: 0.4634 - Val accuracy: 0.8209 - Val loss: 0.3985 - Val F1: 0.8117 - LR: 8.00e-06\n",
      "\tEpoch 30/100 - Train loss: 0.4117 - Val accuracy: 0.9254 - Val loss: 0.2893 - Val F1: 0.9238 - LR: 7.00e-06\n",
      "\tEpoch 40/100 - Train loss: 0.2104 - Val accuracy: 0.9254 - Val loss: 0.2480 - Val F1: 0.9238 - LR: 6.00e-06\n",
      "\tEpoch 50/100 - Train loss: 0.3373 - Val accuracy: 0.9254 - Val loss: 0.1990 - Val F1: 0.9250 - LR: 5.00e-06\n",
      "\tEpoch 60/100 - Train loss: 0.4134 - Val accuracy: 0.9254 - Val loss: 0.1810 - Val F1: 0.9250 - LR: 4.00e-06\n",
      "\tEpoch 70/100 - Train loss: 0.3276 - Val accuracy: 0.9254 - Val loss: 0.1672 - Val F1: 0.9250 - LR: 3.00e-06\n",
      "\tEpoch 80/100 - Train loss: 0.2615 - Val accuracy: 0.9254 - Val loss: 0.1565 - Val F1: 0.9250 - LR: 2.00e-06\n",
      "\tEpoch 90/100 - Train loss: 0.2344 - Val accuracy: 0.9254 - Val loss: 0.1530 - Val F1: 0.9250 - LR: 1.00e-06\n",
      "\tEpoch 100/100 - Train loss: 0.2479 - Val accuracy: 0.9403 - Val loss: 0.1476 - Val F1: 0.9403 - LR: 0.00e+00\n",
      "\tBest epoch: 100 - Best val accuracy: 0.9403 - Best val loss: 0.1476 - Best val F1: 0.9403\n",
      "\n",
      "Source class: WAL | Domain: 49 | Accuracy: 0.5660 | Loss: 1.8539 | F1: 0.5581\n",
      "\n",
      "Domain: 50\n",
      "x_syn_dom.shape: (333, 3, 128) | np.unique(y_syn_dom): [1 2 3]\n",
      "x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Fine-tuning on synthetic data...\n",
      "\tEpoch 10/100 - Train loss: 1.1593 - Val accuracy: 0.7164 - Val loss: 0.8918 - Val F1: 0.6952 - LR: 9.00e-06\n",
      "\tEpoch 20/100 - Train loss: 0.9795 - Val accuracy: 0.7612 - Val loss: 0.5911 - Val F1: 0.7456 - LR: 8.00e-06\n",
      "\tEpoch 30/100 - Train loss: 0.8270 - Val accuracy: 0.8209 - Val loss: 0.4170 - Val F1: 0.8049 - LR: 7.00e-06\n",
      "\tEpoch 40/100 - Train loss: 0.5967 - Val accuracy: 0.8209 - Val loss: 0.3303 - Val F1: 0.8039 - LR: 6.00e-06\n",
      "\tEpoch 50/100 - Train loss: 0.5695 - Val accuracy: 0.9104 - Val loss: 0.2741 - Val F1: 0.9062 - LR: 5.00e-06\n",
      "\tEpoch 60/100 - Train loss: 0.9459 - Val accuracy: 0.9104 - Val loss: 0.2931 - Val F1: 0.9088 - LR: 4.00e-06\n",
      "\tEpoch 70/100 - Train loss: 0.4684 - Val accuracy: 0.9701 - Val loss: 0.2151 - Val F1: 0.9701 - LR: 3.00e-06\n",
      "\tEpoch 80/100 - Train loss: 0.6051 - Val accuracy: 0.9701 - Val loss: 0.2089 - Val F1: 0.9701 - LR: 2.00e-06\n",
      "\tEpoch 90/100 - Train loss: 0.4157 - Val accuracy: 0.9701 - Val loss: 0.2121 - Val F1: 0.9701 - LR: 1.00e-06\n",
      "\tEpoch 100/100 - Train loss: 0.2363 - Val accuracy: 0.9701 - Val loss: 0.2006 - Val F1: 0.9701 - LR: 0.00e+00\n",
      "\tBest epoch: 92 - Best val accuracy: 0.9701 - Best val loss: 0.1996 - Best val F1: 0.9701\n",
      "\n",
      "Source class: WAL | Domain: 50 | Accuracy: 0.6905 | Loss: 2.1465 | F1: 0.6503\n",
      "\n",
      "Domain: 51\n",
      "x_syn_dom.shape: (333, 3, 128) | np.unique(y_syn_dom): [1 2 3]\n",
      "x_dp_dom.shape: (46, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Fine-tuning on synthetic data...\n",
      "\tEpoch 10/100 - Train loss: 1.1090 - Val accuracy: 0.8507 - Val loss: 0.3781 - Val F1: 0.8439 - LR: 9.00e-06\n",
      "\tEpoch 20/100 - Train loss: 0.8683 - Val accuracy: 0.9104 - Val loss: 0.2588 - Val F1: 0.9093 - LR: 8.00e-06\n",
      "\tEpoch 30/100 - Train loss: 0.7085 - Val accuracy: 0.9254 - Val loss: 0.2113 - Val F1: 0.9250 - LR: 7.00e-06\n",
      "\tEpoch 40/100 - Train loss: 0.7987 - Val accuracy: 0.9254 - Val loss: 0.1843 - Val F1: 0.9250 - LR: 6.00e-06\n",
      "\tEpoch 50/100 - Train loss: 0.5294 - Val accuracy: 0.9403 - Val loss: 0.1648 - Val F1: 0.9403 - LR: 5.00e-06\n",
      "\tEpoch 60/100 - Train loss: 0.6227 - Val accuracy: 0.9254 - Val loss: 0.1511 - Val F1: 0.9250 - LR: 4.00e-06\n",
      "\tEpoch 70/100 - Train loss: 0.7117 - Val accuracy: 0.9403 - Val loss: 0.1378 - Val F1: 0.9403 - LR: 3.00e-06\n",
      "\tEpoch 80/100 - Train loss: 0.5675 - Val accuracy: 0.9552 - Val loss: 0.1495 - Val F1: 0.9556 - LR: 2.00e-06\n",
      "\tEpoch 90/100 - Train loss: 0.5092 - Val accuracy: 0.9552 - Val loss: 0.1370 - Val F1: 0.9556 - LR: 1.00e-06\n",
      "\tEpoch 100/100 - Train loss: 0.5452 - Val accuracy: 0.9552 - Val loss: 0.1388 - Val F1: 0.9556 - LR: 0.00e+00\n",
      "\tBest epoch: 98 - Best val accuracy: 0.9552 - Best val loss: 0.1282 - Best val F1: 0.9556\n",
      "\n",
      "Source class: WAL | Domain: 51 | Accuracy: 0.7174 | Loss: 3.4675 | F1: 0.6532\n",
      "\n",
      "Domain: 52\n",
      "x_syn_dom.shape: (333, 3, 128) | np.unique(y_syn_dom): [1 2 3]\n",
      "x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Fine-tuning on synthetic data...\n",
      "\tEpoch 10/100 - Train loss: 0.8641 - Val accuracy: 0.7612 - Val loss: 0.6206 - Val F1: 0.7380 - LR: 9.00e-06\n",
      "\tEpoch 20/100 - Train loss: 0.5553 - Val accuracy: 0.8358 - Val loss: 0.3334 - Val F1: 0.8290 - LR: 8.00e-06\n",
      "\tEpoch 30/100 - Train loss: 0.4732 - Val accuracy: 0.8806 - Val loss: 0.2833 - Val F1: 0.8782 - LR: 7.00e-06\n",
      "\tEpoch 40/100 - Train loss: 0.3418 - Val accuracy: 0.9104 - Val loss: 0.1862 - Val F1: 0.9097 - LR: 6.00e-06\n",
      "\tEpoch 50/100 - Train loss: 0.7019 - Val accuracy: 0.8955 - Val loss: 0.2400 - Val F1: 0.8928 - LR: 5.00e-06\n",
      "\tEpoch 60/100 - Train loss: 0.2815 - Val accuracy: 0.9254 - Val loss: 0.1536 - Val F1: 0.9250 - LR: 4.00e-06\n",
      "\tEpoch 70/100 - Train loss: 0.3563 - Val accuracy: 0.9254 - Val loss: 0.1378 - Val F1: 0.9250 - LR: 3.00e-06\n",
      "\tEpoch 80/100 - Train loss: 0.6861 - Val accuracy: 0.8955 - Val loss: 0.1993 - Val F1: 0.8942 - LR: 2.00e-06\n",
      "\tEpoch 90/100 - Train loss: 0.3038 - Val accuracy: 0.9254 - Val loss: 0.1378 - Val F1: 0.9250 - LR: 1.00e-06\n",
      "\tEpoch 100/100 - Train loss: 0.4400 - Val accuracy: 0.9254 - Val loss: 0.1314 - Val F1: 0.9250 - LR: 0.00e+00\n",
      "\tBest epoch: 94 - Best val accuracy: 0.9403 - Best val loss: 0.1125 - Best val F1: 0.9403\n",
      "\n",
      "Source class: WAL | Domain: 52 | Accuracy: 0.9286 | Loss: 0.1023 | F1: 0.9251\n",
      "\n",
      "Domain: 53\n",
      "x_syn_dom.shape: (333, 3, 128) | np.unique(y_syn_dom): [1 2 3]\n",
      "x_dp_dom.shape: (48, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Fine-tuning on synthetic data...\n",
      "\tEpoch 10/100 - Train loss: 0.5762 - Val accuracy: 0.8806 - Val loss: 0.3931 - Val F1: 0.8767 - LR: 9.00e-06\n",
      "\tEpoch 20/100 - Train loss: 0.4120 - Val accuracy: 0.9104 - Val loss: 0.2858 - Val F1: 0.9085 - LR: 8.00e-06\n",
      "\tEpoch 30/100 - Train loss: 0.4128 - Val accuracy: 0.9104 - Val loss: 0.2641 - Val F1: 0.9073 - LR: 7.00e-06\n",
      "\tEpoch 40/100 - Train loss: 0.4155 - Val accuracy: 0.9254 - Val loss: 0.2215 - Val F1: 0.9241 - LR: 6.00e-06\n",
      "\tEpoch 50/100 - Train loss: 0.3050 - Val accuracy: 0.9403 - Val loss: 0.2000 - Val F1: 0.9389 - LR: 5.00e-06\n",
      "\tEpoch 60/100 - Train loss: 0.2724 - Val accuracy: 0.9403 - Val loss: 0.1654 - Val F1: 0.9389 - LR: 4.00e-06\n",
      "\tEpoch 70/100 - Train loss: 0.2913 - Val accuracy: 0.9403 - Val loss: 0.1731 - Val F1: 0.9389 - LR: 3.00e-06\n",
      "\tEpoch 80/100 - Train loss: 0.2238 - Val accuracy: 0.9403 - Val loss: 0.1744 - Val F1: 0.9389 - LR: 2.00e-06\n",
      "\tEpoch 90/100 - Train loss: 0.2582 - Val accuracy: 0.9403 - Val loss: 0.1698 - Val F1: 0.9389 - LR: 1.00e-06\n",
      "\tEpoch 100/100 - Train loss: 0.3115 - Val accuracy: 0.9403 - Val loss: 0.1488 - Val F1: 0.9389 - LR: 0.00e+00\n",
      "\tBest epoch: 96 - Best val accuracy: 0.9403 - Best val loss: 0.1452 - Best val F1: 0.9389\n",
      "\n",
      "Source class: WAL | Domain: 53 | Accuracy: 0.6250 | Loss: 4.6802 | F1: 0.5129\n",
      "\n",
      "Domain: 54\n",
      "x_syn_dom.shape: (333, 3, 128) | np.unique(y_syn_dom): [1 2 3]\n",
      "x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Fine-tuning on synthetic data...\n",
      "\tEpoch 10/100 - Train loss: 0.3247 - Val accuracy: 0.8657 - Val loss: 0.5987 - Val F1: 0.8620 - LR: 9.00e-06\n",
      "\tEpoch 20/100 - Train loss: 0.4514 - Val accuracy: 0.8806 - Val loss: 0.4289 - Val F1: 0.8782 - LR: 8.00e-06\n",
      "\tEpoch 30/100 - Train loss: 0.5182 - Val accuracy: 0.8806 - Val loss: 0.3607 - Val F1: 0.8798 - LR: 7.00e-06\n",
      "\tEpoch 40/100 - Train loss: 0.3558 - Val accuracy: 0.8806 - Val loss: 0.3388 - Val F1: 0.8798 - LR: 6.00e-06\n",
      "\tEpoch 50/100 - Train loss: 0.2746 - Val accuracy: 0.8955 - Val loss: 0.3454 - Val F1: 0.8942 - LR: 5.00e-06\n",
      "\tEpoch 60/100 - Train loss: 0.2260 - Val accuracy: 0.9104 - Val loss: 0.3639 - Val F1: 0.9088 - LR: 4.00e-06\n",
      "\tEpoch 70/100 - Train loss: 0.1938 - Val accuracy: 0.8955 - Val loss: 0.3326 - Val F1: 0.8942 - LR: 3.00e-06\n",
      "\tEpoch 80/100 - Train loss: 0.3063 - Val accuracy: 0.8955 - Val loss: 0.3191 - Val F1: 0.8942 - LR: 2.00e-06\n",
      "\tEpoch 90/100 - Train loss: 0.3901 - Val accuracy: 0.8955 - Val loss: 0.3364 - Val F1: 0.8942 - LR: 1.00e-06\n",
      "\tEpoch 100/100 - Train loss: 0.2355 - Val accuracy: 0.8955 - Val loss: 0.3107 - Val F1: 0.8942 - LR: 0.00e+00\n",
      "\tBest epoch: 85 - Best val accuracy: 0.9104 - Best val loss: 0.3055 - Best val F1: 0.9097\n",
      "\n",
      "Source class: WAL | Domain: 54 | Accuracy: 0.9286 | Loss: 0.5671 | F1: 0.9251\n",
      "\n",
      "Domain: 55\n",
      "x_syn_dom.shape: (333, 3, 128) | np.unique(y_syn_dom): [1 2 3]\n",
      "x_dp_dom.shape: (49, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Fine-tuning on synthetic data...\n",
      "\tEpoch 10/100 - Train loss: 0.7892 - Val accuracy: 0.8806 - Val loss: 0.4326 - Val F1: 0.8779 - LR: 9.00e-06\n",
      "\tEpoch 20/100 - Train loss: 0.3829 - Val accuracy: 0.9254 - Val loss: 0.2178 - Val F1: 0.9256 - LR: 8.00e-06\n",
      "\tEpoch 30/100 - Train loss: 0.2649 - Val accuracy: 0.9254 - Val loss: 0.1649 - Val F1: 0.9256 - LR: 7.00e-06\n",
      "\tEpoch 40/100 - Train loss: 0.2818 - Val accuracy: 0.9403 - Val loss: 0.1298 - Val F1: 0.9406 - LR: 6.00e-06\n",
      "\tEpoch 50/100 - Train loss: 0.2847 - Val accuracy: 0.9552 - Val loss: 0.1063 - Val F1: 0.9552 - LR: 5.00e-06\n",
      "\tEpoch 60/100 - Train loss: 0.5067 - Val accuracy: 0.9403 - Val loss: 0.1146 - Val F1: 0.9402 - LR: 4.00e-06\n",
      "\tEpoch 70/100 - Train loss: 0.2563 - Val accuracy: 0.9552 - Val loss: 0.0968 - Val F1: 0.9552 - LR: 3.00e-06\n",
      "\tEpoch 80/100 - Train loss: 0.2860 - Val accuracy: 0.9552 - Val loss: 0.1000 - Val F1: 0.9552 - LR: 2.00e-06\n",
      "\tEpoch 90/100 - Train loss: 0.4047 - Val accuracy: 0.9552 - Val loss: 0.0931 - Val F1: 0.9552 - LR: 1.00e-06\n",
      "\tEpoch 100/100 - Train loss: 0.2094 - Val accuracy: 0.9552 - Val loss: 0.0985 - Val F1: 0.9552 - LR: 0.00e+00\n",
      "\tBest epoch: 89 - Best val accuracy: 0.9552 - Best val loss: 0.0902 - Best val F1: 0.9552\n",
      "\n",
      "Source class: WAL | Domain: 55 | Accuracy: 0.9592 | Loss: 0.0618 | F1: 0.9594\n",
      "\n",
      "Domain: 56\n",
      "x_syn_dom.shape: (333, 3, 128) | np.unique(y_syn_dom): [1 2 3]\n",
      "x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Fine-tuning on synthetic data...\n",
      "\tEpoch 10/100 - Train loss: 0.8014 - Val accuracy: 0.8060 - Val loss: 0.7457 - Val F1: 0.8066 - LR: 9.00e-06\n",
      "\tEpoch 20/100 - Train loss: 0.8531 - Val accuracy: 0.8209 - Val loss: 0.6416 - Val F1: 0.8204 - LR: 8.00e-06\n",
      "\tEpoch 30/100 - Train loss: 0.6921 - Val accuracy: 0.8358 - Val loss: 0.5738 - Val F1: 0.8371 - LR: 7.00e-06\n",
      "\tEpoch 40/100 - Train loss: 0.7724 - Val accuracy: 0.8358 - Val loss: 0.5336 - Val F1: 0.8354 - LR: 6.00e-06\n",
      "\tEpoch 50/100 - Train loss: 0.5550 - Val accuracy: 0.8358 - Val loss: 0.4958 - Val F1: 0.8354 - LR: 5.00e-06\n",
      "\tEpoch 60/100 - Train loss: 0.4841 - Val accuracy: 0.8507 - Val loss: 0.4776 - Val F1: 0.8498 - LR: 4.00e-06\n",
      "\tEpoch 70/100 - Train loss: 0.5490 - Val accuracy: 0.8657 - Val loss: 0.4642 - Val F1: 0.8641 - LR: 3.00e-06\n",
      "\tEpoch 80/100 - Train loss: 0.4833 - Val accuracy: 0.8657 - Val loss: 0.4422 - Val F1: 0.8653 - LR: 2.00e-06\n",
      "\tEpoch 90/100 - Train loss: 0.5129 - Val accuracy: 0.8657 - Val loss: 0.4580 - Val F1: 0.8641 - LR: 1.00e-06\n",
      "\tEpoch 100/100 - Train loss: 0.5719 - Val accuracy: 0.8806 - Val loss: 0.4189 - Val F1: 0.8791 - LR: 0.00e+00\n",
      "\tBest epoch: 100 - Best val accuracy: 0.8806 - Best val loss: 0.4189 - Best val F1: 0.8791\n",
      "\n",
      "Source class: WAL | Domain: 56 | Accuracy: 0.9286 | Loss: 0.2753 | F1: 0.9307\n",
      "\n",
      "Domain: 57\n",
      "x_syn_dom.shape: (333, 3, 128) | np.unique(y_syn_dom): [1 2 3]\n",
      "x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Fine-tuning on synthetic data...\n",
      "\tEpoch 10/100 - Train loss: 0.9526 - Val accuracy: 0.7015 - Val loss: 0.7749 - Val F1: 0.6788 - LR: 9.00e-06\n",
      "\tEpoch 20/100 - Train loss: 0.7500 - Val accuracy: 0.8657 - Val loss: 0.4588 - Val F1: 0.8624 - LR: 8.00e-06\n",
      "\tEpoch 30/100 - Train loss: 0.8033 - Val accuracy: 0.8657 - Val loss: 0.3199 - Val F1: 0.8628 - LR: 7.00e-06\n",
      "\tEpoch 40/100 - Train loss: 0.3733 - Val accuracy: 0.8955 - Val loss: 0.2729 - Val F1: 0.8941 - LR: 6.00e-06\n",
      "\tEpoch 50/100 - Train loss: 0.3687 - Val accuracy: 0.8955 - Val loss: 0.2374 - Val F1: 0.8941 - LR: 5.00e-06\n",
      "\tEpoch 60/100 - Train loss: 0.6147 - Val accuracy: 0.9254 - Val loss: 0.2313 - Val F1: 0.9250 - LR: 4.00e-06\n",
      "\tEpoch 70/100 - Train loss: 0.3170 - Val accuracy: 0.9552 - Val loss: 0.2074 - Val F1: 0.9552 - LR: 3.00e-06\n",
      "\tEpoch 80/100 - Train loss: 0.4266 - Val accuracy: 0.9254 - Val loss: 0.2124 - Val F1: 0.9250 - LR: 2.00e-06\n",
      "\tEpoch 90/100 - Train loss: 0.5109 - Val accuracy: 0.9552 - Val loss: 0.1985 - Val F1: 0.9552 - LR: 1.00e-06\n",
      "\tEpoch 100/100 - Train loss: 0.3136 - Val accuracy: 0.9403 - Val loss: 0.1991 - Val F1: 0.9402 - LR: 0.00e+00\n",
      "\tBest epoch: 86 - Best val accuracy: 0.9552 - Best val loss: 0.1966 - Best val F1: 0.9552\n",
      "\n",
      "Source class: WAL | Domain: 57 | Accuracy: 0.7619 | Loss: 2.0808 | F1: 0.7222\n",
      "\n",
      "Domain: 58\n",
      "x_syn_dom.shape: (333, 3, 128) | np.unique(y_syn_dom): [1 2 3]\n",
      "x_dp_dom.shape: (38, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Fine-tuning on synthetic data...\n",
      "\tEpoch 10/100 - Train loss: 0.8853 - Val accuracy: 0.7761 - Val loss: 1.1274 - Val F1: 0.7751 - LR: 9.00e-06\n",
      "\tEpoch 20/100 - Train loss: 0.7784 - Val accuracy: 0.7910 - Val loss: 1.0536 - Val F1: 0.7906 - LR: 8.00e-06\n",
      "\tEpoch 30/100 - Train loss: 0.6707 - Val accuracy: 0.7761 - Val loss: 0.9657 - Val F1: 0.7751 - LR: 7.00e-06\n",
      "\tEpoch 40/100 - Train loss: 0.6339 - Val accuracy: 0.7761 - Val loss: 0.9555 - Val F1: 0.7751 - LR: 6.00e-06\n",
      "\tEpoch 50/100 - Train loss: 0.5359 - Val accuracy: 0.7761 - Val loss: 0.9046 - Val F1: 0.7751 - LR: 5.00e-06\n",
      "\tEpoch 60/100 - Train loss: 0.5782 - Val accuracy: 0.7761 - Val loss: 0.8724 - Val F1: 0.7751 - LR: 4.00e-06\n",
      "\tEpoch 70/100 - Train loss: 0.5402 - Val accuracy: 0.7761 - Val loss: 0.8399 - Val F1: 0.7751 - LR: 3.00e-06\n",
      "\tEpoch 80/100 - Train loss: 0.5656 - Val accuracy: 0.7761 - Val loss: 0.8617 - Val F1: 0.7751 - LR: 2.00e-06\n",
      "\tEpoch 90/100 - Train loss: 0.5172 - Val accuracy: 0.7761 - Val loss: 0.8405 - Val F1: 0.7751 - LR: 1.00e-06\n",
      "\tEpoch 100/100 - Train loss: 0.5025 - Val accuracy: 0.7761 - Val loss: 0.8187 - Val F1: 0.7751 - LR: 0.00e+00\n",
      "\tBest epoch: 87 - Best val accuracy: 0.7612 - Best val loss: 0.8183 - Best val F1: 0.7612\n",
      "\n",
      "Source class: WAL | Domain: 58 | Accuracy: 0.7105 | Loss: 2.9774 | F1: 0.6217\n",
      "\n",
      "Domain: 59\n",
      "x_syn_dom.shape: (333, 3, 128) | np.unique(y_syn_dom): [1 2 3]\n",
      "x_dp_dom.shape: (43, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Fine-tuning on synthetic data...\n",
      "\tEpoch 10/100 - Train loss: 1.5075 - Val accuracy: 0.6567 - Val loss: 1.2320 - Val F1: 0.6072 - LR: 9.00e-06\n",
      "\tEpoch 20/100 - Train loss: 1.3165 - Val accuracy: 0.6866 - Val loss: 0.8822 - Val F1: 0.6524 - LR: 8.00e-06\n",
      "\tEpoch 30/100 - Train loss: 0.9318 - Val accuracy: 0.7164 - Val loss: 0.6762 - Val F1: 0.6939 - LR: 7.00e-06\n",
      "\tEpoch 40/100 - Train loss: 0.7863 - Val accuracy: 0.7313 - Val loss: 0.6024 - Val F1: 0.7074 - LR: 6.00e-06\n",
      "\tEpoch 50/100 - Train loss: 0.8756 - Val accuracy: 0.7612 - Val loss: 0.4849 - Val F1: 0.7392 - LR: 5.00e-06\n",
      "\tEpoch 60/100 - Train loss: 0.7281 - Val accuracy: 0.8060 - Val loss: 0.5119 - Val F1: 0.7882 - LR: 4.00e-06\n",
      "\tEpoch 70/100 - Train loss: 0.5537 - Val accuracy: 0.8060 - Val loss: 0.4441 - Val F1: 0.7929 - LR: 3.00e-06\n",
      "\tEpoch 80/100 - Train loss: 0.6492 - Val accuracy: 0.8358 - Val loss: 0.4317 - Val F1: 0.8264 - LR: 2.00e-06\n",
      "\tEpoch 90/100 - Train loss: 0.5207 - Val accuracy: 0.7910 - Val loss: 0.3870 - Val F1: 0.7792 - LR: 1.00e-06\n",
      "\tEpoch 100/100 - Train loss: 0.5271 - Val accuracy: 0.8358 - Val loss: 0.4043 - Val F1: 0.8264 - LR: 0.00e+00\n",
      "\tBest epoch: 99 - Best val accuracy: 0.8507 - Best val loss: 0.3593 - Best val F1: 0.8465\n",
      "\n",
      "Source class: WAL | Domain: 59 | Accuracy: 0.9302 | Loss: 0.1142 | F1: 0.9283\n",
      "\n",
      "Domain: 60\n",
      "x_syn_dom.shape: (333, 3, 128) | np.unique(y_syn_dom): [1 2 3]\n",
      "x_dp_dom.shape: (47, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Fine-tuning on synthetic data...\n",
      "\tEpoch 10/100 - Train loss: 0.5278 - Val accuracy: 0.8657 - Val loss: 0.4707 - Val F1: 0.8633 - LR: 9.00e-06\n",
      "\tEpoch 20/100 - Train loss: 0.4262 - Val accuracy: 0.9254 - Val loss: 0.4252 - Val F1: 0.9249 - LR: 8.00e-06\n",
      "\tEpoch 30/100 - Train loss: 0.3230 - Val accuracy: 0.9403 - Val loss: 0.3963 - Val F1: 0.9399 - LR: 7.00e-06\n",
      "\tEpoch 40/100 - Train loss: 0.2444 - Val accuracy: 0.9403 - Val loss: 0.3690 - Val F1: 0.9399 - LR: 6.00e-06\n",
      "\tEpoch 50/100 - Train loss: 0.2481 - Val accuracy: 0.9403 - Val loss: 0.3492 - Val F1: 0.9399 - LR: 5.00e-06\n",
      "\tEpoch 60/100 - Train loss: 0.3541 - Val accuracy: 0.9403 - Val loss: 0.3541 - Val F1: 0.9399 - LR: 4.00e-06\n",
      "\tEpoch 70/100 - Train loss: 0.2866 - Val accuracy: 0.9552 - Val loss: 0.3289 - Val F1: 0.9549 - LR: 3.00e-06\n",
      "\tEpoch 80/100 - Train loss: 0.2383 - Val accuracy: 0.9552 - Val loss: 0.3343 - Val F1: 0.9549 - LR: 2.00e-06\n",
      "\tEpoch 90/100 - Train loss: 0.2626 - Val accuracy: 0.9552 - Val loss: 0.3280 - Val F1: 0.9549 - LR: 1.00e-06\n",
      "\tEpoch 100/100 - Train loss: 0.2135 - Val accuracy: 0.9701 - Val loss: 0.3221 - Val F1: 0.9698 - LR: 0.00e+00\n",
      "\tBest epoch: 78 - Best val accuracy: 0.9701 - Best val loss: 0.3190 - Best val F1: 0.9698\n",
      "\n",
      "Source class: WAL | Domain: 60 | Accuracy: 0.5532 | Loss: 4.9620 | F1: 0.5873\n",
      "\n",
      "Domain: 61\n",
      "x_syn_dom.shape: (333, 3, 128) | np.unique(y_syn_dom): [1 2 3]\n",
      "x_dp_dom.shape: (47, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Fine-tuning on synthetic data...\n",
      "\tEpoch 10/100 - Train loss: 0.9375 - Val accuracy: 0.8209 - Val loss: 0.5642 - Val F1: 0.8121 - LR: 9.00e-06\n",
      "\tEpoch 20/100 - Train loss: 0.6690 - Val accuracy: 0.8507 - Val loss: 0.3869 - Val F1: 0.8488 - LR: 8.00e-06\n",
      "\tEpoch 30/100 - Train loss: 0.6427 - Val accuracy: 0.8806 - Val loss: 0.3180 - Val F1: 0.8816 - LR: 7.00e-06\n",
      "\tEpoch 40/100 - Train loss: 0.4405 - Val accuracy: 0.8657 - Val loss: 0.2848 - Val F1: 0.8670 - LR: 6.00e-06\n",
      "\tEpoch 50/100 - Train loss: 0.4775 - Val accuracy: 0.8806 - Val loss: 0.2802 - Val F1: 0.8816 - LR: 5.00e-06\n",
      "\tEpoch 60/100 - Train loss: 0.5570 - Val accuracy: 0.8806 - Val loss: 0.2455 - Val F1: 0.8818 - LR: 4.00e-06\n",
      "\tEpoch 70/100 - Train loss: 0.4415 - Val accuracy: 0.8806 - Val loss: 0.2348 - Val F1: 0.8818 - LR: 3.00e-06\n",
      "\tEpoch 80/100 - Train loss: 0.4098 - Val accuracy: 0.8806 - Val loss: 0.2351 - Val F1: 0.8818 - LR: 2.00e-06\n",
      "\tEpoch 90/100 - Train loss: 0.3576 - Val accuracy: 0.8657 - Val loss: 0.2346 - Val F1: 0.8670 - LR: 1.00e-06\n",
      "\tEpoch 100/100 - Train loss: 0.3023 - Val accuracy: 0.8806 - Val loss: 0.2268 - Val F1: 0.8818 - LR: 0.00e+00\n",
      "\tBest epoch: 94 - Best val accuracy: 0.8806 - Best val loss: 0.2253 - Best val F1: 0.8818\n",
      "\n",
      "Source class: WAL | Domain: 61 | Accuracy: 0.7872 | Loss: 1.3363 | F1: 0.7834\n",
      "\n",
      "Domain: 62\n",
      "x_syn_dom.shape: (333, 3, 128) | np.unique(y_syn_dom): [1 2 3]\n",
      "x_dp_dom.shape: (47, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Fine-tuning on synthetic data...\n",
      "\tEpoch 10/100 - Train loss: 0.5985 - Val accuracy: 0.8209 - Val loss: 0.5511 - Val F1: 0.8131 - LR: 9.00e-06\n",
      "\tEpoch 20/100 - Train loss: 0.3812 - Val accuracy: 0.8806 - Val loss: 0.3197 - Val F1: 0.8755 - LR: 8.00e-06\n",
      "\tEpoch 30/100 - Train loss: 0.2895 - Val accuracy: 0.8955 - Val loss: 0.2759 - Val F1: 0.8918 - LR: 7.00e-06\n",
      "\tEpoch 40/100 - Train loss: 0.2333 - Val accuracy: 0.9254 - Val loss: 0.1949 - Val F1: 0.9241 - LR: 6.00e-06\n",
      "\tEpoch 50/100 - Train loss: 0.4655 - Val accuracy: 0.9254 - Val loss: 0.2103 - Val F1: 0.9232 - LR: 5.00e-06\n",
      "\tEpoch 60/100 - Train loss: 0.2332 - Val accuracy: 0.9403 - Val loss: 0.1884 - Val F1: 0.9389 - LR: 4.00e-06\n",
      "\tEpoch 70/100 - Train loss: 0.2037 - Val accuracy: 0.9403 - Val loss: 0.1647 - Val F1: 0.9389 - LR: 3.00e-06\n",
      "\tEpoch 80/100 - Train loss: 0.2475 - Val accuracy: 0.9403 - Val loss: 0.1642 - Val F1: 0.9389 - LR: 2.00e-06\n",
      "\tEpoch 90/100 - Train loss: 0.3848 - Val accuracy: 0.9403 - Val loss: 0.1605 - Val F1: 0.9389 - LR: 1.00e-06\n",
      "\tEpoch 100/100 - Train loss: 0.1806 - Val accuracy: 0.9403 - Val loss: 0.1539 - Val F1: 0.9389 - LR: 0.00e+00\n",
      "\tBest epoch: 87 - Best val accuracy: 0.9552 - Best val loss: 0.1437 - Best val F1: 0.9544\n",
      "\n",
      "Source class: WAL | Domain: 62 | Accuracy: 0.7872 | Loss: 0.6105 | F1: 0.8084\n",
      "\n",
      "Domain: 63\n",
      "x_syn_dom.shape: (333, 3, 128) | np.unique(y_syn_dom): [1 2 3]\n",
      "x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Fine-tuning on synthetic data...\n",
      "\tEpoch 10/100 - Train loss: 0.6536 - Val accuracy: 0.8806 - Val loss: 0.3435 - Val F1: 0.8749 - LR: 9.00e-06\n",
      "\tEpoch 20/100 - Train loss: 0.6941 - Val accuracy: 0.8955 - Val loss: 0.2525 - Val F1: 0.8935 - LR: 8.00e-06\n",
      "\tEpoch 30/100 - Train loss: 0.5356 - Val accuracy: 0.9104 - Val loss: 0.1993 - Val F1: 0.9096 - LR: 7.00e-06\n",
      "\tEpoch 40/100 - Train loss: 0.2569 - Val accuracy: 0.9104 - Val loss: 0.1792 - Val F1: 0.9096 - LR: 6.00e-06\n",
      "\tEpoch 50/100 - Train loss: 0.3538 - Val accuracy: 0.9254 - Val loss: 0.1656 - Val F1: 0.9256 - LR: 5.00e-06\n",
      "\tEpoch 60/100 - Train loss: 0.3794 - Val accuracy: 0.9552 - Val loss: 0.1488 - Val F1: 0.9552 - LR: 4.00e-06\n",
      "\tEpoch 70/100 - Train loss: 0.6269 - Val accuracy: 0.9552 - Val loss: 0.1374 - Val F1: 0.9552 - LR: 3.00e-06\n",
      "\tEpoch 80/100 - Train loss: 0.3632 - Val accuracy: 0.9552 - Val loss: 0.1352 - Val F1: 0.9552 - LR: 2.00e-06\n",
      "\tEpoch 90/100 - Train loss: 0.2817 - Val accuracy: 0.9552 - Val loss: 0.1374 - Val F1: 0.9552 - LR: 1.00e-06\n",
      "\tEpoch 100/100 - Train loss: 0.3057 - Val accuracy: 0.9552 - Val loss: 0.1347 - Val F1: 0.9552 - LR: 0.00e+00\n",
      "\tBest epoch: 96 - Best val accuracy: 0.9552 - Best val loss: 0.1273 - Best val F1: 0.9552\n",
      "\n",
      "Source class: WAL | Domain: 63 | Accuracy: 0.3333 | Loss: 2.8838 | F1: 0.3647\n",
      "\n",
      "Domain: 64\n",
      "x_syn_dom.shape: (336, 3, 128) | np.unique(y_syn_dom): [1 2 3]\n",
      "x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Fine-tuning on synthetic data...\n",
      "\tEpoch 10/100 - Train loss: 0.7317 - Val accuracy: 0.7059 - Val loss: 0.9149 - Val F1: 0.6664 - LR: 9.00e-06\n",
      "\tEpoch 20/100 - Train loss: 0.5090 - Val accuracy: 0.7794 - Val loss: 0.5465 - Val F1: 0.7684 - LR: 8.00e-06\n",
      "\tEpoch 30/100 - Train loss: 0.4508 - Val accuracy: 0.8235 - Val loss: 0.4308 - Val F1: 0.8163 - LR: 7.00e-06\n",
      "\tEpoch 40/100 - Train loss: 0.4460 - Val accuracy: 0.8676 - Val loss: 0.3293 - Val F1: 0.8673 - LR: 6.00e-06\n",
      "\tEpoch 50/100 - Train loss: 0.3525 - Val accuracy: 0.8676 - Val loss: 0.3226 - Val F1: 0.8686 - LR: 5.00e-06\n",
      "\tEpoch 60/100 - Train loss: 0.3107 - Val accuracy: 0.8676 - Val loss: 0.3079 - Val F1: 0.8686 - LR: 4.00e-06\n",
      "\tEpoch 70/100 - Train loss: 0.2899 - Val accuracy: 0.8971 - Val loss: 0.2814 - Val F1: 0.8980 - LR: 3.00e-06\n",
      "\tEpoch 80/100 - Train loss: 0.4315 - Val accuracy: 0.8971 - Val loss: 0.2747 - Val F1: 0.8980 - LR: 2.00e-06\n",
      "\tEpoch 90/100 - Train loss: 0.2452 - Val accuracy: 0.8971 - Val loss: 0.2825 - Val F1: 0.8977 - LR: 1.00e-06\n",
      "\tEpoch 100/100 - Train loss: 0.3515 - Val accuracy: 0.9118 - Val loss: 0.2714 - Val F1: 0.9118 - LR: 0.00e+00\n",
      "\tBest epoch: 96 - Best val accuracy: 0.9118 - Best val loss: 0.2623 - Best val F1: 0.9115\n",
      "\n",
      "Source class: WAL | Domain: 64 | Accuracy: 0.9524 | Loss: 0.4248 | F1: 0.9514\n",
      "\n",
      "Domain: 65\n",
      "x_syn_dom.shape: (333, 3, 128) | np.unique(y_syn_dom): [1 2 3]\n",
      "x_dp_dom.shape: (50, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Fine-tuning on synthetic data...\n",
      "\tEpoch 10/100 - Train loss: 0.4519 - Val accuracy: 0.9254 - Val loss: 0.2169 - Val F1: 0.9232 - LR: 9.00e-06\n",
      "\tEpoch 20/100 - Train loss: 0.5123 - Val accuracy: 0.9254 - Val loss: 0.1517 - Val F1: 0.9232 - LR: 8.00e-06\n",
      "\tEpoch 30/100 - Train loss: 0.3067 - Val accuracy: 0.9403 - Val loss: 0.1274 - Val F1: 0.9398 - LR: 7.00e-06\n",
      "\tEpoch 40/100 - Train loss: 0.2879 - Val accuracy: 0.9403 - Val loss: 0.1378 - Val F1: 0.9398 - LR: 6.00e-06\n",
      "\tEpoch 50/100 - Train loss: 0.2964 - Val accuracy: 0.9403 - Val loss: 0.1200 - Val F1: 0.9398 - LR: 5.00e-06\n",
      "\tEpoch 60/100 - Train loss: 0.3586 - Val accuracy: 0.9552 - Val loss: 0.1040 - Val F1: 0.9550 - LR: 4.00e-06\n",
      "\tEpoch 70/100 - Train loss: 0.2676 - Val accuracy: 0.9403 - Val loss: 0.1175 - Val F1: 0.9398 - LR: 3.00e-06\n",
      "\tEpoch 80/100 - Train loss: 0.3265 - Val accuracy: 0.9552 - Val loss: 0.1052 - Val F1: 0.9550 - LR: 2.00e-06\n",
      "\tEpoch 90/100 - Train loss: 0.3353 - Val accuracy: 0.9552 - Val loss: 0.1127 - Val F1: 0.9550 - LR: 1.00e-06\n",
      "\tEpoch 100/100 - Train loss: 0.3021 - Val accuracy: 0.9552 - Val loss: 0.1109 - Val F1: 0.9550 - LR: 0.00e+00\n",
      "\tBest epoch: 75 - Best val accuracy: 0.9552 - Best val loss: 0.0998 - Best val F1: 0.9550\n",
      "\n",
      "Source class: WAL | Domain: 65 | Accuracy: 0.9000 | Loss: 1.2852 | F1: 0.8846\n",
      "\n",
      "Domain: 66\n",
      "x_syn_dom.shape: (333, 3, 128) | np.unique(y_syn_dom): [1 2 3]\n",
      "x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Fine-tuning on synthetic data...\n",
      "\tEpoch 10/100 - Train loss: 1.0030 - Val accuracy: 0.7463 - Val loss: 0.7251 - Val F1: 0.6996 - LR: 9.00e-06\n",
      "\tEpoch 20/100 - Train loss: 0.8320 - Val accuracy: 0.8358 - Val loss: 0.5079 - Val F1: 0.8180 - LR: 8.00e-06\n",
      "\tEpoch 30/100 - Train loss: 0.7695 - Val accuracy: 0.8358 - Val loss: 0.4114 - Val F1: 0.8178 - LR: 7.00e-06\n",
      "\tEpoch 40/100 - Train loss: 0.5143 - Val accuracy: 0.8806 - Val loss: 0.3380 - Val F1: 0.8722 - LR: 6.00e-06\n",
      "\tEpoch 50/100 - Train loss: 0.4542 - Val accuracy: 0.8507 - Val loss: 0.3290 - Val F1: 0.8373 - LR: 5.00e-06\n",
      "\tEpoch 60/100 - Train loss: 0.5395 - Val accuracy: 0.8806 - Val loss: 0.2838 - Val F1: 0.8725 - LR: 4.00e-06\n",
      "\tEpoch 70/100 - Train loss: 0.3897 - Val accuracy: 0.8806 - Val loss: 0.2637 - Val F1: 0.8725 - LR: 3.00e-06\n",
      "\tEpoch 80/100 - Train loss: 0.3874 - Val accuracy: 0.9104 - Val loss: 0.2303 - Val F1: 0.9062 - LR: 2.00e-06\n",
      "\tEpoch 90/100 - Train loss: 0.3960 - Val accuracy: 0.8955 - Val loss: 0.2724 - Val F1: 0.8912 - LR: 1.00e-06\n",
      "\tEpoch 100/100 - Train loss: 0.4250 - Val accuracy: 0.9104 - Val loss: 0.2246 - Val F1: 0.9062 - LR: 0.00e+00\n",
      "\tBest epoch: 96 - Best val accuracy: 0.9403 - Best val loss: 0.2151 - Best val F1: 0.9389\n",
      "\n",
      "Source class: WAL | Domain: 66 | Accuracy: 0.8333 | Loss: 1.0949 | F1: 0.7716\n",
      "\n",
      "Domain: 67\n",
      "x_syn_dom.shape: (333, 3, 128) | np.unique(y_syn_dom): [1 2 3]\n",
      "x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Fine-tuning on synthetic data...\n",
      "\tEpoch 10/100 - Train loss: 0.4997 - Val accuracy: 0.8657 - Val loss: 0.8180 - Val F1: 0.8670 - LR: 9.00e-06\n",
      "\tEpoch 20/100 - Train loss: 0.4845 - Val accuracy: 0.9104 - Val loss: 0.7997 - Val F1: 0.9103 - LR: 8.00e-06\n",
      "\tEpoch 30/100 - Train loss: 0.5026 - Val accuracy: 0.8806 - Val loss: 0.7633 - Val F1: 0.8806 - LR: 7.00e-06\n",
      "\tEpoch 40/100 - Train loss: 0.3899 - Val accuracy: 0.8955 - Val loss: 0.7369 - Val F1: 0.8955 - LR: 6.00e-06\n",
      "\tEpoch 50/100 - Train loss: 0.3414 - Val accuracy: 0.8955 - Val loss: 0.7136 - Val F1: 0.8955 - LR: 5.00e-06\n",
      "\tEpoch 60/100 - Train loss: 0.4280 - Val accuracy: 0.9104 - Val loss: 0.7271 - Val F1: 0.9103 - LR: 4.00e-06\n",
      "\tEpoch 70/100 - Train loss: 0.4119 - Val accuracy: 0.9104 - Val loss: 0.7086 - Val F1: 0.9103 - LR: 3.00e-06\n",
      "\tEpoch 80/100 - Train loss: 0.4487 - Val accuracy: 0.9104 - Val loss: 0.7134 - Val F1: 0.9103 - LR: 2.00e-06\n",
      "\tEpoch 90/100 - Train loss: 0.4132 - Val accuracy: 0.8955 - Val loss: 0.6741 - Val F1: 0.8955 - LR: 1.00e-06\n",
      "\tEpoch 100/100 - Train loss: 0.3933 - Val accuracy: 0.8955 - Val loss: 0.6915 - Val F1: 0.8955 - LR: 0.00e+00\n",
      "\tBest epoch: 81 - Best val accuracy: 0.8955 - Best val loss: 0.6647 - Best val F1: 0.8955\n",
      "\n",
      "Source class: WAL | Domain: 67 | Accuracy: 0.7143 | Loss: 1.3250 | F1: 0.7472\n",
      "\n",
      "Domain: 68\n",
      "x_syn_dom.shape: (333, 3, 128) | np.unique(y_syn_dom): [1 2 3]\n",
      "x_dp_dom.shape: (43, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Fine-tuning on synthetic data...\n",
      "\tEpoch 10/100 - Train loss: 1.2484 - Val accuracy: 0.7313 - Val loss: 1.0128 - Val F1: 0.6916 - LR: 9.00e-06\n",
      "\tEpoch 20/100 - Train loss: 0.8456 - Val accuracy: 0.7313 - Val loss: 0.7440 - Val F1: 0.7012 - LR: 8.00e-06\n",
      "\tEpoch 30/100 - Train loss: 0.6779 - Val accuracy: 0.7313 - Val loss: 0.6024 - Val F1: 0.7091 - LR: 7.00e-06\n",
      "\tEpoch 40/100 - Train loss: 0.8820 - Val accuracy: 0.7612 - Val loss: 0.5210 - Val F1: 0.7411 - LR: 6.00e-06\n",
      "\tEpoch 50/100 - Train loss: 0.8511 - Val accuracy: 0.7463 - Val loss: 0.5434 - Val F1: 0.7217 - LR: 5.00e-06\n",
      "\tEpoch 60/100 - Train loss: 0.7193 - Val accuracy: 0.8209 - Val loss: 0.4218 - Val F1: 0.8092 - LR: 4.00e-06\n",
      "\tEpoch 70/100 - Train loss: 0.6850 - Val accuracy: 0.8209 - Val loss: 0.4149 - Val F1: 0.8092 - LR: 3.00e-06\n",
      "\tEpoch 80/100 - Train loss: 0.4776 - Val accuracy: 0.7910 - Val loss: 0.4778 - Val F1: 0.7769 - LR: 2.00e-06\n",
      "\tEpoch 90/100 - Train loss: 0.5998 - Val accuracy: 0.8209 - Val loss: 0.4414 - Val F1: 0.8148 - LR: 1.00e-06\n",
      "\tEpoch 100/100 - Train loss: 0.4915 - Val accuracy: 0.8209 - Val loss: 0.4163 - Val F1: 0.8124 - LR: 0.00e+00\n",
      "\tBest epoch: 88 - Best val accuracy: 0.8358 - Best val loss: 0.3904 - Best val F1: 0.8317\n",
      "\n",
      "Source class: WAL | Domain: 68 | Accuracy: 0.5581 | Loss: 1.5827 | F1: 0.5719\n",
      "\n",
      "Domain: 69\n",
      "x_syn_dom.shape: (333, 3, 128) | np.unique(y_syn_dom): [1 2 3]\n",
      "x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Fine-tuning on synthetic data...\n",
      "\tEpoch 10/100 - Train loss: 1.0270 - Val accuracy: 0.6418 - Val loss: 1.0024 - Val F1: 0.6426 - LR: 9.00e-06\n",
      "\tEpoch 20/100 - Train loss: 1.0057 - Val accuracy: 0.6866 - Val loss: 0.8577 - Val F1: 0.6844 - LR: 8.00e-06\n",
      "\tEpoch 30/100 - Train loss: 0.6421 - Val accuracy: 0.7164 - Val loss: 0.7484 - Val F1: 0.7174 - LR: 7.00e-06\n",
      "\tEpoch 40/100 - Train loss: 0.6889 - Val accuracy: 0.7612 - Val loss: 0.7235 - Val F1: 0.7557 - LR: 6.00e-06\n",
      "\tEpoch 50/100 - Train loss: 0.7529 - Val accuracy: 0.7910 - Val loss: 0.6703 - Val F1: 0.7884 - LR: 5.00e-06\n",
      "\tEpoch 60/100 - Train loss: 0.9773 - Val accuracy: 0.7910 - Val loss: 0.6357 - Val F1: 0.7884 - LR: 4.00e-06\n",
      "\tEpoch 70/100 - Train loss: 0.4583 - Val accuracy: 0.7910 - Val loss: 0.5987 - Val F1: 0.7932 - LR: 3.00e-06\n",
      "\tEpoch 80/100 - Train loss: 0.4584 - Val accuracy: 0.7910 - Val loss: 0.5842 - Val F1: 0.7932 - LR: 2.00e-06\n",
      "\tEpoch 90/100 - Train loss: 0.4665 - Val accuracy: 0.8209 - Val loss: 0.5842 - Val F1: 0.8212 - LR: 1.00e-06\n",
      "\tEpoch 100/100 - Train loss: 0.5281 - Val accuracy: 0.7910 - Val loss: 0.5648 - Val F1: 0.7932 - LR: 0.00e+00\n",
      "\tBest epoch: 91 - Best val accuracy: 0.7910 - Best val loss: 0.5512 - Best val F1: 0.7932\n",
      "\n",
      "Source class: WAL | Domain: 69 | Accuracy: 0.9762 | Loss: 0.0366 | F1: 0.9761\n",
      "\n",
      "Domain: 70\n",
      "x_syn_dom.shape: (333, 3, 128) | np.unique(y_syn_dom): [1 2 3]\n",
      "x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Fine-tuning on synthetic data...\n",
      "\tEpoch 10/100 - Train loss: 0.5178 - Val accuracy: 0.8358 - Val loss: 0.3813 - Val F1: 0.8337 - LR: 9.00e-06\n",
      "\tEpoch 20/100 - Train loss: 0.5551 - Val accuracy: 0.8358 - Val loss: 0.3684 - Val F1: 0.8337 - LR: 8.00e-06\n",
      "\tEpoch 30/100 - Train loss: 0.5723 - Val accuracy: 0.8358 - Val loss: 0.3569 - Val F1: 0.8337 - LR: 7.00e-06\n",
      "\tEpoch 40/100 - Train loss: 0.6086 - Val accuracy: 0.8358 - Val loss: 0.3357 - Val F1: 0.8337 - LR: 6.00e-06\n",
      "\tEpoch 50/100 - Train loss: 0.5136 - Val accuracy: 0.8507 - Val loss: 0.3277 - Val F1: 0.8495 - LR: 5.00e-06\n",
      "\tEpoch 60/100 - Train loss: 0.4724 - Val accuracy: 0.8657 - Val loss: 0.2983 - Val F1: 0.8650 - LR: 4.00e-06\n",
      "\tEpoch 70/100 - Train loss: 0.4788 - Val accuracy: 0.8507 - Val loss: 0.3113 - Val F1: 0.8495 - LR: 3.00e-06\n",
      "\tEpoch 80/100 - Train loss: 0.4572 - Val accuracy: 0.8657 - Val loss: 0.2956 - Val F1: 0.8650 - LR: 2.00e-06\n",
      "\tEpoch 90/100 - Train loss: 0.4643 - Val accuracy: 0.8806 - Val loss: 0.2750 - Val F1: 0.8803 - LR: 1.00e-06\n",
      "\tEpoch 100/100 - Train loss: 0.4109 - Val accuracy: 0.8806 - Val loss: 0.2808 - Val F1: 0.8803 - LR: 0.00e+00\n",
      "\tBest epoch: 93 - Best val accuracy: 0.8955 - Best val loss: 0.2699 - Best val F1: 0.8955\n",
      "\n",
      "Source class: WAL | Domain: 70 | Accuracy: 0.7143 | Loss: 3.4720 | F1: 0.6860\n",
      "\n",
      "Domain: 71\n",
      "x_syn_dom.shape: (333, 3, 128) | np.unique(y_syn_dom): [1 2 3]\n",
      "x_dp_dom.shape: (44, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Fine-tuning on synthetic data...\n",
      "\tEpoch 10/100 - Train loss: 0.8114 - Val accuracy: 0.7761 - Val loss: 1.1422 - Val F1: 0.7584 - LR: 9.00e-06\n",
      "\tEpoch 20/100 - Train loss: 0.8270 - Val accuracy: 0.8358 - Val loss: 0.9709 - Val F1: 0.8295 - LR: 8.00e-06\n",
      "\tEpoch 30/100 - Train loss: 0.6827 - Val accuracy: 0.8358 - Val loss: 0.9219 - Val F1: 0.8295 - LR: 7.00e-06\n",
      "\tEpoch 40/100 - Train loss: 0.4853 - Val accuracy: 0.8358 - Val loss: 0.8621 - Val F1: 0.8295 - LR: 6.00e-06\n",
      "\tEpoch 50/100 - Train loss: 0.4943 - Val accuracy: 0.8507 - Val loss: 0.8394 - Val F1: 0.8471 - LR: 5.00e-06\n",
      "\tEpoch 60/100 - Train loss: 0.3864 - Val accuracy: 0.8657 - Val loss: 0.8047 - Val F1: 0.8610 - LR: 4.00e-06\n",
      "\tEpoch 70/100 - Train loss: 0.6126 - Val accuracy: 0.8657 - Val loss: 0.7875 - Val F1: 0.8610 - LR: 3.00e-06\n",
      "\tEpoch 80/100 - Train loss: 0.3312 - Val accuracy: 0.8806 - Val loss: 0.7923 - Val F1: 0.8781 - LR: 2.00e-06\n",
      "\tEpoch 90/100 - Train loss: 0.3506 - Val accuracy: 0.8806 - Val loss: 0.7926 - Val F1: 0.8781 - LR: 1.00e-06\n",
      "\tEpoch 100/100 - Train loss: 0.3986 - Val accuracy: 0.8955 - Val loss: 0.7903 - Val F1: 0.8950 - LR: 0.00e+00\n",
      "\tBest epoch: 82 - Best val accuracy: 0.8955 - Best val loss: 0.7661 - Best val F1: 0.8950\n",
      "\n",
      "Source class: WAL | Domain: 71 | Accuracy: 0.5909 | Loss: 1.5569 | F1: 0.6091\n",
      "\n",
      "Domain: 72\n",
      "x_syn_dom.shape: (333, 3, 128) | np.unique(y_syn_dom): [1 2 3]\n",
      "x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Fine-tuning on synthetic data...\n",
      "\tEpoch 10/100 - Train loss: 0.7083 - Val accuracy: 0.7761 - Val loss: 1.0016 - Val F1: 0.7656 - LR: 9.00e-06\n",
      "\tEpoch 20/100 - Train loss: 0.6084 - Val accuracy: 0.8209 - Val loss: 0.7474 - Val F1: 0.8139 - LR: 8.00e-06\n",
      "\tEpoch 30/100 - Train loss: 0.5834 - Val accuracy: 0.8657 - Val loss: 0.6710 - Val F1: 0.8603 - LR: 7.00e-06\n",
      "\tEpoch 40/100 - Train loss: 0.4204 - Val accuracy: 0.8806 - Val loss: 0.6567 - Val F1: 0.8783 - LR: 6.00e-06\n",
      "\tEpoch 50/100 - Train loss: 0.3936 - Val accuracy: 0.8806 - Val loss: 0.6366 - Val F1: 0.8783 - LR: 5.00e-06\n",
      "\tEpoch 60/100 - Train loss: 0.3510 - Val accuracy: 0.8806 - Val loss: 0.6022 - Val F1: 0.8783 - LR: 4.00e-06\n",
      "\tEpoch 70/100 - Train loss: 0.3530 - Val accuracy: 0.8657 - Val loss: 0.5592 - Val F1: 0.8639 - LR: 3.00e-06\n",
      "\tEpoch 80/100 - Train loss: 0.2929 - Val accuracy: 0.8806 - Val loss: 0.5614 - Val F1: 0.8783 - LR: 2.00e-06\n",
      "\tEpoch 90/100 - Train loss: 0.2785 - Val accuracy: 0.8806 - Val loss: 0.5551 - Val F1: 0.8783 - LR: 1.00e-06\n",
      "\tEpoch 100/100 - Train loss: 0.2878 - Val accuracy: 0.8806 - Val loss: 0.5514 - Val F1: 0.8783 - LR: 0.00e+00\n",
      "\tBest epoch: 89 - Best val accuracy: 0.8806 - Best val loss: 0.5284 - Best val F1: 0.8796\n",
      "\n",
      "Source class: WAL | Domain: 72 | Accuracy: 0.8571 | Loss: 0.2964 | F1: 0.8718\n",
      "\n",
      "Domain: 73\n",
      "x_syn_dom.shape: (333, 3, 128) | np.unique(y_syn_dom): [1 2 3]\n",
      "x_dp_dom.shape: (41, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Fine-tuning on synthetic data...\n",
      "\tEpoch 10/100 - Train loss: 0.1815 - Val accuracy: 1.0000 - Val loss: 0.0209 - Val F1: 1.0000 - LR: 9.00e-06\n",
      "\tEpoch 20/100 - Train loss: 0.2992 - Val accuracy: 1.0000 - Val loss: 0.0213 - Val F1: 1.0000 - LR: 8.00e-06\n",
      "\tEpoch 30/100 - Train loss: 0.2317 - Val accuracy: 0.9851 - Val loss: 0.0265 - Val F1: 0.9851 - LR: 7.00e-06\n",
      "\tEpoch 40/100 - Train loss: 0.1792 - Val accuracy: 1.0000 - Val loss: 0.0169 - Val F1: 1.0000 - LR: 6.00e-06\n",
      "\tEpoch 50/100 - Train loss: 0.1996 - Val accuracy: 1.0000 - Val loss: 0.0173 - Val F1: 1.0000 - LR: 5.00e-06\n",
      "\tEpoch 60/100 - Train loss: 0.1913 - Val accuracy: 1.0000 - Val loss: 0.0190 - Val F1: 1.0000 - LR: 4.00e-06\n",
      "\tEpoch 70/100 - Train loss: 0.1685 - Val accuracy: 1.0000 - Val loss: 0.0172 - Val F1: 1.0000 - LR: 3.00e-06\n",
      "\tEpoch 80/100 - Train loss: 0.1310 - Val accuracy: 1.0000 - Val loss: 0.0145 - Val F1: 1.0000 - LR: 2.00e-06\n",
      "\tEpoch 90/100 - Train loss: 0.3296 - Val accuracy: 1.0000 - Val loss: 0.0176 - Val F1: 1.0000 - LR: 1.00e-06\n",
      "\tEpoch 100/100 - Train loss: 0.1493 - Val accuracy: 1.0000 - Val loss: 0.0156 - Val F1: 1.0000 - LR: 0.00e+00\n",
      "\tBest epoch: 89 - Best val accuracy: 1.0000 - Best val loss: 0.0135 - Best val F1: 1.0000\n",
      "\n",
      "Source class: WAL | Domain: 73 | Accuracy: 0.6829 | Loss: 2.8102 | F1: 0.5708\n",
      "\n",
      "Domain: 74\n",
      "x_syn_dom.shape: (333, 3, 128) | np.unique(y_syn_dom): [1 2 3]\n",
      "x_dp_dom.shape: (35, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Fine-tuning on synthetic data...\n",
      "\tEpoch 10/100 - Train loss: 0.4625 - Val accuracy: 0.8955 - Val loss: 0.2186 - Val F1: 0.8951 - LR: 9.00e-06\n",
      "\tEpoch 20/100 - Train loss: 0.3679 - Val accuracy: 0.9552 - Val loss: 0.1770 - Val F1: 0.9556 - LR: 8.00e-06\n",
      "\tEpoch 30/100 - Train loss: 0.4007 - Val accuracy: 0.9552 - Val loss: 0.1573 - Val F1: 0.9558 - LR: 7.00e-06\n",
      "\tEpoch 40/100 - Train loss: 0.3237 - Val accuracy: 0.9552 - Val loss: 0.1294 - Val F1: 0.9556 - LR: 6.00e-06\n",
      "\tEpoch 50/100 - Train loss: 0.2490 - Val accuracy: 0.9701 - Val loss: 0.1258 - Val F1: 0.9705 - LR: 5.00e-06\n",
      "\tEpoch 60/100 - Train loss: 0.2477 - Val accuracy: 0.9701 - Val loss: 0.1174 - Val F1: 0.9701 - LR: 4.00e-06\n",
      "\tEpoch 70/100 - Train loss: 0.3256 - Val accuracy: 0.9701 - Val loss: 0.1163 - Val F1: 0.9705 - LR: 3.00e-06\n",
      "\tEpoch 80/100 - Train loss: 0.2885 - Val accuracy: 0.9851 - Val loss: 0.1093 - Val F1: 0.9851 - LR: 2.00e-06\n",
      "\tEpoch 90/100 - Train loss: 0.2599 - Val accuracy: 0.9851 - Val loss: 0.1042 - Val F1: 0.9851 - LR: 1.00e-06\n",
      "\tEpoch 100/100 - Train loss: 0.2843 - Val accuracy: 0.9851 - Val loss: 0.1013 - Val F1: 0.9851 - LR: 0.00e+00\n",
      "\tBest epoch: 98 - Best val accuracy: 0.9851 - Best val loss: 0.0964 - Best val F1: 0.9851\n",
      "\n",
      "Source class: WAL | Domain: 74 | Accuracy: 0.8000 | Loss: 5.2452 | F1: 0.7226\n",
      "\n",
      "Domain: 75\n",
      "x_syn_dom.shape: (333, 3, 128) | np.unique(y_syn_dom): [1 2 3]\n",
      "x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n",
      "\n",
      "Fine-tuning on synthetic data...\n",
      "\tEpoch 10/100 - Train loss: 0.6344 - Val accuracy: 0.7761 - Val loss: 0.7913 - Val F1: 0.7603 - LR: 9.00e-06\n",
      "\tEpoch 20/100 - Train loss: 0.5643 - Val accuracy: 0.8507 - Val loss: 0.3893 - Val F1: 0.8443 - LR: 8.00e-06\n",
      "\tEpoch 30/100 - Train loss: 0.3480 - Val accuracy: 0.8507 - Val loss: 0.2760 - Val F1: 0.8443 - LR: 7.00e-06\n",
      "\tEpoch 40/100 - Train loss: 0.3641 - Val accuracy: 0.9104 - Val loss: 0.2019 - Val F1: 0.9101 - LR: 6.00e-06\n",
      "\tEpoch 50/100 - Train loss: 0.2369 - Val accuracy: 0.9104 - Val loss: 0.2000 - Val F1: 0.9101 - LR: 5.00e-06\n",
      "\tEpoch 60/100 - Train loss: 0.2048 - Val accuracy: 0.9552 - Val loss: 0.1713 - Val F1: 0.9550 - LR: 4.00e-06\n",
      "\tEpoch 70/100 - Train loss: 0.2086 - Val accuracy: 0.9552 - Val loss: 0.1662 - Val F1: 0.9550 - LR: 3.00e-06\n",
      "\tEpoch 80/100 - Train loss: 0.2181 - Val accuracy: 0.9403 - Val loss: 0.1732 - Val F1: 0.9398 - LR: 2.00e-06\n",
      "\tEpoch 90/100 - Train loss: 0.3328 - Val accuracy: 0.9552 - Val loss: 0.1330 - Val F1: 0.9550 - LR: 1.00e-06\n",
      "\tEpoch 100/100 - Train loss: 0.2620 - Val accuracy: 0.9552 - Val loss: 0.1528 - Val F1: 0.9550 - LR: 0.00e+00\n",
      "\tBest epoch: 97 - Best val accuracy: 0.9552 - Best val loss: 0.1306 - Best val F1: 0.9550\n",
      "\n",
      "Source class: WAL | Domain: 75 | Accuracy: 0.9286 | Loss: 0.2986 | F1: 0.9251\n",
      "\n",
      "Mean accuracy: 0.7316\n",
      "Mean F1: 0.7119\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def compute_TSTR_Df_Syn(dataset):\n",
    "    accs = []\n",
    "    f1s = []\n",
    "\n",
    "    for src_class in config[dataset]['class_names']:\n",
    "        if src_class != 'WAL':\n",
    "            continue\n",
    "\n",
    "        print(f\"Source class: {src_class}\\n\")\n",
    "\n",
    "        # Load Df data\n",
    "        x_df, y_df, k_df = get_data(dataset, 'df', src_class)\n",
    "        print(f'x_df.shape: {x_df.shape} | np.unique(y_df): {np.unique(y_df)}\\n')\n",
    "\n",
    "        # Train on Df data\n",
    "        print('Training on Df data...')\n",
    "        df_model = train_only(x_df, y_df, dataset, num_epochs=num_epochs)\n",
    "\n",
    "        for domain in range(config[dataset]['num_df_domains'], config[dataset]['num_df_domains'] + config[dataset]['num_dp_domains']):\n",
    "            print(f\"Domain: {domain}\")\n",
    "\n",
    "            # Load synthetic data\n",
    "            x_syn_dom, y_syn_dom, k_syn_dom = get_syn_data(dataset, syn_name, src_class, domain)\n",
    "            print(f'x_syn_dom.shape: {x_syn_dom.shape} | np.unique(y_syn_dom): {np.unique(y_syn_dom)}')\n",
    "\n",
    "            # Load Dp data\n",
    "            x_dp_dom, y_dp_dom, k_dp_dom = get_data(dataset, 'dp', src_class, domain)\n",
    "            print(f'x_dp_dom.shape: {x_dp_dom.shape} | np.unique(y_dp_dom): {np.unique(y_dp_dom)}\\n')\n",
    "\n",
    "            # Fine-tune Df model on synthetic data and evaluate on Dp data\n",
    "            print('Fine-tuning on synthetic data...')\n",
    "            df_syn_model = fine_tune(copy.deepcopy(df_model), x_syn_dom, y_syn_dom, num_epochs=num_epochs)\n",
    "            acc, loss, f1 = evaluate_model(df_syn_model, get_dataloader(x_dp_dom, y_dp_dom))\n",
    "            save_scores(src_class, domain, acc, loss, f1, 'Df_Syn', dataset)\n",
    "            accs.append(acc)\n",
    "            f1s.append(f1)\n",
    "            print(f'Source class: {src_class} | Domain: {domain} | Accuracy: {acc:.4f} | Loss: {loss:.4f} | F1: {f1:.4f}\\n')\n",
    "\n",
    "    print(f\"Mean accuracy: {np.mean(accs):.4f}\")\n",
    "    print(f\"Mean F1: {np.mean(f1s):.4f}\\n\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "compute_TSTR_Df_Syn('realworld_mobiact')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "executionInfo": {
     "elapsed": 48,
     "status": "ok",
     "timestamp": 1732620473960,
     "user": {
      "displayName": "Pietro Cirino",
      "userId": "07315473796200699505"
     },
     "user_tz": -60
    },
    "id": "WrQyLH7NMxLn"
   },
   "outputs": [],
   "source": [
    "# def compute_TSTR_Df_Syn_all(dataset):\n",
    "#     accs = []\n",
    "\n",
    "#     for src_class in config[dataset]['class_names']:\n",
    "#         if src_class != 'WAL':\n",
    "#             continue\n",
    "\n",
    "#         print(f\"Source class: {src_class}\\n\")\n",
    "\n",
    "#         # Load Df data\n",
    "#         x_df, y_df, k_df = get_data(dataset, 'df', src_class)\n",
    "#         print(f'x_df.shape: {x_df.shape} | np.unique(y_df): {np.unique(y_df)}\\n')\n",
    "\n",
    "#         # Train on Df data\n",
    "#         print('Training on Df data...')\n",
    "#         df_model = train_only(x_df, y_df, dataset, num_epochs=num_epochs)\n",
    "\n",
    "#         # Load synthetic data\n",
    "#         x_syn, y_syn, k_syn = get_syn_data(dataset, syn_name, src_class)\n",
    "#         print(f'x_syn.shape: {x_syn.shape} | np.unique(y_syn): {np.unique(y_syn)}')\n",
    "\n",
    "#         # Load Dp data\n",
    "#         x_dp, y_dp, k_dp = get_data(dataset, 'dp', src_class)\n",
    "#         print(f'x_dp.shape: {x_dp.shape} | np.unique(y_dp): {np.unique(y_dp)}\\n')\n",
    "\n",
    "#         # Fine-tune Df model on synthetic data and evaluate on Dp data\n",
    "#         print('Fine-tuning on synthetic data...')\n",
    "#         df_syn_model = fine_tune(copy.deepcopy(df_model), x_syn, y_syn, num_epochs=num_epochs)\n",
    "#         acc, loss = evaluate_model(df_syn_model, get_dataloader(x_dp, y_dp))\n",
    "#         save_scores(src_class, 100, acc, loss, 'Df_Syn_all', dataset)\n",
    "#         accs.append(acc)\n",
    "#         print(f'Source class: {src_class} | Domain: All | Accuracy: {acc:.4f} | Loss: {loss:.4f}\\n')\n",
    "\n",
    "#     print(f\"Mean accuracy: {np.mean(accs):.4f}\\n\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# compute_TSTR_Df_Syn_all('realworld_mobiact')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fLSuTddOmD5c"
   },
   "source": [
    "# TSTRFS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 9,
     "status": "aborted",
     "timestamp": 1732616515443,
     "user": {
      "displayName": "Pietro Cirino",
      "userId": "07315473796200699505"
     },
     "user_tz": -60
    },
    "id": "wZqvTTwNCPto"
   },
   "outputs": [],
   "source": [
    "def compute_TSTRFS_Dpfs(dataset):\n",
    "    accs = []\n",
    "\n",
    "    for src_class in config[dataset]['class_names']:\n",
    "        if src_class != 'WAL':\n",
    "            continue\n",
    "\n",
    "        print(f\"Source class: {src_class}\\n\")\n",
    "\n",
    "        for domain in range(config[dataset]['num_df_domains'], config[dataset]['num_df_domains'] + config[dataset]['num_dp_domains']):\n",
    "            print(f\"Domain: {domain}\")\n",
    "\n",
    "            # Load Dpfs data\n",
    "            x_dpfs_dom, y_dpfs_dom, k_dpfs_dom = get_data(dataset, 'dpfs', src_class, domain)\n",
    "            print(f'x_dpfs_dom.shape: {x_dpfs_dom.shape} | np.unique(y_dpfs_dom): {np.unique(y_dpfs_dom)}')\n",
    "\n",
    "            # Load Dp data\n",
    "            x_dp_dom, y_dp_dom, k_dp_dom = get_data(dataset, 'dp', src_class, domain)\n",
    "            print(f'x_dp_dom.shape: {x_dp_dom.shape} | np.unique(y_dp_dom): {np.unique(y_dp_dom)}\\n')\n",
    "\n",
    "            # Train on Dpfs data and test on Dp data\n",
    "            print('Training on Dpfs data...')\n",
    "            acc, loss = train_and_test(x_dpfs_dom, y_dpfs_dom, x_dp_dom, y_dp_dom, dataset, num_epochs=num_epochs)\n",
    "            save_scores(src_class, domain, acc, loss, 'FS_Dpfs', dataset)\n",
    "            accs.append(acc)\n",
    "            print(f'Source class: {src_class} | Domain: {domain} | Accuracy: {acc:.4f} | Loss: {loss:.4f}\\n')\n",
    "\n",
    "    print(f\"Mean accuracy: {np.mean(accs):.4f}\\n\")\n",
    "\n",
    "\n",
    "\n",
    "compute_TSTRFS_Dpfs('realworld_mobiact')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 9,
     "status": "aborted",
     "timestamp": 1732616515443,
     "user": {
      "displayName": "Pietro Cirino",
      "userId": "07315473796200699505"
     },
     "user_tz": -60
    },
    "id": "YOqZB6ARCPtp"
   },
   "outputs": [],
   "source": [
    "def compute_TSTRFS_Df_Dpfs(dataset):\n",
    "    accs = []\n",
    "\n",
    "    for src_class in config[dataset]['class_names']:\n",
    "        if src_class != 'WAL':\n",
    "            continue\n",
    "\n",
    "        print(f\"Source class: {src_class}\\n\")\n",
    "\n",
    "        # Load Df data\n",
    "        x_df, y_df, k_df = get_data(dataset, 'df', src_class)\n",
    "        print(f'x_df.shape: {x_df.shape} | np.unique(y_df): {np.unique(y_df)}\\n')\n",
    "\n",
    "        # Train on Df data\n",
    "        print('Training on Df data...')\n",
    "        df_model = train_only(x_df, y_df, dataset, num_epochs=num_epochs)\n",
    "\n",
    "        for domain in range(config[dataset]['num_df_domains'], config[dataset]['num_df_domains'] + config[dataset]['num_dp_domains']):\n",
    "            print(f\"Domain: {domain}\")\n",
    "\n",
    "            # Load Dpfs data\n",
    "            x_dpfs_dom, y_dpfs_dom, k_dpfs_dom = get_data(dataset, 'dpfs', src_class, domain)\n",
    "            print(f'x_dpfs_dom.shape: {x_dpfs_dom.shape} | np.unique(y_dpfs_dom): {np.unique(y_dpfs_dom)}')\n",
    "\n",
    "            # Load Dp data\n",
    "            x_dp_dom, y_dp_dom, k_dp_dom = get_data(dataset, 'dp', src_class, domain)\n",
    "            print(f'x_dp_dom.shape: {x_dp_dom.shape} | np.unique(y_dp_dom): {np.unique(y_dp_dom)}\\n')\n",
    "\n",
    "            # Fine-tune Df model on Dpfs data and test on Dp data\n",
    "            print('Fine-tuning on Dpfs data...')\n",
    "            df_dpfs_model = fine_tune(copy.deepcopy(df_model), x_dpfs_dom, y_dpfs_dom, num_epochs=num_epochs)\n",
    "            acc, loss = evaluate_model(df_dpfs_model, get_dataloader(x_dp_dom, y_dp_dom))\n",
    "            save_scores(src_class, domain, acc, loss, 'FS_Df_Dpfs', dataset)\n",
    "            accs.append(acc)\n",
    "            print(f'Source class: {src_class} | Domain: {domain} | Accuracy: {acc:.4f} | Loss: {loss:.4f}\\n')\n",
    "\n",
    "    print(f\"Mean accuracy: {np.mean(accs):.4f}\\n\")\n",
    "\n",
    "\n",
    "\n",
    "compute_TSTRFS_Df_Dpfs('realworld_mobiact')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 9,
     "status": "aborted",
     "timestamp": 1732616515443,
     "user": {
      "displayName": "Pietro Cirino",
      "userId": "07315473796200699505"
     },
     "user_tz": -60
    },
    "id": "oA89psVZg5yb"
   },
   "outputs": [],
   "source": [
    "def compute_TSTRFS_Syn(dataset):\n",
    "    accs = []\n",
    "\n",
    "    for src_class in config[dataset]['class_names']:\n",
    "        if src_class != 'WAL':\n",
    "            continue\n",
    "\n",
    "        print(f\"Source class: {src_class}\\n\")\n",
    "\n",
    "        for domain in range(config[dataset]['num_df_domains'], config[dataset]['num_df_domains'] + config[dataset]['num_dp_domains']):\n",
    "            print(f\"Domain: {domain}\")\n",
    "\n",
    "            # Load synthetic data\n",
    "            x_syn_dom, y_syn_dom, k_syn_dom = get_syn_data(dataset, syn_name, src_class, domain)\n",
    "            print(f'x_syn_dom.shape: {x_syn_dom.shape} | np.unique(y_syn_dom): {np.unique(y_syn_dom)}')\n",
    "\n",
    "            # Load Dp data\n",
    "            x_dp_dom, y_dp_dom, k_dp_dom = get_data(dataset, 'dp', src_class, domain)\n",
    "            print(f'x_dp_dom.shape: {x_dp_dom.shape} | np.unique(y_dp_dom): {np.unique(y_dp_dom)}\\n')\n",
    "\n",
    "            # Train on synthetic data and evaluate on Dp data\n",
    "            print('Training on synthetic data...')\n",
    "            acc, loss = train_and_test(x_syn_dom, y_syn_dom, x_dp_dom, y_dp_dom, dataset, num_epochs=num_epochs)\n",
    "            save_scores(src_class, domain, acc, loss, 'FS_Syn', dataset)\n",
    "            accs.append(acc)\n",
    "            print(f'Source class: {src_class} | Domain: {domain} | Accuracy: {acc:.4f} | Loss: {loss:.4f}\\n')\n",
    "\n",
    "    print(f\"Mean accuracy: {np.mean(accs):.4f}\\n\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "compute_TSTRFS_Syn('realworld_mobiact')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 9,
     "status": "aborted",
     "timestamp": 1732616515443,
     "user": {
      "displayName": "Pietro Cirino",
      "userId": "07315473796200699505"
     },
     "user_tz": -60
    },
    "id": "38LHCQjRCPtp"
   },
   "outputs": [],
   "source": [
    "def compute_TSTRFS_Df_Syn(dataset):\n",
    "    accs = []\n",
    "\n",
    "    for src_class in config[dataset]['class_names']:\n",
    "        if src_class != 'WAL':\n",
    "            continue\n",
    "\n",
    "        print(f\"Source class: {src_class}\\n\")\n",
    "\n",
    "        # Load Df data\n",
    "        x_df, y_df, k_df = get_data(dataset, 'df', src_class)\n",
    "        print(f'x_df.shape: {x_df.shape} | np.unique(y_df): {np.unique(y_df)}\\n')\n",
    "\n",
    "        # Train on Df data\n",
    "        print('Training on Df data...')\n",
    "        df_model = train_only(x_df, y_df, dataset, num_epochs=num_epochs)\n",
    "\n",
    "        for domain in range(config[dataset]['num_df_domains'], config[dataset]['num_df_domains'] + config[dataset]['num_dp_domains']):\n",
    "            print(f\"Domain: {domain}\")\n",
    "\n",
    "            # Load synthetic data\n",
    "            x_syn_dom, y_syn_dom, k_syn_dom = get_syn_data(dataset, syn_name, src_class, domain)\n",
    "            print(f'x_syn_dom.shape: {x_syn_dom.shape} | np.unique(y_syn_dom): {np.unique(y_syn_dom)}')\n",
    "\n",
    "            # Load Dp data\n",
    "            x_dp_dom, y_dp_dom, k_dp_dom = get_data(dataset, 'dp', src_class, domain)\n",
    "            print(f'x_dp_dom.shape: {x_dp_dom.shape} | np.unique(y_dp_dom): {np.unique(y_dp_dom)}\\n')\n",
    "\n",
    "            # Fine-tune Df model on synthetic data and evaluate on Dp data\n",
    "            print('Fine-tuning on synthetic data...')\n",
    "            df_syn_model = fine_tune(copy.deepcopy(df_model), x_syn_dom, y_syn_dom, num_epochs=num_epochs)\n",
    "            acc, loss = evaluate_model(df_syn_model, get_dataloader(x_dp_dom, y_dp_dom))\n",
    "            save_scores(src_class, domain, acc, loss, 'FS_Df_Syn', dataset)\n",
    "            accs.append(acc)\n",
    "            print(f'Source class: {src_class} | Domain: {domain} | Accuracy: {acc:.4f} | Loss: {loss:.4f}\\n')\n",
    "\n",
    "    print(f\"Mean accuracy: {np.mean(accs):.4f}\\n\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "compute_TSTRFS_Df_Syn('realworld_mobiact')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 8,
     "status": "aborted",
     "timestamp": 1732616515443,
     "user": {
      "displayName": "Pietro Cirino",
      "userId": "07315473796200699505"
     },
     "user_tz": -60
    },
    "id": "ueNEmwhVCPtp"
   },
   "outputs": [],
   "source": [
    "def compute_TSTRFS_Syn_Dpfs(dataset):\n",
    "    accs = []\n",
    "\n",
    "    for src_class in config[dataset]['class_names']:\n",
    "        if src_class != 'WAL':\n",
    "            continue\n",
    "\n",
    "        print(f\"Source class: {src_class}\\n\")\n",
    "\n",
    "        for domain in range(config[dataset]['num_df_domains'], config[dataset]['num_df_domains'] + config[dataset]['num_dp_domains']):\n",
    "            print(f\"Domain: {domain}\")\n",
    "\n",
    "            # Load synthetic data\n",
    "            x_syn_dom, y_syn_dom, k_syn_dom = get_syn_data(dataset, syn_name, src_class, domain)\n",
    "            print(f'x_syn_dom.shape: {x_syn_dom.shape} | np.unique(y_syn_dom): {np.unique(y_syn_dom)}')\n",
    "\n",
    "            # Load Dpfs data\n",
    "            x_dpfs_dom, y_dpfs_dom, k_dpfs_dom = get_data(dataset, 'dpfs', src_class, domain)\n",
    "            print(f'x_dpfs_dom.shape: {x_dpfs_dom.shape} | np.unique(y_dpfs_dom): {np.unique(y_dpfs_dom)}')\n",
    "\n",
    "            # Load Dp data\n",
    "            x_dp_dom, y_dp_dom, k_dp_dom = get_data(dataset, 'dp', src_class, domain)\n",
    "            print(f'x_dp_dom.shape: {x_dp_dom.shape} | np.unique(y_dp_dom): {np.unique(y_dp_dom)}\\n')\n",
    "\n",
    "            # Train on synthetic data\n",
    "            print('Training on synthetic data...')\n",
    "            syn_model = train_only(x_syn_dom, y_syn_dom, dataset, num_epochs=num_epochs)\n",
    "\n",
    "            # Fine-tune synthetic model on Dpfs data and evaluate on Dp data\n",
    "            print('Fine-tuning on Dpfs data...')\n",
    "            syn_dpfs_model = fine_tune(copy.deepcopy(syn_model), x_dpfs_dom, y_dpfs_dom, num_epochs=num_epochs)\n",
    "            acc, loss = evaluate_model(syn_dpfs_model, get_dataloader(x_dp_dom, y_dp_dom))\n",
    "            save_scores(src_class, domain, acc, loss, 'FS_Syn_Dpfs', dataset)\n",
    "            accs.append(acc)\n",
    "            print(f'Source class: {src_class} | Domain: {domain} | Accuracy: {acc:.4f} | Loss: {loss:.4f}\\n')\n",
    "\n",
    "    print(f\"Mean accuracy: {np.mean(accs):.4f}\\n\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "compute_TSTRFS_Syn_Dpfs('realworld_mobiact')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 8,
     "status": "aborted",
     "timestamp": 1732616515443,
     "user": {
      "displayName": "Pietro Cirino",
      "userId": "07315473796200699505"
     },
     "user_tz": -60
    },
    "id": "7z0xuuhhCPtp"
   },
   "outputs": [],
   "source": [
    "def compute_TSTRFS_Df_Syn_Dpfs(dataset):\n",
    "    accs = []\n",
    "\n",
    "    for src_class in config[dataset]['class_names']:\n",
    "        if src_class != 'WAL':\n",
    "            continue\n",
    "\n",
    "        print(f\"Source class: {src_class}\\n\")\n",
    "\n",
    "        # Load Df data\n",
    "        x_df, y_df, k_df = get_data(dataset, 'df', src_class)\n",
    "        print(f'x_df.shape: {x_df.shape} | np.unique(y_df): {np.unique(y_df)}\\n')\n",
    "\n",
    "        # Train on Df data\n",
    "        print('Training on Df data...')\n",
    "        df_model = train_only(x_df, y_df, dataset, num_epochs=num_epochs)\n",
    "\n",
    "        for domain in range(config[dataset]['num_df_domains'], config[dataset]['num_df_domains'] + config[dataset]['num_dp_domains']):\n",
    "            print(f\"Domain: {domain}\")\n",
    "\n",
    "            # Load synthetic data\n",
    "            x_syn_dom, y_syn_dom, k_syn_dom = get_syn_data(dataset, syn_name, src_class, domain)\n",
    "            print(f'x_syn_dom.shape: {x_syn_dom.shape} | np.unique(y_syn_dom): {np.unique(y_syn_dom)}')\n",
    "\n",
    "            # Load Dpfs data\n",
    "            x_dpfs_dom, y_dpfs_dom, k_dpfs_dom = get_data(dataset, 'dpfs', src_class, domain)\n",
    "            print(f'x_dpfs_dom.shape: {x_dpfs_dom.shape} | np.unique(y_dpfs_dom): {np.unique(y_dpfs_dom)}')\n",
    "\n",
    "            # Load Dp data\n",
    "            x_dp_dom, y_dp_dom, k_dp_dom = get_data(dataset, 'dp', src_class, domain)\n",
    "            print(f'x_dp_dom.shape: {x_dp_dom.shape} | np.unique(y_dp_dom): {np.unique(y_dp_dom)}\\n')\n",
    "\n",
    "            # Fine-tune Df model on synthetic data\n",
    "            print('Fine-tuning on synthetic data...')\n",
    "            df_syn_model = fine_tune(copy.deepcopy(df_model), x_syn_dom, y_syn_dom, num_epochs=num_epochs)\n",
    "\n",
    "            # Fine-tune Df-syn model on Dpfs data and evaluate on Dp data\n",
    "            print('Fine-tuning on Dpfs data...')\n",
    "            df_syn_dpfs_model = fine_tune(copy.deepcopy(df_syn_model), x_dpfs_dom, y_dpfs_dom, num_epochs=num_epochs)\n",
    "            acc, loss = evaluate_model(df_syn_dpfs_model, get_dataloader(x_dp_dom, y_dp_dom))\n",
    "            save_scores(src_class, domain, acc, loss, 'FS_Df_Syn_Dpfs', dataset)\n",
    "            accs.append(acc)\n",
    "            print(f'Source class: {src_class} | Domain: {domain} | Accuracy: {acc:.4f} | Loss: {loss:.4f}\\n')\n",
    "\n",
    "    print(f\"Mean accuracy: {np.mean(accs):.4f}\\n\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "compute_TSTRFS_Df_Syn_Dpfs('realworld_mobiact')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 8,
     "status": "aborted",
     "timestamp": 1732616515443,
     "user": {
      "displayName": "Pietro Cirino",
      "userId": "07315473796200699505"
     },
     "user_tz": -60
    },
    "id": "zpB3ecNGmD5f"
   },
   "outputs": [],
   "source": [
    "def compute_TSTRFS_Df_plus_Dpfs(dataset):\n",
    "    accs = []\n",
    "\n",
    "    for src_class in config[dataset]['class_names']:\n",
    "        if src_class != 'WAL':\n",
    "            continue\n",
    "\n",
    "        print(f\"Source class: {src_class}\\n\")\n",
    "\n",
    "        # Load Df data\n",
    "        x_df, y_df, k_df = get_data(dataset, 'df', src_class)\n",
    "        print(f'x_df.shape: {x_df.shape} | np.unique(y_df): {np.unique(y_df)}\\n')\n",
    "\n",
    "        for domain in range(config[dataset]['num_df_domains'], config[dataset]['num_df_domains'] + config[dataset]['num_dp_domains']):\n",
    "            print(f\"Domain: {domain}\")\n",
    "\n",
    "            # Load Dpfs data\n",
    "            x_dpfs_dom, y_dpfs_dom, k_dpfs_dom = get_data(dataset, 'dpfs', src_class, domain)\n",
    "            print(f'x_dpfs_dom.shape: {x_dpfs_dom.shape} | np.unique(y_dpfs_dom): {np.unique(y_dpfs_dom)}')\n",
    "\n",
    "            # Join Df and Dpfs data\n",
    "            x_df_dpfs = np.concatenate([x_df, x_dpfs_dom], axis=0)\n",
    "            y_df_dpfs = np.concatenate([y_df, y_dpfs_dom], axis=0)\n",
    "            k_df_dpfs = np.concatenate([k_df, k_dpfs_dom], axis=0)\n",
    "            print(f'x_df_dpfs.shape: {x_df_dpfs.shape} | np.unique(y_df_dpfs): {np.unique(y_df_dpfs)}')\n",
    "\n",
    "            # Load Dp data\n",
    "            x_dp_dom, y_dp_dom, k_dp_dom = get_data(dataset, 'dp', src_class, domain)\n",
    "            print(f'x_dp_dom.shape: {x_dp_dom.shape} | np.unique(y_dp_dom): {np.unique(y_dp_dom)}\\n')\n",
    "\n",
    "            # Train on Df plus Dpfs data and test on Dp data\n",
    "            print('Training on Df plus Dpfs data...')\n",
    "            acc, loss = train_and_test(x_df_dpfs, y_df_dpfs, x_dp_dom, y_dp_dom, dataset, num_epochs=num_epochs)\n",
    "            save_scores(src_class, domain, acc, loss, 'FS_Df_plus_Dpfs', dataset)\n",
    "            accs.append(acc)\n",
    "            print(f'Source class: {src_class} | Domain: {domain} | Accuracy: {acc:.4f} | Loss: {loss:.4f}\\n')\n",
    "\n",
    "    print(f\"Mean accuracy: {np.mean(accs):.4f}\\n\")\n",
    "\n",
    "\n",
    "\n",
    "compute_TSTRFS_Df_plus_Dpfs('realworld_mobiact')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 8,
     "status": "aborted",
     "timestamp": 1732616515443,
     "user": {
      "displayName": "Pietro Cirino",
      "userId": "07315473796200699505"
     },
     "user_tz": -60
    },
    "id": "RYl0a9ZJmD5f"
   },
   "outputs": [],
   "source": [
    "def compute_TSTRFS_Df_plus_Syn(dataset):\n",
    "    accs = []\n",
    "\n",
    "    for src_class in config[dataset]['class_names']:\n",
    "        if src_class != 'WAL':\n",
    "            continue\n",
    "\n",
    "        print(f\"Source class: {src_class}\\n\")\n",
    "\n",
    "        # Load Df data\n",
    "        x_df, y_df, k_df = get_data(dataset, 'df', src_class)\n",
    "        print(f'x_df.shape: {x_df.shape} | np.unique(y_df): {np.unique(y_df)}\\n')\n",
    "\n",
    "        for domain in range(config[dataset]['num_df_domains'], config[dataset]['num_df_domains'] + config[dataset]['num_dp_domains']):\n",
    "            print(f\"Domain: {domain}\")\n",
    "\n",
    "            # Load synthetic data\n",
    "            x_syn_dom, y_syn_dom, k_syn_dom = get_syn_data(dataset, syn_name, src_class, domain)\n",
    "            print(f'x_syn_dom.shape: {x_syn_dom.shape} | np.unique(y_syn_dom): {np.unique(y_syn_dom)}')\n",
    "\n",
    "            # Join Df and synthetic data\n",
    "            x_df_syn = np.concatenate([x_df, x_syn_dom], axis=0)\n",
    "            y_df_syn = np.concatenate([y_df, y_syn_dom], axis=0)\n",
    "            k_df_syn = np.concatenate([k_df, k_syn_dom], axis=0)\n",
    "            print(f'x_df_syn.shape: {x_df_syn.shape} | np.unique(y_df_syn): {np.unique(y_df_syn)}')\n",
    "\n",
    "            # Load Dp data\n",
    "            x_dp_dom, y_dp_dom, k_dp_dom = get_data(dataset, 'dp', src_class, domain)\n",
    "            print(f'x_dp_dom.shape: {x_dp_dom.shape} | np.unique(y_dp_dom): {np.unique(y_dp_dom)}\\n')\n",
    "\n",
    "            # Train on Df plus synthetic data and test on Dp data\n",
    "            print('Training on Df plus synthetic data...')\n",
    "            acc, loss = train_and_test(x_df, y_df, x_dp_dom, y_dp_dom, dataset, num_epochs=num_epochs)\n",
    "            save_scores(src_class, domain, acc, loss, 'FS_Df_plus_Syn', dataset)\n",
    "            accs.append(acc)\n",
    "            print(f'Source class: {src_class} | Domain: {domain} | Accuracy: {acc:.4f} | Loss: {loss:.4f}\\n')\n",
    "\n",
    "    print(f\"Mean accuracy: {np.mean(accs):.4f}\\n\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "compute_TSTRFS_Df_plus_Syn('realworld_mobiact')"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "stargan-v2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
