{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":19793,"status":"ok","timestamp":1732698079421,"user":{"displayName":"Pietro Pietro","userId":"08339472013712676764"},"user_tz":-60},"id":"I0_1KsKpCPtk","outputId":"156d9b69-23e0-40da-9b4a-3f0b3ed3f070"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n","/content/drive/MyDrive/ST/stargan\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')\n","\n","%cd drive/MyDrive/ST/stargan"]},{"cell_type":"markdown","metadata":{"id":"lLVVBGiQmD5W"},"source":["# Configuration"]},{"cell_type":"code","execution_count":2,"metadata":{"executionInfo":{"elapsed":11943,"status":"ok","timestamp":1732698091356,"user":{"displayName":"Pietro Pietro","userId":"08339472013712676764"},"user_tz":-60},"id":"yh05UGFkCPtm"},"outputs":[],"source":["import pickle\n","import numpy as np\n","from sklearn.model_selection import train_test_split, StratifiedKFold\n","from sklearn.metrics import accuracy_score, f1_score\n","import torch\n","import torch.nn as nn\n","from torch.utils.data import DataLoader, TensorDataset\n","from torch.optim.lr_scheduler import LambdaLR\n","import torch.optim as optim\n","import os\n","import csv\n","import random\n","import copy\n","\n","seed = 2710\n","torch.manual_seed(seed)\n","torch.cuda.manual_seed(seed)\n","np.random.seed(seed)\n","random.seed(seed)"]},{"cell_type":"code","execution_count":3,"metadata":{"executionInfo":{"elapsed":7,"status":"ok","timestamp":1732698091357,"user":{"displayName":"Pietro Pietro","userId":"08339472013712676764"},"user_tz":-60},"id":"UJN2bKbaCPtm"},"outputs":[],"source":["config = {\n","    'realworld': {\n","        'dataset_name': 'realworld',\n","        'num_df_domains': 10,\n","        'num_dp_domains': 5,\n","        'num_classes': 4,\n","        'class_names': ['WAL', 'RUN', 'CLD', 'CLU'],\n","        'num_timesteps': 128,\n","        'num_channels': 3,\n","        'num_classes': 4,\n","    },\n","    'cwru': {\n","        'dataset_name': 'cwru_256_3ch_5cl',\n","        'num_df_domains': 4,\n","        'num_dp_domains': 4,\n","        'num_classes': 5,\n","        'class_names': ['IR', 'Ball', 'OR_centred', 'OR_orthogonal', 'OR_opposite'],\n","        'num_timesteps': 256,\n","        'num_channels': 3,\n","        'num_classes': 5,\n","    },\n","    'realworld_mobiact': {\n","        'dataset_name': 'realworld_mobiact',\n","        'num_df_domains': 15,\n","        'num_dp_domains': 61,\n","        'num_classes': 4,\n","        'class_names': ['WAL', 'RUN', 'CLD', 'CLU'],\n","        'num_timesteps': 128,\n","        'num_channels': 3,\n","        'num_classes': 4,\n","    }\n","}\n","\n","syn_name = 'rwma11_wal'\n","num_epochs = 100\n","n_runs = 10"]},{"cell_type":"code","execution_count":4,"metadata":{"executionInfo":{"elapsed":6,"status":"ok","timestamp":1732698091357,"user":{"displayName":"Pietro Pietro","userId":"08339472013712676764"},"user_tz":-60},"id":"XwSwaF-LCPtn"},"outputs":[],"source":["def get_data(dataset, domains_set, src_class, domain=None, rot=False):\n","    # Load configurations\n","    dataset_name = config[dataset]['dataset_name']\n","    class_idx = config[dataset]['class_names'].index(src_class)\n","    num_df_domains = config[dataset]['num_df_domains']\n","\n","    if rot:\n","        dataset_name += '_rot'\n","\n","    try:\n","        with open(f'data/{dataset_name}.pkl', 'rb') as f:\n","            x, y, k = pickle.load(f)\n","        with open(f'data/{dataset_name}_fs.pkl', 'rb') as f:\n","            fs = pickle.load(f)\n","    except FileNotFoundError:\n","        raise FileNotFoundError(f\"Dataset files for {dataset} not found.\")\n","\n","\n","    if domains_set == 'df':\n","        mask = (k < num_df_domains)\n","    elif domains_set == 'dp':\n","        mask = (k >= num_df_domains) & (fs == 0)\n","    elif domains_set == 'dpfs':\n","        mask = (k >= num_df_domains) & (fs == 1)\n","    else:\n","        raise ValueError(f\"Invalid domains set: {domains_set}\")\n","\n","    # Apply initial mask\n","    x, y, k = x[mask], y[mask], k[mask]\n","\n","    # Additional domain filtering if specified\n","    if domain is not None:\n","        domain_mask = (k == domain)\n","        x, y, k = x[domain_mask], y[domain_mask], k[domain_mask]\n","\n","    assert len(x) > 0, f\"No data found\"\n","    assert len(x) == len(y) == len(k), f\"Data length mismatch\"\n","\n","    return x, y, k\n","\n","\n","\n","def get_syn_data(dataset, syn_name, src_class, domain=None, fs=False):\n","    # Load configurations\n","    class_names = config[dataset]['class_names']\n","\n","    try:\n","        with open(f'data/{dataset}_{syn_name}.pkl', 'rb') as f:\n","            x, y, k = pickle.load(f)\n","    except FileNotFoundError:\n","        raise FileNotFoundError(f\"Dataset files for {dataset} not found.\")\n","\n","    with open(f'data/{dataset}_{syn_name}_fs.pkl', 'rb') as f:\n","        fs = pickle.load(f)\n","\n","    x, y, k = x[fs == 0], y[fs == 0], k[fs == 0]\n","\n","    if domain is not None:\n","        domain_mask = (k == domain)\n","        x, y, k = x[domain_mask], y[domain_mask], k[domain_mask]\n","\n","    assert len(x) > 0, f\"No data found\"\n","    assert len(x) == len(y) == len(k), f\"Data length mismatch\"\n","\n","    return x, y, k\n","\n","\n","\n","class TSTRClassifier(nn.Module):\n","    def __init__(self, num_timesteps=128, num_channels=3, num_classes=5):\n","        super(TSTRClassifier, self).__init__()\n","\n","        self.conv1 = nn.Conv1d(num_channels, 16, kernel_size=5, stride=1, padding=2)\n","        self.bn1 = nn.BatchNorm1d(16)\n","        self.conv2 = nn.Conv1d(16, 32, kernel_size=5, stride=1, padding=2)\n","        self.bn2 = nn.BatchNorm1d(32)\n","        self.conv3 = nn.Conv1d(32, 64, kernel_size=5, stride=1, padding=2)\n","        self.bn3 = nn.BatchNorm1d(64)\n","        self.conv4 = nn.Conv1d(64, 128, kernel_size=5, stride=1, padding=2)\n","        self.bn4 = nn.BatchNorm1d(128)\n","        self.pool = nn.MaxPool1d(kernel_size=2, stride=2)\n","        self.relu = nn.ReLU()\n","        self.dropout = nn.Dropout(p=0.25)\n","\n","        self.fc_shared = nn.Linear(num_timesteps * 8, 100)\n","\n","        self.fc_class = nn.Linear(100, num_classes)\n","\n","    def forward(self, x):\n","        x = self.pool(self.relu(self.bn1(self.conv1(x))))\n","        x = self.pool(self.relu(self.bn2(self.conv2(x))))\n","        x = self.pool(self.relu(self.bn3(self.conv3(x))))\n","        x = self.pool(self.relu(self.bn4(self.conv4(x))))\n","        x = x.view(x.size(0), -1)  # Flatten\n","        x = self.dropout(x)\n","        x = self.relu(self.fc_shared(x))\n","\n","        # Final output for class prediction\n","        class_outputs = self.fc_class(x)\n","        return class_outputs\n","\n","\n","\n","def remap_labels(y):\n","    label_map = {clss: i for i, clss in enumerate(np.unique(y))}\n","    return np.array([label_map[clss] for clss in y])\n","\n","\n","\n","def get_dataloader(x, y, shuffle=False):\n","    x = torch.tensor(x, dtype=torch.float32)\n","    y = remap_labels(y)\n","    y = torch.tensor(y, dtype=torch.long)\n","\n","    # Determine dataset size and batch size\n","    dataset_size = len(x)\n","    if dataset_size <= 100:\n","        batch_size = dataset_size\n","    elif dataset_size <= 1000:\n","        batch_size = 16\n","    elif dataset_size <= 5000:\n","        batch_size = 32\n","    else:\n","        batch_size = 64\n","\n","    dataset = TensorDataset(x, y)\n","    loader = DataLoader(dataset, batch_size=batch_size, shuffle=shuffle)\n","\n","    return loader\n","\n","\n","def random_rotation_matrix():\n","    \"\"\"Generate a random rotation matrix from a predefined set of quaternions.\"\"\"\n","    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","\n","    # Randomly generate a quaternion\n","    q = np.random.rand(4)\n","\n","    # Convert quaternion to rotation matrix\n","    q = torch.tensor(q, device=device, dtype=torch.float32)\n","    q = q / torch.norm(q)  # Normalize quaternion\n","    q0, q1, q2, q3 = q\n","\n","    R = torch.tensor([\n","        [1 - 2*q2**2 - 2*q3**2, 2*q1*q2 - 2*q3*q0, 2*q1*q3 + 2*q2*q0],\n","        [2*q1*q2 + 2*q3*q0, 1 - 2*q1**2 - 2*q3**2, 2*q2*q3 - 2*q1*q0],\n","        [2*q1*q3 - 2*q2*q0, 2*q2*q3 + 2*q1*q0, 1 - 2*q1**2 - 2*q2**2]\n","    ], device=device, dtype=torch.float32)\n","\n","    return R, q\n","\n","\n","def augment_batch(x_real):\n","    \"\"\"Apply random rotation to the batch of real time series.\"\"\"\n","    min_val, max_val = -19.61, 19.61\n","    x_real = x_real * (max_val - min_val) + min_val  # De-normalize\n","    R, q = random_rotation_matrix()\n","    x_real = torch.matmul(R, x_real)  # Apply rotation\n","    x_real = (x_real - min_val) / (max_val - min_val)  # Re-normalize\n","    return x_real, q\n","\n","\n","\n","def evaluate_model(model, test_loader):\n","    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","    model.to(device)\n","    model.eval()\n","\n","    loss_fn = nn.CrossEntropyLoss()\n","\n","    total_loss = 0\n","    all_preds = []\n","    all_labels = []\n","\n","    with torch.no_grad():\n","        for x_batch, y_batch in test_loader:\n","            x_batch, y_batch = x_batch.to(device), y_batch.to(device)\n","            outputs = model(x_batch)\n","            loss = loss_fn(outputs, y_batch)\n","            total_loss += loss.item()\n","\n","            _, predicted_labels = torch.max(outputs, 1)\n","            all_preds.extend(predicted_labels.detach().cpu().numpy())\n","            all_labels.extend(y_batch.detach().cpu().numpy())\n","\n","    all_labels = np.array(all_labels)\n","    all_preds = np.array(all_preds)\n","    accuracy = accuracy_score(all_labels, all_preds)\n","    f1 = f1_score(all_labels, all_preds, average='weighted')\n","    total_loss /= len(test_loader)\n","\n","    return accuracy, total_loss, f1\n","\n","\n","\n","def train_model(model, train_loader, val_loader, optimizer, num_epochs=100, augment=False):\n","    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","    model.to(device)\n","\n","    loss_fn = nn.CrossEntropyLoss()\n","\n","    loss_train = []\n","    loss_val = []\n","    accuracy_val = []\n","    best_model_state = None\n","    best_loss = np.inf\n","    best_accuracy = 0\n","    best_f1 = 0\n","\n","    # Set up linear learning rate decay\n","    lambda_lr = lambda epoch: 1 - epoch / num_epochs\n","    scheduler = LambdaLR(optimizer, lr_lambda=lambda_lr)\n","\n","    for epoch in range(num_epochs):\n","        model.train()\n","        total_loss = 0\n","        for x_batch, y_batch in train_loader:\n","            x_batch, y_batch = x_batch.to(device), y_batch.to(device)\n","            if augment:\n","                x_batch, _ = augment_batch(x_batch)\n","            optimizer.zero_grad()\n","            outputs = model(x_batch)\n","            loss = loss_fn(outputs, y_batch)\n","            loss.backward()\n","            optimizer.step()\n","            total_loss += loss.item()\n","        total_loss /= len(train_loader)\n","        loss_train.append(total_loss)\n","\n","        # Update learning rate\n","        scheduler.step()\n","\n","        val_accuracy, val_loss, val_f1 = evaluate_model(model, val_loader)\n","        if val_loss < best_loss:\n","            best_epoch = epoch\n","            best_accuracy = val_accuracy\n","            best_f1 = val_f1\n","            best_loss = val_loss\n","            best_model_state = model.state_dict().copy()\n","\n","        loss_val.append(val_loss)\n","        accuracy_val.append(val_accuracy)\n","\n","        current_lr = scheduler.get_last_lr()[0]\n","        if (epoch+1) % 10 == 0:\n","            print(f\"\\tEpoch {epoch + 1}/{num_epochs} - Train loss: {total_loss:.4f} - Val accuracy: {val_accuracy:.4f} - Val loss: {val_loss:.4f} - Val F1: {val_f1:.4f} - LR: {current_lr:.2e}\")\n","\n","    print(f\"\\tBest epoch: {best_epoch + 1} - Best val accuracy: {best_accuracy:.4f} - Best val loss: {best_loss:.4f} - Best val F1: {best_f1:.4f}\\n\")\n","\n","    # Load best model state\n","    model.load_state_dict(best_model_state)\n","\n","    return model\n","\n","\n","\n","def train_and_test(x_train, y_train, x_test, y_test, dataset, num_epochs=100, augment=False):\n","    assert np.array_equal(np.unique(y_train), np.unique(y_test)), \"Training and test labels do not match\"\n","\n","    x_tr, x_val, y_tr, y_val = train_test_split(x_train, y_train, test_size=0.2, stratify=y_train, shuffle=True, random_state=seed)\n","\n","    train_loader = get_dataloader(x_tr, y_tr, shuffle=True)\n","    val_loader = get_dataloader(x_val, y_val)\n","    test_loader = get_dataloader(x_test, y_test)\n","\n","    model = TSTRClassifier(num_timesteps=config[dataset]['num_timesteps'],\n","                           num_channels=config[dataset]['num_channels'],\n","                           num_classes=config[dataset]['num_classes'])\n","    initial_lr = 0.0001\n","    optimizer = optim.Adam(model.parameters(), lr=initial_lr)\n","\n","    trained_model = train_model(model, train_loader, val_loader, optimizer, num_epochs, augment)\n","\n","    test_accuracy, test_loss, test_f1 = evaluate_model(trained_model, test_loader)\n","\n","    return test_accuracy, test_loss, test_f1\n","\n","\n","\n","def train_only(x_train, y_train, dataset, num_epochs=100, augment=False):\n","\n","    x_tr, x_val, y_tr, y_val = train_test_split(x_train, y_train, test_size=0.2, stratify=y_train, shuffle=True, random_state=seed)\n","\n","    train_loader = get_dataloader(x_tr, y_tr, shuffle=True)\n","    val_loader = get_dataloader(x_val, y_val)\n","\n","    model = TSTRClassifier(num_timesteps=config[dataset]['num_timesteps'],\n","                           num_channels=config[dataset]['num_channels'],\n","                           num_classes=config[dataset]['num_classes'])\n","    initial_lr = 0.0001\n","    optimizer = optim.Adam(model.parameters(), lr=initial_lr)\n","\n","    trained_model = train_model(model, train_loader, val_loader, optimizer, num_epochs, augment=augment)\n","\n","    return trained_model\n","\n","\n","\n","def train_classifier_cv(x_train, y_train, dataset, num_epochs=100):\n","    skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=seed)\n","\n","    accs = []\n","    losses = []\n","    f1s = []\n","\n","    for train_index, test_index in skf.split(x_train, y_train):\n","        x_train_fold, x_test_fold = x_train[train_index], x_train[test_index]\n","        y_train_fold, y_test_fold = y_train[train_index], y_train[test_index]\n","\n","        acc, loss, f1 = train_and_test(x_train_fold, y_train_fold, x_test_fold, y_test_fold, dataset, num_epochs)\n","        accs.append(acc)\n","        losses.append(loss)\n","        f1s.append(f1)\n","    return np.mean(accs), np.mean(losses), np.mean(f1s)\n","\n","\n","\n","def fine_tune(model, x_train, y_train, num_epochs=100):\n","    # Freeze feature extraction layers\n","    for name, param in model.named_parameters():\n","        if 'conv' in name or 'bn' in name:\n","            param.requires_grad = False\n","\n","    x_tr, x_val, y_tr, y_val = train_test_split(x_train, y_train, test_size=0.2, stratify=y_train, shuffle=True, random_state=seed)\n","\n","    train_loader = get_dataloader(x_tr, y_tr, shuffle=True)\n","    val_loader = get_dataloader(x_val, y_val)\n","\n","    initial_lr = 0.00001\n","    optimizer = optim.Adam(filter(lambda p: p.requires_grad, model.parameters()), lr=initial_lr)\n","\n","    trained_model = train_model(model, train_loader, val_loader, optimizer, num_epochs)\n","\n","    return trained_model\n","\n","\n","\n","def save_scores(source, domain, accuracy, loss, f1, name, dataset):\n","    results_dir = 'results_wal'\n","    # Ensure the directory exists\n","    os.makedirs(results_dir, exist_ok=True)\n","    # Path to the CSV file\n","    file_path = os.path.join(results_dir, f'{dataset}_{name}.csv')\n","    # Check if the file exists\n","    file_exists = os.path.exists(file_path)\n","\n","    # Open the file in append mode if it exists, or write mode if it doesn't\n","    with open(file_path, mode='a' if file_exists else 'w', newline='') as file:\n","        writer = csv.writer(file)\n","        # If the file does not exist, write the header\n","        if not file_exists:\n","            writer.writerow(['source', 'domain', 'accuracy', 'loss', 'f1'])\n","        # Write the data rows\n","        writer.writerow([source, domain, accuracy, loss, f1])"]},{"cell_type":"markdown","metadata":{"id":"PRAlLTPumD5Z"},"source":["# TSTR"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":661735,"status":"ok","timestamp":1732648243062,"user":{"displayName":"Pietro","userId":"07073247908758556229"},"user_tz":-60},"id":"XrDIDrL9CPtn","outputId":"10591af1-cc91-4a4d-c5f9-2f99557c19e4"},"outputs":[{"name":"stdout","output_type":"stream","text":["Source class: WAL\n","\n","Domain: 15\n","x_dp_dom.shape: (161, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Training and evaluating on Dp data via cross-validation...\n","\tEpoch 10/100 - Train loss: 0.2591 - Val accuracy: 0.9231 - Val loss: 0.2175 - Val F1: 0.8866 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.1023 - Val accuracy: 0.9615 - Val loss: 0.0932 - Val F1: 0.9556 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.0799 - Val accuracy: 1.0000 - Val loss: 0.0461 - Val F1: 1.0000 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.0288 - Val accuracy: 1.0000 - Val loss: 0.0301 - Val F1: 1.0000 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.0181 - Val accuracy: 1.0000 - Val loss: 0.0195 - Val F1: 1.0000 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.0192 - Val accuracy: 1.0000 - Val loss: 0.0177 - Val F1: 1.0000 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0161 - Val accuracy: 1.0000 - Val loss: 0.0143 - Val F1: 1.0000 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0080 - Val accuracy: 1.0000 - Val loss: 0.0128 - Val F1: 1.0000 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0114 - Val accuracy: 1.0000 - Val loss: 0.0134 - Val F1: 1.0000 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0120 - Val accuracy: 1.0000 - Val loss: 0.0136 - Val F1: 1.0000 - LR: 0.00e+00\n","\tBest epoch: 77 - Best val accuracy: 1.0000 - Best val loss: 0.0127 - Best val F1: 1.0000\n","\n","\tEpoch 10/100 - Train loss: 0.2692 - Val accuracy: 0.8462 - Val loss: 0.3753 - Val F1: 0.7789 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.1107 - Val accuracy: 0.9231 - Val loss: 0.3687 - Val F1: 0.8866 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.0445 - Val accuracy: 0.9231 - Val loss: 0.4030 - Val F1: 0.8866 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.0249 - Val accuracy: 0.9231 - Val loss: 0.4002 - Val F1: 0.8866 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.0201 - Val accuracy: 0.9231 - Val loss: 0.4356 - Val F1: 0.8866 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.0096 - Val accuracy: 0.9231 - Val loss: 0.4457 - Val F1: 0.8866 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0123 - Val accuracy: 0.9231 - Val loss: 0.4699 - Val F1: 0.8866 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0087 - Val accuracy: 0.9231 - Val loss: 0.4795 - Val F1: 0.8866 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0053 - Val accuracy: 0.9231 - Val loss: 0.4862 - Val F1: 0.8866 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0085 - Val accuracy: 0.9231 - Val loss: 0.4981 - Val F1: 0.8866 - LR: 0.00e+00\n","\tBest epoch: 15 - Best val accuracy: 0.8846 - Best val loss: 0.3567 - Best val F1: 0.8439\n","\n","\tEpoch 10/100 - Train loss: 0.2663 - Val accuracy: 0.8462 - Val loss: 0.2692 - Val F1: 0.7789 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.0910 - Val accuracy: 0.9615 - Val loss: 0.1551 - Val F1: 0.9556 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.0360 - Val accuracy: 0.9615 - Val loss: 0.1433 - Val F1: 0.9556 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.0281 - Val accuracy: 0.9615 - Val loss: 0.1344 - Val F1: 0.9556 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.0140 - Val accuracy: 0.9615 - Val loss: 0.1351 - Val F1: 0.9556 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.0137 - Val accuracy: 0.9615 - Val loss: 0.1394 - Val F1: 0.9556 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0078 - Val accuracy: 0.9615 - Val loss: 0.1648 - Val F1: 0.9556 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0126 - Val accuracy: 0.9615 - Val loss: 0.1593 - Val F1: 0.9556 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0079 - Val accuracy: 0.9615 - Val loss: 0.1601 - Val F1: 0.9556 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0052 - Val accuracy: 0.9615 - Val loss: 0.1615 - Val F1: 0.9556 - LR: 0.00e+00\n","\tBest epoch: 36 - Best val accuracy: 0.9615 - Best val loss: 0.1288 - Best val F1: 0.9556\n","\n","\tEpoch 10/100 - Train loss: 0.2239 - Val accuracy: 0.8462 - Val loss: 0.2693 - Val F1: 0.7789 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.0750 - Val accuracy: 0.9231 - Val loss: 0.1243 - Val F1: 0.8866 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.0327 - Val accuracy: 0.9615 - Val loss: 0.0902 - Val F1: 0.9556 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.0220 - Val accuracy: 0.9615 - Val loss: 0.0675 - Val F1: 0.9556 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.0149 - Val accuracy: 0.9615 - Val loss: 0.0569 - Val F1: 0.9556 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.0112 - Val accuracy: 0.9615 - Val loss: 0.0459 - Val F1: 0.9556 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0148 - Val accuracy: 0.9615 - Val loss: 0.0512 - Val F1: 0.9556 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0093 - Val accuracy: 0.9615 - Val loss: 0.0440 - Val F1: 0.9556 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0070 - Val accuracy: 0.9615 - Val loss: 0.0410 - Val F1: 0.9556 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0087 - Val accuracy: 1.0000 - Val loss: 0.0397 - Val F1: 1.0000 - LR: 0.00e+00\n","\tBest epoch: 99 - Best val accuracy: 1.0000 - Best val loss: 0.0368 - Best val F1: 1.0000\n","\n","\tEpoch 10/100 - Train loss: 0.2524 - Val accuracy: 0.9231 - Val loss: 0.2753 - Val F1: 0.8866 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.1202 - Val accuracy: 0.9231 - Val loss: 0.1499 - Val F1: 0.8866 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.0760 - Val accuracy: 0.9615 - Val loss: 0.0804 - Val F1: 0.9556 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.0316 - Val accuracy: 1.0000 - Val loss: 0.0627 - Val F1: 1.0000 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.0159 - Val accuracy: 1.0000 - Val loss: 0.0390 - Val F1: 1.0000 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.0252 - Val accuracy: 1.0000 - Val loss: 0.0357 - Val F1: 1.0000 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0103 - Val accuracy: 1.0000 - Val loss: 0.0268 - Val F1: 1.0000 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0115 - Val accuracy: 1.0000 - Val loss: 0.0255 - Val F1: 1.0000 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0099 - Val accuracy: 1.0000 - Val loss: 0.0195 - Val F1: 1.0000 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0083 - Val accuracy: 1.0000 - Val loss: 0.0203 - Val F1: 1.0000 - LR: 0.00e+00\n","\tBest epoch: 88 - Best val accuracy: 1.0000 - Best val loss: 0.0188 - Best val F1: 1.0000\n","\n","Source class: WAL | Domain: 15 | Accuracy: 0.9875 | Loss: 0.0676 | F1: 0.9860\n","\n","Domain: 16\n","x_dp_dom.shape: (165, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Training and evaluating on Dp data via cross-validation...\n","\tEpoch 10/100 - Train loss: 0.2975 - Val accuracy: 0.8519 - Val loss: 0.3302 - Val F1: 0.7852 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.0999 - Val accuracy: 0.9259 - Val loss: 0.1674 - Val F1: 0.9155 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.0522 - Val accuracy: 1.0000 - Val loss: 0.1188 - Val F1: 1.0000 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.0256 - Val accuracy: 1.0000 - Val loss: 0.1048 - Val F1: 1.0000 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.0198 - Val accuracy: 1.0000 - Val loss: 0.0883 - Val F1: 1.0000 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.0137 - Val accuracy: 1.0000 - Val loss: 0.0778 - Val F1: 1.0000 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0081 - Val accuracy: 1.0000 - Val loss: 0.0732 - Val F1: 1.0000 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0062 - Val accuracy: 1.0000 - Val loss: 0.0747 - Val F1: 1.0000 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0089 - Val accuracy: 1.0000 - Val loss: 0.0723 - Val F1: 1.0000 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0100 - Val accuracy: 1.0000 - Val loss: 0.0723 - Val F1: 1.0000 - LR: 0.00e+00\n","\tBest epoch: 89 - Best val accuracy: 1.0000 - Best val loss: 0.0701 - Best val F1: 1.0000\n","\n","\tEpoch 10/100 - Train loss: 0.3721 - Val accuracy: 0.8889 - Val loss: 0.3275 - Val F1: 0.8500 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.1526 - Val accuracy: 0.9630 - Val loss: 0.1551 - Val F1: 0.9605 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.0698 - Val accuracy: 0.9630 - Val loss: 0.0987 - Val F1: 0.9605 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.0323 - Val accuracy: 0.9630 - Val loss: 0.0751 - Val F1: 0.9605 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.0222 - Val accuracy: 0.9630 - Val loss: 0.0636 - Val F1: 0.9605 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.0171 - Val accuracy: 0.9630 - Val loss: 0.0598 - Val F1: 0.9605 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0128 - Val accuracy: 0.9630 - Val loss: 0.0524 - Val F1: 0.9605 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0108 - Val accuracy: 0.9630 - Val loss: 0.0532 - Val F1: 0.9605 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0099 - Val accuracy: 0.9630 - Val loss: 0.0522 - Val F1: 0.9605 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0099 - Val accuracy: 0.9630 - Val loss: 0.0519 - Val F1: 0.9605 - LR: 0.00e+00\n","\tBest epoch: 87 - Best val accuracy: 0.9630 - Best val loss: 0.0513 - Best val F1: 0.9605\n","\n","\tEpoch 10/100 - Train loss: 0.3895 - Val accuracy: 0.8519 - Val loss: 0.4495 - Val F1: 0.7852 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.1894 - Val accuracy: 0.8519 - Val loss: 0.2643 - Val F1: 0.8006 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.0837 - Val accuracy: 0.9259 - Val loss: 0.1699 - Val F1: 0.9259 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.0407 - Val accuracy: 0.9630 - Val loss: 0.1372 - Val F1: 0.9605 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.0256 - Val accuracy: 0.9630 - Val loss: 0.1232 - Val F1: 0.9605 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.0175 - Val accuracy: 0.9630 - Val loss: 0.1143 - Val F1: 0.9605 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0096 - Val accuracy: 0.9630 - Val loss: 0.1120 - Val F1: 0.9605 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0120 - Val accuracy: 0.9630 - Val loss: 0.1092 - Val F1: 0.9605 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0110 - Val accuracy: 0.9630 - Val loss: 0.1083 - Val F1: 0.9605 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0114 - Val accuracy: 0.9630 - Val loss: 0.1064 - Val F1: 0.9605 - LR: 0.00e+00\n","\tBest epoch: 99 - Best val accuracy: 0.9630 - Best val loss: 0.1057 - Best val F1: 0.9605\n","\n","\tEpoch 10/100 - Train loss: 0.3194 - Val accuracy: 0.8519 - Val loss: 0.3706 - Val F1: 0.7852 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.1183 - Val accuracy: 0.9630 - Val loss: 0.1614 - Val F1: 0.9573 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.0425 - Val accuracy: 1.0000 - Val loss: 0.1014 - Val F1: 1.0000 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.0235 - Val accuracy: 1.0000 - Val loss: 0.0732 - Val F1: 1.0000 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.0215 - Val accuracy: 1.0000 - Val loss: 0.0567 - Val F1: 1.0000 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.0122 - Val accuracy: 1.0000 - Val loss: 0.0485 - Val F1: 1.0000 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0169 - Val accuracy: 1.0000 - Val loss: 0.0435 - Val F1: 1.0000 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0101 - Val accuracy: 1.0000 - Val loss: 0.0404 - Val F1: 1.0000 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0060 - Val accuracy: 1.0000 - Val loss: 0.0376 - Val F1: 1.0000 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0066 - Val accuracy: 1.0000 - Val loss: 0.0375 - Val F1: 1.0000 - LR: 0.00e+00\n","\tBest epoch: 99 - Best val accuracy: 1.0000 - Best val loss: 0.0372 - Best val F1: 1.0000\n","\n","\tEpoch 10/100 - Train loss: 0.3241 - Val accuracy: 0.8889 - Val loss: 0.3095 - Val F1: 0.8500 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.0969 - Val accuracy: 0.9630 - Val loss: 0.1494 - Val F1: 0.9573 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.0558 - Val accuracy: 0.9630 - Val loss: 0.1054 - Val F1: 0.9573 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.0162 - Val accuracy: 0.9630 - Val loss: 0.0860 - Val F1: 0.9573 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.0117 - Val accuracy: 0.9630 - Val loss: 0.0808 - Val F1: 0.9573 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.0104 - Val accuracy: 0.9630 - Val loss: 0.0709 - Val F1: 0.9573 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0096 - Val accuracy: 1.0000 - Val loss: 0.0617 - Val F1: 1.0000 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0058 - Val accuracy: 0.9630 - Val loss: 0.0642 - Val F1: 0.9573 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0059 - Val accuracy: 0.9630 - Val loss: 0.0621 - Val F1: 0.9573 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0058 - Val accuracy: 0.9630 - Val loss: 0.0627 - Val F1: 0.9573 - LR: 0.00e+00\n","\tBest epoch: 87 - Best val accuracy: 1.0000 - Best val loss: 0.0601 - Best val F1: 1.0000\n","\n","Source class: WAL | Domain: 16 | Accuracy: 0.9879 | Loss: 0.0979 | F1: 0.9851\n","\n","Domain: 17\n","x_dp_dom.shape: (164, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Training and evaluating on Dp data via cross-validation...\n","\tEpoch 10/100 - Train loss: 0.3761 - Val accuracy: 0.9259 - Val loss: 0.3425 - Val F1: 0.8931 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.1569 - Val accuracy: 0.9630 - Val loss: 0.1225 - Val F1: 0.9605 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.0598 - Val accuracy: 0.9630 - Val loss: 0.0741 - Val F1: 0.9605 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.0375 - Val accuracy: 0.9630 - Val loss: 0.0480 - Val F1: 0.9605 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.0244 - Val accuracy: 0.9630 - Val loss: 0.0381 - Val F1: 0.9605 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.0137 - Val accuracy: 1.0000 - Val loss: 0.0320 - Val F1: 1.0000 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0148 - Val accuracy: 1.0000 - Val loss: 0.0271 - Val F1: 1.0000 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0114 - Val accuracy: 1.0000 - Val loss: 0.0255 - Val F1: 1.0000 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0104 - Val accuracy: 1.0000 - Val loss: 0.0269 - Val F1: 1.0000 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0097 - Val accuracy: 1.0000 - Val loss: 0.0264 - Val F1: 1.0000 - LR: 0.00e+00\n","\tBest epoch: 76 - Best val accuracy: 1.0000 - Best val loss: 0.0239 - Best val F1: 1.0000\n","\n","\tEpoch 10/100 - Train loss: 0.2833 - Val accuracy: 0.8519 - Val loss: 0.3186 - Val F1: 0.7852 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.0849 - Val accuracy: 0.9259 - Val loss: 0.1609 - Val F1: 0.9203 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.0336 - Val accuracy: 0.9630 - Val loss: 0.1337 - Val F1: 0.9605 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.0167 - Val accuracy: 0.9630 - Val loss: 0.1208 - Val F1: 0.9605 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.0118 - Val accuracy: 0.9630 - Val loss: 0.1131 - Val F1: 0.9605 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.0108 - Val accuracy: 0.9630 - Val loss: 0.1075 - Val F1: 0.9605 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0059 - Val accuracy: 0.9630 - Val loss: 0.1040 - Val F1: 0.9605 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0049 - Val accuracy: 0.9630 - Val loss: 0.1031 - Val F1: 0.9605 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0074 - Val accuracy: 0.9630 - Val loss: 0.1012 - Val F1: 0.9605 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0081 - Val accuracy: 0.9630 - Val loss: 0.1026 - Val F1: 0.9605 - LR: 0.00e+00\n","\tBest epoch: 94 - Best val accuracy: 0.9630 - Best val loss: 0.1001 - Best val F1: 0.9605\n","\n","\tEpoch 10/100 - Train loss: 0.3228 - Val accuracy: 0.7778 - Val loss: 0.3367 - Val F1: 0.7243 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.1096 - Val accuracy: 0.9630 - Val loss: 0.1398 - Val F1: 0.9605 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.0404 - Val accuracy: 0.9630 - Val loss: 0.0887 - Val F1: 0.9605 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.0187 - Val accuracy: 0.9630 - Val loss: 0.0709 - Val F1: 0.9605 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.0155 - Val accuracy: 0.9630 - Val loss: 0.0573 - Val F1: 0.9605 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.0116 - Val accuracy: 0.9630 - Val loss: 0.0518 - Val F1: 0.9605 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0073 - Val accuracy: 0.9630 - Val loss: 0.0487 - Val F1: 0.9605 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0066 - Val accuracy: 0.9630 - Val loss: 0.0435 - Val F1: 0.9605 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0068 - Val accuracy: 0.9630 - Val loss: 0.0420 - Val F1: 0.9605 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0057 - Val accuracy: 0.9630 - Val loss: 0.0440 - Val F1: 0.9605 - LR: 0.00e+00\n","\tBest epoch: 81 - Best val accuracy: 0.9630 - Best val loss: 0.0417 - Best val F1: 0.9605\n","\n","\tEpoch 10/100 - Train loss: 0.3449 - Val accuracy: 0.8519 - Val loss: 0.3658 - Val F1: 0.7852 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.1308 - Val accuracy: 0.9630 - Val loss: 0.1390 - Val F1: 0.9573 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.0462 - Val accuracy: 1.0000 - Val loss: 0.0729 - Val F1: 1.0000 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.0295 - Val accuracy: 1.0000 - Val loss: 0.0464 - Val F1: 1.0000 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.0204 - Val accuracy: 1.0000 - Val loss: 0.0349 - Val F1: 1.0000 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.0158 - Val accuracy: 1.0000 - Val loss: 0.0286 - Val F1: 1.0000 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0125 - Val accuracy: 1.0000 - Val loss: 0.0249 - Val F1: 1.0000 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0073 - Val accuracy: 1.0000 - Val loss: 0.0258 - Val F1: 1.0000 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0080 - Val accuracy: 1.0000 - Val loss: 0.0229 - Val F1: 1.0000 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0068 - Val accuracy: 1.0000 - Val loss: 0.0218 - Val F1: 1.0000 - LR: 0.00e+00\n","\tBest epoch: 92 - Best val accuracy: 1.0000 - Best val loss: 0.0217 - Best val F1: 1.0000\n","\n","\tEpoch 10/100 - Train loss: 0.3472 - Val accuracy: 0.8519 - Val loss: 0.3705 - Val F1: 0.7852 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.1647 - Val accuracy: 1.0000 - Val loss: 0.1622 - Val F1: 1.0000 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.0760 - Val accuracy: 0.9630 - Val loss: 0.1044 - Val F1: 0.9605 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.0420 - Val accuracy: 1.0000 - Val loss: 0.0692 - Val F1: 1.0000 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.0265 - Val accuracy: 1.0000 - Val loss: 0.0506 - Val F1: 1.0000 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.0169 - Val accuracy: 1.0000 - Val loss: 0.0408 - Val F1: 1.0000 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0162 - Val accuracy: 1.0000 - Val loss: 0.0283 - Val F1: 1.0000 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0144 - Val accuracy: 1.0000 - Val loss: 0.0324 - Val F1: 1.0000 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0104 - Val accuracy: 1.0000 - Val loss: 0.0304 - Val F1: 1.0000 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0084 - Val accuracy: 1.0000 - Val loss: 0.0279 - Val F1: 1.0000 - LR: 0.00e+00\n","\tBest epoch: 99 - Best val accuracy: 1.0000 - Best val loss: 0.0256 - Best val F1: 1.0000\n","\n","Source class: WAL | Domain: 17 | Accuracy: 0.9877 | Loss: 0.0421 | F1: 0.9866\n","\n","Domain: 18\n","x_dp_dom.shape: (166, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Training and evaluating on Dp data via cross-validation...\n","\tEpoch 10/100 - Train loss: 0.2208 - Val accuracy: 0.9259 - Val loss: 0.2410 - Val F1: 0.8931 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.0910 - Val accuracy: 1.0000 - Val loss: 0.0979 - Val F1: 1.0000 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.0452 - Val accuracy: 1.0000 - Val loss: 0.0511 - Val F1: 1.0000 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.0688 - Val accuracy: 1.0000 - Val loss: 0.0385 - Val F1: 1.0000 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.0139 - Val accuracy: 1.0000 - Val loss: 0.0308 - Val F1: 1.0000 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.0112 - Val accuracy: 1.0000 - Val loss: 0.0244 - Val F1: 1.0000 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0082 - Val accuracy: 1.0000 - Val loss: 0.0227 - Val F1: 1.0000 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0087 - Val accuracy: 1.0000 - Val loss: 0.0217 - Val F1: 1.0000 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0086 - Val accuracy: 1.0000 - Val loss: 0.0205 - Val F1: 1.0000 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0065 - Val accuracy: 1.0000 - Val loss: 0.0197 - Val F1: 1.0000 - LR: 0.00e+00\n","\tBest epoch: 96 - Best val accuracy: 1.0000 - Best val loss: 0.0191 - Best val F1: 1.0000\n","\n","\tEpoch 10/100 - Train loss: 0.2446 - Val accuracy: 0.8889 - Val loss: 0.2462 - Val F1: 0.8538 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.1086 - Val accuracy: 1.0000 - Val loss: 0.1061 - Val F1: 1.0000 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.0438 - Val accuracy: 1.0000 - Val loss: 0.0655 - Val F1: 1.0000 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.0231 - Val accuracy: 1.0000 - Val loss: 0.0481 - Val F1: 1.0000 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.0133 - Val accuracy: 1.0000 - Val loss: 0.0383 - Val F1: 1.0000 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.0095 - Val accuracy: 1.0000 - Val loss: 0.0346 - Val F1: 1.0000 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0086 - Val accuracy: 1.0000 - Val loss: 0.0308 - Val F1: 1.0000 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0100 - Val accuracy: 1.0000 - Val loss: 0.0265 - Val F1: 1.0000 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0077 - Val accuracy: 1.0000 - Val loss: 0.0263 - Val F1: 1.0000 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0057 - Val accuracy: 1.0000 - Val loss: 0.0270 - Val F1: 1.0000 - LR: 0.00e+00\n","\tBest epoch: 94 - Best val accuracy: 1.0000 - Best val loss: 0.0255 - Best val F1: 1.0000\n","\n","\tEpoch 10/100 - Train loss: 0.2252 - Val accuracy: 0.9630 - Val loss: 0.2139 - Val F1: 0.9573 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.0792 - Val accuracy: 1.0000 - Val loss: 0.0757 - Val F1: 1.0000 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.0380 - Val accuracy: 1.0000 - Val loss: 0.0431 - Val F1: 1.0000 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.0173 - Val accuracy: 1.0000 - Val loss: 0.0274 - Val F1: 1.0000 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.0116 - Val accuracy: 1.0000 - Val loss: 0.0214 - Val F1: 1.0000 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.0108 - Val accuracy: 1.0000 - Val loss: 0.0184 - Val F1: 1.0000 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0076 - Val accuracy: 1.0000 - Val loss: 0.0162 - Val F1: 1.0000 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0084 - Val accuracy: 1.0000 - Val loss: 0.0154 - Val F1: 1.0000 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0045 - Val accuracy: 1.0000 - Val loss: 0.0144 - Val F1: 1.0000 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0074 - Val accuracy: 1.0000 - Val loss: 0.0138 - Val F1: 1.0000 - LR: 0.00e+00\n","\tBest epoch: 94 - Best val accuracy: 1.0000 - Best val loss: 0.0135 - Best val F1: 1.0000\n","\n","\tEpoch 10/100 - Train loss: 0.2165 - Val accuracy: 0.8889 - Val loss: 0.2157 - Val F1: 0.8635 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.0723 - Val accuracy: 0.8889 - Val loss: 0.1282 - Val F1: 0.8815 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.0434 - Val accuracy: 0.9259 - Val loss: 0.1055 - Val F1: 0.9259 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.0171 - Val accuracy: 0.9259 - Val loss: 0.0935 - Val F1: 0.9259 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.0120 - Val accuracy: 0.9259 - Val loss: 0.0860 - Val F1: 0.9259 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.0125 - Val accuracy: 0.9630 - Val loss: 0.0780 - Val F1: 0.9605 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0050 - Val accuracy: 1.0000 - Val loss: 0.0760 - Val F1: 1.0000 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0063 - Val accuracy: 1.0000 - Val loss: 0.0742 - Val F1: 1.0000 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0047 - Val accuracy: 1.0000 - Val loss: 0.0720 - Val F1: 1.0000 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0049 - Val accuracy: 1.0000 - Val loss: 0.0701 - Val F1: 1.0000 - LR: 0.00e+00\n","\tBest epoch: 99 - Best val accuracy: 1.0000 - Best val loss: 0.0698 - Best val F1: 1.0000\n","\n","\tEpoch 10/100 - Train loss: 0.2453 - Val accuracy: 0.9630 - Val loss: 0.2263 - Val F1: 0.9573 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.0688 - Val accuracy: 1.0000 - Val loss: 0.0966 - Val F1: 1.0000 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.0278 - Val accuracy: 0.9630 - Val loss: 0.0688 - Val F1: 0.9605 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.0157 - Val accuracy: 0.9630 - Val loss: 0.0579 - Val F1: 0.9605 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.0114 - Val accuracy: 0.9630 - Val loss: 0.0514 - Val F1: 0.9605 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.0191 - Val accuracy: 0.9630 - Val loss: 0.0471 - Val F1: 0.9605 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0054 - Val accuracy: 0.9630 - Val loss: 0.0433 - Val F1: 0.9605 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0046 - Val accuracy: 0.9630 - Val loss: 0.0429 - Val F1: 0.9605 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0060 - Val accuracy: 0.9630 - Val loss: 0.0420 - Val F1: 0.9605 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0043 - Val accuracy: 0.9630 - Val loss: 0.0422 - Val F1: 0.9605 - LR: 0.00e+00\n","\tBest epoch: 83 - Best val accuracy: 1.0000 - Best val loss: 0.0411 - Best val F1: 1.0000\n","\n","Source class: WAL | Domain: 18 | Accuracy: 0.9699 | Loss: 0.0537 | F1: 0.9706\n","\n","Domain: 19\n","x_dp_dom.shape: (165, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Training and evaluating on Dp data via cross-validation...\n","\tEpoch 10/100 - Train loss: 0.2492 - Val accuracy: 0.8889 - Val loss: 0.3103 - Val F1: 0.8500 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.0463 - Val accuracy: 0.9630 - Val loss: 0.0931 - Val F1: 0.9573 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.0198 - Val accuracy: 1.0000 - Val loss: 0.0460 - Val F1: 1.0000 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.0103 - Val accuracy: 1.0000 - Val loss: 0.0364 - Val F1: 1.0000 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.0100 - Val accuracy: 1.0000 - Val loss: 0.0279 - Val F1: 1.0000 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.0067 - Val accuracy: 1.0000 - Val loss: 0.0221 - Val F1: 1.0000 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0057 - Val accuracy: 1.0000 - Val loss: 0.0200 - Val F1: 1.0000 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0046 - Val accuracy: 1.0000 - Val loss: 0.0183 - Val F1: 1.0000 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0086 - Val accuracy: 1.0000 - Val loss: 0.0173 - Val F1: 1.0000 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0049 - Val accuracy: 1.0000 - Val loss: 0.0153 - Val F1: 1.0000 - LR: 0.00e+00\n","\tBest epoch: 100 - Best val accuracy: 1.0000 - Best val loss: 0.0153 - Best val F1: 1.0000\n","\n","\tEpoch 10/100 - Train loss: 0.2370 - Val accuracy: 0.8519 - Val loss: 0.2865 - Val F1: 0.7852 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.0630 - Val accuracy: 1.0000 - Val loss: 0.0819 - Val F1: 1.0000 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.0273 - Val accuracy: 1.0000 - Val loss: 0.0458 - Val F1: 1.0000 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.0173 - Val accuracy: 1.0000 - Val loss: 0.0309 - Val F1: 1.0000 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.0231 - Val accuracy: 1.0000 - Val loss: 0.0215 - Val F1: 1.0000 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.0080 - Val accuracy: 1.0000 - Val loss: 0.0165 - Val F1: 1.0000 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0063 - Val accuracy: 1.0000 - Val loss: 0.0153 - Val F1: 1.0000 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0048 - Val accuracy: 1.0000 - Val loss: 0.0156 - Val F1: 1.0000 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0052 - Val accuracy: 1.0000 - Val loss: 0.0148 - Val F1: 1.0000 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0049 - Val accuracy: 1.0000 - Val loss: 0.0144 - Val F1: 1.0000 - LR: 0.00e+00\n","\tBest epoch: 100 - Best val accuracy: 1.0000 - Best val loss: 0.0144 - Best val F1: 1.0000\n","\n","\tEpoch 10/100 - Train loss: 0.2562 - Val accuracy: 0.8519 - Val loss: 0.2891 - Val F1: 0.7852 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.0627 - Val accuracy: 1.0000 - Val loss: 0.0790 - Val F1: 1.0000 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.0304 - Val accuracy: 1.0000 - Val loss: 0.0421 - Val F1: 1.0000 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.0150 - Val accuracy: 1.0000 - Val loss: 0.0281 - Val F1: 1.0000 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.0105 - Val accuracy: 1.0000 - Val loss: 0.0213 - Val F1: 1.0000 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.0063 - Val accuracy: 1.0000 - Val loss: 0.0169 - Val F1: 1.0000 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0063 - Val accuracy: 1.0000 - Val loss: 0.0150 - Val F1: 1.0000 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0061 - Val accuracy: 1.0000 - Val loss: 0.0142 - Val F1: 1.0000 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0055 - Val accuracy: 1.0000 - Val loss: 0.0137 - Val F1: 1.0000 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0064 - Val accuracy: 1.0000 - Val loss: 0.0131 - Val F1: 1.0000 - LR: 0.00e+00\n","\tBest epoch: 96 - Best val accuracy: 1.0000 - Best val loss: 0.0127 - Best val F1: 1.0000\n","\n","\tEpoch 10/100 - Train loss: 0.2794 - Val accuracy: 0.8889 - Val loss: 0.2975 - Val F1: 0.8500 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.0713 - Val accuracy: 1.0000 - Val loss: 0.0789 - Val F1: 1.0000 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.0278 - Val accuracy: 1.0000 - Val loss: 0.0391 - Val F1: 1.0000 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.0187 - Val accuracy: 1.0000 - Val loss: 0.0228 - Val F1: 1.0000 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.0097 - Val accuracy: 1.0000 - Val loss: 0.0171 - Val F1: 1.0000 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.0069 - Val accuracy: 1.0000 - Val loss: 0.0141 - Val F1: 1.0000 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0057 - Val accuracy: 1.0000 - Val loss: 0.0132 - Val F1: 1.0000 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0052 - Val accuracy: 1.0000 - Val loss: 0.0120 - Val F1: 1.0000 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0056 - Val accuracy: 1.0000 - Val loss: 0.0110 - Val F1: 1.0000 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0042 - Val accuracy: 1.0000 - Val loss: 0.0100 - Val F1: 1.0000 - LR: 0.00e+00\n","\tBest epoch: 100 - Best val accuracy: 1.0000 - Best val loss: 0.0100 - Best val F1: 1.0000\n","\n","\tEpoch 10/100 - Train loss: 0.3051 - Val accuracy: 0.8519 - Val loss: 0.3643 - Val F1: 0.7852 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.1016 - Val accuracy: 1.0000 - Val loss: 0.1089 - Val F1: 1.0000 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.0479 - Val accuracy: 1.0000 - Val loss: 0.0553 - Val F1: 1.0000 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.0190 - Val accuracy: 1.0000 - Val loss: 0.0364 - Val F1: 1.0000 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.0132 - Val accuracy: 1.0000 - Val loss: 0.0244 - Val F1: 1.0000 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.0090 - Val accuracy: 1.0000 - Val loss: 0.0215 - Val F1: 1.0000 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0070 - Val accuracy: 1.0000 - Val loss: 0.0195 - Val F1: 1.0000 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0060 - Val accuracy: 1.0000 - Val loss: 0.0164 - Val F1: 1.0000 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0046 - Val accuracy: 1.0000 - Val loss: 0.0165 - Val F1: 1.0000 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0045 - Val accuracy: 1.0000 - Val loss: 0.0152 - Val F1: 1.0000 - LR: 0.00e+00\n","\tBest epoch: 98 - Best val accuracy: 1.0000 - Best val loss: 0.0150 - Best val F1: 1.0000\n","\n","Source class: WAL | Domain: 19 | Accuracy: 0.9939 | Loss: 0.0325 | F1: 0.9943\n","\n","Domain: 20\n","x_dp_dom.shape: (162, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Training and evaluating on Dp data via cross-validation...\n","\tEpoch 10/100 - Train loss: 0.2809 - Val accuracy: 0.8846 - Val loss: 0.2681 - Val F1: 0.8314 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.0992 - Val accuracy: 0.9615 - Val loss: 0.1578 - Val F1: 0.9556 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.0471 - Val accuracy: 0.9615 - Val loss: 0.1017 - Val F1: 0.9556 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.0312 - Val accuracy: 0.9615 - Val loss: 0.0867 - Val F1: 0.9556 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.0140 - Val accuracy: 0.9615 - Val loss: 0.0702 - Val F1: 0.9556 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.0101 - Val accuracy: 0.9615 - Val loss: 0.0588 - Val F1: 0.9556 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0076 - Val accuracy: 1.0000 - Val loss: 0.0482 - Val F1: 1.0000 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0075 - Val accuracy: 1.0000 - Val loss: 0.0449 - Val F1: 1.0000 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0070 - Val accuracy: 0.9615 - Val loss: 0.0459 - Val F1: 0.9556 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0054 - Val accuracy: 1.0000 - Val loss: 0.0419 - Val F1: 1.0000 - LR: 0.00e+00\n","\tBest epoch: 96 - Best val accuracy: 1.0000 - Best val loss: 0.0391 - Best val F1: 1.0000\n","\n","\tEpoch 10/100 - Train loss: 0.2460 - Val accuracy: 0.8462 - Val loss: 0.3992 - Val F1: 0.7769 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.1033 - Val accuracy: 0.8846 - Val loss: 0.2511 - Val F1: 0.8442 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.0554 - Val accuracy: 0.8846 - Val loss: 0.2327 - Val F1: 0.8442 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.0338 - Val accuracy: 0.9231 - Val loss: 0.1806 - Val F1: 0.8866 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.0188 - Val accuracy: 0.9231 - Val loss: 0.1529 - Val F1: 0.8866 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.0156 - Val accuracy: 0.9231 - Val loss: 0.1807 - Val F1: 0.8866 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0132 - Val accuracy: 0.9231 - Val loss: 0.1758 - Val F1: 0.8866 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0162 - Val accuracy: 0.9615 - Val loss: 0.1300 - Val F1: 0.9556 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0081 - Val accuracy: 0.9615 - Val loss: 0.1289 - Val F1: 0.9556 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0086 - Val accuracy: 0.9615 - Val loss: 0.1445 - Val F1: 0.9556 - LR: 0.00e+00\n","\tBest epoch: 84 - Best val accuracy: 0.9615 - Best val loss: 0.1217 - Best val F1: 0.9556\n","\n","\tEpoch 10/100 - Train loss: 0.2622 - Val accuracy: 0.8846 - Val loss: 0.3657 - Val F1: 0.8442 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.1396 - Val accuracy: 0.8846 - Val loss: 0.3017 - Val F1: 0.8442 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.0550 - Val accuracy: 0.8846 - Val loss: 0.2589 - Val F1: 0.8442 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.0219 - Val accuracy: 0.8846 - Val loss: 0.2113 - Val F1: 0.8442 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.0204 - Val accuracy: 0.8846 - Val loss: 0.2319 - Val F1: 0.8442 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.0102 - Val accuracy: 0.8846 - Val loss: 0.2252 - Val F1: 0.8442 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0112 - Val accuracy: 0.9231 - Val loss: 0.2214 - Val F1: 0.8866 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0088 - Val accuracy: 0.9231 - Val loss: 0.2207 - Val F1: 0.8866 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0061 - Val accuracy: 0.9231 - Val loss: 0.2098 - Val F1: 0.8866 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0096 - Val accuracy: 0.9231 - Val loss: 0.2208 - Val F1: 0.8866 - LR: 0.00e+00\n","\tBest epoch: 93 - Best val accuracy: 0.9231 - Best val loss: 0.1985 - Best val F1: 0.8866\n","\n","\tEpoch 10/100 - Train loss: 0.2820 - Val accuracy: 0.8462 - Val loss: 0.4015 - Val F1: 0.7769 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.1058 - Val accuracy: 0.8846 - Val loss: 0.2396 - Val F1: 0.8442 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.0625 - Val accuracy: 0.9231 - Val loss: 0.1719 - Val F1: 0.8866 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.0505 - Val accuracy: 0.9231 - Val loss: 0.1638 - Val F1: 0.8866 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.0189 - Val accuracy: 0.9231 - Val loss: 0.1487 - Val F1: 0.8866 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.0144 - Val accuracy: 0.9231 - Val loss: 0.1436 - Val F1: 0.8866 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0084 - Val accuracy: 0.9231 - Val loss: 0.1221 - Val F1: 0.8866 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0087 - Val accuracy: 0.9231 - Val loss: 0.1155 - Val F1: 0.8866 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0071 - Val accuracy: 0.9231 - Val loss: 0.1163 - Val F1: 0.8866 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0182 - Val accuracy: 0.9231 - Val loss: 0.1310 - Val F1: 0.8866 - LR: 0.00e+00\n","\tBest epoch: 96 - Best val accuracy: 0.9231 - Best val loss: 0.1048 - Best val F1: 0.8866\n","\n","\tEpoch 10/100 - Train loss: 0.2829 - Val accuracy: 0.8846 - Val loss: 0.3813 - Val F1: 0.8442 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.1243 - Val accuracy: 0.8846 - Val loss: 0.2317 - Val F1: 0.8442 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.0512 - Val accuracy: 0.9231 - Val loss: 0.1812 - Val F1: 0.9123 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.0466 - Val accuracy: 0.9231 - Val loss: 0.1389 - Val F1: 0.9123 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.0200 - Val accuracy: 0.9231 - Val loss: 0.1257 - Val F1: 0.9123 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.0126 - Val accuracy: 0.9231 - Val loss: 0.1070 - Val F1: 0.9123 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0108 - Val accuracy: 0.9231 - Val loss: 0.1063 - Val F1: 0.9123 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0105 - Val accuracy: 0.9231 - Val loss: 0.0989 - Val F1: 0.9123 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0073 - Val accuracy: 0.9615 - Val loss: 0.0893 - Val F1: 0.9556 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0071 - Val accuracy: 0.9615 - Val loss: 0.0908 - Val F1: 0.9556 - LR: 0.00e+00\n","\tBest epoch: 99 - Best val accuracy: 0.9615 - Best val loss: 0.0864 - Best val F1: 0.9556\n","\n","Source class: WAL | Domain: 20 | Accuracy: 0.9568 | Loss: 0.0971 | F1: 0.9504\n","\n","Domain: 21\n","x_dp_dom.shape: (159, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Training and evaluating on Dp data via cross-validation...\n","\tEpoch 10/100 - Train loss: 0.2881 - Val accuracy: 0.8846 - Val loss: 0.3450 - Val F1: 0.8314 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.1080 - Val accuracy: 0.8846 - Val loss: 0.1727 - Val F1: 0.8482 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.0431 - Val accuracy: 0.9615 - Val loss: 0.1205 - Val F1: 0.9556 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.0332 - Val accuracy: 1.0000 - Val loss: 0.0997 - Val F1: 1.0000 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.0172 - Val accuracy: 1.0000 - Val loss: 0.0793 - Val F1: 1.0000 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.0119 - Val accuracy: 1.0000 - Val loss: 0.0748 - Val F1: 1.0000 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0108 - Val accuracy: 1.0000 - Val loss: 0.0762 - Val F1: 1.0000 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0102 - Val accuracy: 1.0000 - Val loss: 0.0696 - Val F1: 1.0000 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0073 - Val accuracy: 1.0000 - Val loss: 0.0667 - Val F1: 1.0000 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0074 - Val accuracy: 1.0000 - Val loss: 0.0639 - Val F1: 1.0000 - LR: 0.00e+00\n","\tBest epoch: 94 - Best val accuracy: 1.0000 - Best val loss: 0.0636 - Best val F1: 1.0000\n","\n","\tEpoch 10/100 - Train loss: 0.2954 - Val accuracy: 0.8846 - Val loss: 0.3818 - Val F1: 0.8314 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.1114 - Val accuracy: 0.8846 - Val loss: 0.2085 - Val F1: 0.8482 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.0551 - Val accuracy: 0.8846 - Val loss: 0.1400 - Val F1: 0.8482 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.0184 - Val accuracy: 0.9615 - Val loss: 0.1100 - Val F1: 0.9556 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.0167 - Val accuracy: 1.0000 - Val loss: 0.0875 - Val F1: 1.0000 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.0092 - Val accuracy: 0.9615 - Val loss: 0.0854 - Val F1: 0.9462 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0202 - Val accuracy: 0.9615 - Val loss: 0.0827 - Val F1: 0.9462 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0107 - Val accuracy: 1.0000 - Val loss: 0.0748 - Val F1: 1.0000 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0062 - Val accuracy: 1.0000 - Val loss: 0.0708 - Val F1: 1.0000 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0075 - Val accuracy: 1.0000 - Val loss: 0.0648 - Val F1: 1.0000 - LR: 0.00e+00\n","\tBest epoch: 100 - Best val accuracy: 1.0000 - Best val loss: 0.0648 - Best val F1: 1.0000\n","\n","\tEpoch 10/100 - Train loss: 0.2763 - Val accuracy: 0.8846 - Val loss: 0.3288 - Val F1: 0.8314 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.1139 - Val accuracy: 0.9231 - Val loss: 0.1625 - Val F1: 0.9044 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.0493 - Val accuracy: 1.0000 - Val loss: 0.0932 - Val F1: 1.0000 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.0276 - Val accuracy: 1.0000 - Val loss: 0.0682 - Val F1: 1.0000 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.0124 - Val accuracy: 1.0000 - Val loss: 0.0556 - Val F1: 1.0000 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.0155 - Val accuracy: 1.0000 - Val loss: 0.0483 - Val F1: 1.0000 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0086 - Val accuracy: 1.0000 - Val loss: 0.0447 - Val F1: 1.0000 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0060 - Val accuracy: 1.0000 - Val loss: 0.0429 - Val F1: 1.0000 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0065 - Val accuracy: 1.0000 - Val loss: 0.0411 - Val F1: 1.0000 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0070 - Val accuracy: 1.0000 - Val loss: 0.0407 - Val F1: 1.0000 - LR: 0.00e+00\n","\tBest epoch: 96 - Best val accuracy: 1.0000 - Best val loss: 0.0400 - Best val F1: 1.0000\n","\n","\tEpoch 10/100 - Train loss: 0.2679 - Val accuracy: 0.8846 - Val loss: 0.3087 - Val F1: 0.8314 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.1126 - Val accuracy: 0.9615 - Val loss: 0.1319 - Val F1: 0.9556 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.0453 - Val accuracy: 1.0000 - Val loss: 0.0762 - Val F1: 1.0000 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.0243 - Val accuracy: 1.0000 - Val loss: 0.0551 - Val F1: 1.0000 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.0183 - Val accuracy: 1.0000 - Val loss: 0.0467 - Val F1: 1.0000 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.0172 - Val accuracy: 1.0000 - Val loss: 0.0394 - Val F1: 1.0000 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0119 - Val accuracy: 1.0000 - Val loss: 0.0392 - Val F1: 1.0000 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0089 - Val accuracy: 1.0000 - Val loss: 0.0348 - Val F1: 1.0000 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0081 - Val accuracy: 1.0000 - Val loss: 0.0338 - Val F1: 1.0000 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0073 - Val accuracy: 1.0000 - Val loss: 0.0332 - Val F1: 1.0000 - LR: 0.00e+00\n","\tBest epoch: 99 - Best val accuracy: 1.0000 - Best val loss: 0.0326 - Best val F1: 1.0000\n","\n","\tEpoch 10/100 - Train loss: 0.2577 - Val accuracy: 0.8846 - Val loss: 0.3276 - Val F1: 0.8314 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.1211 - Val accuracy: 0.9231 - Val loss: 0.1479 - Val F1: 0.9044 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.0496 - Val accuracy: 1.0000 - Val loss: 0.0967 - Val F1: 1.0000 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.0227 - Val accuracy: 1.0000 - Val loss: 0.0693 - Val F1: 1.0000 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.0161 - Val accuracy: 1.0000 - Val loss: 0.0559 - Val F1: 1.0000 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.0103 - Val accuracy: 1.0000 - Val loss: 0.0500 - Val F1: 1.0000 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0101 - Val accuracy: 1.0000 - Val loss: 0.0435 - Val F1: 1.0000 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0079 - Val accuracy: 1.0000 - Val loss: 0.0416 - Val F1: 1.0000 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0078 - Val accuracy: 1.0000 - Val loss: 0.0401 - Val F1: 1.0000 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0090 - Val accuracy: 1.0000 - Val loss: 0.0391 - Val F1: 1.0000 - LR: 0.00e+00\n","\tBest epoch: 100 - Best val accuracy: 1.0000 - Best val loss: 0.0391 - Best val F1: 1.0000\n","\n","Source class: WAL | Domain: 21 | Accuracy: 0.9750 | Loss: 0.0580 | F1: 0.9699\n","\n","Domain: 22\n","x_dp_dom.shape: (165, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Training and evaluating on Dp data via cross-validation...\n","\tEpoch 10/100 - Train loss: 0.3577 - Val accuracy: 0.8519 - Val loss: 0.4039 - Val F1: 0.7852 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.1523 - Val accuracy: 0.8889 - Val loss: 0.2259 - Val F1: 0.8500 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.0545 - Val accuracy: 0.9259 - Val loss: 0.1386 - Val F1: 0.9203 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.0330 - Val accuracy: 0.9259 - Val loss: 0.1166 - Val F1: 0.9203 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.0193 - Val accuracy: 0.9259 - Val loss: 0.1031 - Val F1: 0.9203 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.0126 - Val accuracy: 0.9259 - Val loss: 0.0957 - Val F1: 0.9203 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0095 - Val accuracy: 0.9259 - Val loss: 0.0911 - Val F1: 0.9203 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0104 - Val accuracy: 0.9259 - Val loss: 0.0951 - Val F1: 0.9203 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0092 - Val accuracy: 0.9259 - Val loss: 0.0915 - Val F1: 0.9203 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0083 - Val accuracy: 0.9259 - Val loss: 0.0875 - Val F1: 0.9203 - LR: 0.00e+00\n","\tBest epoch: 67 - Best val accuracy: 0.9630 - Best val loss: 0.0865 - Best val F1: 0.9605\n","\n","\tEpoch 10/100 - Train loss: 0.3100 - Val accuracy: 0.8889 - Val loss: 0.3662 - Val F1: 0.8500 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.0960 - Val accuracy: 0.9630 - Val loss: 0.1465 - Val F1: 0.9605 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.0507 - Val accuracy: 1.0000 - Val loss: 0.0848 - Val F1: 1.0000 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.0527 - Val accuracy: 0.9630 - Val loss: 0.0716 - Val F1: 0.9605 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.0170 - Val accuracy: 1.0000 - Val loss: 0.0561 - Val F1: 1.0000 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.0143 - Val accuracy: 1.0000 - Val loss: 0.0492 - Val F1: 1.0000 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0095 - Val accuracy: 1.0000 - Val loss: 0.0467 - Val F1: 1.0000 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0094 - Val accuracy: 1.0000 - Val loss: 0.0414 - Val F1: 1.0000 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0143 - Val accuracy: 1.0000 - Val loss: 0.0404 - Val F1: 1.0000 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0075 - Val accuracy: 1.0000 - Val loss: 0.0399 - Val F1: 1.0000 - LR: 0.00e+00\n","\tBest epoch: 95 - Best val accuracy: 1.0000 - Best val loss: 0.0380 - Best val F1: 1.0000\n","\n","\tEpoch 10/100 - Train loss: 0.3443 - Val accuracy: 0.8519 - Val loss: 0.4069 - Val F1: 0.7852 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.1421 - Val accuracy: 0.8889 - Val loss: 0.2629 - Val F1: 0.8500 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.0554 - Val accuracy: 0.9630 - Val loss: 0.1904 - Val F1: 0.9573 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.0300 - Val accuracy: 0.9630 - Val loss: 0.1675 - Val F1: 0.9573 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.0228 - Val accuracy: 0.9630 - Val loss: 0.1664 - Val F1: 0.9573 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.0199 - Val accuracy: 0.9630 - Val loss: 0.1457 - Val F1: 0.9573 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0095 - Val accuracy: 0.9630 - Val loss: 0.1516 - Val F1: 0.9573 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0070 - Val accuracy: 0.9630 - Val loss: 0.1498 - Val F1: 0.9573 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0098 - Val accuracy: 0.9630 - Val loss: 0.1476 - Val F1: 0.9573 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0079 - Val accuracy: 0.9630 - Val loss: 0.1478 - Val F1: 0.9573 - LR: 0.00e+00\n","\tBest epoch: 60 - Best val accuracy: 0.9630 - Best val loss: 0.1457 - Best val F1: 0.9573\n","\n","\tEpoch 10/100 - Train loss: 0.3180 - Val accuracy: 0.8519 - Val loss: 0.4484 - Val F1: 0.7852 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.1366 - Val accuracy: 0.8519 - Val loss: 0.2552 - Val F1: 0.7852 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.0455 - Val accuracy: 0.9259 - Val loss: 0.1698 - Val F1: 0.8931 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.0310 - Val accuracy: 0.9259 - Val loss: 0.1601 - Val F1: 0.8931 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.0208 - Val accuracy: 0.9259 - Val loss: 0.1498 - Val F1: 0.8931 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.0195 - Val accuracy: 0.9259 - Val loss: 0.1251 - Val F1: 0.8931 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0098 - Val accuracy: 0.9259 - Val loss: 0.1353 - Val F1: 0.8931 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0108 - Val accuracy: 0.9259 - Val loss: 0.1271 - Val F1: 0.8931 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0069 - Val accuracy: 0.9259 - Val loss: 0.1236 - Val F1: 0.8931 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0061 - Val accuracy: 0.9259 - Val loss: 0.1289 - Val F1: 0.8931 - LR: 0.00e+00\n","\tBest epoch: 76 - Best val accuracy: 0.9259 - Best val loss: 0.1201 - Best val F1: 0.8931\n","\n","\tEpoch 10/100 - Train loss: 0.3791 - Val accuracy: 0.8519 - Val loss: 0.4320 - Val F1: 0.7852 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.1701 - Val accuracy: 0.8519 - Val loss: 0.3073 - Val F1: 0.7852 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.0555 - Val accuracy: 0.9259 - Val loss: 0.2496 - Val F1: 0.9155 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.0298 - Val accuracy: 0.9630 - Val loss: 0.2174 - Val F1: 0.9573 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.0162 - Val accuracy: 0.9630 - Val loss: 0.2312 - Val F1: 0.9573 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.0119 - Val accuracy: 0.9630 - Val loss: 0.2199 - Val F1: 0.9573 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0124 - Val accuracy: 0.9630 - Val loss: 0.2130 - Val F1: 0.9573 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0085 - Val accuracy: 0.9630 - Val loss: 0.2201 - Val F1: 0.9573 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0097 - Val accuracy: 0.9630 - Val loss: 0.2136 - Val F1: 0.9573 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0097 - Val accuracy: 0.9630 - Val loss: 0.2194 - Val F1: 0.9573 - LR: 0.00e+00\n","\tBest epoch: 66 - Best val accuracy: 0.9630 - Best val loss: 0.2077 - Best val F1: 0.9573\n","\n","Source class: WAL | Domain: 22 | Accuracy: 0.9636 | Loss: 0.1391 | F1: 0.9586\n","\n","Domain: 23\n","x_dp_dom.shape: (164, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Training and evaluating on Dp data via cross-validation...\n","\tEpoch 10/100 - Train loss: 0.3725 - Val accuracy: 0.8519 - Val loss: 0.3775 - Val F1: 0.7852 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.1554 - Val accuracy: 0.9630 - Val loss: 0.1826 - Val F1: 0.9573 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.0680 - Val accuracy: 0.9630 - Val loss: 0.1138 - Val F1: 0.9605 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.0736 - Val accuracy: 0.9630 - Val loss: 0.0863 - Val F1: 0.9605 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.0220 - Val accuracy: 0.9630 - Val loss: 0.0753 - Val F1: 0.9605 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.0195 - Val accuracy: 0.9630 - Val loss: 0.0680 - Val F1: 0.9605 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0129 - Val accuracy: 0.9630 - Val loss: 0.0619 - Val F1: 0.9605 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0099 - Val accuracy: 0.9630 - Val loss: 0.0620 - Val F1: 0.9605 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0094 - Val accuracy: 0.9630 - Val loss: 0.0591 - Val F1: 0.9605 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0090 - Val accuracy: 0.9630 - Val loss: 0.0592 - Val F1: 0.9605 - LR: 0.00e+00\n","\tBest epoch: 96 - Best val accuracy: 0.9630 - Best val loss: 0.0580 - Best val F1: 0.9605\n","\n","\tEpoch 10/100 - Train loss: 0.3198 - Val accuracy: 0.8519 - Val loss: 0.3469 - Val F1: 0.7852 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.1400 - Val accuracy: 0.9630 - Val loss: 0.1824 - Val F1: 0.9573 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.0531 - Val accuracy: 0.9630 - Val loss: 0.1313 - Val F1: 0.9573 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.0339 - Val accuracy: 0.9630 - Val loss: 0.1107 - Val F1: 0.9573 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.0273 - Val accuracy: 0.9630 - Val loss: 0.0980 - Val F1: 0.9605 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.0116 - Val accuracy: 0.9630 - Val loss: 0.0936 - Val F1: 0.9605 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0108 - Val accuracy: 0.9630 - Val loss: 0.0930 - Val F1: 0.9605 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0088 - Val accuracy: 0.9630 - Val loss: 0.0894 - Val F1: 0.9605 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0092 - Val accuracy: 0.9630 - Val loss: 0.0903 - Val F1: 0.9605 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0079 - Val accuracy: 0.9630 - Val loss: 0.0868 - Val F1: 0.9605 - LR: 0.00e+00\n","\tBest epoch: 84 - Best val accuracy: 0.9630 - Best val loss: 0.0847 - Best val F1: 0.9605\n","\n","\tEpoch 10/100 - Train loss: 0.3324 - Val accuracy: 0.8519 - Val loss: 0.3334 - Val F1: 0.7848 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.1646 - Val accuracy: 0.9630 - Val loss: 0.1687 - Val F1: 0.9573 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.0720 - Val accuracy: 0.9630 - Val loss: 0.1056 - Val F1: 0.9573 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.0409 - Val accuracy: 1.0000 - Val loss: 0.0836 - Val F1: 1.0000 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.0560 - Val accuracy: 1.0000 - Val loss: 0.0713 - Val F1: 1.0000 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.0174 - Val accuracy: 1.0000 - Val loss: 0.0604 - Val F1: 1.0000 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0156 - Val accuracy: 1.0000 - Val loss: 0.0571 - Val F1: 1.0000 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0107 - Val accuracy: 1.0000 - Val loss: 0.0533 - Val F1: 1.0000 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0123 - Val accuracy: 1.0000 - Val loss: 0.0518 - Val F1: 1.0000 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0118 - Val accuracy: 1.0000 - Val loss: 0.0482 - Val F1: 1.0000 - LR: 0.00e+00\n","\tBest epoch: 94 - Best val accuracy: 1.0000 - Best val loss: 0.0470 - Best val F1: 1.0000\n","\n","\tEpoch 10/100 - Train loss: 0.2911 - Val accuracy: 0.8519 - Val loss: 0.3400 - Val F1: 0.7848 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.1183 - Val accuracy: 0.9259 - Val loss: 0.1717 - Val F1: 0.8931 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.0607 - Val accuracy: 0.9630 - Val loss: 0.1272 - Val F1: 0.9605 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.0261 - Val accuracy: 0.9630 - Val loss: 0.1133 - Val F1: 0.9605 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.0208 - Val accuracy: 0.9630 - Val loss: 0.1083 - Val F1: 0.9605 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.0117 - Val accuracy: 0.9630 - Val loss: 0.0973 - Val F1: 0.9605 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0135 - Val accuracy: 0.9630 - Val loss: 0.0980 - Val F1: 0.9605 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0080 - Val accuracy: 0.9630 - Val loss: 0.1014 - Val F1: 0.9605 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0073 - Val accuracy: 0.9630 - Val loss: 0.0966 - Val F1: 0.9605 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0118 - Val accuracy: 0.9630 - Val loss: 0.0983 - Val F1: 0.9605 - LR: 0.00e+00\n","\tBest epoch: 75 - Best val accuracy: 0.9630 - Best val loss: 0.0944 - Best val F1: 0.9605\n","\n","\tEpoch 10/100 - Train loss: 0.3061 - Val accuracy: 0.8519 - Val loss: 0.3081 - Val F1: 0.7852 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.1271 - Val accuracy: 1.0000 - Val loss: 0.1375 - Val F1: 1.0000 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.0496 - Val accuracy: 1.0000 - Val loss: 0.0931 - Val F1: 1.0000 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.0334 - Val accuracy: 1.0000 - Val loss: 0.0768 - Val F1: 1.0000 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.0201 - Val accuracy: 1.0000 - Val loss: 0.0721 - Val F1: 1.0000 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.0143 - Val accuracy: 1.0000 - Val loss: 0.0624 - Val F1: 1.0000 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0109 - Val accuracy: 1.0000 - Val loss: 0.0618 - Val F1: 1.0000 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0082 - Val accuracy: 1.0000 - Val loss: 0.0558 - Val F1: 1.0000 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0069 - Val accuracy: 1.0000 - Val loss: 0.0576 - Val F1: 1.0000 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0101 - Val accuracy: 1.0000 - Val loss: 0.0559 - Val F1: 1.0000 - LR: 0.00e+00\n","\tBest epoch: 93 - Best val accuracy: 1.0000 - Best val loss: 0.0557 - Best val F1: 1.0000\n","\n","Source class: WAL | Domain: 23 | Accuracy: 0.9390 | Loss: 0.1351 | F1: 0.9281\n","\n","Domain: 24\n","x_dp_dom.shape: (162, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Training and evaluating on Dp data via cross-validation...\n","\tEpoch 10/100 - Train loss: 0.3187 - Val accuracy: 0.8846 - Val loss: 0.2732 - Val F1: 0.8314 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.1211 - Val accuracy: 0.9615 - Val loss: 0.1294 - Val F1: 0.9615 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.0712 - Val accuracy: 1.0000 - Val loss: 0.0876 - Val F1: 1.0000 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.0430 - Val accuracy: 1.0000 - Val loss: 0.0724 - Val F1: 1.0000 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.0299 - Val accuracy: 1.0000 - Val loss: 0.0597 - Val F1: 1.0000 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.0256 - Val accuracy: 0.9615 - Val loss: 0.0590 - Val F1: 0.9615 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0172 - Val accuracy: 1.0000 - Val loss: 0.0540 - Val F1: 1.0000 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0134 - Val accuracy: 1.0000 - Val loss: 0.0495 - Val F1: 1.0000 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0144 - Val accuracy: 1.0000 - Val loss: 0.0478 - Val F1: 1.0000 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0118 - Val accuracy: 1.0000 - Val loss: 0.0466 - Val F1: 1.0000 - LR: 0.00e+00\n","\tBest epoch: 99 - Best val accuracy: 1.0000 - Best val loss: 0.0458 - Best val F1: 1.0000\n","\n","\tEpoch 10/100 - Train loss: 0.3172 - Val accuracy: 0.8462 - Val loss: 0.3479 - Val F1: 0.7769 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.2027 - Val accuracy: 0.9615 - Val loss: 0.1806 - Val F1: 0.9590 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.0847 - Val accuracy: 1.0000 - Val loss: 0.1114 - Val F1: 1.0000 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.0484 - Val accuracy: 1.0000 - Val loss: 0.0768 - Val F1: 1.0000 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.0288 - Val accuracy: 1.0000 - Val loss: 0.0597 - Val F1: 1.0000 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.0252 - Val accuracy: 1.0000 - Val loss: 0.0495 - Val F1: 1.0000 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0138 - Val accuracy: 1.0000 - Val loss: 0.0436 - Val F1: 1.0000 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0130 - Val accuracy: 1.0000 - Val loss: 0.0375 - Val F1: 1.0000 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0115 - Val accuracy: 1.0000 - Val loss: 0.0355 - Val F1: 1.0000 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0095 - Val accuracy: 1.0000 - Val loss: 0.0353 - Val F1: 1.0000 - LR: 0.00e+00\n","\tBest epoch: 98 - Best val accuracy: 1.0000 - Best val loss: 0.0348 - Best val F1: 1.0000\n","\n","\tEpoch 10/100 - Train loss: 0.3353 - Val accuracy: 0.8462 - Val loss: 0.3743 - Val F1: 0.7769 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.1771 - Val accuracy: 0.8846 - Val loss: 0.2087 - Val F1: 0.8482 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.0861 - Val accuracy: 1.0000 - Val loss: 0.1288 - Val F1: 1.0000 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.0344 - Val accuracy: 1.0000 - Val loss: 0.0870 - Val F1: 1.0000 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.0207 - Val accuracy: 1.0000 - Val loss: 0.0594 - Val F1: 1.0000 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.0107 - Val accuracy: 1.0000 - Val loss: 0.0481 - Val F1: 1.0000 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0117 - Val accuracy: 1.0000 - Val loss: 0.0409 - Val F1: 1.0000 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0098 - Val accuracy: 1.0000 - Val loss: 0.0352 - Val F1: 1.0000 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0083 - Val accuracy: 1.0000 - Val loss: 0.0344 - Val F1: 1.0000 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0080 - Val accuracy: 1.0000 - Val loss: 0.0323 - Val F1: 1.0000 - LR: 0.00e+00\n","\tBest epoch: 100 - Best val accuracy: 1.0000 - Best val loss: 0.0323 - Best val F1: 1.0000\n","\n","\tEpoch 10/100 - Train loss: 0.3501 - Val accuracy: 0.8077 - Val loss: 0.4376 - Val F1: 0.7397 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.1501 - Val accuracy: 0.8846 - Val loss: 0.2787 - Val F1: 0.8567 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.0672 - Val accuracy: 0.9615 - Val loss: 0.2381 - Val F1: 0.9593 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.0362 - Val accuracy: 0.9615 - Val loss: 0.2331 - Val F1: 0.9593 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.0279 - Val accuracy: 0.9615 - Val loss: 0.2337 - Val F1: 0.9593 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.0147 - Val accuracy: 0.9615 - Val loss: 0.2281 - Val F1: 0.9593 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0138 - Val accuracy: 0.9615 - Val loss: 0.2434 - Val F1: 0.9593 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0116 - Val accuracy: 0.9615 - Val loss: 0.2335 - Val F1: 0.9593 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0117 - Val accuracy: 0.9615 - Val loss: 0.2331 - Val F1: 0.9593 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0072 - Val accuracy: 0.9615 - Val loss: 0.2280 - Val F1: 0.9593 - LR: 0.00e+00\n","\tBest epoch: 58 - Best val accuracy: 0.9615 - Best val loss: 0.2160 - Best val F1: 0.9593\n","\n","\tEpoch 10/100 - Train loss: 0.3061 - Val accuracy: 0.8462 - Val loss: 0.3380 - Val F1: 0.7769 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.1699 - Val accuracy: 0.9615 - Val loss: 0.1960 - Val F1: 0.9556 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.0774 - Val accuracy: 1.0000 - Val loss: 0.1296 - Val F1: 1.0000 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.0695 - Val accuracy: 1.0000 - Val loss: 0.1037 - Val F1: 1.0000 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.0352 - Val accuracy: 1.0000 - Val loss: 0.0877 - Val F1: 1.0000 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.0137 - Val accuracy: 1.0000 - Val loss: 0.0819 - Val F1: 1.0000 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0157 - Val accuracy: 0.9615 - Val loss: 0.0781 - Val F1: 0.9590 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0160 - Val accuracy: 1.0000 - Val loss: 0.0726 - Val F1: 1.0000 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0102 - Val accuracy: 0.9615 - Val loss: 0.0739 - Val F1: 0.9590 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0127 - Val accuracy: 0.9615 - Val loss: 0.0732 - Val F1: 0.9590 - LR: 0.00e+00\n","\tBest epoch: 95 - Best val accuracy: 1.0000 - Best val loss: 0.0720 - Best val F1: 1.0000\n","\n","Source class: WAL | Domain: 24 | Accuracy: 0.9693 | Loss: 0.0982 | F1: 0.9688\n","\n","Domain: 25\n","x_dp_dom.shape: (166, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Training and evaluating on Dp data via cross-validation...\n","\tEpoch 10/100 - Train loss: 0.3031 - Val accuracy: 0.8519 - Val loss: 0.3032 - Val F1: 0.7852 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.1044 - Val accuracy: 0.9630 - Val loss: 0.1303 - Val F1: 0.9605 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.0512 - Val accuracy: 0.9630 - Val loss: 0.1043 - Val F1: 0.9605 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.0302 - Val accuracy: 0.9630 - Val loss: 0.0977 - Val F1: 0.9605 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.0183 - Val accuracy: 0.9630 - Val loss: 0.0984 - Val F1: 0.9605 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.0129 - Val accuracy: 0.9630 - Val loss: 0.1032 - Val F1: 0.9605 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0118 - Val accuracy: 0.9630 - Val loss: 0.1022 - Val F1: 0.9605 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0083 - Val accuracy: 0.9630 - Val loss: 0.1071 - Val F1: 0.9605 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0086 - Val accuracy: 0.9630 - Val loss: 0.1075 - Val F1: 0.9605 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0084 - Val accuracy: 0.9630 - Val loss: 0.1098 - Val F1: 0.9605 - LR: 0.00e+00\n","\tBest epoch: 39 - Best val accuracy: 0.9630 - Best val loss: 0.0948 - Best val F1: 0.9605\n","\n","\tEpoch 10/100 - Train loss: 0.2384 - Val accuracy: 0.9259 - Val loss: 0.2233 - Val F1: 0.8908 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.0800 - Val accuracy: 1.0000 - Val loss: 0.0851 - Val F1: 1.0000 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.0381 - Val accuracy: 1.0000 - Val loss: 0.0535 - Val F1: 1.0000 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.0182 - Val accuracy: 0.9630 - Val loss: 0.0444 - Val F1: 0.9605 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.0214 - Val accuracy: 1.0000 - Val loss: 0.0328 - Val F1: 1.0000 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.0121 - Val accuracy: 1.0000 - Val loss: 0.0307 - Val F1: 1.0000 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0111 - Val accuracy: 1.0000 - Val loss: 0.0279 - Val F1: 1.0000 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0078 - Val accuracy: 1.0000 - Val loss: 0.0276 - Val F1: 1.0000 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0070 - Val accuracy: 1.0000 - Val loss: 0.0244 - Val F1: 1.0000 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0070 - Val accuracy: 1.0000 - Val loss: 0.0241 - Val F1: 1.0000 - LR: 0.00e+00\n","\tBest epoch: 96 - Best val accuracy: 1.0000 - Best val loss: 0.0224 - Best val F1: 1.0000\n","\n","\tEpoch 10/100 - Train loss: 0.2485 - Val accuracy: 0.8519 - Val loss: 0.2725 - Val F1: 0.7852 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.0997 - Val accuracy: 0.9259 - Val loss: 0.1519 - Val F1: 0.9012 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.0410 - Val accuracy: 0.9630 - Val loss: 0.1315 - Val F1: 0.9605 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.0274 - Val accuracy: 0.9630 - Val loss: 0.1205 - Val F1: 0.9605 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.0134 - Val accuracy: 0.9630 - Val loss: 0.1166 - Val F1: 0.9605 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.0108 - Val accuracy: 0.9630 - Val loss: 0.1172 - Val F1: 0.9605 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0079 - Val accuracy: 0.9630 - Val loss: 0.1153 - Val F1: 0.9605 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0064 - Val accuracy: 0.9630 - Val loss: 0.1186 - Val F1: 0.9605 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0066 - Val accuracy: 0.9630 - Val loss: 0.1162 - Val F1: 0.9605 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0064 - Val accuracy: 0.9630 - Val loss: 0.1178 - Val F1: 0.9605 - LR: 0.00e+00\n","\tBest epoch: 98 - Best val accuracy: 0.9630 - Best val loss: 0.1137 - Best val F1: 0.9605\n","\n","\tEpoch 10/100 - Train loss: 0.2877 - Val accuracy: 0.8889 - Val loss: 0.2811 - Val F1: 0.8538 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.1095 - Val accuracy: 0.9630 - Val loss: 0.1383 - Val F1: 0.9605 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.0665 - Val accuracy: 0.9630 - Val loss: 0.0946 - Val F1: 0.9605 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.0242 - Val accuracy: 0.9630 - Val loss: 0.0698 - Val F1: 0.9605 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.0178 - Val accuracy: 0.9630 - Val loss: 0.0500 - Val F1: 0.9605 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.0098 - Val accuracy: 0.9630 - Val loss: 0.0431 - Val F1: 0.9605 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0110 - Val accuracy: 1.0000 - Val loss: 0.0363 - Val F1: 1.0000 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0065 - Val accuracy: 1.0000 - Val loss: 0.0346 - Val F1: 1.0000 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0076 - Val accuracy: 1.0000 - Val loss: 0.0329 - Val F1: 1.0000 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0056 - Val accuracy: 1.0000 - Val loss: 0.0314 - Val F1: 1.0000 - LR: 0.00e+00\n","\tBest epoch: 97 - Best val accuracy: 1.0000 - Best val loss: 0.0303 - Best val F1: 1.0000\n","\n","\tEpoch 10/100 - Train loss: 0.2366 - Val accuracy: 0.9259 - Val loss: 0.2521 - Val F1: 0.8931 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.1084 - Val accuracy: 0.9630 - Val loss: 0.1139 - Val F1: 0.9605 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.0615 - Val accuracy: 1.0000 - Val loss: 0.0712 - Val F1: 1.0000 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.0319 - Val accuracy: 1.0000 - Val loss: 0.0455 - Val F1: 1.0000 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.0175 - Val accuracy: 1.0000 - Val loss: 0.0297 - Val F1: 1.0000 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.0114 - Val accuracy: 1.0000 - Val loss: 0.0210 - Val F1: 1.0000 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0094 - Val accuracy: 1.0000 - Val loss: 0.0173 - Val F1: 1.0000 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0091 - Val accuracy: 1.0000 - Val loss: 0.0153 - Val F1: 1.0000 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0066 - Val accuracy: 1.0000 - Val loss: 0.0139 - Val F1: 1.0000 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0082 - Val accuracy: 1.0000 - Val loss: 0.0145 - Val F1: 1.0000 - LR: 0.00e+00\n","\tBest epoch: 91 - Best val accuracy: 1.0000 - Best val loss: 0.0134 - Best val F1: 1.0000\n","\n","Source class: WAL | Domain: 25 | Accuracy: 0.9939 | Loss: 0.0590 | F1: 0.9934\n","\n","Domain: 26\n","x_dp_dom.shape: (153, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Training and evaluating on Dp data via cross-validation...\n","\tEpoch 10/100 - Train loss: 0.8921 - Val accuracy: 0.7200 - Val loss: 1.3456 - Val F1: 0.6028 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.5284 - Val accuracy: 0.7200 - Val loss: 1.1772 - Val F1: 0.6028 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.3840 - Val accuracy: 0.7200 - Val loss: 1.0360 - Val F1: 0.6028 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.2941 - Val accuracy: 0.7200 - Val loss: 0.9309 - Val F1: 0.6028 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.2562 - Val accuracy: 0.7200 - Val loss: 0.6496 - Val F1: 0.6028 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.2208 - Val accuracy: 0.9200 - Val loss: 0.3333 - Val F1: 0.8821 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.2030 - Val accuracy: 0.9200 - Val loss: 0.2538 - Val F1: 0.8821 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.1816 - Val accuracy: 0.9200 - Val loss: 0.2321 - Val F1: 0.8821 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.1799 - Val accuracy: 0.9200 - Val loss: 0.2232 - Val F1: 0.8821 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.1705 - Val accuracy: 0.9200 - Val loss: 0.2204 - Val F1: 0.8821 - LR: 0.00e+00\n","\tBest epoch: 100 - Best val accuracy: 0.9200 - Best val loss: 0.2204 - Best val F1: 0.8821\n","\n","\tEpoch 10/100 - Train loss: 0.7842 - Val accuracy: 0.7200 - Val loss: 1.1820 - Val F1: 0.6028 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.4885 - Val accuracy: 0.7200 - Val loss: 0.9640 - Val F1: 0.6028 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.3423 - Val accuracy: 0.7200 - Val loss: 0.9031 - Val F1: 0.6028 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.2480 - Val accuracy: 0.7200 - Val loss: 0.8568 - Val F1: 0.6028 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.1961 - Val accuracy: 0.7200 - Val loss: 0.6088 - Val F1: 0.6028 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.1708 - Val accuracy: 0.8400 - Val loss: 0.3981 - Val F1: 0.7980 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.1349 - Val accuracy: 0.9200 - Val loss: 0.3077 - Val F1: 0.8821 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.1230 - Val accuracy: 0.9200 - Val loss: 0.2710 - Val F1: 0.8821 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.1142 - Val accuracy: 0.9200 - Val loss: 0.2552 - Val F1: 0.8821 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.1121 - Val accuracy: 0.9200 - Val loss: 0.2495 - Val F1: 0.8821 - LR: 0.00e+00\n","\tBest epoch: 100 - Best val accuracy: 0.9200 - Best val loss: 0.2495 - Best val F1: 0.8821\n","\n","\tEpoch 10/100 - Train loss: 0.7402 - Val accuracy: 0.7200 - Val loss: 1.2946 - Val F1: 0.6028 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.4775 - Val accuracy: 0.7200 - Val loss: 1.0957 - Val F1: 0.6028 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.3555 - Val accuracy: 0.7200 - Val loss: 0.9335 - Val F1: 0.6028 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.2772 - Val accuracy: 0.7200 - Val loss: 0.8418 - Val F1: 0.6028 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.2437 - Val accuracy: 0.7200 - Val loss: 0.5557 - Val F1: 0.6028 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.1991 - Val accuracy: 0.9200 - Val loss: 0.3304 - Val F1: 0.8821 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.1819 - Val accuracy: 0.9200 - Val loss: 0.2750 - Val F1: 0.8821 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.1718 - Val accuracy: 0.9200 - Val loss: 0.2579 - Val F1: 0.8821 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.1586 - Val accuracy: 0.9200 - Val loss: 0.2513 - Val F1: 0.8821 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.1527 - Val accuracy: 0.9200 - Val loss: 0.2491 - Val F1: 0.8821 - LR: 0.00e+00\n","\tBest epoch: 100 - Best val accuracy: 0.9200 - Best val loss: 0.2491 - Best val F1: 0.8821\n","\n","\tEpoch 10/100 - Train loss: 0.7016 - Val accuracy: 0.7200 - Val loss: 1.2805 - Val F1: 0.6028 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.4728 - Val accuracy: 0.7200 - Val loss: 1.0042 - Val F1: 0.6028 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.3854 - Val accuracy: 0.7200 - Val loss: 0.9164 - Val F1: 0.6028 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.3260 - Val accuracy: 0.7200 - Val loss: 0.9150 - Val F1: 0.6028 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.2811 - Val accuracy: 0.7200 - Val loss: 0.6332 - Val F1: 0.6028 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.2589 - Val accuracy: 0.9200 - Val loss: 0.3426 - Val F1: 0.8821 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.2314 - Val accuracy: 0.9200 - Val loss: 0.2710 - Val F1: 0.8821 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.2147 - Val accuracy: 0.9200 - Val loss: 0.2501 - Val F1: 0.8821 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.2044 - Val accuracy: 0.9200 - Val loss: 0.2410 - Val F1: 0.8821 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.1963 - Val accuracy: 0.9200 - Val loss: 0.2376 - Val F1: 0.8821 - LR: 0.00e+00\n","\tBest epoch: 100 - Best val accuracy: 0.9200 - Best val loss: 0.2376 - Best val F1: 0.8821\n","\n","\tEpoch 10/100 - Train loss: 0.7552 - Val accuracy: 0.7200 - Val loss: 1.2631 - Val F1: 0.6028 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.4888 - Val accuracy: 0.7200 - Val loss: 0.9469 - Val F1: 0.6028 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.3465 - Val accuracy: 0.7200 - Val loss: 0.9047 - Val F1: 0.6028 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.2538 - Val accuracy: 0.7200 - Val loss: 0.9875 - Val F1: 0.6028 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.2032 - Val accuracy: 0.7200 - Val loss: 0.7955 - Val F1: 0.6028 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.1660 - Val accuracy: 0.8000 - Val loss: 0.4380 - Val F1: 0.7465 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.1448 - Val accuracy: 0.9200 - Val loss: 0.2972 - Val F1: 0.8821 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.1352 - Val accuracy: 0.9200 - Val loss: 0.2616 - Val F1: 0.8821 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.1283 - Val accuracy: 0.9200 - Val loss: 0.2497 - Val F1: 0.8824 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.1256 - Val accuracy: 0.9200 - Val loss: 0.2458 - Val F1: 0.8824 - LR: 0.00e+00\n","\tBest epoch: 100 - Best val accuracy: 0.9200 - Best val loss: 0.2458 - Best val F1: 0.8824\n","\n","Source class: WAL | Domain: 26 | Accuracy: 0.9086 | Loss: 0.2510 | F1: 0.8657\n","\n","Domain: 27\n","x_dp_dom.shape: (165, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Training and evaluating on Dp data via cross-validation...\n","\tEpoch 10/100 - Train loss: 0.3273 - Val accuracy: 0.8519 - Val loss: 0.3945 - Val F1: 0.7852 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.1354 - Val accuracy: 0.9630 - Val loss: 0.1761 - Val F1: 0.9573 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.0524 - Val accuracy: 0.9630 - Val loss: 0.0988 - Val F1: 0.9605 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.0247 - Val accuracy: 0.9630 - Val loss: 0.0752 - Val F1: 0.9605 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.0241 - Val accuracy: 0.9630 - Val loss: 0.0635 - Val F1: 0.9605 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.0159 - Val accuracy: 0.9630 - Val loss: 0.0553 - Val F1: 0.9605 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0407 - Val accuracy: 1.0000 - Val loss: 0.0506 - Val F1: 1.0000 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0086 - Val accuracy: 1.0000 - Val loss: 0.0446 - Val F1: 1.0000 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0065 - Val accuracy: 1.0000 - Val loss: 0.0440 - Val F1: 1.0000 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0060 - Val accuracy: 1.0000 - Val loss: 0.0443 - Val F1: 1.0000 - LR: 0.00e+00\n","\tBest epoch: 94 - Best val accuracy: 1.0000 - Best val loss: 0.0427 - Best val F1: 1.0000\n","\n","\tEpoch 10/100 - Train loss: 0.3434 - Val accuracy: 0.8519 - Val loss: 0.3907 - Val F1: 0.7852 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.1214 - Val accuracy: 0.9259 - Val loss: 0.1997 - Val F1: 0.9155 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.0608 - Val accuracy: 0.9630 - Val loss: 0.1325 - Val F1: 0.9605 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.0305 - Val accuracy: 0.9630 - Val loss: 0.1090 - Val F1: 0.9605 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.0132 - Val accuracy: 0.9630 - Val loss: 0.0935 - Val F1: 0.9605 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.0116 - Val accuracy: 0.9630 - Val loss: 0.0892 - Val F1: 0.9605 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0131 - Val accuracy: 0.9630 - Val loss: 0.0842 - Val F1: 0.9605 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0087 - Val accuracy: 0.9630 - Val loss: 0.0846 - Val F1: 0.9605 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0077 - Val accuracy: 0.9630 - Val loss: 0.0863 - Val F1: 0.9605 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0070 - Val accuracy: 0.9630 - Val loss: 0.0823 - Val F1: 0.9605 - LR: 0.00e+00\n","\tBest epoch: 99 - Best val accuracy: 0.9630 - Best val loss: 0.0812 - Best val F1: 0.9605\n","\n","\tEpoch 10/100 - Train loss: 0.3244 - Val accuracy: 0.8519 - Val loss: 0.3626 - Val F1: 0.7852 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.1168 - Val accuracy: 0.9259 - Val loss: 0.2236 - Val F1: 0.9012 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.0416 - Val accuracy: 0.9259 - Val loss: 0.2245 - Val F1: 0.9012 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.0223 - Val accuracy: 0.9259 - Val loss: 0.2385 - Val F1: 0.9012 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.0132 - Val accuracy: 0.9259 - Val loss: 0.2553 - Val F1: 0.9012 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.0103 - Val accuracy: 0.9259 - Val loss: 0.2552 - Val F1: 0.9012 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0099 - Val accuracy: 0.9259 - Val loss: 0.2740 - Val F1: 0.9012 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0064 - Val accuracy: 0.9259 - Val loss: 0.2701 - Val F1: 0.9012 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0059 - Val accuracy: 0.9259 - Val loss: 0.2722 - Val F1: 0.9012 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0064 - Val accuracy: 0.9259 - Val loss: 0.2753 - Val F1: 0.9012 - LR: 0.00e+00\n","\tBest epoch: 26 - Best val accuracy: 0.9259 - Best val loss: 0.2125 - Best val F1: 0.9012\n","\n","\tEpoch 10/100 - Train loss: 0.2753 - Val accuracy: 0.8148 - Val loss: 0.3182 - Val F1: 0.7500 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.1125 - Val accuracy: 0.9630 - Val loss: 0.1240 - Val F1: 0.9605 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.0555 - Val accuracy: 0.9630 - Val loss: 0.0942 - Val F1: 0.9605 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.0255 - Val accuracy: 0.9630 - Val loss: 0.0731 - Val F1: 0.9605 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.0138 - Val accuracy: 0.9630 - Val loss: 0.0662 - Val F1: 0.9605 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.0153 - Val accuracy: 0.9630 - Val loss: 0.0631 - Val F1: 0.9605 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0082 - Val accuracy: 0.9630 - Val loss: 0.0579 - Val F1: 0.9605 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0075 - Val accuracy: 0.9630 - Val loss: 0.0515 - Val F1: 0.9605 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0112 - Val accuracy: 0.9630 - Val loss: 0.0573 - Val F1: 0.9605 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0063 - Val accuracy: 0.9630 - Val loss: 0.0520 - Val F1: 0.9605 - LR: 0.00e+00\n","\tBest epoch: 94 - Best val accuracy: 0.9630 - Best val loss: 0.0508 - Best val F1: 0.9605\n","\n","\tEpoch 10/100 - Train loss: 0.3147 - Val accuracy: 0.8519 - Val loss: 0.3852 - Val F1: 0.7852 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.1400 - Val accuracy: 0.9630 - Val loss: 0.1742 - Val F1: 0.9605 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.0557 - Val accuracy: 1.0000 - Val loss: 0.1125 - Val F1: 1.0000 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.0411 - Val accuracy: 1.0000 - Val loss: 0.0835 - Val F1: 1.0000 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.0191 - Val accuracy: 1.0000 - Val loss: 0.0695 - Val F1: 1.0000 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.0132 - Val accuracy: 1.0000 - Val loss: 0.0618 - Val F1: 1.0000 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0132 - Val accuracy: 1.0000 - Val loss: 0.0567 - Val F1: 1.0000 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0081 - Val accuracy: 1.0000 - Val loss: 0.0533 - Val F1: 1.0000 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0075 - Val accuracy: 1.0000 - Val loss: 0.0527 - Val F1: 1.0000 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0091 - Val accuracy: 1.0000 - Val loss: 0.0515 - Val F1: 1.0000 - LR: 0.00e+00\n","\tBest epoch: 96 - Best val accuracy: 1.0000 - Best val loss: 0.0507 - Best val F1: 1.0000\n","\n","Source class: WAL | Domain: 27 | Accuracy: 0.9636 | Loss: 0.0763 | F1: 0.9625\n","\n","Domain: 28\n","x_dp_dom.shape: (153, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Training and evaluating on Dp data via cross-validation...\n","\tEpoch 10/100 - Train loss: 0.6741 - Val accuracy: 0.7200 - Val loss: 1.2357 - Val F1: 0.6028 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.3767 - Val accuracy: 0.7200 - Val loss: 1.0021 - Val F1: 0.6028 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.2492 - Val accuracy: 0.7200 - Val loss: 0.8532 - Val F1: 0.6028 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.1903 - Val accuracy: 0.7200 - Val loss: 0.7560 - Val F1: 0.6028 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.1478 - Val accuracy: 0.7200 - Val loss: 0.4646 - Val F1: 0.6028 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.1359 - Val accuracy: 0.9600 - Val loss: 0.2086 - Val F1: 0.9467 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.1260 - Val accuracy: 0.9600 - Val loss: 0.1370 - Val F1: 0.9467 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.1130 - Val accuracy: 0.9600 - Val loss: 0.1176 - Val F1: 0.9467 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.1105 - Val accuracy: 0.9600 - Val loss: 0.1108 - Val F1: 0.9467 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.1090 - Val accuracy: 0.9600 - Val loss: 0.1085 - Val F1: 0.9467 - LR: 0.00e+00\n","\tBest epoch: 100 - Best val accuracy: 0.9600 - Best val loss: 0.1085 - Best val F1: 0.9467\n","\n","\tEpoch 10/100 - Train loss: 0.6282 - Val accuracy: 0.7200 - Val loss: 1.2476 - Val F1: 0.6028 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.3764 - Val accuracy: 0.7200 - Val loss: 1.0060 - Val F1: 0.6028 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.2902 - Val accuracy: 0.7200 - Val loss: 0.9476 - Val F1: 0.6028 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.2335 - Val accuracy: 0.7200 - Val loss: 0.9600 - Val F1: 0.6028 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.1910 - Val accuracy: 0.7200 - Val loss: 0.7601 - Val F1: 0.6028 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.1638 - Val accuracy: 0.8000 - Val loss: 0.3610 - Val F1: 0.7465 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.1421 - Val accuracy: 0.9200 - Val loss: 0.1976 - Val F1: 0.8821 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.1365 - Val accuracy: 0.9200 - Val loss: 0.1654 - Val F1: 0.8824 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.1251 - Val accuracy: 0.9200 - Val loss: 0.1568 - Val F1: 0.8824 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.1226 - Val accuracy: 0.9200 - Val loss: 0.1544 - Val F1: 0.8824 - LR: 0.00e+00\n","\tBest epoch: 100 - Best val accuracy: 0.9200 - Best val loss: 0.1544 - Best val F1: 0.8824\n","\n","\tEpoch 10/100 - Train loss: 0.7678 - Val accuracy: 0.7200 - Val loss: 1.2717 - Val F1: 0.6028 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.4176 - Val accuracy: 0.7200 - Val loss: 1.0502 - Val F1: 0.6028 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.2605 - Val accuracy: 0.7200 - Val loss: 0.8787 - Val F1: 0.6028 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.1825 - Val accuracy: 0.7200 - Val loss: 0.7046 - Val F1: 0.6028 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.1474 - Val accuracy: 0.8400 - Val loss: 0.4074 - Val F1: 0.8023 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.1162 - Val accuracy: 0.9600 - Val loss: 0.2019 - Val F1: 0.9467 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.1114 - Val accuracy: 0.9600 - Val loss: 0.1412 - Val F1: 0.9467 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.1072 - Val accuracy: 0.9600 - Val loss: 0.1230 - Val F1: 0.9467 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0986 - Val accuracy: 0.9600 - Val loss: 0.1164 - Val F1: 0.9467 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0955 - Val accuracy: 0.9600 - Val loss: 0.1143 - Val F1: 0.9467 - LR: 0.00e+00\n","\tBest epoch: 100 - Best val accuracy: 0.9600 - Best val loss: 0.1143 - Best val F1: 0.9467\n","\n","\tEpoch 10/100 - Train loss: 0.5940 - Val accuracy: 0.7200 - Val loss: 1.1883 - Val F1: 0.6028 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.3583 - Val accuracy: 0.7200 - Val loss: 0.9728 - Val F1: 0.6028 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.2502 - Val accuracy: 0.7200 - Val loss: 0.8797 - Val F1: 0.6028 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.1860 - Val accuracy: 0.7200 - Val loss: 0.7753 - Val F1: 0.6028 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.1496 - Val accuracy: 0.7200 - Val loss: 0.4587 - Val F1: 0.6028 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.1340 - Val accuracy: 0.9200 - Val loss: 0.2144 - Val F1: 0.9005 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.1170 - Val accuracy: 0.9200 - Val loss: 0.1437 - Val F1: 0.9005 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.1124 - Val accuracy: 0.9200 - Val loss: 0.1225 - Val F1: 0.9005 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.1022 - Val accuracy: 0.9600 - Val loss: 0.1149 - Val F1: 0.9467 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.1036 - Val accuracy: 0.9600 - Val loss: 0.1124 - Val F1: 0.9467 - LR: 0.00e+00\n","\tBest epoch: 100 - Best val accuracy: 0.9600 - Best val loss: 0.1124 - Best val F1: 0.9467\n","\n","\tEpoch 10/100 - Train loss: 0.6794 - Val accuracy: 0.7200 - Val loss: 1.2152 - Val F1: 0.6028 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.3491 - Val accuracy: 0.7200 - Val loss: 0.9684 - Val F1: 0.6028 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.2407 - Val accuracy: 0.7200 - Val loss: 0.8612 - Val F1: 0.6028 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.1789 - Val accuracy: 0.7200 - Val loss: 0.7762 - Val F1: 0.6028 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.1467 - Val accuracy: 0.7600 - Val loss: 0.4476 - Val F1: 0.6989 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.1292 - Val accuracy: 0.9600 - Val loss: 0.2407 - Val F1: 0.9467 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.1103 - Val accuracy: 0.9600 - Val loss: 0.1939 - Val F1: 0.9467 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.1099 - Val accuracy: 0.9600 - Val loss: 0.1808 - Val F1: 0.9418 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.1016 - Val accuracy: 0.9600 - Val loss: 0.1760 - Val F1: 0.9418 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.1002 - Val accuracy: 0.9600 - Val loss: 0.1747 - Val F1: 0.9418 - LR: 0.00e+00\n","\tBest epoch: 100 - Best val accuracy: 0.9600 - Best val loss: 0.1747 - Best val F1: 0.9418\n","\n","Source class: WAL | Domain: 28 | Accuracy: 0.9477 | Loss: 0.1431 | F1: 0.9302\n","\n","Domain: 29\n","x_dp_dom.shape: (153, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Training and evaluating on Dp data via cross-validation...\n","\tEpoch 10/100 - Train loss: 0.6417 - Val accuracy: 0.7200 - Val loss: 1.1650 - Val F1: 0.6028 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.4354 - Val accuracy: 0.7200 - Val loss: 1.0193 - Val F1: 0.6028 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.2993 - Val accuracy: 0.7200 - Val loss: 0.9689 - Val F1: 0.6028 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.2191 - Val accuracy: 0.7200 - Val loss: 0.9507 - Val F1: 0.6028 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.1768 - Val accuracy: 0.7200 - Val loss: 0.7948 - Val F1: 0.6028 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.1387 - Val accuracy: 0.8800 - Val loss: 0.3694 - Val F1: 0.8424 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.1205 - Val accuracy: 0.9200 - Val loss: 0.1714 - Val F1: 0.8821 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.1035 - Val accuracy: 0.9600 - Val loss: 0.1240 - Val F1: 0.9405 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0969 - Val accuracy: 0.9600 - Val loss: 0.1087 - Val F1: 0.9405 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0949 - Val accuracy: 0.9600 - Val loss: 0.1038 - Val F1: 0.9405 - LR: 0.00e+00\n","\tBest epoch: 100 - Best val accuracy: 0.9600 - Best val loss: 0.1038 - Best val F1: 0.9405\n","\n","\tEpoch 10/100 - Train loss: 0.7740 - Val accuracy: 0.7200 - Val loss: 1.2690 - Val F1: 0.6028 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.5286 - Val accuracy: 0.7200 - Val loss: 1.0646 - Val F1: 0.6028 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.3614 - Val accuracy: 0.7200 - Val loss: 0.9409 - Val F1: 0.6028 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.2610 - Val accuracy: 0.7200 - Val loss: 0.7426 - Val F1: 0.6028 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.2114 - Val accuracy: 0.8000 - Val loss: 0.4877 - Val F1: 0.7465 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.1708 - Val accuracy: 0.9200 - Val loss: 0.3072 - Val F1: 0.8821 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.1444 - Val accuracy: 0.9200 - Val loss: 0.2326 - Val F1: 0.8821 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.1340 - Val accuracy: 0.9200 - Val loss: 0.2034 - Val F1: 0.8821 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.1226 - Val accuracy: 0.9200 - Val loss: 0.1907 - Val F1: 0.8821 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.1206 - Val accuracy: 0.9200 - Val loss: 0.1863 - Val F1: 0.8821 - LR: 0.00e+00\n","\tBest epoch: 100 - Best val accuracy: 0.9200 - Best val loss: 0.1863 - Best val F1: 0.8821\n","\n","\tEpoch 10/100 - Train loss: 0.7398 - Val accuracy: 0.7200 - Val loss: 1.2881 - Val F1: 0.6028 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.4642 - Val accuracy: 0.7200 - Val loss: 1.1392 - Val F1: 0.6028 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.3312 - Val accuracy: 0.7200 - Val loss: 1.0694 - Val F1: 0.6028 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.2647 - Val accuracy: 0.7200 - Val loss: 0.9940 - Val F1: 0.6028 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.2223 - Val accuracy: 0.7200 - Val loss: 0.6718 - Val F1: 0.6028 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.1857 - Val accuracy: 0.9200 - Val loss: 0.2948 - Val F1: 0.8821 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.1672 - Val accuracy: 0.9200 - Val loss: 0.1814 - Val F1: 0.8821 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.1496 - Val accuracy: 0.9600 - Val loss: 0.1498 - Val F1: 0.9405 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.1459 - Val accuracy: 0.9600 - Val loss: 0.1379 - Val F1: 0.9405 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.1474 - Val accuracy: 0.9600 - Val loss: 0.1339 - Val F1: 0.9405 - LR: 0.00e+00\n","\tBest epoch: 100 - Best val accuracy: 0.9600 - Best val loss: 0.1339 - Best val F1: 0.9405\n","\n","\tEpoch 10/100 - Train loss: 0.6488 - Val accuracy: 0.7200 - Val loss: 1.2239 - Val F1: 0.6028 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.3885 - Val accuracy: 0.7200 - Val loss: 0.9982 - Val F1: 0.6028 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.2766 - Val accuracy: 0.7200 - Val loss: 0.8638 - Val F1: 0.6028 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.2038 - Val accuracy: 0.7200 - Val loss: 0.6793 - Val F1: 0.6028 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.1598 - Val accuracy: 0.9200 - Val loss: 0.3878 - Val F1: 0.8821 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.1319 - Val accuracy: 0.9600 - Val loss: 0.1939 - Val F1: 0.9405 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.1164 - Val accuracy: 0.9600 - Val loss: 0.1271 - Val F1: 0.9405 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.1050 - Val accuracy: 0.9600 - Val loss: 0.1044 - Val F1: 0.9405 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0984 - Val accuracy: 1.0000 - Val loss: 0.0953 - Val F1: 1.0000 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0952 - Val accuracy: 1.0000 - Val loss: 0.0921 - Val F1: 1.0000 - LR: 0.00e+00\n","\tBest epoch: 100 - Best val accuracy: 1.0000 - Best val loss: 0.0921 - Best val F1: 1.0000\n","\n","\tEpoch 10/100 - Train loss: 0.7408 - Val accuracy: 0.7200 - Val loss: 1.2115 - Val F1: 0.6028 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.5000 - Val accuracy: 0.7200 - Val loss: 1.0298 - Val F1: 0.6028 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.3373 - Val accuracy: 0.7200 - Val loss: 0.9627 - Val F1: 0.6028 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.2373 - Val accuracy: 0.7200 - Val loss: 0.8834 - Val F1: 0.6028 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.1871 - Val accuracy: 0.7200 - Val loss: 0.5620 - Val F1: 0.6028 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.1462 - Val accuracy: 0.9200 - Val loss: 0.2626 - Val F1: 0.8821 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.1259 - Val accuracy: 0.9200 - Val loss: 0.1687 - Val F1: 0.8821 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.1171 - Val accuracy: 0.9200 - Val loss: 0.1385 - Val F1: 0.8821 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.1044 - Val accuracy: 0.9200 - Val loss: 0.1268 - Val F1: 0.8821 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.1035 - Val accuracy: 0.9200 - Val loss: 0.1229 - Val F1: 0.8821 - LR: 0.00e+00\n","\tBest epoch: 100 - Best val accuracy: 0.9200 - Best val loss: 0.1229 - Best val F1: 0.8821\n","\n","Source class: WAL | Domain: 29 | Accuracy: 0.9348 | Loss: 0.1776 | F1: 0.9062\n","\n","Domain: 30\n","x_dp_dom.shape: (161, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Training and evaluating on Dp data via cross-validation...\n","\tEpoch 10/100 - Train loss: 0.3189 - Val accuracy: 0.9231 - Val loss: 0.2631 - Val F1: 0.8995 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.1339 - Val accuracy: 0.9615 - Val loss: 0.1557 - Val F1: 0.9556 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.0756 - Val accuracy: 0.9615 - Val loss: 0.1372 - Val F1: 0.9556 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.0605 - Val accuracy: 0.9615 - Val loss: 0.1348 - Val F1: 0.9556 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.0336 - Val accuracy: 0.9615 - Val loss: 0.1345 - Val F1: 0.9556 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.0195 - Val accuracy: 0.9615 - Val loss: 0.1300 - Val F1: 0.9556 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0175 - Val accuracy: 0.9615 - Val loss: 0.1289 - Val F1: 0.9556 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0508 - Val accuracy: 0.9615 - Val loss: 0.1283 - Val F1: 0.9556 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0110 - Val accuracy: 0.9615 - Val loss: 0.1244 - Val F1: 0.9556 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0131 - Val accuracy: 0.9615 - Val loss: 0.1239 - Val F1: 0.9556 - LR: 0.00e+00\n","\tBest epoch: 87 - Best val accuracy: 0.9615 - Best val loss: 0.1231 - Best val F1: 0.9556\n","\n","\tEpoch 10/100 - Train loss: 0.2684 - Val accuracy: 0.8846 - Val loss: 0.2911 - Val F1: 0.8439 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.1092 - Val accuracy: 0.8846 - Val loss: 0.1893 - Val F1: 0.8439 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.0604 - Val accuracy: 0.9615 - Val loss: 0.1563 - Val F1: 0.9556 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.0334 - Val accuracy: 0.9615 - Val loss: 0.1352 - Val F1: 0.9556 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.0525 - Val accuracy: 0.9615 - Val loss: 0.1237 - Val F1: 0.9573 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.0180 - Val accuracy: 0.9615 - Val loss: 0.1188 - Val F1: 0.9573 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0145 - Val accuracy: 0.9615 - Val loss: 0.1139 - Val F1: 0.9573 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0120 - Val accuracy: 0.9615 - Val loss: 0.1140 - Val F1: 0.9573 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0125 - Val accuracy: 0.9615 - Val loss: 0.1148 - Val F1: 0.9573 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0162 - Val accuracy: 0.9615 - Val loss: 0.1061 - Val F1: 0.9573 - LR: 0.00e+00\n","\tBest epoch: 100 - Best val accuracy: 0.9615 - Best val loss: 0.1061 - Best val F1: 0.9573\n","\n","\tEpoch 10/100 - Train loss: 0.2309 - Val accuracy: 0.8846 - Val loss: 0.2861 - Val F1: 0.8442 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.1176 - Val accuracy: 0.8846 - Val loss: 0.2492 - Val F1: 0.8442 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.0521 - Val accuracy: 0.9615 - Val loss: 0.1760 - Val F1: 0.9556 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.0337 - Val accuracy: 0.9615 - Val loss: 0.1710 - Val F1: 0.9556 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.0233 - Val accuracy: 0.9231 - Val loss: 0.1748 - Val F1: 0.9123 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.0159 - Val accuracy: 0.9615 - Val loss: 0.1576 - Val F1: 0.9556 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0134 - Val accuracy: 0.9615 - Val loss: 0.1483 - Val F1: 0.9556 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0118 - Val accuracy: 0.9615 - Val loss: 0.1544 - Val F1: 0.9556 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0087 - Val accuracy: 0.9615 - Val loss: 0.1467 - Val F1: 0.9556 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0120 - Val accuracy: 0.9615 - Val loss: 0.1417 - Val F1: 0.9556 - LR: 0.00e+00\n","\tBest epoch: 94 - Best val accuracy: 0.9615 - Best val loss: 0.1400 - Best val F1: 0.9556\n","\n","\tEpoch 10/100 - Train loss: 0.2621 - Val accuracy: 0.8846 - Val loss: 0.2992 - Val F1: 0.8442 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.1141 - Val accuracy: 0.8846 - Val loss: 0.2103 - Val F1: 0.8442 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.0673 - Val accuracy: 0.8846 - Val loss: 0.1891 - Val F1: 0.8442 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.0411 - Val accuracy: 0.9231 - Val loss: 0.1770 - Val F1: 0.9123 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.0235 - Val accuracy: 0.9231 - Val loss: 0.1494 - Val F1: 0.9123 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.0203 - Val accuracy: 0.9615 - Val loss: 0.1266 - Val F1: 0.9556 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0154 - Val accuracy: 0.9231 - Val loss: 0.1316 - Val F1: 0.9123 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0161 - Val accuracy: 0.9231 - Val loss: 0.1281 - Val F1: 0.9123 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0100 - Val accuracy: 0.9615 - Val loss: 0.1148 - Val F1: 0.9556 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0073 - Val accuracy: 0.9615 - Val loss: 0.1236 - Val F1: 0.9556 - LR: 0.00e+00\n","\tBest epoch: 90 - Best val accuracy: 0.9615 - Best val loss: 0.1148 - Best val F1: 0.9556\n","\n","\tEpoch 10/100 - Train loss: 0.2370 - Val accuracy: 0.9231 - Val loss: 0.1979 - Val F1: 0.8866 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.1145 - Val accuracy: 1.0000 - Val loss: 0.0938 - Val F1: 1.0000 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.0699 - Val accuracy: 1.0000 - Val loss: 0.0571 - Val F1: 1.0000 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.0637 - Val accuracy: 1.0000 - Val loss: 0.0403 - Val F1: 1.0000 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.0355 - Val accuracy: 1.0000 - Val loss: 0.0297 - Val F1: 1.0000 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.0328 - Val accuracy: 1.0000 - Val loss: 0.0250 - Val F1: 1.0000 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0188 - Val accuracy: 1.0000 - Val loss: 0.0216 - Val F1: 1.0000 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0172 - Val accuracy: 1.0000 - Val loss: 0.0191 - Val F1: 1.0000 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0165 - Val accuracy: 1.0000 - Val loss: 0.0190 - Val F1: 1.0000 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0181 - Val accuracy: 1.0000 - Val loss: 0.0181 - Val F1: 1.0000 - LR: 0.00e+00\n","\tBest epoch: 100 - Best val accuracy: 1.0000 - Best val loss: 0.0181 - Best val F1: 1.0000\n","\n","Source class: WAL | Domain: 30 | Accuracy: 0.9256 | Loss: 0.1393 | F1: 0.9023\n","\n","Domain: 31\n","x_dp_dom.shape: (154, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Training and evaluating on Dp data via cross-validation...\n","\tEpoch 10/100 - Train loss: 0.5868 - Val accuracy: 0.7200 - Val loss: 1.2391 - Val F1: 0.6028 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.3824 - Val accuracy: 0.7200 - Val loss: 0.9855 - Val F1: 0.6028 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.3016 - Val accuracy: 0.7200 - Val loss: 0.8150 - Val F1: 0.6028 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.2660 - Val accuracy: 0.9200 - Val loss: 0.6189 - Val F1: 0.8821 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.2161 - Val accuracy: 0.9600 - Val loss: 0.4151 - Val F1: 0.9405 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.1948 - Val accuracy: 0.9600 - Val loss: 0.2907 - Val F1: 0.9405 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.1731 - Val accuracy: 0.9200 - Val loss: 0.2432 - Val F1: 0.8824 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.1600 - Val accuracy: 0.9200 - Val loss: 0.2271 - Val F1: 0.8824 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.1491 - Val accuracy: 0.9200 - Val loss: 0.2214 - Val F1: 0.8824 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.1434 - Val accuracy: 0.9200 - Val loss: 0.2192 - Val F1: 0.8824 - LR: 0.00e+00\n","\tBest epoch: 100 - Best val accuracy: 0.9200 - Best val loss: 0.2192 - Best val F1: 0.8824\n","\n","\tEpoch 10/100 - Train loss: 0.6700 - Val accuracy: 0.7200 - Val loss: 1.2903 - Val F1: 0.6028 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.3786 - Val accuracy: 0.7200 - Val loss: 1.0292 - Val F1: 0.6028 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.2759 - Val accuracy: 0.7200 - Val loss: 0.8165 - Val F1: 0.6028 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.2220 - Val accuracy: 0.7200 - Val loss: 0.6292 - Val F1: 0.6821 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.1878 - Val accuracy: 0.9200 - Val loss: 0.4101 - Val F1: 0.9050 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.1594 - Val accuracy: 0.9200 - Val loss: 0.2426 - Val F1: 0.9050 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.1507 - Val accuracy: 0.9600 - Val loss: 0.1724 - Val F1: 0.9405 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.1338 - Val accuracy: 0.9600 - Val loss: 0.1480 - Val F1: 0.9405 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.1312 - Val accuracy: 0.9600 - Val loss: 0.1387 - Val F1: 0.9405 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.1257 - Val accuracy: 0.9600 - Val loss: 0.1355 - Val F1: 0.9405 - LR: 0.00e+00\n","\tBest epoch: 100 - Best val accuracy: 0.9600 - Best val loss: 0.1355 - Best val F1: 0.9405\n","\n","\tEpoch 10/100 - Train loss: 0.8710 - Val accuracy: 0.2000 - Val loss: 1.3331 - Val F1: 0.0667 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.4927 - Val accuracy: 0.7200 - Val loss: 1.1094 - Val F1: 0.6028 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.3358 - Val accuracy: 0.7200 - Val loss: 0.8653 - Val F1: 0.6028 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.2495 - Val accuracy: 0.8400 - Val loss: 0.5963 - Val F1: 0.7980 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.2033 - Val accuracy: 0.9600 - Val loss: 0.3656 - Val F1: 0.9405 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.1697 - Val accuracy: 0.9600 - Val loss: 0.2353 - Val F1: 0.9405 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.1477 - Val accuracy: 0.9600 - Val loss: 0.1784 - Val F1: 0.9405 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.1353 - Val accuracy: 0.9600 - Val loss: 0.1546 - Val F1: 0.9405 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.1290 - Val accuracy: 0.9600 - Val loss: 0.1446 - Val F1: 0.9405 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.1266 - Val accuracy: 0.9600 - Val loss: 0.1411 - Val F1: 0.9405 - LR: 0.00e+00\n","\tBest epoch: 100 - Best val accuracy: 0.9600 - Best val loss: 0.1411 - Best val F1: 0.9405\n","\n","\tEpoch 10/100 - Train loss: 0.6887 - Val accuracy: 0.7200 - Val loss: 1.2375 - Val F1: 0.6028 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.3748 - Val accuracy: 0.7200 - Val loss: 1.0370 - Val F1: 0.6028 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.2747 - Val accuracy: 0.7200 - Val loss: 0.8172 - Val F1: 0.6028 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.2367 - Val accuracy: 0.8800 - Val loss: 0.5465 - Val F1: 0.8424 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.2042 - Val accuracy: 0.9600 - Val loss: 0.3402 - Val F1: 0.9405 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.1817 - Val accuracy: 0.9600 - Val loss: 0.2409 - Val F1: 0.9405 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.1569 - Val accuracy: 0.9600 - Val loss: 0.2026 - Val F1: 0.9405 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.1490 - Val accuracy: 0.9600 - Val loss: 0.1867 - Val F1: 0.9405 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.1402 - Val accuracy: 0.9600 - Val loss: 0.1792 - Val F1: 0.9405 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.1390 - Val accuracy: 0.9600 - Val loss: 0.1768 - Val F1: 0.9405 - LR: 0.00e+00\n","\tBest epoch: 100 - Best val accuracy: 0.9600 - Best val loss: 0.1768 - Best val F1: 0.9405\n","\n","\tEpoch 10/100 - Train loss: 0.7563 - Val accuracy: 0.7200 - Val loss: 1.2818 - Val F1: 0.6028 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.4388 - Val accuracy: 0.7200 - Val loss: 1.0700 - Val F1: 0.6028 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.3077 - Val accuracy: 0.7200 - Val loss: 0.8883 - Val F1: 0.6028 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.2571 - Val accuracy: 0.7200 - Val loss: 0.6903 - Val F1: 0.6028 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.2137 - Val accuracy: 0.9200 - Val loss: 0.4540 - Val F1: 0.8821 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.1948 - Val accuracy: 0.9200 - Val loss: 0.3140 - Val F1: 0.8824 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.1704 - Val accuracy: 0.9200 - Val loss: 0.2606 - Val F1: 0.8824 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.1625 - Val accuracy: 0.9200 - Val loss: 0.2430 - Val F1: 0.8824 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.1514 - Val accuracy: 0.9200 - Val loss: 0.2361 - Val F1: 0.8824 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.1457 - Val accuracy: 0.9200 - Val loss: 0.2333 - Val F1: 0.8824 - LR: 0.00e+00\n","\tBest epoch: 100 - Best val accuracy: 0.9200 - Best val loss: 0.2333 - Best val F1: 0.8824\n","\n","Source class: WAL | Domain: 31 | Accuracy: 0.9155 | Loss: 0.2071 | F1: 0.8776\n","\n","Domain: 32\n","x_dp_dom.shape: (163, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Training and evaluating on Dp data via cross-validation...\n","\tEpoch 10/100 - Train loss: 0.3136 - Val accuracy: 0.9231 - Val loss: 0.3202 - Val F1: 0.9167 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.0861 - Val accuracy: 1.0000 - Val loss: 0.1026 - Val F1: 1.0000 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.0398 - Val accuracy: 1.0000 - Val loss: 0.0423 - Val F1: 1.0000 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.0190 - Val accuracy: 1.0000 - Val loss: 0.0259 - Val F1: 1.0000 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.0162 - Val accuracy: 1.0000 - Val loss: 0.0187 - Val F1: 1.0000 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.0110 - Val accuracy: 1.0000 - Val loss: 0.0146 - Val F1: 1.0000 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0082 - Val accuracy: 1.0000 - Val loss: 0.0134 - Val F1: 1.0000 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0068 - Val accuracy: 1.0000 - Val loss: 0.0109 - Val F1: 1.0000 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0061 - Val accuracy: 1.0000 - Val loss: 0.0099 - Val F1: 1.0000 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0069 - Val accuracy: 1.0000 - Val loss: 0.0092 - Val F1: 1.0000 - LR: 0.00e+00\n","\tBest epoch: 95 - Best val accuracy: 1.0000 - Best val loss: 0.0089 - Best val F1: 1.0000\n","\n","\tEpoch 10/100 - Train loss: 0.2767 - Val accuracy: 0.7692 - Val loss: 0.4015 - Val F1: 0.6960 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.1295 - Val accuracy: 0.9231 - Val loss: 0.2336 - Val F1: 0.9159 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.0624 - Val accuracy: 0.9615 - Val loss: 0.1606 - Val F1: 0.9556 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.0294 - Val accuracy: 0.9615 - Val loss: 0.1181 - Val F1: 0.9556 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.0294 - Val accuracy: 0.9615 - Val loss: 0.1086 - Val F1: 0.9556 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.0103 - Val accuracy: 0.9615 - Val loss: 0.0999 - Val F1: 0.9556 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0166 - Val accuracy: 0.9615 - Val loss: 0.0955 - Val F1: 0.9556 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0108 - Val accuracy: 0.9615 - Val loss: 0.0959 - Val F1: 0.9556 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0089 - Val accuracy: 0.9615 - Val loss: 0.0937 - Val F1: 0.9556 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0088 - Val accuracy: 0.9615 - Val loss: 0.0889 - Val F1: 0.9556 - LR: 0.00e+00\n","\tBest epoch: 74 - Best val accuracy: 0.9615 - Best val loss: 0.0887 - Best val F1: 0.9556\n","\n","\tEpoch 10/100 - Train loss: 0.2791 - Val accuracy: 0.8462 - Val loss: 0.3107 - Val F1: 0.7769 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.1180 - Val accuracy: 0.9615 - Val loss: 0.1397 - Val F1: 0.9556 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.0501 - Val accuracy: 1.0000 - Val loss: 0.0776 - Val F1: 1.0000 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.0307 - Val accuracy: 1.0000 - Val loss: 0.0503 - Val F1: 1.0000 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.0216 - Val accuracy: 1.0000 - Val loss: 0.0363 - Val F1: 1.0000 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.0179 - Val accuracy: 1.0000 - Val loss: 0.0281 - Val F1: 1.0000 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0088 - Val accuracy: 1.0000 - Val loss: 0.0226 - Val F1: 1.0000 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0091 - Val accuracy: 1.0000 - Val loss: 0.0213 - Val F1: 1.0000 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0098 - Val accuracy: 1.0000 - Val loss: 0.0200 - Val F1: 1.0000 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0064 - Val accuracy: 1.0000 - Val loss: 0.0195 - Val F1: 1.0000 - LR: 0.00e+00\n","\tBest epoch: 98 - Best val accuracy: 1.0000 - Best val loss: 0.0187 - Best val F1: 1.0000\n","\n","\tEpoch 10/100 - Train loss: 0.2626 - Val accuracy: 0.8519 - Val loss: 0.3010 - Val F1: 0.8140 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.1173 - Val accuracy: 1.0000 - Val loss: 0.1203 - Val F1: 1.0000 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.0425 - Val accuracy: 1.0000 - Val loss: 0.0580 - Val F1: 1.0000 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.0238 - Val accuracy: 1.0000 - Val loss: 0.0341 - Val F1: 1.0000 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.0186 - Val accuracy: 1.0000 - Val loss: 0.0244 - Val F1: 1.0000 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.0112 - Val accuracy: 1.0000 - Val loss: 0.0180 - Val F1: 1.0000 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0089 - Val accuracy: 1.0000 - Val loss: 0.0153 - Val F1: 1.0000 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0063 - Val accuracy: 1.0000 - Val loss: 0.0152 - Val F1: 1.0000 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0076 - Val accuracy: 1.0000 - Val loss: 0.0133 - Val F1: 1.0000 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0056 - Val accuracy: 1.0000 - Val loss: 0.0132 - Val F1: 1.0000 - LR: 0.00e+00\n","\tBest epoch: 99 - Best val accuracy: 1.0000 - Best val loss: 0.0129 - Best val F1: 1.0000\n","\n","\tEpoch 10/100 - Train loss: 0.3107 - Val accuracy: 0.8519 - Val loss: 0.3539 - Val F1: 0.7852 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.1284 - Val accuracy: 0.9630 - Val loss: 0.1570 - Val F1: 0.9605 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.0613 - Val accuracy: 0.9630 - Val loss: 0.1011 - Val F1: 0.9605 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.0315 - Val accuracy: 0.9630 - Val loss: 0.0769 - Val F1: 0.9605 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.0230 - Val accuracy: 0.9630 - Val loss: 0.0648 - Val F1: 0.9605 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.0166 - Val accuracy: 0.9630 - Val loss: 0.0590 - Val F1: 0.9605 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0107 - Val accuracy: 0.9630 - Val loss: 0.0587 - Val F1: 0.9605 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0124 - Val accuracy: 0.9630 - Val loss: 0.0546 - Val F1: 0.9605 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0103 - Val accuracy: 0.9630 - Val loss: 0.0522 - Val F1: 0.9605 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0094 - Val accuracy: 0.9630 - Val loss: 0.0510 - Val F1: 0.9605 - LR: 0.00e+00\n","\tBest epoch: 99 - Best val accuracy: 0.9630 - Best val loss: 0.0498 - Best val F1: 0.9605\n","\n","Source class: WAL | Domain: 32 | Accuracy: 0.9816 | Loss: 0.0604 | F1: 0.9810\n","\n","Domain: 33\n","x_dp_dom.shape: (156, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Training and evaluating on Dp data via cross-validation...\n","\tEpoch 10/100 - Train loss: 0.7672 - Val accuracy: 0.7200 - Val loss: 1.2862 - Val F1: 0.6028 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.4571 - Val accuracy: 0.7200 - Val loss: 1.0505 - Val F1: 0.6028 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.3486 - Val accuracy: 0.7200 - Val loss: 0.9244 - Val F1: 0.6028 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.2908 - Val accuracy: 0.7200 - Val loss: 0.8185 - Val F1: 0.6028 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.2384 - Val accuracy: 0.7600 - Val loss: 0.5011 - Val F1: 0.6838 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.2153 - Val accuracy: 0.9200 - Val loss: 0.2903 - Val F1: 0.8821 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.1906 - Val accuracy: 0.9200 - Val loss: 0.2342 - Val F1: 0.8821 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.1760 - Val accuracy: 0.9200 - Val loss: 0.2175 - Val F1: 0.8821 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.1637 - Val accuracy: 0.9200 - Val loss: 0.2101 - Val F1: 0.8821 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.1672 - Val accuracy: 0.9200 - Val loss: 0.2073 - Val F1: 0.8821 - LR: 0.00e+00\n","\tBest epoch: 100 - Best val accuracy: 0.9200 - Best val loss: 0.2073 - Best val F1: 0.8821\n","\n","\tEpoch 10/100 - Train loss: 0.8686 - Val accuracy: 0.7200 - Val loss: 1.2551 - Val F1: 0.6028 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.5676 - Val accuracy: 0.7200 - Val loss: 1.0705 - Val F1: 0.6028 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.4430 - Val accuracy: 0.7200 - Val loss: 0.9736 - Val F1: 0.6028 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.3836 - Val accuracy: 0.7200 - Val loss: 0.9395 - Val F1: 0.6028 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.3359 - Val accuracy: 0.7200 - Val loss: 0.7118 - Val F1: 0.6028 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.3031 - Val accuracy: 0.8800 - Val loss: 0.4195 - Val F1: 0.8424 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.2762 - Val accuracy: 0.9200 - Val loss: 0.3109 - Val F1: 0.8821 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.2581 - Val accuracy: 0.9200 - Val loss: 0.2748 - Val F1: 0.8821 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.2450 - Val accuracy: 0.9200 - Val loss: 0.2610 - Val F1: 0.8821 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.2425 - Val accuracy: 0.9200 - Val loss: 0.2561 - Val F1: 0.8821 - LR: 0.00e+00\n","\tBest epoch: 100 - Best val accuracy: 0.9200 - Best val loss: 0.2561 - Best val F1: 0.8821\n","\n","\tEpoch 10/100 - Train loss: 0.7555 - Val accuracy: 0.7200 - Val loss: 1.2434 - Val F1: 0.6028 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.5098 - Val accuracy: 0.7200 - Val loss: 1.0371 - Val F1: 0.6028 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.4072 - Val accuracy: 0.7200 - Val loss: 0.9200 - Val F1: 0.6028 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.3362 - Val accuracy: 0.7200 - Val loss: 0.7483 - Val F1: 0.6028 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.2900 - Val accuracy: 0.9200 - Val loss: 0.4215 - Val F1: 0.8821 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.2521 - Val accuracy: 0.9200 - Val loss: 0.2824 - Val F1: 0.8821 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.2355 - Val accuracy: 0.9200 - Val loss: 0.2391 - Val F1: 0.8821 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.2108 - Val accuracy: 0.9200 - Val loss: 0.2211 - Val F1: 0.8821 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.2033 - Val accuracy: 0.9200 - Val loss: 0.2124 - Val F1: 0.8821 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.1999 - Val accuracy: 0.9200 - Val loss: 0.2095 - Val F1: 0.8821 - LR: 0.00e+00\n","\tBest epoch: 100 - Best val accuracy: 0.9200 - Best val loss: 0.2095 - Best val F1: 0.8821\n","\n","\tEpoch 10/100 - Train loss: 0.7093 - Val accuracy: 0.7200 - Val loss: 1.2092 - Val F1: 0.6028 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.4531 - Val accuracy: 0.7200 - Val loss: 1.0344 - Val F1: 0.6028 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.3447 - Val accuracy: 0.7200 - Val loss: 0.9827 - Val F1: 0.6028 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.2819 - Val accuracy: 0.7200 - Val loss: 0.9664 - Val F1: 0.6028 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.2405 - Val accuracy: 0.7200 - Val loss: 0.6872 - Val F1: 0.6028 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.2076 - Val accuracy: 0.9200 - Val loss: 0.3356 - Val F1: 0.8821 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.1849 - Val accuracy: 0.9200 - Val loss: 0.2130 - Val F1: 0.8821 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.1746 - Val accuracy: 0.9200 - Val loss: 0.1782 - Val F1: 0.8821 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.1636 - Val accuracy: 0.9200 - Val loss: 0.1657 - Val F1: 0.8821 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.1662 - Val accuracy: 0.9200 - Val loss: 0.1617 - Val F1: 0.8821 - LR: 0.00e+00\n","\tBest epoch: 100 - Best val accuracy: 0.9200 - Best val loss: 0.1617 - Best val F1: 0.8821\n","\n","\tEpoch 10/100 - Train loss: 0.6663 - Val accuracy: 0.7200 - Val loss: 1.2394 - Val F1: 0.6028 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.4566 - Val accuracy: 0.7200 - Val loss: 1.0726 - Val F1: 0.6028 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.3631 - Val accuracy: 0.7200 - Val loss: 0.9900 - Val F1: 0.6028 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.3069 - Val accuracy: 0.7200 - Val loss: 0.9221 - Val F1: 0.6028 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.2564 - Val accuracy: 0.7200 - Val loss: 0.6212 - Val F1: 0.6028 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.2287 - Val accuracy: 0.9200 - Val loss: 0.3658 - Val F1: 0.8821 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.2023 - Val accuracy: 0.9200 - Val loss: 0.2783 - Val F1: 0.8821 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.1947 - Val accuracy: 0.9200 - Val loss: 0.2495 - Val F1: 0.8821 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.1742 - Val accuracy: 0.9200 - Val loss: 0.2382 - Val F1: 0.8821 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.1739 - Val accuracy: 0.9200 - Val loss: 0.2340 - Val F1: 0.8821 - LR: 0.00e+00\n","\tBest epoch: 100 - Best val accuracy: 0.9200 - Best val loss: 0.2340 - Best val F1: 0.8821\n","\n","Source class: WAL | Domain: 33 | Accuracy: 0.8976 | Loss: 0.2563 | F1: 0.8498\n","\n","Domain: 34\n","x_dp_dom.shape: (161, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Training and evaluating on Dp data via cross-validation...\n","\tEpoch 10/100 - Train loss: 0.2419 - Val accuracy: 0.9231 - Val loss: 0.2575 - Val F1: 0.9044 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.1352 - Val accuracy: 0.9231 - Val loss: 0.1732 - Val F1: 0.9044 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.0553 - Val accuracy: 0.9231 - Val loss: 0.1421 - Val F1: 0.9044 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.0283 - Val accuracy: 0.9231 - Val loss: 0.1242 - Val F1: 0.9044 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.0235 - Val accuracy: 0.9231 - Val loss: 0.1062 - Val F1: 0.9044 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.0178 - Val accuracy: 0.9231 - Val loss: 0.1096 - Val F1: 0.9044 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0091 - Val accuracy: 0.9231 - Val loss: 0.1074 - Val F1: 0.9044 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0111 - Val accuracy: 0.9231 - Val loss: 0.1066 - Val F1: 0.9044 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0099 - Val accuracy: 0.9231 - Val loss: 0.1119 - Val F1: 0.9044 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0092 - Val accuracy: 0.9231 - Val loss: 0.1107 - Val F1: 0.9044 - LR: 0.00e+00\n","\tBest epoch: 67 - Best val accuracy: 0.9231 - Best val loss: 0.1051 - Best val F1: 0.9044\n","\n","\tEpoch 10/100 - Train loss: 0.2639 - Val accuracy: 0.9615 - Val loss: 0.2205 - Val F1: 0.9441 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.0973 - Val accuracy: 1.0000 - Val loss: 0.1056 - Val F1: 1.0000 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.0719 - Val accuracy: 1.0000 - Val loss: 0.0676 - Val F1: 1.0000 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.0514 - Val accuracy: 1.0000 - Val loss: 0.0472 - Val F1: 1.0000 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.0262 - Val accuracy: 1.0000 - Val loss: 0.0344 - Val F1: 1.0000 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.0196 - Val accuracy: 1.0000 - Val loss: 0.0267 - Val F1: 1.0000 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0139 - Val accuracy: 1.0000 - Val loss: 0.0228 - Val F1: 1.0000 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0142 - Val accuracy: 1.0000 - Val loss: 0.0206 - Val F1: 1.0000 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0068 - Val accuracy: 1.0000 - Val loss: 0.0185 - Val F1: 1.0000 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0111 - Val accuracy: 1.0000 - Val loss: 0.0181 - Val F1: 1.0000 - LR: 0.00e+00\n","\tBest epoch: 100 - Best val accuracy: 1.0000 - Best val loss: 0.0181 - Best val F1: 1.0000\n","\n","\tEpoch 10/100 - Train loss: 0.2115 - Val accuracy: 0.8846 - Val loss: 0.2713 - Val F1: 0.8659 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.0942 - Val accuracy: 0.9231 - Val loss: 0.1498 - Val F1: 0.9044 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.0901 - Val accuracy: 0.9615 - Val loss: 0.1095 - Val F1: 0.9556 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.0388 - Val accuracy: 1.0000 - Val loss: 0.0739 - Val F1: 1.0000 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.0223 - Val accuracy: 0.9615 - Val loss: 0.0716 - Val F1: 0.9462 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.0223 - Val accuracy: 0.9615 - Val loss: 0.0616 - Val F1: 0.9462 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0139 - Val accuracy: 0.9615 - Val loss: 0.0690 - Val F1: 0.9462 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0160 - Val accuracy: 1.0000 - Val loss: 0.0532 - Val F1: 1.0000 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0094 - Val accuracy: 1.0000 - Val loss: 0.0526 - Val F1: 1.0000 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0147 - Val accuracy: 1.0000 - Val loss: 0.0607 - Val F1: 1.0000 - LR: 0.00e+00\n","\tBest epoch: 94 - Best val accuracy: 1.0000 - Best val loss: 0.0497 - Best val F1: 1.0000\n","\n","\tEpoch 10/100 - Train loss: 0.1808 - Val accuracy: 0.8846 - Val loss: 0.3973 - Val F1: 0.8482 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.1164 - Val accuracy: 0.9231 - Val loss: 0.2646 - Val F1: 0.8866 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.0506 - Val accuracy: 0.9231 - Val loss: 0.2223 - Val F1: 0.8866 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.0270 - Val accuracy: 0.9231 - Val loss: 0.1990 - Val F1: 0.8866 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.0179 - Val accuracy: 0.9231 - Val loss: 0.1962 - Val F1: 0.8866 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.0113 - Val accuracy: 0.9231 - Val loss: 0.1696 - Val F1: 0.8866 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0112 - Val accuracy: 0.9231 - Val loss: 0.1422 - Val F1: 0.8866 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0096 - Val accuracy: 0.9231 - Val loss: 0.1582 - Val F1: 0.8866 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0152 - Val accuracy: 0.9231 - Val loss: 0.1619 - Val F1: 0.8866 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.2356 - Val accuracy: 0.9231 - Val loss: 0.1726 - Val F1: 0.8866 - LR: 0.00e+00\n","\tBest epoch: 70 - Best val accuracy: 0.9231 - Best val loss: 0.1422 - Best val F1: 0.8866\n","\n","\tEpoch 10/100 - Train loss: 0.1537 - Val accuracy: 0.8846 - Val loss: 0.3959 - Val F1: 0.8482 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.0773 - Val accuracy: 0.9231 - Val loss: 0.2937 - Val F1: 0.8866 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.0371 - Val accuracy: 0.9231 - Val loss: 0.3133 - Val F1: 0.8866 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.0313 - Val accuracy: 0.9231 - Val loss: 0.3521 - Val F1: 0.8866 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.0210 - Val accuracy: 0.9231 - Val loss: 0.2781 - Val F1: 0.8866 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.0115 - Val accuracy: 0.9231 - Val loss: 0.3010 - Val F1: 0.8866 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0096 - Val accuracy: 0.9231 - Val loss: 0.3231 - Val F1: 0.8866 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0068 - Val accuracy: 0.9231 - Val loss: 0.3408 - Val F1: 0.8866 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0070 - Val accuracy: 0.9231 - Val loss: 0.3337 - Val F1: 0.8866 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0074 - Val accuracy: 0.9231 - Val loss: 0.3309 - Val F1: 0.8866 - LR: 0.00e+00\n","\tBest epoch: 48 - Best val accuracy: 0.9231 - Best val loss: 0.2699 - Best val F1: 0.8866\n","\n","Source class: WAL | Domain: 34 | Accuracy: 0.9689 | Loss: 0.0918 | F1: 0.9657\n","\n","Domain: 35\n","x_dp_dom.shape: (159, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Training and evaluating on Dp data via cross-validation...\n","\tEpoch 10/100 - Train loss: 0.1730 - Val accuracy: 0.9615 - Val loss: 0.1498 - Val F1: 0.9462 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.0786 - Val accuracy: 0.9615 - Val loss: 0.0886 - Val F1: 0.9462 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.0439 - Val accuracy: 0.9615 - Val loss: 0.0695 - Val F1: 0.9462 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.0231 - Val accuracy: 0.9615 - Val loss: 0.0604 - Val F1: 0.9462 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.0201 - Val accuracy: 0.9615 - Val loss: 0.0528 - Val F1: 0.9462 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.0116 - Val accuracy: 0.9615 - Val loss: 0.0477 - Val F1: 0.9462 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0095 - Val accuracy: 0.9615 - Val loss: 0.0457 - Val F1: 0.9462 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0057 - Val accuracy: 0.9615 - Val loss: 0.0481 - Val F1: 0.9462 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0093 - Val accuracy: 0.9615 - Val loss: 0.0428 - Val F1: 0.9462 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0067 - Val accuracy: 0.9615 - Val loss: 0.0429 - Val F1: 0.9462 - LR: 0.00e+00\n","\tBest epoch: 87 - Best val accuracy: 0.9615 - Best val loss: 0.0425 - Best val F1: 0.9462\n","\n","\tEpoch 10/100 - Train loss: 0.1724 - Val accuracy: 0.9615 - Val loss: 0.1599 - Val F1: 0.9462 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.0764 - Val accuracy: 0.9615 - Val loss: 0.0896 - Val F1: 0.9462 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.0488 - Val accuracy: 0.9615 - Val loss: 0.0727 - Val F1: 0.9462 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.0322 - Val accuracy: 0.9615 - Val loss: 0.0670 - Val F1: 0.9462 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.0222 - Val accuracy: 0.9615 - Val loss: 0.0589 - Val F1: 0.9462 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.0276 - Val accuracy: 0.9615 - Val loss: 0.0573 - Val F1: 0.9462 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0109 - Val accuracy: 0.9615 - Val loss: 0.0544 - Val F1: 0.9462 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0085 - Val accuracy: 0.9615 - Val loss: 0.0566 - Val F1: 0.9462 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0276 - Val accuracy: 0.9615 - Val loss: 0.0580 - Val F1: 0.9462 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0072 - Val accuracy: 0.9615 - Val loss: 0.0555 - Val F1: 0.9462 - LR: 0.00e+00\n","\tBest epoch: 76 - Best val accuracy: 0.9615 - Best val loss: 0.0493 - Best val F1: 0.9462\n","\n","\tEpoch 10/100 - Train loss: 0.1990 - Val accuracy: 0.9615 - Val loss: 0.1709 - Val F1: 0.9462 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.1848 - Val accuracy: 1.0000 - Val loss: 0.0725 - Val F1: 1.0000 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.0986 - Val accuracy: 1.0000 - Val loss: 0.0534 - Val F1: 1.0000 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.0288 - Val accuracy: 1.0000 - Val loss: 0.0385 - Val F1: 1.0000 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.0428 - Val accuracy: 1.0000 - Val loss: 0.0302 - Val F1: 1.0000 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.0158 - Val accuracy: 1.0000 - Val loss: 0.0241 - Val F1: 1.0000 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0107 - Val accuracy: 1.0000 - Val loss: 0.0206 - Val F1: 1.0000 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0078 - Val accuracy: 1.0000 - Val loss: 0.0187 - Val F1: 1.0000 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0102 - Val accuracy: 1.0000 - Val loss: 0.0169 - Val F1: 1.0000 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0102 - Val accuracy: 1.0000 - Val loss: 0.0164 - Val F1: 1.0000 - LR: 0.00e+00\n","\tBest epoch: 100 - Best val accuracy: 1.0000 - Best val loss: 0.0164 - Best val F1: 1.0000\n","\n","\tEpoch 10/100 - Train loss: 0.2342 - Val accuracy: 0.9231 - Val loss: 0.1764 - Val F1: 0.9044 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.2339 - Val accuracy: 0.9615 - Val loss: 0.0927 - Val F1: 0.9462 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.0556 - Val accuracy: 0.9615 - Val loss: 0.0729 - Val F1: 0.9462 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.0342 - Val accuracy: 0.9615 - Val loss: 0.0637 - Val F1: 0.9462 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.0192 - Val accuracy: 0.9615 - Val loss: 0.0527 - Val F1: 0.9462 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.0135 - Val accuracy: 0.9615 - Val loss: 0.0494 - Val F1: 0.9462 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0132 - Val accuracy: 0.9615 - Val loss: 0.0451 - Val F1: 0.9462 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0158 - Val accuracy: 0.9615 - Val loss: 0.0447 - Val F1: 0.9462 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0087 - Val accuracy: 0.9615 - Val loss: 0.0427 - Val F1: 0.9462 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0085 - Val accuracy: 0.9615 - Val loss: 0.0421 - Val F1: 0.9462 - LR: 0.00e+00\n","\tBest epoch: 93 - Best val accuracy: 0.9615 - Best val loss: 0.0403 - Best val F1: 0.9462\n","\n","\tEpoch 10/100 - Train loss: 0.1774 - Val accuracy: 0.9615 - Val loss: 0.1749 - Val F1: 0.9462 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.1123 - Val accuracy: 0.9615 - Val loss: 0.0940 - Val F1: 0.9462 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.0533 - Val accuracy: 0.9615 - Val loss: 0.0842 - Val F1: 0.9462 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.0261 - Val accuracy: 0.9615 - Val loss: 0.0770 - Val F1: 0.9462 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.0175 - Val accuracy: 0.9615 - Val loss: 0.0765 - Val F1: 0.9462 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.0181 - Val accuracy: 0.9615 - Val loss: 0.0733 - Val F1: 0.9462 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0098 - Val accuracy: 0.9615 - Val loss: 0.0772 - Val F1: 0.9462 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0177 - Val accuracy: 0.9615 - Val loss: 0.0744 - Val F1: 0.9462 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0082 - Val accuracy: 0.9615 - Val loss: 0.0713 - Val F1: 0.9462 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0101 - Val accuracy: 0.9615 - Val loss: 0.0686 - Val F1: 0.9462 - LR: 0.00e+00\n","\tBest epoch: 53 - Best val accuracy: 0.9615 - Best val loss: 0.0685 - Best val F1: 0.9462\n","\n","Source class: WAL | Domain: 35 | Accuracy: 0.9623 | Loss: 0.0634 | F1: 0.9561\n","\n","Domain: 36\n","x_dp_dom.shape: (155, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Training and evaluating on Dp data via cross-validation...\n","\tEpoch 10/100 - Train loss: 0.7036 - Val accuracy: 0.7200 - Val loss: 1.2255 - Val F1: 0.6028 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.4501 - Val accuracy: 0.7200 - Val loss: 1.0092 - Val F1: 0.6028 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.3195 - Val accuracy: 0.7200 - Val loss: 0.8841 - Val F1: 0.6028 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.2445 - Val accuracy: 0.7200 - Val loss: 0.7845 - Val F1: 0.6028 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.1973 - Val accuracy: 0.7600 - Val loss: 0.5062 - Val F1: 0.6838 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.1703 - Val accuracy: 0.9200 - Val loss: 0.2935 - Val F1: 0.8821 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.1508 - Val accuracy: 0.9200 - Val loss: 0.2216 - Val F1: 0.8821 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.1351 - Val accuracy: 0.9200 - Val loss: 0.1974 - Val F1: 0.8821 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.1276 - Val accuracy: 0.9200 - Val loss: 0.1879 - Val F1: 0.8821 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.1212 - Val accuracy: 0.9200 - Val loss: 0.1847 - Val F1: 0.8821 - LR: 0.00e+00\n","\tBest epoch: 100 - Best val accuracy: 0.9200 - Best val loss: 0.1847 - Best val F1: 0.8821\n","\n","\tEpoch 10/100 - Train loss: 0.7278 - Val accuracy: 0.7200 - Val loss: 1.2867 - Val F1: 0.6028 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.4455 - Val accuracy: 0.7200 - Val loss: 1.0217 - Val F1: 0.6028 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.2861 - Val accuracy: 0.7200 - Val loss: 0.9356 - Val F1: 0.6028 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.2077 - Val accuracy: 0.7200 - Val loss: 0.9013 - Val F1: 0.6028 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.1549 - Val accuracy: 0.7200 - Val loss: 0.7140 - Val F1: 0.6028 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.1299 - Val accuracy: 0.8400 - Val loss: 0.4049 - Val F1: 0.7980 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.1112 - Val accuracy: 0.9200 - Val loss: 0.2612 - Val F1: 0.8821 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0965 - Val accuracy: 0.9200 - Val loss: 0.2247 - Val F1: 0.9005 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0911 - Val accuracy: 0.9200 - Val loss: 0.2147 - Val F1: 0.9005 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0910 - Val accuracy: 0.9200 - Val loss: 0.2127 - Val F1: 0.9005 - LR: 0.00e+00\n","\tBest epoch: 99 - Best val accuracy: 0.9200 - Best val loss: 0.2127 - Best val F1: 0.9005\n","\n","\tEpoch 10/100 - Train loss: 0.7485 - Val accuracy: 0.7200 - Val loss: 1.2723 - Val F1: 0.6028 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.4871 - Val accuracy: 0.7200 - Val loss: 1.0676 - Val F1: 0.6028 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.3823 - Val accuracy: 0.7200 - Val loss: 0.9475 - Val F1: 0.6028 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.2997 - Val accuracy: 0.7200 - Val loss: 0.8364 - Val F1: 0.6028 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.2525 - Val accuracy: 0.7600 - Val loss: 0.5639 - Val F1: 0.6838 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.2203 - Val accuracy: 0.8800 - Val loss: 0.2848 - Val F1: 0.8424 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.1961 - Val accuracy: 0.9600 - Val loss: 0.1853 - Val F1: 0.9405 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.1735 - Val accuracy: 0.9600 - Val loss: 0.1523 - Val F1: 0.9405 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.1698 - Val accuracy: 0.9600 - Val loss: 0.1397 - Val F1: 0.9405 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.1660 - Val accuracy: 0.9600 - Val loss: 0.1354 - Val F1: 0.9405 - LR: 0.00e+00\n","\tBest epoch: 100 - Best val accuracy: 0.9600 - Best val loss: 0.1354 - Best val F1: 0.9405\n","\n","\tEpoch 10/100 - Train loss: 0.7134 - Val accuracy: 0.7200 - Val loss: 1.3065 - Val F1: 0.6028 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.4918 - Val accuracy: 0.7200 - Val loss: 1.1003 - Val F1: 0.6028 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.3630 - Val accuracy: 0.7200 - Val loss: 0.9591 - Val F1: 0.6028 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.2852 - Val accuracy: 0.7200 - Val loss: 0.8808 - Val F1: 0.6028 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.2433 - Val accuracy: 0.7200 - Val loss: 0.6163 - Val F1: 0.6028 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.2026 - Val accuracy: 0.8800 - Val loss: 0.2905 - Val F1: 0.8424 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.1746 - Val accuracy: 0.9600 - Val loss: 0.1842 - Val F1: 0.9405 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.1518 - Val accuracy: 0.9600 - Val loss: 0.1518 - Val F1: 0.9405 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.1431 - Val accuracy: 0.9600 - Val loss: 0.1391 - Val F1: 0.9405 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.1455 - Val accuracy: 0.9600 - Val loss: 0.1348 - Val F1: 0.9405 - LR: 0.00e+00\n","\tBest epoch: 100 - Best val accuracy: 0.9600 - Best val loss: 0.1348 - Best val F1: 0.9405\n","\n","\tEpoch 10/100 - Train loss: 0.7801 - Val accuracy: 0.7200 - Val loss: 1.3216 - Val F1: 0.6028 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.4943 - Val accuracy: 0.7200 - Val loss: 1.1208 - Val F1: 0.6028 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.3738 - Val accuracy: 0.7200 - Val loss: 0.9978 - Val F1: 0.6028 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.3040 - Val accuracy: 0.7200 - Val loss: 0.9357 - Val F1: 0.6028 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.2476 - Val accuracy: 0.7200 - Val loss: 0.6965 - Val F1: 0.6028 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.2187 - Val accuracy: 0.8800 - Val loss: 0.3520 - Val F1: 0.8424 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.2013 - Val accuracy: 0.8800 - Val loss: 0.2324 - Val F1: 0.8424 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.1863 - Val accuracy: 0.9200 - Val loss: 0.1959 - Val F1: 0.8821 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.1744 - Val accuracy: 0.9200 - Val loss: 0.1823 - Val F1: 0.8821 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.1730 - Val accuracy: 0.9200 - Val loss: 0.1776 - Val F1: 0.8821 - LR: 0.00e+00\n","\tBest epoch: 100 - Best val accuracy: 0.9200 - Best val loss: 0.1776 - Best val F1: 0.8821\n","\n","Source class: WAL | Domain: 36 | Accuracy: 0.9226 | Loss: 0.2057 | F1: 0.8911\n","\n","Domain: 37\n","x_dp_dom.shape: (154, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Training and evaluating on Dp data via cross-validation...\n","\tEpoch 10/100 - Train loss: 0.7709 - Val accuracy: 0.7200 - Val loss: 1.2814 - Val F1: 0.6028 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.4401 - Val accuracy: 0.7200 - Val loss: 1.0426 - Val F1: 0.6028 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.3464 - Val accuracy: 0.7200 - Val loss: 0.8628 - Val F1: 0.6028 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.2999 - Val accuracy: 0.7200 - Val loss: 0.7043 - Val F1: 0.6028 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.2589 - Val accuracy: 0.8000 - Val loss: 0.4252 - Val F1: 0.7465 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.2337 - Val accuracy: 0.9200 - Val loss: 0.2912 - Val F1: 0.8821 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.2162 - Val accuracy: 0.9200 - Val loss: 0.2575 - Val F1: 0.8821 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.1989 - Val accuracy: 0.9200 - Val loss: 0.2458 - Val F1: 0.8821 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.1813 - Val accuracy: 0.9200 - Val loss: 0.2402 - Val F1: 0.8821 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.1798 - Val accuracy: 0.9200 - Val loss: 0.2381 - Val F1: 0.8821 - LR: 0.00e+00\n","\tBest epoch: 100 - Best val accuracy: 0.9200 - Best val loss: 0.2381 - Best val F1: 0.8821\n","\n","\tEpoch 10/100 - Train loss: 0.8211 - Val accuracy: 0.7200 - Val loss: 1.3147 - Val F1: 0.6028 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.4600 - Val accuracy: 0.7200 - Val loss: 1.1173 - Val F1: 0.6028 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.3454 - Val accuracy: 0.7200 - Val loss: 0.9186 - Val F1: 0.6028 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.2782 - Val accuracy: 0.7600 - Val loss: 0.6546 - Val F1: 0.6838 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.2554 - Val accuracy: 0.8800 - Val loss: 0.3702 - Val F1: 0.8424 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.2191 - Val accuracy: 0.9200 - Val loss: 0.2482 - Val F1: 0.8821 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.2035 - Val accuracy: 0.9200 - Val loss: 0.2031 - Val F1: 0.8821 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.1848 - Val accuracy: 0.9200 - Val loss: 0.1842 - Val F1: 0.8821 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.1752 - Val accuracy: 0.9200 - Val loss: 0.1759 - Val F1: 0.8824 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.1703 - Val accuracy: 0.9200 - Val loss: 0.1734 - Val F1: 0.8824 - LR: 0.00e+00\n","\tBest epoch: 100 - Best val accuracy: 0.9200 - Best val loss: 0.1734 - Best val F1: 0.8824\n","\n","\tEpoch 10/100 - Train loss: 0.7150 - Val accuracy: 0.7200 - Val loss: 1.2913 - Val F1: 0.6028 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.4107 - Val accuracy: 0.7200 - Val loss: 1.0684 - Val F1: 0.6028 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.3433 - Val accuracy: 0.7200 - Val loss: 0.9514 - Val F1: 0.6028 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.2928 - Val accuracy: 0.7200 - Val loss: 0.8759 - Val F1: 0.6028 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.2592 - Val accuracy: 0.7200 - Val loss: 0.6038 - Val F1: 0.6028 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.2376 - Val accuracy: 0.9200 - Val loss: 0.3510 - Val F1: 0.8821 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.2198 - Val accuracy: 0.9200 - Val loss: 0.2870 - Val F1: 0.8821 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.2011 - Val accuracy: 0.9200 - Val loss: 0.2713 - Val F1: 0.8821 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.2017 - Val accuracy: 0.9200 - Val loss: 0.2655 - Val F1: 0.8821 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.2057 - Val accuracy: 0.9200 - Val loss: 0.2635 - Val F1: 0.8821 - LR: 0.00e+00\n","\tBest epoch: 100 - Best val accuracy: 0.9200 - Best val loss: 0.2635 - Best val F1: 0.8821\n","\n","\tEpoch 10/100 - Train loss: 0.7365 - Val accuracy: 0.7200 - Val loss: 1.3085 - Val F1: 0.6028 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.4508 - Val accuracy: 0.7200 - Val loss: 1.0706 - Val F1: 0.6028 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.3450 - Val accuracy: 0.7200 - Val loss: 0.9335 - Val F1: 0.6028 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.2703 - Val accuracy: 0.7200 - Val loss: 0.8961 - Val F1: 0.6028 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.2288 - Val accuracy: 0.7200 - Val loss: 0.6431 - Val F1: 0.6028 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.2010 - Val accuracy: 0.8800 - Val loss: 0.3928 - Val F1: 0.8424 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.1780 - Val accuracy: 0.9200 - Val loss: 0.3224 - Val F1: 0.8821 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.1677 - Val accuracy: 0.9200 - Val loss: 0.3021 - Val F1: 0.8821 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.1539 - Val accuracy: 0.9200 - Val loss: 0.2947 - Val F1: 0.8821 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.1554 - Val accuracy: 0.9200 - Val loss: 0.2916 - Val F1: 0.8821 - LR: 0.00e+00\n","\tBest epoch: 100 - Best val accuracy: 0.9200 - Best val loss: 0.2916 - Best val F1: 0.8821\n","\n","\tEpoch 10/100 - Train loss: 0.5890 - Val accuracy: 0.7200 - Val loss: 1.1869 - Val F1: 0.6028 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.4229 - Val accuracy: 0.7200 - Val loss: 0.9683 - Val F1: 0.6028 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.3496 - Val accuracy: 0.7200 - Val loss: 0.9334 - Val F1: 0.6028 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.2875 - Val accuracy: 0.7200 - Val loss: 0.8439 - Val F1: 0.6028 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.2632 - Val accuracy: 0.8400 - Val loss: 0.5718 - Val F1: 0.7980 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.2334 - Val accuracy: 0.8800 - Val loss: 0.3893 - Val F1: 0.8424 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.2047 - Val accuracy: 0.9200 - Val loss: 0.3292 - Val F1: 0.8821 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.1968 - Val accuracy: 0.9200 - Val loss: 0.3089 - Val F1: 0.8821 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.1886 - Val accuracy: 0.9200 - Val loss: 0.2999 - Val F1: 0.8821 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.1841 - Val accuracy: 0.9200 - Val loss: 0.2960 - Val F1: 0.8821 - LR: 0.00e+00\n","\tBest epoch: 100 - Best val accuracy: 0.9200 - Best val loss: 0.2960 - Best val F1: 0.8821\n","\n","Source class: WAL | Domain: 37 | Accuracy: 0.9092 | Loss: 0.2849 | F1: 0.8696\n","\n","Domain: 38\n","x_dp_dom.shape: (158, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Training and evaluating on Dp data via cross-validation...\n","\tEpoch 10/100 - Train loss: 0.6732 - Val accuracy: 0.6923 - Val loss: 1.1906 - Val F1: 0.5664 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.3491 - Val accuracy: 0.6923 - Val loss: 0.9284 - Val F1: 0.5664 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.2182 - Val accuracy: 0.6923 - Val loss: 0.7609 - Val F1: 0.5664 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.1553 - Val accuracy: 0.7308 - Val loss: 0.5009 - Val F1: 0.6309 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.1211 - Val accuracy: 0.9231 - Val loss: 0.2514 - Val F1: 0.8995 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.1014 - Val accuracy: 0.9615 - Val loss: 0.1509 - Val F1: 0.9615 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0846 - Val accuracy: 0.9615 - Val loss: 0.1207 - Val F1: 0.9615 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0779 - Val accuracy: 0.9615 - Val loss: 0.1090 - Val F1: 0.9615 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0717 - Val accuracy: 1.0000 - Val loss: 0.1031 - Val F1: 1.0000 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0712 - Val accuracy: 1.0000 - Val loss: 0.1010 - Val F1: 1.0000 - LR: 0.00e+00\n","\tBest epoch: 100 - Best val accuracy: 1.0000 - Best val loss: 0.1010 - Best val F1: 1.0000\n","\n","\tEpoch 10/100 - Train loss: 0.8302 - Val accuracy: 0.6923 - Val loss: 1.3031 - Val F1: 0.5664 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.4948 - Val accuracy: 0.6923 - Val loss: 1.0870 - Val F1: 0.5664 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.3239 - Val accuracy: 0.6923 - Val loss: 0.8541 - Val F1: 0.5664 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.2437 - Val accuracy: 0.7308 - Val loss: 0.6096 - Val F1: 0.6560 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.1987 - Val accuracy: 0.8846 - Val loss: 0.3812 - Val F1: 0.8339 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.1754 - Val accuracy: 0.9231 - Val loss: 0.2424 - Val F1: 0.8910 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.1588 - Val accuracy: 0.9231 - Val loss: 0.1918 - Val F1: 0.8910 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.1467 - Val accuracy: 0.9231 - Val loss: 0.1717 - Val F1: 0.8910 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.1382 - Val accuracy: 0.9231 - Val loss: 0.1619 - Val F1: 0.8910 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.1407 - Val accuracy: 0.9231 - Val loss: 0.1586 - Val F1: 0.8910 - LR: 0.00e+00\n","\tBest epoch: 100 - Best val accuracy: 0.9231 - Best val loss: 0.1586 - Best val F1: 0.8910\n","\n","\tEpoch 10/100 - Train loss: 0.6424 - Val accuracy: 0.6923 - Val loss: 1.1822 - Val F1: 0.5664 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.3457 - Val accuracy: 0.6923 - Val loss: 0.9842 - Val F1: 0.5664 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.2292 - Val accuracy: 0.6923 - Val loss: 0.8681 - Val F1: 0.5664 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.1790 - Val accuracy: 0.6923 - Val loss: 0.6806 - Val F1: 0.5664 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.1417 - Val accuracy: 0.8077 - Val loss: 0.4294 - Val F1: 0.7797 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.1320 - Val accuracy: 0.8846 - Val loss: 0.2637 - Val F1: 0.8339 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.1130 - Val accuracy: 0.9231 - Val loss: 0.1924 - Val F1: 0.8910 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.1016 - Val accuracy: 0.9231 - Val loss: 0.1681 - Val F1: 0.8910 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0954 - Val accuracy: 0.9231 - Val loss: 0.1598 - Val F1: 0.8910 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0940 - Val accuracy: 0.9231 - Val loss: 0.1576 - Val F1: 0.8910 - LR: 0.00e+00\n","\tBest epoch: 100 - Best val accuracy: 0.9231 - Best val loss: 0.1576 - Best val F1: 0.8910\n","\n","\tEpoch 10/100 - Train loss: 0.1790 - Val accuracy: 0.9615 - Val loss: 0.1922 - Val F1: 0.9462 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.0947 - Val accuracy: 0.9615 - Val loss: 0.0885 - Val F1: 0.9462 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.0462 - Val accuracy: 0.9615 - Val loss: 0.0671 - Val F1: 0.9615 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.0378 - Val accuracy: 0.9231 - Val loss: 0.0628 - Val F1: 0.9231 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.0234 - Val accuracy: 0.9231 - Val loss: 0.0610 - Val F1: 0.9231 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.0196 - Val accuracy: 0.9615 - Val loss: 0.0619 - Val F1: 0.9615 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0133 - Val accuracy: 0.9231 - Val loss: 0.0614 - Val F1: 0.9231 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0160 - Val accuracy: 0.9231 - Val loss: 0.0626 - Val F1: 0.9231 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0129 - Val accuracy: 0.9231 - Val loss: 0.0602 - Val F1: 0.9231 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0158 - Val accuracy: 0.9231 - Val loss: 0.0604 - Val F1: 0.9231 - LR: 0.00e+00\n","\tBest epoch: 48 - Best val accuracy: 0.9615 - Best val loss: 0.0594 - Best val F1: 0.9462\n","\n","\tEpoch 10/100 - Train loss: 0.1863 - Val accuracy: 0.9615 - Val loss: 0.1702 - Val F1: 0.9462 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.0778 - Val accuracy: 0.9615 - Val loss: 0.0892 - Val F1: 0.9462 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.0457 - Val accuracy: 0.9615 - Val loss: 0.0784 - Val F1: 0.9462 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.1804 - Val accuracy: 0.9615 - Val loss: 0.0675 - Val F1: 0.9462 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.0499 - Val accuracy: 0.9615 - Val loss: 0.0714 - Val F1: 0.9462 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.0196 - Val accuracy: 0.9615 - Val loss: 0.0722 - Val F1: 0.9462 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0176 - Val accuracy: 0.9615 - Val loss: 0.0722 - Val F1: 0.9462 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0192 - Val accuracy: 0.9615 - Val loss: 0.0756 - Val F1: 0.9462 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0093 - Val accuracy: 0.9615 - Val loss: 0.0756 - Val F1: 0.9462 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0065 - Val accuracy: 0.9615 - Val loss: 0.0788 - Val F1: 0.9462 - LR: 0.00e+00\n","\tBest epoch: 54 - Best val accuracy: 0.9615 - Best val loss: 0.0651 - Best val F1: 0.9462\n","\n","Source class: WAL | Domain: 38 | Accuracy: 0.9433 | Loss: 0.1340 | F1: 0.9308\n","\n","Domain: 39\n","x_dp_dom.shape: (165, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Training and evaluating on Dp data via cross-validation...\n","\tEpoch 10/100 - Train loss: 0.2916 - Val accuracy: 0.9259 - Val loss: 0.2767 - Val F1: 0.8908 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.0982 - Val accuracy: 0.9630 - Val loss: 0.0841 - Val F1: 0.9573 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.0399 - Val accuracy: 1.0000 - Val loss: 0.0283 - Val F1: 1.0000 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.0201 - Val accuracy: 1.0000 - Val loss: 0.0124 - Val F1: 1.0000 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.0116 - Val accuracy: 1.0000 - Val loss: 0.0072 - Val F1: 1.0000 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.0089 - Val accuracy: 1.0000 - Val loss: 0.0053 - Val F1: 1.0000 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0079 - Val accuracy: 1.0000 - Val loss: 0.0040 - Val F1: 1.0000 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0112 - Val accuracy: 1.0000 - Val loss: 0.0037 - Val F1: 1.0000 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0083 - Val accuracy: 1.0000 - Val loss: 0.0031 - Val F1: 1.0000 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0078 - Val accuracy: 1.0000 - Val loss: 0.0032 - Val F1: 1.0000 - LR: 0.00e+00\n","\tBest epoch: 96 - Best val accuracy: 1.0000 - Best val loss: 0.0028 - Best val F1: 1.0000\n","\n","\tEpoch 10/100 - Train loss: 0.2865 - Val accuracy: 0.9259 - Val loss: 0.3051 - Val F1: 0.8908 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.0993 - Val accuracy: 0.9630 - Val loss: 0.1276 - Val F1: 0.9573 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.0332 - Val accuracy: 0.9630 - Val loss: 0.0605 - Val F1: 0.9573 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.0196 - Val accuracy: 1.0000 - Val loss: 0.0389 - Val F1: 1.0000 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.0113 - Val accuracy: 1.0000 - Val loss: 0.0269 - Val F1: 1.0000 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.0072 - Val accuracy: 1.0000 - Val loss: 0.0241 - Val F1: 1.0000 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0058 - Val accuracy: 1.0000 - Val loss: 0.0170 - Val F1: 1.0000 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0079 - Val accuracy: 1.0000 - Val loss: 0.0171 - Val F1: 1.0000 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0053 - Val accuracy: 1.0000 - Val loss: 0.0177 - Val F1: 1.0000 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0037 - Val accuracy: 1.0000 - Val loss: 0.0135 - Val F1: 1.0000 - LR: 0.00e+00\n","\tBest epoch: 100 - Best val accuracy: 1.0000 - Best val loss: 0.0135 - Best val F1: 1.0000\n","\n","\tEpoch 10/100 - Train loss: 0.2692 - Val accuracy: 0.9259 - Val loss: 0.2754 - Val F1: 0.8908 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.0960 - Val accuracy: 0.9259 - Val loss: 0.1183 - Val F1: 0.8908 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.0371 - Val accuracy: 1.0000 - Val loss: 0.0477 - Val F1: 1.0000 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.0171 - Val accuracy: 1.0000 - Val loss: 0.0274 - Val F1: 1.0000 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.0125 - Val accuracy: 1.0000 - Val loss: 0.0214 - Val F1: 1.0000 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.0162 - Val accuracy: 1.0000 - Val loss: 0.0185 - Val F1: 1.0000 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0074 - Val accuracy: 1.0000 - Val loss: 0.0167 - Val F1: 1.0000 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0065 - Val accuracy: 1.0000 - Val loss: 0.0114 - Val F1: 1.0000 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0039 - Val accuracy: 1.0000 - Val loss: 0.0107 - Val F1: 1.0000 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0052 - Val accuracy: 1.0000 - Val loss: 0.0104 - Val F1: 1.0000 - LR: 0.00e+00\n","\tBest epoch: 87 - Best val accuracy: 1.0000 - Best val loss: 0.0098 - Best val F1: 1.0000\n","\n","\tEpoch 10/100 - Train loss: 0.2761 - Val accuracy: 0.9259 - Val loss: 0.1988 - Val F1: 0.8908 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.0528 - Val accuracy: 1.0000 - Val loss: 0.0432 - Val F1: 1.0000 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.0254 - Val accuracy: 1.0000 - Val loss: 0.0140 - Val F1: 1.0000 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.0142 - Val accuracy: 1.0000 - Val loss: 0.0076 - Val F1: 1.0000 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.0090 - Val accuracy: 1.0000 - Val loss: 0.0050 - Val F1: 1.0000 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.0091 - Val accuracy: 1.0000 - Val loss: 0.0035 - Val F1: 1.0000 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0065 - Val accuracy: 1.0000 - Val loss: 0.0033 - Val F1: 1.0000 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0065 - Val accuracy: 1.0000 - Val loss: 0.0024 - Val F1: 1.0000 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0048 - Val accuracy: 1.0000 - Val loss: 0.0025 - Val F1: 1.0000 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0040 - Val accuracy: 1.0000 - Val loss: 0.0022 - Val F1: 1.0000 - LR: 0.00e+00\n","\tBest epoch: 100 - Best val accuracy: 1.0000 - Best val loss: 0.0022 - Best val F1: 1.0000\n","\n","\tEpoch 10/100 - Train loss: 0.2024 - Val accuracy: 0.9259 - Val loss: 0.2571 - Val F1: 0.8908 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.0542 - Val accuracy: 0.9259 - Val loss: 0.1166 - Val F1: 0.8908 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.0190 - Val accuracy: 0.9630 - Val loss: 0.0641 - Val F1: 0.9573 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.0135 - Val accuracy: 1.0000 - Val loss: 0.0562 - Val F1: 1.0000 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.0073 - Val accuracy: 1.0000 - Val loss: 0.0400 - Val F1: 1.0000 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.0058 - Val accuracy: 1.0000 - Val loss: 0.0307 - Val F1: 1.0000 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0042 - Val accuracy: 1.0000 - Val loss: 0.0299 - Val F1: 1.0000 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0070 - Val accuracy: 1.0000 - Val loss: 0.0209 - Val F1: 1.0000 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0052 - Val accuracy: 1.0000 - Val loss: 0.0316 - Val F1: 1.0000 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0048 - Val accuracy: 1.0000 - Val loss: 0.0224 - Val F1: 1.0000 - LR: 0.00e+00\n","\tBest epoch: 98 - Best val accuracy: 1.0000 - Best val loss: 0.0184 - Best val F1: 1.0000\n","\n","Source class: WAL | Domain: 39 | Accuracy: 1.0000 | Loss: 0.0121 | F1: 1.0000\n","\n","Domain: 40\n","x_dp_dom.shape: (155, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Training and evaluating on Dp data via cross-validation...\n","\tEpoch 10/100 - Train loss: 0.7211 - Val accuracy: 0.7200 - Val loss: 1.2048 - Val F1: 0.6028 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.4580 - Val accuracy: 0.7200 - Val loss: 0.9573 - Val F1: 0.6028 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.3451 - Val accuracy: 0.7200 - Val loss: 0.8772 - Val F1: 0.6028 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.2550 - Val accuracy: 0.7200 - Val loss: 0.7811 - Val F1: 0.6028 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.2070 - Val accuracy: 0.8800 - Val loss: 0.4541 - Val F1: 0.8424 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.1711 - Val accuracy: 0.9200 - Val loss: 0.2465 - Val F1: 0.8821 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.1445 - Val accuracy: 0.9600 - Val loss: 0.1791 - Val F1: 0.9405 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.1270 - Val accuracy: 0.9600 - Val loss: 0.1602 - Val F1: 0.9405 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.1253 - Val accuracy: 0.9600 - Val loss: 0.1546 - Val F1: 0.9405 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.1176 - Val accuracy: 0.9600 - Val loss: 0.1537 - Val F1: 0.9405 - LR: 0.00e+00\n","\tBest epoch: 98 - Best val accuracy: 0.9600 - Best val loss: 0.1537 - Best val F1: 0.9405\n","\n","\tEpoch 10/100 - Train loss: 0.7242 - Val accuracy: 0.7200 - Val loss: 1.2628 - Val F1: 0.6028 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.4252 - Val accuracy: 0.7200 - Val loss: 1.0335 - Val F1: 0.6028 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.3311 - Val accuracy: 0.7200 - Val loss: 0.9265 - Val F1: 0.6028 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.2556 - Val accuracy: 0.7200 - Val loss: 0.8259 - Val F1: 0.6028 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.2062 - Val accuracy: 0.8400 - Val loss: 0.5675 - Val F1: 0.7980 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.1754 - Val accuracy: 0.8800 - Val loss: 0.3574 - Val F1: 0.8424 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.1566 - Val accuracy: 0.9200 - Val loss: 0.2660 - Val F1: 0.8821 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.1375 - Val accuracy: 0.9200 - Val loss: 0.2236 - Val F1: 0.8821 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.1243 - Val accuracy: 0.9200 - Val loss: 0.2055 - Val F1: 0.8821 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.1217 - Val accuracy: 0.9200 - Val loss: 0.1984 - Val F1: 0.8821 - LR: 0.00e+00\n","\tBest epoch: 100 - Best val accuracy: 0.9200 - Best val loss: 0.1984 - Best val F1: 0.8821\n","\n","\tEpoch 10/100 - Train loss: 0.7475 - Val accuracy: 0.7200 - Val loss: 1.2366 - Val F1: 0.6028 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.4796 - Val accuracy: 0.7200 - Val loss: 1.0324 - Val F1: 0.6028 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.3639 - Val accuracy: 0.7200 - Val loss: 0.9174 - Val F1: 0.6028 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.2906 - Val accuracy: 0.7200 - Val loss: 0.7932 - Val F1: 0.6028 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.2433 - Val accuracy: 0.8400 - Val loss: 0.4863 - Val F1: 0.7980 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.2003 - Val accuracy: 0.9200 - Val loss: 0.2970 - Val F1: 0.8821 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.1776 - Val accuracy: 0.9200 - Val loss: 0.2278 - Val F1: 0.8821 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.1711 - Val accuracy: 0.9200 - Val loss: 0.1989 - Val F1: 0.8821 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.1553 - Val accuracy: 0.9200 - Val loss: 0.1858 - Val F1: 0.8821 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.1575 - Val accuracy: 0.9200 - Val loss: 0.1804 - Val F1: 0.8821 - LR: 0.00e+00\n","\tBest epoch: 100 - Best val accuracy: 0.9200 - Best val loss: 0.1804 - Best val F1: 0.8821\n","\n","\tEpoch 10/100 - Train loss: 0.7879 - Val accuracy: 0.7200 - Val loss: 1.3178 - Val F1: 0.6028 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.4845 - Val accuracy: 0.7200 - Val loss: 1.0712 - Val F1: 0.6028 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.3731 - Val accuracy: 0.7200 - Val loss: 0.8780 - Val F1: 0.6028 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.2923 - Val accuracy: 0.7200 - Val loss: 0.6692 - Val F1: 0.6028 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.2440 - Val accuracy: 0.8400 - Val loss: 0.4244 - Val F1: 0.7980 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.2076 - Val accuracy: 0.9200 - Val loss: 0.3055 - Val F1: 0.8821 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.1800 - Val accuracy: 0.9200 - Val loss: 0.2553 - Val F1: 0.8821 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.1608 - Val accuracy: 0.9200 - Val loss: 0.2325 - Val F1: 0.8821 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.1526 - Val accuracy: 0.9200 - Val loss: 0.2214 - Val F1: 0.8821 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.1493 - Val accuracy: 0.9200 - Val loss: 0.2163 - Val F1: 0.8821 - LR: 0.00e+00\n","\tBest epoch: 100 - Best val accuracy: 0.9200 - Best val loss: 0.2163 - Best val F1: 0.8821\n","\n","\tEpoch 10/100 - Train loss: 0.6620 - Val accuracy: 0.7200 - Val loss: 1.2745 - Val F1: 0.6028 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.4167 - Val accuracy: 0.7200 - Val loss: 1.0566 - Val F1: 0.6028 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.3102 - Val accuracy: 0.7200 - Val loss: 0.9479 - Val F1: 0.6028 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.2387 - Val accuracy: 0.7200 - Val loss: 0.8786 - Val F1: 0.6028 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.1910 - Val accuracy: 0.7600 - Val loss: 0.6434 - Val F1: 0.6838 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.1542 - Val accuracy: 0.8800 - Val loss: 0.4095 - Val F1: 0.8424 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.1328 - Val accuracy: 0.8800 - Val loss: 0.3088 - Val F1: 0.8424 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.1225 - Val accuracy: 0.9200 - Val loss: 0.2640 - Val F1: 0.8821 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.1101 - Val accuracy: 0.9200 - Val loss: 0.2455 - Val F1: 0.8821 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.1002 - Val accuracy: 0.9200 - Val loss: 0.2375 - Val F1: 0.8821 - LR: 0.00e+00\n","\tBest epoch: 100 - Best val accuracy: 0.9200 - Best val loss: 0.2375 - Best val F1: 0.8821\n","\n","Source class: WAL | Domain: 40 | Accuracy: 0.8968 | Loss: 0.2281 | F1: 0.8516\n","\n","Domain: 41\n","x_dp_dom.shape: (156, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Training and evaluating on Dp data via cross-validation...\n","\tEpoch 10/100 - Train loss: 0.5511 - Val accuracy: 0.7200 - Val loss: 1.1873 - Val F1: 0.6028 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.3236 - Val accuracy: 0.7200 - Val loss: 0.9312 - Val F1: 0.6028 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.2253 - Val accuracy: 0.7200 - Val loss: 0.7191 - Val F1: 0.6028 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.1876 - Val accuracy: 0.9200 - Val loss: 0.5213 - Val F1: 0.8821 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.1550 - Val accuracy: 0.9200 - Val loss: 0.3827 - Val F1: 0.8821 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.1249 - Val accuracy: 0.9200 - Val loss: 0.3200 - Val F1: 0.8821 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.1047 - Val accuracy: 0.9200 - Val loss: 0.2993 - Val F1: 0.8821 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.1086 - Val accuracy: 0.9200 - Val loss: 0.2905 - Val F1: 0.8821 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0953 - Val accuracy: 0.9200 - Val loss: 0.2866 - Val F1: 0.8821 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0955 - Val accuracy: 0.9200 - Val loss: 0.2846 - Val F1: 0.8821 - LR: 0.00e+00\n","\tBest epoch: 100 - Best val accuracy: 0.9200 - Best val loss: 0.2846 - Best val F1: 0.8821\n","\n","\tEpoch 10/100 - Train loss: 0.7217 - Val accuracy: 0.7200 - Val loss: 1.2217 - Val F1: 0.6028 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.3916 - Val accuracy: 0.7200 - Val loss: 0.9769 - Val F1: 0.6028 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.2795 - Val accuracy: 0.7200 - Val loss: 0.7277 - Val F1: 0.6028 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.2193 - Val accuracy: 0.7600 - Val loss: 0.5044 - Val F1: 0.6811 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.1740 - Val accuracy: 0.9200 - Val loss: 0.3608 - Val F1: 0.8872 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.1439 - Val accuracy: 0.9200 - Val loss: 0.3100 - Val F1: 0.8872 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.1323 - Val accuracy: 0.9200 - Val loss: 0.2938 - Val F1: 0.8872 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.1143 - Val accuracy: 0.9200 - Val loss: 0.2882 - Val F1: 0.8872 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.1141 - Val accuracy: 0.9200 - Val loss: 0.2857 - Val F1: 0.8872 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.1123 - Val accuracy: 0.9200 - Val loss: 0.2849 - Val F1: 0.8872 - LR: 0.00e+00\n","\tBest epoch: 100 - Best val accuracy: 0.9200 - Best val loss: 0.2849 - Best val F1: 0.8872\n","\n","\tEpoch 10/100 - Train loss: 0.7623 - Val accuracy: 0.7200 - Val loss: 1.2466 - Val F1: 0.6028 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.4409 - Val accuracy: 0.7200 - Val loss: 1.0133 - Val F1: 0.6028 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.2972 - Val accuracy: 0.7200 - Val loss: 0.8030 - Val F1: 0.6028 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.2397 - Val accuracy: 0.7200 - Val loss: 0.5980 - Val F1: 0.6028 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.2032 - Val accuracy: 0.9200 - Val loss: 0.4038 - Val F1: 0.8872 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.1627 - Val accuracy: 0.9200 - Val loss: 0.3213 - Val F1: 0.8872 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.1502 - Val accuracy: 0.9200 - Val loss: 0.2959 - Val F1: 0.8872 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.1288 - Val accuracy: 0.9200 - Val loss: 0.2882 - Val F1: 0.8872 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.1228 - Val accuracy: 0.9200 - Val loss: 0.2859 - Val F1: 0.8872 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.1233 - Val accuracy: 0.9200 - Val loss: 0.2852 - Val F1: 0.8872 - LR: 0.00e+00\n","\tBest epoch: 100 - Best val accuracy: 0.9200 - Best val loss: 0.2852 - Best val F1: 0.8872\n","\n","\tEpoch 10/100 - Train loss: 0.7244 - Val accuracy: 0.7200 - Val loss: 1.2515 - Val F1: 0.6028 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.4439 - Val accuracy: 0.7200 - Val loss: 1.0444 - Val F1: 0.6028 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.3168 - Val accuracy: 0.7200 - Val loss: 0.8482 - Val F1: 0.6028 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.2564 - Val accuracy: 0.8800 - Val loss: 0.6591 - Val F1: 0.8246 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.2193 - Val accuracy: 0.8800 - Val loss: 0.5001 - Val F1: 0.8246 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.1882 - Val accuracy: 0.8800 - Val loss: 0.4202 - Val F1: 0.8246 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.1750 - Val accuracy: 0.8800 - Val loss: 0.3990 - Val F1: 0.8246 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.1618 - Val accuracy: 0.8800 - Val loss: 0.3958 - Val F1: 0.8246 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.1508 - Val accuracy: 0.8800 - Val loss: 0.3965 - Val F1: 0.8246 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.1453 - Val accuracy: 0.8800 - Val loss: 0.3974 - Val F1: 0.8246 - LR: 0.00e+00\n","\tBest epoch: 79 - Best val accuracy: 0.8800 - Best val loss: 0.3957 - Best val F1: 0.8246\n","\n","\tEpoch 10/100 - Train loss: 0.6804 - Val accuracy: 0.7200 - Val loss: 1.1765 - Val F1: 0.6028 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.4150 - Val accuracy: 0.7200 - Val loss: 0.9687 - Val F1: 0.6028 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.3003 - Val accuracy: 0.7200 - Val loss: 0.8128 - Val F1: 0.6028 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.2307 - Val accuracy: 0.7200 - Val loss: 0.6269 - Val F1: 0.6028 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.1876 - Val accuracy: 0.9200 - Val loss: 0.4095 - Val F1: 0.8821 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.1521 - Val accuracy: 0.9200 - Val loss: 0.2962 - Val F1: 0.8824 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.1320 - Val accuracy: 0.9200 - Val loss: 0.2637 - Val F1: 0.8824 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.1154 - Val accuracy: 0.9200 - Val loss: 0.2547 - Val F1: 0.8824 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.1056 - Val accuracy: 0.9200 - Val loss: 0.2521 - Val F1: 0.8824 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.1032 - Val accuracy: 0.9200 - Val loss: 0.2513 - Val F1: 0.8824 - LR: 0.00e+00\n","\tBest epoch: 100 - Best val accuracy: 0.9200 - Best val loss: 0.2513 - Best val F1: 0.8824\n","\n","Source class: WAL | Domain: 41 | Accuracy: 0.9105 | Loss: 0.2586 | F1: 0.8798\n","\n","Domain: 42\n","x_dp_dom.shape: (158, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Training and evaluating on Dp data via cross-validation...\n","\tEpoch 10/100 - Train loss: 0.9248 - Val accuracy: 0.6923 - Val loss: 1.3353 - Val F1: 0.5664 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.6479 - Val accuracy: 0.6923 - Val loss: 1.1460 - Val F1: 0.5664 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.4939 - Val accuracy: 0.6923 - Val loss: 1.0294 - Val F1: 0.5664 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.3889 - Val accuracy: 0.6923 - Val loss: 0.9502 - Val F1: 0.5664 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.3214 - Val accuracy: 0.6923 - Val loss: 0.7200 - Val F1: 0.5664 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.2716 - Val accuracy: 0.8846 - Val loss: 0.4305 - Val F1: 0.8314 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.2418 - Val accuracy: 0.8846 - Val loss: 0.3188 - Val F1: 0.8314 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.2307 - Val accuracy: 0.8846 - Val loss: 0.2828 - Val F1: 0.8314 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.2197 - Val accuracy: 0.8846 - Val loss: 0.2685 - Val F1: 0.8314 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.2101 - Val accuracy: 0.8846 - Val loss: 0.2636 - Val F1: 0.8314 - LR: 0.00e+00\n","\tBest epoch: 100 - Best val accuracy: 0.8846 - Best val loss: 0.2636 - Best val F1: 0.8314\n","\n","\tEpoch 10/100 - Train loss: 0.8604 - Val accuracy: 0.6923 - Val loss: 1.2748 - Val F1: 0.5664 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.6230 - Val accuracy: 0.6923 - Val loss: 1.1061 - Val F1: 0.5664 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.4593 - Val accuracy: 0.6923 - Val loss: 1.0133 - Val F1: 0.5664 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.3434 - Val accuracy: 0.6923 - Val loss: 0.8787 - Val F1: 0.5664 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.2524 - Val accuracy: 0.6923 - Val loss: 0.6419 - Val F1: 0.5664 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.1962 - Val accuracy: 0.8462 - Val loss: 0.4131 - Val F1: 0.7940 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.1708 - Val accuracy: 0.8846 - Val loss: 0.3029 - Val F1: 0.8613 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.1483 - Val accuracy: 0.8846 - Val loss: 0.2563 - Val F1: 0.8613 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.1361 - Val accuracy: 0.9231 - Val loss: 0.2362 - Val F1: 0.8995 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.1407 - Val accuracy: 0.9231 - Val loss: 0.2292 - Val F1: 0.8995 - LR: 0.00e+00\n","\tBest epoch: 100 - Best val accuracy: 0.9231 - Best val loss: 0.2292 - Best val F1: 0.8995\n","\n","\tEpoch 10/100 - Train loss: 0.8216 - Val accuracy: 0.7308 - Val loss: 1.3177 - Val F1: 0.6171 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.5739 - Val accuracy: 0.7308 - Val loss: 1.1130 - Val F1: 0.6171 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.4322 - Val accuracy: 0.7308 - Val loss: 0.9507 - Val F1: 0.6171 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.3325 - Val accuracy: 0.7308 - Val loss: 0.8234 - Val F1: 0.6171 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.2661 - Val accuracy: 0.7308 - Val loss: 0.5862 - Val F1: 0.6171 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.2200 - Val accuracy: 0.8846 - Val loss: 0.3625 - Val F1: 0.8311 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.1881 - Val accuracy: 0.8846 - Val loss: 0.2769 - Val F1: 0.8311 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.1696 - Val accuracy: 0.8846 - Val loss: 0.2453 - Val F1: 0.8311 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.1594 - Val accuracy: 0.8846 - Val loss: 0.2311 - Val F1: 0.8311 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.1616 - Val accuracy: 0.8846 - Val loss: 0.2258 - Val F1: 0.8311 - LR: 0.00e+00\n","\tBest epoch: 100 - Best val accuracy: 0.8846 - Best val loss: 0.2258 - Best val F1: 0.8311\n","\n","\tEpoch 10/100 - Train loss: 0.2506 - Val accuracy: 0.8462 - Val loss: 0.3551 - Val F1: 0.7940 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.0942 - Val accuracy: 1.0000 - Val loss: 0.1279 - Val F1: 1.0000 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.0557 - Val accuracy: 1.0000 - Val loss: 0.0687 - Val F1: 1.0000 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.0327 - Val accuracy: 1.0000 - Val loss: 0.0455 - Val F1: 1.0000 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.0221 - Val accuracy: 1.0000 - Val loss: 0.0365 - Val F1: 1.0000 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.0196 - Val accuracy: 1.0000 - Val loss: 0.0276 - Val F1: 1.0000 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0112 - Val accuracy: 1.0000 - Val loss: 0.0235 - Val F1: 1.0000 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0076 - Val accuracy: 1.0000 - Val loss: 0.0238 - Val F1: 1.0000 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0075 - Val accuracy: 1.0000 - Val loss: 0.0234 - Val F1: 1.0000 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0085 - Val accuracy: 1.0000 - Val loss: 0.0208 - Val F1: 1.0000 - LR: 0.00e+00\n","\tBest epoch: 95 - Best val accuracy: 1.0000 - Best val loss: 0.0203 - Best val F1: 1.0000\n","\n","\tEpoch 10/100 - Train loss: 0.3134 - Val accuracy: 0.8462 - Val loss: 0.3827 - Val F1: 0.7940 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.1233 - Val accuracy: 0.9231 - Val loss: 0.1418 - Val F1: 0.9231 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.0542 - Val accuracy: 0.9615 - Val loss: 0.1030 - Val F1: 0.9615 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.0326 - Val accuracy: 0.9615 - Val loss: 0.0850 - Val F1: 0.9462 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.0268 - Val accuracy: 0.9615 - Val loss: 0.0803 - Val F1: 0.9462 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.0179 - Val accuracy: 0.9615 - Val loss: 0.0747 - Val F1: 0.9462 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0160 - Val accuracy: 1.0000 - Val loss: 0.0671 - Val F1: 1.0000 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0100 - Val accuracy: 0.9615 - Val loss: 0.0637 - Val F1: 0.9462 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0091 - Val accuracy: 0.9615 - Val loss: 0.0643 - Val F1: 0.9462 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0221 - Val accuracy: 0.9615 - Val loss: 0.0653 - Val F1: 0.9462 - LR: 0.00e+00\n","\tBest epoch: 95 - Best val accuracy: 0.9615 - Best val loss: 0.0626 - Best val F1: 0.9462\n","\n","Source class: WAL | Domain: 42 | Accuracy: 0.9435 | Loss: 0.1807 | F1: 0.9238\n","\n","Domain: 43\n","x_dp_dom.shape: (153, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Training and evaluating on Dp data via cross-validation...\n","\tEpoch 10/100 - Train loss: 0.8392 - Val accuracy: 0.7200 - Val loss: 1.3304 - Val F1: 0.6028 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.4941 - Val accuracy: 0.7200 - Val loss: 1.0764 - Val F1: 0.6028 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.3672 - Val accuracy: 0.7200 - Val loss: 0.8944 - Val F1: 0.6028 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.2757 - Val accuracy: 0.7200 - Val loss: 0.7507 - Val F1: 0.6028 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.2229 - Val accuracy: 0.8400 - Val loss: 0.4443 - Val F1: 0.7980 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.1843 - Val accuracy: 0.9200 - Val loss: 0.2555 - Val F1: 0.9005 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.1627 - Val accuracy: 0.9600 - Val loss: 0.2012 - Val F1: 0.9418 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.1474 - Val accuracy: 0.9600 - Val loss: 0.1856 - Val F1: 0.9418 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.1400 - Val accuracy: 0.9600 - Val loss: 0.1797 - Val F1: 0.9418 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.1323 - Val accuracy: 0.9600 - Val loss: 0.1784 - Val F1: 0.9418 - LR: 0.00e+00\n","\tBest epoch: 99 - Best val accuracy: 0.9600 - Best val loss: 0.1783 - Best val F1: 0.9418\n","\n","\tEpoch 10/100 - Train loss: 0.7858 - Val accuracy: 0.7200 - Val loss: 1.2890 - Val F1: 0.6028 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.4889 - Val accuracy: 0.7200 - Val loss: 1.0321 - Val F1: 0.6028 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.3508 - Val accuracy: 0.7200 - Val loss: 0.8557 - Val F1: 0.6028 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.2700 - Val accuracy: 0.7200 - Val loss: 0.6936 - Val F1: 0.6028 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.2244 - Val accuracy: 0.8800 - Val loss: 0.4390 - Val F1: 0.8424 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.1901 - Val accuracy: 0.9200 - Val loss: 0.2737 - Val F1: 0.8821 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.1664 - Val accuracy: 0.9600 - Val loss: 0.2147 - Val F1: 0.9405 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.1468 - Val accuracy: 0.9600 - Val loss: 0.1958 - Val F1: 0.9405 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.1408 - Val accuracy: 0.9600 - Val loss: 0.1885 - Val F1: 0.9405 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.1370 - Val accuracy: 0.9600 - Val loss: 0.1863 - Val F1: 0.9405 - LR: 0.00e+00\n","\tBest epoch: 100 - Best val accuracy: 0.9600 - Best val loss: 0.1863 - Best val F1: 0.9405\n","\n","\tEpoch 10/100 - Train loss: 0.6488 - Val accuracy: 0.7200 - Val loss: 1.2513 - Val F1: 0.6028 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.4314 - Val accuracy: 0.7200 - Val loss: 0.9690 - Val F1: 0.6028 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.3136 - Val accuracy: 0.7200 - Val loss: 0.8402 - Val F1: 0.6028 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.2466 - Val accuracy: 0.7200 - Val loss: 0.6817 - Val F1: 0.6028 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.1985 - Val accuracy: 0.8400 - Val loss: 0.3900 - Val F1: 0.7980 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.1770 - Val accuracy: 0.9200 - Val loss: 0.2099 - Val F1: 0.8821 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.1475 - Val accuracy: 0.9600 - Val loss: 0.1606 - Val F1: 0.9467 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.1411 - Val accuracy: 0.9600 - Val loss: 0.1453 - Val F1: 0.9467 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.1301 - Val accuracy: 0.9600 - Val loss: 0.1390 - Val F1: 0.9467 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.1267 - Val accuracy: 0.9600 - Val loss: 0.1371 - Val F1: 0.9467 - LR: 0.00e+00\n","\tBest epoch: 100 - Best val accuracy: 0.9600 - Best val loss: 0.1371 - Best val F1: 0.9467\n","\n","\tEpoch 10/100 - Train loss: 0.6610 - Val accuracy: 0.7200 - Val loss: 1.2194 - Val F1: 0.6028 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.4053 - Val accuracy: 0.7200 - Val loss: 0.9480 - Val F1: 0.6028 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.3095 - Val accuracy: 0.7200 - Val loss: 0.7825 - Val F1: 0.6028 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.2437 - Val accuracy: 0.7600 - Val loss: 0.6079 - Val F1: 0.6838 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.1984 - Val accuracy: 0.8400 - Val loss: 0.3431 - Val F1: 0.7980 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.1727 - Val accuracy: 0.9600 - Val loss: 0.2017 - Val F1: 0.9405 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.1584 - Val accuracy: 0.9600 - Val loss: 0.1687 - Val F1: 0.9467 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.1449 - Val accuracy: 0.9600 - Val loss: 0.1605 - Val F1: 0.9467 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.1353 - Val accuracy: 0.9600 - Val loss: 0.1580 - Val F1: 0.9467 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.1405 - Val accuracy: 0.9600 - Val loss: 0.1578 - Val F1: 0.9467 - LR: 0.00e+00\n","\tBest epoch: 96 - Best val accuracy: 0.9600 - Best val loss: 0.1576 - Best val F1: 0.9467\n","\n","\tEpoch 10/100 - Train loss: 0.7298 - Val accuracy: 0.7200 - Val loss: 1.2411 - Val F1: 0.6028 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.4091 - Val accuracy: 0.7200 - Val loss: 0.9374 - Val F1: 0.6028 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.3080 - Val accuracy: 0.7200 - Val loss: 0.7200 - Val F1: 0.6028 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.2466 - Val accuracy: 0.8400 - Val loss: 0.4907 - Val F1: 0.7980 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.2062 - Val accuracy: 0.8800 - Val loss: 0.3159 - Val F1: 0.8421 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.1815 - Val accuracy: 0.9600 - Val loss: 0.2326 - Val F1: 0.9418 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.1581 - Val accuracy: 0.9600 - Val loss: 0.2070 - Val F1: 0.9418 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.1444 - Val accuracy: 0.9600 - Val loss: 0.1998 - Val F1: 0.9418 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.1356 - Val accuracy: 0.9600 - Val loss: 0.1972 - Val F1: 0.9418 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.1354 - Val accuracy: 0.9600 - Val loss: 0.1968 - Val F1: 0.9418 - LR: 0.00e+00\n","\tBest epoch: 97 - Best val accuracy: 0.9600 - Best val loss: 0.1967 - Best val F1: 0.9418\n","\n","Source class: WAL | Domain: 43 | Accuracy: 0.9411 | Loss: 0.2045 | F1: 0.9152\n","\n","Domain: 44\n","x_dp_dom.shape: (153, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Training and evaluating on Dp data via cross-validation...\n","\tEpoch 10/100 - Train loss: 0.6615 - Val accuracy: 0.7200 - Val loss: 1.2899 - Val F1: 0.6028 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.3932 - Val accuracy: 0.7200 - Val loss: 1.0221 - Val F1: 0.6028 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.2895 - Val accuracy: 0.7200 - Val loss: 0.9112 - Val F1: 0.6028 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.2336 - Val accuracy: 0.7200 - Val loss: 0.8064 - Val F1: 0.6028 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.1847 - Val accuracy: 0.8400 - Val loss: 0.4694 - Val F1: 0.7980 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.1557 - Val accuracy: 0.9200 - Val loss: 0.2768 - Val F1: 0.8821 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.1416 - Val accuracy: 0.9200 - Val loss: 0.2229 - Val F1: 0.8821 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.1278 - Val accuracy: 0.9200 - Val loss: 0.2053 - Val F1: 0.8821 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.1223 - Val accuracy: 0.9200 - Val loss: 0.1982 - Val F1: 0.8821 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.1193 - Val accuracy: 0.9200 - Val loss: 0.1959 - Val F1: 0.8821 - LR: 0.00e+00\n","\tBest epoch: 100 - Best val accuracy: 0.9200 - Best val loss: 0.1959 - Best val F1: 0.8821\n","\n","\tEpoch 10/100 - Train loss: 0.6699 - Val accuracy: 0.7200 - Val loss: 1.2611 - Val F1: 0.6028 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.4199 - Val accuracy: 0.7200 - Val loss: 1.0776 - Val F1: 0.6028 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.3354 - Val accuracy: 0.7200 - Val loss: 0.9777 - Val F1: 0.6028 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.2682 - Val accuracy: 0.7200 - Val loss: 0.9068 - Val F1: 0.6028 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.2249 - Val accuracy: 0.7200 - Val loss: 0.6155 - Val F1: 0.6028 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.1877 - Val accuracy: 0.9200 - Val loss: 0.3070 - Val F1: 0.8821 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.1704 - Val accuracy: 0.9600 - Val loss: 0.1957 - Val F1: 0.9405 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.1584 - Val accuracy: 0.9600 - Val loss: 0.1581 - Val F1: 0.9405 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.1437 - Val accuracy: 0.9600 - Val loss: 0.1431 - Val F1: 0.9405 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.1425 - Val accuracy: 0.9600 - Val loss: 0.1376 - Val F1: 0.9405 - LR: 0.00e+00\n","\tBest epoch: 100 - Best val accuracy: 0.9600 - Best val loss: 0.1376 - Best val F1: 0.9405\n","\n","\tEpoch 10/100 - Train loss: 0.6527 - Val accuracy: 0.7200 - Val loss: 1.1910 - Val F1: 0.6028 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.4170 - Val accuracy: 0.7200 - Val loss: 0.9709 - Val F1: 0.6028 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.3212 - Val accuracy: 0.7200 - Val loss: 0.8965 - Val F1: 0.6028 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.2741 - Val accuracy: 0.7200 - Val loss: 0.8168 - Val F1: 0.6028 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.2280 - Val accuracy: 0.8000 - Val loss: 0.5231 - Val F1: 0.7465 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.1974 - Val accuracy: 0.9200 - Val loss: 0.3155 - Val F1: 0.8821 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.1805 - Val accuracy: 0.9200 - Val loss: 0.2280 - Val F1: 0.8821 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.1637 - Val accuracy: 0.9200 - Val loss: 0.1908 - Val F1: 0.8821 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.1622 - Val accuracy: 0.9200 - Val loss: 0.1749 - Val F1: 0.8821 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.1522 - Val accuracy: 0.9200 - Val loss: 0.1688 - Val F1: 0.8821 - LR: 0.00e+00\n","\tBest epoch: 100 - Best val accuracy: 0.9200 - Best val loss: 0.1688 - Best val F1: 0.8821\n","\n","\tEpoch 10/100 - Train loss: 0.7415 - Val accuracy: 0.7200 - Val loss: 1.3004 - Val F1: 0.6028 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.4705 - Val accuracy: 0.7200 - Val loss: 1.0749 - Val F1: 0.6028 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.3789 - Val accuracy: 0.7200 - Val loss: 0.9595 - Val F1: 0.6028 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.3249 - Val accuracy: 0.7200 - Val loss: 0.8259 - Val F1: 0.6028 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.2830 - Val accuracy: 0.8400 - Val loss: 0.4754 - Val F1: 0.7980 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.2464 - Val accuracy: 0.9200 - Val loss: 0.2918 - Val F1: 0.8821 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.2237 - Val accuracy: 0.9200 - Val loss: 0.2341 - Val F1: 0.8821 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.2069 - Val accuracy: 0.9200 - Val loss: 0.2118 - Val F1: 0.8821 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.1934 - Val accuracy: 0.9200 - Val loss: 0.2019 - Val F1: 0.8821 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.1960 - Val accuracy: 0.9200 - Val loss: 0.1985 - Val F1: 0.8821 - LR: 0.00e+00\n","\tBest epoch: 100 - Best val accuracy: 0.9200 - Best val loss: 0.1985 - Best val F1: 0.8821\n","\n","\tEpoch 10/100 - Train loss: 0.7360 - Val accuracy: 0.7200 - Val loss: 1.3047 - Val F1: 0.6028 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.4642 - Val accuracy: 0.7200 - Val loss: 1.0941 - Val F1: 0.6028 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.3394 - Val accuracy: 0.7200 - Val loss: 0.9700 - Val F1: 0.6028 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.2776 - Val accuracy: 0.7200 - Val loss: 0.9223 - Val F1: 0.6028 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.2304 - Val accuracy: 0.7600 - Val loss: 0.6497 - Val F1: 0.6838 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.2112 - Val accuracy: 0.8800 - Val loss: 0.3640 - Val F1: 0.8424 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.1932 - Val accuracy: 0.9200 - Val loss: 0.2837 - Val F1: 0.8821 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.1817 - Val accuracy: 0.9200 - Val loss: 0.2629 - Val F1: 0.8821 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.1681 - Val accuracy: 0.9200 - Val loss: 0.2552 - Val F1: 0.8821 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.1691 - Val accuracy: 0.9200 - Val loss: 0.2527 - Val F1: 0.8821 - LR: 0.00e+00\n","\tBest epoch: 100 - Best val accuracy: 0.9200 - Best val loss: 0.2527 - Best val F1: 0.8821\n","\n","Source class: WAL | Domain: 44 | Accuracy: 0.9086 | Loss: 0.2174 | F1: 0.8657\n","\n","Domain: 45\n","x_dp_dom.shape: (163, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Training and evaluating on Dp data via cross-validation...\n","\tEpoch 10/100 - Train loss: 0.3204 - Val accuracy: 0.8462 - Val loss: 0.3732 - Val F1: 0.7773 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.1393 - Val accuracy: 0.9231 - Val loss: 0.1969 - Val F1: 0.9124 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.0505 - Val accuracy: 0.9615 - Val loss: 0.1160 - Val F1: 0.9557 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.0244 - Val accuracy: 0.9615 - Val loss: 0.0793 - Val F1: 0.9557 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.0139 - Val accuracy: 1.0000 - Val loss: 0.0645 - Val F1: 1.0000 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.0097 - Val accuracy: 1.0000 - Val loss: 0.0526 - Val F1: 1.0000 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0088 - Val accuracy: 1.0000 - Val loss: 0.0473 - Val F1: 1.0000 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0081 - Val accuracy: 1.0000 - Val loss: 0.0445 - Val F1: 1.0000 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0072 - Val accuracy: 1.0000 - Val loss: 0.0444 - Val F1: 1.0000 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0065 - Val accuracy: 1.0000 - Val loss: 0.0419 - Val F1: 1.0000 - LR: 0.00e+00\n","\tBest epoch: 92 - Best val accuracy: 1.0000 - Best val loss: 0.0414 - Best val F1: 1.0000\n","\n","\tEpoch 10/100 - Train loss: 0.2784 - Val accuracy: 0.8462 - Val loss: 0.3239 - Val F1: 0.7769 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.0915 - Val accuracy: 1.0000 - Val loss: 0.1107 - Val F1: 1.0000 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.0330 - Val accuracy: 1.0000 - Val loss: 0.0587 - Val F1: 1.0000 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.0144 - Val accuracy: 1.0000 - Val loss: 0.0362 - Val F1: 1.0000 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.0158 - Val accuracy: 1.0000 - Val loss: 0.0277 - Val F1: 1.0000 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.0100 - Val accuracy: 1.0000 - Val loss: 0.0224 - Val F1: 1.0000 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0057 - Val accuracy: 1.0000 - Val loss: 0.0203 - Val F1: 1.0000 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0054 - Val accuracy: 1.0000 - Val loss: 0.0181 - Val F1: 1.0000 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0056 - Val accuracy: 1.0000 - Val loss: 0.0156 - Val F1: 1.0000 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0060 - Val accuracy: 1.0000 - Val loss: 0.0170 - Val F1: 1.0000 - LR: 0.00e+00\n","\tBest epoch: 92 - Best val accuracy: 1.0000 - Best val loss: 0.0155 - Best val F1: 1.0000\n","\n","\tEpoch 10/100 - Train loss: 0.2708 - Val accuracy: 0.8462 - Val loss: 0.3517 - Val F1: 0.7769 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.0868 - Val accuracy: 0.9615 - Val loss: 0.1383 - Val F1: 0.9556 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.0395 - Val accuracy: 1.0000 - Val loss: 0.0793 - Val F1: 1.0000 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.0269 - Val accuracy: 1.0000 - Val loss: 0.0600 - Val F1: 1.0000 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.0132 - Val accuracy: 1.0000 - Val loss: 0.0419 - Val F1: 1.0000 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.0100 - Val accuracy: 1.0000 - Val loss: 0.0372 - Val F1: 1.0000 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0081 - Val accuracy: 1.0000 - Val loss: 0.0304 - Val F1: 1.0000 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0074 - Val accuracy: 1.0000 - Val loss: 0.0280 - Val F1: 1.0000 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0061 - Val accuracy: 1.0000 - Val loss: 0.0252 - Val F1: 1.0000 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0055 - Val accuracy: 1.0000 - Val loss: 0.0252 - Val F1: 1.0000 - LR: 0.00e+00\n","\tBest epoch: 90 - Best val accuracy: 1.0000 - Best val loss: 0.0252 - Best val F1: 1.0000\n","\n","\tEpoch 10/100 - Train loss: 0.2797 - Val accuracy: 0.8519 - Val loss: 0.3182 - Val F1: 0.7852 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.0829 - Val accuracy: 0.9259 - Val loss: 0.1291 - Val F1: 0.9012 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.0346 - Val accuracy: 0.9630 - Val loss: 0.0914 - Val F1: 0.9605 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.0192 - Val accuracy: 1.0000 - Val loss: 0.0718 - Val F1: 1.0000 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.0179 - Val accuracy: 1.0000 - Val loss: 0.0664 - Val F1: 1.0000 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.0096 - Val accuracy: 1.0000 - Val loss: 0.0564 - Val F1: 1.0000 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0071 - Val accuracy: 1.0000 - Val loss: 0.0542 - Val F1: 1.0000 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0062 - Val accuracy: 1.0000 - Val loss: 0.0464 - Val F1: 1.0000 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0072 - Val accuracy: 1.0000 - Val loss: 0.0502 - Val F1: 1.0000 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0268 - Val accuracy: 1.0000 - Val loss: 0.0506 - Val F1: 1.0000 - LR: 0.00e+00\n","\tBest epoch: 82 - Best val accuracy: 1.0000 - Best val loss: 0.0461 - Best val F1: 1.0000\n","\n","\tEpoch 10/100 - Train loss: 0.3337 - Val accuracy: 0.8519 - Val loss: 0.3686 - Val F1: 0.7852 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.1042 - Val accuracy: 0.9259 - Val loss: 0.1413 - Val F1: 0.9012 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.0378 - Val accuracy: 0.9630 - Val loss: 0.0851 - Val F1: 0.9605 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.0213 - Val accuracy: 1.0000 - Val loss: 0.0628 - Val F1: 1.0000 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.0114 - Val accuracy: 1.0000 - Val loss: 0.0522 - Val F1: 1.0000 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.0199 - Val accuracy: 1.0000 - Val loss: 0.0453 - Val F1: 1.0000 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0076 - Val accuracy: 1.0000 - Val loss: 0.0388 - Val F1: 1.0000 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0068 - Val accuracy: 1.0000 - Val loss: 0.0356 - Val F1: 1.0000 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0055 - Val accuracy: 1.0000 - Val loss: 0.0365 - Val F1: 1.0000 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0069 - Val accuracy: 1.0000 - Val loss: 0.0332 - Val F1: 1.0000 - LR: 0.00e+00\n","\tBest epoch: 85 - Best val accuracy: 1.0000 - Best val loss: 0.0307 - Best val F1: 1.0000\n","\n","Source class: WAL | Domain: 45 | Accuracy: 0.9750 | Loss: 0.0616 | F1: 0.9698\n","\n","Domain: 46\n","x_dp_dom.shape: (160, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Training and evaluating on Dp data via cross-validation...\n","\tEpoch 10/100 - Train loss: 0.3135 - Val accuracy: 0.8846 - Val loss: 0.3491 - Val F1: 0.8314 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.1326 - Val accuracy: 0.9231 - Val loss: 0.1559 - Val F1: 0.8995 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.0475 - Val accuracy: 1.0000 - Val loss: 0.0844 - Val F1: 1.0000 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.0337 - Val accuracy: 1.0000 - Val loss: 0.0641 - Val F1: 1.0000 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.0166 - Val accuracy: 1.0000 - Val loss: 0.0493 - Val F1: 1.0000 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.0307 - Val accuracy: 1.0000 - Val loss: 0.0456 - Val F1: 1.0000 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0090 - Val accuracy: 1.0000 - Val loss: 0.0353 - Val F1: 1.0000 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0092 - Val accuracy: 1.0000 - Val loss: 0.0343 - Val F1: 1.0000 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0085 - Val accuracy: 1.0000 - Val loss: 0.0325 - Val F1: 1.0000 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0073 - Val accuracy: 1.0000 - Val loss: 0.0334 - Val F1: 1.0000 - LR: 0.00e+00\n","\tBest epoch: 93 - Best val accuracy: 1.0000 - Best val loss: 0.0310 - Best val F1: 1.0000\n","\n","\tEpoch 10/100 - Train loss: 0.3524 - Val accuracy: 0.8846 - Val loss: 0.3153 - Val F1: 0.8314 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.1015 - Val accuracy: 0.9231 - Val loss: 0.1340 - Val F1: 0.8995 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.0465 - Val accuracy: 1.0000 - Val loss: 0.0803 - Val F1: 1.0000 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.0462 - Val accuracy: 1.0000 - Val loss: 0.0616 - Val F1: 1.0000 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.0205 - Val accuracy: 1.0000 - Val loss: 0.0435 - Val F1: 1.0000 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.0140 - Val accuracy: 1.0000 - Val loss: 0.0375 - Val F1: 1.0000 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0111 - Val accuracy: 1.0000 - Val loss: 0.0337 - Val F1: 1.0000 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0077 - Val accuracy: 1.0000 - Val loss: 0.0313 - Val F1: 1.0000 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0075 - Val accuracy: 1.0000 - Val loss: 0.0301 - Val F1: 1.0000 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0079 - Val accuracy: 1.0000 - Val loss: 0.0297 - Val F1: 1.0000 - LR: 0.00e+00\n","\tBest epoch: 92 - Best val accuracy: 1.0000 - Best val loss: 0.0278 - Best val F1: 1.0000\n","\n","\tEpoch 10/100 - Train loss: 0.3309 - Val accuracy: 0.8846 - Val loss: 0.3372 - Val F1: 0.8314 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.1540 - Val accuracy: 0.9231 - Val loss: 0.1769 - Val F1: 0.8995 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.0600 - Val accuracy: 1.0000 - Val loss: 0.0978 - Val F1: 1.0000 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.0351 - Val accuracy: 1.0000 - Val loss: 0.0670 - Val F1: 1.0000 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.0167 - Val accuracy: 1.0000 - Val loss: 0.0517 - Val F1: 1.0000 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.0117 - Val accuracy: 1.0000 - Val loss: 0.0401 - Val F1: 1.0000 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0092 - Val accuracy: 1.0000 - Val loss: 0.0350 - Val F1: 1.0000 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0100 - Val accuracy: 1.0000 - Val loss: 0.0317 - Val F1: 1.0000 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0113 - Val accuracy: 1.0000 - Val loss: 0.0312 - Val F1: 1.0000 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0061 - Val accuracy: 1.0000 - Val loss: 0.0302 - Val F1: 1.0000 - LR: 0.00e+00\n","\tBest epoch: 97 - Best val accuracy: 1.0000 - Best val loss: 0.0292 - Best val F1: 1.0000\n","\n","\tEpoch 10/100 - Train loss: 0.3501 - Val accuracy: 0.8846 - Val loss: 0.3810 - Val F1: 0.8314 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.1229 - Val accuracy: 0.9231 - Val loss: 0.1681 - Val F1: 0.8995 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.0594 - Val accuracy: 1.0000 - Val loss: 0.0857 - Val F1: 1.0000 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.0287 - Val accuracy: 1.0000 - Val loss: 0.0514 - Val F1: 1.0000 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.0174 - Val accuracy: 1.0000 - Val loss: 0.0411 - Val F1: 1.0000 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.0151 - Val accuracy: 1.0000 - Val loss: 0.0322 - Val F1: 1.0000 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0095 - Val accuracy: 1.0000 - Val loss: 0.0288 - Val F1: 1.0000 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0105 - Val accuracy: 1.0000 - Val loss: 0.0262 - Val F1: 1.0000 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0102 - Val accuracy: 1.0000 - Val loss: 0.0250 - Val F1: 1.0000 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0099 - Val accuracy: 1.0000 - Val loss: 0.0241 - Val F1: 1.0000 - LR: 0.00e+00\n","\tBest epoch: 89 - Best val accuracy: 1.0000 - Best val loss: 0.0225 - Best val F1: 1.0000\n","\n","\tEpoch 10/100 - Train loss: 0.3292 - Val accuracy: 0.8846 - Val loss: 0.4148 - Val F1: 0.8314 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.1525 - Val accuracy: 0.8846 - Val loss: 0.2039 - Val F1: 0.8314 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.0592 - Val accuracy: 0.9615 - Val loss: 0.1199 - Val F1: 0.9428 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.0335 - Val accuracy: 0.9615 - Val loss: 0.0806 - Val F1: 0.9428 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.0196 - Val accuracy: 1.0000 - Val loss: 0.0602 - Val F1: 1.0000 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.0122 - Val accuracy: 1.0000 - Val loss: 0.0542 - Val F1: 1.0000 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0404 - Val accuracy: 0.9615 - Val loss: 0.0541 - Val F1: 0.9462 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0089 - Val accuracy: 1.0000 - Val loss: 0.0413 - Val F1: 1.0000 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0083 - Val accuracy: 1.0000 - Val loss: 0.0420 - Val F1: 1.0000 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0089 - Val accuracy: 1.0000 - Val loss: 0.0383 - Val F1: 1.0000 - LR: 0.00e+00\n","\tBest epoch: 93 - Best val accuracy: 1.0000 - Best val loss: 0.0363 - Best val F1: 1.0000\n","\n","Source class: WAL | Domain: 46 | Accuracy: 0.9938 | Loss: 0.0461 | F1: 0.9911\n","\n","Domain: 47\n","x_dp_dom.shape: (155, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Training and evaluating on Dp data via cross-validation...\n","\tEpoch 10/100 - Train loss: 0.8073 - Val accuracy: 0.7200 - Val loss: 1.3030 - Val F1: 0.6028 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.4667 - Val accuracy: 0.7200 - Val loss: 1.0599 - Val F1: 0.6028 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.3658 - Val accuracy: 0.7200 - Val loss: 0.9461 - Val F1: 0.6028 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.3031 - Val accuracy: 0.7200 - Val loss: 0.8870 - Val F1: 0.6028 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.2515 - Val accuracy: 0.8000 - Val loss: 0.5337 - Val F1: 0.7465 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.2310 - Val accuracy: 0.9200 - Val loss: 0.3221 - Val F1: 0.8821 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.2040 - Val accuracy: 0.9200 - Val loss: 0.2777 - Val F1: 0.8821 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.1831 - Val accuracy: 0.9200 - Val loss: 0.2605 - Val F1: 0.8821 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.1730 - Val accuracy: 0.9200 - Val loss: 0.2525 - Val F1: 0.8821 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.1658 - Val accuracy: 0.9200 - Val loss: 0.2499 - Val F1: 0.8821 - LR: 0.00e+00\n","\tBest epoch: 100 - Best val accuracy: 0.9200 - Best val loss: 0.2499 - Best val F1: 0.8821\n","\n","\tEpoch 10/100 - Train loss: 0.7530 - Val accuracy: 0.7200 - Val loss: 1.2455 - Val F1: 0.6028 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.4706 - Val accuracy: 0.7200 - Val loss: 1.0540 - Val F1: 0.6028 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.3726 - Val accuracy: 0.7200 - Val loss: 0.9008 - Val F1: 0.6028 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.3100 - Val accuracy: 0.7200 - Val loss: 0.7364 - Val F1: 0.6028 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.2565 - Val accuracy: 0.9200 - Val loss: 0.4130 - Val F1: 0.8821 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.2317 - Val accuracy: 0.9200 - Val loss: 0.2661 - Val F1: 0.8821 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.2043 - Val accuracy: 0.9200 - Val loss: 0.2075 - Val F1: 0.8821 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.1820 - Val accuracy: 0.9200 - Val loss: 0.1804 - Val F1: 0.8821 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.1772 - Val accuracy: 0.9600 - Val loss: 0.1681 - Val F1: 0.9405 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.1739 - Val accuracy: 0.9600 - Val loss: 0.1636 - Val F1: 0.9405 - LR: 0.00e+00\n","\tBest epoch: 100 - Best val accuracy: 0.9600 - Best val loss: 0.1636 - Best val F1: 0.9405\n","\n","\tEpoch 10/100 - Train loss: 0.8061 - Val accuracy: 0.7200 - Val loss: 1.3044 - Val F1: 0.6028 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.5090 - Val accuracy: 0.7200 - Val loss: 1.0767 - Val F1: 0.6028 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.3914 - Val accuracy: 0.7200 - Val loss: 0.9746 - Val F1: 0.6028 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.3345 - Val accuracy: 0.7200 - Val loss: 0.9090 - Val F1: 0.6028 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.2789 - Val accuracy: 0.7200 - Val loss: 0.5907 - Val F1: 0.6028 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.2468 - Val accuracy: 0.9200 - Val loss: 0.3089 - Val F1: 0.8821 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.2250 - Val accuracy: 0.9200 - Val loss: 0.2366 - Val F1: 0.8821 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.2013 - Val accuracy: 0.9200 - Val loss: 0.2074 - Val F1: 0.8821 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.1977 - Val accuracy: 0.9200 - Val loss: 0.1942 - Val F1: 0.8821 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.1912 - Val accuracy: 0.9200 - Val loss: 0.1895 - Val F1: 0.8821 - LR: 0.00e+00\n","\tBest epoch: 100 - Best val accuracy: 0.9200 - Best val loss: 0.1895 - Best val F1: 0.8821\n","\n","\tEpoch 10/100 - Train loss: 0.7454 - Val accuracy: 0.7200 - Val loss: 1.2443 - Val F1: 0.6028 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.4775 - Val accuracy: 0.7200 - Val loss: 1.0081 - Val F1: 0.6028 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.3691 - Val accuracy: 0.7200 - Val loss: 0.9195 - Val F1: 0.6028 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.2869 - Val accuracy: 0.7200 - Val loss: 0.8785 - Val F1: 0.6028 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.2412 - Val accuracy: 0.7200 - Val loss: 0.5599 - Val F1: 0.6028 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.2043 - Val accuracy: 0.9200 - Val loss: 0.3077 - Val F1: 0.8821 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.1859 - Val accuracy: 0.9200 - Val loss: 0.2488 - Val F1: 0.8821 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.1667 - Val accuracy: 0.9200 - Val loss: 0.2290 - Val F1: 0.8821 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.1601 - Val accuracy: 0.9200 - Val loss: 0.2195 - Val F1: 0.8821 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.1577 - Val accuracy: 0.9200 - Val loss: 0.2161 - Val F1: 0.8821 - LR: 0.00e+00\n","\tBest epoch: 100 - Best val accuracy: 0.9200 - Best val loss: 0.2161 - Best val F1: 0.8821\n","\n","\tEpoch 10/100 - Train loss: 0.6546 - Val accuracy: 0.7200 - Val loss: 1.2742 - Val F1: 0.6028 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.4005 - Val accuracy: 0.7200 - Val loss: 1.0419 - Val F1: 0.6028 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.3323 - Val accuracy: 0.7200 - Val loss: 0.9560 - Val F1: 0.6028 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.2654 - Val accuracy: 0.7200 - Val loss: 0.9099 - Val F1: 0.6028 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.2278 - Val accuracy: 0.8000 - Val loss: 0.5369 - Val F1: 0.7465 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.1968 - Val accuracy: 0.9200 - Val loss: 0.3248 - Val F1: 0.8821 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.1665 - Val accuracy: 0.9200 - Val loss: 0.2859 - Val F1: 0.8821 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.1537 - Val accuracy: 0.9200 - Val loss: 0.2732 - Val F1: 0.8821 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.1511 - Val accuracy: 0.9200 - Val loss: 0.2680 - Val F1: 0.8821 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.1448 - Val accuracy: 0.9200 - Val loss: 0.2661 - Val F1: 0.8821 - LR: 0.00e+00\n","\tBest epoch: 100 - Best val accuracy: 0.9200 - Best val loss: 0.2661 - Best val F1: 0.8821\n","\n","Source class: WAL | Domain: 47 | Accuracy: 0.9032 | Loss: 0.2626 | F1: 0.8580\n","\n","Domain: 48\n","x_dp_dom.shape: (159, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Training and evaluating on Dp data via cross-validation...\n","\tEpoch 10/100 - Train loss: 0.2579 - Val accuracy: 0.9231 - Val loss: 0.2343 - Val F1: 0.8995 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.0776 - Val accuracy: 0.9615 - Val loss: 0.0845 - Val F1: 0.9462 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.1119 - Val accuracy: 1.0000 - Val loss: 0.0509 - Val F1: 1.0000 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.0231 - Val accuracy: 1.0000 - Val loss: 0.0368 - Val F1: 1.0000 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.0153 - Val accuracy: 1.0000 - Val loss: 0.0298 - Val F1: 1.0000 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.0147 - Val accuracy: 1.0000 - Val loss: 0.0274 - Val F1: 1.0000 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0208 - Val accuracy: 1.0000 - Val loss: 0.0233 - Val F1: 1.0000 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0296 - Val accuracy: 1.0000 - Val loss: 0.0226 - Val F1: 1.0000 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0071 - Val accuracy: 1.0000 - Val loss: 0.0210 - Val F1: 1.0000 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0091 - Val accuracy: 1.0000 - Val loss: 0.0192 - Val F1: 1.0000 - LR: 0.00e+00\n","\tBest epoch: 100 - Best val accuracy: 1.0000 - Best val loss: 0.0192 - Best val F1: 1.0000\n","\n","\tEpoch 10/100 - Train loss: 0.2457 - Val accuracy: 0.8846 - Val loss: 0.3071 - Val F1: 0.8314 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.0896 - Val accuracy: 0.9615 - Val loss: 0.1340 - Val F1: 0.9462 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.0345 - Val accuracy: 0.9615 - Val loss: 0.1018 - Val F1: 0.9462 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.0193 - Val accuracy: 0.9615 - Val loss: 0.1025 - Val F1: 0.9462 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.0159 - Val accuracy: 0.9615 - Val loss: 0.1088 - Val F1: 0.9462 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.0140 - Val accuracy: 0.9615 - Val loss: 0.1042 - Val F1: 0.9462 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0120 - Val accuracy: 0.9615 - Val loss: 0.1101 - Val F1: 0.9462 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0067 - Val accuracy: 0.9615 - Val loss: 0.1132 - Val F1: 0.9462 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0054 - Val accuracy: 0.9615 - Val loss: 0.1086 - Val F1: 0.9462 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0102 - Val accuracy: 0.9615 - Val loss: 0.1126 - Val F1: 0.9462 - LR: 0.00e+00\n","\tBest epoch: 44 - Best val accuracy: 0.9615 - Best val loss: 0.0976 - Best val F1: 0.9462\n","\n","\tEpoch 10/100 - Train loss: 0.2534 - Val accuracy: 0.8846 - Val loss: 0.2543 - Val F1: 0.8314 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.0988 - Val accuracy: 1.0000 - Val loss: 0.1051 - Val F1: 1.0000 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.0335 - Val accuracy: 1.0000 - Val loss: 0.0666 - Val F1: 1.0000 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.0162 - Val accuracy: 1.0000 - Val loss: 0.0580 - Val F1: 1.0000 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.0146 - Val accuracy: 1.0000 - Val loss: 0.0457 - Val F1: 1.0000 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.0071 - Val accuracy: 1.0000 - Val loss: 0.0423 - Val F1: 1.0000 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0111 - Val accuracy: 1.0000 - Val loss: 0.0403 - Val F1: 1.0000 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0115 - Val accuracy: 1.0000 - Val loss: 0.0391 - Val F1: 1.0000 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0058 - Val accuracy: 1.0000 - Val loss: 0.0369 - Val F1: 1.0000 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0064 - Val accuracy: 1.0000 - Val loss: 0.0373 - Val F1: 1.0000 - LR: 0.00e+00\n","\tBest epoch: 93 - Best val accuracy: 1.0000 - Best val loss: 0.0366 - Best val F1: 1.0000\n","\n","\tEpoch 10/100 - Train loss: 0.2523 - Val accuracy: 0.8846 - Val loss: 0.2723 - Val F1: 0.8314 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.0932 - Val accuracy: 1.0000 - Val loss: 0.1047 - Val F1: 1.0000 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.0488 - Val accuracy: 1.0000 - Val loss: 0.0561 - Val F1: 1.0000 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.0172 - Val accuracy: 1.0000 - Val loss: 0.0387 - Val F1: 1.0000 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.0102 - Val accuracy: 1.0000 - Val loss: 0.0291 - Val F1: 1.0000 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.0114 - Val accuracy: 1.0000 - Val loss: 0.0257 - Val F1: 1.0000 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0100 - Val accuracy: 1.0000 - Val loss: 0.0234 - Val F1: 1.0000 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0061 - Val accuracy: 1.0000 - Val loss: 0.0214 - Val F1: 1.0000 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0058 - Val accuracy: 1.0000 - Val loss: 0.0205 - Val F1: 1.0000 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0054 - Val accuracy: 1.0000 - Val loss: 0.0200 - Val F1: 1.0000 - LR: 0.00e+00\n","\tBest epoch: 99 - Best val accuracy: 1.0000 - Best val loss: 0.0192 - Best val F1: 1.0000\n","\n","\tEpoch 10/100 - Train loss: 0.2627 - Val accuracy: 0.8846 - Val loss: 0.3063 - Val F1: 0.8314 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.1093 - Val accuracy: 0.9615 - Val loss: 0.1354 - Val F1: 0.9462 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.0383 - Val accuracy: 0.9615 - Val loss: 0.0996 - Val F1: 0.9462 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.0220 - Val accuracy: 0.9615 - Val loss: 0.0891 - Val F1: 0.9462 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.0142 - Val accuracy: 0.9615 - Val loss: 0.0886 - Val F1: 0.9462 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.0113 - Val accuracy: 0.9615 - Val loss: 0.0891 - Val F1: 0.9462 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0085 - Val accuracy: 0.9615 - Val loss: 0.0909 - Val F1: 0.9462 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0080 - Val accuracy: 0.9615 - Val loss: 0.0868 - Val F1: 0.9462 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0072 - Val accuracy: 0.9615 - Val loss: 0.0880 - Val F1: 0.9462 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0061 - Val accuracy: 0.9615 - Val loss: 0.0848 - Val F1: 0.9462 - LR: 0.00e+00\n","\tBest epoch: 96 - Best val accuracy: 0.9615 - Best val loss: 0.0842 - Best val F1: 0.9462\n","\n","Source class: WAL | Domain: 48 | Accuracy: 0.9810 | Loss: 0.0509 | F1: 0.9804\n","\n","Domain: 49\n","x_dp_dom.shape: (164, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Training and evaluating on Dp data via cross-validation...\n","\tEpoch 10/100 - Train loss: 0.3108 - Val accuracy: 0.8889 - Val loss: 0.3122 - Val F1: 0.8500 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.1009 - Val accuracy: 0.9630 - Val loss: 0.1186 - Val F1: 0.9573 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.0433 - Val accuracy: 0.9630 - Val loss: 0.0837 - Val F1: 0.9605 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.0217 - Val accuracy: 0.9630 - Val loss: 0.0708 - Val F1: 0.9605 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.0276 - Val accuracy: 0.9630 - Val loss: 0.0624 - Val F1: 0.9605 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.0094 - Val accuracy: 0.9630 - Val loss: 0.0560 - Val F1: 0.9605 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0074 - Val accuracy: 1.0000 - Val loss: 0.0535 - Val F1: 1.0000 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0064 - Val accuracy: 1.0000 - Val loss: 0.0517 - Val F1: 1.0000 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0062 - Val accuracy: 1.0000 - Val loss: 0.0488 - Val F1: 1.0000 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0060 - Val accuracy: 1.0000 - Val loss: 0.0494 - Val F1: 1.0000 - LR: 0.00e+00\n","\tBest epoch: 92 - Best val accuracy: 1.0000 - Best val loss: 0.0479 - Best val F1: 1.0000\n","\n","\tEpoch 10/100 - Train loss: 0.3491 - Val accuracy: 0.8519 - Val loss: 0.3705 - Val F1: 0.7852 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.1216 - Val accuracy: 0.9630 - Val loss: 0.1416 - Val F1: 0.9573 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.0532 - Val accuracy: 1.0000 - Val loss: 0.0716 - Val F1: 1.0000 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.0276 - Val accuracy: 1.0000 - Val loss: 0.0492 - Val F1: 1.0000 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.0168 - Val accuracy: 1.0000 - Val loss: 0.0411 - Val F1: 1.0000 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.0089 - Val accuracy: 1.0000 - Val loss: 0.0308 - Val F1: 1.0000 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0172 - Val accuracy: 1.0000 - Val loss: 0.0281 - Val F1: 1.0000 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0067 - Val accuracy: 1.0000 - Val loss: 0.0261 - Val F1: 1.0000 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0065 - Val accuracy: 1.0000 - Val loss: 0.0251 - Val F1: 1.0000 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0089 - Val accuracy: 1.0000 - Val loss: 0.0245 - Val F1: 1.0000 - LR: 0.00e+00\n","\tBest epoch: 100 - Best val accuracy: 1.0000 - Best val loss: 0.0245 - Best val F1: 1.0000\n","\n","\tEpoch 10/100 - Train loss: 0.3337 - Val accuracy: 0.8519 - Val loss: 0.3647 - Val F1: 0.7852 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.0923 - Val accuracy: 1.0000 - Val loss: 0.0921 - Val F1: 1.0000 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.0395 - Val accuracy: 1.0000 - Val loss: 0.0415 - Val F1: 1.0000 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.0180 - Val accuracy: 1.0000 - Val loss: 0.0269 - Val F1: 1.0000 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.0123 - Val accuracy: 1.0000 - Val loss: 0.0191 - Val F1: 1.0000 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.0078 - Val accuracy: 1.0000 - Val loss: 0.0148 - Val F1: 1.0000 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0100 - Val accuracy: 1.0000 - Val loss: 0.0120 - Val F1: 1.0000 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0064 - Val accuracy: 1.0000 - Val loss: 0.0107 - Val F1: 1.0000 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0052 - Val accuracy: 1.0000 - Val loss: 0.0095 - Val F1: 1.0000 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0040 - Val accuracy: 1.0000 - Val loss: 0.0099 - Val F1: 1.0000 - LR: 0.00e+00\n","\tBest epoch: 93 - Best val accuracy: 1.0000 - Best val loss: 0.0092 - Best val F1: 1.0000\n","\n","\tEpoch 10/100 - Train loss: 0.2866 - Val accuracy: 0.8519 - Val loss: 0.3163 - Val F1: 0.7852 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.1045 - Val accuracy: 0.9630 - Val loss: 0.1239 - Val F1: 0.9605 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.0462 - Val accuracy: 1.0000 - Val loss: 0.0767 - Val F1: 1.0000 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.0203 - Val accuracy: 1.0000 - Val loss: 0.0530 - Val F1: 1.0000 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.0268 - Val accuracy: 1.0000 - Val loss: 0.0392 - Val F1: 1.0000 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.0110 - Val accuracy: 1.0000 - Val loss: 0.0339 - Val F1: 1.0000 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0063 - Val accuracy: 1.0000 - Val loss: 0.0290 - Val F1: 1.0000 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0056 - Val accuracy: 1.0000 - Val loss: 0.0260 - Val F1: 1.0000 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0060 - Val accuracy: 1.0000 - Val loss: 0.0244 - Val F1: 1.0000 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0051 - Val accuracy: 1.0000 - Val loss: 0.0243 - Val F1: 1.0000 - LR: 0.00e+00\n","\tBest epoch: 95 - Best val accuracy: 1.0000 - Best val loss: 0.0239 - Best val F1: 1.0000\n","\n","\tEpoch 10/100 - Train loss: 0.2545 - Val accuracy: 0.8519 - Val loss: 0.3047 - Val F1: 0.7852 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.0855 - Val accuracy: 0.9630 - Val loss: 0.1085 - Val F1: 0.9605 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.0390 - Val accuracy: 1.0000 - Val loss: 0.0634 - Val F1: 1.0000 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.0185 - Val accuracy: 1.0000 - Val loss: 0.0451 - Val F1: 1.0000 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.0169 - Val accuracy: 1.0000 - Val loss: 0.0344 - Val F1: 1.0000 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.0066 - Val accuracy: 1.0000 - Val loss: 0.0289 - Val F1: 1.0000 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0107 - Val accuracy: 1.0000 - Val loss: 0.0265 - Val F1: 1.0000 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0062 - Val accuracy: 1.0000 - Val loss: 0.0251 - Val F1: 1.0000 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0069 - Val accuracy: 1.0000 - Val loss: 0.0228 - Val F1: 1.0000 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0100 - Val accuracy: 1.0000 - Val loss: 0.0231 - Val F1: 1.0000 - LR: 0.00e+00\n","\tBest epoch: 93 - Best val accuracy: 1.0000 - Best val loss: 0.0228 - Best val F1: 1.0000\n","\n","Source class: WAL | Domain: 49 | Accuracy: 0.9756 | Loss: 0.0629 | F1: 0.9736\n","\n","Domain: 50\n","x_dp_dom.shape: (153, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Training and evaluating on Dp data via cross-validation...\n","\tEpoch 10/100 - Train loss: 0.6334 - Val accuracy: 0.7200 - Val loss: 1.2067 - Val F1: 0.6028 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.4243 - Val accuracy: 0.7200 - Val loss: 1.0073 - Val F1: 0.6028 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.3193 - Val accuracy: 0.7200 - Val loss: 0.9503 - Val F1: 0.6028 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.2539 - Val accuracy: 0.7200 - Val loss: 0.8860 - Val F1: 0.6028 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.2100 - Val accuracy: 0.8000 - Val loss: 0.5429 - Val F1: 0.7465 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.1780 - Val accuracy: 0.9200 - Val loss: 0.2837 - Val F1: 0.8821 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.1514 - Val accuracy: 0.9200 - Val loss: 0.1983 - Val F1: 0.8821 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.1401 - Val accuracy: 0.9200 - Val loss: 0.1716 - Val F1: 0.8821 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.1321 - Val accuracy: 0.9200 - Val loss: 0.1606 - Val F1: 0.8821 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.1347 - Val accuracy: 0.9200 - Val loss: 0.1567 - Val F1: 0.8821 - LR: 0.00e+00\n","\tBest epoch: 100 - Best val accuracy: 0.9200 - Best val loss: 0.1567 - Best val F1: 0.8821\n","\n","\tEpoch 10/100 - Train loss: 0.6494 - Val accuracy: 0.7200 - Val loss: 1.2265 - Val F1: 0.6028 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.4200 - Val accuracy: 0.7200 - Val loss: 0.9782 - Val F1: 0.6028 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.3124 - Val accuracy: 0.7200 - Val loss: 0.8627 - Val F1: 0.6028 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.2447 - Val accuracy: 0.7200 - Val loss: 0.6652 - Val F1: 0.6028 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.1885 - Val accuracy: 0.8800 - Val loss: 0.4069 - Val F1: 0.8424 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.1538 - Val accuracy: 0.8800 - Val loss: 0.2943 - Val F1: 0.8424 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.1304 - Val accuracy: 0.9200 - Val loss: 0.2512 - Val F1: 0.8821 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.1206 - Val accuracy: 0.9200 - Val loss: 0.2320 - Val F1: 0.8821 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.1094 - Val accuracy: 0.9200 - Val loss: 0.2221 - Val F1: 0.8821 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.1100 - Val accuracy: 0.9200 - Val loss: 0.2178 - Val F1: 0.8821 - LR: 0.00e+00\n","\tBest epoch: 100 - Best val accuracy: 0.9200 - Best val loss: 0.2178 - Best val F1: 0.8821\n","\n","\tEpoch 10/100 - Train loss: 0.7259 - Val accuracy: 0.7200 - Val loss: 1.2042 - Val F1: 0.6028 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.4805 - Val accuracy: 0.7200 - Val loss: 1.0228 - Val F1: 0.6028 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.3464 - Val accuracy: 0.7200 - Val loss: 0.9102 - Val F1: 0.6028 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.2777 - Val accuracy: 0.7200 - Val loss: 0.7629 - Val F1: 0.6028 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.2274 - Val accuracy: 0.8000 - Val loss: 0.4697 - Val F1: 0.7465 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.1914 - Val accuracy: 0.8800 - Val loss: 0.3092 - Val F1: 0.8424 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.1645 - Val accuracy: 0.8800 - Val loss: 0.2564 - Val F1: 0.8424 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.1524 - Val accuracy: 0.9200 - Val loss: 0.2355 - Val F1: 0.8821 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.1490 - Val accuracy: 0.9200 - Val loss: 0.2255 - Val F1: 0.8821 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.1368 - Val accuracy: 0.9200 - Val loss: 0.2215 - Val F1: 0.8821 - LR: 0.00e+00\n","\tBest epoch: 100 - Best val accuracy: 0.9200 - Best val loss: 0.2215 - Best val F1: 0.8821\n","\n","\tEpoch 10/100 - Train loss: 0.6604 - Val accuracy: 0.7200 - Val loss: 1.2409 - Val F1: 0.6028 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.4270 - Val accuracy: 0.7200 - Val loss: 1.0204 - Val F1: 0.6028 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.3354 - Val accuracy: 0.7200 - Val loss: 0.9622 - Val F1: 0.6028 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.2666 - Val accuracy: 0.7200 - Val loss: 0.8827 - Val F1: 0.6028 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.2197 - Val accuracy: 0.8000 - Val loss: 0.5358 - Val F1: 0.7465 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.1914 - Val accuracy: 0.9200 - Val loss: 0.3004 - Val F1: 0.8821 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.1707 - Val accuracy: 0.9200 - Val loss: 0.2265 - Val F1: 0.8821 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.1545 - Val accuracy: 0.9200 - Val loss: 0.2014 - Val F1: 0.8821 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.1425 - Val accuracy: 0.9200 - Val loss: 0.1909 - Val F1: 0.8821 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.1462 - Val accuracy: 0.9200 - Val loss: 0.1871 - Val F1: 0.8821 - LR: 0.00e+00\n","\tBest epoch: 100 - Best val accuracy: 0.9200 - Best val loss: 0.1871 - Best val F1: 0.8821\n","\n","\tEpoch 10/100 - Train loss: 0.7332 - Val accuracy: 0.7200 - Val loss: 1.2778 - Val F1: 0.6028 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.4437 - Val accuracy: 0.7200 - Val loss: 1.0378 - Val F1: 0.6028 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.3189 - Val accuracy: 0.7200 - Val loss: 0.9466 - Val F1: 0.6028 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.2552 - Val accuracy: 0.7200 - Val loss: 0.9242 - Val F1: 0.6028 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.2084 - Val accuracy: 0.7600 - Val loss: 0.6843 - Val F1: 0.6838 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.1810 - Val accuracy: 0.8400 - Val loss: 0.4161 - Val F1: 0.7980 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.1565 - Val accuracy: 0.8400 - Val loss: 0.3115 - Val F1: 0.7980 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.1472 - Val accuracy: 0.8800 - Val loss: 0.2713 - Val F1: 0.8424 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.1407 - Val accuracy: 0.9200 - Val loss: 0.2539 - Val F1: 0.8821 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.1380 - Val accuracy: 0.9200 - Val loss: 0.2471 - Val F1: 0.8821 - LR: 0.00e+00\n","\tBest epoch: 100 - Best val accuracy: 0.9200 - Best val loss: 0.2471 - Best val F1: 0.8821\n","\n","Source class: WAL | Domain: 50 | Accuracy: 0.9022 | Loss: 0.2289 | F1: 0.8594\n","\n","Domain: 51\n","x_dp_dom.shape: (157, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Training and evaluating on Dp data via cross-validation...\n","\tEpoch 10/100 - Train loss: 0.7152 - Val accuracy: 0.7200 - Val loss: 1.2393 - Val F1: 0.6028 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.4373 - Val accuracy: 0.7200 - Val loss: 0.9979 - Val F1: 0.6028 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.3518 - Val accuracy: 0.7200 - Val loss: 0.8956 - Val F1: 0.6028 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.2734 - Val accuracy: 0.7200 - Val loss: 0.6900 - Val F1: 0.6028 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.2355 - Val accuracy: 0.8800 - Val loss: 0.3663 - Val F1: 0.8424 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.2026 - Val accuracy: 0.9200 - Val loss: 0.2304 - Val F1: 0.8821 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.1730 - Val accuracy: 0.9200 - Val loss: 0.1848 - Val F1: 0.8821 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.1483 - Val accuracy: 0.9600 - Val loss: 0.1650 - Val F1: 0.9405 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.1454 - Val accuracy: 0.9600 - Val loss: 0.1558 - Val F1: 0.9405 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.1417 - Val accuracy: 0.9600 - Val loss: 0.1521 - Val F1: 0.9405 - LR: 0.00e+00\n","\tBest epoch: 100 - Best val accuracy: 0.9600 - Best val loss: 0.1521 - Best val F1: 0.9405\n","\n","\tEpoch 10/100 - Train loss: 0.6683 - Val accuracy: 0.7200 - Val loss: 1.2326 - Val F1: 0.6028 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.4307 - Val accuracy: 0.7200 - Val loss: 1.0081 - Val F1: 0.6028 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.3316 - Val accuracy: 0.7200 - Val loss: 0.8892 - Val F1: 0.6028 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.2682 - Val accuracy: 0.7200 - Val loss: 0.6559 - Val F1: 0.6028 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.2229 - Val accuracy: 0.9200 - Val loss: 0.3711 - Val F1: 0.8821 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.1885 - Val accuracy: 0.9200 - Val loss: 0.2707 - Val F1: 0.8821 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.1737 - Val accuracy: 0.9200 - Val loss: 0.2407 - Val F1: 0.8821 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.1556 - Val accuracy: 0.9600 - Val loss: 0.2288 - Val F1: 0.9405 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.1455 - Val accuracy: 0.9600 - Val loss: 0.2231 - Val F1: 0.9405 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.1402 - Val accuracy: 0.9600 - Val loss: 0.2207 - Val F1: 0.9405 - LR: 0.00e+00\n","\tBest epoch: 100 - Best val accuracy: 0.9600 - Best val loss: 0.2207 - Best val F1: 0.9405\n","\n","\tEpoch 10/100 - Train loss: 0.7921 - Val accuracy: 0.6923 - Val loss: 1.2924 - Val F1: 0.5664 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.5146 - Val accuracy: 0.6923 - Val loss: 1.0892 - Val F1: 0.5664 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.3868 - Val accuracy: 0.6923 - Val loss: 0.9352 - Val F1: 0.5664 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.3041 - Val accuracy: 0.6923 - Val loss: 0.7512 - Val F1: 0.5664 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.2414 - Val accuracy: 0.8846 - Val loss: 0.4661 - Val F1: 0.8314 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.2076 - Val accuracy: 0.8846 - Val loss: 0.3313 - Val F1: 0.8314 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.1750 - Val accuracy: 0.8846 - Val loss: 0.2839 - Val F1: 0.8314 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.1584 - Val accuracy: 0.8846 - Val loss: 0.2647 - Val F1: 0.8314 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.1480 - Val accuracy: 0.9615 - Val loss: 0.2557 - Val F1: 0.9428 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.1493 - Val accuracy: 0.9615 - Val loss: 0.2526 - Val F1: 0.9428 - LR: 0.00e+00\n","\tBest epoch: 100 - Best val accuracy: 0.9615 - Best val loss: 0.2526 - Best val F1: 0.9428\n","\n","\tEpoch 10/100 - Train loss: 0.8438 - Val accuracy: 0.6923 - Val loss: 1.2793 - Val F1: 0.5664 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.5342 - Val accuracy: 0.6923 - Val loss: 1.0574 - Val F1: 0.5664 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.3974 - Val accuracy: 0.6923 - Val loss: 0.8967 - Val F1: 0.5664 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.3278 - Val accuracy: 0.6923 - Val loss: 0.6893 - Val F1: 0.5664 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.2665 - Val accuracy: 0.8846 - Val loss: 0.4308 - Val F1: 0.8307 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.2335 - Val accuracy: 0.8846 - Val loss: 0.3078 - Val F1: 0.8307 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.1937 - Val accuracy: 0.8846 - Val loss: 0.2570 - Val F1: 0.8307 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.1866 - Val accuracy: 0.8846 - Val loss: 0.2342 - Val F1: 0.8307 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.1704 - Val accuracy: 0.8846 - Val loss: 0.2234 - Val F1: 0.8307 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.1631 - Val accuracy: 0.8846 - Val loss: 0.2190 - Val F1: 0.8307 - LR: 0.00e+00\n","\tBest epoch: 100 - Best val accuracy: 0.8846 - Best val loss: 0.2190 - Best val F1: 0.8307\n","\n","\tEpoch 10/100 - Train loss: 0.8210 - Val accuracy: 0.6923 - Val loss: 1.2596 - Val F1: 0.5664 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.5111 - Val accuracy: 0.6923 - Val loss: 1.0466 - Val F1: 0.5664 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.3702 - Val accuracy: 0.6923 - Val loss: 0.9079 - Val F1: 0.5664 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.2933 - Val accuracy: 0.6923 - Val loss: 0.7224 - Val F1: 0.5664 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.2301 - Val accuracy: 0.9231 - Val loss: 0.4280 - Val F1: 0.8995 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.1918 - Val accuracy: 0.9615 - Val loss: 0.2859 - Val F1: 0.9556 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.1681 - Val accuracy: 0.9615 - Val loss: 0.2366 - Val F1: 0.9556 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.1540 - Val accuracy: 0.9615 - Val loss: 0.2178 - Val F1: 0.9556 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.1364 - Val accuracy: 0.9615 - Val loss: 0.2098 - Val F1: 0.9556 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.1311 - Val accuracy: 0.9615 - Val loss: 0.2069 - Val F1: 0.9556 - LR: 0.00e+00\n","\tBest epoch: 100 - Best val accuracy: 0.9615 - Best val loss: 0.2069 - Best val F1: 0.9556\n","\n","Source class: WAL | Domain: 51 | Accuracy: 0.8982 | Loss: 0.2412 | F1: 0.8548\n","\n","Domain: 52\n","x_dp_dom.shape: (153, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Training and evaluating on Dp data via cross-validation...\n","\tEpoch 10/100 - Train loss: 0.7998 - Val accuracy: 0.7200 - Val loss: 1.2783 - Val F1: 0.6028 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.4852 - Val accuracy: 0.7200 - Val loss: 1.0535 - Val F1: 0.6028 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.3452 - Val accuracy: 0.7200 - Val loss: 0.9188 - Val F1: 0.6028 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.2635 - Val accuracy: 0.7200 - Val loss: 0.7901 - Val F1: 0.6028 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.2147 - Val accuracy: 0.8000 - Val loss: 0.4885 - Val F1: 0.7465 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.1875 - Val accuracy: 0.9200 - Val loss: 0.2628 - Val F1: 0.8821 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.1665 - Val accuracy: 0.9200 - Val loss: 0.1934 - Val F1: 0.8821 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.1541 - Val accuracy: 0.9200 - Val loss: 0.1704 - Val F1: 0.8821 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.1495 - Val accuracy: 0.9200 - Val loss: 0.1613 - Val F1: 0.8821 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.1432 - Val accuracy: 0.9200 - Val loss: 0.1582 - Val F1: 0.8821 - LR: 0.00e+00\n","\tBest epoch: 100 - Best val accuracy: 0.9200 - Best val loss: 0.1582 - Best val F1: 0.8821\n","\n","\tEpoch 10/100 - Train loss: 0.6748 - Val accuracy: 0.7200 - Val loss: 1.2537 - Val F1: 0.6028 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.4539 - Val accuracy: 0.7200 - Val loss: 1.0865 - Val F1: 0.6028 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.3329 - Val accuracy: 0.7200 - Val loss: 1.0345 - Val F1: 0.6028 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.2238 - Val accuracy: 0.7200 - Val loss: 0.9189 - Val F1: 0.6028 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.1718 - Val accuracy: 0.9200 - Val loss: 0.5678 - Val F1: 0.8821 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.1474 - Val accuracy: 0.9200 - Val loss: 0.2816 - Val F1: 0.8821 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.1316 - Val accuracy: 0.9200 - Val loss: 0.1881 - Val F1: 0.9005 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.1173 - Val accuracy: 0.9200 - Val loss: 0.1617 - Val F1: 0.9005 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.1131 - Val accuracy: 0.9200 - Val loss: 0.1527 - Val F1: 0.9005 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.1011 - Val accuracy: 0.9200 - Val loss: 0.1496 - Val F1: 0.9005 - LR: 0.00e+00\n","\tBest epoch: 100 - Best val accuracy: 0.9200 - Best val loss: 0.1496 - Best val F1: 0.9005\n","\n","\tEpoch 10/100 - Train loss: 0.7629 - Val accuracy: 0.7200 - Val loss: 1.2780 - Val F1: 0.6028 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.4498 - Val accuracy: 0.7200 - Val loss: 1.0479 - Val F1: 0.6028 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.3334 - Val accuracy: 0.7200 - Val loss: 0.9141 - Val F1: 0.6028 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.2873 - Val accuracy: 0.7200 - Val loss: 0.8195 - Val F1: 0.6028 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.2345 - Val accuracy: 0.8000 - Val loss: 0.5094 - Val F1: 0.7465 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.1983 - Val accuracy: 0.9200 - Val loss: 0.2992 - Val F1: 0.8821 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.1812 - Val accuracy: 0.9200 - Val loss: 0.2425 - Val F1: 0.8821 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.1662 - Val accuracy: 0.9200 - Val loss: 0.2220 - Val F1: 0.8821 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.1617 - Val accuracy: 0.9200 - Val loss: 0.2130 - Val F1: 0.8821 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.1606 - Val accuracy: 0.9200 - Val loss: 0.2097 - Val F1: 0.8821 - LR: 0.00e+00\n","\tBest epoch: 100 - Best val accuracy: 0.9200 - Best val loss: 0.2097 - Best val F1: 0.8821\n","\n","\tEpoch 10/100 - Train loss: 0.7684 - Val accuracy: 0.7200 - Val loss: 1.2367 - Val F1: 0.6028 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.5023 - Val accuracy: 0.7200 - Val loss: 1.0431 - Val F1: 0.6028 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.3426 - Val accuracy: 0.7200 - Val loss: 0.9031 - Val F1: 0.6028 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.2546 - Val accuracy: 0.7200 - Val loss: 0.6776 - Val F1: 0.6028 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.1937 - Val accuracy: 0.8800 - Val loss: 0.3851 - Val F1: 0.8424 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.1580 - Val accuracy: 0.9200 - Val loss: 0.2381 - Val F1: 0.8821 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.1383 - Val accuracy: 0.9200 - Val loss: 0.1859 - Val F1: 0.8821 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.1300 - Val accuracy: 0.9200 - Val loss: 0.1661 - Val F1: 0.8821 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.1151 - Val accuracy: 0.9200 - Val loss: 0.1577 - Val F1: 0.8821 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.1152 - Val accuracy: 0.9200 - Val loss: 0.1547 - Val F1: 0.8821 - LR: 0.00e+00\n","\tBest epoch: 100 - Best val accuracy: 0.9200 - Best val loss: 0.1547 - Best val F1: 0.8821\n","\n","\tEpoch 10/100 - Train loss: 0.6700 - Val accuracy: 0.7200 - Val loss: 1.2638 - Val F1: 0.6028 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.4333 - Val accuracy: 0.7200 - Val loss: 1.0356 - Val F1: 0.6028 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.3024 - Val accuracy: 0.7200 - Val loss: 0.9413 - Val F1: 0.6028 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.2212 - Val accuracy: 0.7200 - Val loss: 0.8470 - Val F1: 0.6028 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.1844 - Val accuracy: 0.7200 - Val loss: 0.5093 - Val F1: 0.6028 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.1564 - Val accuracy: 0.9200 - Val loss: 0.2509 - Val F1: 0.8821 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.1381 - Val accuracy: 0.9200 - Val loss: 0.1772 - Val F1: 0.8821 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.1270 - Val accuracy: 0.9200 - Val loss: 0.1558 - Val F1: 0.8821 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.1193 - Val accuracy: 0.9200 - Val loss: 0.1478 - Val F1: 0.8821 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.1162 - Val accuracy: 0.9200 - Val loss: 0.1451 - Val F1: 0.8821 - LR: 0.00e+00\n","\tBest epoch: 100 - Best val accuracy: 0.9200 - Best val loss: 0.1451 - Best val F1: 0.8821\n","\n","Source class: WAL | Domain: 52 | Accuracy: 0.9219 | Loss: 0.1878 | F1: 0.8883\n","\n","Domain: 53\n","x_dp_dom.shape: (159, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Training and evaluating on Dp data via cross-validation...\n","\tEpoch 10/100 - Train loss: 0.2091 - Val accuracy: 0.9615 - Val loss: 0.1595 - Val F1: 0.9462 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.0774 - Val accuracy: 0.9615 - Val loss: 0.0802 - Val F1: 0.9462 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.0393 - Val accuracy: 1.0000 - Val loss: 0.0616 - Val F1: 1.0000 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.0287 - Val accuracy: 0.9615 - Val loss: 0.0510 - Val F1: 0.9462 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.0229 - Val accuracy: 0.9615 - Val loss: 0.0455 - Val F1: 0.9462 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.0183 - Val accuracy: 0.9615 - Val loss: 0.0462 - Val F1: 0.9462 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0095 - Val accuracy: 0.9615 - Val loss: 0.0484 - Val F1: 0.9462 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0107 - Val accuracy: 0.9615 - Val loss: 0.0442 - Val F1: 0.9462 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0062 - Val accuracy: 0.9615 - Val loss: 0.0456 - Val F1: 0.9462 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0095 - Val accuracy: 0.9615 - Val loss: 0.0454 - Val F1: 0.9462 - LR: 0.00e+00\n","\tBest epoch: 65 - Best val accuracy: 1.0000 - Best val loss: 0.0405 - Best val F1: 1.0000\n","\n","\tEpoch 10/100 - Train loss: 0.1581 - Val accuracy: 0.9615 - Val loss: 0.1318 - Val F1: 0.9462 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.1139 - Val accuracy: 0.9615 - Val loss: 0.0755 - Val F1: 0.9462 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.0621 - Val accuracy: 0.9615 - Val loss: 0.0588 - Val F1: 0.9462 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.0353 - Val accuracy: 1.0000 - Val loss: 0.0394 - Val F1: 1.0000 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.0255 - Val accuracy: 0.9615 - Val loss: 0.0364 - Val F1: 0.9462 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.0149 - Val accuracy: 1.0000 - Val loss: 0.0243 - Val F1: 1.0000 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0133 - Val accuracy: 1.0000 - Val loss: 0.0202 - Val F1: 1.0000 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0100 - Val accuracy: 1.0000 - Val loss: 0.0187 - Val F1: 1.0000 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0077 - Val accuracy: 1.0000 - Val loss: 0.0174 - Val F1: 1.0000 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0096 - Val accuracy: 1.0000 - Val loss: 0.0194 - Val F1: 1.0000 - LR: 0.00e+00\n","\tBest epoch: 75 - Best val accuracy: 1.0000 - Best val loss: 0.0172 - Best val F1: 1.0000\n","\n","\tEpoch 10/100 - Train loss: 0.2494 - Val accuracy: 0.9615 - Val loss: 0.1636 - Val F1: 0.9462 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.1522 - Val accuracy: 0.9615 - Val loss: 0.0978 - Val F1: 0.9462 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.0743 - Val accuracy: 0.9615 - Val loss: 0.0737 - Val F1: 0.9462 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.0432 - Val accuracy: 1.0000 - Val loss: 0.0623 - Val F1: 1.0000 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.0323 - Val accuracy: 1.0000 - Val loss: 0.0486 - Val F1: 1.0000 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.0171 - Val accuracy: 1.0000 - Val loss: 0.0386 - Val F1: 1.0000 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0130 - Val accuracy: 1.0000 - Val loss: 0.0324 - Val F1: 1.0000 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0156 - Val accuracy: 1.0000 - Val loss: 0.0306 - Val F1: 1.0000 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0133 - Val accuracy: 1.0000 - Val loss: 0.0275 - Val F1: 1.0000 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0097 - Val accuracy: 1.0000 - Val loss: 0.0251 - Val F1: 1.0000 - LR: 0.00e+00\n","\tBest epoch: 100 - Best val accuracy: 1.0000 - Best val loss: 0.0251 - Best val F1: 1.0000\n","\n","\tEpoch 10/100 - Train loss: 0.1644 - Val accuracy: 1.0000 - Val loss: 0.1579 - Val F1: 1.0000 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.1178 - Val accuracy: 1.0000 - Val loss: 0.0988 - Val F1: 1.0000 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.0684 - Val accuracy: 1.0000 - Val loss: 0.0763 - Val F1: 1.0000 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.0532 - Val accuracy: 1.0000 - Val loss: 0.0682 - Val F1: 1.0000 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.0254 - Val accuracy: 1.0000 - Val loss: 0.0532 - Val F1: 1.0000 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.0228 - Val accuracy: 1.0000 - Val loss: 0.0373 - Val F1: 1.0000 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0172 - Val accuracy: 1.0000 - Val loss: 0.0390 - Val F1: 1.0000 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0121 - Val accuracy: 1.0000 - Val loss: 0.0392 - Val F1: 1.0000 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0205 - Val accuracy: 1.0000 - Val loss: 0.0393 - Val F1: 1.0000 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0082 - Val accuracy: 1.0000 - Val loss: 0.0331 - Val F1: 1.0000 - LR: 0.00e+00\n","\tBest epoch: 87 - Best val accuracy: 1.0000 - Best val loss: 0.0292 - Best val F1: 1.0000\n","\n","\tEpoch 10/100 - Train loss: 0.1420 - Val accuracy: 0.9615 - Val loss: 0.1313 - Val F1: 0.9462 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.0765 - Val accuracy: 0.9615 - Val loss: 0.0679 - Val F1: 0.9462 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.0371 - Val accuracy: 1.0000 - Val loss: 0.0449 - Val F1: 1.0000 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.0224 - Val accuracy: 1.0000 - Val loss: 0.0331 - Val F1: 1.0000 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.0129 - Val accuracy: 1.0000 - Val loss: 0.0241 - Val F1: 1.0000 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.0153 - Val accuracy: 1.0000 - Val loss: 0.0216 - Val F1: 1.0000 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0092 - Val accuracy: 1.0000 - Val loss: 0.0196 - Val F1: 1.0000 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0082 - Val accuracy: 1.0000 - Val loss: 0.0195 - Val F1: 1.0000 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0103 - Val accuracy: 1.0000 - Val loss: 0.0177 - Val F1: 1.0000 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0109 - Val accuracy: 1.0000 - Val loss: 0.0166 - Val F1: 1.0000 - LR: 0.00e+00\n","\tBest epoch: 93 - Best val accuracy: 1.0000 - Best val loss: 0.0165 - Best val F1: 1.0000\n","\n","Source class: WAL | Domain: 53 | Accuracy: 0.9938 | Loss: 0.0362 | F1: 0.9933\n","\n","Domain: 54\n","x_dp_dom.shape: (153, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Training and evaluating on Dp data via cross-validation...\n","\tEpoch 10/100 - Train loss: 0.6975 - Val accuracy: 0.7200 - Val loss: 1.2897 - Val F1: 0.6028 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.4181 - Val accuracy: 0.7200 - Val loss: 1.0835 - Val F1: 0.6028 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.2918 - Val accuracy: 0.7200 - Val loss: 0.9079 - Val F1: 0.6028 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.2416 - Val accuracy: 0.7200 - Val loss: 0.6743 - Val F1: 0.6028 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.1964 - Val accuracy: 0.9200 - Val loss: 0.3741 - Val F1: 0.8821 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.1743 - Val accuracy: 0.9200 - Val loss: 0.2315 - Val F1: 0.8821 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.1490 - Val accuracy: 0.9600 - Val loss: 0.1801 - Val F1: 0.9467 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.1418 - Val accuracy: 0.9600 - Val loss: 0.1597 - Val F1: 0.9467 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.1380 - Val accuracy: 0.9600 - Val loss: 0.1507 - Val F1: 0.9467 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.1303 - Val accuracy: 0.9600 - Val loss: 0.1479 - Val F1: 0.9467 - LR: 0.00e+00\n","\tBest epoch: 100 - Best val accuracy: 0.9600 - Best val loss: 0.1479 - Best val F1: 0.9467\n","\n","\tEpoch 10/100 - Train loss: 0.5620 - Val accuracy: 0.7200 - Val loss: 1.2891 - Val F1: 0.6028 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.3298 - Val accuracy: 0.7200 - Val loss: 1.0510 - Val F1: 0.6028 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.2565 - Val accuracy: 0.7200 - Val loss: 0.7963 - Val F1: 0.6028 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.2140 - Val accuracy: 0.8000 - Val loss: 0.5115 - Val F1: 0.7465 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.1824 - Val accuracy: 0.9200 - Val loss: 0.2762 - Val F1: 0.8821 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.1685 - Val accuracy: 0.9600 - Val loss: 0.1751 - Val F1: 0.9405 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.1496 - Val accuracy: 0.9600 - Val loss: 0.1422 - Val F1: 0.9467 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.1404 - Val accuracy: 0.9600 - Val loss: 0.1305 - Val F1: 0.9467 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.1305 - Val accuracy: 0.9600 - Val loss: 0.1254 - Val F1: 0.9467 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.1379 - Val accuracy: 0.9600 - Val loss: 0.1238 - Val F1: 0.9467 - LR: 0.00e+00\n","\tBest epoch: 100 - Best val accuracy: 0.9600 - Best val loss: 0.1238 - Best val F1: 0.9467\n","\n","\tEpoch 10/100 - Train loss: 0.7514 - Val accuracy: 0.7200 - Val loss: 1.3000 - Val F1: 0.6028 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.4137 - Val accuracy: 0.7200 - Val loss: 1.0810 - Val F1: 0.6028 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.3170 - Val accuracy: 0.7200 - Val loss: 0.9031 - Val F1: 0.6028 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.2573 - Val accuracy: 0.7200 - Val loss: 0.7396 - Val F1: 0.6028 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.2410 - Val accuracy: 0.8800 - Val loss: 0.4579 - Val F1: 0.8424 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.2169 - Val accuracy: 0.9200 - Val loss: 0.2813 - Val F1: 0.9005 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.1926 - Val accuracy: 0.9200 - Val loss: 0.2200 - Val F1: 0.9005 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.1829 - Val accuracy: 0.9200 - Val loss: 0.1992 - Val F1: 0.9005 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.1741 - Val accuracy: 0.9200 - Val loss: 0.1911 - Val F1: 0.9005 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.1714 - Val accuracy: 0.9200 - Val loss: 0.1886 - Val F1: 0.9005 - LR: 0.00e+00\n","\tBest epoch: 100 - Best val accuracy: 0.9200 - Best val loss: 0.1886 - Best val F1: 0.9005\n","\n","\tEpoch 10/100 - Train loss: 0.7809 - Val accuracy: 0.7200 - Val loss: 1.3377 - Val F1: 0.6028 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.4622 - Val accuracy: 0.7200 - Val loss: 1.1254 - Val F1: 0.6028 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.3478 - Val accuracy: 0.7200 - Val loss: 0.9476 - Val F1: 0.6028 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.2790 - Val accuracy: 0.7200 - Val loss: 0.7357 - Val F1: 0.6028 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.2379 - Val accuracy: 0.9200 - Val loss: 0.4278 - Val F1: 0.8821 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.2117 - Val accuracy: 0.9200 - Val loss: 0.2583 - Val F1: 0.8821 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.1818 - Val accuracy: 0.9200 - Val loss: 0.1940 - Val F1: 0.9005 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.1736 - Val accuracy: 0.9200 - Val loss: 0.1685 - Val F1: 0.9005 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.1595 - Val accuracy: 0.9200 - Val loss: 0.1573 - Val F1: 0.9005 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.1552 - Val accuracy: 0.9600 - Val loss: 0.1535 - Val F1: 0.9467 - LR: 0.00e+00\n","\tBest epoch: 100 - Best val accuracy: 0.9600 - Best val loss: 0.1535 - Best val F1: 0.9467\n","\n","\tEpoch 10/100 - Train loss: 0.6626 - Val accuracy: 0.7200 - Val loss: 1.3322 - Val F1: 0.6028 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.3882 - Val accuracy: 0.7200 - Val loss: 1.1141 - Val F1: 0.6028 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.2886 - Val accuracy: 0.7200 - Val loss: 0.9400 - Val F1: 0.6028 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.2374 - Val accuracy: 0.7200 - Val loss: 0.6251 - Val F1: 0.6028 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.1932 - Val accuracy: 0.9200 - Val loss: 0.3205 - Val F1: 0.8821 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.1736 - Val accuracy: 0.9200 - Val loss: 0.2096 - Val F1: 0.9005 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.1499 - Val accuracy: 0.9600 - Val loss: 0.1696 - Val F1: 0.9405 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.1436 - Val accuracy: 0.9600 - Val loss: 0.1520 - Val F1: 0.9405 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.1355 - Val accuracy: 0.9600 - Val loss: 0.1440 - Val F1: 0.9405 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.1316 - Val accuracy: 0.9600 - Val loss: 0.1411 - Val F1: 0.9405 - LR: 0.00e+00\n","\tBest epoch: 100 - Best val accuracy: 0.9600 - Best val loss: 0.1411 - Best val F1: 0.9405\n","\n","Source class: WAL | Domain: 54 | Accuracy: 0.9284 | Loss: 0.2579 | F1: 0.9006\n","\n","Domain: 55\n","x_dp_dom.shape: (160, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Training and evaluating on Dp data via cross-validation...\n","\tEpoch 10/100 - Train loss: 0.1728 - Val accuracy: 0.9231 - Val loss: 0.2452 - Val F1: 0.8995 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.0662 - Val accuracy: 0.9615 - Val loss: 0.1227 - Val F1: 0.9462 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.0313 - Val accuracy: 0.9615 - Val loss: 0.0946 - Val F1: 0.9462 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.0162 - Val accuracy: 0.9615 - Val loss: 0.0812 - Val F1: 0.9462 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.0070 - Val accuracy: 0.9615 - Val loss: 0.0690 - Val F1: 0.9462 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.0080 - Val accuracy: 0.9615 - Val loss: 0.0648 - Val F1: 0.9462 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0153 - Val accuracy: 0.9615 - Val loss: 0.0608 - Val F1: 0.9462 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0067 - Val accuracy: 0.9615 - Val loss: 0.0680 - Val F1: 0.9462 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0039 - Val accuracy: 0.9615 - Val loss: 0.0654 - Val F1: 0.9462 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0046 - Val accuracy: 0.9615 - Val loss: 0.0623 - Val F1: 0.9462 - LR: 0.00e+00\n","\tBest epoch: 55 - Best val accuracy: 0.9615 - Best val loss: 0.0595 - Best val F1: 0.9462\n","\n","\tEpoch 10/100 - Train loss: 0.2400 - Val accuracy: 0.9231 - Val loss: 0.2289 - Val F1: 0.8995 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.0798 - Val accuracy: 1.0000 - Val loss: 0.0780 - Val F1: 1.0000 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.0295 - Val accuracy: 1.0000 - Val loss: 0.0401 - Val F1: 1.0000 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.0195 - Val accuracy: 1.0000 - Val loss: 0.0245 - Val F1: 1.0000 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.0181 - Val accuracy: 1.0000 - Val loss: 0.0162 - Val F1: 1.0000 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.0104 - Val accuracy: 1.0000 - Val loss: 0.0128 - Val F1: 1.0000 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0068 - Val accuracy: 1.0000 - Val loss: 0.0113 - Val F1: 1.0000 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0069 - Val accuracy: 1.0000 - Val loss: 0.0092 - Val F1: 1.0000 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0095 - Val accuracy: 1.0000 - Val loss: 0.0091 - Val F1: 1.0000 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0049 - Val accuracy: 1.0000 - Val loss: 0.0085 - Val F1: 1.0000 - LR: 0.00e+00\n","\tBest epoch: 100 - Best val accuracy: 1.0000 - Best val loss: 0.0085 - Best val F1: 1.0000\n","\n","\tEpoch 10/100 - Train loss: 0.2582 - Val accuracy: 0.9615 - Val loss: 0.2289 - Val F1: 0.9428 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.1019 - Val accuracy: 1.0000 - Val loss: 0.0705 - Val F1: 1.0000 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.0416 - Val accuracy: 1.0000 - Val loss: 0.0269 - Val F1: 1.0000 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.0211 - Val accuracy: 1.0000 - Val loss: 0.0129 - Val F1: 1.0000 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.0129 - Val accuracy: 1.0000 - Val loss: 0.0089 - Val F1: 1.0000 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.0105 - Val accuracy: 1.0000 - Val loss: 0.0060 - Val F1: 1.0000 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0128 - Val accuracy: 1.0000 - Val loss: 0.0051 - Val F1: 1.0000 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0080 - Val accuracy: 1.0000 - Val loss: 0.0045 - Val F1: 1.0000 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0095 - Val accuracy: 1.0000 - Val loss: 0.0040 - Val F1: 1.0000 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0060 - Val accuracy: 1.0000 - Val loss: 0.0037 - Val F1: 1.0000 - LR: 0.00e+00\n","\tBest epoch: 100 - Best val accuracy: 1.0000 - Best val loss: 0.0037 - Best val F1: 1.0000\n","\n","\tEpoch 10/100 - Train loss: 0.2779 - Val accuracy: 0.8846 - Val loss: 0.2293 - Val F1: 0.8314 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.1014 - Val accuracy: 0.9615 - Val loss: 0.0880 - Val F1: 0.9462 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.0472 - Val accuracy: 0.9615 - Val loss: 0.0586 - Val F1: 0.9462 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.0252 - Val accuracy: 0.9615 - Val loss: 0.0467 - Val F1: 0.9462 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.0187 - Val accuracy: 0.9615 - Val loss: 0.0408 - Val F1: 0.9462 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.0139 - Val accuracy: 0.9615 - Val loss: 0.0345 - Val F1: 0.9462 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0085 - Val accuracy: 0.9615 - Val loss: 0.0322 - Val F1: 0.9462 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0070 - Val accuracy: 0.9615 - Val loss: 0.0318 - Val F1: 0.9462 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0070 - Val accuracy: 1.0000 - Val loss: 0.0285 - Val F1: 1.0000 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0123 - Val accuracy: 1.0000 - Val loss: 0.0309 - Val F1: 1.0000 - LR: 0.00e+00\n","\tBest epoch: 90 - Best val accuracy: 1.0000 - Best val loss: 0.0285 - Best val F1: 1.0000\n","\n","\tEpoch 10/100 - Train loss: 0.2211 - Val accuracy: 0.9231 - Val loss: 0.2416 - Val F1: 0.8995 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.0639 - Val accuracy: 0.9615 - Val loss: 0.0797 - Val F1: 0.9615 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.0231 - Val accuracy: 0.9615 - Val loss: 0.0473 - Val F1: 0.9615 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.0194 - Val accuracy: 1.0000 - Val loss: 0.0385 - Val F1: 1.0000 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.0157 - Val accuracy: 1.0000 - Val loss: 0.0248 - Val F1: 1.0000 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.0063 - Val accuracy: 1.0000 - Val loss: 0.0231 - Val F1: 1.0000 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0057 - Val accuracy: 1.0000 - Val loss: 0.0199 - Val F1: 1.0000 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0046 - Val accuracy: 1.0000 - Val loss: 0.0215 - Val F1: 1.0000 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0035 - Val accuracy: 1.0000 - Val loss: 0.0212 - Val F1: 1.0000 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0042 - Val accuracy: 1.0000 - Val loss: 0.0208 - Val F1: 1.0000 - LR: 0.00e+00\n","\tBest epoch: 71 - Best val accuracy: 1.0000 - Best val loss: 0.0191 - Best val F1: 1.0000\n","\n","Source class: WAL | Domain: 55 | Accuracy: 0.9938 | Loss: 0.0312 | F1: 0.9928\n","\n","Domain: 56\n","x_dp_dom.shape: (153, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Training and evaluating on Dp data via cross-validation...\n","\tEpoch 10/100 - Train loss: 0.7550 - Val accuracy: 0.7200 - Val loss: 1.2109 - Val F1: 0.6028 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.4423 - Val accuracy: 0.7200 - Val loss: 0.9936 - Val F1: 0.6028 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.3045 - Val accuracy: 0.7200 - Val loss: 0.8829 - Val F1: 0.6028 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.2366 - Val accuracy: 0.7200 - Val loss: 0.7347 - Val F1: 0.6028 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.1872 - Val accuracy: 0.8800 - Val loss: 0.3771 - Val F1: 0.8424 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.1497 - Val accuracy: 0.9200 - Val loss: 0.2162 - Val F1: 0.8821 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.1334 - Val accuracy: 0.9200 - Val loss: 0.1636 - Val F1: 0.8821 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.1178 - Val accuracy: 0.9200 - Val loss: 0.1411 - Val F1: 0.8821 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.1078 - Val accuracy: 0.9600 - Val loss: 0.1309 - Val F1: 0.9405 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.1043 - Val accuracy: 0.9600 - Val loss: 0.1271 - Val F1: 0.9405 - LR: 0.00e+00\n","\tBest epoch: 100 - Best val accuracy: 0.9600 - Best val loss: 0.1271 - Best val F1: 0.9405\n","\n","\tEpoch 10/100 - Train loss: 0.8177 - Val accuracy: 0.7200 - Val loss: 1.3024 - Val F1: 0.6028 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.4630 - Val accuracy: 0.7200 - Val loss: 1.0883 - Val F1: 0.6028 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.3265 - Val accuracy: 0.7200 - Val loss: 0.9362 - Val F1: 0.6028 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.2343 - Val accuracy: 0.7200 - Val loss: 0.8302 - Val F1: 0.6028 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.1864 - Val accuracy: 0.7600 - Val loss: 0.4688 - Val F1: 0.6838 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.1521 - Val accuracy: 0.9200 - Val loss: 0.2596 - Val F1: 0.8821 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.1287 - Val accuracy: 0.9600 - Val loss: 0.1964 - Val F1: 0.9405 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.1178 - Val accuracy: 0.9600 - Val loss: 0.1730 - Val F1: 0.9405 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.1059 - Val accuracy: 0.9600 - Val loss: 0.1629 - Val F1: 0.9405 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.1001 - Val accuracy: 0.9600 - Val loss: 0.1593 - Val F1: 0.9405 - LR: 0.00e+00\n","\tBest epoch: 100 - Best val accuracy: 0.9600 - Best val loss: 0.1593 - Best val F1: 0.9405\n","\n","\tEpoch 10/100 - Train loss: 0.8875 - Val accuracy: 0.7200 - Val loss: 1.3315 - Val F1: 0.6028 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.5238 - Val accuracy: 0.7200 - Val loss: 1.1107 - Val F1: 0.6028 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.3572 - Val accuracy: 0.7200 - Val loss: 0.9201 - Val F1: 0.6028 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.2918 - Val accuracy: 0.7200 - Val loss: 0.7165 - Val F1: 0.6028 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.2403 - Val accuracy: 0.9200 - Val loss: 0.3776 - Val F1: 0.8821 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.2060 - Val accuracy: 0.9200 - Val loss: 0.2618 - Val F1: 0.8821 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.1786 - Val accuracy: 0.9200 - Val loss: 0.2268 - Val F1: 0.8821 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.1645 - Val accuracy: 0.9200 - Val loss: 0.2122 - Val F1: 0.8821 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.1511 - Val accuracy: 0.9600 - Val loss: 0.2045 - Val F1: 0.9405 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.1489 - Val accuracy: 0.9200 - Val loss: 0.2018 - Val F1: 0.8824 - LR: 0.00e+00\n","\tBest epoch: 100 - Best val accuracy: 0.9200 - Best val loss: 0.2018 - Best val F1: 0.8824\n","\n","\tEpoch 10/100 - Train loss: 0.6902 - Val accuracy: 0.7200 - Val loss: 1.1937 - Val F1: 0.6028 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.4404 - Val accuracy: 0.7200 - Val loss: 0.9620 - Val F1: 0.6028 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.3454 - Val accuracy: 0.7200 - Val loss: 0.9135 - Val F1: 0.6028 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.2576 - Val accuracy: 0.7200 - Val loss: 0.7743 - Val F1: 0.6028 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.2133 - Val accuracy: 0.8800 - Val loss: 0.4163 - Val F1: 0.8424 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.1764 - Val accuracy: 0.9200 - Val loss: 0.2536 - Val F1: 0.8821 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.1591 - Val accuracy: 0.9200 - Val loss: 0.2045 - Val F1: 0.8821 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.1457 - Val accuracy: 0.9200 - Val loss: 0.1853 - Val F1: 0.8821 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.1366 - Val accuracy: 0.9200 - Val loss: 0.1767 - Val F1: 0.8821 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.1278 - Val accuracy: 0.9200 - Val loss: 0.1736 - Val F1: 0.8821 - LR: 0.00e+00\n","\tBest epoch: 100 - Best val accuracy: 0.9200 - Best val loss: 0.1736 - Best val F1: 0.8821\n","\n","\tEpoch 10/100 - Train loss: 0.6563 - Val accuracy: 0.7200 - Val loss: 1.2174 - Val F1: 0.6028 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.3803 - Val accuracy: 0.7200 - Val loss: 0.9757 - Val F1: 0.6028 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.2815 - Val accuracy: 0.7200 - Val loss: 0.8894 - Val F1: 0.6028 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.2073 - Val accuracy: 0.7200 - Val loss: 0.7760 - Val F1: 0.6028 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.1642 - Val accuracy: 0.8800 - Val loss: 0.4000 - Val F1: 0.8424 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.1350 - Val accuracy: 0.9200 - Val loss: 0.2061 - Val F1: 0.8821 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.1179 - Val accuracy: 0.9600 - Val loss: 0.1446 - Val F1: 0.9405 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.1057 - Val accuracy: 0.9600 - Val loss: 0.1214 - Val F1: 0.9405 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0976 - Val accuracy: 0.9600 - Val loss: 0.1117 - Val F1: 0.9405 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0935 - Val accuracy: 0.9600 - Val loss: 0.1082 - Val F1: 0.9405 - LR: 0.00e+00\n","\tBest epoch: 100 - Best val accuracy: 0.9600 - Best val loss: 0.1082 - Best val F1: 0.9405\n","\n","Source class: WAL | Domain: 56 | Accuracy: 0.9413 | Loss: 0.1790 | F1: 0.9178\n","\n","Domain: 57\n","x_dp_dom.shape: (153, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Training and evaluating on Dp data via cross-validation...\n","\tEpoch 10/100 - Train loss: 0.7332 - Val accuracy: 0.7200 - Val loss: 1.2322 - Val F1: 0.6028 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.4413 - Val accuracy: 0.7200 - Val loss: 1.0184 - Val F1: 0.6028 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.3317 - Val accuracy: 0.7200 - Val loss: 0.9039 - Val F1: 0.6028 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.2644 - Val accuracy: 0.7200 - Val loss: 0.8606 - Val F1: 0.6028 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.2154 - Val accuracy: 0.7600 - Val loss: 0.5464 - Val F1: 0.6838 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.1814 - Val accuracy: 0.9200 - Val loss: 0.3059 - Val F1: 0.8821 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.1583 - Val accuracy: 0.9200 - Val loss: 0.2340 - Val F1: 0.8821 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.1421 - Val accuracy: 0.9200 - Val loss: 0.2071 - Val F1: 0.8821 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.1412 - Val accuracy: 0.9200 - Val loss: 0.1960 - Val F1: 0.8821 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.1282 - Val accuracy: 0.9200 - Val loss: 0.1920 - Val F1: 0.8821 - LR: 0.00e+00\n","\tBest epoch: 100 - Best val accuracy: 0.9200 - Best val loss: 0.1920 - Best val F1: 0.8821\n","\n","\tEpoch 10/100 - Train loss: 0.7635 - Val accuracy: 0.7200 - Val loss: 1.2475 - Val F1: 0.6028 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.4389 - Val accuracy: 0.7200 - Val loss: 0.9745 - Val F1: 0.6028 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.2681 - Val accuracy: 0.7200 - Val loss: 0.8595 - Val F1: 0.6028 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.1910 - Val accuracy: 0.7200 - Val loss: 0.8158 - Val F1: 0.6028 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.1425 - Val accuracy: 0.7200 - Val loss: 0.5291 - Val F1: 0.6028 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.1124 - Val accuracy: 0.8800 - Val loss: 0.2537 - Val F1: 0.8424 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0929 - Val accuracy: 0.9600 - Val loss: 0.1609 - Val F1: 0.9405 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0806 - Val accuracy: 0.9600 - Val loss: 0.1371 - Val F1: 0.9467 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0778 - Val accuracy: 0.9600 - Val loss: 0.1292 - Val F1: 0.9467 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0766 - Val accuracy: 0.9600 - Val loss: 0.1267 - Val F1: 0.9467 - LR: 0.00e+00\n","\tBest epoch: 100 - Best val accuracy: 0.9600 - Best val loss: 0.1267 - Best val F1: 0.9467\n","\n","\tEpoch 10/100 - Train loss: 0.8491 - Val accuracy: 0.7200 - Val loss: 1.3417 - Val F1: 0.6028 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.4947 - Val accuracy: 0.7200 - Val loss: 1.1339 - Val F1: 0.6028 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.3623 - Val accuracy: 0.7200 - Val loss: 0.9408 - Val F1: 0.6028 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.2877 - Val accuracy: 0.7200 - Val loss: 0.7628 - Val F1: 0.6028 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.2375 - Val accuracy: 0.8400 - Val loss: 0.4390 - Val F1: 0.7980 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.2125 - Val accuracy: 0.9200 - Val loss: 0.2794 - Val F1: 0.8821 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.1881 - Val accuracy: 0.9200 - Val loss: 0.2296 - Val F1: 0.8821 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.1713 - Val accuracy: 0.9200 - Val loss: 0.2084 - Val F1: 0.8821 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.1610 - Val accuracy: 0.9200 - Val loss: 0.1982 - Val F1: 0.8821 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.1627 - Val accuracy: 0.9200 - Val loss: 0.1946 - Val F1: 0.8821 - LR: 0.00e+00\n","\tBest epoch: 100 - Best val accuracy: 0.9200 - Best val loss: 0.1946 - Best val F1: 0.8821\n","\n","\tEpoch 10/100 - Train loss: 0.7321 - Val accuracy: 0.7200 - Val loss: 1.2436 - Val F1: 0.6028 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.4743 - Val accuracy: 0.7200 - Val loss: 1.0016 - Val F1: 0.6028 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.3453 - Val accuracy: 0.7200 - Val loss: 0.8676 - Val F1: 0.6028 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.2639 - Val accuracy: 0.7200 - Val loss: 0.6639 - Val F1: 0.6028 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.2082 - Val accuracy: 0.8800 - Val loss: 0.3620 - Val F1: 0.8424 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.1746 - Val accuracy: 0.9200 - Val loss: 0.2191 - Val F1: 0.8821 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.1458 - Val accuracy: 0.9200 - Val loss: 0.1690 - Val F1: 0.8821 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.1365 - Val accuracy: 0.9600 - Val loss: 0.1495 - Val F1: 0.9405 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.1256 - Val accuracy: 0.9600 - Val loss: 0.1407 - Val F1: 0.9405 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.1205 - Val accuracy: 0.9600 - Val loss: 0.1378 - Val F1: 0.9405 - LR: 0.00e+00\n","\tBest epoch: 100 - Best val accuracy: 0.9600 - Best val loss: 0.1378 - Best val F1: 0.9405\n","\n","\tEpoch 10/100 - Train loss: 0.7916 - Val accuracy: 0.7200 - Val loss: 1.2814 - Val F1: 0.6028 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.4872 - Val accuracy: 0.7200 - Val loss: 1.0648 - Val F1: 0.6028 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.3414 - Val accuracy: 0.7200 - Val loss: 0.9418 - Val F1: 0.6028 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.2752 - Val accuracy: 0.7200 - Val loss: 0.8568 - Val F1: 0.6028 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.2304 - Val accuracy: 0.8000 - Val loss: 0.5409 - Val F1: 0.7465 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.1906 - Val accuracy: 0.9200 - Val loss: 0.3122 - Val F1: 0.8821 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.1690 - Val accuracy: 0.9200 - Val loss: 0.2358 - Val F1: 0.8821 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.1562 - Val accuracy: 0.9200 - Val loss: 0.2084 - Val F1: 0.8821 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.1442 - Val accuracy: 0.9200 - Val loss: 0.1964 - Val F1: 0.8821 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.1345 - Val accuracy: 0.9200 - Val loss: 0.1921 - Val F1: 0.8821 - LR: 0.00e+00\n","\tBest epoch: 100 - Best val accuracy: 0.9200 - Best val loss: 0.1921 - Best val F1: 0.8821\n","\n","Source class: WAL | Domain: 57 | Accuracy: 0.9217 | Loss: 0.2074 | F1: 0.8848\n","\n","Domain: 58\n","x_dp_dom.shape: (149, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Training and evaluating on Dp data via cross-validation...\n","\tEpoch 10/100 - Train loss: 0.6112 - Val accuracy: 0.7500 - Val loss: 1.2433 - Val F1: 0.6429 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.2954 - Val accuracy: 0.7500 - Val loss: 0.9605 - Val F1: 0.6429 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.1892 - Val accuracy: 0.7500 - Val loss: 0.7152 - Val F1: 0.6429 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.1463 - Val accuracy: 0.9167 - Val loss: 0.4243 - Val F1: 0.8772 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.1141 - Val accuracy: 0.9167 - Val loss: 0.2546 - Val F1: 0.8772 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.0982 - Val accuracy: 0.9167 - Val loss: 0.1859 - Val F1: 0.8772 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0846 - Val accuracy: 0.9167 - Val loss: 0.1590 - Val F1: 0.8772 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0839 - Val accuracy: 0.9167 - Val loss: 0.1482 - Val F1: 0.8772 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0770 - Val accuracy: 0.9167 - Val loss: 0.1437 - Val F1: 0.8772 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0787 - Val accuracy: 0.9167 - Val loss: 0.1421 - Val F1: 0.8772 - LR: 0.00e+00\n","\tBest epoch: 100 - Best val accuracy: 0.9167 - Best val loss: 0.1421 - Best val F1: 0.8772\n","\n","\tEpoch 10/100 - Train loss: 0.4757 - Val accuracy: 0.7500 - Val loss: 1.1441 - Val F1: 0.6429 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.2493 - Val accuracy: 0.7500 - Val loss: 0.9162 - Val F1: 0.6429 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.1756 - Val accuracy: 0.7500 - Val loss: 0.7079 - Val F1: 0.6429 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.1262 - Val accuracy: 0.9167 - Val loss: 0.4423 - Val F1: 0.8772 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.1067 - Val accuracy: 0.9167 - Val loss: 0.2740 - Val F1: 0.8772 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.0845 - Val accuracy: 0.9167 - Val loss: 0.2145 - Val F1: 0.8772 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0810 - Val accuracy: 0.9167 - Val loss: 0.1965 - Val F1: 0.8772 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0662 - Val accuracy: 0.9167 - Val loss: 0.1909 - Val F1: 0.8772 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0645 - Val accuracy: 0.9167 - Val loss: 0.1886 - Val F1: 0.8772 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0666 - Val accuracy: 0.9167 - Val loss: 0.1875 - Val F1: 0.8772 - LR: 0.00e+00\n","\tBest epoch: 100 - Best val accuracy: 0.9167 - Best val loss: 0.1875 - Best val F1: 0.8772\n","\n","\tEpoch 10/100 - Train loss: 0.6117 - Val accuracy: 0.7500 - Val loss: 1.2428 - Val F1: 0.6429 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.3148 - Val accuracy: 0.7500 - Val loss: 0.9769 - Val F1: 0.6429 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.2187 - Val accuracy: 0.7500 - Val loss: 0.7997 - Val F1: 0.6429 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.1717 - Val accuracy: 0.7917 - Val loss: 0.5608 - Val F1: 0.7252 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.1421 - Val accuracy: 0.9167 - Val loss: 0.3241 - Val F1: 0.8772 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.1208 - Val accuracy: 0.9167 - Val loss: 0.2221 - Val F1: 0.8772 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.1163 - Val accuracy: 0.9167 - Val loss: 0.1909 - Val F1: 0.8772 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.1085 - Val accuracy: 0.9167 - Val loss: 0.1802 - Val F1: 0.8772 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.1044 - Val accuracy: 0.9167 - Val loss: 0.1763 - Val F1: 0.8772 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0996 - Val accuracy: 0.9167 - Val loss: 0.1749 - Val F1: 0.8772 - LR: 0.00e+00\n","\tBest epoch: 100 - Best val accuracy: 0.9167 - Best val loss: 0.1749 - Best val F1: 0.8772\n","\n","\tEpoch 10/100 - Train loss: 0.7947 - Val accuracy: 0.7500 - Val loss: 1.3031 - Val F1: 0.6429 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.3899 - Val accuracy: 0.7500 - Val loss: 1.0627 - Val F1: 0.6429 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.2360 - Val accuracy: 0.7500 - Val loss: 0.8694 - Val F1: 0.6429 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.1689 - Val accuracy: 0.7500 - Val loss: 0.7175 - Val F1: 0.6429 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.1282 - Val accuracy: 0.8333 - Val loss: 0.4461 - Val F1: 0.7861 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.1076 - Val accuracy: 0.9167 - Val loss: 0.3025 - Val F1: 0.8772 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0918 - Val accuracy: 0.9167 - Val loss: 0.2543 - Val F1: 0.8772 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0814 - Val accuracy: 0.9167 - Val loss: 0.2371 - Val F1: 0.8772 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0757 - Val accuracy: 0.9167 - Val loss: 0.2308 - Val F1: 0.8772 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0757 - Val accuracy: 0.9167 - Val loss: 0.2285 - Val F1: 0.8772 - LR: 0.00e+00\n","\tBest epoch: 100 - Best val accuracy: 0.9167 - Best val loss: 0.2285 - Best val F1: 0.8772\n","\n","\tEpoch 10/100 - Train loss: 0.6623 - Val accuracy: 0.7500 - Val loss: 1.2199 - Val F1: 0.6429 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.3321 - Val accuracy: 0.7500 - Val loss: 0.9518 - Val F1: 0.6429 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.2288 - Val accuracy: 0.7500 - Val loss: 0.7842 - Val F1: 0.6429 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.1622 - Val accuracy: 0.7500 - Val loss: 0.5752 - Val F1: 0.6429 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.1409 - Val accuracy: 0.9167 - Val loss: 0.3430 - Val F1: 0.8772 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.1121 - Val accuracy: 0.9167 - Val loss: 0.2437 - Val F1: 0.8772 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0974 - Val accuracy: 0.9167 - Val loss: 0.2083 - Val F1: 0.8772 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0908 - Val accuracy: 0.9167 - Val loss: 0.1957 - Val F1: 0.8772 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0887 - Val accuracy: 0.9167 - Val loss: 0.1913 - Val F1: 0.8772 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0861 - Val accuracy: 0.9167 - Val loss: 0.1901 - Val F1: 0.8772 - LR: 0.00e+00\n","\tBest epoch: 100 - Best val accuracy: 0.9167 - Best val loss: 0.1901 - Best val F1: 0.8772\n","\n","Source class: WAL | Domain: 58 | Accuracy: 0.9329 | Loss: 0.1532 | F1: 0.9008\n","\n","Domain: 59\n","x_dp_dom.shape: (154, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Training and evaluating on Dp data via cross-validation...\n","\tEpoch 10/100 - Train loss: 0.8288 - Val accuracy: 0.7200 - Val loss: 1.2810 - Val F1: 0.6028 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.4948 - Val accuracy: 0.7200 - Val loss: 1.0462 - Val F1: 0.6028 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.3706 - Val accuracy: 0.7200 - Val loss: 0.9590 - Val F1: 0.6028 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.3275 - Val accuracy: 0.7200 - Val loss: 0.9176 - Val F1: 0.6028 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.2697 - Val accuracy: 0.7600 - Val loss: 0.5758 - Val F1: 0.6838 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.2408 - Val accuracy: 0.8800 - Val loss: 0.3364 - Val F1: 0.8424 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.2190 - Val accuracy: 0.9200 - Val loss: 0.2658 - Val F1: 0.8821 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.2022 - Val accuracy: 0.9200 - Val loss: 0.2417 - Val F1: 0.8821 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.1968 - Val accuracy: 0.9200 - Val loss: 0.2313 - Val F1: 0.8821 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.1941 - Val accuracy: 0.9200 - Val loss: 0.2273 - Val F1: 0.8821 - LR: 0.00e+00\n","\tBest epoch: 100 - Best val accuracy: 0.9200 - Best val loss: 0.2273 - Best val F1: 0.8821\n","\n","\tEpoch 10/100 - Train loss: 0.7325 - Val accuracy: 0.7200 - Val loss: 1.2442 - Val F1: 0.6028 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.4536 - Val accuracy: 0.7200 - Val loss: 1.0445 - Val F1: 0.6028 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.3520 - Val accuracy: 0.7200 - Val loss: 0.9733 - Val F1: 0.6028 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.2921 - Val accuracy: 0.7200 - Val loss: 0.9314 - Val F1: 0.6028 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.2448 - Val accuracy: 0.7200 - Val loss: 0.6723 - Val F1: 0.6028 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.2191 - Val accuracy: 0.8400 - Val loss: 0.3961 - Val F1: 0.7980 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.1935 - Val accuracy: 0.9200 - Val loss: 0.2943 - Val F1: 0.8821 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.1729 - Val accuracy: 0.9200 - Val loss: 0.2617 - Val F1: 0.8821 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.1678 - Val accuracy: 0.9200 - Val loss: 0.2493 - Val F1: 0.8821 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.1627 - Val accuracy: 0.9200 - Val loss: 0.2450 - Val F1: 0.8821 - LR: 0.00e+00\n","\tBest epoch: 100 - Best val accuracy: 0.9200 - Best val loss: 0.2450 - Best val F1: 0.8821\n","\n","\tEpoch 10/100 - Train loss: 0.6806 - Val accuracy: 0.7200 - Val loss: 1.2012 - Val F1: 0.6028 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.3769 - Val accuracy: 0.7200 - Val loss: 0.9784 - Val F1: 0.6028 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.2637 - Val accuracy: 0.7200 - Val loss: 0.9368 - Val F1: 0.6028 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.1973 - Val accuracy: 0.7200 - Val loss: 0.7901 - Val F1: 0.6028 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.1438 - Val accuracy: 0.8400 - Val loss: 0.4094 - Val F1: 0.7980 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.1102 - Val accuracy: 0.9200 - Val loss: 0.2320 - Val F1: 0.8821 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0927 - Val accuracy: 0.9600 - Val loss: 0.1700 - Val F1: 0.9405 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0808 - Val accuracy: 0.9600 - Val loss: 0.1435 - Val F1: 0.9405 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0739 - Val accuracy: 0.9600 - Val loss: 0.1316 - Val F1: 0.9405 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0717 - Val accuracy: 0.9600 - Val loss: 0.1268 - Val F1: 0.9405 - LR: 0.00e+00\n","\tBest epoch: 100 - Best val accuracy: 0.9600 - Best val loss: 0.1268 - Best val F1: 0.9405\n","\n","\tEpoch 10/100 - Train loss: 0.6581 - Val accuracy: 0.7200 - Val loss: 1.1855 - Val F1: 0.6028 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.4419 - Val accuracy: 0.7200 - Val loss: 0.9809 - Val F1: 0.6028 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.3345 - Val accuracy: 0.7200 - Val loss: 0.9408 - Val F1: 0.6028 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.2775 - Val accuracy: 0.7200 - Val loss: 0.8750 - Val F1: 0.6028 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.2335 - Val accuracy: 0.7600 - Val loss: 0.5511 - Val F1: 0.6838 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.2051 - Val accuracy: 0.8800 - Val loss: 0.3171 - Val F1: 0.8424 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.1813 - Val accuracy: 0.9200 - Val loss: 0.2377 - Val F1: 0.8821 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.1594 - Val accuracy: 0.9200 - Val loss: 0.2094 - Val F1: 0.8821 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.1494 - Val accuracy: 0.9200 - Val loss: 0.1968 - Val F1: 0.8821 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.1484 - Val accuracy: 0.9200 - Val loss: 0.1921 - Val F1: 0.8821 - LR: 0.00e+00\n","\tBest epoch: 100 - Best val accuracy: 0.9200 - Best val loss: 0.1921 - Best val F1: 0.8821\n","\n","\tEpoch 10/100 - Train loss: 0.6570 - Val accuracy: 0.7200 - Val loss: 1.2381 - Val F1: 0.6028 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.4146 - Val accuracy: 0.7200 - Val loss: 1.0279 - Val F1: 0.6028 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.3078 - Val accuracy: 0.7200 - Val loss: 0.9505 - Val F1: 0.6028 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.2516 - Val accuracy: 0.7200 - Val loss: 0.8873 - Val F1: 0.6028 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.1956 - Val accuracy: 0.7600 - Val loss: 0.5666 - Val F1: 0.6838 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.1695 - Val accuracy: 0.9200 - Val loss: 0.3063 - Val F1: 0.8821 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.1437 - Val accuracy: 0.9200 - Val loss: 0.2313 - Val F1: 0.8821 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.1276 - Val accuracy: 0.9200 - Val loss: 0.2055 - Val F1: 0.8821 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.1152 - Val accuracy: 0.9200 - Val loss: 0.1946 - Val F1: 0.8821 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.1166 - Val accuracy: 0.9200 - Val loss: 0.1906 - Val F1: 0.8821 - LR: 0.00e+00\n","\tBest epoch: 100 - Best val accuracy: 0.9200 - Best val loss: 0.1906 - Best val F1: 0.8821\n","\n","Source class: WAL | Domain: 59 | Accuracy: 0.9157 | Loss: 0.2041 | F1: 0.8781\n","\n","Domain: 60\n","x_dp_dom.shape: (158, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Training and evaluating on Dp data via cross-validation...\n","\tEpoch 10/100 - Train loss: 0.7139 - Val accuracy: 0.6923 - Val loss: 1.2444 - Val F1: 0.5664 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.5243 - Val accuracy: 0.6923 - Val loss: 1.0296 - Val F1: 0.5664 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.4114 - Val accuracy: 0.6923 - Val loss: 0.9503 - Val F1: 0.5664 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.3478 - Val accuracy: 0.7692 - Val loss: 0.8263 - Val F1: 0.7033 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.2952 - Val accuracy: 0.7692 - Val loss: 0.6016 - Val F1: 0.7033 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.2684 - Val accuracy: 0.8846 - Val loss: 0.3926 - Val F1: 0.8314 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.2401 - Val accuracy: 0.8846 - Val loss: 0.3059 - Val F1: 0.8314 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.2209 - Val accuracy: 0.8846 - Val loss: 0.2773 - Val F1: 0.8314 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.2123 - Val accuracy: 0.8846 - Val loss: 0.2662 - Val F1: 0.8314 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.2101 - Val accuracy: 0.8846 - Val loss: 0.2622 - Val F1: 0.8314 - LR: 0.00e+00\n","\tBest epoch: 100 - Best val accuracy: 0.8846 - Best val loss: 0.2622 - Best val F1: 0.8314\n","\n","\tEpoch 10/100 - Train loss: 0.8191 - Val accuracy: 0.6923 - Val loss: 1.2438 - Val F1: 0.5664 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.5286 - Val accuracy: 0.6923 - Val loss: 1.0443 - Val F1: 0.5664 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.4228 - Val accuracy: 0.6923 - Val loss: 0.9296 - Val F1: 0.5664 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.3634 - Val accuracy: 0.7692 - Val loss: 0.8233 - Val F1: 0.7033 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.3119 - Val accuracy: 0.7692 - Val loss: 0.6403 - Val F1: 0.7033 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.2707 - Val accuracy: 0.8462 - Val loss: 0.4440 - Val F1: 0.7940 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.2602 - Val accuracy: 0.8846 - Val loss: 0.3790 - Val F1: 0.8314 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.2403 - Val accuracy: 0.8846 - Val loss: 0.3604 - Val F1: 0.8314 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.2216 - Val accuracy: 0.8846 - Val loss: 0.3526 - Val F1: 0.8314 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.2215 - Val accuracy: 0.8846 - Val loss: 0.3495 - Val F1: 0.8314 - LR: 0.00e+00\n","\tBest epoch: 100 - Best val accuracy: 0.8846 - Best val loss: 0.3495 - Best val F1: 0.8314\n","\n","\tEpoch 10/100 - Train loss: 0.7388 - Val accuracy: 0.6923 - Val loss: 1.2967 - Val F1: 0.5664 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.5060 - Val accuracy: 0.6923 - Val loss: 1.0864 - Val F1: 0.5664 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.4000 - Val accuracy: 0.6923 - Val loss: 0.9872 - Val F1: 0.5664 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.3314 - Val accuracy: 0.6923 - Val loss: 0.8959 - Val F1: 0.5664 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.2923 - Val accuracy: 0.7692 - Val loss: 0.6904 - Val F1: 0.7033 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.2557 - Val accuracy: 0.8462 - Val loss: 0.4515 - Val F1: 0.7940 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.2130 - Val accuracy: 0.8846 - Val loss: 0.3451 - Val F1: 0.8314 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.1974 - Val accuracy: 0.8846 - Val loss: 0.3090 - Val F1: 0.8314 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.1842 - Val accuracy: 0.8846 - Val loss: 0.2950 - Val F1: 0.8314 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.1824 - Val accuracy: 0.8846 - Val loss: 0.2899 - Val F1: 0.8314 - LR: 0.00e+00\n","\tBest epoch: 100 - Best val accuracy: 0.8846 - Best val loss: 0.2899 - Best val F1: 0.8314\n","\n","\tEpoch 10/100 - Train loss: 0.3922 - Val accuracy: 0.8846 - Val loss: 0.4209 - Val F1: 0.8314 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.1574 - Val accuracy: 0.8846 - Val loss: 0.2016 - Val F1: 0.8314 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.0642 - Val accuracy: 0.9615 - Val loss: 0.1197 - Val F1: 0.9462 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.0467 - Val accuracy: 1.0000 - Val loss: 0.0892 - Val F1: 1.0000 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.0249 - Val accuracy: 1.0000 - Val loss: 0.0714 - Val F1: 1.0000 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.0154 - Val accuracy: 1.0000 - Val loss: 0.0571 - Val F1: 1.0000 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0179 - Val accuracy: 1.0000 - Val loss: 0.0567 - Val F1: 1.0000 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0135 - Val accuracy: 1.0000 - Val loss: 0.0508 - Val F1: 1.0000 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0104 - Val accuracy: 1.0000 - Val loss: 0.0482 - Val F1: 1.0000 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0104 - Val accuracy: 1.0000 - Val loss: 0.0438 - Val F1: 1.0000 - LR: 0.00e+00\n","\tBest epoch: 100 - Best val accuracy: 1.0000 - Best val loss: 0.0438 - Best val F1: 1.0000\n","\n","\tEpoch 10/100 - Train loss: 0.2607 - Val accuracy: 0.8846 - Val loss: 0.3784 - Val F1: 0.8314 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.1090 - Val accuracy: 0.8846 - Val loss: 0.2361 - Val F1: 0.8314 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.0563 - Val accuracy: 0.9231 - Val loss: 0.2106 - Val F1: 0.8995 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.0347 - Val accuracy: 0.9231 - Val loss: 0.1979 - Val F1: 0.8995 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.0245 - Val accuracy: 0.9231 - Val loss: 0.2041 - Val F1: 0.8995 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.0141 - Val accuracy: 0.9615 - Val loss: 0.2021 - Val F1: 0.9556 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0171 - Val accuracy: 0.9615 - Val loss: 0.2059 - Val F1: 0.9556 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0119 - Val accuracy: 0.9615 - Val loss: 0.1995 - Val F1: 0.9556 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0091 - Val accuracy: 0.9615 - Val loss: 0.2118 - Val F1: 0.9556 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0172 - Val accuracy: 0.9231 - Val loss: 0.2240 - Val F1: 0.8995 - LR: 0.00e+00\n","\tBest epoch: 55 - Best val accuracy: 0.9231 - Best val loss: 0.1899 - Best val F1: 0.9044\n","\n","Source class: WAL | Domain: 60 | Accuracy: 0.8927 | Loss: 0.2650 | F1: 0.8522\n","\n","Domain: 61\n","x_dp_dom.shape: (158, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Training and evaluating on Dp data via cross-validation...\n","\tEpoch 10/100 - Train loss: 0.8692 - Val accuracy: 0.6923 - Val loss: 1.3020 - Val F1: 0.5664 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.6329 - Val accuracy: 0.6923 - Val loss: 1.1462 - Val F1: 0.5664 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.4726 - Val accuracy: 0.6923 - Val loss: 1.0275 - Val F1: 0.5664 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.3683 - Val accuracy: 0.6923 - Val loss: 0.9051 - Val F1: 0.5664 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.2865 - Val accuracy: 0.6923 - Val loss: 0.6648 - Val F1: 0.5664 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.2360 - Val accuracy: 0.8462 - Val loss: 0.4218 - Val F1: 0.7929 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.1936 - Val accuracy: 0.9231 - Val loss: 0.3131 - Val F1: 0.8997 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.1801 - Val accuracy: 0.9615 - Val loss: 0.2709 - Val F1: 0.9441 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.1617 - Val accuracy: 0.9615 - Val loss: 0.2534 - Val F1: 0.9441 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.1620 - Val accuracy: 0.9615 - Val loss: 0.2477 - Val F1: 0.9441 - LR: 0.00e+00\n","\tBest epoch: 100 - Best val accuracy: 0.9615 - Best val loss: 0.2477 - Best val F1: 0.9441\n","\n","\tEpoch 10/100 - Train loss: 0.7554 - Val accuracy: 0.6923 - Val loss: 1.2577 - Val F1: 0.5664 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.5375 - Val accuracy: 0.6923 - Val loss: 1.0909 - Val F1: 0.5664 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.3750 - Val accuracy: 0.6923 - Val loss: 0.9533 - Val F1: 0.5664 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.2852 - Val accuracy: 0.6923 - Val loss: 0.8149 - Val F1: 0.5664 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.2341 - Val accuracy: 0.6923 - Val loss: 0.6252 - Val F1: 0.5664 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.1947 - Val accuracy: 0.7692 - Val loss: 0.3883 - Val F1: 0.7033 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.1672 - Val accuracy: 0.9615 - Val loss: 0.2476 - Val F1: 0.9556 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.1573 - Val accuracy: 0.9615 - Val loss: 0.1921 - Val F1: 0.9556 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.1474 - Val accuracy: 1.0000 - Val loss: 0.1722 - Val F1: 1.0000 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.1374 - Val accuracy: 1.0000 - Val loss: 0.1656 - Val F1: 1.0000 - LR: 0.00e+00\n","\tBest epoch: 100 - Best val accuracy: 1.0000 - Best val loss: 0.1656 - Best val F1: 1.0000\n","\n","\tEpoch 10/100 - Train loss: 0.7892 - Val accuracy: 0.6923 - Val loss: 1.2776 - Val F1: 0.5664 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.5724 - Val accuracy: 0.6923 - Val loss: 1.1063 - Val F1: 0.5664 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.4312 - Val accuracy: 0.6923 - Val loss: 1.0129 - Val F1: 0.5664 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.3393 - Val accuracy: 0.6923 - Val loss: 0.9082 - Val F1: 0.5664 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.2653 - Val accuracy: 0.6923 - Val loss: 0.6930 - Val F1: 0.5664 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.2172 - Val accuracy: 0.8077 - Val loss: 0.3938 - Val F1: 0.7521 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.1872 - Val accuracy: 0.8846 - Val loss: 0.2469 - Val F1: 0.8307 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.1691 - Val accuracy: 0.9615 - Val loss: 0.2022 - Val F1: 0.9441 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.1564 - Val accuracy: 0.9615 - Val loss: 0.1871 - Val F1: 0.9441 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.1562 - Val accuracy: 0.9615 - Val loss: 0.1822 - Val F1: 0.9441 - LR: 0.00e+00\n","\tBest epoch: 100 - Best val accuracy: 0.9615 - Best val loss: 0.1822 - Best val F1: 0.9441\n","\n","\tEpoch 10/100 - Train loss: 0.3236 - Val accuracy: 0.8077 - Val loss: 0.3755 - Val F1: 0.7521 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.0961 - Val accuracy: 0.9615 - Val loss: 0.1734 - Val F1: 0.9599 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.0381 - Val accuracy: 0.9231 - Val loss: 0.1183 - Val F1: 0.9215 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.0335 - Val accuracy: 0.9615 - Val loss: 0.0941 - Val F1: 0.9615 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.0190 - Val accuracy: 0.9615 - Val loss: 0.0791 - Val F1: 0.9615 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.0105 - Val accuracy: 0.9615 - Val loss: 0.0728 - Val F1: 0.9615 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0098 - Val accuracy: 0.9615 - Val loss: 0.0717 - Val F1: 0.9615 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0110 - Val accuracy: 0.9615 - Val loss: 0.0722 - Val F1: 0.9615 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0098 - Val accuracy: 0.9615 - Val loss: 0.0677 - Val F1: 0.9615 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0073 - Val accuracy: 0.9615 - Val loss: 0.0669 - Val F1: 0.9615 - LR: 0.00e+00\n","\tBest epoch: 87 - Best val accuracy: 0.9615 - Best val loss: 0.0657 - Best val F1: 0.9615\n","\n","\tEpoch 10/100 - Train loss: 0.2383 - Val accuracy: 0.8846 - Val loss: 0.6807 - Val F1: 0.8307 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.0781 - Val accuracy: 0.9231 - Val loss: 0.7595 - Val F1: 0.9038 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.0813 - Val accuracy: 0.9231 - Val loss: 0.7173 - Val F1: 0.9038 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.0201 - Val accuracy: 0.9231 - Val loss: 0.8350 - Val F1: 0.9038 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.0141 - Val accuracy: 0.9231 - Val loss: 0.8426 - Val F1: 0.9038 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.0114 - Val accuracy: 0.9231 - Val loss: 0.8413 - Val F1: 0.9038 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0085 - Val accuracy: 0.9231 - Val loss: 0.8777 - Val F1: 0.9038 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0062 - Val accuracy: 0.9231 - Val loss: 0.8774 - Val F1: 0.9038 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0060 - Val accuracy: 0.9231 - Val loss: 0.8192 - Val F1: 0.9038 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0057 - Val accuracy: 0.9231 - Val loss: 0.8855 - Val F1: 0.9038 - LR: 0.00e+00\n","\tBest epoch: 10 - Best val accuracy: 0.8846 - Best val loss: 0.6807 - Best val F1: 0.8307\n","\n","Source class: WAL | Domain: 61 | Accuracy: 0.9313 | Loss: 0.2199 | F1: 0.9127\n","\n","Domain: 62\n","x_dp_dom.shape: (158, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Training and evaluating on Dp data via cross-validation...\n","\tEpoch 10/100 - Train loss: 0.7502 - Val accuracy: 0.6923 - Val loss: 1.3357 - Val F1: 0.5664 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.4836 - Val accuracy: 0.6923 - Val loss: 1.1462 - Val F1: 0.5664 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.3730 - Val accuracy: 0.6923 - Val loss: 1.0580 - Val F1: 0.5664 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.3200 - Val accuracy: 0.6923 - Val loss: 0.9981 - Val F1: 0.5664 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.2779 - Val accuracy: 0.6923 - Val loss: 0.7401 - Val F1: 0.5664 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.2426 - Val accuracy: 0.8846 - Val loss: 0.4280 - Val F1: 0.8314 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.2131 - Val accuracy: 0.8846 - Val loss: 0.3111 - Val F1: 0.8314 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.2039 - Val accuracy: 0.8846 - Val loss: 0.2689 - Val F1: 0.8314 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.1972 - Val accuracy: 0.9231 - Val loss: 0.2524 - Val F1: 0.8995 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.1878 - Val accuracy: 0.9231 - Val loss: 0.2465 - Val F1: 0.8995 - LR: 0.00e+00\n","\tBest epoch: 100 - Best val accuracy: 0.9231 - Best val loss: 0.2465 - Best val F1: 0.8995\n","\n","\tEpoch 10/100 - Train loss: 0.7170 - Val accuracy: 0.6923 - Val loss: 1.2622 - Val F1: 0.5664 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.4654 - Val accuracy: 0.6923 - Val loss: 1.0793 - Val F1: 0.5664 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.3605 - Val accuracy: 0.6923 - Val loss: 1.0078 - Val F1: 0.5664 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.2845 - Val accuracy: 0.6923 - Val loss: 0.8966 - Val F1: 0.5664 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.2380 - Val accuracy: 0.8462 - Val loss: 0.5624 - Val F1: 0.7940 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.2150 - Val accuracy: 0.8846 - Val loss: 0.3626 - Val F1: 0.8314 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.1887 - Val accuracy: 0.8846 - Val loss: 0.2978 - Val F1: 0.8314 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.1717 - Val accuracy: 0.8846 - Val loss: 0.2712 - Val F1: 0.8314 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.1522 - Val accuracy: 0.8846 - Val loss: 0.2580 - Val F1: 0.8314 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.1424 - Val accuracy: 0.8846 - Val loss: 0.2530 - Val F1: 0.8314 - LR: 0.00e+00\n","\tBest epoch: 100 - Best val accuracy: 0.8846 - Best val loss: 0.2530 - Best val F1: 0.8314\n","\n","\tEpoch 10/100 - Train loss: 0.6926 - Val accuracy: 0.6923 - Val loss: 1.2540 - Val F1: 0.5664 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.4689 - Val accuracy: 0.6923 - Val loss: 1.0751 - Val F1: 0.5664 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.3873 - Val accuracy: 0.6923 - Val loss: 0.9960 - Val F1: 0.5664 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.3201 - Val accuracy: 0.6923 - Val loss: 0.9463 - Val F1: 0.5664 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.2675 - Val accuracy: 0.7308 - Val loss: 0.6716 - Val F1: 0.6437 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.2302 - Val accuracy: 0.8846 - Val loss: 0.3967 - Val F1: 0.8314 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.2018 - Val accuracy: 0.8846 - Val loss: 0.3041 - Val F1: 0.8314 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.1737 - Val accuracy: 0.8846 - Val loss: 0.2667 - Val F1: 0.8314 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.1593 - Val accuracy: 0.9231 - Val loss: 0.2494 - Val F1: 0.8995 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.1565 - Val accuracy: 0.9231 - Val loss: 0.2425 - Val F1: 0.8995 - LR: 0.00e+00\n","\tBest epoch: 100 - Best val accuracy: 0.9231 - Best val loss: 0.2425 - Best val F1: 0.8995\n","\n","\tEpoch 10/100 - Train loss: 0.2630 - Val accuracy: 0.8846 - Val loss: 0.3595 - Val F1: 0.8314 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.1143 - Val accuracy: 0.8846 - Val loss: 0.2550 - Val F1: 0.8314 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.0348 - Val accuracy: 0.9231 - Val loss: 0.1925 - Val F1: 0.8995 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.0225 - Val accuracy: 0.9615 - Val loss: 0.1629 - Val F1: 0.9428 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.0149 - Val accuracy: 0.9615 - Val loss: 0.1467 - Val F1: 0.9428 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.0100 - Val accuracy: 0.9615 - Val loss: 0.1427 - Val F1: 0.9428 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0092 - Val accuracy: 0.9615 - Val loss: 0.1272 - Val F1: 0.9428 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0082 - Val accuracy: 0.9615 - Val loss: 0.1334 - Val F1: 0.9428 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0068 - Val accuracy: 0.9615 - Val loss: 0.1388 - Val F1: 0.9428 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0056 - Val accuracy: 0.9615 - Val loss: 0.1331 - Val F1: 0.9428 - LR: 0.00e+00\n","\tBest epoch: 70 - Best val accuracy: 0.9615 - Best val loss: 0.1272 - Best val F1: 0.9428\n","\n","\tEpoch 10/100 - Train loss: 0.2865 - Val accuracy: 0.8846 - Val loss: 0.3594 - Val F1: 0.8314 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.1065 - Val accuracy: 0.8846 - Val loss: 0.2103 - Val F1: 0.8314 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.0435 - Val accuracy: 0.9231 - Val loss: 0.1369 - Val F1: 0.8995 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.0231 - Val accuracy: 0.9615 - Val loss: 0.0886 - Val F1: 0.9556 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.0130 - Val accuracy: 1.0000 - Val loss: 0.0671 - Val F1: 1.0000 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.0117 - Val accuracy: 1.0000 - Val loss: 0.0597 - Val F1: 1.0000 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0083 - Val accuracy: 1.0000 - Val loss: 0.0586 - Val F1: 1.0000 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0078 - Val accuracy: 1.0000 - Val loss: 0.0528 - Val F1: 1.0000 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0054 - Val accuracy: 1.0000 - Val loss: 0.0523 - Val F1: 1.0000 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0072 - Val accuracy: 1.0000 - Val loss: 0.0567 - Val F1: 1.0000 - LR: 0.00e+00\n","\tBest epoch: 93 - Best val accuracy: 1.0000 - Best val loss: 0.0485 - Best val F1: 1.0000\n","\n","Source class: WAL | Domain: 62 | Accuracy: 0.9121 | Loss: 0.1961 | F1: 0.8758\n","\n","Domain: 63\n","x_dp_dom.shape: (153, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Training and evaluating on Dp data via cross-validation...\n","\tEpoch 10/100 - Train loss: 0.7586 - Val accuracy: 0.7200 - Val loss: 1.2216 - Val F1: 0.6028 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.5173 - Val accuracy: 0.7200 - Val loss: 0.9965 - Val F1: 0.6028 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.3633 - Val accuracy: 0.7200 - Val loss: 0.8931 - Val F1: 0.6028 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.2873 - Val accuracy: 0.7200 - Val loss: 0.8446 - Val F1: 0.6028 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.2258 - Val accuracy: 0.7600 - Val loss: 0.5478 - Val F1: 0.6838 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.1928 - Val accuracy: 0.9200 - Val loss: 0.3379 - Val F1: 0.8821 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.1700 - Val accuracy: 0.9200 - Val loss: 0.2790 - Val F1: 0.8821 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.1470 - Val accuracy: 0.9200 - Val loss: 0.2609 - Val F1: 0.8821 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.1356 - Val accuracy: 0.9200 - Val loss: 0.2544 - Val F1: 0.8821 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.1434 - Val accuracy: 0.9200 - Val loss: 0.2522 - Val F1: 0.8821 - LR: 0.00e+00\n","\tBest epoch: 100 - Best val accuracy: 0.9200 - Best val loss: 0.2522 - Best val F1: 0.8821\n","\n","\tEpoch 10/100 - Train loss: 0.8988 - Val accuracy: 0.7200 - Val loss: 1.3329 - Val F1: 0.6028 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.5720 - Val accuracy: 0.7200 - Val loss: 1.0835 - Val F1: 0.6028 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.4270 - Val accuracy: 0.7200 - Val loss: 0.9073 - Val F1: 0.6028 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.3370 - Val accuracy: 0.7200 - Val loss: 0.7838 - Val F1: 0.6028 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.2757 - Val accuracy: 0.7600 - Val loss: 0.4897 - Val F1: 0.6838 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.2311 - Val accuracy: 0.9200 - Val loss: 0.2927 - Val F1: 0.8821 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.2030 - Val accuracy: 0.9200 - Val loss: 0.2213 - Val F1: 0.8821 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.1913 - Val accuracy: 0.9200 - Val loss: 0.1944 - Val F1: 0.8821 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.1844 - Val accuracy: 0.9200 - Val loss: 0.1826 - Val F1: 0.8821 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.1753 - Val accuracy: 0.9200 - Val loss: 0.1786 - Val F1: 0.8821 - LR: 0.00e+00\n","\tBest epoch: 100 - Best val accuracy: 0.9200 - Best val loss: 0.1786 - Best val F1: 0.8821\n","\n","\tEpoch 10/100 - Train loss: 0.8372 - Val accuracy: 0.7200 - Val loss: 1.2586 - Val F1: 0.6028 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.5375 - Val accuracy: 0.7200 - Val loss: 1.0496 - Val F1: 0.6028 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.3748 - Val accuracy: 0.7200 - Val loss: 0.8934 - Val F1: 0.6028 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.2949 - Val accuracy: 0.7200 - Val loss: 0.8384 - Val F1: 0.6028 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.2336 - Val accuracy: 0.7200 - Val loss: 0.6681 - Val F1: 0.6028 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.2024 - Val accuracy: 0.9200 - Val loss: 0.3572 - Val F1: 0.8821 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.1745 - Val accuracy: 0.9200 - Val loss: 0.2151 - Val F1: 0.8821 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.1640 - Val accuracy: 0.9200 - Val loss: 0.1741 - Val F1: 0.8821 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.1496 - Val accuracy: 0.9200 - Val loss: 0.1608 - Val F1: 0.8821 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.1402 - Val accuracy: 0.9200 - Val loss: 0.1568 - Val F1: 0.8824 - LR: 0.00e+00\n","\tBest epoch: 100 - Best val accuracy: 0.9200 - Best val loss: 0.1568 - Best val F1: 0.8824\n","\n","\tEpoch 10/100 - Train loss: 0.7891 - Val accuracy: 0.7200 - Val loss: 1.2890 - Val F1: 0.6028 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.4862 - Val accuracy: 0.7200 - Val loss: 1.0350 - Val F1: 0.6028 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.3737 - Val accuracy: 0.7200 - Val loss: 0.9190 - Val F1: 0.6028 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.3007 - Val accuracy: 0.7200 - Val loss: 0.7737 - Val F1: 0.6028 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.2671 - Val accuracy: 0.9200 - Val loss: 0.3994 - Val F1: 0.8821 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.2152 - Val accuracy: 0.9200 - Val loss: 0.2331 - Val F1: 0.8821 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.1930 - Val accuracy: 0.9200 - Val loss: 0.1834 - Val F1: 0.8821 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.1804 - Val accuracy: 0.9200 - Val loss: 0.1645 - Val F1: 0.8821 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.1701 - Val accuracy: 0.9200 - Val loss: 0.1566 - Val F1: 0.8821 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.1596 - Val accuracy: 0.9600 - Val loss: 0.1545 - Val F1: 0.9418 - LR: 0.00e+00\n","\tBest epoch: 99 - Best val accuracy: 0.9600 - Best val loss: 0.1545 - Best val F1: 0.9405\n","\n","\tEpoch 10/100 - Train loss: 0.6686 - Val accuracy: 0.7200 - Val loss: 1.2041 - Val F1: 0.6028 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.4461 - Val accuracy: 0.7200 - Val loss: 0.9780 - Val F1: 0.6028 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.3200 - Val accuracy: 0.7200 - Val loss: 0.8276 - Val F1: 0.6028 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.2470 - Val accuracy: 0.7200 - Val loss: 0.6593 - Val F1: 0.6028 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.1876 - Val accuracy: 0.8800 - Val loss: 0.4039 - Val F1: 0.8424 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.1536 - Val accuracy: 0.9200 - Val loss: 0.2643 - Val F1: 0.8821 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.1349 - Val accuracy: 0.9200 - Val loss: 0.2212 - Val F1: 0.8821 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.1283 - Val accuracy: 0.9200 - Val loss: 0.2087 - Val F1: 0.8824 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.1112 - Val accuracy: 0.9200 - Val loss: 0.2040 - Val F1: 0.8824 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.1096 - Val accuracy: 0.9200 - Val loss: 0.2025 - Val F1: 0.8824 - LR: 0.00e+00\n","\tBest epoch: 100 - Best val accuracy: 0.9200 - Best val loss: 0.2025 - Best val F1: 0.8824\n","\n","Source class: WAL | Domain: 63 | Accuracy: 0.9022 | Loss: 0.2764 | F1: 0.8599\n","\n","Domain: 64\n","x_dp_dom.shape: (154, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Training and evaluating on Dp data via cross-validation...\n","\tEpoch 10/100 - Train loss: 0.7544 - Val accuracy: 0.7200 - Val loss: 1.2445 - Val F1: 0.6028 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.4717 - Val accuracy: 0.7200 - Val loss: 0.9709 - Val F1: 0.6028 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.3396 - Val accuracy: 0.7200 - Val loss: 0.8498 - Val F1: 0.6028 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.2695 - Val accuracy: 0.7200 - Val loss: 0.7529 - Val F1: 0.6028 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.2260 - Val accuracy: 0.8400 - Val loss: 0.4540 - Val F1: 0.7980 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.1933 - Val accuracy: 0.9200 - Val loss: 0.2624 - Val F1: 0.8821 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.1690 - Val accuracy: 0.9200 - Val loss: 0.1937 - Val F1: 0.8821 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.1537 - Val accuracy: 0.9200 - Val loss: 0.1680 - Val F1: 0.8821 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.1541 - Val accuracy: 0.9200 - Val loss: 0.1576 - Val F1: 0.8821 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.1511 - Val accuracy: 0.9200 - Val loss: 0.1540 - Val F1: 0.8821 - LR: 0.00e+00\n","\tBest epoch: 100 - Best val accuracy: 0.9200 - Best val loss: 0.1540 - Best val F1: 0.8821\n","\n","\tEpoch 10/100 - Train loss: 0.7026 - Val accuracy: 0.7200 - Val loss: 1.2579 - Val F1: 0.6028 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.4266 - Val accuracy: 0.7200 - Val loss: 1.0466 - Val F1: 0.6028 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.3066 - Val accuracy: 0.7200 - Val loss: 0.8994 - Val F1: 0.6028 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.2435 - Val accuracy: 0.7200 - Val loss: 0.7416 - Val F1: 0.6028 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.1887 - Val accuracy: 0.8400 - Val loss: 0.4224 - Val F1: 0.7980 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.1565 - Val accuracy: 0.9200 - Val loss: 0.2476 - Val F1: 0.8821 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.1360 - Val accuracy: 0.9200 - Val loss: 0.1852 - Val F1: 0.8821 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.1209 - Val accuracy: 0.9200 - Val loss: 0.1596 - Val F1: 0.8821 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.1113 - Val accuracy: 0.9200 - Val loss: 0.1484 - Val F1: 0.8821 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.1104 - Val accuracy: 0.9200 - Val loss: 0.1443 - Val F1: 0.8821 - LR: 0.00e+00\n","\tBest epoch: 100 - Best val accuracy: 0.9200 - Best val loss: 0.1443 - Best val F1: 0.8821\n","\n","\tEpoch 10/100 - Train loss: 0.6715 - Val accuracy: 0.7200 - Val loss: 1.2313 - Val F1: 0.6028 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.3935 - Val accuracy: 0.7200 - Val loss: 1.0301 - Val F1: 0.6028 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.2766 - Val accuracy: 0.7200 - Val loss: 0.9070 - Val F1: 0.6028 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.2143 - Val accuracy: 0.7200 - Val loss: 0.6880 - Val F1: 0.6028 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.1608 - Val accuracy: 0.9200 - Val loss: 0.3441 - Val F1: 0.8821 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.1351 - Val accuracy: 0.9200 - Val loss: 0.2048 - Val F1: 0.8821 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.1127 - Val accuracy: 0.9200 - Val loss: 0.1531 - Val F1: 0.8821 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.1007 - Val accuracy: 0.9200 - Val loss: 0.1317 - Val F1: 0.8821 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0942 - Val accuracy: 0.9600 - Val loss: 0.1220 - Val F1: 0.9405 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0878 - Val accuracy: 0.9600 - Val loss: 0.1186 - Val F1: 0.9405 - LR: 0.00e+00\n","\tBest epoch: 100 - Best val accuracy: 0.9600 - Best val loss: 0.1186 - Best val F1: 0.9405\n","\n","\tEpoch 10/100 - Train loss: 0.7814 - Val accuracy: 0.7200 - Val loss: 1.3288 - Val F1: 0.6028 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.4484 - Val accuracy: 0.7200 - Val loss: 1.1149 - Val F1: 0.6028 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.3407 - Val accuracy: 0.7200 - Val loss: 0.9526 - Val F1: 0.6028 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.2749 - Val accuracy: 0.7200 - Val loss: 0.8085 - Val F1: 0.6028 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.2269 - Val accuracy: 0.8000 - Val loss: 0.4401 - Val F1: 0.7465 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.1961 - Val accuracy: 0.9200 - Val loss: 0.2561 - Val F1: 0.8821 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.1742 - Val accuracy: 0.9200 - Val loss: 0.1998 - Val F1: 0.8821 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.1601 - Val accuracy: 0.9200 - Val loss: 0.1762 - Val F1: 0.8821 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.1536 - Val accuracy: 0.9200 - Val loss: 0.1657 - Val F1: 0.8821 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.1495 - Val accuracy: 0.9200 - Val loss: 0.1622 - Val F1: 0.8821 - LR: 0.00e+00\n","\tBest epoch: 100 - Best val accuracy: 0.9200 - Best val loss: 0.1622 - Best val F1: 0.8821\n","\n","\tEpoch 10/100 - Train loss: 0.6248 - Val accuracy: 0.7200 - Val loss: 1.2033 - Val F1: 0.6028 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.4032 - Val accuracy: 0.7200 - Val loss: 0.9935 - Val F1: 0.6028 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.2787 - Val accuracy: 0.7200 - Val loss: 0.9264 - Val F1: 0.6028 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.2154 - Val accuracy: 0.7200 - Val loss: 0.8561 - Val F1: 0.6028 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.1727 - Val accuracy: 0.7200 - Val loss: 0.4523 - Val F1: 0.6028 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.1455 - Val accuracy: 0.9200 - Val loss: 0.2161 - Val F1: 0.8821 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.1232 - Val accuracy: 0.9200 - Val loss: 0.1531 - Val F1: 0.8821 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.1099 - Val accuracy: 0.9600 - Val loss: 0.1292 - Val F1: 0.9405 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.1031 - Val accuracy: 0.9600 - Val loss: 0.1193 - Val F1: 0.9405 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0988 - Val accuracy: 0.9600 - Val loss: 0.1156 - Val F1: 0.9405 - LR: 0.00e+00\n","\tBest epoch: 100 - Best val accuracy: 0.9600 - Best val loss: 0.1156 - Best val F1: 0.9405\n","\n","Source class: WAL | Domain: 64 | Accuracy: 0.9353 | Loss: 0.1683 | F1: 0.9088\n","\n","Domain: 65\n","x_dp_dom.shape: (161, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Training and evaluating on Dp data via cross-validation...\n","\tEpoch 10/100 - Train loss: 0.2973 - Val accuracy: 0.8846 - Val loss: 0.3021 - Val F1: 0.8314 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.1065 - Val accuracy: 1.0000 - Val loss: 0.1368 - Val F1: 1.0000 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.0463 - Val accuracy: 1.0000 - Val loss: 0.0664 - Val F1: 1.0000 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.0271 - Val accuracy: 1.0000 - Val loss: 0.0352 - Val F1: 1.0000 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.0158 - Val accuracy: 1.0000 - Val loss: 0.0343 - Val F1: 1.0000 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.0114 - Val accuracy: 1.0000 - Val loss: 0.0168 - Val F1: 1.0000 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0092 - Val accuracy: 1.0000 - Val loss: 0.0152 - Val F1: 1.0000 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0059 - Val accuracy: 1.0000 - Val loss: 0.0134 - Val F1: 1.0000 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0075 - Val accuracy: 1.0000 - Val loss: 0.0124 - Val F1: 1.0000 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0046 - Val accuracy: 1.0000 - Val loss: 0.0105 - Val F1: 1.0000 - LR: 0.00e+00\n","\tBest epoch: 97 - Best val accuracy: 1.0000 - Best val loss: 0.0096 - Best val F1: 1.0000\n","\n","\tEpoch 10/100 - Train loss: 0.3308 - Val accuracy: 0.8846 - Val loss: 0.2962 - Val F1: 0.8314 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.1126 - Val accuracy: 1.0000 - Val loss: 0.1194 - Val F1: 1.0000 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.0421 - Val accuracy: 1.0000 - Val loss: 0.0607 - Val F1: 1.0000 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.0225 - Val accuracy: 1.0000 - Val loss: 0.0349 - Val F1: 1.0000 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.0117 - Val accuracy: 1.0000 - Val loss: 0.0219 - Val F1: 1.0000 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.0114 - Val accuracy: 1.0000 - Val loss: 0.0166 - Val F1: 1.0000 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0118 - Val accuracy: 1.0000 - Val loss: 0.0156 - Val F1: 1.0000 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0061 - Val accuracy: 1.0000 - Val loss: 0.0139 - Val F1: 1.0000 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0080 - Val accuracy: 1.0000 - Val loss: 0.0114 - Val F1: 1.0000 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0057 - Val accuracy: 1.0000 - Val loss: 0.0119 - Val F1: 1.0000 - LR: 0.00e+00\n","\tBest epoch: 98 - Best val accuracy: 1.0000 - Best val loss: 0.0106 - Best val F1: 1.0000\n","\n","\tEpoch 10/100 - Train loss: 0.3174 - Val accuracy: 0.8846 - Val loss: 0.3054 - Val F1: 0.8314 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.1090 - Val accuracy: 0.9615 - Val loss: 0.1196 - Val F1: 0.9556 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.0386 - Val accuracy: 1.0000 - Val loss: 0.0602 - Val F1: 1.0000 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.0401 - Val accuracy: 1.0000 - Val loss: 0.0399 - Val F1: 1.0000 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.0131 - Val accuracy: 1.0000 - Val loss: 0.0229 - Val F1: 1.0000 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.0123 - Val accuracy: 1.0000 - Val loss: 0.0204 - Val F1: 1.0000 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0107 - Val accuracy: 1.0000 - Val loss: 0.0169 - Val F1: 1.0000 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0077 - Val accuracy: 1.0000 - Val loss: 0.0138 - Val F1: 1.0000 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0057 - Val accuracy: 1.0000 - Val loss: 0.0136 - Val F1: 1.0000 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0068 - Val accuracy: 1.0000 - Val loss: 0.0116 - Val F1: 1.0000 - LR: 0.00e+00\n","\tBest epoch: 100 - Best val accuracy: 1.0000 - Best val loss: 0.0116 - Best val F1: 1.0000\n","\n","\tEpoch 10/100 - Train loss: 0.2243 - Val accuracy: 0.8462 - Val loss: 0.3213 - Val F1: 0.7758 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.0889 - Val accuracy: 0.9231 - Val loss: 0.1487 - Val F1: 0.8873 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.0226 - Val accuracy: 1.0000 - Val loss: 0.0762 - Val F1: 1.0000 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.0140 - Val accuracy: 1.0000 - Val loss: 0.0512 - Val F1: 1.0000 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.0091 - Val accuracy: 1.0000 - Val loss: 0.0405 - Val F1: 1.0000 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.0100 - Val accuracy: 1.0000 - Val loss: 0.0311 - Val F1: 1.0000 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0081 - Val accuracy: 1.0000 - Val loss: 0.0272 - Val F1: 1.0000 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0222 - Val accuracy: 1.0000 - Val loss: 0.0278 - Val F1: 1.0000 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0110 - Val accuracy: 1.0000 - Val loss: 0.0221 - Val F1: 1.0000 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0050 - Val accuracy: 1.0000 - Val loss: 0.0216 - Val F1: 1.0000 - LR: 0.00e+00\n","\tBest epoch: 98 - Best val accuracy: 1.0000 - Best val loss: 0.0207 - Best val F1: 1.0000\n","\n","\tEpoch 10/100 - Train loss: 0.3282 - Val accuracy: 0.8846 - Val loss: 0.3528 - Val F1: 0.8314 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.1568 - Val accuracy: 0.8846 - Val loss: 0.2142 - Val F1: 0.8314 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.0884 - Val accuracy: 0.9615 - Val loss: 0.1497 - Val F1: 0.9556 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.0347 - Val accuracy: 0.9615 - Val loss: 0.1238 - Val F1: 0.9556 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.0212 - Val accuracy: 0.9615 - Val loss: 0.0872 - Val F1: 0.9556 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.0193 - Val accuracy: 1.0000 - Val loss: 0.0587 - Val F1: 1.0000 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0092 - Val accuracy: 0.9615 - Val loss: 0.0585 - Val F1: 0.9556 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0088 - Val accuracy: 0.9615 - Val loss: 0.0539 - Val F1: 0.9556 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0144 - Val accuracy: 0.9615 - Val loss: 0.0537 - Val F1: 0.9556 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0070 - Val accuracy: 1.0000 - Val loss: 0.0459 - Val F1: 1.0000 - LR: 0.00e+00\n","\tBest epoch: 100 - Best val accuracy: 1.0000 - Best val loss: 0.0459 - Best val F1: 1.0000\n","\n","Source class: WAL | Domain: 65 | Accuracy: 1.0000 | Loss: 0.0226 | F1: 1.0000\n","\n","Domain: 66\n","x_dp_dom.shape: (153, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Training and evaluating on Dp data via cross-validation...\n","\tEpoch 10/100 - Train loss: 0.6355 - Val accuracy: 0.7200 - Val loss: 1.2316 - Val F1: 0.6028 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.3328 - Val accuracy: 0.7200 - Val loss: 0.9236 - Val F1: 0.6028 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.2304 - Val accuracy: 0.7200 - Val loss: 0.7120 - Val F1: 0.6028 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.1921 - Val accuracy: 0.8400 - Val loss: 0.4475 - Val F1: 0.7980 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.1628 - Val accuracy: 0.9600 - Val loss: 0.2166 - Val F1: 0.9405 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.1479 - Val accuracy: 1.0000 - Val loss: 0.1338 - Val F1: 1.0000 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.1287 - Val accuracy: 1.0000 - Val loss: 0.1080 - Val F1: 1.0000 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.1177 - Val accuracy: 1.0000 - Val loss: 0.0979 - Val F1: 1.0000 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.1126 - Val accuracy: 1.0000 - Val loss: 0.0935 - Val F1: 1.0000 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.1132 - Val accuracy: 1.0000 - Val loss: 0.0919 - Val F1: 1.0000 - LR: 0.00e+00\n","\tBest epoch: 100 - Best val accuracy: 1.0000 - Best val loss: 0.0919 - Best val F1: 1.0000\n","\n","\tEpoch 10/100 - Train loss: 0.6531 - Val accuracy: 0.7200 - Val loss: 1.2332 - Val F1: 0.6028 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.3250 - Val accuracy: 0.7200 - Val loss: 0.9942 - Val F1: 0.6028 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.2313 - Val accuracy: 0.7200 - Val loss: 0.7661 - Val F1: 0.6028 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.1852 - Val accuracy: 0.8400 - Val loss: 0.4772 - Val F1: 0.7980 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.1659 - Val accuracy: 0.9600 - Val loss: 0.2603 - Val F1: 0.9467 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.1378 - Val accuracy: 0.9600 - Val loss: 0.1709 - Val F1: 0.9467 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.1347 - Val accuracy: 0.9600 - Val loss: 0.1410 - Val F1: 0.9467 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.1266 - Val accuracy: 0.9600 - Val loss: 0.1306 - Val F1: 0.9467 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.1206 - Val accuracy: 0.9600 - Val loss: 0.1262 - Val F1: 0.9467 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.1175 - Val accuracy: 0.9600 - Val loss: 0.1247 - Val F1: 0.9467 - LR: 0.00e+00\n","\tBest epoch: 100 - Best val accuracy: 0.9600 - Best val loss: 0.1247 - Best val F1: 0.9467\n","\n","\tEpoch 10/100 - Train loss: 0.6723 - Val accuracy: 0.7200 - Val loss: 1.2544 - Val F1: 0.6028 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.3382 - Val accuracy: 0.7200 - Val loss: 1.0042 - Val F1: 0.6028 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.2101 - Val accuracy: 0.7200 - Val loss: 0.7710 - Val F1: 0.6028 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.1602 - Val accuracy: 0.7200 - Val loss: 0.5420 - Val F1: 0.6322 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.1352 - Val accuracy: 0.9600 - Val loss: 0.3184 - Val F1: 0.9467 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.1140 - Val accuracy: 0.9600 - Val loss: 0.1791 - Val F1: 0.9467 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.1068 - Val accuracy: 0.9600 - Val loss: 0.1320 - Val F1: 0.9467 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.1015 - Val accuracy: 0.9600 - Val loss: 0.1160 - Val F1: 0.9467 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0950 - Val accuracy: 0.9600 - Val loss: 0.1098 - Val F1: 0.9467 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0979 - Val accuracy: 0.9600 - Val loss: 0.1075 - Val F1: 0.9467 - LR: 0.00e+00\n","\tBest epoch: 100 - Best val accuracy: 0.9600 - Best val loss: 0.1075 - Best val F1: 0.9467\n","\n","\tEpoch 10/100 - Train loss: 0.7268 - Val accuracy: 0.7200 - Val loss: 1.2833 - Val F1: 0.6028 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.3825 - Val accuracy: 0.7200 - Val loss: 1.0533 - Val F1: 0.6028 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.2698 - Val accuracy: 0.7200 - Val loss: 0.7513 - Val F1: 0.6028 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.2217 - Val accuracy: 0.8400 - Val loss: 0.4627 - Val F1: 0.7980 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.1787 - Val accuracy: 0.9600 - Val loss: 0.2856 - Val F1: 0.9418 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.1578 - Val accuracy: 1.0000 - Val loss: 0.1940 - Val F1: 1.0000 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.1412 - Val accuracy: 1.0000 - Val loss: 0.1528 - Val F1: 1.0000 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.1257 - Val accuracy: 1.0000 - Val loss: 0.1348 - Val F1: 1.0000 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.1130 - Val accuracy: 1.0000 - Val loss: 0.1263 - Val F1: 1.0000 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.1218 - Val accuracy: 1.0000 - Val loss: 0.1230 - Val F1: 1.0000 - LR: 0.00e+00\n","\tBest epoch: 100 - Best val accuracy: 1.0000 - Best val loss: 0.1230 - Best val F1: 1.0000\n","\n","\tEpoch 10/100 - Train loss: 0.5194 - Val accuracy: 0.7200 - Val loss: 1.1947 - Val F1: 0.6028 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.2944 - Val accuracy: 0.7200 - Val loss: 0.9642 - Val F1: 0.6028 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.2319 - Val accuracy: 0.7200 - Val loss: 0.7353 - Val F1: 0.6028 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.1993 - Val accuracy: 0.9200 - Val loss: 0.4663 - Val F1: 0.8821 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.1618 - Val accuracy: 0.9600 - Val loss: 0.2533 - Val F1: 0.9405 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.1450 - Val accuracy: 0.9600 - Val loss: 0.1591 - Val F1: 0.9467 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.1245 - Val accuracy: 0.9600 - Val loss: 0.1287 - Val F1: 0.9467 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.1191 - Val accuracy: 0.9600 - Val loss: 0.1172 - Val F1: 0.9467 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.1162 - Val accuracy: 0.9600 - Val loss: 0.1122 - Val F1: 0.9467 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.1109 - Val accuracy: 0.9600 - Val loss: 0.1105 - Val F1: 0.9467 - LR: 0.00e+00\n","\tBest epoch: 100 - Best val accuracy: 0.9600 - Best val loss: 0.1105 - Best val F1: 0.9467\n","\n","Source class: WAL | Domain: 66 | Accuracy: 0.9609 | Loss: 0.1821 | F1: 0.9484\n","\n","Domain: 67\n","x_dp_dom.shape: (153, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Training and evaluating on Dp data via cross-validation...\n","\tEpoch 10/100 - Train loss: 0.7065 - Val accuracy: 0.7200 - Val loss: 1.3366 - Val F1: 0.6028 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.3826 - Val accuracy: 0.7200 - Val loss: 1.1316 - Val F1: 0.6028 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.2543 - Val accuracy: 0.7200 - Val loss: 0.8543 - Val F1: 0.6028 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.1982 - Val accuracy: 0.8400 - Val loss: 0.5216 - Val F1: 0.7980 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.1606 - Val accuracy: 0.9200 - Val loss: 0.3237 - Val F1: 0.8821 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.1399 - Val accuracy: 0.9200 - Val loss: 0.2561 - Val F1: 0.8821 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.1248 - Val accuracy: 0.9200 - Val loss: 0.2310 - Val F1: 0.8821 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.1150 - Val accuracy: 0.9600 - Val loss: 0.2183 - Val F1: 0.9405 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.1068 - Val accuracy: 0.9600 - Val loss: 0.2114 - Val F1: 0.9405 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.1084 - Val accuracy: 0.9600 - Val loss: 0.2085 - Val F1: 0.9405 - LR: 0.00e+00\n","\tBest epoch: 100 - Best val accuracy: 0.9600 - Best val loss: 0.2085 - Best val F1: 0.9405\n","\n","\tEpoch 10/100 - Train loss: 0.6459 - Val accuracy: 0.7200 - Val loss: 1.2186 - Val F1: 0.6028 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.4117 - Val accuracy: 0.7200 - Val loss: 1.0128 - Val F1: 0.6028 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.2927 - Val accuracy: 0.7200 - Val loss: 0.8674 - Val F1: 0.6028 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.2300 - Val accuracy: 0.7200 - Val loss: 0.6142 - Val F1: 0.6028 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.1836 - Val accuracy: 0.9200 - Val loss: 0.3269 - Val F1: 0.8821 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.1578 - Val accuracy: 0.9200 - Val loss: 0.1977 - Val F1: 0.8821 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.1408 - Val accuracy: 0.9600 - Val loss: 0.1548 - Val F1: 0.9405 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.1297 - Val accuracy: 0.9600 - Val loss: 0.1387 - Val F1: 0.9405 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.1273 - Val accuracy: 0.9600 - Val loss: 0.1317 - Val F1: 0.9405 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.1199 - Val accuracy: 0.9600 - Val loss: 0.1293 - Val F1: 0.9405 - LR: 0.00e+00\n","\tBest epoch: 100 - Best val accuracy: 0.9600 - Best val loss: 0.1293 - Best val F1: 0.9405\n","\n","\tEpoch 10/100 - Train loss: 0.7415 - Val accuracy: 0.7200 - Val loss: 1.3021 - Val F1: 0.6028 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.4160 - Val accuracy: 0.7200 - Val loss: 1.0693 - Val F1: 0.6028 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.3082 - Val accuracy: 0.7200 - Val loss: 0.8776 - Val F1: 0.6028 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.2602 - Val accuracy: 0.8000 - Val loss: 0.5751 - Val F1: 0.7465 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.2265 - Val accuracy: 0.9200 - Val loss: 0.3257 - Val F1: 0.8821 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.2018 - Val accuracy: 0.9200 - Val loss: 0.2465 - Val F1: 0.8821 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.1876 - Val accuracy: 0.9200 - Val loss: 0.2213 - Val F1: 0.8821 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.1698 - Val accuracy: 0.9200 - Val loss: 0.2105 - Val F1: 0.8821 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.1657 - Val accuracy: 0.9200 - Val loss: 0.2051 - Val F1: 0.8821 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.1637 - Val accuracy: 0.9200 - Val loss: 0.2030 - Val F1: 0.8821 - LR: 0.00e+00\n","\tBest epoch: 100 - Best val accuracy: 0.9200 - Best val loss: 0.2030 - Best val F1: 0.8821\n","\n","\tEpoch 10/100 - Train loss: 0.6700 - Val accuracy: 0.7200 - Val loss: 1.2354 - Val F1: 0.6028 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.3758 - Val accuracy: 0.7200 - Val loss: 1.0220 - Val F1: 0.6028 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.2775 - Val accuracy: 0.7200 - Val loss: 0.8768 - Val F1: 0.6028 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.2118 - Val accuracy: 0.7200 - Val loss: 0.6598 - Val F1: 0.6028 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.1793 - Val accuracy: 0.8800 - Val loss: 0.3533 - Val F1: 0.8424 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.1613 - Val accuracy: 0.9600 - Val loss: 0.2312 - Val F1: 0.9405 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.1434 - Val accuracy: 0.9600 - Val loss: 0.1924 - Val F1: 0.9405 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.1300 - Val accuracy: 0.9600 - Val loss: 0.1774 - Val F1: 0.9405 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.1233 - Val accuracy: 0.9600 - Val loss: 0.1702 - Val F1: 0.9405 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.1228 - Val accuracy: 0.9600 - Val loss: 0.1673 - Val F1: 0.9405 - LR: 0.00e+00\n","\tBest epoch: 100 - Best val accuracy: 0.9600 - Best val loss: 0.1673 - Best val F1: 0.9405\n","\n","\tEpoch 10/100 - Train loss: 0.5621 - Val accuracy: 0.7200 - Val loss: 1.2826 - Val F1: 0.6028 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.3057 - Val accuracy: 0.7200 - Val loss: 1.0683 - Val F1: 0.6028 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.2190 - Val accuracy: 0.7200 - Val loss: 0.9221 - Val F1: 0.6028 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.1657 - Val accuracy: 0.8400 - Val loss: 0.6679 - Val F1: 0.7980 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.1373 - Val accuracy: 0.9200 - Val loss: 0.4335 - Val F1: 0.8821 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.1205 - Val accuracy: 0.9600 - Val loss: 0.3849 - Val F1: 0.9405 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.1094 - Val accuracy: 0.9600 - Val loss: 0.3962 - Val F1: 0.9405 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0955 - Val accuracy: 0.9600 - Val loss: 0.4062 - Val F1: 0.9405 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0910 - Val accuracy: 0.9600 - Val loss: 0.4111 - Val F1: 0.9405 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0899 - Val accuracy: 0.9600 - Val loss: 0.4133 - Val F1: 0.9405 - LR: 0.00e+00\n","\tBest epoch: 60 - Best val accuracy: 0.9600 - Best val loss: 0.3849 - Best val F1: 0.9405\n","\n","Source class: WAL | Domain: 67 | Accuracy: 0.9351 | Loss: 0.1956 | F1: 0.9073\n","\n","Domain: 68\n","x_dp_dom.shape: (154, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Training and evaluating on Dp data via cross-validation...\n","\tEpoch 10/100 - Train loss: 0.8705 - Val accuracy: 0.7200 - Val loss: 1.2806 - Val F1: 0.6028 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.5427 - Val accuracy: 0.7200 - Val loss: 1.0559 - Val F1: 0.6028 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.4109 - Val accuracy: 0.7200 - Val loss: 0.9349 - Val F1: 0.6028 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.3299 - Val accuracy: 0.7200 - Val loss: 0.8619 - Val F1: 0.6028 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.2840 - Val accuracy: 0.7200 - Val loss: 0.6051 - Val F1: 0.6028 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.2525 - Val accuracy: 0.9200 - Val loss: 0.3398 - Val F1: 0.8821 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.2280 - Val accuracy: 0.9200 - Val loss: 0.2503 - Val F1: 0.8821 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.2106 - Val accuracy: 0.9200 - Val loss: 0.2192 - Val F1: 0.8821 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.1977 - Val accuracy: 0.9200 - Val loss: 0.2060 - Val F1: 0.8821 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.1908 - Val accuracy: 0.9200 - Val loss: 0.2012 - Val F1: 0.8821 - LR: 0.00e+00\n","\tBest epoch: 100 - Best val accuracy: 0.9200 - Best val loss: 0.2012 - Best val F1: 0.8821\n","\n","\tEpoch 10/100 - Train loss: 0.6869 - Val accuracy: 0.7200 - Val loss: 1.1886 - Val F1: 0.6028 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.4707 - Val accuracy: 0.7200 - Val loss: 0.9956 - Val F1: 0.6028 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.3716 - Val accuracy: 0.7200 - Val loss: 0.9594 - Val F1: 0.6028 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.3036 - Val accuracy: 0.7200 - Val loss: 0.9222 - Val F1: 0.6028 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.2598 - Val accuracy: 0.7200 - Val loss: 0.6622 - Val F1: 0.6028 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.2313 - Val accuracy: 0.9200 - Val loss: 0.3776 - Val F1: 0.8821 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.2041 - Val accuracy: 0.9200 - Val loss: 0.2714 - Val F1: 0.8821 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.1848 - Val accuracy: 0.9200 - Val loss: 0.2382 - Val F1: 0.8821 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.1827 - Val accuracy: 0.9200 - Val loss: 0.2259 - Val F1: 0.8821 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.1818 - Val accuracy: 0.9200 - Val loss: 0.2218 - Val F1: 0.8821 - LR: 0.00e+00\n","\tBest epoch: 100 - Best val accuracy: 0.9200 - Best val loss: 0.2218 - Best val F1: 0.8821\n","\n","\tEpoch 10/100 - Train loss: 0.7571 - Val accuracy: 0.7200 - Val loss: 1.2334 - Val F1: 0.6028 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.4818 - Val accuracy: 0.7200 - Val loss: 1.0312 - Val F1: 0.6028 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.3641 - Val accuracy: 0.7200 - Val loss: 0.9547 - Val F1: 0.6028 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.2913 - Val accuracy: 0.7200 - Val loss: 0.8849 - Val F1: 0.6028 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.2438 - Val accuracy: 0.7200 - Val loss: 0.5967 - Val F1: 0.6028 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.2230 - Val accuracy: 0.8400 - Val loss: 0.3308 - Val F1: 0.7980 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.2014 - Val accuracy: 0.9200 - Val loss: 0.2357 - Val F1: 0.8821 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.1794 - Val accuracy: 0.9200 - Val loss: 0.2037 - Val F1: 0.8821 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.1729 - Val accuracy: 0.9200 - Val loss: 0.1912 - Val F1: 0.8821 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.1655 - Val accuracy: 0.9200 - Val loss: 0.1870 - Val F1: 0.8821 - LR: 0.00e+00\n","\tBest epoch: 100 - Best val accuracy: 0.9200 - Best val loss: 0.1870 - Best val F1: 0.8821\n","\n","\tEpoch 10/100 - Train loss: 0.7959 - Val accuracy: 0.7200 - Val loss: 1.3023 - Val F1: 0.6028 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.5098 - Val accuracy: 0.7200 - Val loss: 1.0897 - Val F1: 0.6028 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.3839 - Val accuracy: 0.7200 - Val loss: 0.9984 - Val F1: 0.6028 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.3093 - Val accuracy: 0.7200 - Val loss: 0.9360 - Val F1: 0.6028 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.2668 - Val accuracy: 0.7200 - Val loss: 0.7200 - Val F1: 0.6028 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.2349 - Val accuracy: 0.8000 - Val loss: 0.4469 - Val F1: 0.7465 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.2160 - Val accuracy: 0.8400 - Val loss: 0.3059 - Val F1: 0.7980 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.1970 - Val accuracy: 0.9200 - Val loss: 0.2488 - Val F1: 0.8821 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.1939 - Val accuracy: 0.9200 - Val loss: 0.2268 - Val F1: 0.8821 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.1894 - Val accuracy: 0.9200 - Val loss: 0.2183 - Val F1: 0.8821 - LR: 0.00e+00\n","\tBest epoch: 100 - Best val accuracy: 0.9200 - Best val loss: 0.2183 - Best val F1: 0.8821\n","\n","\tEpoch 10/100 - Train loss: 0.7051 - Val accuracy: 0.7200 - Val loss: 1.2846 - Val F1: 0.6028 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.4562 - Val accuracy: 0.7200 - Val loss: 1.0661 - Val F1: 0.6028 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.3555 - Val accuracy: 0.7200 - Val loss: 0.9800 - Val F1: 0.6028 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.2722 - Val accuracy: 0.7200 - Val loss: 0.9535 - Val F1: 0.6028 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.2230 - Val accuracy: 0.7200 - Val loss: 0.7700 - Val F1: 0.6028 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.1930 - Val accuracy: 0.7600 - Val loss: 0.4179 - Val F1: 0.6838 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.1664 - Val accuracy: 0.9200 - Val loss: 0.2407 - Val F1: 0.8821 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.1549 - Val accuracy: 0.9200 - Val loss: 0.1883 - Val F1: 0.8821 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.1416 - Val accuracy: 0.9200 - Val loss: 0.1707 - Val F1: 0.8821 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.1421 - Val accuracy: 0.9200 - Val loss: 0.1648 - Val F1: 0.8821 - LR: 0.00e+00\n","\tBest epoch: 100 - Best val accuracy: 0.9200 - Best val loss: 0.1648 - Best val F1: 0.8821\n","\n","Source class: WAL | Domain: 68 | Accuracy: 0.9026 | Loss: 0.2505 | F1: 0.8570\n","\n","Domain: 69\n","x_dp_dom.shape: (153, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Training and evaluating on Dp data via cross-validation...\n","\tEpoch 10/100 - Train loss: 0.5860 - Val accuracy: 0.7200 - Val loss: 1.2168 - Val F1: 0.6028 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.3713 - Val accuracy: 0.7200 - Val loss: 0.9618 - Val F1: 0.6028 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.2711 - Val accuracy: 0.7200 - Val loss: 0.7516 - Val F1: 0.6028 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.2146 - Val accuracy: 0.9200 - Val loss: 0.4795 - Val F1: 0.8821 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.1819 - Val accuracy: 0.9200 - Val loss: 0.3057 - Val F1: 0.8821 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.1576 - Val accuracy: 0.9200 - Val loss: 0.2385 - Val F1: 0.8821 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.1395 - Val accuracy: 0.9200 - Val loss: 0.2123 - Val F1: 0.8821 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.1266 - Val accuracy: 0.9200 - Val loss: 0.1992 - Val F1: 0.8821 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.1173 - Val accuracy: 0.9200 - Val loss: 0.1919 - Val F1: 0.8821 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.1145 - Val accuracy: 0.9200 - Val loss: 0.1890 - Val F1: 0.8821 - LR: 0.00e+00\n","\tBest epoch: 100 - Best val accuracy: 0.9200 - Best val loss: 0.1890 - Best val F1: 0.8821\n","\n","\tEpoch 10/100 - Train loss: 0.5723 - Val accuracy: 0.7200 - Val loss: 1.2166 - Val F1: 0.6028 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.3516 - Val accuracy: 0.7200 - Val loss: 0.9963 - Val F1: 0.6028 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.2769 - Val accuracy: 0.7200 - Val loss: 0.7869 - Val F1: 0.6028 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.2176 - Val accuracy: 0.9200 - Val loss: 0.5212 - Val F1: 0.8821 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.1750 - Val accuracy: 0.9200 - Val loss: 0.3388 - Val F1: 0.8821 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.1523 - Val accuracy: 0.9200 - Val loss: 0.2377 - Val F1: 0.8821 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.1252 - Val accuracy: 0.9200 - Val loss: 0.2009 - Val F1: 0.8821 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.1186 - Val accuracy: 0.9200 - Val loss: 0.1886 - Val F1: 0.8821 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.1110 - Val accuracy: 0.9200 - Val loss: 0.1833 - Val F1: 0.8821 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.1117 - Val accuracy: 0.9200 - Val loss: 0.1815 - Val F1: 0.8821 - LR: 0.00e+00\n","\tBest epoch: 100 - Best val accuracy: 0.9200 - Best val loss: 0.1815 - Best val F1: 0.8821\n","\n","\tEpoch 10/100 - Train loss: 0.6500 - Val accuracy: 0.7200 - Val loss: 1.2520 - Val F1: 0.6028 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.4035 - Val accuracy: 0.7200 - Val loss: 1.0454 - Val F1: 0.6028 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.3003 - Val accuracy: 0.7200 - Val loss: 0.8539 - Val F1: 0.6028 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.2510 - Val accuracy: 0.9200 - Val loss: 0.5724 - Val F1: 0.8821 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.1996 - Val accuracy: 0.9200 - Val loss: 0.3614 - Val F1: 0.8821 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.1794 - Val accuracy: 0.9200 - Val loss: 0.2716 - Val F1: 0.8821 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.1549 - Val accuracy: 0.9200 - Val loss: 0.2382 - Val F1: 0.8821 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.1451 - Val accuracy: 0.9200 - Val loss: 0.2255 - Val F1: 0.8821 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.1325 - Val accuracy: 0.9200 - Val loss: 0.2199 - Val F1: 0.8821 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.1341 - Val accuracy: 0.9200 - Val loss: 0.2180 - Val F1: 0.8821 - LR: 0.00e+00\n","\tBest epoch: 100 - Best val accuracy: 0.9200 - Best val loss: 0.2180 - Best val F1: 0.8821\n","\n","\tEpoch 10/100 - Train loss: 0.6679 - Val accuracy: 0.7200 - Val loss: 1.2976 - Val F1: 0.6028 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.3932 - Val accuracy: 0.7200 - Val loss: 1.1155 - Val F1: 0.6028 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.3195 - Val accuracy: 0.7200 - Val loss: 0.9221 - Val F1: 0.6028 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.2646 - Val accuracy: 0.9200 - Val loss: 0.6097 - Val F1: 0.8821 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.2219 - Val accuracy: 0.9200 - Val loss: 0.3537 - Val F1: 0.8821 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.1868 - Val accuracy: 0.9200 - Val loss: 0.2440 - Val F1: 0.8821 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.1674 - Val accuracy: 0.9200 - Val loss: 0.2009 - Val F1: 0.8821 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.1416 - Val accuracy: 0.9200 - Val loss: 0.1828 - Val F1: 0.8821 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.1359 - Val accuracy: 0.9200 - Val loss: 0.1745 - Val F1: 0.8821 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.1368 - Val accuracy: 0.9200 - Val loss: 0.1719 - Val F1: 0.8821 - LR: 0.00e+00\n","\tBest epoch: 100 - Best val accuracy: 0.9200 - Best val loss: 0.1719 - Best val F1: 0.8821\n","\n","\tEpoch 10/100 - Train loss: 0.7380 - Val accuracy: 0.7200 - Val loss: 1.3248 - Val F1: 0.6028 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.4056 - Val accuracy: 0.7200 - Val loss: 1.1264 - Val F1: 0.6028 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.3217 - Val accuracy: 0.7200 - Val loss: 0.8335 - Val F1: 0.6028 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.2658 - Val accuracy: 0.9200 - Val loss: 0.4963 - Val F1: 0.8821 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.2347 - Val accuracy: 0.9200 - Val loss: 0.3291 - Val F1: 0.8821 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.2092 - Val accuracy: 0.9200 - Val loss: 0.2634 - Val F1: 0.8821 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.1896 - Val accuracy: 0.9200 - Val loss: 0.2353 - Val F1: 0.8821 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.1819 - Val accuracy: 0.9200 - Val loss: 0.2221 - Val F1: 0.8821 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.1736 - Val accuracy: 0.9200 - Val loss: 0.2160 - Val F1: 0.8821 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.1718 - Val accuracy: 0.9200 - Val loss: 0.2137 - Val F1: 0.8821 - LR: 0.00e+00\n","\tBest epoch: 100 - Best val accuracy: 0.9200 - Best val loss: 0.2137 - Best val F1: 0.8821\n","\n","Source class: WAL | Domain: 69 | Accuracy: 0.9151 | Loss: 0.2122 | F1: 0.8772\n","\n","Domain: 70\n","x_dp_dom.shape: (153, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Training and evaluating on Dp data via cross-validation...\n","\tEpoch 10/100 - Train loss: 0.6537 - Val accuracy: 0.7200 - Val loss: 1.1772 - Val F1: 0.6028 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.3516 - Val accuracy: 0.7200 - Val loss: 0.9745 - Val F1: 0.6028 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.2335 - Val accuracy: 0.7200 - Val loss: 0.9655 - Val F1: 0.6028 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.1786 - Val accuracy: 0.7200 - Val loss: 0.9712 - Val F1: 0.6028 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.1352 - Val accuracy: 0.7200 - Val loss: 0.6301 - Val F1: 0.6028 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.1078 - Val accuracy: 0.8800 - Val loss: 0.3254 - Val F1: 0.8424 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0984 - Val accuracy: 0.9200 - Val loss: 0.2277 - Val F1: 0.8821 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0891 - Val accuracy: 0.9200 - Val loss: 0.1929 - Val F1: 0.8821 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0801 - Val accuracy: 0.9200 - Val loss: 0.1782 - Val F1: 0.8821 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0813 - Val accuracy: 0.9200 - Val loss: 0.1728 - Val F1: 0.8821 - LR: 0.00e+00\n","\tBest epoch: 100 - Best val accuracy: 0.9200 - Best val loss: 0.1728 - Best val F1: 0.8821\n","\n","\tEpoch 10/100 - Train loss: 0.7338 - Val accuracy: 0.7200 - Val loss: 1.2115 - Val F1: 0.6028 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.4546 - Val accuracy: 0.7200 - Val loss: 0.9732 - Val F1: 0.6028 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.3124 - Val accuracy: 0.7200 - Val loss: 0.8890 - Val F1: 0.6028 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.2490 - Val accuracy: 0.7200 - Val loss: 0.8605 - Val F1: 0.6028 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.2063 - Val accuracy: 0.7200 - Val loss: 0.6235 - Val F1: 0.6028 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.1720 - Val accuracy: 0.8800 - Val loss: 0.3850 - Val F1: 0.8424 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.1528 - Val accuracy: 0.9200 - Val loss: 0.2985 - Val F1: 0.8821 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.1453 - Val accuracy: 0.9200 - Val loss: 0.2660 - Val F1: 0.8821 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.1338 - Val accuracy: 0.9200 - Val loss: 0.2517 - Val F1: 0.8821 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.1366 - Val accuracy: 0.9200 - Val loss: 0.2461 - Val F1: 0.8821 - LR: 0.00e+00\n","\tBest epoch: 100 - Best val accuracy: 0.9200 - Best val loss: 0.2461 - Best val F1: 0.8821\n","\n","\tEpoch 10/100 - Train loss: 0.6654 - Val accuracy: 0.7200 - Val loss: 1.1807 - Val F1: 0.6028 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.4048 - Val accuracy: 0.7200 - Val loss: 0.9389 - Val F1: 0.6028 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.2724 - Val accuracy: 0.7200 - Val loss: 0.8999 - Val F1: 0.6028 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.1980 - Val accuracy: 0.7200 - Val loss: 0.8860 - Val F1: 0.6028 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.1552 - Val accuracy: 0.7200 - Val loss: 0.5685 - Val F1: 0.6028 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.1218 - Val accuracy: 0.9200 - Val loss: 0.2695 - Val F1: 0.8821 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.1094 - Val accuracy: 0.9200 - Val loss: 0.1803 - Val F1: 0.8821 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.1036 - Val accuracy: 0.9200 - Val loss: 0.1517 - Val F1: 0.8821 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0986 - Val accuracy: 0.9600 - Val loss: 0.1410 - Val F1: 0.9405 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0943 - Val accuracy: 0.9600 - Val loss: 0.1373 - Val F1: 0.9405 - LR: 0.00e+00\n","\tBest epoch: 100 - Best val accuracy: 0.9600 - Best val loss: 0.1373 - Best val F1: 0.9405\n","\n","\tEpoch 10/100 - Train loss: 0.7188 - Val accuracy: 0.7200 - Val loss: 1.2801 - Val F1: 0.6028 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.4105 - Val accuracy: 0.7200 - Val loss: 1.0081 - Val F1: 0.6028 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.2684 - Val accuracy: 0.7200 - Val loss: 0.8957 - Val F1: 0.6028 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.2096 - Val accuracy: 0.7200 - Val loss: 0.7521 - Val F1: 0.6028 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.1712 - Val accuracy: 0.8000 - Val loss: 0.3863 - Val F1: 0.7465 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.1571 - Val accuracy: 0.9200 - Val loss: 0.2355 - Val F1: 0.8821 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.1352 - Val accuracy: 0.9200 - Val loss: 0.1952 - Val F1: 0.8821 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.1272 - Val accuracy: 0.9200 - Val loss: 0.1780 - Val F1: 0.8821 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.1242 - Val accuracy: 0.9200 - Val loss: 0.1697 - Val F1: 0.8821 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.1186 - Val accuracy: 0.9200 - Val loss: 0.1666 - Val F1: 0.8821 - LR: 0.00e+00\n","\tBest epoch: 100 - Best val accuracy: 0.9200 - Best val loss: 0.1666 - Best val F1: 0.8821\n","\n","\tEpoch 10/100 - Train loss: 0.7900 - Val accuracy: 0.7200 - Val loss: 1.3129 - Val F1: 0.6028 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.4643 - Val accuracy: 0.7200 - Val loss: 1.0450 - Val F1: 0.6028 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.3048 - Val accuracy: 0.7200 - Val loss: 0.8682 - Val F1: 0.6028 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.2353 - Val accuracy: 0.7200 - Val loss: 0.7269 - Val F1: 0.6028 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.1979 - Val accuracy: 0.8000 - Val loss: 0.4848 - Val F1: 0.7465 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.1702 - Val accuracy: 0.9200 - Val loss: 0.3299 - Val F1: 0.8821 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.1606 - Val accuracy: 0.9200 - Val loss: 0.2769 - Val F1: 0.8821 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.1492 - Val accuracy: 0.9200 - Val loss: 0.2555 - Val F1: 0.8821 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.1358 - Val accuracy: 0.9200 - Val loss: 0.2449 - Val F1: 0.8821 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.1383 - Val accuracy: 0.9200 - Val loss: 0.2408 - Val F1: 0.8821 - LR: 0.00e+00\n","\tBest epoch: 100 - Best val accuracy: 0.9200 - Best val loss: 0.2408 - Best val F1: 0.8821\n","\n","Source class: WAL | Domain: 70 | Accuracy: 0.9344 | Loss: 0.1912 | F1: 0.9068\n","\n","Domain: 71\n","x_dp_dom.shape: (155, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Training and evaluating on Dp data via cross-validation...\n","\tEpoch 10/100 - Train loss: 0.6945 - Val accuracy: 0.7200 - Val loss: 1.2579 - Val F1: 0.6028 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.4437 - Val accuracy: 0.7200 - Val loss: 1.0433 - Val F1: 0.6028 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.3282 - Val accuracy: 0.7200 - Val loss: 0.9558 - Val F1: 0.6028 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.2644 - Val accuracy: 0.7200 - Val loss: 0.9072 - Val F1: 0.6028 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.2159 - Val accuracy: 0.7200 - Val loss: 0.6300 - Val F1: 0.6028 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.1745 - Val accuracy: 0.9200 - Val loss: 0.3232 - Val F1: 0.8821 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.1558 - Val accuracy: 0.9200 - Val loss: 0.2220 - Val F1: 0.8821 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.1366 - Val accuracy: 0.9200 - Val loss: 0.1889 - Val F1: 0.8821 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.1266 - Val accuracy: 0.9200 - Val loss: 0.1756 - Val F1: 0.8821 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.1313 - Val accuracy: 0.9200 - Val loss: 0.1706 - Val F1: 0.8821 - LR: 0.00e+00\n","\tBest epoch: 100 - Best val accuracy: 0.9200 - Best val loss: 0.1706 - Best val F1: 0.8821\n","\n","\tEpoch 10/100 - Train loss: 0.6710 - Val accuracy: 0.7200 - Val loss: 1.1519 - Val F1: 0.6028 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.4231 - Val accuracy: 0.7200 - Val loss: 0.9317 - Val F1: 0.6028 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.3019 - Val accuracy: 0.7200 - Val loss: 0.8054 - Val F1: 0.6028 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.2367 - Val accuracy: 0.7200 - Val loss: 0.6671 - Val F1: 0.6028 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.1937 - Val accuracy: 0.8400 - Val loss: 0.3616 - Val F1: 0.7980 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.1643 - Val accuracy: 0.9600 - Val loss: 0.1906 - Val F1: 0.9405 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.1457 - Val accuracy: 0.9600 - Val loss: 0.1366 - Val F1: 0.9405 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.1232 - Val accuracy: 0.9600 - Val loss: 0.1180 - Val F1: 0.9418 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.1177 - Val accuracy: 0.9600 - Val loss: 0.1107 - Val F1: 0.9418 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.1142 - Val accuracy: 0.9600 - Val loss: 0.1083 - Val F1: 0.9418 - LR: 0.00e+00\n","\tBest epoch: 100 - Best val accuracy: 0.9600 - Best val loss: 0.1083 - Best val F1: 0.9418\n","\n","\tEpoch 10/100 - Train loss: 0.8166 - Val accuracy: 0.7200 - Val loss: 1.3089 - Val F1: 0.6028 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.4614 - Val accuracy: 0.7200 - Val loss: 1.0413 - Val F1: 0.6028 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.3328 - Val accuracy: 0.7200 - Val loss: 0.8992 - Val F1: 0.6028 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.2757 - Val accuracy: 0.7200 - Val loss: 0.9053 - Val F1: 0.6028 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.2133 - Val accuracy: 0.7200 - Val loss: 0.7076 - Val F1: 0.6028 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.1851 - Val accuracy: 0.8800 - Val loss: 0.3305 - Val F1: 0.8424 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.1586 - Val accuracy: 0.9200 - Val loss: 0.1945 - Val F1: 0.8821 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.1387 - Val accuracy: 0.9200 - Val loss: 0.1537 - Val F1: 0.8821 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.1330 - Val accuracy: 0.9200 - Val loss: 0.1399 - Val F1: 0.8821 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.1331 - Val accuracy: 0.9200 - Val loss: 0.1358 - Val F1: 0.8824 - LR: 0.00e+00\n","\tBest epoch: 100 - Best val accuracy: 0.9200 - Best val loss: 0.1358 - Best val F1: 0.8824\n","\n","\tEpoch 10/100 - Train loss: 0.5838 - Val accuracy: 0.7200 - Val loss: 1.1681 - Val F1: 0.6028 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.3991 - Val accuracy: 0.7200 - Val loss: 0.9771 - Val F1: 0.6028 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.2980 - Val accuracy: 0.7200 - Val loss: 1.0117 - Val F1: 0.6028 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.2297 - Val accuracy: 0.7200 - Val loss: 1.0050 - Val F1: 0.6028 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.1978 - Val accuracy: 0.7200 - Val loss: 0.7007 - Val F1: 0.6028 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.1565 - Val accuracy: 0.8800 - Val loss: 0.3258 - Val F1: 0.8424 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.1350 - Val accuracy: 0.9200 - Val loss: 0.1872 - Val F1: 0.8821 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.1120 - Val accuracy: 0.9200 - Val loss: 0.1470 - Val F1: 0.8821 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.1183 - Val accuracy: 0.9200 - Val loss: 0.1340 - Val F1: 0.8824 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.1062 - Val accuracy: 0.9600 - Val loss: 0.1300 - Val F1: 0.9418 - LR: 0.00e+00\n","\tBest epoch: 100 - Best val accuracy: 0.9600 - Best val loss: 0.1300 - Best val F1: 0.9418\n","\n","\tEpoch 10/100 - Train loss: 0.6300 - Val accuracy: 0.7200 - Val loss: 1.2056 - Val F1: 0.6028 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.3666 - Val accuracy: 0.7200 - Val loss: 0.9851 - Val F1: 0.6028 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.2678 - Val accuracy: 0.7200 - Val loss: 0.9353 - Val F1: 0.6028 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.1935 - Val accuracy: 0.7200 - Val loss: 0.8344 - Val F1: 0.6028 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.1533 - Val accuracy: 0.7600 - Val loss: 0.4726 - Val F1: 0.6838 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.1295 - Val accuracy: 0.9600 - Val loss: 0.2293 - Val F1: 0.9405 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.1110 - Val accuracy: 0.9600 - Val loss: 0.1576 - Val F1: 0.9405 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.1011 - Val accuracy: 0.9600 - Val loss: 0.1355 - Val F1: 0.9405 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0952 - Val accuracy: 0.9600 - Val loss: 0.1264 - Val F1: 0.9405 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0943 - Val accuracy: 0.9600 - Val loss: 0.1231 - Val F1: 0.9405 - LR: 0.00e+00\n","\tBest epoch: 100 - Best val accuracy: 0.9600 - Best val loss: 0.1231 - Best val F1: 0.9405\n","\n","Source class: WAL | Domain: 71 | Accuracy: 0.9419 | Loss: 0.1849 | F1: 0.9185\n","\n","Domain: 72\n","x_dp_dom.shape: (153, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Training and evaluating on Dp data via cross-validation...\n","\tEpoch 10/100 - Train loss: 0.7468 - Val accuracy: 0.7200 - Val loss: 1.2860 - Val F1: 0.6028 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.4453 - Val accuracy: 0.7200 - Val loss: 1.0450 - Val F1: 0.6028 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.3469 - Val accuracy: 0.7200 - Val loss: 0.9282 - Val F1: 0.6028 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.2866 - Val accuracy: 0.7200 - Val loss: 0.8357 - Val F1: 0.6028 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.2463 - Val accuracy: 0.7200 - Val loss: 0.5079 - Val F1: 0.6028 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.2230 - Val accuracy: 0.9200 - Val loss: 0.2840 - Val F1: 0.8821 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.1994 - Val accuracy: 0.9200 - Val loss: 0.2230 - Val F1: 0.8821 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.1848 - Val accuracy: 0.9200 - Val loss: 0.2007 - Val F1: 0.8821 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.1733 - Val accuracy: 0.9200 - Val loss: 0.1903 - Val F1: 0.8821 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.1704 - Val accuracy: 0.9200 - Val loss: 0.1863 - Val F1: 0.8821 - LR: 0.00e+00\n","\tBest epoch: 100 - Best val accuracy: 0.9200 - Best val loss: 0.1863 - Best val F1: 0.8821\n","\n","\tEpoch 10/100 - Train loss: 0.7622 - Val accuracy: 0.7200 - Val loss: 1.2495 - Val F1: 0.6028 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.4810 - Val accuracy: 0.7200 - Val loss: 1.0312 - Val F1: 0.6028 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.3556 - Val accuracy: 0.7200 - Val loss: 0.9302 - Val F1: 0.6028 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.2920 - Val accuracy: 0.7200 - Val loss: 0.8592 - Val F1: 0.6028 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.2403 - Val accuracy: 0.7200 - Val loss: 0.5694 - Val F1: 0.6028 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.2135 - Val accuracy: 0.9200 - Val loss: 0.3302 - Val F1: 0.8821 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.1938 - Val accuracy: 0.9200 - Val loss: 0.2520 - Val F1: 0.8821 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.1780 - Val accuracy: 0.9200 - Val loss: 0.2235 - Val F1: 0.8821 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.1645 - Val accuracy: 0.9200 - Val loss: 0.2110 - Val F1: 0.8821 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.1595 - Val accuracy: 0.9200 - Val loss: 0.2062 - Val F1: 0.8821 - LR: 0.00e+00\n","\tBest epoch: 100 - Best val accuracy: 0.9200 - Best val loss: 0.2062 - Best val F1: 0.8821\n","\n","\tEpoch 10/100 - Train loss: 0.5936 - Val accuracy: 0.7200 - Val loss: 1.2273 - Val F1: 0.6028 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.3584 - Val accuracy: 0.7200 - Val loss: 0.9715 - Val F1: 0.6028 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.2666 - Val accuracy: 0.7200 - Val loss: 0.9008 - Val F1: 0.6028 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.2004 - Val accuracy: 0.7200 - Val loss: 0.8130 - Val F1: 0.6028 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.1577 - Val accuracy: 0.8000 - Val loss: 0.4444 - Val F1: 0.7465 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.1343 - Val accuracy: 0.9200 - Val loss: 0.2451 - Val F1: 0.8821 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.1215 - Val accuracy: 0.9200 - Val loss: 0.1952 - Val F1: 0.8821 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.1075 - Val accuracy: 0.9200 - Val loss: 0.1780 - Val F1: 0.8821 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0964 - Val accuracy: 0.9200 - Val loss: 0.1708 - Val F1: 0.8821 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0945 - Val accuracy: 0.9200 - Val loss: 0.1683 - Val F1: 0.8821 - LR: 0.00e+00\n","\tBest epoch: 100 - Best val accuracy: 0.9200 - Best val loss: 0.1683 - Best val F1: 0.8821\n","\n","\tEpoch 10/100 - Train loss: 0.7395 - Val accuracy: 0.7200 - Val loss: 1.2569 - Val F1: 0.6028 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.4628 - Val accuracy: 0.7200 - Val loss: 1.0669 - Val F1: 0.6028 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.3575 - Val accuracy: 0.7200 - Val loss: 0.8929 - Val F1: 0.6028 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.2814 - Val accuracy: 0.7200 - Val loss: 0.6504 - Val F1: 0.6028 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.2342 - Val accuracy: 0.9200 - Val loss: 0.3826 - Val F1: 0.8821 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.2031 - Val accuracy: 0.9200 - Val loss: 0.2543 - Val F1: 0.8821 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.1742 - Val accuracy: 0.9200 - Val loss: 0.2034 - Val F1: 0.8821 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.1562 - Val accuracy: 0.9200 - Val loss: 0.1796 - Val F1: 0.8821 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.1452 - Val accuracy: 0.9200 - Val loss: 0.1676 - Val F1: 0.8821 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.1344 - Val accuracy: 0.9200 - Val loss: 0.1625 - Val F1: 0.8821 - LR: 0.00e+00\n","\tBest epoch: 100 - Best val accuracy: 0.9200 - Best val loss: 0.1625 - Best val F1: 0.8821\n","\n","\tEpoch 10/100 - Train loss: 0.6955 - Val accuracy: 0.7200 - Val loss: 1.2139 - Val F1: 0.6028 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.4345 - Val accuracy: 0.7200 - Val loss: 0.9952 - Val F1: 0.6028 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.3160 - Val accuracy: 0.7200 - Val loss: 0.8708 - Val F1: 0.6028 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.2435 - Val accuracy: 0.7200 - Val loss: 0.7299 - Val F1: 0.6028 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.1982 - Val accuracy: 0.8800 - Val loss: 0.4228 - Val F1: 0.8424 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.1646 - Val accuracy: 0.9200 - Val loss: 0.2783 - Val F1: 0.8821 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.1444 - Val accuracy: 0.9200 - Val loss: 0.2366 - Val F1: 0.8821 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.1346 - Val accuracy: 0.9200 - Val loss: 0.2206 - Val F1: 0.8821 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.1304 - Val accuracy: 0.9200 - Val loss: 0.2125 - Val F1: 0.8821 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.1280 - Val accuracy: 0.9200 - Val loss: 0.2095 - Val F1: 0.8821 - LR: 0.00e+00\n","\tBest epoch: 100 - Best val accuracy: 0.9200 - Best val loss: 0.2095 - Best val F1: 0.8821\n","\n","Source class: WAL | Domain: 72 | Accuracy: 0.9217 | Loss: 0.1964 | F1: 0.8848\n","\n","Domain: 73\n","x_dp_dom.shape: (152, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Training and evaluating on Dp data via cross-validation...\n","\tEpoch 10/100 - Train loss: 0.7467 - Val accuracy: 0.7200 - Val loss: 1.2960 - Val F1: 0.6028 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.4140 - Val accuracy: 0.7200 - Val loss: 1.0328 - Val F1: 0.6028 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.2990 - Val accuracy: 0.7200 - Val loss: 0.9454 - Val F1: 0.6028 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.2538 - Val accuracy: 0.7200 - Val loss: 0.9480 - Val F1: 0.6028 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.2083 - Val accuracy: 0.7200 - Val loss: 0.6244 - Val F1: 0.6028 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.1875 - Val accuracy: 0.9200 - Val loss: 0.3205 - Val F1: 0.8821 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.1573 - Val accuracy: 0.9200 - Val loss: 0.2448 - Val F1: 0.8821 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.1444 - Val accuracy: 0.9200 - Val loss: 0.2238 - Val F1: 0.8821 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.1426 - Val accuracy: 0.9200 - Val loss: 0.2145 - Val F1: 0.8821 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.1370 - Val accuracy: 0.9200 - Val loss: 0.2109 - Val F1: 0.8821 - LR: 0.00e+00\n","\tBest epoch: 100 - Best val accuracy: 0.9200 - Best val loss: 0.2109 - Best val F1: 0.8821\n","\n","\tEpoch 10/100 - Train loss: 0.7727 - Val accuracy: 0.7200 - Val loss: 1.3155 - Val F1: 0.6028 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.4609 - Val accuracy: 0.7200 - Val loss: 1.0740 - Val F1: 0.6028 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.3217 - Val accuracy: 0.7200 - Val loss: 0.9257 - Val F1: 0.6028 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.2428 - Val accuracy: 0.7200 - Val loss: 0.8341 - Val F1: 0.6028 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.1942 - Val accuracy: 0.7600 - Val loss: 0.5579 - Val F1: 0.6838 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.1647 - Val accuracy: 0.8800 - Val loss: 0.3297 - Val F1: 0.8424 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.1451 - Val accuracy: 0.9200 - Val loss: 0.2505 - Val F1: 0.8821 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.1343 - Val accuracy: 0.9200 - Val loss: 0.2209 - Val F1: 0.8821 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.1219 - Val accuracy: 0.9200 - Val loss: 0.2083 - Val F1: 0.8821 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.1246 - Val accuracy: 0.9200 - Val loss: 0.2034 - Val F1: 0.8821 - LR: 0.00e+00\n","\tBest epoch: 100 - Best val accuracy: 0.9200 - Best val loss: 0.2034 - Best val F1: 0.8821\n","\n","\tEpoch 10/100 - Train loss: 0.6983 - Val accuracy: 0.7200 - Val loss: 1.2998 - Val F1: 0.6028 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.4219 - Val accuracy: 0.7200 - Val loss: 1.0293 - Val F1: 0.6028 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.3244 - Val accuracy: 0.7200 - Val loss: 0.9661 - Val F1: 0.6028 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.2590 - Val accuracy: 0.7200 - Val loss: 0.9495 - Val F1: 0.6028 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.2140 - Val accuracy: 0.7200 - Val loss: 0.6527 - Val F1: 0.6028 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.1867 - Val accuracy: 0.9200 - Val loss: 0.3270 - Val F1: 0.8821 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.1684 - Val accuracy: 0.9200 - Val loss: 0.2284 - Val F1: 0.8821 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.1562 - Val accuracy: 0.9200 - Val loss: 0.1982 - Val F1: 0.8821 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.1428 - Val accuracy: 0.9200 - Val loss: 0.1862 - Val F1: 0.8821 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.1411 - Val accuracy: 0.9200 - Val loss: 0.1818 - Val F1: 0.8821 - LR: 0.00e+00\n","\tBest epoch: 100 - Best val accuracy: 0.9200 - Best val loss: 0.1818 - Best val F1: 0.8821\n","\n","\tEpoch 10/100 - Train loss: 0.7647 - Val accuracy: 0.7200 - Val loss: 1.2526 - Val F1: 0.6028 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.4462 - Val accuracy: 0.7200 - Val loss: 0.9959 - Val F1: 0.6028 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.3353 - Val accuracy: 0.7200 - Val loss: 0.9228 - Val F1: 0.6028 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.2795 - Val accuracy: 0.7200 - Val loss: 0.9009 - Val F1: 0.6028 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.2248 - Val accuracy: 0.7200 - Val loss: 0.5803 - Val F1: 0.6028 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.1894 - Val accuracy: 0.9200 - Val loss: 0.3289 - Val F1: 0.8821 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.1677 - Val accuracy: 0.9200 - Val loss: 0.2609 - Val F1: 0.8821 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.1587 - Val accuracy: 0.9200 - Val loss: 0.2346 - Val F1: 0.8821 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.1539 - Val accuracy: 0.9200 - Val loss: 0.2212 - Val F1: 0.8821 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.1482 - Val accuracy: 0.9200 - Val loss: 0.2156 - Val F1: 0.8821 - LR: 0.00e+00\n","\tBest epoch: 100 - Best val accuracy: 0.9200 - Best val loss: 0.2156 - Best val F1: 0.8821\n","\n","\tEpoch 10/100 - Train loss: 0.6768 - Val accuracy: 0.7200 - Val loss: 1.2166 - Val F1: 0.6028 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.3873 - Val accuracy: 0.7200 - Val loss: 1.0082 - Val F1: 0.6028 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.2594 - Val accuracy: 0.7200 - Val loss: 0.9085 - Val F1: 0.6028 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.1874 - Val accuracy: 0.7200 - Val loss: 0.8475 - Val F1: 0.6028 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.1545 - Val accuracy: 0.8000 - Val loss: 0.5326 - Val F1: 0.7465 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.1257 - Val accuracy: 0.9200 - Val loss: 0.3136 - Val F1: 0.8821 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.1133 - Val accuracy: 0.9200 - Val loss: 0.2484 - Val F1: 0.8821 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.1019 - Val accuracy: 0.9200 - Val loss: 0.2260 - Val F1: 0.8821 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0977 - Val accuracy: 0.9200 - Val loss: 0.2173 - Val F1: 0.8821 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0908 - Val accuracy: 0.9200 - Val loss: 0.2138 - Val F1: 0.8821 - LR: 0.00e+00\n","\tBest epoch: 100 - Best val accuracy: 0.9200 - Best val loss: 0.2138 - Best val F1: 0.8821\n","\n","Source class: WAL | Domain: 73 | Accuracy: 0.9146 | Loss: 0.2197 | F1: 0.8744\n","\n","Domain: 74\n","Domain: 75\n","x_dp_dom.shape: (153, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Training and evaluating on Dp data via cross-validation...\n","\tEpoch 10/100 - Train loss: 0.6732 - Val accuracy: 0.7200 - Val loss: 1.2346 - Val F1: 0.6028 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.4109 - Val accuracy: 0.7200 - Val loss: 1.0275 - Val F1: 0.6028 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.3072 - Val accuracy: 0.7200 - Val loss: 0.9097 - Val F1: 0.6028 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.2398 - Val accuracy: 0.7200 - Val loss: 0.7075 - Val F1: 0.6028 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.2027 - Val accuracy: 0.9200 - Val loss: 0.4084 - Val F1: 0.8821 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.1655 - Val accuracy: 0.9200 - Val loss: 0.2865 - Val F1: 0.8821 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.1444 - Val accuracy: 0.9200 - Val loss: 0.2490 - Val F1: 0.8821 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.1291 - Val accuracy: 0.9200 - Val loss: 0.2325 - Val F1: 0.8821 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.1176 - Val accuracy: 0.9200 - Val loss: 0.2230 - Val F1: 0.8821 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.1163 - Val accuracy: 0.9200 - Val loss: 0.2190 - Val F1: 0.8821 - LR: 0.00e+00\n","\tBest epoch: 100 - Best val accuracy: 0.9200 - Best val loss: 0.2190 - Best val F1: 0.8821\n","\n","\tEpoch 10/100 - Train loss: 0.8029 - Val accuracy: 0.7200 - Val loss: 1.2899 - Val F1: 0.6028 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.4517 - Val accuracy: 0.7200 - Val loss: 1.0414 - Val F1: 0.6028 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.3404 - Val accuracy: 0.7200 - Val loss: 0.9224 - Val F1: 0.6028 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.2912 - Val accuracy: 0.7200 - Val loss: 0.8154 - Val F1: 0.6028 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.2659 - Val accuracy: 0.7600 - Val loss: 0.5233 - Val F1: 0.6838 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.2325 - Val accuracy: 0.8800 - Val loss: 0.3284 - Val F1: 0.8424 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.2215 - Val accuracy: 0.9200 - Val loss: 0.2582 - Val F1: 0.8821 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.2027 - Val accuracy: 0.9200 - Val loss: 0.2321 - Val F1: 0.8821 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.1918 - Val accuracy: 0.9200 - Val loss: 0.2209 - Val F1: 0.8821 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.1844 - Val accuracy: 0.9200 - Val loss: 0.2167 - Val F1: 0.8821 - LR: 0.00e+00\n","\tBest epoch: 100 - Best val accuracy: 0.9200 - Best val loss: 0.2167 - Best val F1: 0.8821\n","\n","\tEpoch 10/100 - Train loss: 0.7371 - Val accuracy: 0.7200 - Val loss: 1.2804 - Val F1: 0.6028 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.4715 - Val accuracy: 0.7200 - Val loss: 1.0491 - Val F1: 0.6028 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.3712 - Val accuracy: 0.7200 - Val loss: 0.9033 - Val F1: 0.6028 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.3116 - Val accuracy: 0.7200 - Val loss: 0.7785 - Val F1: 0.6028 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.2739 - Val accuracy: 0.9200 - Val loss: 0.4489 - Val F1: 0.8821 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.2366 - Val accuracy: 0.9200 - Val loss: 0.2822 - Val F1: 0.8821 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.2170 - Val accuracy: 0.9200 - Val loss: 0.2292 - Val F1: 0.8821 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.2090 - Val accuracy: 0.9200 - Val loss: 0.2053 - Val F1: 0.8821 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.1861 - Val accuracy: 0.9200 - Val loss: 0.1929 - Val F1: 0.8821 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.1913 - Val accuracy: 0.9200 - Val loss: 0.1880 - Val F1: 0.8821 - LR: 0.00e+00\n","\tBest epoch: 100 - Best val accuracy: 0.9200 - Best val loss: 0.1880 - Best val F1: 0.8821\n","\n","\tEpoch 10/100 - Train loss: 0.6510 - Val accuracy: 0.7200 - Val loss: 1.2519 - Val F1: 0.6028 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.4085 - Val accuracy: 0.7200 - Val loss: 0.9768 - Val F1: 0.6028 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.3276 - Val accuracy: 0.7200 - Val loss: 0.8829 - Val F1: 0.6028 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.2628 - Val accuracy: 0.7200 - Val loss: 0.8531 - Val F1: 0.6028 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.2068 - Val accuracy: 0.7200 - Val loss: 0.5773 - Val F1: 0.6028 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.1795 - Val accuracy: 0.9200 - Val loss: 0.2933 - Val F1: 0.8821 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.1581 - Val accuracy: 0.9200 - Val loss: 0.1979 - Val F1: 0.8821 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.1416 - Val accuracy: 0.9600 - Val loss: 0.1625 - Val F1: 0.9405 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.1352 - Val accuracy: 0.9600 - Val loss: 0.1471 - Val F1: 0.9405 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.1318 - Val accuracy: 0.9600 - Val loss: 0.1413 - Val F1: 0.9405 - LR: 0.00e+00\n","\tBest epoch: 100 - Best val accuracy: 0.9600 - Best val loss: 0.1413 - Best val F1: 0.9405\n","\n","\tEpoch 10/100 - Train loss: 0.6839 - Val accuracy: 0.7200 - Val loss: 1.2690 - Val F1: 0.6028 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.3681 - Val accuracy: 0.7200 - Val loss: 1.0518 - Val F1: 0.6028 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.3091 - Val accuracy: 0.7200 - Val loss: 0.9988 - Val F1: 0.6028 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.2514 - Val accuracy: 0.7200 - Val loss: 0.9635 - Val F1: 0.6028 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.2113 - Val accuracy: 0.7600 - Val loss: 0.5612 - Val F1: 0.6838 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.1873 - Val accuracy: 0.9200 - Val loss: 0.2978 - Val F1: 0.8821 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.1664 - Val accuracy: 0.9200 - Val loss: 0.2344 - Val F1: 0.8821 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.1465 - Val accuracy: 0.9200 - Val loss: 0.2127 - Val F1: 0.8821 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.1418 - Val accuracy: 0.9200 - Val loss: 0.2024 - Val F1: 0.8821 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.1384 - Val accuracy: 0.9200 - Val loss: 0.1983 - Val F1: 0.8821 - LR: 0.00e+00\n","\tBest epoch: 100 - Best val accuracy: 0.9200 - Best val loss: 0.1983 - Best val F1: 0.8821\n","\n","Source class: WAL | Domain: 75 | Accuracy: 0.9151 | Loss: 0.2161 | F1: 0.8750\n","\n","Mean accuracy: 0.9433 +- 0.0323\n","Mean F1: 0.9220 +- 0.0487\n","\n"]}],"source":["def compute_TSTR_Dp(dataset):\n","    accs = []\n","    f1s = []\n","\n","    for src_class in config[dataset]['class_names']:\n","        if src_class != 'WAL':\n","            continue\n","\n","        print(f\"Source class: {src_class}\\n\")\n","\n","        for domain in range(config[dataset]['num_df_domains'], config[dataset]['num_df_domains'] + config[dataset]['num_dp_domains']):\n","            print(f\"Domain: {domain}\")\n","\n","            if domain == 74:\n","              continue\n","\n","            # Load Dp data\n","            x_dp_dom, y_dp_dom, k_dp_dom = get_data(dataset, 'dp', src_class, domain)\n","            print(f'x_dp_dom.shape: {x_dp_dom.shape} | np.unique(y_dp_dom): {np.unique(y_dp_dom)}\\n')\n","\n","            # Train and evaluate via cross-validation on Dp data\n","            print('Training and evaluating on Dp data via cross-validation...')\n","            acc, loss, f1 = train_classifier_cv(x_dp_dom, y_dp_dom, dataset, num_epochs=num_epochs)\n","            save_scores(src_class, domain, acc, loss, f1, 'Dp', dataset)\n","            accs.append(acc)\n","            f1s.append(f1)\n","            print(f'Source class: {src_class} | Domain: {domain} | Accuracy: {acc:.4f} | Loss: {loss:.4f} | F1: {f1:.4f}\\n')\n","\n","    print(f\"Mean accuracy: {np.mean(accs):.4f} +- {np.std(accs):.4f}\")\n","    print(f\"Mean F1: {np.mean(f1s):.4f} +- {np.std(f1s):.4f}\\n\")\n","\n","\n","\n","compute_TSTR_Dp('realworld_mobiact')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"M7S9IU2VVAmx"},"outputs":[],"source":["def compute_TSTR_Dpc(dataset):\n","\n","    raise NotImplementedError\n","\n","\n","\n","# compute_TSTR_Dpc('realworld_mobiact')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":862648,"status":"ok","timestamp":1732649105527,"user":{"displayName":"Pietro","userId":"07073247908758556229"},"user_tz":-60},"id":"zhTuwDtYCPto","outputId":"a2c27db5-8149-4475-9979-6f8f9382bd0b"},"outputs":[{"name":"stdout","output_type":"stream","text":["Source class: WAL\n","\n","x_df.shape: (11483, 3, 128) | np.unique(y_df): [0 1 2 3]\n","\n","Training on Df data...\n","\tEpoch 10/100 - Train loss: 0.1029 - Val accuracy: 0.9499 - Val loss: 0.1445 - Val F1: 0.9501 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.0441 - Val accuracy: 0.9512 - Val loss: 0.1437 - Val F1: 0.9512 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.0179 - Val accuracy: 0.9565 - Val loss: 0.1322 - Val F1: 0.9566 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.0091 - Val accuracy: 0.9639 - Val loss: 0.1444 - Val F1: 0.9638 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.0059 - Val accuracy: 0.9634 - Val loss: 0.1531 - Val F1: 0.9633 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.0040 - Val accuracy: 0.9604 - Val loss: 0.1584 - Val F1: 0.9604 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0022 - Val accuracy: 0.9626 - Val loss: 0.1608 - Val F1: 0.9625 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0020 - Val accuracy: 0.9591 - Val loss: 0.1656 - Val F1: 0.9591 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0015 - Val accuracy: 0.9599 - Val loss: 0.1720 - Val F1: 0.9600 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0011 - Val accuracy: 0.9626 - Val loss: 0.1724 - Val F1: 0.9625 - LR: 0.00e+00\n","\tBest epoch: 17 - Best val accuracy: 0.9613 - Best val loss: 0.1219 - Best val F1: 0.9611\n","\n","Domain: 15\n","x_dp_dom.shape: (161, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 15 | Accuracy: 0.1739 | Loss: 22.4131 | F1: 0.1037\n","\n","Domain: 16\n","x_dp_dom.shape: (165, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 16 | Accuracy: 0.0788 | Loss: 23.0770 | F1: 0.0125\n","\n","Domain: 17\n","x_dp_dom.shape: (164, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 17 | Accuracy: 0.0915 | Loss: 29.7279 | F1: 0.0247\n","\n","Domain: 18\n","x_dp_dom.shape: (166, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 18 | Accuracy: 0.0663 | Loss: 25.8303 | F1: 0.0197\n","\n","Domain: 19\n","x_dp_dom.shape: (165, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 19 | Accuracy: 0.0848 | Loss: 19.9191 | F1: 0.0175\n","\n","Domain: 20\n","x_dp_dom.shape: (162, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 20 | Accuracy: 0.0802 | Loss: 23.4095 | F1: 0.0139\n","\n","Domain: 21\n","x_dp_dom.shape: (159, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 21 | Accuracy: 0.0755 | Loss: 26.8543 | F1: 0.0150\n","\n","Domain: 22\n","x_dp_dom.shape: (165, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 22 | Accuracy: 0.1939 | Loss: 23.8443 | F1: 0.1298\n","\n","Domain: 23\n","x_dp_dom.shape: (164, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 23 | Accuracy: 0.0976 | Loss: 17.4598 | F1: 0.0620\n","\n","Domain: 24\n","x_dp_dom.shape: (162, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 24 | Accuracy: 0.0988 | Loss: 26.0211 | F1: 0.0695\n","\n","Domain: 25\n","x_dp_dom.shape: (166, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 25 | Accuracy: 0.0783 | Loss: 25.5088 | F1: 0.0139\n","\n","Domain: 26\n","x_dp_dom.shape: (153, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 26 | Accuracy: 0.0392 | Loss: 32.1357 | F1: 0.0057\n","\n","Domain: 27\n","x_dp_dom.shape: (165, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 27 | Accuracy: 0.0606 | Loss: 16.5390 | F1: 0.0164\n","\n","Domain: 28\n","x_dp_dom.shape: (153, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 28 | Accuracy: 0.0458 | Loss: 19.4449 | F1: 0.0075\n","\n","Domain: 29\n","x_dp_dom.shape: (153, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 29 | Accuracy: 0.0654 | Loss: 23.3837 | F1: 0.0122\n","\n","Domain: 30\n","x_dp_dom.shape: (161, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 30 | Accuracy: 0.0932 | Loss: 27.8589 | F1: 0.0266\n","\n","Domain: 31\n","x_dp_dom.shape: (154, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 31 | Accuracy: 0.0325 | Loss: 11.7316 | F1: 0.0166\n","\n","Domain: 32\n","x_dp_dom.shape: (163, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 32 | Accuracy: 0.0798 | Loss: 25.4987 | F1: 0.0151\n","\n","Domain: 33\n","x_dp_dom.shape: (156, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 33 | Accuracy: 0.0577 | Loss: 33.8908 | F1: 0.0074\n","\n","Domain: 34\n","x_dp_dom.shape: (161, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 34 | Accuracy: 0.1180 | Loss: 12.2044 | F1: 0.0819\n","\n","Domain: 35\n","x_dp_dom.shape: (159, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 35 | Accuracy: 0.1132 | Loss: 7.8507 | F1: 0.0995\n","\n","Domain: 36\n","x_dp_dom.shape: (155, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 36 | Accuracy: 0.0516 | Loss: 29.8475 | F1: 0.0061\n","\n","Domain: 37\n","x_dp_dom.shape: (154, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 37 | Accuracy: 0.0584 | Loss: 28.9229 | F1: 0.0089\n","\n","Domain: 38\n","x_dp_dom.shape: (158, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 38 | Accuracy: 0.1772 | Loss: 24.3218 | F1: 0.0872\n","\n","Domain: 39\n","x_dp_dom.shape: (165, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 39 | Accuracy: 0.0848 | Loss: 22.5808 | F1: 0.1019\n","\n","Domain: 40\n","x_dp_dom.shape: (155, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 40 | Accuracy: 0.0452 | Loss: 34.4178 | F1: 0.0060\n","\n","Domain: 41\n","x_dp_dom.shape: (156, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 41 | Accuracy: 0.1923 | Loss: 9.3036 | F1: 0.2618\n","\n","Domain: 42\n","x_dp_dom.shape: (158, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 42 | Accuracy: 0.0823 | Loss: 28.6520 | F1: 0.0207\n","\n","Domain: 43\n","x_dp_dom.shape: (153, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 43 | Accuracy: 0.1176 | Loss: 8.8732 | F1: 0.1438\n","\n","Domain: 44\n","x_dp_dom.shape: (153, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 44 | Accuracy: 0.0719 | Loss: 24.1404 | F1: 0.0137\n","\n","Domain: 45\n","x_dp_dom.shape: (163, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 45 | Accuracy: 0.0798 | Loss: 28.9087 | F1: 0.0139\n","\n","Domain: 46\n","x_dp_dom.shape: (160, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 46 | Accuracy: 0.0875 | Loss: 15.5237 | F1: 0.0395\n","\n","Domain: 47\n","x_dp_dom.shape: (155, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 47 | Accuracy: 0.0581 | Loss: 22.7070 | F1: 0.0094\n","\n","Domain: 48\n","x_dp_dom.shape: (159, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 48 | Accuracy: 0.0881 | Loss: 30.7738 | F1: 0.0213\n","\n","Domain: 49\n","x_dp_dom.shape: (164, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 49 | Accuracy: 0.0793 | Loss: 29.7942 | F1: 0.0129\n","\n","Domain: 50\n","x_dp_dom.shape: (153, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 50 | Accuracy: 0.0850 | Loss: 26.7635 | F1: 0.0187\n","\n","Domain: 51\n","x_dp_dom.shape: (157, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 51 | Accuracy: 0.0764 | Loss: 23.3564 | F1: 0.0150\n","\n","Domain: 52\n","x_dp_dom.shape: (153, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 52 | Accuracy: 0.0458 | Loss: 29.7055 | F1: 0.0053\n","\n","Domain: 53\n","x_dp_dom.shape: (159, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 53 | Accuracy: 0.0818 | Loss: 10.7391 | F1: 0.0598\n","\n","Domain: 54\n","x_dp_dom.shape: (153, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 54 | Accuracy: 0.0392 | Loss: 21.0959 | F1: 0.0060\n","\n","Domain: 55\n","x_dp_dom.shape: (160, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 55 | Accuracy: 0.0813 | Loss: 30.7743 | F1: 0.0149\n","\n","Domain: 56\n","x_dp_dom.shape: (153, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 56 | Accuracy: 0.0719 | Loss: 22.4526 | F1: 0.0349\n","\n","Domain: 57\n","x_dp_dom.shape: (153, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 57 | Accuracy: 0.0719 | Loss: 31.6717 | F1: 0.0149\n","\n","Domain: 58\n","x_dp_dom.shape: (149, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 58 | Accuracy: 0.0336 | Loss: 16.9030 | F1: 0.0199\n","\n","Domain: 59\n","x_dp_dom.shape: (154, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 59 | Accuracy: 0.0519 | Loss: 30.9898 | F1: 0.0079\n","\n","Domain: 60\n","x_dp_dom.shape: (158, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 60 | Accuracy: 0.0886 | Loss: 24.2537 | F1: 0.0732\n","\n","Domain: 61\n","x_dp_dom.shape: (158, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 61 | Accuracy: 0.0696 | Loss: 30.0189 | F1: 0.0317\n","\n","Domain: 62\n","x_dp_dom.shape: (158, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 62 | Accuracy: 0.0759 | Loss: 28.3305 | F1: 0.0125\n","\n","Domain: 63\n","x_dp_dom.shape: (153, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 63 | Accuracy: 0.0719 | Loss: 19.2177 | F1: 0.0121\n","\n","Domain: 64\n","x_dp_dom.shape: (154, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 64 | Accuracy: 0.0455 | Loss: 26.3551 | F1: 0.0049\n","\n","Domain: 65\n","x_dp_dom.shape: (161, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 65 | Accuracy: 0.2547 | Loss: 23.9945 | F1: 0.1993\n","\n","Domain: 66\n","x_dp_dom.shape: (153, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 66 | Accuracy: 0.0458 | Loss: 36.7043 | F1: 0.0337\n","\n","Domain: 67\n","x_dp_dom.shape: (153, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 67 | Accuracy: 0.0458 | Loss: 21.2579 | F1: 0.0058\n","\n","Domain: 68\n","x_dp_dom.shape: (154, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 68 | Accuracy: 0.0779 | Loss: 31.4595 | F1: 0.0272\n","\n","Domain: 69\n","x_dp_dom.shape: (153, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 69 | Accuracy: 0.1503 | Loss: 23.1097 | F1: 0.1358\n","\n","Domain: 70\n","x_dp_dom.shape: (153, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 70 | Accuracy: 0.0654 | Loss: 26.8731 | F1: 0.0651\n","\n","Domain: 71\n","x_dp_dom.shape: (155, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 71 | Accuracy: 0.0387 | Loss: 20.4682 | F1: 0.0336\n","\n","Domain: 72\n","x_dp_dom.shape: (153, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 72 | Accuracy: 0.0327 | Loss: 26.4606 | F1: 0.0035\n","\n","Domain: 73\n","x_dp_dom.shape: (152, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 73 | Accuracy: 0.1776 | Loss: 10.2091 | F1: 0.1553\n","\n","Domain: 74\n","x_dp_dom.shape: (146, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 74 | Accuracy: 0.0205 | Loss: 23.1950 | F1: 0.0021\n","\n","Domain: 75\n","x_dp_dom.shape: (153, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 75 | Accuracy: 0.0458 | Loss: 28.5941 | F1: 0.0047\n","\n","Mean accuracy for run 0: 0.0827\n","Mean F1 for run 0: 0.0412\n","\n","Source class: WAL\n","\n","x_df.shape: (11483, 3, 128) | np.unique(y_df): [0 1 2 3]\n","\n","Training on Df data...\n","\tEpoch 10/100 - Train loss: 0.1084 - Val accuracy: 0.9512 - Val loss: 0.1317 - Val F1: 0.9513 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.0476 - Val accuracy: 0.9560 - Val loss: 0.1254 - Val F1: 0.9560 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.0212 - Val accuracy: 0.9599 - Val loss: 0.1267 - Val F1: 0.9599 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.0122 - Val accuracy: 0.9604 - Val loss: 0.1415 - Val F1: 0.9604 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.0067 - Val accuracy: 0.9617 - Val loss: 0.1453 - Val F1: 0.9617 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.0043 - Val accuracy: 0.9643 - Val loss: 0.1515 - Val F1: 0.9643 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0034 - Val accuracy: 0.9630 - Val loss: 0.1596 - Val F1: 0.9630 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0031 - Val accuracy: 0.9630 - Val loss: 0.1775 - Val F1: 0.9630 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0015 - Val accuracy: 0.9630 - Val loss: 0.1701 - Val F1: 0.9630 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0014 - Val accuracy: 0.9639 - Val loss: 0.1727 - Val F1: 0.9639 - LR: 0.00e+00\n","\tBest epoch: 22 - Best val accuracy: 0.9604 - Best val loss: 0.1172 - Best val F1: 0.9604\n","\n","Domain: 15\n","x_dp_dom.shape: (161, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 15 | Accuracy: 0.0124 | Loss: 22.4635 | F1: 0.0057\n","\n","Domain: 16\n","x_dp_dom.shape: (165, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 16 | Accuracy: 0.1697 | Loss: 20.3599 | F1: 0.0525\n","\n","Domain: 17\n","x_dp_dom.shape: (164, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 17 | Accuracy: 0.2012 | Loss: 14.6051 | F1: 0.0913\n","\n","Domain: 18\n","x_dp_dom.shape: (166, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 18 | Accuracy: 0.1687 | Loss: 20.0389 | F1: 0.0487\n","\n","Domain: 19\n","x_dp_dom.shape: (165, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 19 | Accuracy: 0.1818 | Loss: 19.9058 | F1: 0.0708\n","\n","Domain: 20\n","x_dp_dom.shape: (162, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 20 | Accuracy: 0.1667 | Loss: 20.4708 | F1: 0.0539\n","\n","Domain: 21\n","x_dp_dom.shape: (159, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 21 | Accuracy: 0.1761 | Loss: 18.4494 | F1: 0.0527\n","\n","Domain: 22\n","x_dp_dom.shape: (165, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 22 | Accuracy: 0.1697 | Loss: 20.6342 | F1: 0.0498\n","\n","Domain: 23\n","x_dp_dom.shape: (164, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 23 | Accuracy: 0.2012 | Loss: 34.6437 | F1: 0.0870\n","\n","Domain: 24\n","x_dp_dom.shape: (162, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 24 | Accuracy: 0.1420 | Loss: 24.2211 | F1: 0.0622\n","\n","Domain: 25\n","x_dp_dom.shape: (166, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 25 | Accuracy: 0.1687 | Loss: 17.5420 | F1: 0.0487\n","\n","Domain: 26\n","x_dp_dom.shape: (153, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 26 | Accuracy: 0.1699 | Loss: 20.1999 | F1: 0.0532\n","\n","Domain: 27\n","x_dp_dom.shape: (165, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 27 | Accuracy: 0.2485 | Loss: 24.0144 | F1: 0.1116\n","\n","Domain: 28\n","x_dp_dom.shape: (153, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 28 | Accuracy: 0.1765 | Loss: 31.0247 | F1: 0.0618\n","\n","Domain: 29\n","x_dp_dom.shape: (153, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 29 | Accuracy: 0.1830 | Loss: 24.7951 | F1: 0.0566\n","\n","Domain: 30\n","x_dp_dom.shape: (161, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 30 | Accuracy: 0.2174 | Loss: 14.4394 | F1: 0.0916\n","\n","Domain: 31\n","x_dp_dom.shape: (154, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 31 | Accuracy: 0.2338 | Loss: 55.4488 | F1: 0.1707\n","\n","Domain: 32\n","x_dp_dom.shape: (163, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 32 | Accuracy: 0.2147 | Loss: 16.2485 | F1: 0.0925\n","\n","Domain: 33\n","x_dp_dom.shape: (156, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 33 | Accuracy: 0.1731 | Loss: 18.0672 | F1: 0.0530\n","\n","Domain: 34\n","x_dp_dom.shape: (161, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 34 | Accuracy: 0.1491 | Loss: 64.0287 | F1: 0.1118\n","\n","Domain: 35\n","x_dp_dom.shape: (159, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 35 | Accuracy: 0.1761 | Loss: 31.2838 | F1: 0.0527\n","\n","Domain: 36\n","x_dp_dom.shape: (155, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 36 | Accuracy: 0.1806 | Loss: 20.8614 | F1: 0.0556\n","\n","Domain: 37\n","x_dp_dom.shape: (154, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 37 | Accuracy: 0.1753 | Loss: 19.6215 | F1: 0.0722\n","\n","Domain: 38\n","x_dp_dom.shape: (158, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 38 | Accuracy: 0.2215 | Loss: 63.9179 | F1: 0.1564\n","\n","Domain: 39\n","x_dp_dom.shape: (165, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 39 | Accuracy: 0.1333 | Loss: 19.4451 | F1: 0.0543\n","\n","Domain: 40\n","x_dp_dom.shape: (155, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 40 | Accuracy: 0.2000 | Loss: 16.8900 | F1: 0.0775\n","\n","Domain: 41\n","x_dp_dom.shape: (156, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 41 | Accuracy: 0.2564 | Loss: 8.1588 | F1: 0.2130\n","\n","Domain: 42\n","x_dp_dom.shape: (158, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 42 | Accuracy: 0.2468 | Loss: 26.6617 | F1: 0.1190\n","\n","Domain: 43\n","x_dp_dom.shape: (153, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 43 | Accuracy: 0.1373 | Loss: 58.4305 | F1: 0.1301\n","\n","Domain: 44\n","x_dp_dom.shape: (153, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 44 | Accuracy: 0.1830 | Loss: 20.3589 | F1: 0.0579\n","\n","Domain: 45\n","x_dp_dom.shape: (163, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 45 | Accuracy: 0.1718 | Loss: 15.7306 | F1: 0.0504\n","\n","Domain: 46\n","x_dp_dom.shape: (160, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 46 | Accuracy: 0.1750 | Loss: 24.5881 | F1: 0.0521\n","\n","Domain: 47\n","x_dp_dom.shape: (155, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 47 | Accuracy: 0.1806 | Loss: 22.6285 | F1: 0.0556\n","\n","Domain: 48\n","x_dp_dom.shape: (159, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 48 | Accuracy: 0.1761 | Loss: 26.1800 | F1: 0.0527\n","\n","Domain: 49\n","x_dp_dom.shape: (164, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 49 | Accuracy: 0.1707 | Loss: 13.4479 | F1: 0.0562\n","\n","Domain: 50\n","x_dp_dom.shape: (153, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 50 | Accuracy: 0.1765 | Loss: 25.5875 | F1: 0.0549\n","\n","Domain: 51\n","x_dp_dom.shape: (157, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 51 | Accuracy: 0.1529 | Loss: 27.3137 | F1: 0.0674\n","\n","Domain: 52\n","x_dp_dom.shape: (153, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 52 | Accuracy: 0.1830 | Loss: 17.7788 | F1: 0.0566\n","\n","Domain: 53\n","x_dp_dom.shape: (159, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 53 | Accuracy: 0.1447 | Loss: 55.5976 | F1: 0.1141\n","\n","Domain: 54\n","x_dp_dom.shape: (153, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 54 | Accuracy: 0.0915 | Loss: 29.7458 | F1: 0.0691\n","\n","Domain: 55\n","x_dp_dom.shape: (160, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 55 | Accuracy: 0.1313 | Loss: 19.5832 | F1: 0.0406\n","\n","Domain: 56\n","x_dp_dom.shape: (153, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 56 | Accuracy: 0.1830 | Loss: 27.9189 | F1: 0.0566\n","\n","Domain: 57\n","x_dp_dom.shape: (153, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 57 | Accuracy: 0.1569 | Loss: 20.5569 | F1: 0.0523\n","\n","Domain: 58\n","x_dp_dom.shape: (149, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 58 | Accuracy: 0.0134 | Loss: 62.9430 | F1: 0.0011\n","\n","Domain: 59\n","x_dp_dom.shape: (154, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 59 | Accuracy: 0.1818 | Loss: 26.0975 | F1: 0.0559\n","\n","Domain: 60\n","x_dp_dom.shape: (158, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 60 | Accuracy: 0.1266 | Loss: 57.5720 | F1: 0.0958\n","\n","Domain: 61\n","x_dp_dom.shape: (158, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 61 | Accuracy: 0.2278 | Loss: 25.4568 | F1: 0.1139\n","\n","Domain: 62\n","x_dp_dom.shape: (158, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 62 | Accuracy: 0.1772 | Loss: 12.3696 | F1: 0.0564\n","\n","Domain: 63\n","x_dp_dom.shape: (153, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 63 | Accuracy: 0.1895 | Loss: 23.6022 | F1: 0.0684\n","\n","Domain: 64\n","x_dp_dom.shape: (154, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 64 | Accuracy: 0.1818 | Loss: 17.4562 | F1: 0.0559\n","\n","Domain: 65\n","x_dp_dom.shape: (161, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 65 | Accuracy: 0.0807 | Loss: 20.0617 | F1: 0.0350\n","\n","Domain: 66\n","x_dp_dom.shape: (153, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 66 | Accuracy: 0.0327 | Loss: 19.0200 | F1: 0.0097\n","\n","Domain: 67\n","x_dp_dom.shape: (153, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 67 | Accuracy: 0.1699 | Loss: 35.7689 | F1: 0.0691\n","\n","Domain: 68\n","x_dp_dom.shape: (154, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 68 | Accuracy: 0.1818 | Loss: 26.0281 | F1: 0.0559\n","\n","Domain: 69\n","x_dp_dom.shape: (153, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 69 | Accuracy: 0.0915 | Loss: 27.7825 | F1: 0.0307\n","\n","Domain: 70\n","x_dp_dom.shape: (153, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 70 | Accuracy: 0.2222 | Loss: 27.9839 | F1: 0.0922\n","\n","Domain: 71\n","x_dp_dom.shape: (155, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 71 | Accuracy: 0.1935 | Loss: 23.6763 | F1: 0.0726\n","\n","Domain: 72\n","x_dp_dom.shape: (153, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 72 | Accuracy: 0.1830 | Loss: 23.4545 | F1: 0.0576\n","\n","Domain: 73\n","x_dp_dom.shape: (152, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 73 | Accuracy: 0.0789 | Loss: 62.3210 | F1: 0.0600\n","\n","Domain: 74\n","x_dp_dom.shape: (146, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 74 | Accuracy: 0.1918 | Loss: 35.2274 | F1: 0.0624\n","\n","Domain: 75\n","x_dp_dom.shape: (153, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 75 | Accuracy: 0.1830 | Loss: 15.3669 | F1: 0.0586\n","\n","Mean accuracy for run 1: 0.1678\n","Mean F1 for run 1: 0.0696\n","\n","Source class: WAL\n","\n","x_df.shape: (11483, 3, 128) | np.unique(y_df): [0 1 2 3]\n","\n","Training on Df data...\n","\tEpoch 10/100 - Train loss: 0.0983 - Val accuracy: 0.9534 - Val loss: 0.1349 - Val F1: 0.9534 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.0442 - Val accuracy: 0.9586 - Val loss: 0.1233 - Val F1: 0.9586 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.0196 - Val accuracy: 0.9626 - Val loss: 0.1260 - Val F1: 0.9626 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.0118 - Val accuracy: 0.9634 - Val loss: 0.1353 - Val F1: 0.9634 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.0058 - Val accuracy: 0.9621 - Val loss: 0.1395 - Val F1: 0.9621 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.0030 - Val accuracy: 0.9621 - Val loss: 0.1446 - Val F1: 0.9621 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0037 - Val accuracy: 0.9626 - Val loss: 0.1577 - Val F1: 0.9625 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0030 - Val accuracy: 0.9608 - Val loss: 0.1791 - Val F1: 0.9608 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0019 - Val accuracy: 0.9673 - Val loss: 0.1534 - Val F1: 0.9673 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0015 - Val accuracy: 0.9660 - Val loss: 0.1520 - Val F1: 0.9660 - LR: 0.00e+00\n","\tBest epoch: 25 - Best val accuracy: 0.9647 - Best val loss: 0.1183 - Best val F1: 0.9647\n","\n","Domain: 15\n","x_dp_dom.shape: (161, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 15 | Accuracy: 0.2236 | Loss: 23.1177 | F1: 0.1479\n","\n","Domain: 16\n","x_dp_dom.shape: (165, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 16 | Accuracy: 0.2485 | Loss: 25.6278 | F1: 0.1834\n","\n","Domain: 17\n","x_dp_dom.shape: (164, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 17 | Accuracy: 0.2317 | Loss: 20.6204 | F1: 0.1717\n","\n","Domain: 18\n","x_dp_dom.shape: (166, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 18 | Accuracy: 0.2410 | Loss: 24.3218 | F1: 0.1286\n","\n","Domain: 19\n","x_dp_dom.shape: (165, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 19 | Accuracy: 0.2485 | Loss: 23.3562 | F1: 0.1834\n","\n","Domain: 20\n","x_dp_dom.shape: (162, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 20 | Accuracy: 0.2531 | Loss: 23.3008 | F1: 0.1759\n","\n","Domain: 21\n","x_dp_dom.shape: (159, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 21 | Accuracy: 0.2516 | Loss: 27.7418 | F1: 0.1888\n","\n","Domain: 22\n","x_dp_dom.shape: (165, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 22 | Accuracy: 0.2424 | Loss: 25.9756 | F1: 0.1693\n","\n","Domain: 23\n","x_dp_dom.shape: (164, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 23 | Accuracy: 0.2500 | Loss: 29.4312 | F1: 0.1762\n","\n","Domain: 24\n","x_dp_dom.shape: (162, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 24 | Accuracy: 0.1605 | Loss: 23.4040 | F1: 0.1264\n","\n","Domain: 25\n","x_dp_dom.shape: (166, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 25 | Accuracy: 0.2470 | Loss: 24.2127 | F1: 0.1765\n","\n","Domain: 26\n","x_dp_dom.shape: (153, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 26 | Accuracy: 0.2092 | Loss: 25.4563 | F1: 0.1013\n","\n","Domain: 27\n","x_dp_dom.shape: (165, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 27 | Accuracy: 0.2485 | Loss: 26.8005 | F1: 0.1834\n","\n","Domain: 28\n","x_dp_dom.shape: (153, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 28 | Accuracy: 0.2288 | Loss: 26.4843 | F1: 0.1816\n","\n","Domain: 29\n","x_dp_dom.shape: (153, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 29 | Accuracy: 0.2222 | Loss: 26.3798 | F1: 0.1141\n","\n","Domain: 30\n","x_dp_dom.shape: (161, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 30 | Accuracy: 0.2422 | Loss: 13.7707 | F1: 0.0976\n","\n","Domain: 31\n","x_dp_dom.shape: (154, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 31 | Accuracy: 0.2338 | Loss: 19.6485 | F1: 0.1734\n","\n","Domain: 32\n","x_dp_dom.shape: (163, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 32 | Accuracy: 0.2331 | Loss: 24.8855 | F1: 0.1648\n","\n","Domain: 33\n","x_dp_dom.shape: (156, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 33 | Accuracy: 0.2372 | Loss: 24.5234 | F1: 0.1363\n","\n","Domain: 34\n","x_dp_dom.shape: (161, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 34 | Accuracy: 0.2112 | Loss: 22.6328 | F1: 0.1418\n","\n","Domain: 35\n","x_dp_dom.shape: (159, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 35 | Accuracy: 0.2579 | Loss: 29.4128 | F1: 0.1850\n","\n","Domain: 36\n","x_dp_dom.shape: (155, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 36 | Accuracy: 0.2258 | Loss: 22.1845 | F1: 0.1523\n","\n","Domain: 37\n","x_dp_dom.shape: (154, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 37 | Accuracy: 0.2338 | Loss: 24.3111 | F1: 0.1734\n","\n","Domain: 38\n","x_dp_dom.shape: (158, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 38 | Accuracy: 0.2468 | Loss: 25.3648 | F1: 0.1232\n","\n","Domain: 39\n","x_dp_dom.shape: (165, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 39 | Accuracy: 0.1879 | Loss: 25.1204 | F1: 0.1456\n","\n","Domain: 40\n","x_dp_dom.shape: (155, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 40 | Accuracy: 0.2387 | Loss: 22.5588 | F1: 0.1852\n","\n","Domain: 41\n","x_dp_dom.shape: (156, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 41 | Accuracy: 0.1603 | Loss: 16.2224 | F1: 0.0979\n","\n","Domain: 42\n","x_dp_dom.shape: (158, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 42 | Accuracy: 0.2152 | Loss: 23.6480 | F1: 0.0932\n","\n","Domain: 43\n","x_dp_dom.shape: (153, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 43 | Accuracy: 0.2157 | Loss: 21.5424 | F1: 0.1718\n","\n","Domain: 44\n","x_dp_dom.shape: (153, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 44 | Accuracy: 0.2288 | Loss: 25.4744 | F1: 0.1704\n","\n","Domain: 45\n","x_dp_dom.shape: (163, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 45 | Accuracy: 0.2515 | Loss: 21.0361 | F1: 0.1773\n","\n","Domain: 46\n","x_dp_dom.shape: (160, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 46 | Accuracy: 0.2562 | Loss: 26.7224 | F1: 0.1896\n","\n","Domain: 47\n","x_dp_dom.shape: (155, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 47 | Accuracy: 0.2258 | Loss: 26.2296 | F1: 0.1776\n","\n","Domain: 48\n","x_dp_dom.shape: (159, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 48 | Accuracy: 0.2453 | Loss: 26.7022 | F1: 0.1641\n","\n","Domain: 49\n","x_dp_dom.shape: (164, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 49 | Accuracy: 0.2500 | Loss: 17.1394 | F1: 0.1640\n","\n","Domain: 50\n","x_dp_dom.shape: (153, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 50 | Accuracy: 0.2092 | Loss: 27.7054 | F1: 0.1011\n","\n","Domain: 51\n","x_dp_dom.shape: (157, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 51 | Accuracy: 0.1847 | Loss: 27.4406 | F1: 0.1474\n","\n","Domain: 52\n","x_dp_dom.shape: (153, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 52 | Accuracy: 0.2288 | Loss: 26.5127 | F1: 0.1678\n","\n","Domain: 53\n","x_dp_dom.shape: (159, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 53 | Accuracy: 0.2516 | Loss: 24.8066 | F1: 0.1858\n","\n","Domain: 54\n","x_dp_dom.shape: (153, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 54 | Accuracy: 0.1765 | Loss: 24.5504 | F1: 0.1574\n","\n","Domain: 55\n","x_dp_dom.shape: (160, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 55 | Accuracy: 0.2562 | Loss: 23.6898 | F1: 0.1837\n","\n","Domain: 56\n","x_dp_dom.shape: (153, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 56 | Accuracy: 0.2288 | Loss: 28.0668 | F1: 0.1704\n","\n","Domain: 57\n","x_dp_dom.shape: (153, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 57 | Accuracy: 0.2092 | Loss: 24.1483 | F1: 0.1331\n","\n","Domain: 58\n","x_dp_dom.shape: (149, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 58 | Accuracy: 0.1141 | Loss: 29.2632 | F1: 0.1127\n","\n","Domain: 59\n","x_dp_dom.shape: (154, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 59 | Accuracy: 0.2273 | Loss: 25.6205 | F1: 0.1649\n","\n","Domain: 60\n","x_dp_dom.shape: (158, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 60 | Accuracy: 0.2405 | Loss: 24.9724 | F1: 0.1848\n","\n","Domain: 61\n","x_dp_dom.shape: (158, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 61 | Accuracy: 0.2468 | Loss: 28.1769 | F1: 0.1588\n","\n","Domain: 62\n","x_dp_dom.shape: (158, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 62 | Accuracy: 0.2532 | Loss: 21.5212 | F1: 0.1841\n","\n","Domain: 63\n","x_dp_dom.shape: (153, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 63 | Accuracy: 0.2026 | Loss: 29.1892 | F1: 0.1598\n","\n","Domain: 64\n","x_dp_dom.shape: (154, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 64 | Accuracy: 0.2273 | Loss: 25.4957 | F1: 0.1775\n","\n","Domain: 65\n","x_dp_dom.shape: (161, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 65 | Accuracy: 0.1801 | Loss: 21.0336 | F1: 0.1344\n","\n","Domain: 66\n","x_dp_dom.shape: (153, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 66 | Accuracy: 0.1961 | Loss: 19.8480 | F1: 0.0763\n","\n","Domain: 67\n","x_dp_dom.shape: (153, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 67 | Accuracy: 0.2222 | Loss: 25.5965 | F1: 0.1487\n","\n","Domain: 68\n","x_dp_dom.shape: (154, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 68 | Accuracy: 0.2338 | Loss: 29.4189 | F1: 0.1203\n","\n","Domain: 69\n","x_dp_dom.shape: (153, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 69 | Accuracy: 0.2157 | Loss: 26.9829 | F1: 0.1589\n","\n","Domain: 70\n","x_dp_dom.shape: (153, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 70 | Accuracy: 0.2288 | Loss: 28.4465 | F1: 0.1518\n","\n","Domain: 71\n","x_dp_dom.shape: (155, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 71 | Accuracy: 0.2387 | Loss: 27.9627 | F1: 0.1712\n","\n","Domain: 72\n","x_dp_dom.shape: (153, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 72 | Accuracy: 0.2288 | Loss: 26.7904 | F1: 0.1847\n","\n","Domain: 73\n","x_dp_dom.shape: (152, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 73 | Accuracy: 0.2303 | Loss: 26.7761 | F1: 0.1891\n","\n","Domain: 74\n","x_dp_dom.shape: (146, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 74 | Accuracy: 0.2123 | Loss: 25.2464 | F1: 0.0916\n","\n","Domain: 75\n","x_dp_dom.shape: (153, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 75 | Accuracy: 0.2288 | Loss: 24.0212 | F1: 0.1758\n","\n","Mean accuracy for run 2: 0.2258\n","Mean F1 for run 2: 0.1555\n","\n","Source class: WAL\n","\n","x_df.shape: (11483, 3, 128) | np.unique(y_df): [0 1 2 3]\n","\n","Training on Df data...\n","\tEpoch 10/100 - Train loss: 0.1032 - Val accuracy: 0.9525 - Val loss: 0.1285 - Val F1: 0.9526 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.0465 - Val accuracy: 0.9613 - Val loss: 0.1243 - Val F1: 0.9612 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.0215 - Val accuracy: 0.9604 - Val loss: 0.1490 - Val F1: 0.9603 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.0093 - Val accuracy: 0.9630 - Val loss: 0.1319 - Val F1: 0.9630 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.0104 - Val accuracy: 0.9630 - Val loss: 0.1378 - Val F1: 0.9630 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.0046 - Val accuracy: 0.9617 - Val loss: 0.1506 - Val F1: 0.9617 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0032 - Val accuracy: 0.9599 - Val loss: 0.1507 - Val F1: 0.9600 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0031 - Val accuracy: 0.9643 - Val loss: 0.1580 - Val F1: 0.9643 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0025 - Val accuracy: 0.9630 - Val loss: 0.1560 - Val F1: 0.9630 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0017 - Val accuracy: 0.9621 - Val loss: 0.1668 - Val F1: 0.9621 - LR: 0.00e+00\n","\tBest epoch: 22 - Best val accuracy: 0.9591 - Best val loss: 0.1185 - Best val F1: 0.9591\n","\n","Domain: 15\n","x_dp_dom.shape: (161, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 15 | Accuracy: 0.0745 | Loss: 12.8351 | F1: 0.0108\n","\n","Domain: 16\n","x_dp_dom.shape: (165, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 16 | Accuracy: 0.2485 | Loss: 10.0362 | F1: 0.1750\n","\n","Domain: 17\n","x_dp_dom.shape: (164, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 17 | Accuracy: 0.1646 | Loss: 12.6780 | F1: 0.1269\n","\n","Domain: 18\n","x_dp_dom.shape: (166, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 18 | Accuracy: 0.2470 | Loss: 10.8677 | F1: 0.1369\n","\n","Domain: 19\n","x_dp_dom.shape: (165, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 19 | Accuracy: 0.1455 | Loss: 12.6088 | F1: 0.1093\n","\n","Domain: 20\n","x_dp_dom.shape: (162, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 20 | Accuracy: 0.1543 | Loss: 7.7029 | F1: 0.1195\n","\n","Domain: 21\n","x_dp_dom.shape: (159, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 21 | Accuracy: 0.2390 | Loss: 10.5688 | F1: 0.1546\n","\n","Domain: 22\n","x_dp_dom.shape: (165, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 22 | Accuracy: 0.1879 | Loss: 13.9268 | F1: 0.1404\n","\n","Domain: 23\n","x_dp_dom.shape: (164, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 23 | Accuracy: 0.2439 | Loss: 11.1250 | F1: 0.0988\n","\n","Domain: 24\n","x_dp_dom.shape: (162, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 24 | Accuracy: 0.2284 | Loss: 5.2223 | F1: 0.1686\n","\n","Domain: 25\n","x_dp_dom.shape: (166, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 25 | Accuracy: 0.2108 | Loss: 15.9056 | F1: 0.1591\n","\n","Domain: 26\n","x_dp_dom.shape: (153, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 26 | Accuracy: 0.1699 | Loss: 13.6077 | F1: 0.0914\n","\n","Domain: 27\n","x_dp_dom.shape: (165, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 27 | Accuracy: 0.2485 | Loss: 13.0062 | F1: 0.1834\n","\n","Domain: 28\n","x_dp_dom.shape: (153, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 28 | Accuracy: 0.2288 | Loss: 9.0418 | F1: 0.1730\n","\n","Domain: 29\n","x_dp_dom.shape: (153, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 29 | Accuracy: 0.1961 | Loss: 9.7646 | F1: 0.0893\n","\n","Domain: 30\n","x_dp_dom.shape: (161, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 30 | Accuracy: 0.2112 | Loss: 8.0158 | F1: 0.1661\n","\n","Domain: 31\n","x_dp_dom.shape: (154, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 31 | Accuracy: 0.0974 | Loss: 41.0605 | F1: 0.0770\n","\n","Domain: 32\n","x_dp_dom.shape: (163, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 32 | Accuracy: 0.2209 | Loss: 8.0495 | F1: 0.1089\n","\n","Domain: 33\n","x_dp_dom.shape: (156, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 33 | Accuracy: 0.1346 | Loss: 10.0174 | F1: 0.0594\n","\n","Domain: 34\n","x_dp_dom.shape: (161, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 34 | Accuracy: 0.1739 | Loss: 59.3386 | F1: 0.1359\n","\n","Domain: 35\n","x_dp_dom.shape: (159, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 35 | Accuracy: 0.2579 | Loss: 17.7539 | F1: 0.1909\n","\n","Domain: 36\n","x_dp_dom.shape: (155, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 36 | Accuracy: 0.1742 | Loss: 11.6335 | F1: 0.1463\n","\n","Domain: 37\n","x_dp_dom.shape: (154, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 37 | Accuracy: 0.1883 | Loss: 8.3386 | F1: 0.1393\n","\n","Domain: 38\n","x_dp_dom.shape: (158, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 38 | Accuracy: 0.1772 | Loss: 72.0797 | F1: 0.1431\n","\n","Domain: 39\n","x_dp_dom.shape: (165, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 39 | Accuracy: 0.1455 | Loss: 9.6648 | F1: 0.1082\n","\n","Domain: 40\n","x_dp_dom.shape: (155, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 40 | Accuracy: 0.2323 | Loss: 8.6101 | F1: 0.1731\n","\n","Domain: 41\n","x_dp_dom.shape: (156, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 41 | Accuracy: 0.2244 | Loss: 12.5540 | F1: 0.1976\n","\n","Domain: 42\n","x_dp_dom.shape: (158, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 42 | Accuracy: 0.2342 | Loss: 8.1056 | F1: 0.0963\n","\n","Domain: 43\n","x_dp_dom.shape: (153, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 43 | Accuracy: 0.1307 | Loss: 45.3585 | F1: 0.1227\n","\n","Domain: 44\n","x_dp_dom.shape: (153, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 44 | Accuracy: 0.0850 | Loss: 14.1581 | F1: 0.0614\n","\n","Domain: 45\n","x_dp_dom.shape: (163, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 45 | Accuracy: 0.1227 | Loss: 12.0625 | F1: 0.0809\n","\n","Domain: 46\n","x_dp_dom.shape: (160, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 46 | Accuracy: 0.2250 | Loss: 16.4312 | F1: 0.1723\n","\n","Domain: 47\n","x_dp_dom.shape: (155, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 47 | Accuracy: 0.2323 | Loss: 12.0547 | F1: 0.1729\n","\n","Domain: 48\n","x_dp_dom.shape: (159, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 48 | Accuracy: 0.2767 | Loss: 6.7873 | F1: 0.1757\n","\n","Domain: 49\n","x_dp_dom.shape: (164, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 49 | Accuracy: 0.1585 | Loss: 9.0477 | F1: 0.1221\n","\n","Domain: 50\n","x_dp_dom.shape: (153, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 50 | Accuracy: 0.5098 | Loss: 2.4938 | F1: 0.5198\n","\n","Domain: 51\n","x_dp_dom.shape: (157, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 51 | Accuracy: 0.2038 | Loss: 9.8907 | F1: 0.1777\n","\n","Domain: 52\n","x_dp_dom.shape: (153, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 52 | Accuracy: 0.2222 | Loss: 8.9718 | F1: 0.0919\n","\n","Domain: 53\n","x_dp_dom.shape: (159, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 53 | Accuracy: 0.2516 | Loss: 50.7588 | F1: 0.1829\n","\n","Domain: 54\n","x_dp_dom.shape: (153, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 54 | Accuracy: 0.0719 | Loss: 9.0941 | F1: 0.0431\n","\n","Domain: 55\n","x_dp_dom.shape: (160, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 55 | Accuracy: 0.1187 | Loss: 7.4582 | F1: 0.0565\n","\n","Domain: 56\n","x_dp_dom.shape: (153, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 56 | Accuracy: 0.2353 | Loss: 8.6935 | F1: 0.1808\n","\n","Domain: 57\n","x_dp_dom.shape: (153, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 57 | Accuracy: 0.1046 | Loss: 8.3820 | F1: 0.0546\n","\n","Domain: 58\n","x_dp_dom.shape: (149, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 58 | Accuracy: 0.1611 | Loss: 40.1345 | F1: 0.1515\n","\n","Domain: 59\n","x_dp_dom.shape: (154, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 59 | Accuracy: 0.2727 | Loss: 4.3157 | F1: 0.1895\n","\n","Domain: 60\n","x_dp_dom.shape: (158, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 60 | Accuracy: 0.1266 | Loss: 48.9284 | F1: 0.0958\n","\n","Domain: 61\n","x_dp_dom.shape: (158, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 61 | Accuracy: 0.2595 | Loss: 8.4463 | F1: 0.1492\n","\n","Domain: 62\n","x_dp_dom.shape: (158, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 62 | Accuracy: 0.1962 | Loss: 14.6293 | F1: 0.1561\n","\n","Domain: 63\n","x_dp_dom.shape: (153, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 63 | Accuracy: 0.2026 | Loss: 10.1535 | F1: 0.1024\n","\n","Domain: 64\n","x_dp_dom.shape: (154, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 64 | Accuracy: 0.1948 | Loss: 11.2159 | F1: 0.1543\n","\n","Domain: 65\n","x_dp_dom.shape: (161, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 65 | Accuracy: 0.1429 | Loss: 8.5849 | F1: 0.1285\n","\n","Domain: 66\n","x_dp_dom.shape: (153, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 66 | Accuracy: 0.0458 | Loss: 13.6275 | F1: 0.0065\n","\n","Domain: 67\n","x_dp_dom.shape: (153, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 67 | Accuracy: 0.1307 | Loss: 10.1058 | F1: 0.0995\n","\n","Domain: 68\n","x_dp_dom.shape: (154, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 68 | Accuracy: 0.2532 | Loss: 5.9530 | F1: 0.1281\n","\n","Domain: 69\n","x_dp_dom.shape: (153, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 69 | Accuracy: 0.0392 | Loss: 9.9508 | F1: 0.0043\n","\n","Domain: 70\n","x_dp_dom.shape: (153, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 70 | Accuracy: 0.2222 | Loss: 8.2718 | F1: 0.0867\n","\n","Domain: 71\n","x_dp_dom.shape: (155, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 71 | Accuracy: 0.2387 | Loss: 10.2211 | F1: 0.1765\n","\n","Domain: 72\n","x_dp_dom.shape: (153, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 72 | Accuracy: 0.2418 | Loss: 6.1148 | F1: 0.1961\n","\n","Domain: 73\n","x_dp_dom.shape: (152, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 73 | Accuracy: 0.0461 | Loss: 59.7086 | F1: 0.0041\n","\n","Domain: 74\n","x_dp_dom.shape: (146, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 74 | Accuracy: 0.2055 | Loss: 7.2696 | F1: 0.0762\n","\n","Domain: 75\n","x_dp_dom.shape: (153, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 75 | Accuracy: 0.1503 | Loss: 10.7514 | F1: 0.1296\n","\n","Mean accuracy for run 3: 0.1892\n","Mean F1 for run 3: 0.1300\n","\n","Source class: WAL\n","\n","x_df.shape: (11483, 3, 128) | np.unique(y_df): [0 1 2 3]\n","\n","Training on Df data...\n","\tEpoch 10/100 - Train loss: 0.1160 - Val accuracy: 0.9478 - Val loss: 0.1438 - Val F1: 0.9477 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.0517 - Val accuracy: 0.9512 - Val loss: 0.1433 - Val F1: 0.9512 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.0212 - Val accuracy: 0.9560 - Val loss: 0.1351 - Val F1: 0.9560 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.0136 - Val accuracy: 0.9591 - Val loss: 0.1545 - Val F1: 0.9591 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.0093 - Val accuracy: 0.9599 - Val loss: 0.1625 - Val F1: 0.9600 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.0051 - Val accuracy: 0.9599 - Val loss: 0.1697 - Val F1: 0.9599 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0026 - Val accuracy: 0.9617 - Val loss: 0.1731 - Val F1: 0.9617 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0034 - Val accuracy: 0.9608 - Val loss: 0.1772 - Val F1: 0.9608 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0025 - Val accuracy: 0.9604 - Val loss: 0.1839 - Val F1: 0.9604 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0024 - Val accuracy: 0.9595 - Val loss: 0.1816 - Val F1: 0.9595 - LR: 0.00e+00\n","\tBest epoch: 23 - Best val accuracy: 0.9586 - Best val loss: 0.1292 - Best val F1: 0.9587\n","\n","Domain: 15\n","x_dp_dom.shape: (161, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 15 | Accuracy: 0.0124 | Loss: 36.2329 | F1: 0.0066\n","\n","Domain: 16\n","x_dp_dom.shape: (165, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 16 | Accuracy: 0.1818 | Loss: 31.5321 | F1: 0.0668\n","\n","Domain: 17\n","x_dp_dom.shape: (164, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 17 | Accuracy: 0.1890 | Loss: 25.3579 | F1: 0.0803\n","\n","Domain: 18\n","x_dp_dom.shape: (166, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 18 | Accuracy: 0.1687 | Loss: 38.0785 | F1: 0.0487\n","\n","Domain: 19\n","x_dp_dom.shape: (165, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 19 | Accuracy: 0.1697 | Loss: 30.3977 | F1: 0.0492\n","\n","Domain: 20\n","x_dp_dom.shape: (162, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 20 | Accuracy: 0.2346 | Loss: 31.9182 | F1: 0.1164\n","\n","Domain: 21\n","x_dp_dom.shape: (159, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 21 | Accuracy: 0.1887 | Loss: 35.3071 | F1: 0.0749\n","\n","Domain: 22\n","x_dp_dom.shape: (165, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 22 | Accuracy: 0.1697 | Loss: 38.8945 | F1: 0.0492\n","\n","Domain: 23\n","x_dp_dom.shape: (164, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 23 | Accuracy: 0.1707 | Loss: 48.9776 | F1: 0.0498\n","\n","Domain: 24\n","x_dp_dom.shape: (162, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 24 | Accuracy: 0.2160 | Loss: 30.8432 | F1: 0.1013\n","\n","Domain: 25\n","x_dp_dom.shape: (166, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 25 | Accuracy: 0.1687 | Loss: 35.6249 | F1: 0.0487\n","\n","Domain: 26\n","x_dp_dom.shape: (153, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 26 | Accuracy: 0.1830 | Loss: 37.1694 | F1: 0.0566\n","\n","Domain: 27\n","x_dp_dom.shape: (165, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 27 | Accuracy: 0.1636 | Loss: 40.2752 | F1: 0.0477\n","\n","Domain: 28\n","x_dp_dom.shape: (153, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 28 | Accuracy: 0.1830 | Loss: 39.4845 | F1: 0.0566\n","\n","Domain: 29\n","x_dp_dom.shape: (153, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 29 | Accuracy: 0.1830 | Loss: 41.0122 | F1: 0.0566\n","\n","Domain: 30\n","x_dp_dom.shape: (161, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 30 | Accuracy: 0.1988 | Loss: 13.9057 | F1: 0.1077\n","\n","Domain: 31\n","x_dp_dom.shape: (154, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 31 | Accuracy: 0.2338 | Loss: 20.8724 | F1: 0.1707\n","\n","Domain: 32\n","x_dp_dom.shape: (163, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 32 | Accuracy: 0.2147 | Loss: 32.8644 | F1: 0.0916\n","\n","Domain: 33\n","x_dp_dom.shape: (156, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 33 | Accuracy: 0.2115 | Loss: 27.6674 | F1: 0.0869\n","\n","Domain: 34\n","x_dp_dom.shape: (161, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 34 | Accuracy: 0.1801 | Loss: 16.5696 | F1: 0.1321\n","\n","Domain: 35\n","x_dp_dom.shape: (159, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 35 | Accuracy: 0.1447 | Loss: 41.8255 | F1: 0.0445\n","\n","Domain: 36\n","x_dp_dom.shape: (155, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 36 | Accuracy: 0.2194 | Loss: 34.3994 | F1: 0.1014\n","\n","Domain: 37\n","x_dp_dom.shape: (154, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 37 | Accuracy: 0.1948 | Loss: 31.7162 | F1: 0.0735\n","\n","Domain: 38\n","x_dp_dom.shape: (158, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 38 | Accuracy: 0.2278 | Loss: 20.7480 | F1: 0.1596\n","\n","Domain: 39\n","x_dp_dom.shape: (165, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 39 | Accuracy: 0.1333 | Loss: 34.1354 | F1: 0.0645\n","\n","Domain: 40\n","x_dp_dom.shape: (155, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 40 | Accuracy: 0.1484 | Loss: 29.6953 | F1: 0.0560\n","\n","Domain: 41\n","x_dp_dom.shape: (156, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 41 | Accuracy: 0.4936 | Loss: 6.4967 | F1: 0.5668\n","\n","Domain: 42\n","x_dp_dom.shape: (158, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 42 | Accuracy: 0.2152 | Loss: 39.6095 | F1: 0.1019\n","\n","Domain: 43\n","x_dp_dom.shape: (153, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 43 | Accuracy: 0.1373 | Loss: 21.6408 | F1: 0.1302\n","\n","Domain: 44\n","x_dp_dom.shape: (153, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 44 | Accuracy: 0.1830 | Loss: 34.1452 | F1: 0.0566\n","\n","Domain: 45\n","x_dp_dom.shape: (163, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 45 | Accuracy: 0.1963 | Loss: 27.8368 | F1: 0.0890\n","\n","Domain: 46\n","x_dp_dom.shape: (160, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 46 | Accuracy: 0.1750 | Loss: 43.8214 | F1: 0.0521\n","\n","Domain: 47\n","x_dp_dom.shape: (155, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 47 | Accuracy: 0.1806 | Loss: 36.6698 | F1: 0.0553\n","\n","Domain: 48\n","x_dp_dom.shape: (159, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 48 | Accuracy: 0.1761 | Loss: 42.2213 | F1: 0.0527\n","\n","Domain: 49\n","x_dp_dom.shape: (164, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 49 | Accuracy: 0.2195 | Loss: 22.1372 | F1: 0.0920\n","\n","Domain: 50\n","x_dp_dom.shape: (153, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 50 | Accuracy: 0.1830 | Loss: 36.7586 | F1: 0.0566\n","\n","Domain: 51\n","x_dp_dom.shape: (157, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 51 | Accuracy: 0.1783 | Loss: 37.4739 | F1: 0.0549\n","\n","Domain: 52\n","x_dp_dom.shape: (153, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 52 | Accuracy: 0.1895 | Loss: 30.5560 | F1: 0.0684\n","\n","Domain: 53\n","x_dp_dom.shape: (159, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 53 | Accuracy: 0.1887 | Loss: 24.0791 | F1: 0.1357\n","\n","Domain: 54\n","x_dp_dom.shape: (153, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 54 | Accuracy: 0.1961 | Loss: 32.3489 | F1: 0.0744\n","\n","Domain: 55\n","x_dp_dom.shape: (160, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 55 | Accuracy: 0.1750 | Loss: 31.1866 | F1: 0.0521\n","\n","Domain: 56\n","x_dp_dom.shape: (153, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 56 | Accuracy: 0.1830 | Loss: 39.4723 | F1: 0.0566\n","\n","Domain: 57\n","x_dp_dom.shape: (153, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 57 | Accuracy: 0.1830 | Loss: 30.5245 | F1: 0.0569\n","\n","Domain: 58\n","x_dp_dom.shape: (149, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 58 | Accuracy: 0.1879 | Loss: 43.1457 | F1: 0.0595\n","\n","Domain: 59\n","x_dp_dom.shape: (154, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 59 | Accuracy: 0.1818 | Loss: 38.5318 | F1: 0.0559\n","\n","Domain: 60\n","x_dp_dom.shape: (158, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 60 | Accuracy: 0.1266 | Loss: 25.0284 | F1: 0.0960\n","\n","Domain: 61\n","x_dp_dom.shape: (158, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 61 | Accuracy: 0.2152 | Loss: 40.9555 | F1: 0.1013\n","\n","Domain: 62\n","x_dp_dom.shape: (158, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 62 | Accuracy: 0.1772 | Loss: 27.4628 | F1: 0.0542\n","\n","Domain: 63\n","x_dp_dom.shape: (153, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 63 | Accuracy: 0.1895 | Loss: 41.0600 | F1: 0.0684\n","\n","Domain: 64\n","x_dp_dom.shape: (154, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 64 | Accuracy: 0.1818 | Loss: 35.4848 | F1: 0.0559\n","\n","Domain: 65\n","x_dp_dom.shape: (161, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 65 | Accuracy: 0.0745 | Loss: 34.3285 | F1: 0.0328\n","\n","Domain: 66\n","x_dp_dom.shape: (153, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 66 | Accuracy: 0.0458 | Loss: 30.6347 | F1: 0.0112\n","\n","Domain: 67\n","x_dp_dom.shape: (153, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 67 | Accuracy: 0.2222 | Loss: 39.2054 | F1: 0.0908\n","\n","Domain: 68\n","x_dp_dom.shape: (154, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 68 | Accuracy: 0.1818 | Loss: 37.6139 | F1: 0.0559\n","\n","Domain: 69\n","x_dp_dom.shape: (153, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 69 | Accuracy: 0.0000 | Loss: 42.6722 | F1: 0.0000\n","\n","Domain: 70\n","x_dp_dom.shape: (153, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 70 | Accuracy: 0.2157 | Loss: 41.0506 | F1: 0.0916\n","\n","Domain: 71\n","x_dp_dom.shape: (155, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 71 | Accuracy: 0.1806 | Loss: 39.6764 | F1: 0.0553\n","\n","Domain: 72\n","x_dp_dom.shape: (153, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 72 | Accuracy: 0.1830 | Loss: 36.1006 | F1: 0.0566\n","\n","Domain: 73\n","x_dp_dom.shape: (152, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 73 | Accuracy: 0.0461 | Loss: 27.0650 | F1: 0.0041\n","\n","Domain: 74\n","x_dp_dom.shape: (146, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 74 | Accuracy: 0.1918 | Loss: 42.1503 | F1: 0.0624\n","\n","Domain: 75\n","x_dp_dom.shape: (153, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 75 | Accuracy: 0.1830 | Loss: 27.4316 | F1: 0.0566\n","\n","Mean accuracy for run 4: 0.1791\n","Mean F1 for run 4: 0.0780\n","\n","Source class: WAL\n","\n","x_df.shape: (11483, 3, 128) | np.unique(y_df): [0 1 2 3]\n","\n","Training on Df data...\n","\tEpoch 10/100 - Train loss: 0.1065 - Val accuracy: 0.9508 - Val loss: 0.1410 - Val F1: 0.9508 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.0489 - Val accuracy: 0.9534 - Val loss: 0.1343 - Val F1: 0.9536 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.0253 - Val accuracy: 0.9599 - Val loss: 0.1320 - Val F1: 0.9600 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.0115 - Val accuracy: 0.9634 - Val loss: 0.1421 - Val F1: 0.9634 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.0076 - Val accuracy: 0.9608 - Val loss: 0.1723 - Val F1: 0.9608 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.0050 - Val accuracy: 0.9621 - Val loss: 0.1594 - Val F1: 0.9621 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0040 - Val accuracy: 0.9634 - Val loss: 0.1766 - Val F1: 0.9634 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0036 - Val accuracy: 0.9634 - Val loss: 0.1771 - Val F1: 0.9634 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0026 - Val accuracy: 0.9604 - Val loss: 0.1736 - Val F1: 0.9604 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0023 - Val accuracy: 0.9617 - Val loss: 0.1741 - Val F1: 0.9617 - LR: 0.00e+00\n","\tBest epoch: 23 - Best val accuracy: 0.9591 - Best val loss: 0.1246 - Best val F1: 0.9591\n","\n","Domain: 15\n","x_dp_dom.shape: (161, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 15 | Accuracy: 0.0745 | Loss: 22.6697 | F1: 0.0177\n","\n","Domain: 16\n","x_dp_dom.shape: (165, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 16 | Accuracy: 0.2424 | Loss: 17.8843 | F1: 0.1515\n","\n","Domain: 17\n","x_dp_dom.shape: (164, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 17 | Accuracy: 0.2317 | Loss: 16.6349 | F1: 0.1145\n","\n","Domain: 18\n","x_dp_dom.shape: (166, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 18 | Accuracy: 0.2590 | Loss: 20.7306 | F1: 0.1434\n","\n","Domain: 19\n","x_dp_dom.shape: (165, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 19 | Accuracy: 0.2788 | Loss: 18.4895 | F1: 0.1786\n","\n","Domain: 20\n","x_dp_dom.shape: (162, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 20 | Accuracy: 0.2654 | Loss: 15.5929 | F1: 0.1375\n","\n","Domain: 21\n","x_dp_dom.shape: (159, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 21 | Accuracy: 0.2390 | Loss: 18.3228 | F1: 0.1055\n","\n","Domain: 22\n","x_dp_dom.shape: (165, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 22 | Accuracy: 0.2242 | Loss: 22.8177 | F1: 0.0946\n","\n","Domain: 23\n","x_dp_dom.shape: (164, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 23 | Accuracy: 0.2561 | Loss: 22.6629 | F1: 0.1185\n","\n","Domain: 24\n","x_dp_dom.shape: (162, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 24 | Accuracy: 0.2284 | Loss: 9.0087 | F1: 0.0919\n","\n","Domain: 25\n","x_dp_dom.shape: (166, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 25 | Accuracy: 0.2470 | Loss: 24.0963 | F1: 0.1495\n","\n","Domain: 26\n","x_dp_dom.shape: (153, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 26 | Accuracy: 0.2092 | Loss: 22.0651 | F1: 0.0939\n","\n","Domain: 27\n","x_dp_dom.shape: (165, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 27 | Accuracy: 0.2485 | Loss: 22.3613 | F1: 0.1168\n","\n","Domain: 28\n","x_dp_dom.shape: (153, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 28 | Accuracy: 0.2288 | Loss: 21.1743 | F1: 0.1407\n","\n","Domain: 29\n","x_dp_dom.shape: (153, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 29 | Accuracy: 0.2288 | Loss: 18.2635 | F1: 0.0944\n","\n","Domain: 30\n","x_dp_dom.shape: (161, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 30 | Accuracy: 0.2484 | Loss: 11.9643 | F1: 0.1872\n","\n","Domain: 31\n","x_dp_dom.shape: (154, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 31 | Accuracy: 0.2468 | Loss: 36.7955 | F1: 0.1992\n","\n","Domain: 32\n","x_dp_dom.shape: (163, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 32 | Accuracy: 0.2454 | Loss: 18.1104 | F1: 0.1002\n","\n","Domain: 33\n","x_dp_dom.shape: (156, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 33 | Accuracy: 0.2115 | Loss: 12.8448 | F1: 0.0926\n","\n","Domain: 34\n","x_dp_dom.shape: (161, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 34 | Accuracy: 0.1491 | Loss: 37.2923 | F1: 0.1177\n","\n","Domain: 35\n","x_dp_dom.shape: (159, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 35 | Accuracy: 0.2956 | Loss: 31.0930 | F1: 0.2316\n","\n","Domain: 36\n","x_dp_dom.shape: (155, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 36 | Accuracy: 0.2129 | Loss: 19.5125 | F1: 0.1018\n","\n","Domain: 37\n","x_dp_dom.shape: (154, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 37 | Accuracy: 0.2338 | Loss: 16.7150 | F1: 0.1504\n","\n","Domain: 38\n","x_dp_dom.shape: (158, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 38 | Accuracy: 0.2405 | Loss: 43.1163 | F1: 0.1820\n","\n","Domain: 39\n","x_dp_dom.shape: (165, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 39 | Accuracy: 0.1333 | Loss: 20.8328 | F1: 0.0642\n","\n","Domain: 40\n","x_dp_dom.shape: (155, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 40 | Accuracy: 0.2129 | Loss: 15.1815 | F1: 0.1082\n","\n","Domain: 41\n","x_dp_dom.shape: (156, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 41 | Accuracy: 0.6410 | Loss: 4.0383 | F1: 0.6958\n","\n","Domain: 42\n","x_dp_dom.shape: (158, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 42 | Accuracy: 0.2405 | Loss: 20.6879 | F1: 0.1096\n","\n","Domain: 43\n","x_dp_dom.shape: (153, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 43 | Accuracy: 0.1569 | Loss: 38.5185 | F1: 0.1397\n","\n","Domain: 44\n","x_dp_dom.shape: (153, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 44 | Accuracy: 0.2288 | Loss: 20.3744 | F1: 0.1118\n","\n","Domain: 45\n","x_dp_dom.shape: (163, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 45 | Accuracy: 0.2699 | Loss: 17.8771 | F1: 0.1467\n","\n","Domain: 46\n","x_dp_dom.shape: (160, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 46 | Accuracy: 0.2562 | Loss: 29.3527 | F1: 0.1896\n","\n","Domain: 47\n","x_dp_dom.shape: (155, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 47 | Accuracy: 0.2258 | Loss: 22.8721 | F1: 0.1748\n","\n","Domain: 48\n","x_dp_dom.shape: (159, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 48 | Accuracy: 0.2327 | Loss: 17.4864 | F1: 0.1113\n","\n","Domain: 49\n","x_dp_dom.shape: (164, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 49 | Accuracy: 0.2927 | Loss: 13.1381 | F1: 0.1828\n","\n","Domain: 50\n","x_dp_dom.shape: (153, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 50 | Accuracy: 0.2810 | Loss: 5.6751 | F1: 0.2334\n","\n","Domain: 51\n","x_dp_dom.shape: (157, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 51 | Accuracy: 0.2038 | Loss: 15.6579 | F1: 0.1069\n","\n","Domain: 52\n","x_dp_dom.shape: (153, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 52 | Accuracy: 0.2222 | Loss: 14.4740 | F1: 0.0935\n","\n","Domain: 53\n","x_dp_dom.shape: (159, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 53 | Accuracy: 0.2516 | Loss: 37.4813 | F1: 0.1897\n","\n","Domain: 54\n","x_dp_dom.shape: (153, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 54 | Accuracy: 0.2288 | Loss: 20.1514 | F1: 0.1817\n","\n","Domain: 55\n","x_dp_dom.shape: (160, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 55 | Accuracy: 0.2750 | Loss: 11.7254 | F1: 0.1396\n","\n","Domain: 56\n","x_dp_dom.shape: (153, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 56 | Accuracy: 0.1895 | Loss: 16.1353 | F1: 0.0912\n","\n","Domain: 57\n","x_dp_dom.shape: (153, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 57 | Accuracy: 0.1895 | Loss: 12.2816 | F1: 0.0822\n","\n","Domain: 58\n","x_dp_dom.shape: (149, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 58 | Accuracy: 0.1611 | Loss: 20.9690 | F1: 0.1479\n","\n","Domain: 59\n","x_dp_dom.shape: (154, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 59 | Accuracy: 0.2403 | Loss: 11.9013 | F1: 0.1115\n","\n","Domain: 60\n","x_dp_dom.shape: (158, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 60 | Accuracy: 0.1266 | Loss: 40.2744 | F1: 0.0958\n","\n","Domain: 61\n","x_dp_dom.shape: (158, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 61 | Accuracy: 0.2405 | Loss: 19.2001 | F1: 0.1234\n","\n","Domain: 62\n","x_dp_dom.shape: (158, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 62 | Accuracy: 0.2911 | Loss: 22.1454 | F1: 0.2212\n","\n","Domain: 63\n","x_dp_dom.shape: (153, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 63 | Accuracy: 0.1895 | Loss: 22.8598 | F1: 0.1039\n","\n","Domain: 64\n","x_dp_dom.shape: (154, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 64 | Accuracy: 0.2143 | Loss: 19.2766 | F1: 0.0856\n","\n","Domain: 65\n","x_dp_dom.shape: (161, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 65 | Accuracy: 0.1180 | Loss: 19.1339 | F1: 0.0557\n","\n","Domain: 66\n","x_dp_dom.shape: (153, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 66 | Accuracy: 0.0327 | Loss: 19.4292 | F1: 0.0095\n","\n","Domain: 67\n","x_dp_dom.shape: (153, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 67 | Accuracy: 0.2092 | Loss: 14.9597 | F1: 0.0867\n","\n","Domain: 68\n","x_dp_dom.shape: (154, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 68 | Accuracy: 0.2273 | Loss: 10.6255 | F1: 0.1016\n","\n","Domain: 69\n","x_dp_dom.shape: (153, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 69 | Accuracy: 0.0458 | Loss: 17.5625 | F1: 0.0190\n","\n","Domain: 70\n","x_dp_dom.shape: (153, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 70 | Accuracy: 0.2157 | Loss: 22.8702 | F1: 0.0810\n","\n","Domain: 71\n","x_dp_dom.shape: (155, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 71 | Accuracy: 0.2452 | Loss: 20.3310 | F1: 0.1402\n","\n","Domain: 72\n","x_dp_dom.shape: (153, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 72 | Accuracy: 0.2222 | Loss: 13.1674 | F1: 0.1379\n","\n","Domain: 73\n","x_dp_dom.shape: (152, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 73 | Accuracy: 0.0461 | Loss: 46.3919 | F1: 0.0041\n","\n","Domain: 74\n","x_dp_dom.shape: (146, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 74 | Accuracy: 0.1918 | Loss: 24.7681 | F1: 0.0852\n","\n","Domain: 75\n","x_dp_dom.shape: (153, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 75 | Accuracy: 0.2484 | Loss: 18.0418 | F1: 0.2034\n","\n","Mean accuracy for run 5: 0.2220\n","Mean F1 for run 5: 0.1324\n","\n","Source class: WAL\n","\n","x_df.shape: (11483, 3, 128) | np.unique(y_df): [0 1 2 3]\n","\n","Training on Df data...\n","\tEpoch 10/100 - Train loss: 0.1044 - Val accuracy: 0.9517 - Val loss: 0.1400 - Val F1: 0.9517 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.0478 - Val accuracy: 0.9591 - Val loss: 0.1325 - Val F1: 0.9590 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.0188 - Val accuracy: 0.9604 - Val loss: 0.1394 - Val F1: 0.9604 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.0106 - Val accuracy: 0.9626 - Val loss: 0.1498 - Val F1: 0.9626 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.0087 - Val accuracy: 0.9626 - Val loss: 0.1579 - Val F1: 0.9626 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.0046 - Val accuracy: 0.9599 - Val loss: 0.1812 - Val F1: 0.9599 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0034 - Val accuracy: 0.9608 - Val loss: 0.1752 - Val F1: 0.9608 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0025 - Val accuracy: 0.9630 - Val loss: 0.1723 - Val F1: 0.9630 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0023 - Val accuracy: 0.9621 - Val loss: 0.1892 - Val F1: 0.9621 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0014 - Val accuracy: 0.9613 - Val loss: 0.1782 - Val F1: 0.9612 - LR: 0.00e+00\n","\tBest epoch: 16 - Best val accuracy: 0.9578 - Best val loss: 0.1219 - Best val F1: 0.9578\n","\n","Domain: 15\n","x_dp_dom.shape: (161, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 15 | Accuracy: 0.0621 | Loss: 19.3399 | F1: 0.0073\n","\n","Domain: 16\n","x_dp_dom.shape: (165, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 16 | Accuracy: 0.1576 | Loss: 19.7188 | F1: 0.1175\n","\n","Domain: 17\n","x_dp_dom.shape: (164, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 17 | Accuracy: 0.1280 | Loss: 10.9889 | F1: 0.0915\n","\n","Domain: 18\n","x_dp_dom.shape: (166, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 18 | Accuracy: 0.1506 | Loss: 22.2844 | F1: 0.1110\n","\n","Domain: 19\n","x_dp_dom.shape: (165, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 19 | Accuracy: 0.0788 | Loss: 15.9847 | F1: 0.0115\n","\n","Domain: 20\n","x_dp_dom.shape: (162, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 20 | Accuracy: 0.2160 | Loss: 18.6916 | F1: 0.1715\n","\n","Domain: 21\n","x_dp_dom.shape: (159, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 21 | Accuracy: 0.1006 | Loss: 18.9813 | F1: 0.0896\n","\n","Domain: 22\n","x_dp_dom.shape: (165, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 22 | Accuracy: 0.1394 | Loss: 19.3787 | F1: 0.1047\n","\n","Domain: 23\n","x_dp_dom.shape: (164, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 23 | Accuracy: 0.2134 | Loss: 22.2350 | F1: 0.1068\n","\n","Domain: 24\n","x_dp_dom.shape: (162, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 24 | Accuracy: 0.2407 | Loss: 12.4031 | F1: 0.1496\n","\n","Domain: 25\n","x_dp_dom.shape: (166, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 25 | Accuracy: 0.0843 | Loss: 22.0685 | F1: 0.0226\n","\n","Domain: 26\n","x_dp_dom.shape: (153, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 26 | Accuracy: 0.0980 | Loss: 19.7911 | F1: 0.0856\n","\n","Domain: 27\n","x_dp_dom.shape: (165, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 27 | Accuracy: 0.1212 | Loss: 22.6276 | F1: 0.0913\n","\n","Domain: 28\n","x_dp_dom.shape: (153, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 28 | Accuracy: 0.0784 | Loss: 19.3184 | F1: 0.0596\n","\n","Domain: 29\n","x_dp_dom.shape: (153, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 29 | Accuracy: 0.0458 | Loss: 23.4883 | F1: 0.0040\n","\n","Domain: 30\n","x_dp_dom.shape: (161, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 30 | Accuracy: 0.3292 | Loss: 6.9096 | F1: 0.4181\n","\n","Domain: 31\n","x_dp_dom.shape: (154, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 31 | Accuracy: 0.1623 | Loss: 20.4182 | F1: 0.1409\n","\n","Domain: 32\n","x_dp_dom.shape: (163, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 32 | Accuracy: 0.0368 | Loss: 21.1639 | F1: 0.0289\n","\n","Domain: 33\n","x_dp_dom.shape: (156, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 33 | Accuracy: 0.1538 | Loss: 12.0797 | F1: 0.1049\n","\n","Domain: 34\n","x_dp_dom.shape: (161, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 34 | Accuracy: 0.1553 | Loss: 26.2980 | F1: 0.1286\n","\n","Domain: 35\n","x_dp_dom.shape: (159, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 35 | Accuracy: 0.1321 | Loss: 22.9108 | F1: 0.1163\n","\n","Domain: 36\n","x_dp_dom.shape: (155, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 36 | Accuracy: 0.0452 | Loss: 19.7940 | F1: 0.0040\n","\n","Domain: 37\n","x_dp_dom.shape: (154, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 37 | Accuracy: 0.1688 | Loss: 13.4525 | F1: 0.1549\n","\n","Domain: 38\n","x_dp_dom.shape: (158, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 38 | Accuracy: 0.1076 | Loss: 36.8428 | F1: 0.0472\n","\n","Domain: 39\n","x_dp_dom.shape: (165, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 39 | Accuracy: 0.1636 | Loss: 13.3251 | F1: 0.1030\n","\n","Domain: 40\n","x_dp_dom.shape: (155, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 40 | Accuracy: 0.1097 | Loss: 9.9705 | F1: 0.0798\n","\n","Domain: 41\n","x_dp_dom.shape: (156, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 41 | Accuracy: 0.0192 | Loss: 13.2341 | F1: 0.0093\n","\n","Domain: 42\n","x_dp_dom.shape: (158, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 42 | Accuracy: 0.0570 | Loss: 19.5770 | F1: 0.0312\n","\n","Domain: 43\n","x_dp_dom.shape: (153, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 43 | Accuracy: 0.0719 | Loss: 24.3644 | F1: 0.0499\n","\n","Domain: 44\n","x_dp_dom.shape: (153, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 44 | Accuracy: 0.0458 | Loss: 16.5389 | F1: 0.0040\n","\n","Domain: 45\n","x_dp_dom.shape: (163, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 45 | Accuracy: 0.1718 | Loss: 16.4316 | F1: 0.1392\n","\n","Domain: 46\n","x_dp_dom.shape: (160, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 46 | Accuracy: 0.0938 | Loss: 23.6781 | F1: 0.0816\n","\n","Domain: 47\n","x_dp_dom.shape: (155, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 47 | Accuracy: 0.0774 | Loss: 16.3686 | F1: 0.0572\n","\n","Domain: 48\n","x_dp_dom.shape: (159, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 48 | Accuracy: 0.1698 | Loss: 18.9305 | F1: 0.1034\n","\n","Domain: 49\n","x_dp_dom.shape: (164, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 49 | Accuracy: 0.1707 | Loss: 9.4078 | F1: 0.1351\n","\n","Domain: 50\n","x_dp_dom.shape: (153, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 50 | Accuracy: 0.1503 | Loss: 18.8522 | F1: 0.0559\n","\n","Domain: 51\n","x_dp_dom.shape: (157, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 51 | Accuracy: 0.2166 | Loss: 19.6814 | F1: 0.1725\n","\n","Domain: 52\n","x_dp_dom.shape: (153, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 52 | Accuracy: 0.2026 | Loss: 16.8175 | F1: 0.1617\n","\n","Domain: 53\n","x_dp_dom.shape: (159, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 53 | Accuracy: 0.1887 | Loss: 16.0128 | F1: 0.1658\n","\n","Domain: 54\n","x_dp_dom.shape: (153, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 54 | Accuracy: 0.1503 | Loss: 12.7784 | F1: 0.1608\n","\n","Domain: 55\n","x_dp_dom.shape: (160, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 55 | Accuracy: 0.2125 | Loss: 13.5836 | F1: 0.1682\n","\n","Domain: 56\n","x_dp_dom.shape: (153, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 56 | Accuracy: 0.2026 | Loss: 18.2182 | F1: 0.1736\n","\n","Domain: 57\n","x_dp_dom.shape: (153, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 57 | Accuracy: 0.1961 | Loss: 12.7985 | F1: 0.1526\n","\n","Domain: 58\n","x_dp_dom.shape: (149, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 58 | Accuracy: 0.1812 | Loss: 25.8118 | F1: 0.1383\n","\n","Domain: 59\n","x_dp_dom.shape: (154, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 59 | Accuracy: 0.0519 | Loss: 22.5645 | F1: 0.0165\n","\n","Domain: 60\n","x_dp_dom.shape: (158, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 60 | Accuracy: 0.1076 | Loss: 21.0736 | F1: 0.0892\n","\n","Domain: 61\n","x_dp_dom.shape: (158, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 61 | Accuracy: 0.0633 | Loss: 23.6741 | F1: 0.0382\n","\n","Domain: 62\n","x_dp_dom.shape: (158, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 62 | Accuracy: 0.0443 | Loss: 15.2185 | F1: 0.0038\n","\n","Domain: 63\n","x_dp_dom.shape: (153, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 63 | Accuracy: 0.0458 | Loss: 25.1539 | F1: 0.0040\n","\n","Domain: 64\n","x_dp_dom.shape: (154, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 64 | Accuracy: 0.0455 | Loss: 19.7970 | F1: 0.0040\n","\n","Domain: 65\n","x_dp_dom.shape: (161, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 65 | Accuracy: 0.0435 | Loss: 16.6322 | F1: 0.0047\n","\n","Domain: 66\n","x_dp_dom.shape: (153, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 66 | Accuracy: 0.0523 | Loss: 11.8300 | F1: 0.0161\n","\n","Domain: 67\n","x_dp_dom.shape: (153, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 67 | Accuracy: 0.1503 | Loss: 19.4925 | F1: 0.1336\n","\n","Domain: 68\n","x_dp_dom.shape: (154, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 68 | Accuracy: 0.1623 | Loss: 20.9488 | F1: 0.1177\n","\n","Domain: 69\n","x_dp_dom.shape: (153, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 69 | Accuracy: 0.0458 | Loss: 19.1395 | F1: 0.0042\n","\n","Domain: 70\n","x_dp_dom.shape: (153, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 70 | Accuracy: 0.0784 | Loss: 23.4143 | F1: 0.0600\n","\n","Domain: 71\n","x_dp_dom.shape: (155, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 71 | Accuracy: 0.1419 | Loss: 17.2323 | F1: 0.1298\n","\n","Domain: 72\n","x_dp_dom.shape: (153, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 72 | Accuracy: 0.0588 | Loss: 16.3402 | F1: 0.0270\n","\n","Domain: 73\n","x_dp_dom.shape: (152, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 73 | Accuracy: 0.0526 | Loss: 21.2455 | F1: 0.0284\n","\n","Domain: 74\n","x_dp_dom.shape: (146, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 74 | Accuracy: 0.1027 | Loss: 26.8345 | F1: 0.1338\n","\n","Domain: 75\n","x_dp_dom.shape: (153, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 75 | Accuracy: 0.1373 | Loss: 12.5382 | F1: 0.1264\n","\n","Mean accuracy for run 6: 0.1220\n","Mean F1 for run 6: 0.0893\n","\n","Source class: WAL\n","\n","x_df.shape: (11483, 3, 128) | np.unique(y_df): [0 1 2 3]\n","\n","Training on Df data...\n","\tEpoch 10/100 - Train loss: 0.1024 - Val accuracy: 0.9560 - Val loss: 0.1227 - Val F1: 0.9560 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.0453 - Val accuracy: 0.9626 - Val loss: 0.1140 - Val F1: 0.9626 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.0204 - Val accuracy: 0.9643 - Val loss: 0.1181 - Val F1: 0.9643 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.0153 - Val accuracy: 0.9660 - Val loss: 0.1247 - Val F1: 0.9661 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.0069 - Val accuracy: 0.9660 - Val loss: 0.1349 - Val F1: 0.9661 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.0053 - Val accuracy: 0.9647 - Val loss: 0.1349 - Val F1: 0.9648 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0033 - Val accuracy: 0.9678 - Val loss: 0.1414 - Val F1: 0.9678 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0023 - Val accuracy: 0.9669 - Val loss: 0.1434 - Val F1: 0.9669 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0017 - Val accuracy: 0.9687 - Val loss: 0.1438 - Val F1: 0.9687 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0018 - Val accuracy: 0.9669 - Val loss: 0.1427 - Val F1: 0.9669 - LR: 0.00e+00\n","\tBest epoch: 15 - Best val accuracy: 0.9626 - Best val loss: 0.1083 - Best val F1: 0.9626\n","\n","Domain: 15\n","x_dp_dom.shape: (161, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 15 | Accuracy: 0.2484 | Loss: 37.6917 | F1: 0.1608\n","\n","Domain: 16\n","x_dp_dom.shape: (165, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 16 | Accuracy: 0.0848 | Loss: 44.1194 | F1: 0.0233\n","\n","Domain: 17\n","x_dp_dom.shape: (164, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 17 | Accuracy: 0.0793 | Loss: 34.0394 | F1: 0.0116\n","\n","Domain: 18\n","x_dp_dom.shape: (166, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 18 | Accuracy: 0.0783 | Loss: 43.3102 | F1: 0.0114\n","\n","Domain: 19\n","x_dp_dom.shape: (165, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 19 | Accuracy: 0.0788 | Loss: 45.7420 | F1: 0.0115\n","\n","Domain: 20\n","x_dp_dom.shape: (162, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 20 | Accuracy: 0.0802 | Loss: 42.6337 | F1: 0.0135\n","\n","Domain: 21\n","x_dp_dom.shape: (159, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 21 | Accuracy: 0.0755 | Loss: 44.5250 | F1: 0.0107\n","\n","Domain: 22\n","x_dp_dom.shape: (165, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 22 | Accuracy: 0.0788 | Loss: 45.1665 | F1: 0.0115\n","\n","Domain: 23\n","x_dp_dom.shape: (164, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 23 | Accuracy: 0.0854 | Loss: 59.7978 | F1: 0.0236\n","\n","Domain: 24\n","x_dp_dom.shape: (162, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 24 | Accuracy: 0.0741 | Loss: 38.8461 | F1: 0.0312\n","\n","Domain: 25\n","x_dp_dom.shape: (166, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 25 | Accuracy: 0.0783 | Loss: 41.4506 | F1: 0.0114\n","\n","Domain: 26\n","x_dp_dom.shape: (153, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 26 | Accuracy: 0.0458 | Loss: 40.0727 | F1: 0.0042\n","\n","Domain: 27\n","x_dp_dom.shape: (165, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 27 | Accuracy: 0.0788 | Loss: 53.9992 | F1: 0.0116\n","\n","Domain: 28\n","x_dp_dom.shape: (153, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 28 | Accuracy: 0.0458 | Loss: 54.7002 | F1: 0.0040\n","\n","Domain: 29\n","x_dp_dom.shape: (153, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 29 | Accuracy: 0.0458 | Loss: 49.2105 | F1: 0.0040\n","\n","Domain: 30\n","x_dp_dom.shape: (161, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 30 | Accuracy: 0.0621 | Loss: 11.4854 | F1: 0.0216\n","\n","Domain: 31\n","x_dp_dom.shape: (154, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 31 | Accuracy: 0.0130 | Loss: 18.8457 | F1: 0.0048\n","\n","Domain: 32\n","x_dp_dom.shape: (163, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 32 | Accuracy: 0.0798 | Loss: 43.0447 | F1: 0.0118\n","\n","Domain: 33\n","x_dp_dom.shape: (156, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 33 | Accuracy: 0.0577 | Loss: 35.8670 | F1: 0.0063\n","\n","Domain: 34\n","x_dp_dom.shape: (161, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 34 | Accuracy: 0.1429 | Loss: 23.9252 | F1: 0.0676\n","\n","Domain: 35\n","x_dp_dom.shape: (159, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 35 | Accuracy: 0.0818 | Loss: 60.0685 | F1: 0.0124\n","\n","Domain: 36\n","x_dp_dom.shape: (155, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 36 | Accuracy: 0.0516 | Loss: 44.9777 | F1: 0.0051\n","\n","Domain: 37\n","x_dp_dom.shape: (154, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 37 | Accuracy: 0.0519 | Loss: 43.8393 | F1: 0.0054\n","\n","Domain: 38\n","x_dp_dom.shape: (158, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 38 | Accuracy: 0.0633 | Loss: 27.3178 | F1: 0.0271\n","\n","Domain: 39\n","x_dp_dom.shape: (165, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 39 | Accuracy: 0.1152 | Loss: 44.1991 | F1: 0.1372\n","\n","Domain: 40\n","x_dp_dom.shape: (155, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 40 | Accuracy: 0.0581 | Loss: 31.6516 | F1: 0.0065\n","\n","Domain: 41\n","x_dp_dom.shape: (156, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 41 | Accuracy: 0.7372 | Loss: 7.1122 | F1: 0.7236\n","\n","Domain: 42\n","x_dp_dom.shape: (158, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 42 | Accuracy: 0.0506 | Loss: 47.6438 | F1: 0.0068\n","\n","Domain: 43\n","x_dp_dom.shape: (153, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 43 | Accuracy: 0.0980 | Loss: 19.4189 | F1: 0.0378\n","\n","Domain: 44\n","x_dp_dom.shape: (153, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 44 | Accuracy: 0.0458 | Loss: 45.9720 | F1: 0.0040\n","\n","Domain: 45\n","x_dp_dom.shape: (163, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 45 | Accuracy: 0.0798 | Loss: 38.0739 | F1: 0.0118\n","\n","Domain: 46\n","x_dp_dom.shape: (160, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 46 | Accuracy: 0.0813 | Loss: 55.0522 | F1: 0.0122\n","\n","Domain: 47\n","x_dp_dom.shape: (155, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 47 | Accuracy: 0.0645 | Loss: 46.1295 | F1: 0.0189\n","\n","Domain: 48\n","x_dp_dom.shape: (159, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 48 | Accuracy: 0.2390 | Loss: 42.4908 | F1: 0.1821\n","\n","Domain: 49\n","x_dp_dom.shape: (164, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 49 | Accuracy: 0.0793 | Loss: 30.4923 | F1: 0.0116\n","\n","Domain: 50\n","x_dp_dom.shape: (153, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 50 | Accuracy: 0.0719 | Loss: 42.9758 | F1: 0.0504\n","\n","Domain: 51\n","x_dp_dom.shape: (157, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 51 | Accuracy: 0.1401 | Loss: 48.3190 | F1: 0.1154\n","\n","Domain: 52\n","x_dp_dom.shape: (153, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 52 | Accuracy: 0.0458 | Loss: 42.8046 | F1: 0.0040\n","\n","Domain: 53\n","x_dp_dom.shape: (159, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 53 | Accuracy: 0.1132 | Loss: 18.1361 | F1: 0.0568\n","\n","Domain: 54\n","x_dp_dom.shape: (153, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 54 | Accuracy: 0.0327 | Loss: 47.8106 | F1: 0.0035\n","\n","Domain: 55\n","x_dp_dom.shape: (160, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 55 | Accuracy: 0.0813 | Loss: 42.3685 | F1: 0.0126\n","\n","Domain: 56\n","x_dp_dom.shape: (153, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 56 | Accuracy: 0.1438 | Loss: 47.7143 | F1: 0.1321\n","\n","Domain: 57\n","x_dp_dom.shape: (153, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 57 | Accuracy: 0.0458 | Loss: 37.8947 | F1: 0.0045\n","\n","Domain: 58\n","x_dp_dom.shape: (149, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 58 | Accuracy: 0.0336 | Loss: 60.0647 | F1: 0.0027\n","\n","Domain: 59\n","x_dp_dom.shape: (154, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 59 | Accuracy: 0.1688 | Loss: 41.9541 | F1: 0.1481\n","\n","Domain: 60\n","x_dp_dom.shape: (158, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 60 | Accuracy: 0.1456 | Loss: 19.3311 | F1: 0.0611\n","\n","Domain: 61\n","x_dp_dom.shape: (158, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 61 | Accuracy: 0.0759 | Loss: 49.0026 | F1: 0.0108\n","\n","Domain: 62\n","x_dp_dom.shape: (158, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 62 | Accuracy: 0.0759 | Loss: 39.3046 | F1: 0.0107\n","\n","Domain: 63\n","x_dp_dom.shape: (153, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 63 | Accuracy: 0.0392 | Loss: 52.1545 | F1: 0.0035\n","\n","Domain: 64\n","x_dp_dom.shape: (154, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 64 | Accuracy: 0.0455 | Loss: 43.9004 | F1: 0.0040\n","\n","Domain: 65\n","x_dp_dom.shape: (161, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 65 | Accuracy: 0.2547 | Loss: 33.7894 | F1: 0.1825\n","\n","Domain: 66\n","x_dp_dom.shape: (153, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 66 | Accuracy: 0.1895 | Loss: 25.8517 | F1: 0.1490\n","\n","Domain: 67\n","x_dp_dom.shape: (153, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 67 | Accuracy: 0.0458 | Loss: 52.3483 | F1: 0.0047\n","\n","Domain: 68\n","x_dp_dom.shape: (154, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 68 | Accuracy: 0.0584 | Loss: 44.5580 | F1: 0.0177\n","\n","Domain: 69\n","x_dp_dom.shape: (153, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 69 | Accuracy: 0.2288 | Loss: 45.9082 | F1: 0.1879\n","\n","Domain: 70\n","x_dp_dom.shape: (153, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 70 | Accuracy: 0.0196 | Loss: 51.4635 | F1: 0.0018\n","\n","Domain: 71\n","x_dp_dom.shape: (155, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 71 | Accuracy: 0.0581 | Loss: 51.4100 | F1: 0.0064\n","\n","Domain: 72\n","x_dp_dom.shape: (153, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 72 | Accuracy: 0.0523 | Loss: 45.2176 | F1: 0.0166\n","\n","Domain: 73\n","x_dp_dom.shape: (152, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 73 | Accuracy: 0.1842 | Loss: 22.2622 | F1: 0.0573\n","\n","Domain: 74\n","x_dp_dom.shape: (146, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 74 | Accuracy: 0.0411 | Loss: 51.1381 | F1: 0.0063\n","\n","Domain: 75\n","x_dp_dom.shape: (153, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 75 | Accuracy: 0.0458 | Loss: 39.8923 | F1: 0.0043\n","\n","Mean accuracy for run 7: 0.0975\n","Mean F1 for run 7: 0.0478\n","\n","Source class: WAL\n","\n","x_df.shape: (11483, 3, 128) | np.unique(y_df): [0 1 2 3]\n","\n","Training on Df data...\n","\tEpoch 10/100 - Train loss: 0.0970 - Val accuracy: 0.9552 - Val loss: 0.1246 - Val F1: 0.9552 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.0360 - Val accuracy: 0.9613 - Val loss: 0.1230 - Val F1: 0.9613 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.0155 - Val accuracy: 0.9604 - Val loss: 0.1351 - Val F1: 0.9604 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.0089 - Val accuracy: 0.9626 - Val loss: 0.1427 - Val F1: 0.9626 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.0041 - Val accuracy: 0.9634 - Val loss: 0.1448 - Val F1: 0.9635 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.0047 - Val accuracy: 0.9613 - Val loss: 0.1713 - Val F1: 0.9613 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0017 - Val accuracy: 0.9678 - Val loss: 0.1596 - Val F1: 0.9678 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0015 - Val accuracy: 0.9656 - Val loss: 0.1613 - Val F1: 0.9656 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0014 - Val accuracy: 0.9643 - Val loss: 0.1689 - Val F1: 0.9643 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0013 - Val accuracy: 0.9647 - Val loss: 0.1641 - Val F1: 0.9647 - LR: 0.00e+00\n","\tBest epoch: 22 - Best val accuracy: 0.9617 - Best val loss: 0.1177 - Best val F1: 0.9617\n","\n","Domain: 15\n","x_dp_dom.shape: (161, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 15 | Accuracy: 0.2050 | Loss: 23.0151 | F1: 0.0859\n","\n","Domain: 16\n","x_dp_dom.shape: (165, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 16 | Accuracy: 0.0970 | Loss: 20.8756 | F1: 0.0515\n","\n","Domain: 17\n","x_dp_dom.shape: (164, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 17 | Accuracy: 0.1707 | Loss: 21.3022 | F1: 0.1243\n","\n","Domain: 18\n","x_dp_dom.shape: (166, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 18 | Accuracy: 0.0301 | Loss: 22.6903 | F1: 0.0136\n","\n","Domain: 19\n","x_dp_dom.shape: (165, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 19 | Accuracy: 0.1455 | Loss: 18.3372 | F1: 0.0919\n","\n","Domain: 20\n","x_dp_dom.shape: (162, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 20 | Accuracy: 0.1667 | Loss: 22.4051 | F1: 0.1195\n","\n","Domain: 21\n","x_dp_dom.shape: (159, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 21 | Accuracy: 0.0881 | Loss: 24.7713 | F1: 0.0627\n","\n","Domain: 22\n","x_dp_dom.shape: (165, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 22 | Accuracy: 0.1394 | Loss: 21.0808 | F1: 0.0759\n","\n","Domain: 23\n","x_dp_dom.shape: (164, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 23 | Accuracy: 0.1159 | Loss: 23.9841 | F1: 0.0356\n","\n","Domain: 24\n","x_dp_dom.shape: (162, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 24 | Accuracy: 0.1173 | Loss: 24.4207 | F1: 0.0926\n","\n","Domain: 25\n","x_dp_dom.shape: (166, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 25 | Accuracy: 0.0422 | Loss: 21.0189 | F1: 0.0307\n","\n","Domain: 26\n","x_dp_dom.shape: (153, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 26 | Accuracy: 0.1307 | Loss: 24.1936 | F1: 0.0684\n","\n","Domain: 27\n","x_dp_dom.shape: (165, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 27 | Accuracy: 0.1758 | Loss: 19.9325 | F1: 0.0702\n","\n","Domain: 28\n","x_dp_dom.shape: (153, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 28 | Accuracy: 0.2222 | Loss: 22.1605 | F1: 0.1814\n","\n","Domain: 29\n","x_dp_dom.shape: (153, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 29 | Accuracy: 0.0000 | Loss: 22.3399 | F1: 0.0000\n","\n","Domain: 30\n","x_dp_dom.shape: (161, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 30 | Accuracy: 0.1429 | Loss: 16.6650 | F1: 0.1104\n","\n","Domain: 31\n","x_dp_dom.shape: (154, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 31 | Accuracy: 0.3701 | Loss: 2.9420 | F1: 0.4834\n","\n","Domain: 32\n","x_dp_dom.shape: (163, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 32 | Accuracy: 0.1779 | Loss: 22.5070 | F1: 0.0747\n","\n","Domain: 33\n","x_dp_dom.shape: (156, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 33 | Accuracy: 0.1731 | Loss: 24.9545 | F1: 0.1346\n","\n","Domain: 34\n","x_dp_dom.shape: (161, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 34 | Accuracy: 0.1863 | Loss: 19.7495 | F1: 0.1374\n","\n","Domain: 35\n","x_dp_dom.shape: (159, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 35 | Accuracy: 0.2138 | Loss: 22.2906 | F1: 0.1115\n","\n","Domain: 36\n","x_dp_dom.shape: (155, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 36 | Accuracy: 0.1290 | Loss: 19.6290 | F1: 0.0583\n","\n","Domain: 37\n","x_dp_dom.shape: (154, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 37 | Accuracy: 0.1299 | Loss: 24.3233 | F1: 0.1127\n","\n","Domain: 38\n","x_dp_dom.shape: (158, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 38 | Accuracy: 0.1013 | Loss: 23.9617 | F1: 0.0766\n","\n","Domain: 39\n","x_dp_dom.shape: (165, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 39 | Accuracy: 0.2424 | Loss: 20.8501 | F1: 0.1802\n","\n","Domain: 40\n","x_dp_dom.shape: (155, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 40 | Accuracy: 0.2065 | Loss: 24.3210 | F1: 0.1703\n","\n","Domain: 41\n","x_dp_dom.shape: (156, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 41 | Accuracy: 0.2372 | Loss: 13.1540 | F1: 0.1815\n","\n","Domain: 42\n","x_dp_dom.shape: (158, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 42 | Accuracy: 0.2152 | Loss: 23.8050 | F1: 0.1106\n","\n","Domain: 43\n","x_dp_dom.shape: (153, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 43 | Accuracy: 0.2876 | Loss: 4.0031 | F1: 0.3242\n","\n","Domain: 44\n","x_dp_dom.shape: (153, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 44 | Accuracy: 0.0131 | Loss: 22.9959 | F1: 0.0017\n","\n","Domain: 45\n","x_dp_dom.shape: (163, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 45 | Accuracy: 0.0491 | Loss: 22.5154 | F1: 0.0258\n","\n","Domain: 46\n","x_dp_dom.shape: (160, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 46 | Accuracy: 0.0500 | Loss: 22.9423 | F1: 0.0264\n","\n","Domain: 47\n","x_dp_dom.shape: (155, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 47 | Accuracy: 0.1226 | Loss: 20.8942 | F1: 0.0616\n","\n","Domain: 48\n","x_dp_dom.shape: (159, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 48 | Accuracy: 0.1447 | Loss: 24.1317 | F1: 0.0460\n","\n","Domain: 49\n","x_dp_dom.shape: (164, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 49 | Accuracy: 0.2134 | Loss: 20.3661 | F1: 0.1637\n","\n","Domain: 50\n","x_dp_dom.shape: (153, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 50 | Accuracy: 0.0588 | Loss: 25.0187 | F1: 0.0312\n","\n","Domain: 51\n","x_dp_dom.shape: (157, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 51 | Accuracy: 0.0573 | Loss: 24.6067 | F1: 0.0158\n","\n","Domain: 52\n","x_dp_dom.shape: (153, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 52 | Accuracy: 0.0850 | Loss: 23.2996 | F1: 0.0688\n","\n","Domain: 53\n","x_dp_dom.shape: (159, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 53 | Accuracy: 0.2453 | Loss: 12.5299 | F1: 0.1712\n","\n","Domain: 54\n","x_dp_dom.shape: (153, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 54 | Accuracy: 0.0588 | Loss: 22.9991 | F1: 0.0293\n","\n","Domain: 55\n","x_dp_dom.shape: (160, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 55 | Accuracy: 0.1250 | Loss: 26.2691 | F1: 0.0970\n","\n","Domain: 56\n","x_dp_dom.shape: (153, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 56 | Accuracy: 0.1569 | Loss: 23.2398 | F1: 0.0974\n","\n","Domain: 57\n","x_dp_dom.shape: (153, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 57 | Accuracy: 0.0915 | Loss: 24.4286 | F1: 0.0838\n","\n","Domain: 58\n","x_dp_dom.shape: (149, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 58 | Accuracy: 0.1208 | Loss: 26.6469 | F1: 0.1218\n","\n","Domain: 59\n","x_dp_dom.shape: (154, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 59 | Accuracy: 0.1753 | Loss: 24.6439 | F1: 0.0624\n","\n","Domain: 60\n","x_dp_dom.shape: (158, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 60 | Accuracy: 0.2911 | Loss: 6.8008 | F1: 0.2129\n","\n","Domain: 61\n","x_dp_dom.shape: (158, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 61 | Accuracy: 0.2152 | Loss: 22.6581 | F1: 0.0888\n","\n","Domain: 62\n","x_dp_dom.shape: (158, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 62 | Accuracy: 0.1582 | Loss: 22.1821 | F1: 0.1202\n","\n","Domain: 63\n","x_dp_dom.shape: (153, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 63 | Accuracy: 0.0196 | Loss: 25.0176 | F1: 0.0085\n","\n","Domain: 64\n","x_dp_dom.shape: (154, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 64 | Accuracy: 0.0130 | Loss: 23.8649 | F1: 0.0091\n","\n","Domain: 65\n","x_dp_dom.shape: (161, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 65 | Accuracy: 0.2236 | Loss: 20.3029 | F1: 0.1623\n","\n","Domain: 66\n","x_dp_dom.shape: (153, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 66 | Accuracy: 0.1765 | Loss: 23.2215 | F1: 0.1387\n","\n","Domain: 67\n","x_dp_dom.shape: (153, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 67 | Accuracy: 0.0850 | Loss: 26.4429 | F1: 0.0614\n","\n","Domain: 68\n","x_dp_dom.shape: (154, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 68 | Accuracy: 0.1364 | Loss: 27.6584 | F1: 0.0505\n","\n","Domain: 69\n","x_dp_dom.shape: (153, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 69 | Accuracy: 0.1895 | Loss: 24.3281 | F1: 0.1025\n","\n","Domain: 70\n","x_dp_dom.shape: (153, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 70 | Accuracy: 0.2288 | Loss: 24.8530 | F1: 0.1088\n","\n","Domain: 71\n","x_dp_dom.shape: (155, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 71 | Accuracy: 0.0903 | Loss: 23.3509 | F1: 0.0619\n","\n","Domain: 72\n","x_dp_dom.shape: (153, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 72 | Accuracy: 0.0261 | Loss: 24.7432 | F1: 0.0318\n","\n","Domain: 73\n","x_dp_dom.shape: (152, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 73 | Accuracy: 0.1579 | Loss: 15.9543 | F1: 0.1463\n","\n","Domain: 74\n","x_dp_dom.shape: (146, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 74 | Accuracy: 0.1712 | Loss: 24.0487 | F1: 0.0661\n","\n","Domain: 75\n","x_dp_dom.shape: (153, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 75 | Accuracy: 0.0654 | Loss: 24.5524 | F1: 0.0605\n","\n","Mean accuracy for run 8: 0.1422\n","Mean F1 for run 8: 0.0968\n","\n","Source class: WAL\n","\n","x_df.shape: (11483, 3, 128) | np.unique(y_df): [0 1 2 3]\n","\n","Training on Df data...\n","\tEpoch 10/100 - Train loss: 0.1046 - Val accuracy: 0.9539 - Val loss: 0.1303 - Val F1: 0.9539 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.0436 - Val accuracy: 0.9599 - Val loss: 0.1242 - Val F1: 0.9599 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.0192 - Val accuracy: 0.9608 - Val loss: 0.1213 - Val F1: 0.9608 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.0109 - Val accuracy: 0.9643 - Val loss: 0.1388 - Val F1: 0.9643 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.0067 - Val accuracy: 0.9634 - Val loss: 0.1360 - Val F1: 0.9634 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.0054 - Val accuracy: 0.9617 - Val loss: 0.1454 - Val F1: 0.9617 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0040 - Val accuracy: 0.9639 - Val loss: 0.1484 - Val F1: 0.9639 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0019 - Val accuracy: 0.9617 - Val loss: 0.1535 - Val F1: 0.9617 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0013 - Val accuracy: 0.9639 - Val loss: 0.1560 - Val F1: 0.9638 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0014 - Val accuracy: 0.9656 - Val loss: 0.1547 - Val F1: 0.9656 - LR: 0.00e+00\n","\tBest epoch: 16 - Best val accuracy: 0.9560 - Best val loss: 0.1150 - Best val F1: 0.9560\n","\n","Domain: 15\n","x_dp_dom.shape: (161, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 15 | Accuracy: 0.8696 | Loss: 3.3206 | F1: 0.8373\n","\n","Domain: 16\n","x_dp_dom.shape: (165, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 16 | Accuracy: 0.8000 | Loss: 2.0244 | F1: 0.7367\n","\n","Domain: 17\n","x_dp_dom.shape: (164, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 17 | Accuracy: 0.8293 | Loss: 1.2312 | F1: 0.7987\n","\n","Domain: 18\n","x_dp_dom.shape: (166, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 18 | Accuracy: 0.7169 | Loss: 3.8251 | F1: 0.6298\n","\n","Domain: 19\n","x_dp_dom.shape: (165, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 19 | Accuracy: 0.7030 | Loss: 2.1704 | F1: 0.6025\n","\n","Domain: 20\n","x_dp_dom.shape: (162, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 20 | Accuracy: 0.7407 | Loss: 2.1619 | F1: 0.7364\n","\n","Domain: 21\n","x_dp_dom.shape: (159, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 21 | Accuracy: 0.8491 | Loss: 1.6720 | F1: 0.7982\n","\n","Domain: 22\n","x_dp_dom.shape: (165, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 22 | Accuracy: 0.7273 | Loss: 3.6753 | F1: 0.6681\n","\n","Domain: 23\n","x_dp_dom.shape: (164, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 23 | Accuracy: 0.7622 | Loss: 3.0004 | F1: 0.6944\n","\n","Domain: 24\n","x_dp_dom.shape: (162, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 24 | Accuracy: 0.8642 | Loss: 0.9296 | F1: 0.8349\n","\n","Domain: 25\n","x_dp_dom.shape: (166, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 25 | Accuracy: 0.7470 | Loss: 2.4611 | F1: 0.6718\n","\n","Domain: 26\n","x_dp_dom.shape: (153, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 26 | Accuracy: 0.7516 | Loss: 2.9962 | F1: 0.6872\n","\n","Domain: 27\n","x_dp_dom.shape: (165, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 27 | Accuracy: 0.8303 | Loss: 2.8244 | F1: 0.7608\n","\n","Domain: 28\n","x_dp_dom.shape: (153, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 28 | Accuracy: 0.8039 | Loss: 1.6927 | F1: 0.7515\n","\n","Domain: 29\n","x_dp_dom.shape: (153, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 29 | Accuracy: 0.6667 | Loss: 4.7151 | F1: 0.5804\n","\n","Domain: 30\n","x_dp_dom.shape: (161, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 30 | Accuracy: 0.0932 | Loss: 11.3754 | F1: 0.1138\n","\n","Domain: 31\n","x_dp_dom.shape: (154, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 31 | Accuracy: 0.2143 | Loss: 18.4665 | F1: 0.1780\n","\n","Domain: 32\n","x_dp_dom.shape: (163, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 32 | Accuracy: 0.7975 | Loss: 2.1906 | F1: 0.7573\n","\n","Domain: 33\n","x_dp_dom.shape: (156, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 33 | Accuracy: 0.4167 | Loss: 2.3645 | F1: 0.4201\n","\n","Domain: 34\n","x_dp_dom.shape: (161, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 34 | Accuracy: 0.0994 | Loss: 23.5554 | F1: 0.0922\n","\n","Domain: 35\n","x_dp_dom.shape: (159, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 35 | Accuracy: 0.8616 | Loss: 1.2964 | F1: 0.8047\n","\n","Domain: 36\n","x_dp_dom.shape: (155, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 36 | Accuracy: 0.7935 | Loss: 1.4660 | F1: 0.7408\n","\n","Domain: 37\n","x_dp_dom.shape: (154, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 37 | Accuracy: 0.6169 | Loss: 1.8463 | F1: 0.6906\n","\n","Domain: 38\n","x_dp_dom.shape: (158, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 38 | Accuracy: 0.0380 | Loss: 30.7037 | F1: 0.0070\n","\n","Domain: 39\n","x_dp_dom.shape: (165, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 39 | Accuracy: 0.8121 | Loss: 1.8623 | F1: 0.7851\n","\n","Domain: 40\n","x_dp_dom.shape: (155, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 40 | Accuracy: 0.7613 | Loss: 1.3458 | F1: 0.7732\n","\n","Domain: 41\n","x_dp_dom.shape: (156, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 41 | Accuracy: 0.1026 | Loss: 8.8035 | F1: 0.1335\n","\n","Domain: 42\n","x_dp_dom.shape: (158, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 42 | Accuracy: 0.7785 | Loss: 2.0196 | F1: 0.7346\n","\n","Domain: 43\n","x_dp_dom.shape: (153, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 43 | Accuracy: 0.1830 | Loss: 19.6560 | F1: 0.1745\n","\n","Domain: 44\n","x_dp_dom.shape: (153, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 44 | Accuracy: 0.7320 | Loss: 2.8255 | F1: 0.6710\n","\n","Domain: 45\n","x_dp_dom.shape: (163, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 45 | Accuracy: 0.8221 | Loss: 2.2010 | F1: 0.7572\n","\n","Domain: 46\n","x_dp_dom.shape: (160, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 46 | Accuracy: 0.7250 | Loss: 3.2540 | F1: 0.6288\n","\n","Domain: 47\n","x_dp_dom.shape: (155, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 47 | Accuracy: 0.8258 | Loss: 2.7846 | F1: 0.7750\n","\n","Domain: 48\n","x_dp_dom.shape: (159, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 48 | Accuracy: 0.8679 | Loss: 2.5114 | F1: 0.8107\n","\n","Domain: 49\n","x_dp_dom.shape: (164, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 49 | Accuracy: 0.7439 | Loss: 1.5070 | F1: 0.7311\n","\n","Domain: 50\n","x_dp_dom.shape: (153, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 50 | Accuracy: 0.8824 | Loss: 2.9991 | F1: 0.8401\n","\n","Domain: 51\n","x_dp_dom.shape: (157, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 51 | Accuracy: 0.7962 | Loss: 2.1550 | F1: 0.7821\n","\n","Domain: 52\n","x_dp_dom.shape: (153, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 52 | Accuracy: 0.8627 | Loss: 2.0450 | F1: 0.8270\n","\n","Domain: 53\n","x_dp_dom.shape: (159, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 53 | Accuracy: 0.1321 | Loss: 21.3487 | F1: 0.1479\n","\n","Domain: 54\n","x_dp_dom.shape: (153, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 54 | Accuracy: 0.6601 | Loss: 1.5246 | F1: 0.7272\n","\n","Domain: 55\n","x_dp_dom.shape: (160, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 55 | Accuracy: 0.8500 | Loss: 1.6641 | F1: 0.7940\n","\n","Domain: 56\n","x_dp_dom.shape: (153, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 56 | Accuracy: 0.8693 | Loss: 2.4909 | F1: 0.8335\n","\n","Domain: 57\n","x_dp_dom.shape: (153, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 57 | Accuracy: 0.7582 | Loss: 3.1443 | F1: 0.7585\n","\n","Domain: 58\n","x_dp_dom.shape: (149, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 58 | Accuracy: 0.9195 | Loss: 2.1556 | F1: 0.8877\n","\n","Domain: 59\n","x_dp_dom.shape: (154, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 59 | Accuracy: 0.8896 | Loss: 2.4880 | F1: 0.8446\n","\n","Domain: 60\n","x_dp_dom.shape: (158, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 60 | Accuracy: 0.1772 | Loss: 18.6018 | F1: 0.1445\n","\n","Domain: 61\n","x_dp_dom.shape: (158, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 61 | Accuracy: 0.8165 | Loss: 1.0649 | F1: 0.7851\n","\n","Domain: 62\n","x_dp_dom.shape: (158, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 62 | Accuracy: 0.7848 | Loss: 1.7666 | F1: 0.7314\n","\n","Domain: 63\n","x_dp_dom.shape: (153, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 63 | Accuracy: 0.8693 | Loss: 2.3310 | F1: 0.8338\n","\n","Domain: 64\n","x_dp_dom.shape: (154, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 64 | Accuracy: 0.8701 | Loss: 1.8150 | F1: 0.8312\n","\n","Domain: 65\n","x_dp_dom.shape: (161, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 65 | Accuracy: 0.8385 | Loss: 0.8731 | F1: 0.8307\n","\n","Domain: 66\n","x_dp_dom.shape: (153, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 66 | Accuracy: 0.8170 | Loss: 2.8132 | F1: 0.8180\n","\n","Domain: 67\n","x_dp_dom.shape: (153, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 67 | Accuracy: 0.9477 | Loss: 1.1896 | F1: 0.9261\n","\n","Domain: 68\n","x_dp_dom.shape: (154, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 68 | Accuracy: 0.7987 | Loss: 2.7144 | F1: 0.7508\n","\n","Domain: 69\n","x_dp_dom.shape: (153, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 69 | Accuracy: 0.9085 | Loss: 2.3611 | F1: 0.8655\n","\n","Domain: 70\n","x_dp_dom.shape: (153, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 70 | Accuracy: 0.7778 | Loss: 1.9378 | F1: 0.7105\n","\n","Domain: 71\n","x_dp_dom.shape: (155, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 71 | Accuracy: 0.7806 | Loss: 2.9421 | F1: 0.7162\n","\n","Domain: 72\n","x_dp_dom.shape: (153, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 72 | Accuracy: 0.8693 | Loss: 2.7604 | F1: 0.8266\n","\n","Domain: 73\n","x_dp_dom.shape: (152, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 73 | Accuracy: 0.2039 | Loss: 23.0997 | F1: 0.1748\n","\n","Domain: 74\n","x_dp_dom.shape: (146, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 74 | Accuracy: 0.8493 | Loss: 2.9836 | F1: 0.8191\n","\n","Domain: 75\n","x_dp_dom.shape: (153, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 75 | Accuracy: 0.8627 | Loss: 1.6832 | F1: 0.8418\n","\n","Mean accuracy for run 9: 0.7006\n","Mean F1 for run 9: 0.6658\n","\n","Mean accuracy over 10 runs: 0.2129 +- 0.1689\n","Mean F1 over 10 runs: 0.1506 +- 0.1753\n","\n"]}],"source":["def compute_TSTR_Df(dataset):\n","    accs = []\n","    f1s = []\n","\n","    for i in range(n_runs):\n","\n","        accs_run = []\n","        f1s_run = []\n","\n","        for src_class in config[dataset]['class_names']:\n","            if src_class != 'WAL':\n","                continue\n","\n","            print(f\"Source class: {src_class}\\n\")\n","\n","            # Load Df data\n","            x_df, y_df, k_df = get_data(dataset, 'df', src_class)\n","            print(f'x_df.shape: {x_df.shape} | np.unique(y_df): {np.unique(y_df)}\\n')\n","\n","            # Train on Df data\n","            print('Training on Df data...')\n","            df_model = train_only(x_df, y_df, dataset, num_epochs=num_epochs)\n","\n","            for domain in range(config[dataset]['num_df_domains'], config[dataset]['num_df_domains'] + config[dataset]['num_dp_domains']):\n","                print(f\"Domain: {domain}\")\n","\n","                # Load Dp data\n","                x_dp_dom, y_dp_dom, k_dp_dom = get_data(dataset, 'dp', src_class, domain)\n","                print(f'x_dp_dom.shape: {x_dp_dom.shape} | np.unique(y_dp_dom): {np.unique(y_dp_dom)}\\n')\n","\n","                # Evaluate on Dp data\n","                acc, loss, f1 = evaluate_model(df_model, get_dataloader(x_dp_dom, y_dp_dom))\n","                save_scores(src_class, domain, acc, loss, f1, 'Df', dataset)\n","                accs_run.append(acc)\n","                f1s_run.append(f1)\n","                print(f'Source class: {src_class} | Domain: {domain} | Accuracy: {acc:.4f} | Loss: {loss:.4f} | F1: {f1:.4f}\\n')\n","\n","        print(f\"Mean accuracy for run {i}: {np.mean(accs_run):.4f}\")\n","        print(f\"Mean F1 for run {i}: {np.mean(f1s_run):.4f}\\n\")\n","        accs.append(np.mean(accs_run))\n","        f1s.append(np.mean(f1s_run))\n","\n","    print(f\"Mean accuracy over {n_runs} runs: {np.mean(accs):.4f} +- {np.std(accs):.4f}\")\n","    print(f\"Mean F1 over {n_runs} runs: {np.mean(f1s):.4f} +- {np.std(f1s):.4f}\\n\")\n","\n","\n","\n","\n","compute_TSTR_Df('realworld_mobiact')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1008890,"status":"ok","timestamp":1732650114408,"user":{"displayName":"Pietro","userId":"07073247908758556229"},"user_tz":-60},"id":"6X3sBMvtdTCl","outputId":"43489865-5bba-4e9b-c294-88472b38b2d2"},"outputs":[{"name":"stdout","output_type":"stream","text":["Source class: WAL\n","\n","x_df.shape: (11483, 3, 128) | np.unique(y_df): [0 1 2 3]\n","\n","Training on Df data...\n","\tEpoch 10/100 - Train loss: 0.2529 - Val accuracy: 0.4645 - Val loss: 1.3613 - Val F1: 0.4208 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.2127 - Val accuracy: 0.5024 - Val loss: 2.8284 - Val F1: 0.3550 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.1693 - Val accuracy: 0.5011 - Val loss: 5.0347 - Val F1: 0.3559 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.1470 - Val accuracy: 0.5020 - Val loss: 5.4479 - Val F1: 0.3666 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.1425 - Val accuracy: 0.5015 - Val loss: 6.9412 - Val F1: 0.3682 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.1356 - Val accuracy: 0.5020 - Val loss: 8.2558 - Val F1: 0.3722 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.1197 - Val accuracy: 0.5020 - Val loss: 6.1627 - Val F1: 0.3740 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.1247 - Val accuracy: 0.5015 - Val loss: 6.8812 - Val F1: 0.3748 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.1111 - Val accuracy: 0.5015 - Val loss: 7.4221 - Val F1: 0.3748 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.1092 - Val accuracy: 0.5020 - Val loss: 6.8401 - Val F1: 0.3747 - LR: 0.00e+00\n","\tBest epoch: 6 - Best val accuracy: 0.5947 - Best val loss: 0.9137 - Best val F1: 0.5667\n","\n","Domain: 15\n","x_dp_dom.shape: (161, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 15 | Accuracy: 0.2484 | Loss: 4.6568 | F1: 0.1876\n","\n","Domain: 16\n","x_dp_dom.shape: (165, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 16 | Accuracy: 0.2606 | Loss: 4.7933 | F1: 0.2045\n","\n","Domain: 17\n","x_dp_dom.shape: (164, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 17 | Accuracy: 0.1829 | Loss: 4.4000 | F1: 0.1428\n","\n","Domain: 18\n","x_dp_dom.shape: (166, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 18 | Accuracy: 0.1928 | Loss: 6.5908 | F1: 0.1502\n","\n","Domain: 19\n","x_dp_dom.shape: (165, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 19 | Accuracy: 0.2303 | Loss: 7.1077 | F1: 0.1737\n","\n","Domain: 20\n","x_dp_dom.shape: (162, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 20 | Accuracy: 0.2222 | Loss: 4.7658 | F1: 0.1785\n","\n","Domain: 21\n","x_dp_dom.shape: (159, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 21 | Accuracy: 0.2516 | Loss: 5.9135 | F1: 0.1913\n","\n","Domain: 22\n","x_dp_dom.shape: (165, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 22 | Accuracy: 0.2606 | Loss: 5.1051 | F1: 0.1942\n","\n","Domain: 23\n","x_dp_dom.shape: (164, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 23 | Accuracy: 0.2439 | Loss: 5.7528 | F1: 0.1502\n","\n","Domain: 24\n","x_dp_dom.shape: (162, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 24 | Accuracy: 0.2222 | Loss: 3.9797 | F1: 0.1720\n","\n","Domain: 25\n","x_dp_dom.shape: (166, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 25 | Accuracy: 0.2349 | Loss: 5.2672 | F1: 0.1804\n","\n","Domain: 26\n","x_dp_dom.shape: (153, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 26 | Accuracy: 0.2353 | Loss: 5.9548 | F1: 0.1953\n","\n","Domain: 27\n","x_dp_dom.shape: (165, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 27 | Accuracy: 0.2061 | Loss: 7.5675 | F1: 0.1595\n","\n","Domain: 28\n","x_dp_dom.shape: (153, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 28 | Accuracy: 0.2288 | Loss: 8.3042 | F1: 0.1879\n","\n","Domain: 29\n","x_dp_dom.shape: (153, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 29 | Accuracy: 0.2092 | Loss: 7.5579 | F1: 0.1774\n","\n","Domain: 30\n","x_dp_dom.shape: (161, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 30 | Accuracy: 0.2547 | Loss: 7.8750 | F1: 0.2045\n","\n","Domain: 31\n","x_dp_dom.shape: (154, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 31 | Accuracy: 0.2468 | Loss: 7.0110 | F1: 0.2094\n","\n","Domain: 32\n","x_dp_dom.shape: (163, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 32 | Accuracy: 0.2025 | Loss: 4.8727 | F1: 0.1575\n","\n","Domain: 33\n","x_dp_dom.shape: (156, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 33 | Accuracy: 0.2756 | Loss: 3.8909 | F1: 0.2098\n","\n","Domain: 34\n","x_dp_dom.shape: (161, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 34 | Accuracy: 0.2733 | Loss: 4.7759 | F1: 0.2157\n","\n","Domain: 35\n","x_dp_dom.shape: (159, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 35 | Accuracy: 0.2704 | Loss: 10.1444 | F1: 0.2120\n","\n","Domain: 36\n","x_dp_dom.shape: (155, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 36 | Accuracy: 0.1355 | Loss: 4.1474 | F1: 0.1105\n","\n","Domain: 37\n","x_dp_dom.shape: (154, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 37 | Accuracy: 0.2273 | Loss: 5.8752 | F1: 0.1847\n","\n","Domain: 38\n","x_dp_dom.shape: (158, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 38 | Accuracy: 0.2468 | Loss: 5.8212 | F1: 0.1868\n","\n","Domain: 39\n","x_dp_dom.shape: (165, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 39 | Accuracy: 0.2303 | Loss: 5.0330 | F1: 0.1766\n","\n","Domain: 40\n","x_dp_dom.shape: (155, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 40 | Accuracy: 0.2387 | Loss: 4.3715 | F1: 0.1928\n","\n","Domain: 41\n","x_dp_dom.shape: (156, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 41 | Accuracy: 0.2051 | Loss: 10.8007 | F1: 0.1382\n","\n","Domain: 42\n","x_dp_dom.shape: (158, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 42 | Accuracy: 0.1899 | Loss: 5.9779 | F1: 0.1655\n","\n","Domain: 43\n","x_dp_dom.shape: (153, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 43 | Accuracy: 0.2353 | Loss: 7.2071 | F1: 0.2029\n","\n","Domain: 44\n","x_dp_dom.shape: (153, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 44 | Accuracy: 0.2288 | Loss: 6.4732 | F1: 0.1935\n","\n","Domain: 45\n","x_dp_dom.shape: (163, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 45 | Accuracy: 0.2822 | Loss: 3.5425 | F1: 0.2274\n","\n","Domain: 46\n","x_dp_dom.shape: (160, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 46 | Accuracy: 0.2437 | Loss: 10.9212 | F1: 0.1831\n","\n","Domain: 47\n","x_dp_dom.shape: (155, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 47 | Accuracy: 0.1935 | Loss: 7.1403 | F1: 0.1639\n","\n","Domain: 48\n","x_dp_dom.shape: (159, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 48 | Accuracy: 0.2642 | Loss: 4.4248 | F1: 0.2110\n","\n","Domain: 49\n","x_dp_dom.shape: (164, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 49 | Accuracy: 0.2256 | Loss: 3.4543 | F1: 0.1802\n","\n","Domain: 50\n","x_dp_dom.shape: (153, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 50 | Accuracy: 0.3333 | Loss: 2.0120 | F1: 0.3039\n","\n","Domain: 51\n","x_dp_dom.shape: (157, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 51 | Accuracy: 0.2420 | Loss: 8.0184 | F1: 0.2042\n","\n","Domain: 52\n","x_dp_dom.shape: (153, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 52 | Accuracy: 0.2288 | Loss: 3.4109 | F1: 0.1887\n","\n","Domain: 53\n","x_dp_dom.shape: (159, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 53 | Accuracy: 0.2516 | Loss: 5.9022 | F1: 0.1888\n","\n","Domain: 54\n","x_dp_dom.shape: (153, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 54 | Accuracy: 0.2484 | Loss: 7.1201 | F1: 0.2154\n","\n","Domain: 55\n","x_dp_dom.shape: (160, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 55 | Accuracy: 0.2313 | Loss: 3.9599 | F1: 0.1813\n","\n","Domain: 56\n","x_dp_dom.shape: (153, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 56 | Accuracy: 0.2614 | Loss: 8.1302 | F1: 0.2208\n","\n","Domain: 57\n","x_dp_dom.shape: (153, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 57 | Accuracy: 0.2680 | Loss: 4.0679 | F1: 0.2242\n","\n","Domain: 58\n","x_dp_dom.shape: (149, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 58 | Accuracy: 0.2282 | Loss: 5.5578 | F1: 0.2002\n","\n","Domain: 59\n","x_dp_dom.shape: (154, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 59 | Accuracy: 0.2208 | Loss: 5.5043 | F1: 0.1885\n","\n","Domain: 60\n","x_dp_dom.shape: (158, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 60 | Accuracy: 0.1772 | Loss: 5.1603 | F1: 0.1444\n","\n","Domain: 61\n","x_dp_dom.shape: (158, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 61 | Accuracy: 0.1899 | Loss: 8.2628 | F1: 0.1559\n","\n","Domain: 62\n","x_dp_dom.shape: (158, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 62 | Accuracy: 0.3924 | Loss: 1.0503 | F1: 0.4117\n","\n","Domain: 63\n","x_dp_dom.shape: (153, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 63 | Accuracy: 0.2418 | Loss: 5.5309 | F1: 0.2072\n","\n","Domain: 64\n","x_dp_dom.shape: (154, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 64 | Accuracy: 0.2338 | Loss: 4.5952 | F1: 0.1895\n","\n","Domain: 65\n","x_dp_dom.shape: (161, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 65 | Accuracy: 0.2733 | Loss: 4.2629 | F1: 0.2089\n","\n","Domain: 66\n","x_dp_dom.shape: (153, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 66 | Accuracy: 0.2157 | Loss: 7.6270 | F1: 0.1931\n","\n","Domain: 67\n","x_dp_dom.shape: (153, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 67 | Accuracy: 0.2353 | Loss: 7.2218 | F1: 0.1897\n","\n","Domain: 68\n","x_dp_dom.shape: (154, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 68 | Accuracy: 0.1299 | Loss: 4.6897 | F1: 0.0972\n","\n","Domain: 69\n","x_dp_dom.shape: (153, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 69 | Accuracy: 0.2353 | Loss: 7.3412 | F1: 0.1993\n","\n","Domain: 70\n","x_dp_dom.shape: (153, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 70 | Accuracy: 0.2418 | Loss: 7.5251 | F1: 0.2054\n","\n","Domain: 71\n","x_dp_dom.shape: (155, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 71 | Accuracy: 0.2710 | Loss: 6.0914 | F1: 0.2241\n","\n","Domain: 72\n","x_dp_dom.shape: (153, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 72 | Accuracy: 0.1176 | Loss: 6.3070 | F1: 0.1081\n","\n","Domain: 73\n","x_dp_dom.shape: (152, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 73 | Accuracy: 0.2303 | Loss: 5.5127 | F1: 0.1891\n","\n","Domain: 74\n","x_dp_dom.shape: (146, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 74 | Accuracy: 0.1986 | Loss: 7.5114 | F1: 0.1779\n","\n","Domain: 75\n","x_dp_dom.shape: (153, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 75 | Accuracy: 0.2222 | Loss: 4.4767 | F1: 0.1942\n","\n","Mean accuracy for run 0: 0.2331\n","Mean F1 for run 0: 0.1899\n","\n","Source class: WAL\n","\n","x_df.shape: (11483, 3, 128) | np.unique(y_df): [0 1 2 3]\n","\n","Training on Df data...\n","\tEpoch 10/100 - Train loss: 0.2717 - Val accuracy: 0.4184 - Val loss: 1.5584 - Val F1: 0.3568 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.2052 - Val accuracy: 0.3444 - Val loss: 3.9968 - Val F1: 0.2744 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.1740 - Val accuracy: 0.4275 - Val loss: 4.2479 - Val F1: 0.3511 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.1535 - Val accuracy: 0.4806 - Val loss: 3.7028 - Val F1: 0.4039 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.1500 - Val accuracy: 0.4724 - Val loss: 4.2880 - Val F1: 0.3874 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.1316 - Val accuracy: 0.4972 - Val loss: 4.6748 - Val F1: 0.4029 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.1348 - Val accuracy: 0.5063 - Val loss: 5.9521 - Val F1: 0.3899 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.1282 - Val accuracy: 0.4771 - Val loss: 6.4708 - Val F1: 0.3833 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.1202 - Val accuracy: 0.5020 - Val loss: 6.3671 - Val F1: 0.3897 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.1129 - Val accuracy: 0.5046 - Val loss: 6.0094 - Val F1: 0.3906 - LR: 0.00e+00\n","\tBest epoch: 2 - Best val accuracy: 0.4750 - Best val loss: 1.0067 - Best val F1: 0.4293\n","\n","Domain: 15\n","x_dp_dom.shape: (161, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 15 | Accuracy: 0.0870 | Loss: 4.7597 | F1: 0.0381\n","\n","Domain: 16\n","x_dp_dom.shape: (165, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 16 | Accuracy: 0.2909 | Loss: 2.2525 | F1: 0.2687\n","\n","Domain: 17\n","x_dp_dom.shape: (164, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 17 | Accuracy: 0.2439 | Loss: 2.4340 | F1: 0.2229\n","\n","Domain: 18\n","x_dp_dom.shape: (166, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 18 | Accuracy: 0.1928 | Loss: 4.3961 | F1: 0.1797\n","\n","Domain: 19\n","x_dp_dom.shape: (165, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 19 | Accuracy: 0.1939 | Loss: 2.9383 | F1: 0.1509\n","\n","Domain: 20\n","x_dp_dom.shape: (162, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 20 | Accuracy: 0.2531 | Loss: 3.4104 | F1: 0.1925\n","\n","Domain: 21\n","x_dp_dom.shape: (159, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 21 | Accuracy: 0.2516 | Loss: 2.6860 | F1: 0.2282\n","\n","Domain: 22\n","x_dp_dom.shape: (165, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 22 | Accuracy: 0.2727 | Loss: 4.6635 | F1: 0.2199\n","\n","Domain: 23\n","x_dp_dom.shape: (164, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 23 | Accuracy: 0.2622 | Loss: 6.1346 | F1: 0.2201\n","\n","Domain: 24\n","x_dp_dom.shape: (162, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 24 | Accuracy: 0.2160 | Loss: 4.6651 | F1: 0.1718\n","\n","Domain: 25\n","x_dp_dom.shape: (166, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 25 | Accuracy: 0.2892 | Loss: 2.5801 | F1: 0.3141\n","\n","Domain: 26\n","x_dp_dom.shape: (153, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 26 | Accuracy: 0.1961 | Loss: 4.5466 | F1: 0.1865\n","\n","Domain: 27\n","x_dp_dom.shape: (165, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 27 | Accuracy: 0.2606 | Loss: 4.6060 | F1: 0.2105\n","\n","Domain: 28\n","x_dp_dom.shape: (153, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 28 | Accuracy: 0.2092 | Loss: 5.7180 | F1: 0.1759\n","\n","Domain: 29\n","x_dp_dom.shape: (153, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 29 | Accuracy: 0.1176 | Loss: 7.6677 | F1: 0.0909\n","\n","Domain: 30\n","x_dp_dom.shape: (161, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 30 | Accuracy: 0.2484 | Loss: 9.0925 | F1: 0.2025\n","\n","Domain: 31\n","x_dp_dom.shape: (154, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 31 | Accuracy: 0.2597 | Loss: 12.3118 | F1: 0.2179\n","\n","Domain: 32\n","x_dp_dom.shape: (163, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 32 | Accuracy: 0.1840 | Loss: 4.0215 | F1: 0.1509\n","\n","Domain: 33\n","x_dp_dom.shape: (156, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 33 | Accuracy: 0.2628 | Loss: 5.1347 | F1: 0.2058\n","\n","Domain: 34\n","x_dp_dom.shape: (161, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 34 | Accuracy: 0.2422 | Loss: 7.9952 | F1: 0.1979\n","\n","Domain: 35\n","x_dp_dom.shape: (159, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 35 | Accuracy: 0.2138 | Loss: 6.2478 | F1: 0.1893\n","\n","Domain: 36\n","x_dp_dom.shape: (155, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 36 | Accuracy: 0.2065 | Loss: 2.6577 | F1: 0.1928\n","\n","Domain: 37\n","x_dp_dom.shape: (154, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 37 | Accuracy: 0.1429 | Loss: 5.1502 | F1: 0.1275\n","\n","Domain: 38\n","x_dp_dom.shape: (158, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 38 | Accuracy: 0.2532 | Loss: 10.9071 | F1: 0.1931\n","\n","Domain: 39\n","x_dp_dom.shape: (165, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 39 | Accuracy: 0.1939 | Loss: 3.5650 | F1: 0.1592\n","\n","Domain: 40\n","x_dp_dom.shape: (155, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 40 | Accuracy: 0.2452 | Loss: 3.4540 | F1: 0.2426\n","\n","Domain: 41\n","x_dp_dom.shape: (156, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 41 | Accuracy: 0.1859 | Loss: 13.2918 | F1: 0.1581\n","\n","Domain: 42\n","x_dp_dom.shape: (158, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 42 | Accuracy: 0.1772 | Loss: 7.4168 | F1: 0.1768\n","\n","Domain: 43\n","x_dp_dom.shape: (153, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 43 | Accuracy: 0.1765 | Loss: 12.0152 | F1: 0.1640\n","\n","Domain: 44\n","x_dp_dom.shape: (153, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 44 | Accuracy: 0.2222 | Loss: 4.8880 | F1: 0.1812\n","\n","Domain: 45\n","x_dp_dom.shape: (163, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 45 | Accuracy: 0.2393 | Loss: 1.8156 | F1: 0.1906\n","\n","Domain: 46\n","x_dp_dom.shape: (160, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 46 | Accuracy: 0.2437 | Loss: 5.7354 | F1: 0.1831\n","\n","Domain: 47\n","x_dp_dom.shape: (155, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 47 | Accuracy: 0.2452 | Loss: 3.3963 | F1: 0.1968\n","\n","Domain: 48\n","x_dp_dom.shape: (159, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 48 | Accuracy: 0.2893 | Loss: 4.5008 | F1: 0.2167\n","\n","Domain: 49\n","x_dp_dom.shape: (164, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 49 | Accuracy: 0.2439 | Loss: 2.2934 | F1: 0.1998\n","\n","Domain: 50\n","x_dp_dom.shape: (153, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 50 | Accuracy: 0.2549 | Loss: 6.5143 | F1: 0.1976\n","\n","Domain: 51\n","x_dp_dom.shape: (157, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 51 | Accuracy: 0.2420 | Loss: 3.6441 | F1: 0.2017\n","\n","Domain: 52\n","x_dp_dom.shape: (153, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 52 | Accuracy: 0.2418 | Loss: 5.0343 | F1: 0.1934\n","\n","Domain: 53\n","x_dp_dom.shape: (159, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 53 | Accuracy: 0.2390 | Loss: 10.7826 | F1: 0.1892\n","\n","Domain: 54\n","x_dp_dom.shape: (153, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 54 | Accuracy: 0.2484 | Loss: 4.9645 | F1: 0.2154\n","\n","Domain: 55\n","x_dp_dom.shape: (160, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 55 | Accuracy: 0.2125 | Loss: 3.5422 | F1: 0.1608\n","\n","Domain: 56\n","x_dp_dom.shape: (153, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 56 | Accuracy: 0.2484 | Loss: 4.9283 | F1: 0.1989\n","\n","Domain: 57\n","x_dp_dom.shape: (153, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 57 | Accuracy: 0.2288 | Loss: 4.3642 | F1: 0.1839\n","\n","Domain: 58\n","x_dp_dom.shape: (149, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 58 | Accuracy: 0.2148 | Loss: 6.8590 | F1: 0.1996\n","\n","Domain: 59\n","x_dp_dom.shape: (154, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 59 | Accuracy: 0.1039 | Loss: 6.2361 | F1: 0.0448\n","\n","Domain: 60\n","x_dp_dom.shape: (158, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 60 | Accuracy: 0.1076 | Loss: 12.1865 | F1: 0.0721\n","\n","Domain: 61\n","x_dp_dom.shape: (158, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 61 | Accuracy: 0.1266 | Loss: 5.1662 | F1: 0.1098\n","\n","Domain: 62\n","x_dp_dom.shape: (158, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 62 | Accuracy: 0.5316 | Loss: 0.8175 | F1: 0.6155\n","\n","Domain: 63\n","x_dp_dom.shape: (153, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 63 | Accuracy: 0.2157 | Loss: 4.1861 | F1: 0.1798\n","\n","Domain: 64\n","x_dp_dom.shape: (154, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 64 | Accuracy: 0.2403 | Loss: 2.6140 | F1: 0.2165\n","\n","Domain: 65\n","x_dp_dom.shape: (161, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 65 | Accuracy: 0.1988 | Loss: 3.3171 | F1: 0.1606\n","\n","Domain: 66\n","x_dp_dom.shape: (153, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 66 | Accuracy: 0.0588 | Loss: 7.3861 | F1: 0.0432\n","\n","Domain: 67\n","x_dp_dom.shape: (153, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 67 | Accuracy: 0.2418 | Loss: 6.4635 | F1: 0.1859\n","\n","Domain: 68\n","x_dp_dom.shape: (154, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 68 | Accuracy: 0.1623 | Loss: 5.6523 | F1: 0.1304\n","\n","Domain: 69\n","x_dp_dom.shape: (153, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 69 | Accuracy: 0.0915 | Loss: 4.9256 | F1: 0.0590\n","\n","Domain: 70\n","x_dp_dom.shape: (153, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 70 | Accuracy: 0.2484 | Loss: 7.7698 | F1: 0.2183\n","\n","Domain: 71\n","x_dp_dom.shape: (155, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 71 | Accuracy: 0.2645 | Loss: 4.7677 | F1: 0.2064\n","\n","Domain: 72\n","x_dp_dom.shape: (153, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 72 | Accuracy: 0.2092 | Loss: 4.6807 | F1: 0.1795\n","\n","Domain: 73\n","x_dp_dom.shape: (152, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 73 | Accuracy: 0.0658 | Loss: 11.2668 | F1: 0.0398\n","\n","Domain: 74\n","x_dp_dom.shape: (146, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 74 | Accuracy: 0.1849 | Loss: 8.1449 | F1: 0.1786\n","\n","Domain: 75\n","x_dp_dom.shape: (153, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 75 | Accuracy: 0.2222 | Loss: 1.9752 | F1: 0.2156\n","\n","Mean accuracy for run 1: 0.2167\n","Mean F1 for run 1: 0.1838\n","\n","Source class: WAL\n","\n","x_df.shape: (11483, 3, 128) | np.unique(y_df): [0 1 2 3]\n","\n","Training on Df data...\n","\tEpoch 10/100 - Train loss: 0.2656 - Val accuracy: 0.3139 - Val loss: 2.9032 - Val F1: 0.2243 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.1978 - Val accuracy: 0.2573 - Val loss: 5.0182 - Val F1: 0.1572 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.1758 - Val accuracy: 0.3648 - Val loss: 6.2780 - Val F1: 0.2917 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.1620 - Val accuracy: 0.3243 - Val loss: 6.1419 - Val F1: 0.2520 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.1531 - Val accuracy: 0.3087 - Val loss: 8.5569 - Val F1: 0.2301 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.1339 - Val accuracy: 0.3770 - Val loss: 8.4475 - Val F1: 0.3004 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.1292 - Val accuracy: 0.3692 - Val loss: 9.2392 - Val F1: 0.2922 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.1209 - Val accuracy: 0.3997 - Val loss: 8.6402 - Val F1: 0.3187 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.1280 - Val accuracy: 0.4105 - Val loss: 9.4267 - Val F1: 0.3263 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.1126 - Val accuracy: 0.4036 - Val loss: 8.7072 - Val F1: 0.3199 - LR: 0.00e+00\n","\tBest epoch: 3 - Best val accuracy: 0.4201 - Best val loss: 1.2607 - Best val F1: 0.4025\n","\n","Domain: 15\n","x_dp_dom.shape: (161, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 15 | Accuracy: 0.2919 | Loss: 4.2419 | F1: 0.2775\n","\n","Domain: 16\n","x_dp_dom.shape: (165, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 16 | Accuracy: 0.2485 | Loss: 4.7464 | F1: 0.1903\n","\n","Domain: 17\n","x_dp_dom.shape: (164, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 17 | Accuracy: 0.2378 | Loss: 4.9487 | F1: 0.1782\n","\n","Domain: 18\n","x_dp_dom.shape: (166, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 18 | Accuracy: 0.2289 | Loss: 4.0296 | F1: 0.1886\n","\n","Domain: 19\n","x_dp_dom.shape: (165, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 19 | Accuracy: 0.2182 | Loss: 6.4765 | F1: 0.1666\n","\n","Domain: 20\n","x_dp_dom.shape: (162, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 20 | Accuracy: 0.2037 | Loss: 3.8068 | F1: 0.1593\n","\n","Domain: 21\n","x_dp_dom.shape: (159, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 21 | Accuracy: 0.2516 | Loss: 4.5201 | F1: 0.1987\n","\n","Domain: 22\n","x_dp_dom.shape: (165, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 22 | Accuracy: 0.2545 | Loss: 3.7931 | F1: 0.2001\n","\n","Domain: 23\n","x_dp_dom.shape: (164, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 23 | Accuracy: 0.2500 | Loss: 5.6078 | F1: 0.1358\n","\n","Domain: 24\n","x_dp_dom.shape: (162, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 24 | Accuracy: 0.1667 | Loss: 4.9111 | F1: 0.1391\n","\n","Domain: 25\n","x_dp_dom.shape: (166, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 25 | Accuracy: 0.2349 | Loss: 4.6425 | F1: 0.1800\n","\n","Domain: 26\n","x_dp_dom.shape: (153, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 26 | Accuracy: 0.2157 | Loss: 4.7420 | F1: 0.2060\n","\n","Domain: 27\n","x_dp_dom.shape: (165, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 27 | Accuracy: 0.2424 | Loss: 5.8081 | F1: 0.2013\n","\n","Domain: 28\n","x_dp_dom.shape: (153, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 28 | Accuracy: 0.2353 | Loss: 6.0718 | F1: 0.1918\n","\n","Domain: 29\n","x_dp_dom.shape: (153, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 29 | Accuracy: 0.1569 | Loss: 7.5540 | F1: 0.1432\n","\n","Domain: 30\n","x_dp_dom.shape: (161, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 30 | Accuracy: 0.2484 | Loss: 8.0958 | F1: 0.1988\n","\n","Domain: 31\n","x_dp_dom.shape: (154, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 31 | Accuracy: 0.2273 | Loss: 12.4785 | F1: 0.1847\n","\n","Domain: 32\n","x_dp_dom.shape: (163, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 32 | Accuracy: 0.2577 | Loss: 3.1493 | F1: 0.2011\n","\n","Domain: 33\n","x_dp_dom.shape: (156, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 33 | Accuracy: 0.2436 | Loss: 2.8094 | F1: 0.1916\n","\n","Domain: 34\n","x_dp_dom.shape: (161, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 34 | Accuracy: 0.2422 | Loss: 5.6956 | F1: 0.2004\n","\n","Domain: 35\n","x_dp_dom.shape: (159, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 35 | Accuracy: 0.2075 | Loss: 8.9135 | F1: 0.1626\n","\n","Domain: 36\n","x_dp_dom.shape: (155, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 36 | Accuracy: 0.2258 | Loss: 2.9546 | F1: 0.2294\n","\n","Domain: 37\n","x_dp_dom.shape: (154, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 37 | Accuracy: 0.1688 | Loss: 4.8436 | F1: 0.1484\n","\n","Domain: 38\n","x_dp_dom.shape: (158, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 38 | Accuracy: 0.2595 | Loss: 2.8518 | F1: 0.1268\n","\n","Domain: 39\n","x_dp_dom.shape: (165, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 39 | Accuracy: 0.2061 | Loss: 4.8572 | F1: 0.1636\n","\n","Domain: 40\n","x_dp_dom.shape: (155, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 40 | Accuracy: 0.2129 | Loss: 4.5223 | F1: 0.1977\n","\n","Domain: 41\n","x_dp_dom.shape: (156, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 41 | Accuracy: 0.2051 | Loss: 11.5356 | F1: 0.1672\n","\n","Domain: 42\n","x_dp_dom.shape: (158, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 42 | Accuracy: 0.2468 | Loss: 6.6096 | F1: 0.2223\n","\n","Domain: 43\n","x_dp_dom.shape: (153, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 43 | Accuracy: 0.1961 | Loss: 12.4492 | F1: 0.1759\n","\n","Domain: 44\n","x_dp_dom.shape: (153, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 44 | Accuracy: 0.2288 | Loss: 6.8720 | F1: 0.1947\n","\n","Domain: 45\n","x_dp_dom.shape: (163, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 45 | Accuracy: 0.2761 | Loss: 2.7982 | F1: 0.2091\n","\n","Domain: 46\n","x_dp_dom.shape: (160, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 46 | Accuracy: 0.2500 | Loss: 7.9430 | F1: 0.1864\n","\n","Domain: 47\n","x_dp_dom.shape: (155, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 47 | Accuracy: 0.2516 | Loss: 5.8610 | F1: 0.2099\n","\n","Domain: 48\n","x_dp_dom.shape: (159, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 48 | Accuracy: 0.2642 | Loss: 3.3205 | F1: 0.1653\n","\n","Domain: 49\n","x_dp_dom.shape: (164, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 49 | Accuracy: 0.2317 | Loss: 3.3040 | F1: 0.1797\n","\n","Domain: 50\n","x_dp_dom.shape: (153, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 50 | Accuracy: 0.3268 | Loss: 2.4652 | F1: 0.2560\n","\n","Domain: 51\n","x_dp_dom.shape: (157, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 51 | Accuracy: 0.2293 | Loss: 6.1083 | F1: 0.1827\n","\n","Domain: 52\n","x_dp_dom.shape: (153, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 52 | Accuracy: 0.3725 | Loss: 1.5263 | F1: 0.4413\n","\n","Domain: 53\n","x_dp_dom.shape: (159, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 53 | Accuracy: 0.2013 | Loss: 12.3034 | F1: 0.1611\n","\n","Domain: 54\n","x_dp_dom.shape: (153, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 54 | Accuracy: 0.2157 | Loss: 6.7652 | F1: 0.1810\n","\n","Domain: 55\n","x_dp_dom.shape: (160, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 55 | Accuracy: 0.1313 | Loss: 2.8519 | F1: 0.0919\n","\n","Domain: 56\n","x_dp_dom.shape: (153, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 56 | Accuracy: 0.2549 | Loss: 5.1212 | F1: 0.2181\n","\n","Domain: 57\n","x_dp_dom.shape: (153, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 57 | Accuracy: 0.2680 | Loss: 3.0568 | F1: 0.2201\n","\n","Domain: 58\n","x_dp_dom.shape: (149, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 58 | Accuracy: 0.2081 | Loss: 8.0099 | F1: 0.1949\n","\n","Domain: 59\n","x_dp_dom.shape: (154, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 59 | Accuracy: 0.2662 | Loss: 3.2141 | F1: 0.2444\n","\n","Domain: 60\n","x_dp_dom.shape: (158, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 60 | Accuracy: 0.1582 | Loss: 11.2756 | F1: 0.1280\n","\n","Domain: 61\n","x_dp_dom.shape: (158, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 61 | Accuracy: 0.2532 | Loss: 5.5941 | F1: 0.1959\n","\n","Domain: 62\n","x_dp_dom.shape: (158, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 62 | Accuracy: 0.2089 | Loss: 2.7769 | F1: 0.1655\n","\n","Domain: 63\n","x_dp_dom.shape: (153, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 63 | Accuracy: 0.2418 | Loss: 4.1764 | F1: 0.2057\n","\n","Domain: 64\n","x_dp_dom.shape: (154, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 64 | Accuracy: 0.2403 | Loss: 4.1087 | F1: 0.2034\n","\n","Domain: 65\n","x_dp_dom.shape: (161, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 65 | Accuracy: 0.1553 | Loss: 4.7122 | F1: 0.1175\n","\n","Domain: 66\n","x_dp_dom.shape: (153, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 66 | Accuracy: 0.2222 | Loss: 4.0640 | F1: 0.1857\n","\n","Domain: 67\n","x_dp_dom.shape: (153, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 67 | Accuracy: 0.2026 | Loss: 6.7315 | F1: 0.1641\n","\n","Domain: 68\n","x_dp_dom.shape: (154, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 68 | Accuracy: 0.2338 | Loss: 4.3483 | F1: 0.1900\n","\n","Domain: 69\n","x_dp_dom.shape: (153, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 69 | Accuracy: 0.2157 | Loss: 5.9242 | F1: 0.1810\n","\n","Domain: 70\n","x_dp_dom.shape: (153, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 70 | Accuracy: 0.2353 | Loss: 6.0374 | F1: 0.2031\n","\n","Domain: 71\n","x_dp_dom.shape: (155, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 71 | Accuracy: 0.2645 | Loss: 5.4866 | F1: 0.2214\n","\n","Domain: 72\n","x_dp_dom.shape: (153, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 72 | Accuracy: 0.1830 | Loss: 4.4286 | F1: 0.1617\n","\n","Domain: 73\n","x_dp_dom.shape: (152, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 73 | Accuracy: 0.1250 | Loss: 10.6995 | F1: 0.1149\n","\n","Domain: 74\n","x_dp_dom.shape: (146, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 74 | Accuracy: 0.1849 | Loss: 7.1140 | F1: 0.1726\n","\n","Domain: 75\n","x_dp_dom.shape: (153, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 75 | Accuracy: 0.2222 | Loss: 2.8715 | F1: 0.1845\n","\n","Mean accuracy for run 2: 0.2280\n","Mean F1 for run 2: 0.1879\n","\n","Source class: WAL\n","\n","x_df.shape: (11483, 3, 128) | np.unique(y_df): [0 1 2 3]\n","\n","Training on Df data...\n","\tEpoch 10/100 - Train loss: 0.2758 - Val accuracy: 0.2577 - Val loss: 3.8053 - Val F1: 0.1444 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.1996 - Val accuracy: 0.2407 - Val loss: 7.9406 - Val F1: 0.1288 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.1681 - Val accuracy: 0.2342 - Val loss: 10.8649 - Val F1: 0.1104 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.1538 - Val accuracy: 0.2586 - Val loss: 9.1786 - Val F1: 0.1575 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.1385 - Val accuracy: 0.2529 - Val loss: 9.4023 - Val F1: 0.1481 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.1233 - Val accuracy: 0.2590 - Val loss: 9.7950 - Val F1: 0.1581 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.1188 - Val accuracy: 0.2525 - Val loss: 12.4001 - Val F1: 0.1438 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.1102 - Val accuracy: 0.2564 - Val loss: 13.1344 - Val F1: 0.1502 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.1141 - Val accuracy: 0.2817 - Val loss: 12.0008 - Val F1: 0.1921 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.1048 - Val accuracy: 0.2490 - Val loss: 11.6628 - Val F1: 0.1421 - LR: 0.00e+00\n","\tBest epoch: 2 - Best val accuracy: 0.6191 - Best val loss: 0.8144 - Best val F1: 0.5957\n","\n","Domain: 15\n","x_dp_dom.shape: (161, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 15 | Accuracy: 0.0745 | Loss: 7.8097 | F1: 0.0118\n","\n","Domain: 16\n","x_dp_dom.shape: (165, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 16 | Accuracy: 0.2182 | Loss: 4.0661 | F1: 0.1668\n","\n","Domain: 17\n","x_dp_dom.shape: (164, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 17 | Accuracy: 0.1768 | Loss: 6.8985 | F1: 0.1379\n","\n","Domain: 18\n","x_dp_dom.shape: (166, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 18 | Accuracy: 0.2229 | Loss: 5.5032 | F1: 0.1852\n","\n","Domain: 19\n","x_dp_dom.shape: (165, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 19 | Accuracy: 0.2242 | Loss: 6.3657 | F1: 0.1703\n","\n","Domain: 20\n","x_dp_dom.shape: (162, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 20 | Accuracy: 0.2099 | Loss: 4.2364 | F1: 0.1642\n","\n","Domain: 21\n","x_dp_dom.shape: (159, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 21 | Accuracy: 0.2453 | Loss: 5.2808 | F1: 0.1897\n","\n","Domain: 22\n","x_dp_dom.shape: (165, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 22 | Accuracy: 0.2606 | Loss: 5.0390 | F1: 0.2004\n","\n","Domain: 23\n","x_dp_dom.shape: (164, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 23 | Accuracy: 0.2744 | Loss: 5.6796 | F1: 0.2232\n","\n","Domain: 24\n","x_dp_dom.shape: (162, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 24 | Accuracy: 0.1296 | Loss: 6.8182 | F1: 0.1061\n","\n","Domain: 25\n","x_dp_dom.shape: (166, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 25 | Accuracy: 0.2349 | Loss: 4.2113 | F1: 0.1816\n","\n","Domain: 26\n","x_dp_dom.shape: (153, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 26 | Accuracy: 0.1895 | Loss: 6.1109 | F1: 0.1818\n","\n","Domain: 27\n","x_dp_dom.shape: (165, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 27 | Accuracy: 0.2485 | Loss: 5.2207 | F1: 0.2003\n","\n","Domain: 28\n","x_dp_dom.shape: (153, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 28 | Accuracy: 0.2222 | Loss: 6.4427 | F1: 0.1861\n","\n","Domain: 29\n","x_dp_dom.shape: (153, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 29 | Accuracy: 0.1634 | Loss: 6.3559 | F1: 0.1471\n","\n","Domain: 30\n","x_dp_dom.shape: (161, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 30 | Accuracy: 0.2298 | Loss: 11.5251 | F1: 0.1919\n","\n","Domain: 31\n","x_dp_dom.shape: (154, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 31 | Accuracy: 0.2532 | Loss: 19.0205 | F1: 0.2152\n","\n","Domain: 32\n","x_dp_dom.shape: (163, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 32 | Accuracy: 0.1534 | Loss: 4.5980 | F1: 0.1191\n","\n","Domain: 33\n","x_dp_dom.shape: (156, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 33 | Accuracy: 0.1987 | Loss: 5.0494 | F1: 0.1639\n","\n","Domain: 34\n","x_dp_dom.shape: (161, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 34 | Accuracy: 0.2112 | Loss: 10.2358 | F1: 0.1742\n","\n","Domain: 35\n","x_dp_dom.shape: (159, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 35 | Accuracy: 0.0881 | Loss: 8.2937 | F1: 0.0269\n","\n","Domain: 36\n","x_dp_dom.shape: (155, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 36 | Accuracy: 0.0968 | Loss: 4.9093 | F1: 0.0785\n","\n","Domain: 37\n","x_dp_dom.shape: (154, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 37 | Accuracy: 0.1364 | Loss: 4.2353 | F1: 0.1216\n","\n","Domain: 38\n","x_dp_dom.shape: (158, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 38 | Accuracy: 0.2468 | Loss: 7.8865 | F1: 0.1867\n","\n","Domain: 39\n","x_dp_dom.shape: (165, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 39 | Accuracy: 0.1273 | Loss: 6.4572 | F1: 0.0891\n","\n","Domain: 40\n","x_dp_dom.shape: (155, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 40 | Accuracy: 0.2258 | Loss: 6.9777 | F1: 0.1880\n","\n","Domain: 41\n","x_dp_dom.shape: (156, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 41 | Accuracy: 0.1026 | Loss: 17.3884 | F1: 0.0726\n","\n","Domain: 42\n","x_dp_dom.shape: (158, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 42 | Accuracy: 0.0759 | Loss: 7.8001 | F1: 0.0534\n","\n","Domain: 43\n","x_dp_dom.shape: (153, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 43 | Accuracy: 0.1634 | Loss: 19.2173 | F1: 0.1520\n","\n","Domain: 44\n","x_dp_dom.shape: (153, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 44 | Accuracy: 0.2092 | Loss: 5.5480 | F1: 0.1764\n","\n","Domain: 45\n","x_dp_dom.shape: (163, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 45 | Accuracy: 0.2086 | Loss: 5.4449 | F1: 0.1613\n","\n","Domain: 46\n","x_dp_dom.shape: (160, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 46 | Accuracy: 0.2437 | Loss: 7.8412 | F1: 0.1831\n","\n","Domain: 47\n","x_dp_dom.shape: (155, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 47 | Accuracy: 0.1935 | Loss: 5.8421 | F1: 0.1608\n","\n","Domain: 48\n","x_dp_dom.shape: (159, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 48 | Accuracy: 0.2327 | Loss: 4.5978 | F1: 0.1814\n","\n","Domain: 49\n","x_dp_dom.shape: (164, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 49 | Accuracy: 0.1463 | Loss: 7.0614 | F1: 0.1101\n","\n","Domain: 50\n","x_dp_dom.shape: (153, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 50 | Accuracy: 0.2353 | Loss: 3.5274 | F1: 0.1845\n","\n","Domain: 51\n","x_dp_dom.shape: (157, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 51 | Accuracy: 0.2357 | Loss: 6.5098 | F1: 0.1922\n","\n","Domain: 52\n","x_dp_dom.shape: (153, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 52 | Accuracy: 0.1830 | Loss: 4.4592 | F1: 0.1641\n","\n","Domain: 53\n","x_dp_dom.shape: (159, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 53 | Accuracy: 0.2264 | Loss: 19.9810 | F1: 0.1752\n","\n","Domain: 54\n","x_dp_dom.shape: (153, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 54 | Accuracy: 0.2353 | Loss: 5.9746 | F1: 0.2029\n","\n","Domain: 55\n","x_dp_dom.shape: (160, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 55 | Accuracy: 0.1437 | Loss: 5.3394 | F1: 0.1068\n","\n","Domain: 56\n","x_dp_dom.shape: (153, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 56 | Accuracy: 0.2222 | Loss: 6.4693 | F1: 0.1854\n","\n","Domain: 57\n","x_dp_dom.shape: (153, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 57 | Accuracy: 0.2418 | Loss: 5.0095 | F1: 0.1860\n","\n","Domain: 58\n","x_dp_dom.shape: (149, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 58 | Accuracy: 0.2148 | Loss: 9.9025 | F1: 0.2053\n","\n","Domain: 59\n","x_dp_dom.shape: (154, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 59 | Accuracy: 0.1818 | Loss: 4.1185 | F1: 0.1583\n","\n","Domain: 60\n","x_dp_dom.shape: (158, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 60 | Accuracy: 0.1266 | Loss: 23.0633 | F1: 0.0958\n","\n","Domain: 61\n","x_dp_dom.shape: (158, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 61 | Accuracy: 0.1835 | Loss: 6.2668 | F1: 0.1591\n","\n","Domain: 62\n","x_dp_dom.shape: (158, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 62 | Accuracy: 0.1203 | Loss: 5.6025 | F1: 0.0784\n","\n","Domain: 63\n","x_dp_dom.shape: (153, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 63 | Accuracy: 0.2549 | Loss: 4.9824 | F1: 0.2196\n","\n","Domain: 64\n","x_dp_dom.shape: (154, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 64 | Accuracy: 0.2338 | Loss: 5.3340 | F1: 0.1905\n","\n","Domain: 65\n","x_dp_dom.shape: (161, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 65 | Accuracy: 0.0870 | Loss: 6.3141 | F1: 0.0179\n","\n","Domain: 66\n","x_dp_dom.shape: (153, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 66 | Accuracy: 0.0915 | Loss: 8.6113 | F1: 0.0774\n","\n","Domain: 67\n","x_dp_dom.shape: (153, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 67 | Accuracy: 0.1830 | Loss: 6.5233 | F1: 0.1599\n","\n","Domain: 68\n","x_dp_dom.shape: (154, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 68 | Accuracy: 0.0714 | Loss: 4.8593 | F1: 0.0249\n","\n","Domain: 69\n","x_dp_dom.shape: (153, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 69 | Accuracy: 0.0523 | Loss: 8.1779 | F1: 0.0118\n","\n","Domain: 70\n","x_dp_dom.shape: (153, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 70 | Accuracy: 0.2288 | Loss: 8.0642 | F1: 0.2096\n","\n","Domain: 71\n","x_dp_dom.shape: (155, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 71 | Accuracy: 0.2710 | Loss: 5.9167 | F1: 0.2263\n","\n","Domain: 72\n","x_dp_dom.shape: (153, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 72 | Accuracy: 0.1242 | Loss: 5.5208 | F1: 0.1118\n","\n","Domain: 73\n","x_dp_dom.shape: (152, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 73 | Accuracy: 0.0461 | Loss: 20.1344 | F1: 0.0041\n","\n","Domain: 74\n","x_dp_dom.shape: (146, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 74 | Accuracy: 0.1849 | Loss: 7.9571 | F1: 0.1755\n","\n","Domain: 75\n","x_dp_dom.shape: (153, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 75 | Accuracy: 0.2157 | Loss: 4.8983 | F1: 0.1852\n","\n","Mean accuracy for run 3: 0.1842\n","Mean F1 for run 3: 0.1470\n","\n","Source class: WAL\n","\n","x_df.shape: (11483, 3, 128) | np.unique(y_df): [0 1 2 3]\n","\n","Training on Df data...\n","\tEpoch 10/100 - Train loss: 0.2512 - Val accuracy: 0.3526 - Val loss: 3.6642 - Val F1: 0.2403 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.2045 - Val accuracy: 0.4872 - Val loss: 3.5300 - Val F1: 0.3986 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.1736 - Val accuracy: 0.5159 - Val loss: 3.7043 - Val F1: 0.3752 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.1572 - Val accuracy: 0.5141 - Val loss: 5.3531 - Val F1: 0.3980 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.1381 - Val accuracy: 0.5015 - Val loss: 6.9944 - Val F1: 0.3478 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.1274 - Val accuracy: 0.5089 - Val loss: 6.4916 - Val F1: 0.3685 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.1304 - Val accuracy: 0.5011 - Val loss: 7.7750 - Val F1: 0.3429 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.1227 - Val accuracy: 0.5111 - Val loss: 6.5714 - Val F1: 0.3786 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.1121 - Val accuracy: 0.5067 - Val loss: 7.7265 - Val F1: 0.3627 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.1148 - Val accuracy: 0.4993 - Val loss: 8.1146 - Val F1: 0.3462 - LR: 0.00e+00\n","\tBest epoch: 3 - Best val accuracy: 0.6918 - Best val loss: 0.7146 - Best val F1: 0.6319\n","\n","Domain: 15\n","x_dp_dom.shape: (161, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 15 | Accuracy: 0.2484 | Loss: 5.7161 | F1: 0.1903\n","\n","Domain: 16\n","x_dp_dom.shape: (165, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 16 | Accuracy: 0.2061 | Loss: 3.8143 | F1: 0.1610\n","\n","Domain: 17\n","x_dp_dom.shape: (164, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 17 | Accuracy: 0.1220 | Loss: 5.5382 | F1: 0.0861\n","\n","Domain: 18\n","x_dp_dom.shape: (166, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 18 | Accuracy: 0.1386 | Loss: 5.6987 | F1: 0.1038\n","\n","Domain: 19\n","x_dp_dom.shape: (165, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 19 | Accuracy: 0.1515 | Loss: 4.8346 | F1: 0.1154\n","\n","Domain: 20\n","x_dp_dom.shape: (162, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 20 | Accuracy: 0.2346 | Loss: 4.2992 | F1: 0.1898\n","\n","Domain: 21\n","x_dp_dom.shape: (159, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 21 | Accuracy: 0.1887 | Loss: 5.6344 | F1: 0.1527\n","\n","Domain: 22\n","x_dp_dom.shape: (165, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 22 | Accuracy: 0.2727 | Loss: 4.5450 | F1: 0.2044\n","\n","Domain: 23\n","x_dp_dom.shape: (164, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 23 | Accuracy: 0.2561 | Loss: 5.9503 | F1: 0.2003\n","\n","Domain: 24\n","x_dp_dom.shape: (162, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 24 | Accuracy: 0.2037 | Loss: 5.6590 | F1: 0.1644\n","\n","Domain: 25\n","x_dp_dom.shape: (166, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 25 | Accuracy: 0.2108 | Loss: 2.7175 | F1: 0.2088\n","\n","Domain: 26\n","x_dp_dom.shape: (153, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 26 | Accuracy: 0.1765 | Loss: 4.9096 | F1: 0.1393\n","\n","Domain: 27\n","x_dp_dom.shape: (165, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 27 | Accuracy: 0.2485 | Loss: 6.2655 | F1: 0.2152\n","\n","Domain: 28\n","x_dp_dom.shape: (153, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 28 | Accuracy: 0.2288 | Loss: 5.1596 | F1: 0.1828\n","\n","Domain: 29\n","x_dp_dom.shape: (153, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 29 | Accuracy: 0.1176 | Loss: 6.4027 | F1: 0.0991\n","\n","Domain: 30\n","x_dp_dom.shape: (161, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 30 | Accuracy: 0.2360 | Loss: 14.0298 | F1: 0.1975\n","\n","Domain: 31\n","x_dp_dom.shape: (154, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 31 | Accuracy: 0.2273 | Loss: 3.2587 | F1: 0.1917\n","\n","Domain: 32\n","x_dp_dom.shape: (163, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 32 | Accuracy: 0.1227 | Loss: 6.0357 | F1: 0.0834\n","\n","Domain: 33\n","x_dp_dom.shape: (156, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 33 | Accuracy: 0.2628 | Loss: 8.5804 | F1: 0.1953\n","\n","Domain: 34\n","x_dp_dom.shape: (161, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 34 | Accuracy: 0.9441 | Loss: 0.4471 | F1: 0.9399\n","\n","Domain: 35\n","x_dp_dom.shape: (159, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 35 | Accuracy: 0.1950 | Loss: 8.7580 | F1: 0.1583\n","\n","Domain: 36\n","x_dp_dom.shape: (155, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 36 | Accuracy: 0.0710 | Loss: 3.6011 | F1: 0.0261\n","\n","Domain: 37\n","x_dp_dom.shape: (154, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 37 | Accuracy: 0.0844 | Loss: 4.5838 | F1: 0.0616\n","\n","Domain: 38\n","x_dp_dom.shape: (158, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 38 | Accuracy: 0.9304 | Loss: 0.5237 | F1: 0.9227\n","\n","Domain: 39\n","x_dp_dom.shape: (165, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 39 | Accuracy: 0.2485 | Loss: 5.3808 | F1: 0.1889\n","\n","Domain: 40\n","x_dp_dom.shape: (155, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 40 | Accuracy: 0.2258 | Loss: 7.4693 | F1: 0.1865\n","\n","Domain: 41\n","x_dp_dom.shape: (156, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 41 | Accuracy: 0.0641 | Loss: 20.3145 | F1: 0.0267\n","\n","Domain: 42\n","x_dp_dom.shape: (158, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 42 | Accuracy: 0.0949 | Loss: 7.8358 | F1: 0.0707\n","\n","Domain: 43\n","x_dp_dom.shape: (153, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 43 | Accuracy: 0.2418 | Loss: 2.5189 | F1: 0.2194\n","\n","Domain: 44\n","x_dp_dom.shape: (153, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 44 | Accuracy: 0.1699 | Loss: 4.5860 | F1: 0.1471\n","\n","Domain: 45\n","x_dp_dom.shape: (163, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 45 | Accuracy: 0.2577 | Loss: 5.8352 | F1: 0.2037\n","\n","Domain: 46\n","x_dp_dom.shape: (160, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 46 | Accuracy: 0.1938 | Loss: 5.8675 | F1: 0.1515\n","\n","Domain: 47\n","x_dp_dom.shape: (155, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 47 | Accuracy: 0.1742 | Loss: 4.8636 | F1: 0.1457\n","\n","Domain: 48\n","x_dp_dom.shape: (159, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 48 | Accuracy: 0.2704 | Loss: 5.6265 | F1: 0.2051\n","\n","Domain: 49\n","x_dp_dom.shape: (164, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 49 | Accuracy: 0.1402 | Loss: 8.1358 | F1: 0.1037\n","\n","Domain: 50\n","x_dp_dom.shape: (153, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 50 | Accuracy: 0.2549 | Loss: 5.7942 | F1: 0.1853\n","\n","Domain: 51\n","x_dp_dom.shape: (157, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 51 | Accuracy: 0.2293 | Loss: 5.2204 | F1: 0.1798\n","\n","Domain: 52\n","x_dp_dom.shape: (153, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 52 | Accuracy: 0.2222 | Loss: 6.1574 | F1: 0.1854\n","\n","Domain: 53\n","x_dp_dom.shape: (159, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 53 | Accuracy: 0.2579 | Loss: 4.5386 | F1: 0.2060\n","\n","Domain: 54\n","x_dp_dom.shape: (153, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 54 | Accuracy: 0.2092 | Loss: 6.4772 | F1: 0.1775\n","\n","Domain: 55\n","x_dp_dom.shape: (160, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 55 | Accuracy: 0.1875 | Loss: 7.2720 | F1: 0.1459\n","\n","Domain: 56\n","x_dp_dom.shape: (153, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 56 | Accuracy: 0.2222 | Loss: 5.5322 | F1: 0.1924\n","\n","Domain: 57\n","x_dp_dom.shape: (153, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 57 | Accuracy: 0.2614 | Loss: 7.7623 | F1: 0.2121\n","\n","Domain: 58\n","x_dp_dom.shape: (149, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 58 | Accuracy: 0.2081 | Loss: 9.6962 | F1: 0.2007\n","\n","Domain: 59\n","x_dp_dom.shape: (154, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 59 | Accuracy: 0.1883 | Loss: 5.1832 | F1: 0.1529\n","\n","Domain: 60\n","x_dp_dom.shape: (158, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 60 | Accuracy: 0.2215 | Loss: 4.7464 | F1: 0.1657\n","\n","Domain: 61\n","x_dp_dom.shape: (158, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 61 | Accuracy: 0.1266 | Loss: 5.3228 | F1: 0.0725\n","\n","Domain: 62\n","x_dp_dom.shape: (158, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 62 | Accuracy: 0.1329 | Loss: 3.0613 | F1: 0.0963\n","\n","Domain: 63\n","x_dp_dom.shape: (153, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 63 | Accuracy: 0.1895 | Loss: 5.3674 | F1: 0.1604\n","\n","Domain: 64\n","x_dp_dom.shape: (154, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 64 | Accuracy: 0.1558 | Loss: 4.4530 | F1: 0.1325\n","\n","Domain: 65\n","x_dp_dom.shape: (161, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 65 | Accuracy: 0.2547 | Loss: 5.6245 | F1: 0.1920\n","\n","Domain: 66\n","x_dp_dom.shape: (153, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 66 | Accuracy: 0.1961 | Loss: 11.7614 | F1: 0.1853\n","\n","Domain: 67\n","x_dp_dom.shape: (153, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 67 | Accuracy: 0.2484 | Loss: 6.1125 | F1: 0.1948\n","\n","Domain: 68\n","x_dp_dom.shape: (154, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 68 | Accuracy: 0.0714 | Loss: 7.7527 | F1: 0.0332\n","\n","Domain: 69\n","x_dp_dom.shape: (153, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 69 | Accuracy: 0.2484 | Loss: 5.7334 | F1: 0.2130\n","\n","Domain: 70\n","x_dp_dom.shape: (153, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 70 | Accuracy: 0.2484 | Loss: 10.0746 | F1: 0.2157\n","\n","Domain: 71\n","x_dp_dom.shape: (155, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 71 | Accuracy: 0.2516 | Loss: 4.6195 | F1: 0.1923\n","\n","Domain: 72\n","x_dp_dom.shape: (153, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 72 | Accuracy: 0.0458 | Loss: 5.6984 | F1: 0.0048\n","\n","Domain: 73\n","x_dp_dom.shape: (152, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 73 | Accuracy: 0.6316 | Loss: 1.5973 | F1: 0.6692\n","\n","Domain: 74\n","x_dp_dom.shape: (146, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 74 | Accuracy: 0.2055 | Loss: 7.9547 | F1: 0.1871\n","\n","Domain: 75\n","x_dp_dom.shape: (153, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 75 | Accuracy: 0.2026 | Loss: 5.0643 | F1: 0.1739\n","\n","Mean accuracy for run 4: 0.2267\n","Mean F1 for run 4: 0.1896\n","\n","Source class: WAL\n","\n","x_df.shape: (11483, 3, 128) | np.unique(y_df): [0 1 2 3]\n","\n","Training on Df data...\n","\tEpoch 10/100 - Train loss: 0.2688 - Val accuracy: 0.5194 - Val loss: 1.8403 - Val F1: 0.4281 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.2005 - Val accuracy: 0.3352 - Val loss: 4.1073 - Val F1: 0.2284 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.1692 - Val accuracy: 0.3683 - Val loss: 5.2944 - Val F1: 0.2574 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.1597 - Val accuracy: 0.4414 - Val loss: 5.3318 - Val F1: 0.3035 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.1398 - Val accuracy: 0.5024 - Val loss: 4.2005 - Val F1: 0.3761 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.1322 - Val accuracy: 0.4702 - Val loss: 5.2875 - Val F1: 0.3286 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.1342 - Val accuracy: 0.5342 - Val loss: 4.5168 - Val F1: 0.4404 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.1123 - Val accuracy: 0.4845 - Val loss: 5.4033 - Val F1: 0.3471 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.1198 - Val accuracy: 0.4184 - Val loss: 7.4291 - Val F1: 0.2872 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.1208 - Val accuracy: 0.4863 - Val loss: 6.0792 - Val F1: 0.3467 - LR: 0.00e+00\n","\tBest epoch: 5 - Best val accuracy: 0.5050 - Best val loss: 1.1740 - Best val F1: 0.4453\n","\n","Domain: 15\n","x_dp_dom.shape: (161, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 15 | Accuracy: 0.0994 | Loss: 7.4319 | F1: 0.0544\n","\n","Domain: 16\n","x_dp_dom.shape: (165, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 16 | Accuracy: 0.2485 | Loss: 6.7861 | F1: 0.1834\n","\n","Domain: 17\n","x_dp_dom.shape: (164, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 17 | Accuracy: 0.1707 | Loss: 6.9077 | F1: 0.1329\n","\n","Domain: 18\n","x_dp_dom.shape: (166, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 18 | Accuracy: 0.1627 | Loss: 6.7925 | F1: 0.1259\n","\n","Domain: 19\n","x_dp_dom.shape: (165, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 19 | Accuracy: 0.2121 | Loss: 7.6674 | F1: 0.1630\n","\n","Domain: 20\n","x_dp_dom.shape: (162, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 20 | Accuracy: 0.2160 | Loss: 6.7511 | F1: 0.1663\n","\n","Domain: 21\n","x_dp_dom.shape: (159, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 21 | Accuracy: 0.2390 | Loss: 6.6783 | F1: 0.1827\n","\n","Domain: 22\n","x_dp_dom.shape: (165, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 22 | Accuracy: 0.2667 | Loss: 5.9072 | F1: 0.2028\n","\n","Domain: 23\n","x_dp_dom.shape: (164, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 23 | Accuracy: 0.2500 | Loss: 4.1789 | F1: 0.1774\n","\n","Domain: 24\n","x_dp_dom.shape: (162, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 24 | Accuracy: 0.1975 | Loss: 6.7588 | F1: 0.1606\n","\n","Domain: 25\n","x_dp_dom.shape: (166, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 25 | Accuracy: 0.2410 | Loss: 6.9284 | F1: 0.1793\n","\n","Domain: 26\n","x_dp_dom.shape: (153, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 26 | Accuracy: 0.2157 | Loss: 5.4351 | F1: 0.1747\n","\n","Domain: 27\n","x_dp_dom.shape: (165, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 27 | Accuracy: 0.2485 | Loss: 6.7222 | F1: 0.1888\n","\n","Domain: 28\n","x_dp_dom.shape: (153, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 28 | Accuracy: 0.2222 | Loss: 7.6716 | F1: 0.1846\n","\n","Domain: 29\n","x_dp_dom.shape: (153, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 29 | Accuracy: 0.1242 | Loss: 7.6566 | F1: 0.1138\n","\n","Domain: 30\n","x_dp_dom.shape: (161, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 30 | Accuracy: 0.2422 | Loss: 7.7965 | F1: 0.1605\n","\n","Domain: 31\n","x_dp_dom.shape: (154, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 31 | Accuracy: 0.2468 | Loss: 21.7627 | F1: 0.2097\n","\n","Domain: 32\n","x_dp_dom.shape: (163, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 32 | Accuracy: 0.1902 | Loss: 6.6015 | F1: 0.1486\n","\n","Domain: 33\n","x_dp_dom.shape: (156, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 33 | Accuracy: 0.2372 | Loss: 5.2615 | F1: 0.1598\n","\n","Domain: 34\n","x_dp_dom.shape: (161, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 34 | Accuracy: 0.2112 | Loss: 13.8575 | F1: 0.1628\n","\n","Domain: 35\n","x_dp_dom.shape: (159, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 35 | Accuracy: 0.2516 | Loss: 8.3755 | F1: 0.1876\n","\n","Domain: 36\n","x_dp_dom.shape: (155, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 36 | Accuracy: 0.1742 | Loss: 6.2212 | F1: 0.1522\n","\n","Domain: 37\n","x_dp_dom.shape: (154, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 37 | Accuracy: 0.1169 | Loss: 7.6737 | F1: 0.1019\n","\n","Domain: 38\n","x_dp_dom.shape: (158, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 38 | Accuracy: 0.2468 | Loss: 9.4113 | F1: 0.1838\n","\n","Domain: 39\n","x_dp_dom.shape: (165, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 39 | Accuracy: 0.2303 | Loss: 7.4154 | F1: 0.1735\n","\n","Domain: 40\n","x_dp_dom.shape: (155, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 40 | Accuracy: 0.2516 | Loss: 6.1528 | F1: 0.2031\n","\n","Domain: 41\n","x_dp_dom.shape: (156, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 41 | Accuracy: 0.1731 | Loss: 12.5204 | F1: 0.0759\n","\n","Domain: 42\n","x_dp_dom.shape: (158, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 42 | Accuracy: 0.1962 | Loss: 7.4385 | F1: 0.1638\n","\n","Domain: 43\n","x_dp_dom.shape: (153, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 43 | Accuracy: 0.1503 | Loss: 21.9538 | F1: 0.1377\n","\n","Domain: 44\n","x_dp_dom.shape: (153, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 44 | Accuracy: 0.1961 | Loss: 7.5073 | F1: 0.1703\n","\n","Domain: 45\n","x_dp_dom.shape: (163, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 45 | Accuracy: 0.2515 | Loss: 5.7781 | F1: 0.1858\n","\n","Domain: 46\n","x_dp_dom.shape: (160, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 46 | Accuracy: 0.2500 | Loss: 9.4630 | F1: 0.1864\n","\n","Domain: 47\n","x_dp_dom.shape: (155, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 47 | Accuracy: 0.1806 | Loss: 7.1542 | F1: 0.1479\n","\n","Domain: 48\n","x_dp_dom.shape: (159, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 48 | Accuracy: 0.2767 | Loss: 6.3432 | F1: 0.2172\n","\n","Domain: 49\n","x_dp_dom.shape: (164, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 49 | Accuracy: 0.2256 | Loss: 5.2855 | F1: 0.1714\n","\n","Domain: 50\n","x_dp_dom.shape: (153, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 50 | Accuracy: 0.2418 | Loss: 4.3372 | F1: 0.1326\n","\n","Domain: 51\n","x_dp_dom.shape: (157, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 51 | Accuracy: 0.2293 | Loss: 8.0007 | F1: 0.1891\n","\n","Domain: 52\n","x_dp_dom.shape: (153, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 52 | Accuracy: 0.2288 | Loss: 6.3455 | F1: 0.1884\n","\n","Domain: 53\n","x_dp_dom.shape: (159, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 53 | Accuracy: 0.2516 | Loss: 21.6946 | F1: 0.1888\n","\n","Domain: 54\n","x_dp_dom.shape: (153, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 54 | Accuracy: 0.2484 | Loss: 8.5217 | F1: 0.2154\n","\n","Domain: 55\n","x_dp_dom.shape: (160, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 55 | Accuracy: 0.1313 | Loss: 6.9080 | F1: 0.0923\n","\n","Domain: 56\n","x_dp_dom.shape: (153, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 56 | Accuracy: 0.2418 | Loss: 8.0478 | F1: 0.2032\n","\n","Domain: 57\n","x_dp_dom.shape: (153, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 57 | Accuracy: 0.2418 | Loss: 5.3674 | F1: 0.1867\n","\n","Domain: 58\n","x_dp_dom.shape: (149, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 58 | Accuracy: 0.2215 | Loss: 8.2077 | F1: 0.2089\n","\n","Domain: 59\n","x_dp_dom.shape: (154, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 59 | Accuracy: 0.1753 | Loss: 6.2269 | F1: 0.1528\n","\n","Domain: 60\n","x_dp_dom.shape: (158, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 60 | Accuracy: 0.2089 | Loss: 21.8403 | F1: 0.1664\n","\n","Domain: 61\n","x_dp_dom.shape: (158, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 61 | Accuracy: 0.2405 | Loss: 7.3261 | F1: 0.1804\n","\n","Domain: 62\n","x_dp_dom.shape: (158, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 62 | Accuracy: 0.1266 | Loss: 5.3398 | F1: 0.0916\n","\n","Domain: 63\n","x_dp_dom.shape: (153, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 63 | Accuracy: 0.2353 | Loss: 6.5450 | F1: 0.1929\n","\n","Domain: 64\n","x_dp_dom.shape: (154, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 64 | Accuracy: 0.1948 | Loss: 6.2428 | F1: 0.1709\n","\n","Domain: 65\n","x_dp_dom.shape: (161, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 65 | Accuracy: 0.1366 | Loss: 6.8198 | F1: 0.1026\n","\n","Domain: 66\n","x_dp_dom.shape: (153, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 66 | Accuracy: 0.1046 | Loss: 6.8886 | F1: 0.0944\n","\n","Domain: 67\n","x_dp_dom.shape: (153, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 67 | Accuracy: 0.2418 | Loss: 7.7623 | F1: 0.1891\n","\n","Domain: 68\n","x_dp_dom.shape: (154, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 68 | Accuracy: 0.0714 | Loss: 7.1394 | F1: 0.0415\n","\n","Domain: 69\n","x_dp_dom.shape: (153, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 69 | Accuracy: 0.2092 | Loss: 7.4818 | F1: 0.1774\n","\n","Domain: 70\n","x_dp_dom.shape: (153, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 70 | Accuracy: 0.2288 | Loss: 7.4424 | F1: 0.1976\n","\n","Domain: 71\n","x_dp_dom.shape: (155, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 71 | Accuracy: 0.2323 | Loss: 7.9549 | F1: 0.1890\n","\n","Domain: 72\n","x_dp_dom.shape: (153, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 72 | Accuracy: 0.0980 | Loss: 7.5947 | F1: 0.0862\n","\n","Domain: 73\n","x_dp_dom.shape: (152, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 73 | Accuracy: 0.0855 | Loss: 20.4563 | F1: 0.0692\n","\n","Domain: 74\n","x_dp_dom.shape: (146, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 74 | Accuracy: 0.1918 | Loss: 9.8727 | F1: 0.1790\n","\n","Domain: 75\n","x_dp_dom.shape: (153, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 75 | Accuracy: 0.2222 | Loss: 5.7347 | F1: 0.1845\n","\n","Mean accuracy for run 5: 0.2041\n","Mean F1 for run 5: 0.1600\n","\n","Source class: WAL\n","\n","x_df.shape: (11483, 3, 128) | np.unique(y_df): [0 1 2 3]\n","\n","Training on Df data...\n","\tEpoch 10/100 - Train loss: 0.2666 - Val accuracy: 0.4201 - Val loss: 5.1012 - Val F1: 0.3361 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.1983 - Val accuracy: 0.3709 - Val loss: 9.4315 - Val F1: 0.2855 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.1691 - Val accuracy: 0.4027 - Val loss: 8.2347 - Val F1: 0.3158 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.1541 - Val accuracy: 0.3478 - Val loss: 15.2863 - Val F1: 0.2623 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.1450 - Val accuracy: 0.3814 - Val loss: 11.8905 - Val F1: 0.2969 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.1207 - Val accuracy: 0.4162 - Val loss: 11.8122 - Val F1: 0.3250 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.1233 - Val accuracy: 0.3761 - Val loss: 14.1292 - Val F1: 0.2919 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.1263 - Val accuracy: 0.3705 - Val loss: 16.4506 - Val F1: 0.2845 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.1122 - Val accuracy: 0.3722 - Val loss: 13.4973 - Val F1: 0.2893 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.1162 - Val accuracy: 0.4005 - Val loss: 14.4085 - Val F1: 0.3124 - LR: 0.00e+00\n","\tBest epoch: 2 - Best val accuracy: 0.5124 - Best val loss: 1.1491 - Best val F1: 0.4279\n","\n","Domain: 15\n","x_dp_dom.shape: (161, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 15 | Accuracy: 0.0870 | Loss: 7.7418 | F1: 0.0358\n","\n","Domain: 16\n","x_dp_dom.shape: (165, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 16 | Accuracy: 0.2545 | Loss: 5.3200 | F1: 0.1991\n","\n","Domain: 17\n","x_dp_dom.shape: (164, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 17 | Accuracy: 0.1951 | Loss: 4.2915 | F1: 0.1529\n","\n","Domain: 18\n","x_dp_dom.shape: (166, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 18 | Accuracy: 0.2349 | Loss: 6.0347 | F1: 0.1816\n","\n","Domain: 19\n","x_dp_dom.shape: (165, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 19 | Accuracy: 0.2182 | Loss: 7.5414 | F1: 0.1667\n","\n","Domain: 20\n","x_dp_dom.shape: (162, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 20 | Accuracy: 0.2346 | Loss: 5.0127 | F1: 0.1798\n","\n","Domain: 21\n","x_dp_dom.shape: (159, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 21 | Accuracy: 0.2516 | Loss: 5.3999 | F1: 0.2020\n","\n","Domain: 22\n","x_dp_dom.shape: (165, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 22 | Accuracy: 0.2545 | Loss: 6.9586 | F1: 0.2070\n","\n","Domain: 23\n","x_dp_dom.shape: (164, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 23 | Accuracy: 0.2561 | Loss: 7.6027 | F1: 0.1889\n","\n","Domain: 24\n","x_dp_dom.shape: (162, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 24 | Accuracy: 0.1852 | Loss: 3.9110 | F1: 0.1549\n","\n","Domain: 25\n","x_dp_dom.shape: (166, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 25 | Accuracy: 0.2470 | Loss: 6.1338 | F1: 0.2071\n","\n","Domain: 26\n","x_dp_dom.shape: (153, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 26 | Accuracy: 0.2092 | Loss: 7.3816 | F1: 0.2003\n","\n","Domain: 27\n","x_dp_dom.shape: (165, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 27 | Accuracy: 0.2485 | Loss: 7.1902 | F1: 0.1866\n","\n","Domain: 28\n","x_dp_dom.shape: (153, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 28 | Accuracy: 0.2484 | Loss: 7.7897 | F1: 0.1970\n","\n","Domain: 29\n","x_dp_dom.shape: (153, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 29 | Accuracy: 0.1961 | Loss: 6.9568 | F1: 0.1723\n","\n","Domain: 30\n","x_dp_dom.shape: (161, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 30 | Accuracy: 0.2174 | Loss: 12.0707 | F1: 0.1880\n","\n","Domain: 31\n","x_dp_dom.shape: (154, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 31 | Accuracy: 0.2273 | Loss: 25.3168 | F1: 0.1847\n","\n","Domain: 32\n","x_dp_dom.shape: (163, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 32 | Accuracy: 0.2393 | Loss: 4.3162 | F1: 0.1800\n","\n","Domain: 33\n","x_dp_dom.shape: (156, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 33 | Accuracy: 0.2372 | Loss: 2.9729 | F1: 0.2032\n","\n","Domain: 34\n","x_dp_dom.shape: (161, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 34 | Accuracy: 0.2174 | Loss: 15.1709 | F1: 0.1830\n","\n","Domain: 35\n","x_dp_dom.shape: (159, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 35 | Accuracy: 0.2201 | Loss: 9.4959 | F1: 0.1675\n","\n","Domain: 36\n","x_dp_dom.shape: (155, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 36 | Accuracy: 0.1355 | Loss: 4.2270 | F1: 0.1114\n","\n","Domain: 37\n","x_dp_dom.shape: (154, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 37 | Accuracy: 0.1688 | Loss: 5.1757 | F1: 0.1577\n","\n","Domain: 38\n","x_dp_dom.shape: (158, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 38 | Accuracy: 0.2532 | Loss: 11.2703 | F1: 0.1901\n","\n","Domain: 39\n","x_dp_dom.shape: (165, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 39 | Accuracy: 0.1273 | Loss: 9.5877 | F1: 0.0925\n","\n","Domain: 40\n","x_dp_dom.shape: (155, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 40 | Accuracy: 0.2194 | Loss: 5.4146 | F1: 0.2057\n","\n","Domain: 41\n","x_dp_dom.shape: (156, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 41 | Accuracy: 0.2051 | Loss: 23.8546 | F1: 0.1703\n","\n","Domain: 42\n","x_dp_dom.shape: (158, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 42 | Accuracy: 0.2405 | Loss: 7.2980 | F1: 0.2242\n","\n","Domain: 43\n","x_dp_dom.shape: (153, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 43 | Accuracy: 0.1699 | Loss: 26.1579 | F1: 0.1580\n","\n","Domain: 44\n","x_dp_dom.shape: (153, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 44 | Accuracy: 0.2222 | Loss: 7.1635 | F1: 0.1878\n","\n","Domain: 45\n","x_dp_dom.shape: (163, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 45 | Accuracy: 0.2761 | Loss: 3.5284 | F1: 0.2181\n","\n","Domain: 46\n","x_dp_dom.shape: (160, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 46 | Accuracy: 0.2562 | Loss: 9.9935 | F1: 0.1896\n","\n","Domain: 47\n","x_dp_dom.shape: (155, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 47 | Accuracy: 0.2516 | Loss: 6.4144 | F1: 0.2099\n","\n","Domain: 48\n","x_dp_dom.shape: (159, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 48 | Accuracy: 0.2642 | Loss: 4.4709 | F1: 0.1923\n","\n","Domain: 49\n","x_dp_dom.shape: (164, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 49 | Accuracy: 0.2866 | Loss: 2.2632 | F1: 0.2292\n","\n","Domain: 50\n","x_dp_dom.shape: (153, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 50 | Accuracy: 0.2680 | Loss: 3.1612 | F1: 0.1729\n","\n","Domain: 51\n","x_dp_dom.shape: (157, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 51 | Accuracy: 0.2420 | Loss: 7.9715 | F1: 0.1920\n","\n","Domain: 52\n","x_dp_dom.shape: (153, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 52 | Accuracy: 0.2549 | Loss: 2.6527 | F1: 0.2321\n","\n","Domain: 53\n","x_dp_dom.shape: (159, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 53 | Accuracy: 0.2767 | Loss: 24.4804 | F1: 0.2227\n","\n","Domain: 54\n","x_dp_dom.shape: (153, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 54 | Accuracy: 0.2418 | Loss: 8.6738 | F1: 0.2083\n","\n","Domain: 55\n","x_dp_dom.shape: (160, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 55 | Accuracy: 0.2812 | Loss: 3.5200 | F1: 0.2304\n","\n","Domain: 56\n","x_dp_dom.shape: (153, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 56 | Accuracy: 0.2614 | Loss: 7.2681 | F1: 0.2199\n","\n","Domain: 57\n","x_dp_dom.shape: (153, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 57 | Accuracy: 0.2614 | Loss: 2.6405 | F1: 0.2073\n","\n","Domain: 58\n","x_dp_dom.shape: (149, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 58 | Accuracy: 0.1879 | Loss: 7.9953 | F1: 0.1846\n","\n","Domain: 59\n","x_dp_dom.shape: (154, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 59 | Accuracy: 0.3377 | Loss: 2.0953 | F1: 0.3317\n","\n","Domain: 60\n","x_dp_dom.shape: (158, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 60 | Accuracy: 0.1266 | Loss: 29.8368 | F1: 0.0958\n","\n","Domain: 61\n","x_dp_dom.shape: (158, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 61 | Accuracy: 0.1835 | Loss: 8.4017 | F1: 0.1564\n","\n","Domain: 62\n","x_dp_dom.shape: (158, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 62 | Accuracy: 0.2785 | Loss: 2.3351 | F1: 0.2027\n","\n","Domain: 63\n","x_dp_dom.shape: (153, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 63 | Accuracy: 0.2353 | Loss: 6.2526 | F1: 0.2024\n","\n","Domain: 64\n","x_dp_dom.shape: (154, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 64 | Accuracy: 0.2273 | Loss: 5.0321 | F1: 0.1934\n","\n","Domain: 65\n","x_dp_dom.shape: (161, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 65 | Accuracy: 0.1304 | Loss: 5.9281 | F1: 0.0725\n","\n","Domain: 66\n","x_dp_dom.shape: (153, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 66 | Accuracy: 0.0980 | Loss: 6.4053 | F1: 0.1050\n","\n","Domain: 67\n","x_dp_dom.shape: (153, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 67 | Accuracy: 0.2092 | Loss: 7.6204 | F1: 0.1695\n","\n","Domain: 68\n","x_dp_dom.shape: (154, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 68 | Accuracy: 0.2403 | Loss: 4.5615 | F1: 0.1452\n","\n","Domain: 69\n","x_dp_dom.shape: (153, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 69 | Accuracy: 0.0523 | Loss: 9.4755 | F1: 0.0155\n","\n","Domain: 70\n","x_dp_dom.shape: (153, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 70 | Accuracy: 0.2418 | Loss: 7.4150 | F1: 0.2158\n","\n","Domain: 71\n","x_dp_dom.shape: (155, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 71 | Accuracy: 0.2710 | Loss: 6.1470 | F1: 0.2263\n","\n","Domain: 72\n","x_dp_dom.shape: (153, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 72 | Accuracy: 0.2288 | Loss: 5.2742 | F1: 0.1879\n","\n","Domain: 73\n","x_dp_dom.shape: (152, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 73 | Accuracy: 0.0461 | Loss: 26.8152 | F1: 0.0041\n","\n","Domain: 74\n","x_dp_dom.shape: (146, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 74 | Accuracy: 0.1918 | Loss: 7.3641 | F1: 0.1696\n","\n","Domain: 75\n","x_dp_dom.shape: (153, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 75 | Accuracy: 0.2418 | Loss: 1.9880 | F1: 0.2241\n","\n","Mean accuracy for run 6: 0.2192\n","Mean F1 for run 6: 0.1781\n","\n","Source class: WAL\n","\n","x_df.shape: (11483, 3, 128) | np.unique(y_df): [0 1 2 3]\n","\n","Training on Df data...\n","\tEpoch 10/100 - Train loss: 0.2694 - Val accuracy: 0.4859 - Val loss: 3.1479 - Val F1: 0.4031 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.2144 - Val accuracy: 0.4941 - Val loss: 4.1192 - Val F1: 0.4077 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.1833 - Val accuracy: 0.4166 - Val loss: 8.1948 - Val F1: 0.3292 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.1612 - Val accuracy: 0.4906 - Val loss: 7.1972 - Val F1: 0.3825 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.1396 - Val accuracy: 0.4497 - Val loss: 9.2339 - Val F1: 0.3530 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.1296 - Val accuracy: 0.4210 - Val loss: 10.5334 - Val F1: 0.3303 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.1338 - Val accuracy: 0.3857 - Val loss: 11.8043 - Val F1: 0.3012 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.1205 - Val accuracy: 0.4314 - Val loss: 11.5079 - Val F1: 0.3387 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.1290 - Val accuracy: 0.4023 - Val loss: 11.8028 - Val F1: 0.3167 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.1131 - Val accuracy: 0.4541 - Val loss: 10.8753 - Val F1: 0.3556 - LR: 0.00e+00\n","\tBest epoch: 2 - Best val accuracy: 0.5572 - Best val loss: 1.2962 - Best val F1: 0.4867\n","\n","Domain: 15\n","x_dp_dom.shape: (161, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 15 | Accuracy: 0.2547 | Loss: 3.0069 | F1: 0.2011\n","\n","Domain: 16\n","x_dp_dom.shape: (165, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 16 | Accuracy: 0.2424 | Loss: 3.1580 | F1: 0.1944\n","\n","Domain: 17\n","x_dp_dom.shape: (164, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 17 | Accuracy: 0.1585 | Loss: 2.7763 | F1: 0.1400\n","\n","Domain: 18\n","x_dp_dom.shape: (166, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 18 | Accuracy: 0.2470 | Loss: 3.7485 | F1: 0.2122\n","\n","Domain: 19\n","x_dp_dom.shape: (165, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 19 | Accuracy: 0.2000 | Loss: 5.0598 | F1: 0.1550\n","\n","Domain: 20\n","x_dp_dom.shape: (162, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 20 | Accuracy: 0.2469 | Loss: 3.7041 | F1: 0.1938\n","\n","Domain: 21\n","x_dp_dom.shape: (159, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 21 | Accuracy: 0.2138 | Loss: 3.9355 | F1: 0.1720\n","\n","Domain: 22\n","x_dp_dom.shape: (165, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 22 | Accuracy: 0.2545 | Loss: 3.4191 | F1: 0.2122\n","\n","Domain: 23\n","x_dp_dom.shape: (164, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 23 | Accuracy: 0.2500 | Loss: 6.0726 | F1: 0.1868\n","\n","Domain: 24\n","x_dp_dom.shape: (162, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 24 | Accuracy: 0.2284 | Loss: 3.7640 | F1: 0.1837\n","\n","Domain: 25\n","x_dp_dom.shape: (166, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 25 | Accuracy: 0.2530 | Loss: 3.2955 | F1: 0.2168\n","\n","Domain: 26\n","x_dp_dom.shape: (153, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 26 | Accuracy: 0.2222 | Loss: 4.3687 | F1: 0.2023\n","\n","Domain: 27\n","x_dp_dom.shape: (165, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 27 | Accuracy: 0.2485 | Loss: 5.3356 | F1: 0.1850\n","\n","Domain: 28\n","x_dp_dom.shape: (153, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 28 | Accuracy: 0.2418 | Loss: 6.4382 | F1: 0.2063\n","\n","Domain: 29\n","x_dp_dom.shape: (153, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 29 | Accuracy: 0.1830 | Loss: 6.4537 | F1: 0.1608\n","\n","Domain: 30\n","x_dp_dom.shape: (161, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 30 | Accuracy: 0.2484 | Loss: 9.9845 | F1: 0.1992\n","\n","Domain: 31\n","x_dp_dom.shape: (154, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 31 | Accuracy: 0.2403 | Loss: 3.5234 | F1: 0.2027\n","\n","Domain: 32\n","x_dp_dom.shape: (163, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 32 | Accuracy: 0.2393 | Loss: 2.6804 | F1: 0.1976\n","\n","Domain: 33\n","x_dp_dom.shape: (156, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 33 | Accuracy: 0.2564 | Loss: 4.5342 | F1: 0.2189\n","\n","Domain: 34\n","x_dp_dom.shape: (161, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 34 | Accuracy: 0.7453 | Loss: 0.6400 | F1: 0.7691\n","\n","Domain: 35\n","x_dp_dom.shape: (159, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 35 | Accuracy: 0.2516 | Loss: 7.9833 | F1: 0.1994\n","\n","Domain: 36\n","x_dp_dom.shape: (155, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 36 | Accuracy: 0.1161 | Loss: 2.6634 | F1: 0.0927\n","\n","Domain: 37\n","x_dp_dom.shape: (154, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 37 | Accuracy: 0.2208 | Loss: 4.1808 | F1: 0.1815\n","\n","Domain: 38\n","x_dp_dom.shape: (158, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 38 | Accuracy: 0.9241 | Loss: 0.5938 | F1: 0.9149\n","\n","Domain: 39\n","x_dp_dom.shape: (165, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 39 | Accuracy: 0.2303 | Loss: 4.3110 | F1: 0.1742\n","\n","Domain: 40\n","x_dp_dom.shape: (155, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 40 | Accuracy: 0.2323 | Loss: 2.9391 | F1: 0.2238\n","\n","Domain: 41\n","x_dp_dom.shape: (156, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 41 | Accuracy: 0.1731 | Loss: 15.2821 | F1: 0.1450\n","\n","Domain: 42\n","x_dp_dom.shape: (158, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 42 | Accuracy: 0.2215 | Loss: 4.7278 | F1: 0.1962\n","\n","Domain: 43\n","x_dp_dom.shape: (153, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 43 | Accuracy: 0.2288 | Loss: 2.5773 | F1: 0.1949\n","\n","Domain: 44\n","x_dp_dom.shape: (153, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 44 | Accuracy: 0.2157 | Loss: 4.9338 | F1: 0.1820\n","\n","Domain: 45\n","x_dp_dom.shape: (163, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 45 | Accuracy: 0.2945 | Loss: 2.5229 | F1: 0.2203\n","\n","Domain: 46\n","x_dp_dom.shape: (160, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 46 | Accuracy: 0.2375 | Loss: 7.2907 | F1: 0.1796\n","\n","Domain: 47\n","x_dp_dom.shape: (155, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 47 | Accuracy: 0.2581 | Loss: 4.4730 | F1: 0.2142\n","\n","Domain: 48\n","x_dp_dom.shape: (159, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 48 | Accuracy: 0.2830 | Loss: 3.1753 | F1: 0.2259\n","\n","Domain: 49\n","x_dp_dom.shape: (164, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 49 | Accuracy: 0.2622 | Loss: 2.2808 | F1: 0.2041\n","\n","Domain: 50\n","x_dp_dom.shape: (153, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 50 | Accuracy: 0.3922 | Loss: 1.6899 | F1: 0.3679\n","\n","Domain: 51\n","x_dp_dom.shape: (157, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 51 | Accuracy: 0.2548 | Loss: 4.9055 | F1: 0.2128\n","\n","Domain: 52\n","x_dp_dom.shape: (153, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 52 | Accuracy: 0.2222 | Loss: 3.3276 | F1: 0.1887\n","\n","Domain: 53\n","x_dp_dom.shape: (159, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 53 | Accuracy: 0.2516 | Loss: 3.9431 | F1: 0.2006\n","\n","Domain: 54\n","x_dp_dom.shape: (153, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 54 | Accuracy: 0.2288 | Loss: 5.3345 | F1: 0.1879\n","\n","Domain: 55\n","x_dp_dom.shape: (160, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 55 | Accuracy: 0.2750 | Loss: 2.7792 | F1: 0.2216\n","\n","Domain: 56\n","x_dp_dom.shape: (153, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 56 | Accuracy: 0.2680 | Loss: 3.3817 | F1: 0.2114\n","\n","Domain: 57\n","x_dp_dom.shape: (153, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 57 | Accuracy: 0.2680 | Loss: 3.7619 | F1: 0.1973\n","\n","Domain: 58\n","x_dp_dom.shape: (149, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 58 | Accuracy: 0.2081 | Loss: 7.4852 | F1: 0.2034\n","\n","Domain: 59\n","x_dp_dom.shape: (154, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 59 | Accuracy: 0.3571 | Loss: 1.9739 | F1: 0.3984\n","\n","Domain: 60\n","x_dp_dom.shape: (158, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 60 | Accuracy: 0.2405 | Loss: 4.1868 | F1: 0.1848\n","\n","Domain: 61\n","x_dp_dom.shape: (158, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 61 | Accuracy: 0.2152 | Loss: 4.5495 | F1: 0.1636\n","\n","Domain: 62\n","x_dp_dom.shape: (158, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 62 | Accuracy: 0.3861 | Loss: 1.3161 | F1: 0.3946\n","\n","Domain: 63\n","x_dp_dom.shape: (153, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 63 | Accuracy: 0.2680 | Loss: 2.7165 | F1: 0.2437\n","\n","Domain: 64\n","x_dp_dom.shape: (154, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 64 | Accuracy: 0.2727 | Loss: 2.4825 | F1: 0.2346\n","\n","Domain: 65\n","x_dp_dom.shape: (161, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 65 | Accuracy: 0.2733 | Loss: 2.8323 | F1: 0.2049\n","\n","Domain: 66\n","x_dp_dom.shape: (153, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 66 | Accuracy: 0.2092 | Loss: 2.8094 | F1: 0.1713\n","\n","Domain: 67\n","x_dp_dom.shape: (153, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 67 | Accuracy: 0.2353 | Loss: 6.7733 | F1: 0.1919\n","\n","Domain: 68\n","x_dp_dom.shape: (154, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 68 | Accuracy: 0.2987 | Loss: 2.4579 | F1: 0.2548\n","\n","Domain: 69\n","x_dp_dom.shape: (153, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 69 | Accuracy: 0.2680 | Loss: 3.5679 | F1: 0.2591\n","\n","Domain: 70\n","x_dp_dom.shape: (153, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 70 | Accuracy: 0.2484 | Loss: 4.7711 | F1: 0.2110\n","\n","Domain: 71\n","x_dp_dom.shape: (155, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 71 | Accuracy: 0.2774 | Loss: 3.3539 | F1: 0.2174\n","\n","Domain: 72\n","x_dp_dom.shape: (153, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 72 | Accuracy: 0.2157 | Loss: 2.5282 | F1: 0.2230\n","\n","Domain: 73\n","x_dp_dom.shape: (152, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 73 | Accuracy: 0.2171 | Loss: 2.4201 | F1: 0.1786\n","\n","Domain: 74\n","x_dp_dom.shape: (146, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 74 | Accuracy: 0.1986 | Loss: 5.9587 | F1: 0.1802\n","\n","Domain: 75\n","x_dp_dom.shape: (153, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 75 | Accuracy: 0.2484 | Loss: 3.5111 | F1: 0.2078\n","\n","Mean accuracy for run 7: 0.2643\n","Mean F1 for run 7: 0.2274\n","\n","Source class: WAL\n","\n","x_df.shape: (11483, 3, 128) | np.unique(y_df): [0 1 2 3]\n","\n","Training on Df data...\n","\tEpoch 10/100 - Train loss: 0.2757 - Val accuracy: 0.4880 - Val loss: 2.8983 - Val F1: 0.4191 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.1981 - Val accuracy: 0.5281 - Val loss: 3.4969 - Val F1: 0.4522 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.1742 - Val accuracy: 0.5372 - Val loss: 3.5142 - Val F1: 0.4600 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.1607 - Val accuracy: 0.5738 - Val loss: 3.8117 - Val F1: 0.4901 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.1492 - Val accuracy: 0.4745 - Val loss: 5.9803 - Val F1: 0.3921 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.1312 - Val accuracy: 0.5642 - Val loss: 4.4479 - Val F1: 0.4816 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.1201 - Val accuracy: 0.4993 - Val loss: 5.6809 - Val F1: 0.4276 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.1250 - Val accuracy: 0.5015 - Val loss: 6.1323 - Val F1: 0.4231 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.1156 - Val accuracy: 0.4980 - Val loss: 5.6427 - Val F1: 0.4174 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.1197 - Val accuracy: 0.5067 - Val loss: 6.8614 - Val F1: 0.4251 - LR: 0.00e+00\n","\tBest epoch: 2 - Best val accuracy: 0.5355 - Best val loss: 0.9487 - Best val F1: 0.5302\n","\n","Domain: 15\n","x_dp_dom.shape: (161, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 15 | Accuracy: 0.2981 | Loss: 3.2005 | F1: 0.2233\n","\n","Domain: 16\n","x_dp_dom.shape: (165, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 16 | Accuracy: 0.2303 | Loss: 5.0535 | F1: 0.1737\n","\n","Domain: 17\n","x_dp_dom.shape: (164, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 17 | Accuracy: 0.1829 | Loss: 5.5020 | F1: 0.1426\n","\n","Domain: 18\n","x_dp_dom.shape: (166, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 18 | Accuracy: 0.1446 | Loss: 7.6366 | F1: 0.1085\n","\n","Domain: 19\n","x_dp_dom.shape: (165, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 19 | Accuracy: 0.2182 | Loss: 6.8146 | F1: 0.1667\n","\n","Domain: 20\n","x_dp_dom.shape: (162, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 20 | Accuracy: 0.2531 | Loss: 3.8150 | F1: 0.1972\n","\n","Domain: 21\n","x_dp_dom.shape: (159, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 21 | Accuracy: 0.2579 | Loss: 5.3205 | F1: 0.1946\n","\n","Domain: 22\n","x_dp_dom.shape: (165, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 22 | Accuracy: 0.2606 | Loss: 5.0034 | F1: 0.1970\n","\n","Domain: 23\n","x_dp_dom.shape: (164, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 23 | Accuracy: 0.2683 | Loss: 6.5925 | F1: 0.2269\n","\n","Domain: 24\n","x_dp_dom.shape: (162, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 24 | Accuracy: 0.2099 | Loss: 4.9231 | F1: 0.1683\n","\n","Domain: 25\n","x_dp_dom.shape: (166, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 25 | Accuracy: 0.2410 | Loss: 5.6218 | F1: 0.1833\n","\n","Domain: 26\n","x_dp_dom.shape: (153, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 26 | Accuracy: 0.1307 | Loss: 6.6264 | F1: 0.0951\n","\n","Domain: 27\n","x_dp_dom.shape: (165, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 27 | Accuracy: 0.2485 | Loss: 6.6326 | F1: 0.1978\n","\n","Domain: 28\n","x_dp_dom.shape: (153, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 28 | Accuracy: 0.2288 | Loss: 9.5392 | F1: 0.1880\n","\n","Domain: 29\n","x_dp_dom.shape: (153, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 29 | Accuracy: 0.1046 | Loss: 9.6095 | F1: 0.0893\n","\n","Domain: 30\n","x_dp_dom.shape: (161, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 30 | Accuracy: 0.2484 | Loss: 10.5274 | F1: 0.2036\n","\n","Domain: 31\n","x_dp_dom.shape: (154, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 31 | Accuracy: 0.2532 | Loss: 11.4849 | F1: 0.2129\n","\n","Domain: 32\n","x_dp_dom.shape: (163, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 32 | Accuracy: 0.1656 | Loss: 4.1277 | F1: 0.1295\n","\n","Domain: 33\n","x_dp_dom.shape: (156, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 33 | Accuracy: 0.2500 | Loss: 3.5062 | F1: 0.2057\n","\n","Domain: 34\n","x_dp_dom.shape: (161, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 34 | Accuracy: 0.2484 | Loss: 7.3199 | F1: 0.1221\n","\n","Domain: 35\n","x_dp_dom.shape: (159, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 35 | Accuracy: 0.2264 | Loss: 7.6507 | F1: 0.1789\n","\n","Domain: 36\n","x_dp_dom.shape: (155, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 36 | Accuracy: 0.1355 | Loss: 3.0516 | F1: 0.1370\n","\n","Domain: 37\n","x_dp_dom.shape: (154, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 37 | Accuracy: 0.0909 | Loss: 4.6120 | F1: 0.0705\n","\n","Domain: 38\n","x_dp_dom.shape: (158, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 38 | Accuracy: 0.2532 | Loss: 7.6879 | F1: 0.1853\n","\n","Domain: 39\n","x_dp_dom.shape: (165, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 39 | Accuracy: 0.1939 | Loss: 6.0791 | F1: 0.1512\n","\n","Domain: 40\n","x_dp_dom.shape: (155, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 40 | Accuracy: 0.2258 | Loss: 4.4432 | F1: 0.1857\n","\n","Domain: 41\n","x_dp_dom.shape: (156, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 41 | Accuracy: 0.1795 | Loss: 16.8254 | F1: 0.1571\n","\n","Domain: 42\n","x_dp_dom.shape: (158, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 42 | Accuracy: 0.1646 | Loss: 6.9872 | F1: 0.1371\n","\n","Domain: 43\n","x_dp_dom.shape: (153, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 43 | Accuracy: 0.2484 | Loss: 11.1521 | F1: 0.1971\n","\n","Domain: 44\n","x_dp_dom.shape: (153, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 44 | Accuracy: 0.2157 | Loss: 7.1931 | F1: 0.1783\n","\n","Domain: 45\n","x_dp_dom.shape: (163, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 45 | Accuracy: 0.3190 | Loss: 1.7703 | F1: 0.3074\n","\n","Domain: 46\n","x_dp_dom.shape: (160, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 46 | Accuracy: 0.2437 | Loss: 10.2037 | F1: 0.1831\n","\n","Domain: 47\n","x_dp_dom.shape: (155, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 47 | Accuracy: 0.1355 | Loss: 7.4258 | F1: 0.1096\n","\n","Domain: 48\n","x_dp_dom.shape: (159, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 48 | Accuracy: 0.2013 | Loss: 4.4516 | F1: 0.1617\n","\n","Domain: 49\n","x_dp_dom.shape: (164, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 49 | Accuracy: 0.2073 | Loss: 3.2675 | F1: 0.1607\n","\n","Domain: 50\n","x_dp_dom.shape: (153, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 50 | Accuracy: 0.3072 | Loss: 2.8621 | F1: 0.2848\n","\n","Domain: 51\n","x_dp_dom.shape: (157, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 51 | Accuracy: 0.2357 | Loss: 7.1878 | F1: 0.1827\n","\n","Domain: 52\n","x_dp_dom.shape: (153, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 52 | Accuracy: 0.3595 | Loss: 1.6604 | F1: 0.4170\n","\n","Domain: 53\n","x_dp_dom.shape: (159, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 53 | Accuracy: 0.2327 | Loss: 15.2287 | F1: 0.1831\n","\n","Domain: 54\n","x_dp_dom.shape: (153, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 54 | Accuracy: 0.2353 | Loss: 7.1547 | F1: 0.1993\n","\n","Domain: 55\n","x_dp_dom.shape: (160, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 55 | Accuracy: 0.2125 | Loss: 2.7249 | F1: 0.1988\n","\n","Domain: 56\n","x_dp_dom.shape: (153, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 56 | Accuracy: 0.2157 | Loss: 7.0753 | F1: 0.1815\n","\n","Domain: 57\n","x_dp_dom.shape: (153, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 57 | Accuracy: 0.2745 | Loss: 2.8088 | F1: 0.2251\n","\n","Domain: 58\n","x_dp_dom.shape: (149, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 58 | Accuracy: 0.2081 | Loss: 4.6761 | F1: 0.1997\n","\n","Domain: 59\n","x_dp_dom.shape: (154, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 59 | Accuracy: 0.1234 | Loss: 5.5073 | F1: 0.0962\n","\n","Domain: 60\n","x_dp_dom.shape: (158, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 60 | Accuracy: 0.2405 | Loss: 11.9777 | F1: 0.1855\n","\n","Domain: 61\n","x_dp_dom.shape: (158, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 61 | Accuracy: 0.1646 | Loss: 9.3191 | F1: 0.1190\n","\n","Domain: 62\n","x_dp_dom.shape: (158, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 62 | Accuracy: 0.3354 | Loss: 1.3766 | F1: 0.3505\n","\n","Domain: 63\n","x_dp_dom.shape: (153, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 63 | Accuracy: 0.1569 | Loss: 5.9002 | F1: 0.1256\n","\n","Domain: 64\n","x_dp_dom.shape: (154, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 64 | Accuracy: 0.2273 | Loss: 5.2892 | F1: 0.1909\n","\n","Domain: 65\n","x_dp_dom.shape: (161, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 65 | Accuracy: 0.2547 | Loss: 5.4350 | F1: 0.1884\n","\n","Domain: 66\n","x_dp_dom.shape: (153, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 66 | Accuracy: 0.2680 | Loss: 5.3084 | F1: 0.2011\n","\n","Domain: 67\n","x_dp_dom.shape: (153, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 67 | Accuracy: 0.2484 | Loss: 9.1384 | F1: 0.1915\n","\n","Domain: 68\n","x_dp_dom.shape: (154, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 68 | Accuracy: 0.0649 | Loss: 7.9582 | F1: 0.0305\n","\n","Domain: 69\n","x_dp_dom.shape: (153, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 69 | Accuracy: 0.2288 | Loss: 8.3609 | F1: 0.1879\n","\n","Domain: 70\n","x_dp_dom.shape: (153, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 70 | Accuracy: 0.2353 | Loss: 7.5947 | F1: 0.1999\n","\n","Domain: 71\n","x_dp_dom.shape: (155, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 71 | Accuracy: 0.2839 | Loss: 5.4994 | F1: 0.2208\n","\n","Domain: 72\n","x_dp_dom.shape: (153, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 72 | Accuracy: 0.0588 | Loss: 6.7485 | F1: 0.0293\n","\n","Domain: 73\n","x_dp_dom.shape: (152, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 73 | Accuracy: 0.2368 | Loss: 10.6692 | F1: 0.1875\n","\n","Domain: 74\n","x_dp_dom.shape: (146, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 74 | Accuracy: 0.1918 | Loss: 9.0778 | F1: 0.1763\n","\n","Domain: 75\n","x_dp_dom.shape: (153, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 75 | Accuracy: 0.2288 | Loss: 2.5935 | F1: 0.2158\n","\n","Mean accuracy for run 8: 0.2182\n","Mean F1 for run 8: 0.1786\n","\n","Source class: WAL\n","\n","x_df.shape: (11483, 3, 128) | np.unique(y_df): [0 1 2 3]\n","\n","Training on Df data...\n","\tEpoch 10/100 - Train loss: 0.2805 - Val accuracy: 0.4375 - Val loss: 2.5526 - Val F1: 0.2983 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.2061 - Val accuracy: 0.4933 - Val loss: 3.3196 - Val F1: 0.3312 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.1740 - Val accuracy: 0.4976 - Val loss: 3.5395 - Val F1: 0.3550 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.1553 - Val accuracy: 0.4950 - Val loss: 4.4146 - Val F1: 0.3588 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.1490 - Val accuracy: 0.4963 - Val loss: 3.6342 - Val F1: 0.3382 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.1367 - Val accuracy: 0.4576 - Val loss: 3.4361 - Val F1: 0.3265 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.1343 - Val accuracy: 0.4880 - Val loss: 4.1462 - Val F1: 0.3718 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.1220 - Val accuracy: 0.4623 - Val loss: 4.2805 - Val F1: 0.3101 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.1136 - Val accuracy: 0.4933 - Val loss: 5.5715 - Val F1: 0.3566 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.1064 - Val accuracy: 0.4863 - Val loss: 5.1941 - Val F1: 0.3281 - LR: 0.00e+00\n","\tBest epoch: 3 - Best val accuracy: 0.4201 - Best val loss: 1.4555 - Best val F1: 0.2888\n","\n","Domain: 15\n","x_dp_dom.shape: (161, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 15 | Accuracy: 0.2484 | Loss: 5.6126 | F1: 0.1637\n","\n","Domain: 16\n","x_dp_dom.shape: (165, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 16 | Accuracy: 0.2303 | Loss: 5.0180 | F1: 0.1782\n","\n","Domain: 17\n","x_dp_dom.shape: (164, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 17 | Accuracy: 0.0854 | Loss: 8.6966 | F1: 0.0253\n","\n","Domain: 18\n","x_dp_dom.shape: (166, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 18 | Accuracy: 0.0843 | Loss: 6.5770 | F1: 0.0231\n","\n","Domain: 19\n","x_dp_dom.shape: (165, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 19 | Accuracy: 0.0909 | Loss: 6.2697 | F1: 0.0363\n","\n","Domain: 20\n","x_dp_dom.shape: (162, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 20 | Accuracy: 0.2407 | Loss: 5.5763 | F1: 0.1811\n","\n","Domain: 21\n","x_dp_dom.shape: (159, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 21 | Accuracy: 0.1509 | Loss: 6.6392 | F1: 0.1217\n","\n","Domain: 22\n","x_dp_dom.shape: (165, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 22 | Accuracy: 0.2364 | Loss: 5.5003 | F1: 0.1809\n","\n","Domain: 23\n","x_dp_dom.shape: (164, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 23 | Accuracy: 0.2561 | Loss: 7.7955 | F1: 0.2184\n","\n","Domain: 24\n","x_dp_dom.shape: (162, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 24 | Accuracy: 0.2160 | Loss: 6.3444 | F1: 0.1722\n","\n","Domain: 25\n","x_dp_dom.shape: (166, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 25 | Accuracy: 0.1687 | Loss: 6.5309 | F1: 0.1313\n","\n","Domain: 26\n","x_dp_dom.shape: (153, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 26 | Accuracy: 0.2157 | Loss: 7.5657 | F1: 0.1775\n","\n","Domain: 27\n","x_dp_dom.shape: (165, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 27 | Accuracy: 0.1515 | Loss: 6.2999 | F1: 0.1170\n","\n","Domain: 28\n","x_dp_dom.shape: (153, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 28 | Accuracy: 0.1895 | Loss: 7.1385 | F1: 0.1660\n","\n","Domain: 29\n","x_dp_dom.shape: (153, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 29 | Accuracy: 0.1242 | Loss: 7.3136 | F1: 0.0880\n","\n","Domain: 30\n","x_dp_dom.shape: (161, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 30 | Accuracy: 0.1988 | Loss: 10.4427 | F1: 0.1523\n","\n","Domain: 31\n","x_dp_dom.shape: (154, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 31 | Accuracy: 0.2013 | Loss: 9.8140 | F1: 0.0949\n","\n","Domain: 32\n","x_dp_dom.shape: (163, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 32 | Accuracy: 0.2270 | Loss: 5.8781 | F1: 0.1753\n","\n","Domain: 33\n","x_dp_dom.shape: (156, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 33 | Accuracy: 0.1795 | Loss: 8.5767 | F1: 0.1524\n","\n","Domain: 34\n","x_dp_dom.shape: (161, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 34 | Accuracy: 0.2360 | Loss: 5.5397 | F1: 0.1184\n","\n","Domain: 35\n","x_dp_dom.shape: (159, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 35 | Accuracy: 0.0818 | Loss: 10.6490 | F1: 0.0145\n","\n","Domain: 36\n","x_dp_dom.shape: (155, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 36 | Accuracy: 0.0710 | Loss: 7.7900 | F1: 0.0412\n","\n","Domain: 37\n","x_dp_dom.shape: (154, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 37 | Accuracy: 0.1039 | Loss: 7.0102 | F1: 0.0876\n","\n","Domain: 38\n","x_dp_dom.shape: (158, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 38 | Accuracy: 0.3671 | Loss: 1.5800 | F1: 0.4074\n","\n","Domain: 39\n","x_dp_dom.shape: (165, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 39 | Accuracy: 0.1697 | Loss: 6.0621 | F1: 0.1377\n","\n","Domain: 40\n","x_dp_dom.shape: (155, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 40 | Accuracy: 0.2194 | Loss: 10.6054 | F1: 0.1863\n","\n","Domain: 41\n","x_dp_dom.shape: (156, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 41 | Accuracy: 0.1218 | Loss: 10.2221 | F1: 0.0570\n","\n","Domain: 42\n","x_dp_dom.shape: (158, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 42 | Accuracy: 0.1139 | Loss: 7.7115 | F1: 0.0888\n","\n","Domain: 43\n","x_dp_dom.shape: (153, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 43 | Accuracy: 0.2157 | Loss: 9.5283 | F1: 0.1025\n","\n","Domain: 44\n","x_dp_dom.shape: (153, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 44 | Accuracy: 0.1503 | Loss: 6.1197 | F1: 0.1357\n","\n","Domain: 45\n","x_dp_dom.shape: (163, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 45 | Accuracy: 0.2086 | Loss: 7.0294 | F1: 0.1613\n","\n","Domain: 46\n","x_dp_dom.shape: (160, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 46 | Accuracy: 0.2125 | Loss: 8.5491 | F1: 0.1646\n","\n","Domain: 47\n","x_dp_dom.shape: (155, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 47 | Accuracy: 0.2387 | Loss: 5.6666 | F1: 0.1991\n","\n","Domain: 48\n","x_dp_dom.shape: (159, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 48 | Accuracy: 0.2767 | Loss: 5.5000 | F1: 0.2022\n","\n","Domain: 49\n","x_dp_dom.shape: (164, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 49 | Accuracy: 0.0976 | Loss: 8.8170 | F1: 0.0453\n","\n","Domain: 50\n","x_dp_dom.shape: (153, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 50 | Accuracy: 0.2614 | Loss: 4.5445 | F1: 0.1997\n","\n","Domain: 51\n","x_dp_dom.shape: (157, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 51 | Accuracy: 0.2484 | Loss: 6.3607 | F1: 0.1991\n","\n","Domain: 52\n","x_dp_dom.shape: (153, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 52 | Accuracy: 0.1961 | Loss: 6.1061 | F1: 0.1723\n","\n","Domain: 53\n","x_dp_dom.shape: (159, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 53 | Accuracy: 0.2138 | Loss: 9.1014 | F1: 0.1030\n","\n","Domain: 54\n","x_dp_dom.shape: (153, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 54 | Accuracy: 0.2353 | Loss: 4.9036 | F1: 0.1993\n","\n","Domain: 55\n","x_dp_dom.shape: (160, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 55 | Accuracy: 0.1375 | Loss: 6.5187 | F1: 0.1056\n","\n","Domain: 56\n","x_dp_dom.shape: (153, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 56 | Accuracy: 0.2614 | Loss: 6.3921 | F1: 0.2191\n","\n","Domain: 57\n","x_dp_dom.shape: (153, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 57 | Accuracy: 0.2680 | Loss: 6.9527 | F1: 0.1981\n","\n","Domain: 58\n","x_dp_dom.shape: (149, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 58 | Accuracy: 0.2215 | Loss: 8.8295 | F1: 0.2077\n","\n","Domain: 59\n","x_dp_dom.shape: (154, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 59 | Accuracy: 0.2078 | Loss: 7.1987 | F1: 0.1679\n","\n","Domain: 60\n","x_dp_dom.shape: (158, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 60 | Accuracy: 0.1456 | Loss: 11.3821 | F1: 0.0450\n","\n","Domain: 61\n","x_dp_dom.shape: (158, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 61 | Accuracy: 0.1203 | Loss: 6.6454 | F1: 0.0706\n","\n","Domain: 62\n","x_dp_dom.shape: (158, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 62 | Accuracy: 0.1646 | Loss: 6.8543 | F1: 0.1308\n","\n","Domain: 63\n","x_dp_dom.shape: (153, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 63 | Accuracy: 0.2418 | Loss: 4.1426 | F1: 0.1892\n","\n","Domain: 64\n","x_dp_dom.shape: (154, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 64 | Accuracy: 0.1883 | Loss: 6.8862 | F1: 0.1649\n","\n","Domain: 65\n","x_dp_dom.shape: (161, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 65 | Accuracy: 0.2547 | Loss: 7.0668 | F1: 0.1825\n","\n","Domain: 66\n","x_dp_dom.shape: (153, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 66 | Accuracy: 0.1961 | Loss: 9.5906 | F1: 0.1553\n","\n","Domain: 67\n","x_dp_dom.shape: (153, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 67 | Accuracy: 0.2484 | Loss: 7.8714 | F1: 0.1935\n","\n","Domain: 68\n","x_dp_dom.shape: (154, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 68 | Accuracy: 0.1299 | Loss: 6.5153 | F1: 0.0951\n","\n","Domain: 69\n","x_dp_dom.shape: (153, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 69 | Accuracy: 0.2288 | Loss: 5.2139 | F1: 0.1887\n","\n","Domain: 70\n","x_dp_dom.shape: (153, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 70 | Accuracy: 0.2157 | Loss: 8.9109 | F1: 0.1754\n","\n","Domain: 71\n","x_dp_dom.shape: (155, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 71 | Accuracy: 0.2000 | Loss: 5.2926 | F1: 0.1611\n","\n","Domain: 72\n","x_dp_dom.shape: (153, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 72 | Accuracy: 0.1111 | Loss: 5.7950 | F1: 0.0970\n","\n","Domain: 73\n","x_dp_dom.shape: (152, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 73 | Accuracy: 0.1842 | Loss: 10.1871 | F1: 0.0573\n","\n","Domain: 74\n","x_dp_dom.shape: (146, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 74 | Accuracy: 0.1918 | Loss: 8.8894 | F1: 0.1705\n","\n","Domain: 75\n","x_dp_dom.shape: (153, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 75 | Accuracy: 0.2157 | Loss: 6.3044 | F1: 0.1819\n","\n","Mean accuracy for run 9: 0.1913\n","Mean F1 for run 9: 0.1432\n","\n","Mean accuracy over 10 runs: 0.2186 +- 0.0214\n","Mean F1 over 10 runs: 0.1785 +- 0.0231\n","\n"]}],"source":["def compute_TSTR_Df_aug(dataset):\n","    accs = []\n","    f1s = []\n","\n","    for i in range(n_runs):\n","\n","        accs_run = []\n","        f1s_run = []\n","\n","        for src_class in config[dataset]['class_names']:\n","            if src_class != 'WAL':\n","                continue\n","\n","            print(f\"Source class: {src_class}\\n\")\n","\n","            # Load Df data\n","            x_df, y_df, k_df = get_data(dataset, 'df', src_class)\n","            print(f'x_df.shape: {x_df.shape} | np.unique(y_df): {np.unique(y_df)}\\n')\n","\n","            # Train on Df data\n","            print('Training on Df data...')\n","            df_model = train_only(x_df, y_df, dataset, num_epochs=num_epochs, augment=True)\n","\n","            for domain in range(config[dataset]['num_df_domains'], config[dataset]['num_df_domains'] + config[dataset]['num_dp_domains']):\n","                print(f\"Domain: {domain}\")\n","\n","                # Load Dp data\n","                x_dp_dom, y_dp_dom, k_dp_dom = get_data(dataset, 'dp', src_class, domain)\n","                print(f'x_dp_dom.shape: {x_dp_dom.shape} | np.unique(y_dp_dom): {np.unique(y_dp_dom)}\\n')\n","\n","                # Evaluate on Dp data\n","                acc, loss, f1 = evaluate_model(df_model, get_dataloader(x_dp_dom, y_dp_dom))\n","                save_scores(src_class, domain, acc, loss, f1, 'Df_aug', dataset)\n","                accs_run.append(acc)\n","                f1s_run.append(f1)\n","                print(f'Source class: {src_class} | Domain: {domain} | Accuracy: {acc:.4f} | Loss: {loss:.4f} | F1: {f1:.4f}\\n')\n","\n","        print(f\"Mean accuracy for run {i}: {np.mean(accs_run):.4f}\")\n","        print(f\"Mean F1 for run {i}: {np.mean(f1s_run):.4f}\\n\")\n","        accs.append(np.mean(accs_run))\n","        f1s.append(np.mean(f1s_run))\n","\n","    print(f\"Mean accuracy over {n_runs} runs: {np.mean(accs):.4f} +- {np.std(accs):.4f}\")\n","    print(f\"Mean F1 over {n_runs} runs: {np.mean(f1s):.4f} +- {np.std(f1s):.4f}\\n\")\n","\n","\n","\n","\n","compute_TSTR_Df_aug('realworld_mobiact')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":867134,"status":"ok","timestamp":1732650981539,"user":{"displayName":"Pietro","userId":"07073247908758556229"},"user_tz":-60},"id":"aDSS4eIiUHeq","outputId":"a767654b-2b9e-4721-9e57-80f2732b9434"},"outputs":[{"name":"stdout","output_type":"stream","text":["Source class: WAL\n","\n","x_df.shape: (11483, 3, 128) | np.unique(y_df): [0 1 2 3]\n","\n","Training on Df data...\n","\tEpoch 10/100 - Train loss: 0.1030 - Val accuracy: 0.9547 - Val loss: 0.1364 - Val F1: 0.9547 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.0406 - Val accuracy: 0.9608 - Val loss: 0.1182 - Val F1: 0.9609 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.0155 - Val accuracy: 0.9626 - Val loss: 0.1243 - Val F1: 0.9625 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.0109 - Val accuracy: 0.9630 - Val loss: 0.1340 - Val F1: 0.9631 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.0054 - Val accuracy: 0.9582 - Val loss: 0.1592 - Val F1: 0.9582 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.0039 - Val accuracy: 0.9673 - Val loss: 0.1550 - Val F1: 0.9674 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0028 - Val accuracy: 0.9639 - Val loss: 0.1662 - Val F1: 0.9638 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0011 - Val accuracy: 0.9673 - Val loss: 0.1596 - Val F1: 0.9674 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0018 - Val accuracy: 0.9678 - Val loss: 0.1561 - Val F1: 0.9678 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0010 - Val accuracy: 0.9678 - Val loss: 0.1590 - Val F1: 0.9678 - LR: 0.00e+00\n","\tBest epoch: 22 - Best val accuracy: 0.9626 - Best val loss: 0.1174 - Best val F1: 0.9626\n","\n","Domain: 15\n","x_dp_dom.shape: (161, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 15 | Accuracy: 0.0870 | Loss: 10.3667 | F1: 0.0531\n","\n","Domain: 16\n","x_dp_dom.shape: (165, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 16 | Accuracy: 0.2424 | Loss: 8.0589 | F1: 0.1945\n","\n","Domain: 17\n","x_dp_dom.shape: (164, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 17 | Accuracy: 0.2927 | Loss: 4.7815 | F1: 0.2854\n","\n","Domain: 18\n","x_dp_dom.shape: (166, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 18 | Accuracy: 0.0843 | Loss: 9.2344 | F1: 0.0588\n","\n","Domain: 19\n","x_dp_dom.shape: (165, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 19 | Accuracy: 0.2667 | Loss: 5.8033 | F1: 0.2266\n","\n","Domain: 20\n","x_dp_dom.shape: (162, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 20 | Accuracy: 0.2037 | Loss: 7.4588 | F1: 0.1967\n","\n","Domain: 21\n","x_dp_dom.shape: (159, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 21 | Accuracy: 0.1824 | Loss: 7.9599 | F1: 0.1423\n","\n","Domain: 22\n","x_dp_dom.shape: (165, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 22 | Accuracy: 0.2727 | Loss: 6.5014 | F1: 0.2173\n","\n","Domain: 23\n","x_dp_dom.shape: (164, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 23 | Accuracy: 0.2439 | Loss: 9.4149 | F1: 0.1708\n","\n","Domain: 24\n","x_dp_dom.shape: (162, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 24 | Accuracy: 0.2222 | Loss: 8.1206 | F1: 0.1704\n","\n","Domain: 25\n","x_dp_dom.shape: (166, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 25 | Accuracy: 0.0964 | Loss: 11.3573 | F1: 0.0483\n","\n","Domain: 26\n","x_dp_dom.shape: (153, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 26 | Accuracy: 0.2549 | Loss: 6.2031 | F1: 0.2836\n","\n","Domain: 27\n","x_dp_dom.shape: (165, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 27 | Accuracy: 0.2545 | Loss: 12.7556 | F1: 0.1947\n","\n","Domain: 28\n","x_dp_dom.shape: (153, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 28 | Accuracy: 0.2418 | Loss: 14.3442 | F1: 0.2083\n","\n","Domain: 29\n","x_dp_dom.shape: (153, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 29 | Accuracy: 0.1634 | Loss: 6.2060 | F1: 0.1312\n","\n","Domain: 30\n","x_dp_dom.shape: (161, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 30 | Accuracy: 0.2360 | Loss: 21.1190 | F1: 0.1905\n","\n","Domain: 31\n","x_dp_dom.shape: (154, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 31 | Accuracy: 0.2468 | Loss: 20.9446 | F1: 0.2083\n","\n","Domain: 32\n","x_dp_dom.shape: (163, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 32 | Accuracy: 0.2209 | Loss: 10.1112 | F1: 0.1787\n","\n","Domain: 33\n","x_dp_dom.shape: (156, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 33 | Accuracy: 0.2115 | Loss: 16.0280 | F1: 0.1980\n","\n","Domain: 34\n","x_dp_dom.shape: (161, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 34 | Accuracy: 0.1553 | Loss: 12.1140 | F1: 0.1374\n","\n","Domain: 35\n","x_dp_dom.shape: (159, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 35 | Accuracy: 0.1698 | Loss: 12.1422 | F1: 0.1315\n","\n","Domain: 36\n","x_dp_dom.shape: (155, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 36 | Accuracy: 0.2581 | Loss: 5.0645 | F1: 0.3063\n","\n","Domain: 37\n","x_dp_dom.shape: (154, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 37 | Accuracy: 0.2792 | Loss: 5.1344 | F1: 0.2313\n","\n","Domain: 38\n","x_dp_dom.shape: (158, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 38 | Accuracy: 0.2152 | Loss: 12.0027 | F1: 0.1797\n","\n","Domain: 39\n","x_dp_dom.shape: (165, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 39 | Accuracy: 0.1576 | Loss: 15.2538 | F1: 0.1218\n","\n","Domain: 40\n","x_dp_dom.shape: (155, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 40 | Accuracy: 0.2129 | Loss: 9.0383 | F1: 0.1822\n","\n","Domain: 41\n","x_dp_dom.shape: (156, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 41 | Accuracy: 0.1603 | Loss: 23.9035 | F1: 0.1432\n","\n","Domain: 42\n","x_dp_dom.shape: (158, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 42 | Accuracy: 0.2405 | Loss: 12.8123 | F1: 0.1817\n","\n","Domain: 43\n","x_dp_dom.shape: (153, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 43 | Accuracy: 0.1634 | Loss: 22.7440 | F1: 0.1478\n","\n","Domain: 44\n","x_dp_dom.shape: (153, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 44 | Accuracy: 0.3072 | Loss: 4.8757 | F1: 0.2920\n","\n","Domain: 45\n","x_dp_dom.shape: (163, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 45 | Accuracy: 0.2270 | Loss: 11.5461 | F1: 0.1749\n","\n","Domain: 46\n","x_dp_dom.shape: (160, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 46 | Accuracy: 0.0938 | Loss: 9.1207 | F1: 0.0503\n","\n","Domain: 47\n","x_dp_dom.shape: (155, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 47 | Accuracy: 0.0903 | Loss: 9.3177 | F1: 0.0638\n","\n","Domain: 48\n","x_dp_dom.shape: (159, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 48 | Accuracy: 0.1006 | Loss: 13.6165 | F1: 0.1037\n","\n","Domain: 49\n","x_dp_dom.shape: (164, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 49 | Accuracy: 0.2195 | Loss: 7.7259 | F1: 0.1706\n","\n","Domain: 50\n","x_dp_dom.shape: (153, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 50 | Accuracy: 0.2353 | Loss: 14.1932 | F1: 0.1770\n","\n","Domain: 51\n","x_dp_dom.shape: (157, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 51 | Accuracy: 0.3057 | Loss: 6.7538 | F1: 0.3073\n","\n","Domain: 52\n","x_dp_dom.shape: (153, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 52 | Accuracy: 0.1895 | Loss: 12.4250 | F1: 0.1460\n","\n","Domain: 53\n","x_dp_dom.shape: (159, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 53 | Accuracy: 0.1635 | Loss: 16.8864 | F1: 0.1422\n","\n","Domain: 54\n","x_dp_dom.shape: (153, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 54 | Accuracy: 0.2288 | Loss: 9.1349 | F1: 0.1848\n","\n","Domain: 55\n","x_dp_dom.shape: (160, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 55 | Accuracy: 0.2000 | Loss: 14.4534 | F1: 0.1795\n","\n","Domain: 56\n","x_dp_dom.shape: (153, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 56 | Accuracy: 0.2092 | Loss: 6.6314 | F1: 0.1596\n","\n","Domain: 57\n","x_dp_dom.shape: (153, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 57 | Accuracy: 0.2288 | Loss: 10.2218 | F1: 0.1509\n","\n","Domain: 58\n","x_dp_dom.shape: (149, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 58 | Accuracy: 0.2013 | Loss: 18.9527 | F1: 0.1795\n","\n","Domain: 59\n","x_dp_dom.shape: (154, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 59 | Accuracy: 0.1558 | Loss: 14.8756 | F1: 0.1578\n","\n","Domain: 60\n","x_dp_dom.shape: (158, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 60 | Accuracy: 0.1266 | Loss: 23.5080 | F1: 0.0958\n","\n","Domain: 61\n","x_dp_dom.shape: (158, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 61 | Accuracy: 0.3418 | Loss: 4.5030 | F1: 0.3640\n","\n","Domain: 62\n","x_dp_dom.shape: (158, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 62 | Accuracy: 0.1962 | Loss: 9.9504 | F1: 0.1561\n","\n","Domain: 63\n","x_dp_dom.shape: (153, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 63 | Accuracy: 0.2026 | Loss: 12.5868 | F1: 0.1732\n","\n","Domain: 64\n","x_dp_dom.shape: (154, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 64 | Accuracy: 0.2468 | Loss: 6.9468 | F1: 0.2273\n","\n","Domain: 65\n","x_dp_dom.shape: (161, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 65 | Accuracy: 0.0621 | Loss: 11.5501 | F1: 0.0168\n","\n","Domain: 66\n","x_dp_dom.shape: (153, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 66 | Accuracy: 0.0980 | Loss: 12.9980 | F1: 0.0884\n","\n","Domain: 67\n","x_dp_dom.shape: (153, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 67 | Accuracy: 0.2026 | Loss: 9.6538 | F1: 0.1194\n","\n","Domain: 68\n","x_dp_dom.shape: (154, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 68 | Accuracy: 0.0519 | Loss: 11.7220 | F1: 0.0383\n","\n","Domain: 69\n","x_dp_dom.shape: (153, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 69 | Accuracy: 0.0523 | Loss: 11.9016 | F1: 0.0086\n","\n","Domain: 70\n","x_dp_dom.shape: (153, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 70 | Accuracy: 0.2092 | Loss: 12.8332 | F1: 0.1613\n","\n","Domain: 71\n","x_dp_dom.shape: (155, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 71 | Accuracy: 0.2129 | Loss: 6.1364 | F1: 0.1733\n","\n","Domain: 72\n","x_dp_dom.shape: (153, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 72 | Accuracy: 0.0654 | Loss: 10.9147 | F1: 0.0760\n","\n","Domain: 73\n","x_dp_dom.shape: (152, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 73 | Accuracy: 0.0461 | Loss: 21.8638 | F1: 0.0041\n","\n","Domain: 74\n","x_dp_dom.shape: (146, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 74 | Accuracy: 0.1918 | Loss: 17.6647 | F1: 0.1732\n","\n","Domain: 75\n","x_dp_dom.shape: (153, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 75 | Accuracy: 0.2288 | Loss: 7.6871 | F1: 0.1534\n","\n","Mean accuracy for run 0: 0.1923\n","Mean F1 for run 0: 0.1605\n","\n","Source class: WAL\n","\n","x_df.shape: (11483, 3, 128) | np.unique(y_df): [0 1 2 3]\n","\n","Training on Df data...\n","\tEpoch 10/100 - Train loss: 0.1020 - Val accuracy: 0.9417 - Val loss: 0.1547 - Val F1: 0.9417 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.0468 - Val accuracy: 0.9499 - Val loss: 0.1532 - Val F1: 0.9498 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.0239 - Val accuracy: 0.9539 - Val loss: 0.1432 - Val F1: 0.9539 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.0118 - Val accuracy: 0.9569 - Val loss: 0.1605 - Val F1: 0.9569 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.0109 - Val accuracy: 0.9552 - Val loss: 0.1722 - Val F1: 0.9552 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.0050 - Val accuracy: 0.9591 - Val loss: 0.1767 - Val F1: 0.9591 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0041 - Val accuracy: 0.9560 - Val loss: 0.1928 - Val F1: 0.9560 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0034 - Val accuracy: 0.9578 - Val loss: 0.1882 - Val F1: 0.9578 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0024 - Val accuracy: 0.9595 - Val loss: 0.1960 - Val F1: 0.9595 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0020 - Val accuracy: 0.9586 - Val loss: 0.1909 - Val F1: 0.9586 - LR: 0.00e+00\n","\tBest epoch: 17 - Best val accuracy: 0.9521 - Best val loss: 0.1335 - Best val F1: 0.9521\n","\n","Domain: 15\n","x_dp_dom.shape: (161, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 15 | Accuracy: 0.2360 | Loss: 14.0211 | F1: 0.1676\n","\n","Domain: 16\n","x_dp_dom.shape: (165, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 16 | Accuracy: 0.2364 | Loss: 10.0131 | F1: 0.1969\n","\n","Domain: 17\n","x_dp_dom.shape: (164, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 17 | Accuracy: 0.2378 | Loss: 10.2719 | F1: 0.1899\n","\n","Domain: 18\n","x_dp_dom.shape: (166, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 18 | Accuracy: 0.0843 | Loss: 11.6025 | F1: 0.0377\n","\n","Domain: 19\n","x_dp_dom.shape: (165, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 19 | Accuracy: 0.2485 | Loss: 9.2368 | F1: 0.1909\n","\n","Domain: 20\n","x_dp_dom.shape: (162, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 20 | Accuracy: 0.2346 | Loss: 14.1116 | F1: 0.1986\n","\n","Domain: 21\n","x_dp_dom.shape: (159, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 21 | Accuracy: 0.1572 | Loss: 14.1929 | F1: 0.1511\n","\n","Domain: 22\n","x_dp_dom.shape: (165, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 22 | Accuracy: 0.3333 | Loss: 6.8686 | F1: 0.2537\n","\n","Domain: 23\n","x_dp_dom.shape: (164, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 23 | Accuracy: 0.2805 | Loss: 7.6230 | F1: 0.1753\n","\n","Domain: 24\n","x_dp_dom.shape: (162, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 24 | Accuracy: 0.1728 | Loss: 22.1368 | F1: 0.1468\n","\n","Domain: 25\n","x_dp_dom.shape: (166, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 25 | Accuracy: 0.1687 | Loss: 7.3011 | F1: 0.1456\n","\n","Domain: 26\n","x_dp_dom.shape: (153, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 26 | Accuracy: 0.1634 | Loss: 11.9576 | F1: 0.1479\n","\n","Domain: 27\n","x_dp_dom.shape: (165, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 27 | Accuracy: 0.4848 | Loss: 1.9707 | F1: 0.5515\n","\n","Domain: 28\n","x_dp_dom.shape: (153, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 28 | Accuracy: 0.4314 | Loss: 3.1184 | F1: 0.5038\n","\n","Domain: 29\n","x_dp_dom.shape: (153, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 29 | Accuracy: 0.2680 | Loss: 5.4566 | F1: 0.2384\n","\n","Domain: 30\n","x_dp_dom.shape: (161, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 30 | Accuracy: 0.2050 | Loss: 12.5177 | F1: 0.1628\n","\n","Domain: 31\n","x_dp_dom.shape: (154, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 31 | Accuracy: 0.1948 | Loss: 27.5418 | F1: 0.0730\n","\n","Domain: 32\n","x_dp_dom.shape: (163, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 32 | Accuracy: 0.2577 | Loss: 12.9885 | F1: 0.1930\n","\n","Domain: 33\n","x_dp_dom.shape: (156, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 33 | Accuracy: 0.2244 | Loss: 25.8255 | F1: 0.2077\n","\n","Domain: 34\n","x_dp_dom.shape: (161, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 34 | Accuracy: 0.1925 | Loss: 28.9113 | F1: 0.0925\n","\n","Domain: 35\n","x_dp_dom.shape: (159, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 35 | Accuracy: 0.2579 | Loss: 6.1332 | F1: 0.2180\n","\n","Domain: 36\n","x_dp_dom.shape: (155, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 36 | Accuracy: 0.2000 | Loss: 10.2380 | F1: 0.1751\n","\n","Domain: 37\n","x_dp_dom.shape: (154, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 37 | Accuracy: 0.1948 | Loss: 18.1032 | F1: 0.1850\n","\n","Domain: 38\n","x_dp_dom.shape: (158, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 38 | Accuracy: 0.1519 | Loss: 33.9776 | F1: 0.0749\n","\n","Domain: 39\n","x_dp_dom.shape: (165, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 39 | Accuracy: 0.3091 | Loss: 6.6600 | F1: 0.2217\n","\n","Domain: 40\n","x_dp_dom.shape: (155, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 40 | Accuracy: 0.2323 | Loss: 9.4727 | F1: 0.1889\n","\n","Domain: 41\n","x_dp_dom.shape: (156, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 41 | Accuracy: 0.0833 | Loss: 21.7467 | F1: 0.0867\n","\n","Domain: 42\n","x_dp_dom.shape: (158, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 42 | Accuracy: 0.2658 | Loss: 11.6461 | F1: 0.1685\n","\n","Domain: 43\n","x_dp_dom.shape: (153, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 43 | Accuracy: 0.2288 | Loss: 29.3955 | F1: 0.1148\n","\n","Domain: 44\n","x_dp_dom.shape: (153, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 44 | Accuracy: 0.3007 | Loss: 6.8608 | F1: 0.2633\n","\n","Domain: 45\n","x_dp_dom.shape: (163, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 45 | Accuracy: 0.2270 | Loss: 15.4502 | F1: 0.1910\n","\n","Domain: 46\n","x_dp_dom.shape: (160, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 46 | Accuracy: 0.3375 | Loss: 3.8490 | F1: 0.3797\n","\n","Domain: 47\n","x_dp_dom.shape: (155, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 47 | Accuracy: 0.2258 | Loss: 7.8972 | F1: 0.1928\n","\n","Domain: 48\n","x_dp_dom.shape: (159, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 48 | Accuracy: 0.1761 | Loss: 19.3721 | F1: 0.1861\n","\n","Domain: 49\n","x_dp_dom.shape: (164, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 49 | Accuracy: 0.2073 | Loss: 14.8452 | F1: 0.1735\n","\n","Domain: 50\n","x_dp_dom.shape: (153, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 50 | Accuracy: 0.2418 | Loss: 25.0782 | F1: 0.2155\n","\n","Domain: 51\n","x_dp_dom.shape: (157, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 51 | Accuracy: 0.2484 | Loss: 9.0820 | F1: 0.2266\n","\n","Domain: 52\n","x_dp_dom.shape: (153, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 52 | Accuracy: 0.2353 | Loss: 21.5515 | F1: 0.2158\n","\n","Domain: 53\n","x_dp_dom.shape: (159, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 53 | Accuracy: 0.2579 | Loss: 26.0564 | F1: 0.1280\n","\n","Domain: 54\n","x_dp_dom.shape: (153, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 54 | Accuracy: 0.2745 | Loss: 5.1563 | F1: 0.2250\n","\n","Domain: 55\n","x_dp_dom.shape: (160, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 55 | Accuracy: 0.2562 | Loss: 24.3942 | F1: 0.2371\n","\n","Domain: 56\n","x_dp_dom.shape: (153, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 56 | Accuracy: 0.1242 | Loss: 9.5519 | F1: 0.1228\n","\n","Domain: 57\n","x_dp_dom.shape: (153, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 57 | Accuracy: 0.2222 | Loss: 20.1515 | F1: 0.1928\n","\n","Domain: 58\n","x_dp_dom.shape: (149, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 58 | Accuracy: 0.2215 | Loss: 14.7713 | F1: 0.1346\n","\n","Domain: 59\n","x_dp_dom.shape: (154, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 59 | Accuracy: 0.2208 | Loss: 18.6804 | F1: 0.2057\n","\n","Domain: 60\n","x_dp_dom.shape: (158, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 60 | Accuracy: 0.2342 | Loss: 26.9663 | F1: 0.0932\n","\n","Domain: 61\n","x_dp_dom.shape: (158, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 61 | Accuracy: 0.1646 | Loss: 6.7690 | F1: 0.1780\n","\n","Domain: 62\n","x_dp_dom.shape: (158, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 62 | Accuracy: 0.2152 | Loss: 14.1253 | F1: 0.1738\n","\n","Domain: 63\n","x_dp_dom.shape: (153, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 63 | Accuracy: 0.2288 | Loss: 11.6864 | F1: 0.1804\n","\n","Domain: 64\n","x_dp_dom.shape: (154, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 64 | Accuracy: 0.1883 | Loss: 11.5982 | F1: 0.1725\n","\n","Domain: 65\n","x_dp_dom.shape: (161, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 65 | Accuracy: 0.2298 | Loss: 11.4520 | F1: 0.1831\n","\n","Domain: 66\n","x_dp_dom.shape: (153, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 66 | Accuracy: 0.1895 | Loss: 23.1950 | F1: 0.1606\n","\n","Domain: 67\n","x_dp_dom.shape: (153, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 67 | Accuracy: 0.2549 | Loss: 6.7103 | F1: 0.2009\n","\n","Domain: 68\n","x_dp_dom.shape: (154, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 68 | Accuracy: 0.0974 | Loss: 18.4956 | F1: 0.0869\n","\n","Domain: 69\n","x_dp_dom.shape: (153, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 69 | Accuracy: 0.2418 | Loss: 13.2022 | F1: 0.1942\n","\n","Domain: 70\n","x_dp_dom.shape: (153, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 70 | Accuracy: 0.3137 | Loss: 5.1945 | F1: 0.3329\n","\n","Domain: 71\n","x_dp_dom.shape: (155, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 71 | Accuracy: 0.1871 | Loss: 10.2148 | F1: 0.1580\n","\n","Domain: 72\n","x_dp_dom.shape: (153, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 72 | Accuracy: 0.1569 | Loss: 18.8861 | F1: 0.1661\n","\n","Domain: 73\n","x_dp_dom.shape: (152, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 73 | Accuracy: 0.1842 | Loss: 29.8254 | F1: 0.0589\n","\n","Domain: 74\n","x_dp_dom.shape: (146, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 74 | Accuracy: 0.2877 | Loss: 5.5367 | F1: 0.2981\n","\n","Domain: 75\n","x_dp_dom.shape: (153, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 75 | Accuracy: 0.2092 | Loss: 18.9240 | F1: 0.1841\n","\n","Mean accuracy for run 1: 0.2278\n","Mean F1 for run 1: 0.1897\n","\n","Source class: WAL\n","\n","x_df.shape: (11483, 3, 128) | np.unique(y_df): [0 1 2 3]\n","\n","Training on Df data...\n","\tEpoch 10/100 - Train loss: 0.1029 - Val accuracy: 0.9525 - Val loss: 0.1345 - Val F1: 0.9525 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.0427 - Val accuracy: 0.9517 - Val loss: 0.1280 - Val F1: 0.9518 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.0168 - Val accuracy: 0.9599 - Val loss: 0.1355 - Val F1: 0.9600 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.0114 - Val accuracy: 0.9604 - Val loss: 0.1385 - Val F1: 0.9605 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.0046 - Val accuracy: 0.9630 - Val loss: 0.1505 - Val F1: 0.9630 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.0042 - Val accuracy: 0.9599 - Val loss: 0.1645 - Val F1: 0.9600 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0023 - Val accuracy: 0.9630 - Val loss: 0.1753 - Val F1: 0.9630 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0021 - Val accuracy: 0.9634 - Val loss: 0.1649 - Val F1: 0.9635 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0017 - Val accuracy: 0.9647 - Val loss: 0.1675 - Val F1: 0.9648 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0016 - Val accuracy: 0.9634 - Val loss: 0.1745 - Val F1: 0.9635 - LR: 0.00e+00\n","\tBest epoch: 22 - Best val accuracy: 0.9569 - Best val loss: 0.1182 - Best val F1: 0.9570\n","\n","Domain: 15\n","x_dp_dom.shape: (161, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 15 | Accuracy: 0.0683 | Loss: 29.0577 | F1: 0.0174\n","\n","Domain: 16\n","x_dp_dom.shape: (165, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 16 | Accuracy: 0.2182 | Loss: 11.9725 | F1: 0.1947\n","\n","Domain: 17\n","x_dp_dom.shape: (164, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 17 | Accuracy: 0.3049 | Loss: 4.8034 | F1: 0.3053\n","\n","Domain: 18\n","x_dp_dom.shape: (166, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 18 | Accuracy: 0.2169 | Loss: 14.6446 | F1: 0.1995\n","\n","Domain: 19\n","x_dp_dom.shape: (165, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 19 | Accuracy: 0.2545 | Loss: 6.3449 | F1: 0.2011\n","\n","Domain: 20\n","x_dp_dom.shape: (162, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 20 | Accuracy: 0.1173 | Loss: 14.2441 | F1: 0.0958\n","\n","Domain: 21\n","x_dp_dom.shape: (159, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 21 | Accuracy: 0.2516 | Loss: 13.0902 | F1: 0.2251\n","\n","Domain: 22\n","x_dp_dom.shape: (165, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 22 | Accuracy: 0.2970 | Loss: 5.6160 | F1: 0.3001\n","\n","Domain: 23\n","x_dp_dom.shape: (164, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 23 | Accuracy: 0.8110 | Loss: 1.1050 | F1: 0.7760\n","\n","Domain: 24\n","x_dp_dom.shape: (162, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 24 | Accuracy: 0.1173 | Loss: 18.0644 | F1: 0.0509\n","\n","Domain: 25\n","x_dp_dom.shape: (166, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 25 | Accuracy: 0.2349 | Loss: 10.9475 | F1: 0.1765\n","\n","Domain: 26\n","x_dp_dom.shape: (153, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 26 | Accuracy: 0.1176 | Loss: 9.5341 | F1: 0.1010\n","\n","Domain: 27\n","x_dp_dom.shape: (165, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 27 | Accuracy: 0.3515 | Loss: 3.4816 | F1: 0.3698\n","\n","Domain: 28\n","x_dp_dom.shape: (153, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 28 | Accuracy: 0.3856 | Loss: 3.5138 | F1: 0.4760\n","\n","Domain: 29\n","x_dp_dom.shape: (153, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 29 | Accuracy: 0.2026 | Loss: 12.0531 | F1: 0.2059\n","\n","Domain: 30\n","x_dp_dom.shape: (161, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 30 | Accuracy: 0.2484 | Loss: 13.4687 | F1: 0.1971\n","\n","Domain: 31\n","x_dp_dom.shape: (154, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 31 | Accuracy: 0.2143 | Loss: 38.4603 | F1: 0.1805\n","\n","Domain: 32\n","x_dp_dom.shape: (163, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 32 | Accuracy: 0.1963 | Loss: 15.0126 | F1: 0.1731\n","\n","Domain: 33\n","x_dp_dom.shape: (156, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 33 | Accuracy: 0.1410 | Loss: 22.1125 | F1: 0.1293\n","\n","Domain: 34\n","x_dp_dom.shape: (161, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 34 | Accuracy: 0.1242 | Loss: 18.8885 | F1: 0.1133\n","\n","Domain: 35\n","x_dp_dom.shape: (159, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 35 | Accuracy: 0.4465 | Loss: 3.5546 | F1: 0.5055\n","\n","Domain: 36\n","x_dp_dom.shape: (155, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 36 | Accuracy: 0.1935 | Loss: 12.5112 | F1: 0.1689\n","\n","Domain: 37\n","x_dp_dom.shape: (154, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 37 | Accuracy: 0.1429 | Loss: 10.5714 | F1: 0.1445\n","\n","Domain: 38\n","x_dp_dom.shape: (158, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 38 | Accuracy: 0.1266 | Loss: 16.7296 | F1: 0.0933\n","\n","Domain: 39\n","x_dp_dom.shape: (165, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 39 | Accuracy: 0.1576 | Loss: 16.1155 | F1: 0.1177\n","\n","Domain: 40\n","x_dp_dom.shape: (155, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 40 | Accuracy: 0.2065 | Loss: 8.7260 | F1: 0.1891\n","\n","Domain: 41\n","x_dp_dom.shape: (156, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 41 | Accuracy: 0.0897 | Loss: 28.3694 | F1: 0.0739\n","\n","Domain: 42\n","x_dp_dom.shape: (158, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 42 | Accuracy: 0.2658 | Loss: 10.2174 | F1: 0.2321\n","\n","Domain: 43\n","x_dp_dom.shape: (153, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 43 | Accuracy: 0.1634 | Loss: 39.9573 | F1: 0.1520\n","\n","Domain: 44\n","x_dp_dom.shape: (153, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 44 | Accuracy: 0.2353 | Loss: 7.0039 | F1: 0.2152\n","\n","Domain: 45\n","x_dp_dom.shape: (163, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 45 | Accuracy: 0.1840 | Loss: 13.9863 | F1: 0.1577\n","\n","Domain: 46\n","x_dp_dom.shape: (160, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 46 | Accuracy: 0.2500 | Loss: 8.9362 | F1: 0.1977\n","\n","Domain: 47\n","x_dp_dom.shape: (155, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 47 | Accuracy: 0.1677 | Loss: 11.2454 | F1: 0.1595\n","\n","Domain: 48\n","x_dp_dom.shape: (159, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 48 | Accuracy: 0.1761 | Loss: 14.7073 | F1: 0.1877\n","\n","Domain: 49\n","x_dp_dom.shape: (164, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 49 | Accuracy: 0.0854 | Loss: 13.0069 | F1: 0.0287\n","\n","Domain: 50\n","x_dp_dom.shape: (153, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 50 | Accuracy: 0.1895 | Loss: 27.0536 | F1: 0.1813\n","\n","Domain: 51\n","x_dp_dom.shape: (157, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 51 | Accuracy: 0.2229 | Loss: 10.0582 | F1: 0.2404\n","\n","Domain: 52\n","x_dp_dom.shape: (153, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 52 | Accuracy: 0.2222 | Loss: 19.1831 | F1: 0.2088\n","\n","Domain: 53\n","x_dp_dom.shape: (159, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 53 | Accuracy: 0.1069 | Loss: 27.6370 | F1: 0.0738\n","\n","Domain: 54\n","x_dp_dom.shape: (153, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 54 | Accuracy: 0.2680 | Loss: 6.3735 | F1: 0.2337\n","\n","Domain: 55\n","x_dp_dom.shape: (160, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 55 | Accuracy: 0.2313 | Loss: 19.9321 | F1: 0.2202\n","\n","Domain: 56\n","x_dp_dom.shape: (153, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 56 | Accuracy: 0.1699 | Loss: 7.0044 | F1: 0.2142\n","\n","Domain: 57\n","x_dp_dom.shape: (153, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 57 | Accuracy: 0.1699 | Loss: 19.0195 | F1: 0.1708\n","\n","Domain: 58\n","x_dp_dom.shape: (149, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 58 | Accuracy: 0.2416 | Loss: 6.5916 | F1: 0.2567\n","\n","Domain: 59\n","x_dp_dom.shape: (154, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 59 | Accuracy: 0.1169 | Loss: 25.8783 | F1: 0.0980\n","\n","Domain: 60\n","x_dp_dom.shape: (158, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 60 | Accuracy: 0.1203 | Loss: 39.7459 | F1: 0.0883\n","\n","Domain: 61\n","x_dp_dom.shape: (158, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 61 | Accuracy: 0.2595 | Loss: 6.7197 | F1: 0.3338\n","\n","Domain: 62\n","x_dp_dom.shape: (158, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 62 | Accuracy: 0.2532 | Loss: 11.0334 | F1: 0.1922\n","\n","Domain: 63\n","x_dp_dom.shape: (153, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 63 | Accuracy: 0.1699 | Loss: 15.3837 | F1: 0.1731\n","\n","Domain: 64\n","x_dp_dom.shape: (154, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 64 | Accuracy: 0.1494 | Loss: 12.7888 | F1: 0.1521\n","\n","Domain: 65\n","x_dp_dom.shape: (161, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 65 | Accuracy: 0.0683 | Loss: 18.6574 | F1: 0.0185\n","\n","Domain: 66\n","x_dp_dom.shape: (153, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 66 | Accuracy: 0.0458 | Loss: 29.0655 | F1: 0.0092\n","\n","Domain: 67\n","x_dp_dom.shape: (153, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 67 | Accuracy: 0.4510 | Loss: 3.5182 | F1: 0.5445\n","\n","Domain: 68\n","x_dp_dom.shape: (154, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 68 | Accuracy: 0.0974 | Loss: 23.6762 | F1: 0.0883\n","\n","Domain: 69\n","x_dp_dom.shape: (153, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 69 | Accuracy: 0.0523 | Loss: 25.6105 | F1: 0.0133\n","\n","Domain: 70\n","x_dp_dom.shape: (153, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 70 | Accuracy: 0.4379 | Loss: 4.6301 | F1: 0.5445\n","\n","Domain: 71\n","x_dp_dom.shape: (155, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 71 | Accuracy: 0.2194 | Loss: 12.3455 | F1: 0.2032\n","\n","Domain: 72\n","x_dp_dom.shape: (153, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 72 | Accuracy: 0.1046 | Loss: 18.6462 | F1: 0.1181\n","\n","Domain: 73\n","x_dp_dom.shape: (152, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 73 | Accuracy: 0.0461 | Loss: 31.3431 | F1: 0.0041\n","\n","Domain: 74\n","x_dp_dom.shape: (146, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 74 | Accuracy: 0.4726 | Loss: 4.4201 | F1: 0.5939\n","\n","Domain: 75\n","x_dp_dom.shape: (153, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 75 | Accuracy: 0.1242 | Loss: 17.7026 | F1: 0.1389\n","\n","Mean accuracy for run 2: 0.2094\n","Mean F1 for run 2: 0.2004\n","\n","Source class: WAL\n","\n","x_df.shape: (11483, 3, 128) | np.unique(y_df): [0 1 2 3]\n","\n","Training on Df data...\n","\tEpoch 10/100 - Train loss: 0.1041 - Val accuracy: 0.9512 - Val loss: 0.1351 - Val F1: 0.9513 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.0379 - Val accuracy: 0.9617 - Val loss: 0.1167 - Val F1: 0.9618 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.0167 - Val accuracy: 0.9617 - Val loss: 0.1212 - Val F1: 0.9617 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.0084 - Val accuracy: 0.9639 - Val loss: 0.1323 - Val F1: 0.9639 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.0060 - Val accuracy: 0.9604 - Val loss: 0.1613 - Val F1: 0.9604 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.0042 - Val accuracy: 0.9630 - Val loss: 0.1542 - Val F1: 0.9629 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0032 - Val accuracy: 0.9639 - Val loss: 0.1556 - Val F1: 0.9639 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0019 - Val accuracy: 0.9634 - Val loss: 0.1640 - Val F1: 0.9634 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0018 - Val accuracy: 0.9656 - Val loss: 0.1588 - Val F1: 0.9656 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0012 - Val accuracy: 0.9639 - Val loss: 0.1589 - Val F1: 0.9639 - LR: 0.00e+00\n","\tBest epoch: 16 - Best val accuracy: 0.9599 - Best val loss: 0.1130 - Best val F1: 0.9600\n","\n","Domain: 15\n","x_dp_dom.shape: (161, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 15 | Accuracy: 0.2050 | Loss: 15.9528 | F1: 0.1665\n","\n","Domain: 16\n","x_dp_dom.shape: (165, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 16 | Accuracy: 0.2182 | Loss: 13.3192 | F1: 0.1830\n","\n","Domain: 17\n","x_dp_dom.shape: (164, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 17 | Accuracy: 0.1890 | Loss: 6.1347 | F1: 0.2000\n","\n","Domain: 18\n","x_dp_dom.shape: (166, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 18 | Accuracy: 0.2048 | Loss: 18.6130 | F1: 0.1774\n","\n","Domain: 19\n","x_dp_dom.shape: (165, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 19 | Accuracy: 0.2545 | Loss: 10.9094 | F1: 0.2001\n","\n","Domain: 20\n","x_dp_dom.shape: (162, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 20 | Accuracy: 0.2346 | Loss: 9.8851 | F1: 0.1950\n","\n","Domain: 21\n","x_dp_dom.shape: (159, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 21 | Accuracy: 0.1384 | Loss: 12.6786 | F1: 0.1460\n","\n","Domain: 22\n","x_dp_dom.shape: (165, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 22 | Accuracy: 0.2788 | Loss: 8.0646 | F1: 0.2400\n","\n","Domain: 23\n","x_dp_dom.shape: (164, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 23 | Accuracy: 0.2500 | Loss: 12.4723 | F1: 0.1855\n","\n","Domain: 24\n","x_dp_dom.shape: (162, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 24 | Accuracy: 0.2654 | Loss: 13.5581 | F1: 0.2145\n","\n","Domain: 25\n","x_dp_dom.shape: (166, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 25 | Accuracy: 0.1928 | Loss: 12.9012 | F1: 0.1541\n","\n","Domain: 26\n","x_dp_dom.shape: (153, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 26 | Accuracy: 0.1503 | Loss: 13.8328 | F1: 0.1627\n","\n","Domain: 27\n","x_dp_dom.shape: (165, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 27 | Accuracy: 0.3758 | Loss: 4.3458 | F1: 0.4148\n","\n","Domain: 28\n","x_dp_dom.shape: (153, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 28 | Accuracy: 0.1699 | Loss: 8.5531 | F1: 0.1677\n","\n","Domain: 29\n","x_dp_dom.shape: (153, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 29 | Accuracy: 0.2418 | Loss: 16.6248 | F1: 0.1829\n","\n","Domain: 30\n","x_dp_dom.shape: (161, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 30 | Accuracy: 0.2050 | Loss: 26.4256 | F1: 0.1724\n","\n","Domain: 31\n","x_dp_dom.shape: (154, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 31 | Accuracy: 0.2338 | Loss: 32.0535 | F1: 0.1979\n","\n","Domain: 32\n","x_dp_dom.shape: (163, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 32 | Accuracy: 0.1718 | Loss: 15.9009 | F1: 0.1442\n","\n","Domain: 33\n","x_dp_dom.shape: (156, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 33 | Accuracy: 0.2179 | Loss: 9.9941 | F1: 0.1809\n","\n","Domain: 34\n","x_dp_dom.shape: (161, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 34 | Accuracy: 0.1801 | Loss: 18.2936 | F1: 0.1608\n","\n","Domain: 35\n","x_dp_dom.shape: (159, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 35 | Accuracy: 0.2327 | Loss: 13.3339 | F1: 0.1773\n","\n","Domain: 36\n","x_dp_dom.shape: (155, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 36 | Accuracy: 0.2323 | Loss: 7.7029 | F1: 0.1978\n","\n","Domain: 37\n","x_dp_dom.shape: (154, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 37 | Accuracy: 0.1558 | Loss: 12.7423 | F1: 0.1470\n","\n","Domain: 38\n","x_dp_dom.shape: (158, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 38 | Accuracy: 0.2025 | Loss: 21.6069 | F1: 0.1742\n","\n","Domain: 39\n","x_dp_dom.shape: (165, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 39 | Accuracy: 0.1697 | Loss: 10.1609 | F1: 0.1406\n","\n","Domain: 40\n","x_dp_dom.shape: (155, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 40 | Accuracy: 0.2065 | Loss: 9.0100 | F1: 0.1886\n","\n","Domain: 41\n","x_dp_dom.shape: (156, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 41 | Accuracy: 0.0577 | Loss: 41.0852 | F1: 0.0470\n","\n","Domain: 42\n","x_dp_dom.shape: (158, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 42 | Accuracy: 0.1899 | Loss: 11.4286 | F1: 0.1625\n","\n","Domain: 43\n","x_dp_dom.shape: (153, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 43 | Accuracy: 0.1895 | Loss: 30.9890 | F1: 0.1657\n","\n","Domain: 44\n","x_dp_dom.shape: (153, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 44 | Accuracy: 0.2680 | Loss: 5.9257 | F1: 0.2341\n","\n","Domain: 45\n","x_dp_dom.shape: (163, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 45 | Accuracy: 0.2515 | Loss: 12.6964 | F1: 0.1900\n","\n","Domain: 46\n","x_dp_dom.shape: (160, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 46 | Accuracy: 0.2562 | Loss: 11.2127 | F1: 0.1899\n","\n","Domain: 47\n","x_dp_dom.shape: (155, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 47 | Accuracy: 0.1806 | Loss: 11.4450 | F1: 0.1568\n","\n","Domain: 48\n","x_dp_dom.shape: (159, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 48 | Accuracy: 0.2453 | Loss: 17.8398 | F1: 0.2267\n","\n","Domain: 49\n","x_dp_dom.shape: (164, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 49 | Accuracy: 0.2073 | Loss: 12.0098 | F1: 0.1602\n","\n","Domain: 50\n","x_dp_dom.shape: (153, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 50 | Accuracy: 0.2549 | Loss: 18.5945 | F1: 0.2035\n","\n","Domain: 51\n","x_dp_dom.shape: (157, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 51 | Accuracy: 0.2739 | Loss: 10.9220 | F1: 0.2662\n","\n","Domain: 52\n","x_dp_dom.shape: (153, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 52 | Accuracy: 0.2222 | Loss: 14.7854 | F1: 0.2043\n","\n","Domain: 53\n","x_dp_dom.shape: (159, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 53 | Accuracy: 0.2327 | Loss: 20.8962 | F1: 0.1813\n","\n","Domain: 54\n","x_dp_dom.shape: (153, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 54 | Accuracy: 0.2288 | Loss: 10.3153 | F1: 0.1871\n","\n","Domain: 55\n","x_dp_dom.shape: (160, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 55 | Accuracy: 0.2437 | Loss: 11.6821 | F1: 0.1940\n","\n","Domain: 56\n","x_dp_dom.shape: (153, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 56 | Accuracy: 0.0588 | Loss: 11.3562 | F1: 0.0402\n","\n","Domain: 57\n","x_dp_dom.shape: (153, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 57 | Accuracy: 0.2222 | Loss: 9.5110 | F1: 0.1699\n","\n","Domain: 58\n","x_dp_dom.shape: (149, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 58 | Accuracy: 0.2081 | Loss: 18.6380 | F1: 0.1948\n","\n","Domain: 59\n","x_dp_dom.shape: (154, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 59 | Accuracy: 0.1169 | Loss: 19.6005 | F1: 0.1125\n","\n","Domain: 60\n","x_dp_dom.shape: (158, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 60 | Accuracy: 0.1456 | Loss: 30.9361 | F1: 0.1161\n","\n","Domain: 61\n","x_dp_dom.shape: (158, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 61 | Accuracy: 0.1329 | Loss: 8.7874 | F1: 0.1395\n","\n","Domain: 62\n","x_dp_dom.shape: (158, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 62 | Accuracy: 0.2532 | Loss: 14.1686 | F1: 0.1901\n","\n","Domain: 63\n","x_dp_dom.shape: (153, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 63 | Accuracy: 0.2157 | Loss: 12.7693 | F1: 0.1698\n","\n","Domain: 64\n","x_dp_dom.shape: (154, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 64 | Accuracy: 0.2013 | Loss: 15.6649 | F1: 0.1841\n","\n","Domain: 65\n","x_dp_dom.shape: (161, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 65 | Accuracy: 0.0870 | Loss: 10.7952 | F1: 0.0408\n","\n","Domain: 66\n","x_dp_dom.shape: (153, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 66 | Accuracy: 0.1634 | Loss: 11.1107 | F1: 0.0661\n","\n","Domain: 67\n","x_dp_dom.shape: (153, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 67 | Accuracy: 0.2026 | Loss: 10.8248 | F1: 0.1486\n","\n","Domain: 68\n","x_dp_dom.shape: (154, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 68 | Accuracy: 0.1818 | Loss: 13.0445 | F1: 0.1489\n","\n","Domain: 69\n","x_dp_dom.shape: (153, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 69 | Accuracy: 0.1830 | Loss: 13.8866 | F1: 0.1610\n","\n","Domain: 70\n","x_dp_dom.shape: (153, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 70 | Accuracy: 0.2222 | Loss: 7.8633 | F1: 0.2206\n","\n","Domain: 71\n","x_dp_dom.shape: (155, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 71 | Accuracy: 0.2839 | Loss: 13.9550 | F1: 0.2039\n","\n","Domain: 72\n","x_dp_dom.shape: (153, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 72 | Accuracy: 0.1046 | Loss: 14.3451 | F1: 0.0997\n","\n","Domain: 73\n","x_dp_dom.shape: (152, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 73 | Accuracy: 0.1842 | Loss: 23.7380 | F1: 0.1626\n","\n","Domain: 74\n","x_dp_dom.shape: (146, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 74 | Accuracy: 0.2123 | Loss: 9.1733 | F1: 0.2133\n","\n","Domain: 75\n","x_dp_dom.shape: (153, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 75 | Accuracy: 0.2222 | Loss: 14.8506 | F1: 0.1845\n","\n","Mean accuracy for run 3: 0.2046\n","Mean F1 for run 3: 0.1739\n","\n","Source class: WAL\n","\n","x_df.shape: (11483, 3, 128) | np.unique(y_df): [0 1 2 3]\n","\n","Training on Df data...\n","\tEpoch 10/100 - Train loss: 0.1111 - Val accuracy: 0.9495 - Val loss: 0.1394 - Val F1: 0.9496 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.0482 - Val accuracy: 0.9595 - Val loss: 0.1207 - Val F1: 0.9595 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.0258 - Val accuracy: 0.9565 - Val loss: 0.1303 - Val F1: 0.9565 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.0149 - Val accuracy: 0.9578 - Val loss: 0.1446 - Val F1: 0.9578 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.0085 - Val accuracy: 0.9599 - Val loss: 0.1509 - Val F1: 0.9600 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.0061 - Val accuracy: 0.9613 - Val loss: 0.1557 - Val F1: 0.9613 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0045 - Val accuracy: 0.9613 - Val loss: 0.1650 - Val F1: 0.9613 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0033 - Val accuracy: 0.9621 - Val loss: 0.1650 - Val F1: 0.9621 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0017 - Val accuracy: 0.9604 - Val loss: 0.1663 - Val F1: 0.9604 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0021 - Val accuracy: 0.9613 - Val loss: 0.1745 - Val F1: 0.9613 - LR: 0.00e+00\n","\tBest epoch: 25 - Best val accuracy: 0.9617 - Best val loss: 0.1201 - Best val F1: 0.9617\n","\n","Domain: 15\n","x_dp_dom.shape: (161, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 15 | Accuracy: 0.1304 | Loss: 13.1154 | F1: 0.1152\n","\n","Domain: 16\n","x_dp_dom.shape: (165, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 16 | Accuracy: 0.2424 | Loss: 12.4934 | F1: 0.1947\n","\n","Domain: 17\n","x_dp_dom.shape: (164, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 17 | Accuracy: 0.2561 | Loss: 7.3037 | F1: 0.2092\n","\n","Domain: 18\n","x_dp_dom.shape: (166, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 18 | Accuracy: 0.2169 | Loss: 11.1859 | F1: 0.1909\n","\n","Domain: 19\n","x_dp_dom.shape: (165, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 19 | Accuracy: 0.2364 | Loss: 10.5226 | F1: 0.1771\n","\n","Domain: 20\n","x_dp_dom.shape: (162, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 20 | Accuracy: 0.2407 | Loss: 8.9808 | F1: 0.2243\n","\n","Domain: 21\n","x_dp_dom.shape: (159, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 21 | Accuracy: 0.2201 | Loss: 12.5174 | F1: 0.2090\n","\n","Domain: 22\n","x_dp_dom.shape: (165, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 22 | Accuracy: 0.2364 | Loss: 7.8890 | F1: 0.1911\n","\n","Domain: 23\n","x_dp_dom.shape: (164, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 23 | Accuracy: 0.3110 | Loss: 4.5463 | F1: 0.3716\n","\n","Domain: 24\n","x_dp_dom.shape: (162, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 24 | Accuracy: 0.2654 | Loss: 13.5808 | F1: 0.2145\n","\n","Domain: 25\n","x_dp_dom.shape: (166, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 25 | Accuracy: 0.1566 | Loss: 7.9295 | F1: 0.1500\n","\n","Domain: 26\n","x_dp_dom.shape: (153, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 26 | Accuracy: 0.2549 | Loss: 11.8282 | F1: 0.2333\n","\n","Domain: 27\n","x_dp_dom.shape: (165, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 27 | Accuracy: 0.3212 | Loss: 5.5275 | F1: 0.3147\n","\n","Domain: 28\n","x_dp_dom.shape: (153, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 28 | Accuracy: 0.3791 | Loss: 4.0094 | F1: 0.4451\n","\n","Domain: 29\n","x_dp_dom.shape: (153, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 29 | Accuracy: 0.2484 | Loss: 7.6540 | F1: 0.1842\n","\n","Domain: 30\n","x_dp_dom.shape: (161, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 30 | Accuracy: 0.2298 | Loss: 18.6709 | F1: 0.1904\n","\n","Domain: 31\n","x_dp_dom.shape: (154, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 31 | Accuracy: 0.2208 | Loss: 44.0230 | F1: 0.1865\n","\n","Domain: 32\n","x_dp_dom.shape: (163, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 32 | Accuracy: 0.1779 | Loss: 12.9459 | F1: 0.1376\n","\n","Domain: 33\n","x_dp_dom.shape: (156, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 33 | Accuracy: 0.2372 | Loss: 12.0382 | F1: 0.2141\n","\n","Domain: 34\n","x_dp_dom.shape: (161, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 34 | Accuracy: 0.1304 | Loss: 33.2900 | F1: 0.1063\n","\n","Domain: 35\n","x_dp_dom.shape: (159, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 35 | Accuracy: 0.3208 | Loss: 4.9920 | F1: 0.3217\n","\n","Domain: 36\n","x_dp_dom.shape: (155, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 36 | Accuracy: 0.2129 | Loss: 8.4515 | F1: 0.1831\n","\n","Domain: 37\n","x_dp_dom.shape: (154, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 37 | Accuracy: 0.2208 | Loss: 7.1965 | F1: 0.2280\n","\n","Domain: 38\n","x_dp_dom.shape: (158, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 38 | Accuracy: 0.1519 | Loss: 38.8558 | F1: 0.1282\n","\n","Domain: 39\n","x_dp_dom.shape: (165, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 39 | Accuracy: 0.1879 | Loss: 12.5576 | F1: 0.1523\n","\n","Domain: 40\n","x_dp_dom.shape: (155, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 40 | Accuracy: 0.2258 | Loss: 8.3961 | F1: 0.2000\n","\n","Domain: 41\n","x_dp_dom.shape: (156, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 41 | Accuracy: 0.1410 | Loss: 32.5011 | F1: 0.1362\n","\n","Domain: 42\n","x_dp_dom.shape: (158, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 42 | Accuracy: 0.2215 | Loss: 12.5265 | F1: 0.2078\n","\n","Domain: 43\n","x_dp_dom.shape: (153, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 43 | Accuracy: 0.1765 | Loss: 44.6479 | F1: 0.1667\n","\n","Domain: 44\n","x_dp_dom.shape: (153, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 44 | Accuracy: 0.2418 | Loss: 10.2590 | F1: 0.1953\n","\n","Domain: 45\n","x_dp_dom.shape: (163, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 45 | Accuracy: 0.2515 | Loss: 11.5320 | F1: 0.1959\n","\n","Domain: 46\n","x_dp_dom.shape: (160, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 46 | Accuracy: 0.2125 | Loss: 5.0846 | F1: 0.2217\n","\n","Domain: 47\n","x_dp_dom.shape: (155, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 47 | Accuracy: 0.0968 | Loss: 10.3886 | F1: 0.0917\n","\n","Domain: 48\n","x_dp_dom.shape: (159, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 48 | Accuracy: 0.0692 | Loss: 16.7222 | F1: 0.0850\n","\n","Domain: 49\n","x_dp_dom.shape: (164, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 49 | Accuracy: 0.2378 | Loss: 12.6266 | F1: 0.1781\n","\n","Domain: 50\n","x_dp_dom.shape: (153, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 50 | Accuracy: 0.2222 | Loss: 19.5186 | F1: 0.2070\n","\n","Domain: 51\n","x_dp_dom.shape: (157, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 51 | Accuracy: 0.2548 | Loss: 9.2477 | F1: 0.2152\n","\n","Domain: 52\n","x_dp_dom.shape: (153, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 52 | Accuracy: 0.2222 | Loss: 13.4880 | F1: 0.2088\n","\n","Domain: 53\n","x_dp_dom.shape: (159, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 53 | Accuracy: 0.2327 | Loss: 38.0769 | F1: 0.1862\n","\n","Domain: 54\n","x_dp_dom.shape: (153, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 54 | Accuracy: 0.2484 | Loss: 7.6912 | F1: 0.2028\n","\n","Domain: 55\n","x_dp_dom.shape: (160, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 55 | Accuracy: 0.2500 | Loss: 15.2206 | F1: 0.2188\n","\n","Domain: 56\n","x_dp_dom.shape: (153, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 56 | Accuracy: 0.1830 | Loss: 8.1395 | F1: 0.2432\n","\n","Domain: 57\n","x_dp_dom.shape: (153, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 57 | Accuracy: 0.2157 | Loss: 10.4570 | F1: 0.1952\n","\n","Domain: 58\n","x_dp_dom.shape: (149, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 58 | Accuracy: 0.2081 | Loss: 14.5604 | F1: 0.2005\n","\n","Domain: 59\n","x_dp_dom.shape: (154, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 59 | Accuracy: 0.0325 | Loss: 19.5671 | F1: 0.0103\n","\n","Domain: 60\n","x_dp_dom.shape: (158, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 60 | Accuracy: 0.1329 | Loss: 44.5150 | F1: 0.1029\n","\n","Domain: 61\n","x_dp_dom.shape: (158, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 61 | Accuracy: 0.4241 | Loss: 3.6922 | F1: 0.5520\n","\n","Domain: 62\n","x_dp_dom.shape: (158, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 62 | Accuracy: 0.2532 | Loss: 12.9674 | F1: 0.1902\n","\n","Domain: 63\n","x_dp_dom.shape: (153, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 63 | Accuracy: 0.2222 | Loss: 13.1956 | F1: 0.1938\n","\n","Domain: 64\n","x_dp_dom.shape: (154, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 64 | Accuracy: 0.2013 | Loss: 12.4004 | F1: 0.1923\n","\n","Domain: 65\n","x_dp_dom.shape: (161, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 65 | Accuracy: 0.0994 | Loss: 10.9380 | F1: 0.1140\n","\n","Domain: 66\n","x_dp_dom.shape: (153, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 66 | Accuracy: 0.0588 | Loss: 15.3115 | F1: 0.0209\n","\n","Domain: 67\n","x_dp_dom.shape: (153, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 67 | Accuracy: 0.2810 | Loss: 5.6775 | F1: 0.2921\n","\n","Domain: 68\n","x_dp_dom.shape: (154, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 68 | Accuracy: 0.1039 | Loss: 12.9100 | F1: 0.0934\n","\n","Domain: 69\n","x_dp_dom.shape: (153, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 69 | Accuracy: 0.1830 | Loss: 14.4439 | F1: 0.1624\n","\n","Domain: 70\n","x_dp_dom.shape: (153, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 70 | Accuracy: 0.3333 | Loss: 7.1767 | F1: 0.3759\n","\n","Domain: 71\n","x_dp_dom.shape: (155, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 71 | Accuracy: 0.2581 | Loss: 13.0534 | F1: 0.2227\n","\n","Domain: 72\n","x_dp_dom.shape: (153, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 72 | Accuracy: 0.0523 | Loss: 13.6082 | F1: 0.0524\n","\n","Domain: 73\n","x_dp_dom.shape: (152, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 73 | Accuracy: 0.0789 | Loss: 40.9833 | F1: 0.0600\n","\n","Domain: 74\n","x_dp_dom.shape: (146, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 74 | Accuracy: 0.5068 | Loss: 3.9093 | F1: 0.6203\n","\n","Domain: 75\n","x_dp_dom.shape: (153, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 75 | Accuracy: 0.1699 | Loss: 13.7094 | F1: 0.1530\n","\n","Mean accuracy for run 4: 0.2149\n","Mean F1 for run 4: 0.2006\n","\n","Source class: WAL\n","\n","x_df.shape: (11483, 3, 128) | np.unique(y_df): [0 1 2 3]\n","\n","Training on Df data...\n","\tEpoch 10/100 - Train loss: 0.1068 - Val accuracy: 0.9539 - Val loss: 0.1333 - Val F1: 0.9539 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.0500 - Val accuracy: 0.9599 - Val loss: 0.1221 - Val F1: 0.9600 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.0220 - Val accuracy: 0.9613 - Val loss: 0.1268 - Val F1: 0.9613 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.0106 - Val accuracy: 0.9604 - Val loss: 0.1424 - Val F1: 0.9604 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.0080 - Val accuracy: 0.9621 - Val loss: 0.1487 - Val F1: 0.9621 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.0042 - Val accuracy: 0.9578 - Val loss: 0.1671 - Val F1: 0.9578 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0044 - Val accuracy: 0.9599 - Val loss: 0.1684 - Val F1: 0.9600 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0027 - Val accuracy: 0.9639 - Val loss: 0.1681 - Val F1: 0.9639 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0017 - Val accuracy: 0.9613 - Val loss: 0.1698 - Val F1: 0.9613 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0018 - Val accuracy: 0.9613 - Val loss: 0.1787 - Val F1: 0.9613 - LR: 0.00e+00\n","\tBest epoch: 19 - Best val accuracy: 0.9626 - Best val loss: 0.1082 - Best val F1: 0.9626\n","\n","Domain: 15\n","x_dp_dom.shape: (161, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 15 | Accuracy: 0.0621 | Loss: 14.1211 | F1: 0.0136\n","\n","Domain: 16\n","x_dp_dom.shape: (165, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 16 | Accuracy: 0.2667 | Loss: 8.8887 | F1: 0.2420\n","\n","Domain: 17\n","x_dp_dom.shape: (164, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 17 | Accuracy: 0.2500 | Loss: 7.6952 | F1: 0.1866\n","\n","Domain: 18\n","x_dp_dom.shape: (166, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 18 | Accuracy: 0.2289 | Loss: 10.1914 | F1: 0.1601\n","\n","Domain: 19\n","x_dp_dom.shape: (165, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 19 | Accuracy: 0.2485 | Loss: 6.1498 | F1: 0.1856\n","\n","Domain: 20\n","x_dp_dom.shape: (162, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 20 | Accuracy: 0.1790 | Loss: 10.0699 | F1: 0.1444\n","\n","Domain: 21\n","x_dp_dom.shape: (159, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 21 | Accuracy: 0.2516 | Loss: 11.9091 | F1: 0.1858\n","\n","Domain: 22\n","x_dp_dom.shape: (165, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 22 | Accuracy: 0.2848 | Loss: 6.0673 | F1: 0.2291\n","\n","Domain: 23\n","x_dp_dom.shape: (164, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 23 | Accuracy: 0.3049 | Loss: 5.4448 | F1: 0.2943\n","\n","Domain: 24\n","x_dp_dom.shape: (162, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 24 | Accuracy: 0.1975 | Loss: 13.8539 | F1: 0.1291\n","\n","Domain: 25\n","x_dp_dom.shape: (166, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 25 | Accuracy: 0.1928 | Loss: 8.8756 | F1: 0.1507\n","\n","Domain: 26\n","x_dp_dom.shape: (153, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 26 | Accuracy: 0.2288 | Loss: 11.0023 | F1: 0.1634\n","\n","Domain: 27\n","x_dp_dom.shape: (165, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 27 | Accuracy: 0.5515 | Loss: 2.7509 | F1: 0.6138\n","\n","Domain: 28\n","x_dp_dom.shape: (153, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 28 | Accuracy: 0.6471 | Loss: 1.5146 | F1: 0.7320\n","\n","Domain: 29\n","x_dp_dom.shape: (153, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 29 | Accuracy: 0.2222 | Loss: 8.7459 | F1: 0.1897\n","\n","Domain: 30\n","x_dp_dom.shape: (161, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 30 | Accuracy: 0.2236 | Loss: 13.2900 | F1: 0.1709\n","\n","Domain: 31\n","x_dp_dom.shape: (154, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 31 | Accuracy: 0.2468 | Loss: 33.8861 | F1: 0.2121\n","\n","Domain: 32\n","x_dp_dom.shape: (163, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 32 | Accuracy: 0.1534 | Loss: 8.3013 | F1: 0.1208\n","\n","Domain: 33\n","x_dp_dom.shape: (156, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 33 | Accuracy: 0.1859 | Loss: 11.5878 | F1: 0.1188\n","\n","Domain: 34\n","x_dp_dom.shape: (161, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 34 | Accuracy: 0.1739 | Loss: 19.7360 | F1: 0.1470\n","\n","Domain: 35\n","x_dp_dom.shape: (159, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 35 | Accuracy: 0.2327 | Loss: 8.6917 | F1: 0.1774\n","\n","Domain: 36\n","x_dp_dom.shape: (155, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 36 | Accuracy: 0.2194 | Loss: 7.9882 | F1: 0.1890\n","\n","Domain: 37\n","x_dp_dom.shape: (154, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 37 | Accuracy: 0.2532 | Loss: 9.7566 | F1: 0.1716\n","\n","Domain: 38\n","x_dp_dom.shape: (158, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 38 | Accuracy: 0.1519 | Loss: 22.4680 | F1: 0.1383\n","\n","Domain: 39\n","x_dp_dom.shape: (165, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 39 | Accuracy: 0.1576 | Loss: 10.2408 | F1: 0.1417\n","\n","Domain: 40\n","x_dp_dom.shape: (155, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 40 | Accuracy: 0.2581 | Loss: 5.4870 | F1: 0.2714\n","\n","Domain: 41\n","x_dp_dom.shape: (156, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 41 | Accuracy: 0.1603 | Loss: 32.0962 | F1: 0.1371\n","\n","Domain: 42\n","x_dp_dom.shape: (158, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 42 | Accuracy: 0.2215 | Loss: 8.6386 | F1: 0.2263\n","\n","Domain: 43\n","x_dp_dom.shape: (153, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 43 | Accuracy: 0.1765 | Loss: 34.6064 | F1: 0.1640\n","\n","Domain: 44\n","x_dp_dom.shape: (153, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 44 | Accuracy: 0.2484 | Loss: 8.0085 | F1: 0.1960\n","\n","Domain: 45\n","x_dp_dom.shape: (163, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 45 | Accuracy: 0.2270 | Loss: 11.9098 | F1: 0.1746\n","\n","Domain: 46\n","x_dp_dom.shape: (160, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 46 | Accuracy: 0.2313 | Loss: 6.5832 | F1: 0.1790\n","\n","Domain: 47\n","x_dp_dom.shape: (155, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 47 | Accuracy: 0.2839 | Loss: 5.4949 | F1: 0.2955\n","\n","Domain: 48\n","x_dp_dom.shape: (159, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 48 | Accuracy: 0.2201 | Loss: 10.2783 | F1: 0.2086\n","\n","Domain: 49\n","x_dp_dom.shape: (164, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 49 | Accuracy: 0.2378 | Loss: 10.8967 | F1: 0.1790\n","\n","Domain: 50\n","x_dp_dom.shape: (153, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 50 | Accuracy: 0.2680 | Loss: 15.9894 | F1: 0.1333\n","\n","Domain: 51\n","x_dp_dom.shape: (157, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 51 | Accuracy: 0.2548 | Loss: 8.7144 | F1: 0.2644\n","\n","Domain: 52\n","x_dp_dom.shape: (153, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 52 | Accuracy: 0.2222 | Loss: 16.5587 | F1: 0.0997\n","\n","Domain: 53\n","x_dp_dom.shape: (159, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 53 | Accuracy: 0.2390 | Loss: 29.0776 | F1: 0.1948\n","\n","Domain: 54\n","x_dp_dom.shape: (153, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 54 | Accuracy: 0.4510 | Loss: 2.0268 | F1: 0.5092\n","\n","Domain: 55\n","x_dp_dom.shape: (160, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 55 | Accuracy: 0.2375 | Loss: 12.9280 | F1: 0.1613\n","\n","Domain: 56\n","x_dp_dom.shape: (153, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 56 | Accuracy: 0.4575 | Loss: 2.5535 | F1: 0.5142\n","\n","Domain: 57\n","x_dp_dom.shape: (153, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 57 | Accuracy: 0.2549 | Loss: 12.2228 | F1: 0.1393\n","\n","Domain: 58\n","x_dp_dom.shape: (149, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 58 | Accuracy: 0.2081 | Loss: 25.1036 | F1: 0.1910\n","\n","Domain: 59\n","x_dp_dom.shape: (154, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 59 | Accuracy: 0.2273 | Loss: 12.2044 | F1: 0.1927\n","\n","Domain: 60\n","x_dp_dom.shape: (158, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 60 | Accuracy: 0.1076 | Loss: 34.5072 | F1: 0.0722\n","\n","Domain: 61\n","x_dp_dom.shape: (158, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 61 | Accuracy: 0.3924 | Loss: 4.3757 | F1: 0.4131\n","\n","Domain: 62\n","x_dp_dom.shape: (158, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 62 | Accuracy: 0.2532 | Loss: 12.5950 | F1: 0.1901\n","\n","Domain: 63\n","x_dp_dom.shape: (153, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 63 | Accuracy: 0.2418 | Loss: 11.0778 | F1: 0.2254\n","\n","Domain: 64\n","x_dp_dom.shape: (154, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 64 | Accuracy: 0.2273 | Loss: 9.8625 | F1: 0.1869\n","\n","Domain: 65\n","x_dp_dom.shape: (161, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 65 | Accuracy: 0.0807 | Loss: 8.1443 | F1: 0.0165\n","\n","Domain: 66\n","x_dp_dom.shape: (153, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 66 | Accuracy: 0.0458 | Loss: 16.7573 | F1: 0.0093\n","\n","Domain: 67\n","x_dp_dom.shape: (153, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 67 | Accuracy: 0.4183 | Loss: 3.7280 | F1: 0.4746\n","\n","Domain: 68\n","x_dp_dom.shape: (154, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 68 | Accuracy: 0.1818 | Loss: 10.8465 | F1: 0.1165\n","\n","Domain: 69\n","x_dp_dom.shape: (153, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 69 | Accuracy: 0.1046 | Loss: 10.3323 | F1: 0.1002\n","\n","Domain: 70\n","x_dp_dom.shape: (153, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 70 | Accuracy: 0.3268 | Loss: 4.8581 | F1: 0.3673\n","\n","Domain: 71\n","x_dp_dom.shape: (155, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 71 | Accuracy: 0.2774 | Loss: 8.5149 | F1: 0.2240\n","\n","Domain: 72\n","x_dp_dom.shape: (153, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 72 | Accuracy: 0.2092 | Loss: 10.8808 | F1: 0.1945\n","\n","Domain: 73\n","x_dp_dom.shape: (152, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 73 | Accuracy: 0.1184 | Loss: 26.3843 | F1: 0.1087\n","\n","Domain: 74\n","x_dp_dom.shape: (146, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 74 | Accuracy: 0.2808 | Loss: 6.1020 | F1: 0.2949\n","\n","Domain: 75\n","x_dp_dom.shape: (153, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 75 | Accuracy: 0.2288 | Loss: 12.6437 | F1: 0.1850\n","\n","Mean accuracy for run 5: 0.2409\n","Mean F1 for run 5: 0.2101\n","\n","Source class: WAL\n","\n","x_df.shape: (11483, 3, 128) | np.unique(y_df): [0 1 2 3]\n","\n","Training on Df data...\n","\tEpoch 10/100 - Train loss: 0.0976 - Val accuracy: 0.9521 - Val loss: 0.1326 - Val F1: 0.9522 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.0393 - Val accuracy: 0.9604 - Val loss: 0.1204 - Val F1: 0.9604 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.0157 - Val accuracy: 0.9595 - Val loss: 0.1290 - Val F1: 0.9595 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.0090 - Val accuracy: 0.9578 - Val loss: 0.1514 - Val F1: 0.9578 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.0058 - Val accuracy: 0.9591 - Val loss: 0.1720 - Val F1: 0.9591 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.0067 - Val accuracy: 0.9599 - Val loss: 0.1687 - Val F1: 0.9599 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0041 - Val accuracy: 0.9582 - Val loss: 0.1723 - Val F1: 0.9582 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0019 - Val accuracy: 0.9591 - Val loss: 0.1709 - Val F1: 0.9591 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0016 - Val accuracy: 0.9608 - Val loss: 0.1761 - Val F1: 0.9608 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0014 - Val accuracy: 0.9595 - Val loss: 0.1722 - Val F1: 0.9595 - LR: 0.00e+00\n","\tBest epoch: 15 - Best val accuracy: 0.9573 - Best val loss: 0.1161 - Best val F1: 0.9574\n","\n","Domain: 15\n","x_dp_dom.shape: (161, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 15 | Accuracy: 0.0870 | Loss: 11.9986 | F1: 0.0788\n","\n","Domain: 16\n","x_dp_dom.shape: (165, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 16 | Accuracy: 0.1758 | Loss: 10.0125 | F1: 0.1402\n","\n","Domain: 17\n","x_dp_dom.shape: (164, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 17 | Accuracy: 0.2256 | Loss: 7.1802 | F1: 0.1810\n","\n","Domain: 18\n","x_dp_dom.shape: (166, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 18 | Accuracy: 0.1386 | Loss: 10.2526 | F1: 0.0882\n","\n","Domain: 19\n","x_dp_dom.shape: (165, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 19 | Accuracy: 0.2364 | Loss: 10.3028 | F1: 0.1771\n","\n","Domain: 20\n","x_dp_dom.shape: (162, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 20 | Accuracy: 0.2469 | Loss: 10.4275 | F1: 0.2020\n","\n","Domain: 21\n","x_dp_dom.shape: (159, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 21 | Accuracy: 0.2516 | Loss: 11.5578 | F1: 0.1850\n","\n","Domain: 22\n","x_dp_dom.shape: (165, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 22 | Accuracy: 0.3576 | Loss: 3.1396 | F1: 0.3522\n","\n","Domain: 23\n","x_dp_dom.shape: (164, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 23 | Accuracy: 0.3841 | Loss: 4.6848 | F1: 0.3781\n","\n","Domain: 24\n","x_dp_dom.shape: (162, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 24 | Accuracy: 0.2778 | Loss: 10.3090 | F1: 0.2189\n","\n","Domain: 25\n","x_dp_dom.shape: (166, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 25 | Accuracy: 0.2229 | Loss: 7.4431 | F1: 0.1815\n","\n","Domain: 26\n","x_dp_dom.shape: (153, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 26 | Accuracy: 0.3529 | Loss: 4.3272 | F1: 0.4267\n","\n","Domain: 27\n","x_dp_dom.shape: (165, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 27 | Accuracy: 0.3515 | Loss: 4.5823 | F1: 0.3721\n","\n","Domain: 28\n","x_dp_dom.shape: (153, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 28 | Accuracy: 0.2288 | Loss: 10.4375 | F1: 0.1879\n","\n","Domain: 29\n","x_dp_dom.shape: (153, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 29 | Accuracy: 0.1961 | Loss: 7.2601 | F1: 0.2126\n","\n","Domain: 30\n","x_dp_dom.shape: (161, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 30 | Accuracy: 0.2422 | Loss: 5.2993 | F1: 0.2432\n","\n","Domain: 31\n","x_dp_dom.shape: (154, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 31 | Accuracy: 0.2338 | Loss: 10.5226 | F1: 0.2060\n","\n","Domain: 32\n","x_dp_dom.shape: (163, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 32 | Accuracy: 0.1718 | Loss: 11.1355 | F1: 0.1366\n","\n","Domain: 33\n","x_dp_dom.shape: (156, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 33 | Accuracy: 0.2244 | Loss: 12.4056 | F1: 0.1874\n","\n","Domain: 34\n","x_dp_dom.shape: (161, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 34 | Accuracy: 0.6646 | Loss: 1.4577 | F1: 0.6856\n","\n","Domain: 35\n","x_dp_dom.shape: (159, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 35 | Accuracy: 0.2830 | Loss: 6.3360 | F1: 0.2505\n","\n","Domain: 36\n","x_dp_dom.shape: (155, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 36 | Accuracy: 0.2323 | Loss: 9.9169 | F1: 0.1996\n","\n","Domain: 37\n","x_dp_dom.shape: (154, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 37 | Accuracy: 0.2208 | Loss: 6.7436 | F1: 0.2344\n","\n","Domain: 38\n","x_dp_dom.shape: (158, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 38 | Accuracy: 0.1519 | Loss: 4.9476 | F1: 0.0852\n","\n","Domain: 39\n","x_dp_dom.shape: (165, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 39 | Accuracy: 0.2970 | Loss: 4.5009 | F1: 0.2548\n","\n","Domain: 40\n","x_dp_dom.shape: (155, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 40 | Accuracy: 0.2129 | Loss: 6.0164 | F1: 0.1912\n","\n","Domain: 41\n","x_dp_dom.shape: (156, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 41 | Accuracy: 0.1282 | Loss: 16.1533 | F1: 0.1318\n","\n","Domain: 42\n","x_dp_dom.shape: (158, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 42 | Accuracy: 0.4557 | Loss: 3.2731 | F1: 0.5437\n","\n","Domain: 43\n","x_dp_dom.shape: (153, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 43 | Accuracy: 0.1699 | Loss: 8.3661 | F1: 0.1792\n","\n","Domain: 44\n","x_dp_dom.shape: (153, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 44 | Accuracy: 0.2288 | Loss: 8.7228 | F1: 0.1841\n","\n","Domain: 45\n","x_dp_dom.shape: (163, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 45 | Accuracy: 0.2454 | Loss: 13.4789 | F1: 0.1837\n","\n","Domain: 46\n","x_dp_dom.shape: (160, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 46 | Accuracy: 0.1375 | Loss: 8.0379 | F1: 0.0807\n","\n","Domain: 47\n","x_dp_dom.shape: (155, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 47 | Accuracy: 0.2000 | Loss: 7.1710 | F1: 0.1781\n","\n","Domain: 48\n","x_dp_dom.shape: (159, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 48 | Accuracy: 0.0692 | Loss: 12.9125 | F1: 0.0563\n","\n","Domain: 49\n","x_dp_dom.shape: (164, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 49 | Accuracy: 0.2317 | Loss: 9.5524 | F1: 0.1759\n","\n","Domain: 50\n","x_dp_dom.shape: (153, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 50 | Accuracy: 0.2614 | Loss: 12.5820 | F1: 0.2284\n","\n","Domain: 51\n","x_dp_dom.shape: (157, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 51 | Accuracy: 0.2611 | Loss: 9.2072 | F1: 0.2106\n","\n","Domain: 52\n","x_dp_dom.shape: (153, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 52 | Accuracy: 0.2288 | Loss: 9.0723 | F1: 0.1540\n","\n","Domain: 53\n","x_dp_dom.shape: (159, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 53 | Accuracy: 0.2138 | Loss: 14.7759 | F1: 0.1733\n","\n","Domain: 54\n","x_dp_dom.shape: (153, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 54 | Accuracy: 0.2614 | Loss: 5.8911 | F1: 0.2359\n","\n","Domain: 55\n","x_dp_dom.shape: (160, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 55 | Accuracy: 0.2437 | Loss: 13.1790 | F1: 0.1949\n","\n","Domain: 56\n","x_dp_dom.shape: (153, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 56 | Accuracy: 0.0915 | Loss: 9.4246 | F1: 0.1008\n","\n","Domain: 57\n","x_dp_dom.shape: (153, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 57 | Accuracy: 0.2549 | Loss: 11.4562 | F1: 0.2077\n","\n","Domain: 58\n","x_dp_dom.shape: (149, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 58 | Accuracy: 0.2215 | Loss: 13.4447 | F1: 0.1985\n","\n","Domain: 59\n","x_dp_dom.shape: (154, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 59 | Accuracy: 0.0584 | Loss: 10.6873 | F1: 0.0452\n","\n","Domain: 60\n","x_dp_dom.shape: (158, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 60 | Accuracy: 0.1772 | Loss: 8.5966 | F1: 0.1341\n","\n","Domain: 61\n","x_dp_dom.shape: (158, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 61 | Accuracy: 0.1266 | Loss: 10.5508 | F1: 0.1153\n","\n","Domain: 62\n","x_dp_dom.shape: (158, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 62 | Accuracy: 0.2532 | Loss: 12.6032 | F1: 0.1901\n","\n","Domain: 63\n","x_dp_dom.shape: (153, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 63 | Accuracy: 0.2288 | Loss: 13.5693 | F1: 0.2032\n","\n","Domain: 64\n","x_dp_dom.shape: (154, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 64 | Accuracy: 0.1753 | Loss: 10.2521 | F1: 0.1422\n","\n","Domain: 65\n","x_dp_dom.shape: (161, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 65 | Accuracy: 0.1863 | Loss: 8.5422 | F1: 0.1743\n","\n","Domain: 66\n","x_dp_dom.shape: (153, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 66 | Accuracy: 0.1242 | Loss: 15.7482 | F1: 0.1301\n","\n","Domain: 67\n","x_dp_dom.shape: (153, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 67 | Accuracy: 0.2549 | Loss: 7.7316 | F1: 0.2308\n","\n","Domain: 68\n","x_dp_dom.shape: (154, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 68 | Accuracy: 0.2078 | Loss: 12.2272 | F1: 0.1911\n","\n","Domain: 69\n","x_dp_dom.shape: (153, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 69 | Accuracy: 0.1634 | Loss: 10.3459 | F1: 0.1346\n","\n","Domain: 70\n","x_dp_dom.shape: (153, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 70 | Accuracy: 0.5621 | Loss: 2.3199 | F1: 0.6456\n","\n","Domain: 71\n","x_dp_dom.shape: (155, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 71 | Accuracy: 0.2065 | Loss: 11.3880 | F1: 0.1927\n","\n","Domain: 72\n","x_dp_dom.shape: (153, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 72 | Accuracy: 0.0392 | Loss: 13.3397 | F1: 0.0298\n","\n","Domain: 73\n","x_dp_dom.shape: (152, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 73 | Accuracy: 0.2961 | Loss: 4.0674 | F1: 0.2375\n","\n","Domain: 74\n","x_dp_dom.shape: (146, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 74 | Accuracy: 0.2192 | Loss: 9.4968 | F1: 0.2103\n","\n","Domain: 75\n","x_dp_dom.shape: (153, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 75 | Accuracy: 0.2157 | Loss: 13.9235 | F1: 0.1839\n","\n","Mean accuracy for run 6: 0.2306\n","Mean F1 for run 6: 0.2076\n","\n","Source class: WAL\n","\n","x_df.shape: (11483, 3, 128) | np.unique(y_df): [0 1 2 3]\n","\n","Training on Df data...\n","\tEpoch 10/100 - Train loss: 0.0937 - Val accuracy: 0.9560 - Val loss: 0.1338 - Val F1: 0.9561 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.0383 - Val accuracy: 0.9552 - Val loss: 0.1258 - Val F1: 0.9551 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.0190 - Val accuracy: 0.9586 - Val loss: 0.1473 - Val F1: 0.9586 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.0102 - Val accuracy: 0.9595 - Val loss: 0.1620 - Val F1: 0.9595 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.0081 - Val accuracy: 0.9578 - Val loss: 0.1657 - Val F1: 0.9578 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.0037 - Val accuracy: 0.9582 - Val loss: 0.1721 - Val F1: 0.9582 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0019 - Val accuracy: 0.9595 - Val loss: 0.1791 - Val F1: 0.9595 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0018 - Val accuracy: 0.9621 - Val loss: 0.1719 - Val F1: 0.9621 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0013 - Val accuracy: 0.9604 - Val loss: 0.1808 - Val F1: 0.9604 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0012 - Val accuracy: 0.9595 - Val loss: 0.1901 - Val F1: 0.9595 - LR: 0.00e+00\n","\tBest epoch: 13 - Best val accuracy: 0.9547 - Best val loss: 0.1252 - Best val F1: 0.9548\n","\n","Domain: 15\n","x_dp_dom.shape: (161, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 15 | Accuracy: 0.0807 | Loss: 16.3930 | F1: 0.0295\n","\n","Domain: 16\n","x_dp_dom.shape: (165, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 16 | Accuracy: 0.2727 | Loss: 11.4111 | F1: 0.2219\n","\n","Domain: 17\n","x_dp_dom.shape: (164, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 17 | Accuracy: 0.1951 | Loss: 9.5208 | F1: 0.1517\n","\n","Domain: 18\n","x_dp_dom.shape: (166, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 18 | Accuracy: 0.2410 | Loss: 10.5668 | F1: 0.2225\n","\n","Domain: 19\n","x_dp_dom.shape: (165, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 19 | Accuracy: 0.2727 | Loss: 11.3726 | F1: 0.2208\n","\n","Domain: 20\n","x_dp_dom.shape: (162, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 20 | Accuracy: 0.2407 | Loss: 6.9533 | F1: 0.2608\n","\n","Domain: 21\n","x_dp_dom.shape: (159, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 21 | Accuracy: 0.1761 | Loss: 11.6911 | F1: 0.1786\n","\n","Domain: 22\n","x_dp_dom.shape: (165, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 22 | Accuracy: 0.3273 | Loss: 4.9924 | F1: 0.3525\n","\n","Domain: 23\n","x_dp_dom.shape: (164, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 23 | Accuracy: 0.2439 | Loss: 9.8240 | F1: 0.1948\n","\n","Domain: 24\n","x_dp_dom.shape: (162, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 24 | Accuracy: 0.1914 | Loss: 15.1193 | F1: 0.1495\n","\n","Domain: 25\n","x_dp_dom.shape: (166, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 25 | Accuracy: 0.2470 | Loss: 10.6914 | F1: 0.1826\n","\n","Domain: 26\n","x_dp_dom.shape: (153, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 26 | Accuracy: 0.1634 | Loss: 9.7575 | F1: 0.1354\n","\n","Domain: 27\n","x_dp_dom.shape: (165, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 27 | Accuracy: 0.1818 | Loss: 11.8749 | F1: 0.1491\n","\n","Domain: 28\n","x_dp_dom.shape: (153, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 28 | Accuracy: 0.2484 | Loss: 6.5361 | F1: 0.2826\n","\n","Domain: 29\n","x_dp_dom.shape: (153, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 29 | Accuracy: 0.2680 | Loss: 11.0681 | F1: 0.2141\n","\n","Domain: 30\n","x_dp_dom.shape: (161, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 30 | Accuracy: 0.2360 | Loss: 14.1832 | F1: 0.1969\n","\n","Domain: 31\n","x_dp_dom.shape: (154, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 31 | Accuracy: 0.2403 | Loss: 24.8159 | F1: 0.2050\n","\n","Domain: 32\n","x_dp_dom.shape: (163, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 32 | Accuracy: 0.1288 | Loss: 13.4382 | F1: 0.1127\n","\n","Domain: 33\n","x_dp_dom.shape: (156, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 33 | Accuracy: 0.0833 | Loss: 13.2554 | F1: 0.0596\n","\n","Domain: 34\n","x_dp_dom.shape: (161, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 34 | Accuracy: 0.1366 | Loss: 19.6825 | F1: 0.1265\n","\n","Domain: 35\n","x_dp_dom.shape: (159, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 35 | Accuracy: 0.2453 | Loss: 10.5371 | F1: 0.1848\n","\n","Domain: 36\n","x_dp_dom.shape: (155, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 36 | Accuracy: 0.2323 | Loss: 11.0370 | F1: 0.1892\n","\n","Domain: 37\n","x_dp_dom.shape: (154, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 37 | Accuracy: 0.2078 | Loss: 10.7149 | F1: 0.2075\n","\n","Domain: 38\n","x_dp_dom.shape: (158, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 38 | Accuracy: 0.1392 | Loss: 13.5603 | F1: 0.1120\n","\n","Domain: 39\n","x_dp_dom.shape: (165, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 39 | Accuracy: 0.1636 | Loss: 13.4735 | F1: 0.1390\n","\n","Domain: 40\n","x_dp_dom.shape: (155, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 40 | Accuracy: 0.2000 | Loss: 9.8218 | F1: 0.1784\n","\n","Domain: 41\n","x_dp_dom.shape: (156, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 41 | Accuracy: 0.0705 | Loss: 37.6877 | F1: 0.0581\n","\n","Domain: 42\n","x_dp_dom.shape: (158, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 42 | Accuracy: 0.1962 | Loss: 14.9689 | F1: 0.1664\n","\n","Domain: 43\n","x_dp_dom.shape: (153, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 43 | Accuracy: 0.1699 | Loss: 29.5022 | F1: 0.1621\n","\n","Domain: 44\n","x_dp_dom.shape: (153, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 44 | Accuracy: 0.2418 | Loss: 9.4746 | F1: 0.1916\n","\n","Domain: 45\n","x_dp_dom.shape: (163, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 45 | Accuracy: 0.1656 | Loss: 13.2011 | F1: 0.1370\n","\n","Domain: 46\n","x_dp_dom.shape: (160, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 46 | Accuracy: 0.2625 | Loss: 8.8828 | F1: 0.1955\n","\n","Domain: 47\n","x_dp_dom.shape: (155, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 47 | Accuracy: 0.2129 | Loss: 10.0342 | F1: 0.1858\n","\n","Domain: 48\n","x_dp_dom.shape: (159, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 48 | Accuracy: 0.2516 | Loss: 10.7500 | F1: 0.2326\n","\n","Domain: 49\n","x_dp_dom.shape: (164, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 49 | Accuracy: 0.1829 | Loss: 12.5629 | F1: 0.1483\n","\n","Domain: 50\n","x_dp_dom.shape: (153, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 50 | Accuracy: 0.2288 | Loss: 18.3543 | F1: 0.1881\n","\n","Domain: 51\n","x_dp_dom.shape: (157, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 51 | Accuracy: 0.3312 | Loss: 6.1961 | F1: 0.3670\n","\n","Domain: 52\n","x_dp_dom.shape: (153, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 52 | Accuracy: 0.2222 | Loss: 17.5753 | F1: 0.1942\n","\n","Domain: 53\n","x_dp_dom.shape: (159, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 53 | Accuracy: 0.1887 | Loss: 29.6992 | F1: 0.1804\n","\n","Domain: 54\n","x_dp_dom.shape: (153, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 54 | Accuracy: 0.2680 | Loss: 5.4600 | F1: 0.2426\n","\n","Domain: 55\n","x_dp_dom.shape: (160, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 55 | Accuracy: 0.2250 | Loss: 20.7787 | F1: 0.2120\n","\n","Domain: 56\n","x_dp_dom.shape: (153, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 56 | Accuracy: 0.1634 | Loss: 7.5913 | F1: 0.1937\n","\n","Domain: 57\n","x_dp_dom.shape: (153, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 57 | Accuracy: 0.1503 | Loss: 18.4081 | F1: 0.1063\n","\n","Domain: 58\n","x_dp_dom.shape: (149, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 58 | Accuracy: 0.2081 | Loss: 23.0137 | F1: 0.2007\n","\n","Domain: 59\n","x_dp_dom.shape: (154, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 59 | Accuracy: 0.1688 | Loss: 16.4769 | F1: 0.1651\n","\n","Domain: 60\n","x_dp_dom.shape: (158, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 60 | Accuracy: 0.1139 | Loss: 36.4879 | F1: 0.0803\n","\n","Domain: 61\n","x_dp_dom.shape: (158, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 61 | Accuracy: 0.4747 | Loss: 3.2856 | F1: 0.5862\n","\n","Domain: 62\n","x_dp_dom.shape: (158, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 62 | Accuracy: 0.2532 | Loss: 14.1163 | F1: 0.1920\n","\n","Domain: 63\n","x_dp_dom.shape: (153, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 63 | Accuracy: 0.2288 | Loss: 17.1004 | F1: 0.2029\n","\n","Domain: 64\n","x_dp_dom.shape: (154, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 64 | Accuracy: 0.2857 | Loss: 7.8872 | F1: 0.2943\n","\n","Domain: 65\n","x_dp_dom.shape: (161, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 65 | Accuracy: 0.0683 | Loss: 15.5601 | F1: 0.0217\n","\n","Domain: 66\n","x_dp_dom.shape: (153, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 66 | Accuracy: 0.0392 | Loss: 24.1744 | F1: 0.0051\n","\n","Domain: 67\n","x_dp_dom.shape: (153, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 67 | Accuracy: 0.4967 | Loss: 2.6384 | F1: 0.6094\n","\n","Domain: 68\n","x_dp_dom.shape: (154, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 68 | Accuracy: 0.2143 | Loss: 10.1631 | F1: 0.2483\n","\n","Domain: 69\n","x_dp_dom.shape: (153, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 69 | Accuracy: 0.0719 | Loss: 18.0305 | F1: 0.0251\n","\n","Domain: 70\n","x_dp_dom.shape: (153, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 70 | Accuracy: 0.1765 | Loss: 12.4580 | F1: 0.1787\n","\n","Domain: 71\n","x_dp_dom.shape: (155, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 71 | Accuracy: 0.2645 | Loss: 11.1400 | F1: 0.2144\n","\n","Domain: 72\n","x_dp_dom.shape: (153, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 72 | Accuracy: 0.0719 | Loss: 17.4976 | F1: 0.0816\n","\n","Domain: 73\n","x_dp_dom.shape: (152, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 73 | Accuracy: 0.0461 | Loss: 31.8066 | F1: 0.0041\n","\n","Domain: 74\n","x_dp_dom.shape: (146, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 74 | Accuracy: 0.2534 | Loss: 6.0701 | F1: 0.3303\n","\n","Domain: 75\n","x_dp_dom.shape: (153, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 75 | Accuracy: 0.1699 | Loss: 13.3229 | F1: 0.1574\n","\n","Mean accuracy for run 7: 0.2049\n","Mean F1 for run 7: 0.1872\n","\n","Source class: WAL\n","\n","x_df.shape: (11483, 3, 128) | np.unique(y_df): [0 1 2 3]\n","\n","Training on Df data...\n","\tEpoch 10/100 - Train loss: 0.1089 - Val accuracy: 0.9473 - Val loss: 0.1439 - Val F1: 0.9473 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.0534 - Val accuracy: 0.9547 - Val loss: 0.1269 - Val F1: 0.9547 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.0225 - Val accuracy: 0.9582 - Val loss: 0.1398 - Val F1: 0.9582 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.0129 - Val accuracy: 0.9573 - Val loss: 0.1398 - Val F1: 0.9574 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.0070 - Val accuracy: 0.9595 - Val loss: 0.1523 - Val F1: 0.9595 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.0040 - Val accuracy: 0.9599 - Val loss: 0.1464 - Val F1: 0.9600 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0062 - Val accuracy: 0.9613 - Val loss: 0.1707 - Val F1: 0.9612 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0022 - Val accuracy: 0.9573 - Val loss: 0.1652 - Val F1: 0.9573 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0018 - Val accuracy: 0.9604 - Val loss: 0.1742 - Val F1: 0.9604 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0014 - Val accuracy: 0.9613 - Val loss: 0.1745 - Val F1: 0.9613 - LR: 0.00e+00\n","\tBest epoch: 20 - Best val accuracy: 0.9547 - Best val loss: 0.1269 - Best val F1: 0.9547\n","\n","Domain: 15\n","x_dp_dom.shape: (161, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 15 | Accuracy: 0.2422 | Loss: 14.9372 | F1: 0.1787\n","\n","Domain: 16\n","x_dp_dom.shape: (165, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 16 | Accuracy: 0.1879 | Loss: 9.7494 | F1: 0.1571\n","\n","Domain: 17\n","x_dp_dom.shape: (164, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 17 | Accuracy: 0.1585 | Loss: 8.8173 | F1: 0.1162\n","\n","Domain: 18\n","x_dp_dom.shape: (166, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 18 | Accuracy: 0.0723 | Loss: 14.4427 | F1: 0.0594\n","\n","Domain: 19\n","x_dp_dom.shape: (165, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 19 | Accuracy: 0.2182 | Loss: 8.1810 | F1: 0.1697\n","\n","Domain: 20\n","x_dp_dom.shape: (162, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 20 | Accuracy: 0.1543 | Loss: 10.3996 | F1: 0.1087\n","\n","Domain: 21\n","x_dp_dom.shape: (159, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 21 | Accuracy: 0.1132 | Loss: 17.5999 | F1: 0.0906\n","\n","Domain: 22\n","x_dp_dom.shape: (165, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 22 | Accuracy: 0.2000 | Loss: 10.2811 | F1: 0.1410\n","\n","Domain: 23\n","x_dp_dom.shape: (164, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 23 | Accuracy: 0.2317 | Loss: 18.7351 | F1: 0.1804\n","\n","Domain: 24\n","x_dp_dom.shape: (162, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 24 | Accuracy: 0.2284 | Loss: 11.3612 | F1: 0.1814\n","\n","Domain: 25\n","x_dp_dom.shape: (166, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 25 | Accuracy: 0.1687 | Loss: 12.8279 | F1: 0.1502\n","\n","Domain: 26\n","x_dp_dom.shape: (153, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 26 | Accuracy: 0.1895 | Loss: 20.1039 | F1: 0.1793\n","\n","Domain: 27\n","x_dp_dom.shape: (165, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 27 | Accuracy: 0.2485 | Loss: 9.0339 | F1: 0.1846\n","\n","Domain: 28\n","x_dp_dom.shape: (153, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 28 | Accuracy: 0.2549 | Loss: 7.0697 | F1: 0.2163\n","\n","Domain: 29\n","x_dp_dom.shape: (153, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 29 | Accuracy: 0.1046 | Loss: 11.3233 | F1: 0.0446\n","\n","Domain: 30\n","x_dp_dom.shape: (161, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 30 | Accuracy: 0.2050 | Loss: 14.9322 | F1: 0.1579\n","\n","Domain: 31\n","x_dp_dom.shape: (154, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 31 | Accuracy: 0.2338 | Loss: 25.7752 | F1: 0.1240\n","\n","Domain: 32\n","x_dp_dom.shape: (163, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 32 | Accuracy: 0.1534 | Loss: 13.7774 | F1: 0.1240\n","\n","Domain: 33\n","x_dp_dom.shape: (156, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 33 | Accuracy: 0.2500 | Loss: 15.8406 | F1: 0.1732\n","\n","Domain: 34\n","x_dp_dom.shape: (161, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 34 | Accuracy: 0.1988 | Loss: 25.0164 | F1: 0.1014\n","\n","Domain: 35\n","x_dp_dom.shape: (159, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 35 | Accuracy: 0.0818 | Loss: 16.3855 | F1: 0.0135\n","\n","Domain: 36\n","x_dp_dom.shape: (155, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 36 | Accuracy: 0.0774 | Loss: 9.5136 | F1: 0.0231\n","\n","Domain: 37\n","x_dp_dom.shape: (154, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 37 | Accuracy: 0.2143 | Loss: 10.7278 | F1: 0.2048\n","\n","Domain: 38\n","x_dp_dom.shape: (158, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 38 | Accuracy: 0.1582 | Loss: 32.9669 | F1: 0.0807\n","\n","Domain: 39\n","x_dp_dom.shape: (165, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 39 | Accuracy: 0.2000 | Loss: 12.6809 | F1: 0.1792\n","\n","Domain: 40\n","x_dp_dom.shape: (155, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 40 | Accuracy: 0.2065 | Loss: 10.3230 | F1: 0.1898\n","\n","Domain: 41\n","x_dp_dom.shape: (156, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 41 | Accuracy: 0.0769 | Loss: 17.2271 | F1: 0.0503\n","\n","Domain: 42\n","x_dp_dom.shape: (158, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 42 | Accuracy: 0.0759 | Loss: 14.8407 | F1: 0.0626\n","\n","Domain: 43\n","x_dp_dom.shape: (153, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 43 | Accuracy: 0.2222 | Loss: 27.7912 | F1: 0.1105\n","\n","Domain: 44\n","x_dp_dom.shape: (153, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 44 | Accuracy: 0.1242 | Loss: 7.9548 | F1: 0.1070\n","\n","Domain: 45\n","x_dp_dom.shape: (163, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 45 | Accuracy: 0.1963 | Loss: 17.0662 | F1: 0.1443\n","\n","Domain: 46\n","x_dp_dom.shape: (160, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 46 | Accuracy: 0.1750 | Loss: 11.6501 | F1: 0.1503\n","\n","Domain: 47\n","x_dp_dom.shape: (155, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 47 | Accuracy: 0.1226 | Loss: 9.3039 | F1: 0.1229\n","\n","Domain: 48\n","x_dp_dom.shape: (159, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 48 | Accuracy: 0.2201 | Loss: 15.9872 | F1: 0.2083\n","\n","Domain: 49\n","x_dp_dom.shape: (164, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 49 | Accuracy: 0.0793 | Loss: 16.2336 | F1: 0.0116\n","\n","Domain: 50\n","x_dp_dom.shape: (153, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 50 | Accuracy: 0.2222 | Loss: 24.4382 | F1: 0.1229\n","\n","Domain: 51\n","x_dp_dom.shape: (157, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 51 | Accuracy: 0.1720 | Loss: 13.8528 | F1: 0.1556\n","\n","Domain: 52\n","x_dp_dom.shape: (153, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 52 | Accuracy: 0.1503 | Loss: 17.1687 | F1: 0.1136\n","\n","Domain: 53\n","x_dp_dom.shape: (159, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 53 | Accuracy: 0.2075 | Loss: 18.9117 | F1: 0.1017\n","\n","Domain: 54\n","x_dp_dom.shape: (153, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 54 | Accuracy: 0.2484 | Loss: 5.5753 | F1: 0.2116\n","\n","Domain: 55\n","x_dp_dom.shape: (160, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 55 | Accuracy: 0.2188 | Loss: 18.9148 | F1: 0.1384\n","\n","Domain: 56\n","x_dp_dom.shape: (153, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 56 | Accuracy: 0.1242 | Loss: 13.3846 | F1: 0.1118\n","\n","Domain: 57\n","x_dp_dom.shape: (153, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 57 | Accuracy: 0.2484 | Loss: 13.9806 | F1: 0.1691\n","\n","Domain: 58\n","x_dp_dom.shape: (149, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 58 | Accuracy: 0.2282 | Loss: 28.7832 | F1: 0.2018\n","\n","Domain: 59\n","x_dp_dom.shape: (154, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 59 | Accuracy: 0.1364 | Loss: 12.0212 | F1: 0.1091\n","\n","Domain: 60\n","x_dp_dom.shape: (158, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 60 | Accuracy: 0.1519 | Loss: 28.8289 | F1: 0.0467\n","\n","Domain: 61\n","x_dp_dom.shape: (158, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 61 | Accuracy: 0.1392 | Loss: 8.0892 | F1: 0.1362\n","\n","Domain: 62\n","x_dp_dom.shape: (158, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 62 | Accuracy: 0.1013 | Loss: 16.0637 | F1: 0.0559\n","\n","Domain: 63\n","x_dp_dom.shape: (153, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 63 | Accuracy: 0.1961 | Loss: 17.1734 | F1: 0.1753\n","\n","Domain: 64\n","x_dp_dom.shape: (154, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 64 | Accuracy: 0.1883 | Loss: 17.8287 | F1: 0.1804\n","\n","Domain: 65\n","x_dp_dom.shape: (161, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 65 | Accuracy: 0.2174 | Loss: 7.4589 | F1: 0.2085\n","\n","Domain: 66\n","x_dp_dom.shape: (153, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 66 | Accuracy: 0.2092 | Loss: 18.1919 | F1: 0.1585\n","\n","Domain: 67\n","x_dp_dom.shape: (153, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 67 | Accuracy: 0.2157 | Loss: 11.3456 | F1: 0.1954\n","\n","Domain: 68\n","x_dp_dom.shape: (154, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 68 | Accuracy: 0.0779 | Loss: 16.8679 | F1: 0.0429\n","\n","Domain: 69\n","x_dp_dom.shape: (153, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 69 | Accuracy: 0.2680 | Loss: 15.5361 | F1: 0.1931\n","\n","Domain: 70\n","x_dp_dom.shape: (153, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 70 | Accuracy: 0.1830 | Loss: 9.6069 | F1: 0.2079\n","\n","Domain: 71\n","x_dp_dom.shape: (155, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 71 | Accuracy: 0.1226 | Loss: 14.9877 | F1: 0.0872\n","\n","Domain: 72\n","x_dp_dom.shape: (153, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 72 | Accuracy: 0.1373 | Loss: 15.5273 | F1: 0.1215\n","\n","Domain: 73\n","x_dp_dom.shape: (152, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 73 | Accuracy: 0.1842 | Loss: 23.1670 | F1: 0.0573\n","\n","Domain: 74\n","x_dp_dom.shape: (146, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 74 | Accuracy: 0.2397 | Loss: 8.5908 | F1: 0.2645\n","\n","Domain: 75\n","x_dp_dom.shape: (153, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 75 | Accuracy: 0.2092 | Loss: 17.3118 | F1: 0.1821\n","\n","Mean accuracy for run 8: 0.1777\n","Mean F1 for run 8: 0.1352\n","\n","Source class: WAL\n","\n","x_df.shape: (11483, 3, 128) | np.unique(y_df): [0 1 2 3]\n","\n","Training on Df data...\n","\tEpoch 10/100 - Train loss: 0.1026 - Val accuracy: 0.9508 - Val loss: 0.1428 - Val F1: 0.9508 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.0372 - Val accuracy: 0.9599 - Val loss: 0.1242 - Val F1: 0.9599 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.0172 - Val accuracy: 0.9595 - Val loss: 0.1339 - Val F1: 0.9595 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.0098 - Val accuracy: 0.9626 - Val loss: 0.1435 - Val F1: 0.9626 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.0071 - Val accuracy: 0.9626 - Val loss: 0.1479 - Val F1: 0.9626 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.0044 - Val accuracy: 0.9613 - Val loss: 0.1609 - Val F1: 0.9613 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0039 - Val accuracy: 0.9634 - Val loss: 0.1668 - Val F1: 0.9634 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0022 - Val accuracy: 0.9652 - Val loss: 0.1600 - Val F1: 0.9651 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0016 - Val accuracy: 0.9652 - Val loss: 0.1729 - Val F1: 0.9652 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0016 - Val accuracy: 0.9652 - Val loss: 0.1671 - Val F1: 0.9652 - LR: 0.00e+00\n","\tBest epoch: 24 - Best val accuracy: 0.9613 - Best val loss: 0.1216 - Best val F1: 0.9612\n","\n","Domain: 15\n","x_dp_dom.shape: (161, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 15 | Accuracy: 0.0745 | Loss: 15.3131 | F1: 0.0148\n","\n","Domain: 16\n","x_dp_dom.shape: (165, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 16 | Accuracy: 0.2485 | Loss: 13.0262 | F1: 0.2100\n","\n","Domain: 17\n","x_dp_dom.shape: (164, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 17 | Accuracy: 0.2622 | Loss: 5.4901 | F1: 0.2103\n","\n","Domain: 18\n","x_dp_dom.shape: (166, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 18 | Accuracy: 0.2229 | Loss: 15.1340 | F1: 0.1867\n","\n","Domain: 19\n","x_dp_dom.shape: (165, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 19 | Accuracy: 0.2606 | Loss: 8.0697 | F1: 0.2045\n","\n","Domain: 20\n","x_dp_dom.shape: (162, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 20 | Accuracy: 0.2716 | Loss: 9.0551 | F1: 0.2342\n","\n","Domain: 21\n","x_dp_dom.shape: (159, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 21 | Accuracy: 0.2327 | Loss: 11.3857 | F1: 0.1971\n","\n","Domain: 22\n","x_dp_dom.shape: (165, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 22 | Accuracy: 0.3212 | Loss: 5.0301 | F1: 0.2762\n","\n","Domain: 23\n","x_dp_dom.shape: (164, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 23 | Accuracy: 0.2256 | Loss: 14.2433 | F1: 0.1108\n","\n","Domain: 24\n","x_dp_dom.shape: (162, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 24 | Accuracy: 0.2469 | Loss: 14.5343 | F1: 0.2010\n","\n","Domain: 25\n","x_dp_dom.shape: (166, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 25 | Accuracy: 0.2590 | Loss: 7.6670 | F1: 0.2160\n","\n","Domain: 26\n","x_dp_dom.shape: (153, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 26 | Accuracy: 0.1373 | Loss: 11.3461 | F1: 0.0927\n","\n","Domain: 27\n","x_dp_dom.shape: (165, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 27 | Accuracy: 0.4788 | Loss: 2.9402 | F1: 0.5274\n","\n","Domain: 28\n","x_dp_dom.shape: (153, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 28 | Accuracy: 0.4444 | Loss: 3.3399 | F1: 0.5279\n","\n","Domain: 29\n","x_dp_dom.shape: (153, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 29 | Accuracy: 0.2157 | Loss: 11.2780 | F1: 0.1748\n","\n","Domain: 30\n","x_dp_dom.shape: (161, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 30 | Accuracy: 0.2236 | Loss: 13.4777 | F1: 0.1799\n","\n","Domain: 31\n","x_dp_dom.shape: (154, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 31 | Accuracy: 0.2468 | Loss: 56.5492 | F1: 0.2097\n","\n","Domain: 32\n","x_dp_dom.shape: (163, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 32 | Accuracy: 0.1350 | Loss: 17.3919 | F1: 0.1065\n","\n","Domain: 33\n","x_dp_dom.shape: (156, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 33 | Accuracy: 0.2179 | Loss: 19.4102 | F1: 0.1650\n","\n","Domain: 34\n","x_dp_dom.shape: (161, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 34 | Accuracy: 0.1863 | Loss: 58.6069 | F1: 0.1657\n","\n","Domain: 35\n","x_dp_dom.shape: (159, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 35 | Accuracy: 0.2579 | Loss: 9.1873 | F1: 0.1911\n","\n","Domain: 36\n","x_dp_dom.shape: (155, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 36 | Accuracy: 0.2258 | Loss: 8.1954 | F1: 0.2023\n","\n","Domain: 37\n","x_dp_dom.shape: (154, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 37 | Accuracy: 0.1688 | Loss: 9.4213 | F1: 0.1533\n","\n","Domain: 38\n","x_dp_dom.shape: (158, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 38 | Accuracy: 0.2089 | Loss: 59.6329 | F1: 0.1757\n","\n","Domain: 39\n","x_dp_dom.shape: (165, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 39 | Accuracy: 0.1576 | Loss: 13.1435 | F1: 0.1159\n","\n","Domain: 40\n","x_dp_dom.shape: (155, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 40 | Accuracy: 0.2323 | Loss: 15.8477 | F1: 0.1881\n","\n","Domain: 41\n","x_dp_dom.shape: (156, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 41 | Accuracy: 0.0705 | Loss: 26.2621 | F1: 0.0531\n","\n","Domain: 42\n","x_dp_dom.shape: (158, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 42 | Accuracy: 0.1646 | Loss: 8.5857 | F1: 0.1560\n","\n","Domain: 43\n","x_dp_dom.shape: (153, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 43 | Accuracy: 0.1438 | Loss: 58.5512 | F1: 0.1428\n","\n","Domain: 44\n","x_dp_dom.shape: (153, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 44 | Accuracy: 0.2745 | Loss: 7.9085 | F1: 0.2328\n","\n","Domain: 45\n","x_dp_dom.shape: (163, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 45 | Accuracy: 0.2577 | Loss: 12.3692 | F1: 0.1626\n","\n","Domain: 46\n","x_dp_dom.shape: (160, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 46 | Accuracy: 0.2812 | Loss: 6.1892 | F1: 0.1977\n","\n","Domain: 47\n","x_dp_dom.shape: (155, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 47 | Accuracy: 0.1677 | Loss: 7.4678 | F1: 0.1586\n","\n","Domain: 48\n","x_dp_dom.shape: (159, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 48 | Accuracy: 0.1195 | Loss: 15.3615 | F1: 0.1018\n","\n","Domain: 49\n","x_dp_dom.shape: (164, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 49 | Accuracy: 0.2378 | Loss: 11.2987 | F1: 0.1782\n","\n","Domain: 50\n","x_dp_dom.shape: (153, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 50 | Accuracy: 0.2288 | Loss: 21.6108 | F1: 0.1842\n","\n","Domain: 51\n","x_dp_dom.shape: (157, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 51 | Accuracy: 0.2293 | Loss: 9.8337 | F1: 0.2068\n","\n","Domain: 52\n","x_dp_dom.shape: (153, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 52 | Accuracy: 0.2353 | Loss: 14.0385 | F1: 0.1636\n","\n","Domain: 53\n","x_dp_dom.shape: (159, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 53 | Accuracy: 0.1824 | Loss: 51.9903 | F1: 0.1496\n","\n","Domain: 54\n","x_dp_dom.shape: (153, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 54 | Accuracy: 0.2026 | Loss: 12.5332 | F1: 0.1743\n","\n","Domain: 55\n","x_dp_dom.shape: (160, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 55 | Accuracy: 0.2562 | Loss: 17.1462 | F1: 0.1811\n","\n","Domain: 56\n","x_dp_dom.shape: (153, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 56 | Accuracy: 0.0261 | Loss: 10.2108 | F1: 0.0242\n","\n","Domain: 57\n","x_dp_dom.shape: (153, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 57 | Accuracy: 0.2092 | Loss: 14.3066 | F1: 0.1008\n","\n","Domain: 58\n","x_dp_dom.shape: (149, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 58 | Accuracy: 0.2081 | Loss: 26.1588 | F1: 0.1968\n","\n","Domain: 59\n","x_dp_dom.shape: (154, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 59 | Accuracy: 0.1948 | Loss: 16.6285 | F1: 0.1782\n","\n","Domain: 60\n","x_dp_dom.shape: (158, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 60 | Accuracy: 0.1266 | Loss: 58.8556 | F1: 0.0958\n","\n","Domain: 61\n","x_dp_dom.shape: (158, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 61 | Accuracy: 0.2532 | Loss: 4.9335 | F1: 0.2677\n","\n","Domain: 62\n","x_dp_dom.shape: (158, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 62 | Accuracy: 0.2532 | Loss: 14.1771 | F1: 0.1901\n","\n","Domain: 63\n","x_dp_dom.shape: (153, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 63 | Accuracy: 0.2026 | Loss: 17.6472 | F1: 0.1679\n","\n","Domain: 64\n","x_dp_dom.shape: (154, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 64 | Accuracy: 0.2208 | Loss: 11.6596 | F1: 0.1998\n","\n","Domain: 65\n","x_dp_dom.shape: (161, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 65 | Accuracy: 0.1056 | Loss: 19.1707 | F1: 0.0514\n","\n","Domain: 66\n","x_dp_dom.shape: (153, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 66 | Accuracy: 0.0458 | Loss: 15.7884 | F1: 0.0079\n","\n","Domain: 67\n","x_dp_dom.shape: (153, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 67 | Accuracy: 0.2810 | Loss: 7.0876 | F1: 0.2683\n","\n","Domain: 68\n","x_dp_dom.shape: (154, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 68 | Accuracy: 0.0779 | Loss: 20.3910 | F1: 0.0522\n","\n","Domain: 69\n","x_dp_dom.shape: (153, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 69 | Accuracy: 0.0784 | Loss: 17.2533 | F1: 0.0156\n","\n","Domain: 70\n","x_dp_dom.shape: (153, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 70 | Accuracy: 0.2810 | Loss: 7.4649 | F1: 0.3054\n","\n","Domain: 71\n","x_dp_dom.shape: (155, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 71 | Accuracy: 0.2323 | Loss: 12.6673 | F1: 0.1735\n","\n","Domain: 72\n","x_dp_dom.shape: (153, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 72 | Accuracy: 0.1569 | Loss: 15.5646 | F1: 0.1047\n","\n","Domain: 73\n","x_dp_dom.shape: (152, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 73 | Accuracy: 0.0461 | Loss: 59.1585 | F1: 0.0041\n","\n","Domain: 74\n","x_dp_dom.shape: (146, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 74 | Accuracy: 0.2123 | Loss: 12.6854 | F1: 0.1923\n","\n","Domain: 75\n","x_dp_dom.shape: (153, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 75 | Accuracy: 0.2222 | Loss: 10.9587 | F1: 0.1237\n","\n","Mean accuracy for run 9: 0.2074\n","Mean F1 for run 9: 0.1705\n","\n","Mean accuracy over 10 runs: 0.2111 +- 0.0177\n","Mean F1 over 10 runs: 0.1836 +- 0.0225\n","\n"]}],"source":["def compute_TSTR_Df_rot(dataset):\n","    accs = []\n","    f1s = []\n","\n","    for i in range(n_runs):\n","\n","        accs_run = []\n","        f1s_run = []\n","\n","        for src_class in config[dataset]['class_names']:\n","            if src_class != 'WAL':\n","                continue\n","\n","            print(f\"Source class: {src_class}\\n\")\n","\n","            # Load Df data\n","            x_df, y_df, k_df = get_data(dataset, 'df', src_class, rot=True)\n","            print(f'x_df.shape: {x_df.shape} | np.unique(y_df): {np.unique(y_df)}\\n')\n","\n","            # Train on Df data\n","            print('Training on Df data...')\n","            df_model = train_only(x_df, y_df, dataset, num_epochs=num_epochs)\n","\n","            for domain in range(config[dataset]['num_df_domains'], config[dataset]['num_df_domains'] + config[dataset]['num_dp_domains']):\n","                print(f\"Domain: {domain}\")\n","\n","                # Load Dp data\n","                x_dp_dom, y_dp_dom, k_dp_dom = get_data(dataset, 'dp', src_class, domain)\n","                print(f'x_dp_dom.shape: {x_dp_dom.shape} | np.unique(y_dp_dom): {np.unique(y_dp_dom)}\\n')\n","\n","                # Evaluate on Dp data\n","                acc, loss, f1 = evaluate_model(df_model, get_dataloader(x_dp_dom, y_dp_dom))\n","                save_scores(src_class, domain, acc, loss, f1, 'Df_rot', dataset)\n","                accs_run.append(acc)\n","                f1s_run.append(f1)\n","                print(f'Source class: {src_class} | Domain: {domain} | Accuracy: {acc:.4f} | Loss: {loss:.4f} | F1: {f1:.4f}\\n')\n","\n","        print(f\"Mean accuracy for run {i}: {np.mean(accs_run):.4f}\")\n","        print(f\"Mean F1 for run {i}: {np.mean(f1s_run):.4f}\\n\")\n","        accs.append(np.mean(accs_run))\n","        f1s.append(np.mean(f1s_run))\n","\n","    print(f\"Mean accuracy over {n_runs} runs: {np.mean(accs):.4f} +- {np.std(accs):.4f}\")\n","    print(f\"Mean F1 over {n_runs} runs: {np.mean(f1s):.4f} +- {np.std(f1s):.4f}\\n\")\n","\n","\n","\n","\n","compute_TSTR_Df_rot('realworld_mobiact')"]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":576599,"status":"ok","timestamp":1732698667950,"user":{"displayName":"Pietro Pietro","userId":"08339472013712676764"},"user_tz":-60},"id":"SmGQm1ZFCPto","outputId":"57bb0797-4a8f-4486-8b49-b8fb460c5f53"},"outputs":[{"output_type":"stream","name":"stdout","text":["Source class: WAL\n","\n","Domain: 15\n","x_syn_dom.shape: (444, 3, 128) | np.unique(y_syn_dom): [0 1 2 3]\n","x_dp_dom.shape: (161, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","x_syn_dom.shape: (388, 3, 128) | np.unique(y_syn_dom): [0 1 2 3]\n","x_dp_dom.shape: (106, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Training on synthetic data...\n","\tEpoch 10/100 - Train loss: 0.2452 - Val accuracy: 1.0000 - Val loss: 0.2434 - Val F1: 1.0000 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.0292 - Val accuracy: 0.9872 - Val loss: 0.0394 - Val F1: 0.9873 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.0093 - Val accuracy: 1.0000 - Val loss: 0.0125 - Val F1: 1.0000 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.0102 - Val accuracy: 1.0000 - Val loss: 0.0084 - Val F1: 1.0000 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.0067 - Val accuracy: 1.0000 - Val loss: 0.0055 - Val F1: 1.0000 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.0087 - Val accuracy: 1.0000 - Val loss: 0.0057 - Val F1: 1.0000 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0020 - Val accuracy: 1.0000 - Val loss: 0.0049 - Val F1: 1.0000 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0048 - Val accuracy: 1.0000 - Val loss: 0.0039 - Val F1: 1.0000 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0039 - Val accuracy: 1.0000 - Val loss: 0.0034 - Val F1: 1.0000 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0047 - Val accuracy: 1.0000 - Val loss: 0.0026 - Val F1: 1.0000 - LR: 0.00e+00\n","\tBest epoch: 86 - Best val accuracy: 1.0000 - Best val loss: 0.0024 - Best val F1: 1.0000\n","\n","Source class: WAL | Domain: 15 | Accuracy: 0.8679 | Loss: 0.8336 | F1: 0.8346\n","\n","Domain: 16\n","x_syn_dom.shape: (444, 3, 128) | np.unique(y_syn_dom): [0 1 2 3]\n","x_dp_dom.shape: (165, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","x_syn_dom.shape: (388, 3, 128) | np.unique(y_syn_dom): [0 1 2 3]\n","x_dp_dom.shape: (110, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Training on synthetic data...\n","\tEpoch 10/100 - Train loss: 0.2493 - Val accuracy: 0.9487 - Val loss: 0.2891 - Val F1: 0.9503 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.0370 - Val accuracy: 1.0000 - Val loss: 0.0329 - Val F1: 1.0000 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.0115 - Val accuracy: 1.0000 - Val loss: 0.0147 - Val F1: 1.0000 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.0091 - Val accuracy: 1.0000 - Val loss: 0.0064 - Val F1: 1.0000 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.0041 - Val accuracy: 1.0000 - Val loss: 0.0052 - Val F1: 1.0000 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.0041 - Val accuracy: 1.0000 - Val loss: 0.0038 - Val F1: 1.0000 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0017 - Val accuracy: 1.0000 - Val loss: 0.0039 - Val F1: 1.0000 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0021 - Val accuracy: 1.0000 - Val loss: 0.0026 - Val F1: 1.0000 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0059 - Val accuracy: 1.0000 - Val loss: 0.0039 - Val F1: 1.0000 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0031 - Val accuracy: 1.0000 - Val loss: 0.0026 - Val F1: 1.0000 - LR: 0.00e+00\n","\tBest epoch: 92 - Best val accuracy: 1.0000 - Best val loss: 0.0021 - Best val F1: 1.0000\n","\n","Source class: WAL | Domain: 16 | Accuracy: 0.8091 | Loss: 0.7959 | F1: 0.7637\n","\n","Domain: 17\n","x_syn_dom.shape: (444, 3, 128) | np.unique(y_syn_dom): [0 1 2 3]\n","x_dp_dom.shape: (164, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","x_syn_dom.shape: (388, 3, 128) | np.unique(y_syn_dom): [0 1 2 3]\n","x_dp_dom.shape: (109, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Training on synthetic data...\n","\tEpoch 10/100 - Train loss: 0.2352 - Val accuracy: 1.0000 - Val loss: 0.2279 - Val F1: 1.0000 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.0194 - Val accuracy: 1.0000 - Val loss: 0.0173 - Val F1: 1.0000 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.0179 - Val accuracy: 1.0000 - Val loss: 0.0078 - Val F1: 1.0000 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.0087 - Val accuracy: 1.0000 - Val loss: 0.0042 - Val F1: 1.0000 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.0083 - Val accuracy: 1.0000 - Val loss: 0.0037 - Val F1: 1.0000 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.0031 - Val accuracy: 1.0000 - Val loss: 0.0030 - Val F1: 1.0000 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0017 - Val accuracy: 1.0000 - Val loss: 0.0019 - Val F1: 1.0000 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0028 - Val accuracy: 1.0000 - Val loss: 0.0015 - Val F1: 1.0000 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0018 - Val accuracy: 1.0000 - Val loss: 0.0016 - Val F1: 1.0000 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0016 - Val accuracy: 1.0000 - Val loss: 0.0016 - Val F1: 1.0000 - LR: 0.00e+00\n","\tBest epoch: 93 - Best val accuracy: 1.0000 - Best val loss: 0.0013 - Best val F1: 1.0000\n","\n","Source class: WAL | Domain: 17 | Accuracy: 0.7706 | Loss: 1.3255 | F1: 0.7195\n","\n","Domain: 18\n","x_syn_dom.shape: (448, 3, 128) | np.unique(y_syn_dom): [0 1 2 3]\n","x_dp_dom.shape: (166, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","x_syn_dom.shape: (392, 3, 128) | np.unique(y_syn_dom): [0 1 2 3]\n","x_dp_dom.shape: (110, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Training on synthetic data...\n","\tEpoch 10/100 - Train loss: 0.1528 - Val accuracy: 1.0000 - Val loss: 0.1386 - Val F1: 1.0000 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.0201 - Val accuracy: 1.0000 - Val loss: 0.0140 - Val F1: 1.0000 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.0080 - Val accuracy: 1.0000 - Val loss: 0.0050 - Val F1: 1.0000 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.0051 - Val accuracy: 1.0000 - Val loss: 0.0030 - Val F1: 1.0000 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.0038 - Val accuracy: 1.0000 - Val loss: 0.0018 - Val F1: 1.0000 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.0015 - Val accuracy: 1.0000 - Val loss: 0.0014 - Val F1: 1.0000 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0025 - Val accuracy: 1.0000 - Val loss: 0.0013 - Val F1: 1.0000 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0022 - Val accuracy: 1.0000 - Val loss: 0.0010 - Val F1: 1.0000 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0015 - Val accuracy: 1.0000 - Val loss: 0.0009 - Val F1: 1.0000 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0016 - Val accuracy: 1.0000 - Val loss: 0.0007 - Val F1: 1.0000 - LR: 0.00e+00\n","\tBest epoch: 98 - Best val accuracy: 1.0000 - Best val loss: 0.0007 - Best val F1: 1.0000\n","\n","Source class: WAL | Domain: 18 | Accuracy: 0.9273 | Loss: 0.2127 | F1: 0.9227\n","\n","Domain: 19\n","x_syn_dom.shape: (444, 3, 128) | np.unique(y_syn_dom): [0 1 2 3]\n","x_dp_dom.shape: (165, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","x_syn_dom.shape: (388, 3, 128) | np.unique(y_syn_dom): [0 1 2 3]\n","x_dp_dom.shape: (110, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Training on synthetic data...\n","\tEpoch 10/100 - Train loss: 0.1134 - Val accuracy: 1.0000 - Val loss: 0.0910 - Val F1: 1.0000 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.0138 - Val accuracy: 1.0000 - Val loss: 0.0081 - Val F1: 1.0000 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.0058 - Val accuracy: 1.0000 - Val loss: 0.0026 - Val F1: 1.0000 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.0034 - Val accuracy: 1.0000 - Val loss: 0.0012 - Val F1: 1.0000 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.0022 - Val accuracy: 1.0000 - Val loss: 0.0008 - Val F1: 1.0000 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.0019 - Val accuracy: 1.0000 - Val loss: 0.0005 - Val F1: 1.0000 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0022 - Val accuracy: 1.0000 - Val loss: 0.0004 - Val F1: 1.0000 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0012 - Val accuracy: 1.0000 - Val loss: 0.0003 - Val F1: 1.0000 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0034 - Val accuracy: 1.0000 - Val loss: 0.0003 - Val F1: 1.0000 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0007 - Val accuracy: 1.0000 - Val loss: 0.0003 - Val F1: 1.0000 - LR: 0.00e+00\n","\tBest epoch: 89 - Best val accuracy: 1.0000 - Best val loss: 0.0003 - Best val F1: 1.0000\n","\n","Source class: WAL | Domain: 19 | Accuracy: 0.8000 | Loss: 0.6903 | F1: 0.7456\n","\n","Domain: 20\n","x_syn_dom.shape: (444, 3, 128) | np.unique(y_syn_dom): [0 1 2 3]\n","x_dp_dom.shape: (162, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","x_syn_dom.shape: (388, 3, 128) | np.unique(y_syn_dom): [0 1 2 3]\n","x_dp_dom.shape: (107, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Training on synthetic data...\n","\tEpoch 10/100 - Train loss: 0.1133 - Val accuracy: 1.0000 - Val loss: 0.1209 - Val F1: 1.0000 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.0180 - Val accuracy: 1.0000 - Val loss: 0.0192 - Val F1: 1.0000 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.0059 - Val accuracy: 1.0000 - Val loss: 0.0084 - Val F1: 1.0000 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.0043 - Val accuracy: 1.0000 - Val loss: 0.0043 - Val F1: 1.0000 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.0030 - Val accuracy: 1.0000 - Val loss: 0.0035 - Val F1: 1.0000 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.0015 - Val accuracy: 1.0000 - Val loss: 0.0023 - Val F1: 1.0000 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0025 - Val accuracy: 1.0000 - Val loss: 0.0022 - Val F1: 1.0000 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0014 - Val accuracy: 1.0000 - Val loss: 0.0017 - Val F1: 1.0000 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0017 - Val accuracy: 1.0000 - Val loss: 0.0015 - Val F1: 1.0000 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0022 - Val accuracy: 1.0000 - Val loss: 0.0015 - Val F1: 1.0000 - LR: 0.00e+00\n","\tBest epoch: 99 - Best val accuracy: 1.0000 - Best val loss: 0.0012 - Best val F1: 1.0000\n","\n","Source class: WAL | Domain: 20 | Accuracy: 0.7477 | Loss: 1.3652 | F1: 0.6925\n","\n","Domain: 21\n","x_syn_dom.shape: (448, 3, 128) | np.unique(y_syn_dom): [0 1 2 3]\n","x_dp_dom.shape: (159, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","x_syn_dom.shape: (392, 3, 128) | np.unique(y_syn_dom): [0 1 2 3]\n","x_dp_dom.shape: (103, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Training on synthetic data...\n","\tEpoch 10/100 - Train loss: 0.0911 - Val accuracy: 1.0000 - Val loss: 0.0722 - Val F1: 1.0000 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.0103 - Val accuracy: 1.0000 - Val loss: 0.0130 - Val F1: 1.0000 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.0047 - Val accuracy: 1.0000 - Val loss: 0.0054 - Val F1: 1.0000 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.0034 - Val accuracy: 1.0000 - Val loss: 0.0027 - Val F1: 1.0000 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.0018 - Val accuracy: 1.0000 - Val loss: 0.0027 - Val F1: 1.0000 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.0016 - Val accuracy: 1.0000 - Val loss: 0.0013 - Val F1: 1.0000 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0035 - Val accuracy: 1.0000 - Val loss: 0.0018 - Val F1: 1.0000 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0014 - Val accuracy: 1.0000 - Val loss: 0.0013 - Val F1: 1.0000 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0017 - Val accuracy: 1.0000 - Val loss: 0.0009 - Val F1: 1.0000 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0047 - Val accuracy: 1.0000 - Val loss: 0.0008 - Val F1: 1.0000 - LR: 0.00e+00\n","\tBest epoch: 97 - Best val accuracy: 1.0000 - Best val loss: 0.0007 - Best val F1: 1.0000\n","\n","Source class: WAL | Domain: 21 | Accuracy: 0.9806 | Loss: 0.1286 | F1: 0.9805\n","\n","Domain: 22\n","x_syn_dom.shape: (444, 3, 128) | np.unique(y_syn_dom): [0 1 2 3]\n","x_dp_dom.shape: (165, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","x_syn_dom.shape: (388, 3, 128) | np.unique(y_syn_dom): [0 1 2 3]\n","x_dp_dom.shape: (110, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Training on synthetic data...\n","\tEpoch 10/100 - Train loss: 0.1752 - Val accuracy: 1.0000 - Val loss: 0.1609 - Val F1: 1.0000 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.0323 - Val accuracy: 1.0000 - Val loss: 0.0202 - Val F1: 1.0000 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.0154 - Val accuracy: 1.0000 - Val loss: 0.0083 - Val F1: 1.0000 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.0108 - Val accuracy: 1.0000 - Val loss: 0.0069 - Val F1: 1.0000 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.0070 - Val accuracy: 1.0000 - Val loss: 0.0048 - Val F1: 1.0000 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.0042 - Val accuracy: 1.0000 - Val loss: 0.0022 - Val F1: 1.0000 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0139 - Val accuracy: 1.0000 - Val loss: 0.0021 - Val F1: 1.0000 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0021 - Val accuracy: 1.0000 - Val loss: 0.0020 - Val F1: 1.0000 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0040 - Val accuracy: 1.0000 - Val loss: 0.0019 - Val F1: 1.0000 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0051 - Val accuracy: 1.0000 - Val loss: 0.0018 - Val F1: 1.0000 - LR: 0.00e+00\n","\tBest epoch: 91 - Best val accuracy: 1.0000 - Best val loss: 0.0015 - Best val F1: 1.0000\n","\n","Source class: WAL | Domain: 22 | Accuracy: 0.8636 | Loss: 0.5567 | F1: 0.8521\n","\n","Domain: 23\n","x_syn_dom.shape: (448, 3, 128) | np.unique(y_syn_dom): [0 1 2 3]\n","x_dp_dom.shape: (164, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","x_syn_dom.shape: (392, 3, 128) | np.unique(y_syn_dom): [0 1 2 3]\n","x_dp_dom.shape: (108, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Training on synthetic data...\n","\tEpoch 10/100 - Train loss: 0.1465 - Val accuracy: 0.9873 - Val loss: 0.0823 - Val F1: 0.9875 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.0293 - Val accuracy: 1.0000 - Val loss: 0.0270 - Val F1: 1.0000 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.0090 - Val accuracy: 1.0000 - Val loss: 0.0101 - Val F1: 1.0000 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.0073 - Val accuracy: 1.0000 - Val loss: 0.0075 - Val F1: 1.0000 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.0050 - Val accuracy: 1.0000 - Val loss: 0.0042 - Val F1: 1.0000 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.0041 - Val accuracy: 1.0000 - Val loss: 0.0051 - Val F1: 1.0000 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0030 - Val accuracy: 1.0000 - Val loss: 0.0051 - Val F1: 1.0000 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0016 - Val accuracy: 1.0000 - Val loss: 0.0023 - Val F1: 1.0000 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0029 - Val accuracy: 1.0000 - Val loss: 0.0016 - Val F1: 1.0000 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0020 - Val accuracy: 1.0000 - Val loss: 0.0017 - Val F1: 1.0000 - LR: 0.00e+00\n","\tBest epoch: 95 - Best val accuracy: 1.0000 - Best val loss: 0.0015 - Best val F1: 1.0000\n","\n","Source class: WAL | Domain: 23 | Accuracy: 0.8056 | Loss: 1.0360 | F1: 0.7769\n","\n","Domain: 24\n","x_syn_dom.shape: (444, 3, 128) | np.unique(y_syn_dom): [0 1 2 3]\n","x_dp_dom.shape: (162, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","x_syn_dom.shape: (388, 3, 128) | np.unique(y_syn_dom): [0 1 2 3]\n","x_dp_dom.shape: (107, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Training on synthetic data...\n","\tEpoch 10/100 - Train loss: 0.1453 - Val accuracy: 0.9872 - Val loss: 0.1478 - Val F1: 0.9873 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.0252 - Val accuracy: 1.0000 - Val loss: 0.0180 - Val F1: 1.0000 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.0089 - Val accuracy: 1.0000 - Val loss: 0.0072 - Val F1: 1.0000 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.0073 - Val accuracy: 1.0000 - Val loss: 0.0038 - Val F1: 1.0000 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.0050 - Val accuracy: 1.0000 - Val loss: 0.0026 - Val F1: 1.0000 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.0223 - Val accuracy: 1.0000 - Val loss: 0.0019 - Val F1: 1.0000 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0040 - Val accuracy: 1.0000 - Val loss: 0.0017 - Val F1: 1.0000 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0033 - Val accuracy: 1.0000 - Val loss: 0.0011 - Val F1: 1.0000 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0035 - Val accuracy: 1.0000 - Val loss: 0.0015 - Val F1: 1.0000 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0023 - Val accuracy: 1.0000 - Val loss: 0.0009 - Val F1: 1.0000 - LR: 0.00e+00\n","\tBest epoch: 100 - Best val accuracy: 1.0000 - Best val loss: 0.0009 - Best val F1: 1.0000\n","\n","Source class: WAL | Domain: 24 | Accuracy: 0.8037 | Loss: 0.7864 | F1: 0.7676\n","\n","Domain: 25\n","x_syn_dom.shape: (448, 3, 128) | np.unique(y_syn_dom): [0 1 2 3]\n","x_dp_dom.shape: (166, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","x_syn_dom.shape: (392, 3, 128) | np.unique(y_syn_dom): [0 1 2 3]\n","x_dp_dom.shape: (110, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Training on synthetic data...\n","\tEpoch 10/100 - Train loss: 0.1368 - Val accuracy: 1.0000 - Val loss: 0.1099 - Val F1: 1.0000 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.0150 - Val accuracy: 1.0000 - Val loss: 0.0106 - Val F1: 1.0000 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.0058 - Val accuracy: 1.0000 - Val loss: 0.0038 - Val F1: 1.0000 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.0045 - Val accuracy: 1.0000 - Val loss: 0.0022 - Val F1: 1.0000 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.0074 - Val accuracy: 1.0000 - Val loss: 0.0013 - Val F1: 1.0000 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.0018 - Val accuracy: 1.0000 - Val loss: 0.0008 - Val F1: 1.0000 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0018 - Val accuracy: 1.0000 - Val loss: 0.0011 - Val F1: 1.0000 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0018 - Val accuracy: 1.0000 - Val loss: 0.0006 - Val F1: 1.0000 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0013 - Val accuracy: 1.0000 - Val loss: 0.0005 - Val F1: 1.0000 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0041 - Val accuracy: 1.0000 - Val loss: 0.0006 - Val F1: 1.0000 - LR: 0.00e+00\n","\tBest epoch: 90 - Best val accuracy: 1.0000 - Best val loss: 0.0005 - Best val F1: 1.0000\n","\n","Source class: WAL | Domain: 25 | Accuracy: 0.9000 | Loss: 0.3683 | F1: 0.8965\n","\n","Domain: 26\n","x_syn_dom.shape: (444, 3, 128) | np.unique(y_syn_dom): [0 1 2 3]\n","x_dp_dom.shape: (153, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","x_syn_dom.shape: (388, 3, 128) | np.unique(y_syn_dom): [0 1 2 3]\n","x_dp_dom.shape: (98, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Training on synthetic data...\n","\tEpoch 10/100 - Train loss: 0.1431 - Val accuracy: 1.0000 - Val loss: 0.0913 - Val F1: 1.0000 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.0269 - Val accuracy: 1.0000 - Val loss: 0.0143 - Val F1: 1.0000 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.0132 - Val accuracy: 1.0000 - Val loss: 0.0056 - Val F1: 1.0000 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.0242 - Val accuracy: 1.0000 - Val loss: 0.0031 - Val F1: 1.0000 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.0046 - Val accuracy: 1.0000 - Val loss: 0.0021 - Val F1: 1.0000 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.0025 - Val accuracy: 1.0000 - Val loss: 0.0014 - Val F1: 1.0000 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0016 - Val accuracy: 1.0000 - Val loss: 0.0013 - Val F1: 1.0000 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0032 - Val accuracy: 1.0000 - Val loss: 0.0013 - Val F1: 1.0000 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0039 - Val accuracy: 1.0000 - Val loss: 0.0012 - Val F1: 1.0000 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0017 - Val accuracy: 1.0000 - Val loss: 0.0010 - Val F1: 1.0000 - LR: 0.00e+00\n","\tBest epoch: 85 - Best val accuracy: 1.0000 - Best val loss: 0.0009 - Best val F1: 1.0000\n","\n","Source class: WAL | Domain: 26 | Accuracy: 0.7449 | Loss: 1.8156 | F1: 0.6930\n","\n","Domain: 27\n","x_syn_dom.shape: (444, 3, 128) | np.unique(y_syn_dom): [0 1 2 3]\n","x_dp_dom.shape: (165, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","x_syn_dom.shape: (388, 3, 128) | np.unique(y_syn_dom): [0 1 2 3]\n","x_dp_dom.shape: (110, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Training on synthetic data...\n","\tEpoch 10/100 - Train loss: 0.1671 - Val accuracy: 0.9615 - Val loss: 0.1702 - Val F1: 0.9624 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.0288 - Val accuracy: 1.0000 - Val loss: 0.0268 - Val F1: 1.0000 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.0081 - Val accuracy: 1.0000 - Val loss: 0.0072 - Val F1: 1.0000 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.0045 - Val accuracy: 1.0000 - Val loss: 0.0076 - Val F1: 1.0000 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.0064 - Val accuracy: 1.0000 - Val loss: 0.0055 - Val F1: 1.0000 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.0058 - Val accuracy: 1.0000 - Val loss: 0.0023 - Val F1: 1.0000 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0022 - Val accuracy: 1.0000 - Val loss: 0.0024 - Val F1: 1.0000 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0019 - Val accuracy: 1.0000 - Val loss: 0.0022 - Val F1: 1.0000 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0017 - Val accuracy: 1.0000 - Val loss: 0.0013 - Val F1: 1.0000 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0020 - Val accuracy: 1.0000 - Val loss: 0.0011 - Val F1: 1.0000 - LR: 0.00e+00\n","\tBest epoch: 100 - Best val accuracy: 1.0000 - Best val loss: 0.0011 - Best val F1: 1.0000\n","\n","Source class: WAL | Domain: 27 | Accuracy: 0.5636 | Loss: 1.4246 | F1: 0.4510\n","\n","Domain: 28\n","x_syn_dom.shape: (444, 3, 128) | np.unique(y_syn_dom): [0 1 2 3]\n","x_dp_dom.shape: (153, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","x_syn_dom.shape: (388, 3, 128) | np.unique(y_syn_dom): [0 1 2 3]\n","x_dp_dom.shape: (98, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Training on synthetic data...\n","\tEpoch 10/100 - Train loss: 0.1088 - Val accuracy: 1.0000 - Val loss: 0.0889 - Val F1: 1.0000 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.0112 - Val accuracy: 1.0000 - Val loss: 0.0098 - Val F1: 1.0000 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.0053 - Val accuracy: 1.0000 - Val loss: 0.0039 - Val F1: 1.0000 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.0039 - Val accuracy: 1.0000 - Val loss: 0.0023 - Val F1: 1.0000 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.0020 - Val accuracy: 1.0000 - Val loss: 0.0014 - Val F1: 1.0000 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.0029 - Val accuracy: 1.0000 - Val loss: 0.0010 - Val F1: 1.0000 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0066 - Val accuracy: 1.0000 - Val loss: 0.0011 - Val F1: 1.0000 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0010 - Val accuracy: 1.0000 - Val loss: 0.0008 - Val F1: 1.0000 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0014 - Val accuracy: 1.0000 - Val loss: 0.0008 - Val F1: 1.0000 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0011 - Val accuracy: 1.0000 - Val loss: 0.0006 - Val F1: 1.0000 - LR: 0.00e+00\n","\tBest epoch: 100 - Best val accuracy: 1.0000 - Best val loss: 0.0006 - Best val F1: 1.0000\n","\n","Source class: WAL | Domain: 28 | Accuracy: 0.8776 | Loss: 1.1269 | F1: 0.8346\n","\n","Domain: 29\n","x_syn_dom.shape: (444, 3, 128) | np.unique(y_syn_dom): [0 1 2 3]\n","x_dp_dom.shape: (153, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","x_syn_dom.shape: (388, 3, 128) | np.unique(y_syn_dom): [0 1 2 3]\n","x_dp_dom.shape: (98, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Training on synthetic data...\n","\tEpoch 10/100 - Train loss: 0.1330 - Val accuracy: 1.0000 - Val loss: 0.1131 - Val F1: 1.0000 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.0212 - Val accuracy: 1.0000 - Val loss: 0.0192 - Val F1: 1.0000 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.0141 - Val accuracy: 1.0000 - Val loss: 0.0099 - Val F1: 1.0000 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.0055 - Val accuracy: 1.0000 - Val loss: 0.0052 - Val F1: 1.0000 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.0043 - Val accuracy: 1.0000 - Val loss: 0.0028 - Val F1: 1.0000 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.0025 - Val accuracy: 1.0000 - Val loss: 0.0042 - Val F1: 1.0000 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0018 - Val accuracy: 1.0000 - Val loss: 0.0026 - Val F1: 1.0000 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0019 - Val accuracy: 1.0000 - Val loss: 0.0018 - Val F1: 1.0000 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0017 - Val accuracy: 1.0000 - Val loss: 0.0023 - Val F1: 1.0000 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0029 - Val accuracy: 1.0000 - Val loss: 0.0024 - Val F1: 1.0000 - LR: 0.00e+00\n","\tBest epoch: 89 - Best val accuracy: 1.0000 - Best val loss: 0.0016 - Best val F1: 1.0000\n","\n","Source class: WAL | Domain: 29 | Accuracy: 0.9490 | Loss: 0.2331 | F1: 0.9453\n","\n","Domain: 30\n","x_syn_dom.shape: (444, 3, 128) | np.unique(y_syn_dom): [0 1 2 3]\n","x_dp_dom.shape: (161, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","x_syn_dom.shape: (388, 3, 128) | np.unique(y_syn_dom): [0 1 2 3]\n","x_dp_dom.shape: (106, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Training on synthetic data...\n","\tEpoch 10/100 - Train loss: 0.2273 - Val accuracy: 0.9359 - Val loss: 0.2413 - Val F1: 0.9357 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.0501 - Val accuracy: 1.0000 - Val loss: 0.0526 - Val F1: 1.0000 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.0164 - Val accuracy: 1.0000 - Val loss: 0.0302 - Val F1: 1.0000 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.0123 - Val accuracy: 1.0000 - Val loss: 0.0185 - Val F1: 1.0000 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.0063 - Val accuracy: 1.0000 - Val loss: 0.0078 - Val F1: 1.0000 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.0058 - Val accuracy: 1.0000 - Val loss: 0.0128 - Val F1: 1.0000 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0030 - Val accuracy: 1.0000 - Val loss: 0.0083 - Val F1: 1.0000 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0098 - Val accuracy: 1.0000 - Val loss: 0.0064 - Val F1: 1.0000 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0034 - Val accuracy: 1.0000 - Val loss: 0.0043 - Val F1: 1.0000 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0057 - Val accuracy: 1.0000 - Val loss: 0.0048 - Val F1: 1.0000 - LR: 0.00e+00\n","\tBest epoch: 91 - Best val accuracy: 1.0000 - Best val loss: 0.0036 - Best val F1: 1.0000\n","\n","Source class: WAL | Domain: 30 | Accuracy: 0.8113 | Loss: 1.3795 | F1: 0.7575\n","\n","Domain: 31\n","x_syn_dom.shape: (444, 3, 128) | np.unique(y_syn_dom): [0 1 2 3]\n","x_dp_dom.shape: (154, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","x_syn_dom.shape: (388, 3, 128) | np.unique(y_syn_dom): [0 1 2 3]\n","x_dp_dom.shape: (99, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Training on synthetic data...\n","\tEpoch 10/100 - Train loss: 0.0412 - Val accuracy: 1.0000 - Val loss: 0.0217 - Val F1: 1.0000 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.0123 - Val accuracy: 1.0000 - Val loss: 0.0105 - Val F1: 1.0000 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.0060 - Val accuracy: 1.0000 - Val loss: 0.0037 - Val F1: 1.0000 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.0092 - Val accuracy: 1.0000 - Val loss: 0.0031 - Val F1: 1.0000 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.0046 - Val accuracy: 1.0000 - Val loss: 0.0031 - Val F1: 1.0000 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.0016 - Val accuracy: 1.0000 - Val loss: 0.0018 - Val F1: 1.0000 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0034 - Val accuracy: 1.0000 - Val loss: 0.0012 - Val F1: 1.0000 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0008 - Val accuracy: 1.0000 - Val loss: 0.0009 - Val F1: 1.0000 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0018 - Val accuracy: 1.0000 - Val loss: 0.0017 - Val F1: 1.0000 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0012 - Val accuracy: 1.0000 - Val loss: 0.0009 - Val F1: 1.0000 - LR: 0.00e+00\n","\tBest epoch: 87 - Best val accuracy: 1.0000 - Best val loss: 0.0009 - Best val F1: 1.0000\n","\n","Source class: WAL | Domain: 31 | Accuracy: 0.8485 | Loss: 1.0615 | F1: 0.7799\n","\n","Domain: 32\n","x_syn_dom.shape: (444, 3, 128) | np.unique(y_syn_dom): [0 1 2 3]\n","x_dp_dom.shape: (163, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","x_syn_dom.shape: (388, 3, 128) | np.unique(y_syn_dom): [0 1 2 3]\n","x_dp_dom.shape: (108, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Training on synthetic data...\n","\tEpoch 10/100 - Train loss: 0.1522 - Val accuracy: 0.9872 - Val loss: 0.1454 - Val F1: 0.9870 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.0321 - Val accuracy: 0.9872 - Val loss: 0.0527 - Val F1: 0.9870 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.0088 - Val accuracy: 0.9872 - Val loss: 0.0577 - Val F1: 0.9870 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.0076 - Val accuracy: 0.9872 - Val loss: 0.0591 - Val F1: 0.9870 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.0063 - Val accuracy: 0.9872 - Val loss: 0.0476 - Val F1: 0.9870 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.0129 - Val accuracy: 0.9872 - Val loss: 0.0506 - Val F1: 0.9870 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0023 - Val accuracy: 0.9872 - Val loss: 0.0530 - Val F1: 0.9870 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0028 - Val accuracy: 0.9872 - Val loss: 0.0417 - Val F1: 0.9870 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0031 - Val accuracy: 0.9872 - Val loss: 0.0531 - Val F1: 0.9870 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0013 - Val accuracy: 0.9872 - Val loss: 0.0477 - Val F1: 0.9870 - LR: 0.00e+00\n","\tBest epoch: 49 - Best val accuracy: 0.9872 - Best val loss: 0.0410 - Best val F1: 0.9870\n","\n","Source class: WAL | Domain: 32 | Accuracy: 0.7963 | Loss: 2.4354 | F1: 0.7487\n","\n","Domain: 33\n","x_syn_dom.shape: (448, 3, 128) | np.unique(y_syn_dom): [0 1 2 3]\n","x_dp_dom.shape: (156, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","x_syn_dom.shape: (392, 3, 128) | np.unique(y_syn_dom): [0 1 2 3]\n","x_dp_dom.shape: (100, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Training on synthetic data...\n","\tEpoch 10/100 - Train loss: 0.1154 - Val accuracy: 1.0000 - Val loss: 0.0573 - Val F1: 1.0000 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.0170 - Val accuracy: 1.0000 - Val loss: 0.0056 - Val F1: 1.0000 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.0067 - Val accuracy: 1.0000 - Val loss: 0.0025 - Val F1: 1.0000 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.0028 - Val accuracy: 1.0000 - Val loss: 0.0013 - Val F1: 1.0000 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.0020 - Val accuracy: 1.0000 - Val loss: 0.0008 - Val F1: 1.0000 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.0018 - Val accuracy: 1.0000 - Val loss: 0.0007 - Val F1: 1.0000 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0026 - Val accuracy: 1.0000 - Val loss: 0.0005 - Val F1: 1.0000 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0018 - Val accuracy: 1.0000 - Val loss: 0.0006 - Val F1: 1.0000 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0028 - Val accuracy: 1.0000 - Val loss: 0.0004 - Val F1: 1.0000 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0007 - Val accuracy: 1.0000 - Val loss: 0.0004 - Val F1: 1.0000 - LR: 0.00e+00\n","\tBest epoch: 93 - Best val accuracy: 1.0000 - Best val loss: 0.0004 - Best val F1: 1.0000\n","\n","Source class: WAL | Domain: 33 | Accuracy: 0.8500 | Loss: 0.5772 | F1: 0.8284\n","\n","Domain: 34\n","x_syn_dom.shape: (448, 3, 128) | np.unique(y_syn_dom): [0 1 2 3]\n","x_dp_dom.shape: (161, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","x_syn_dom.shape: (392, 3, 128) | np.unique(y_syn_dom): [0 1 2 3]\n","x_dp_dom.shape: (105, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Training on synthetic data...\n","\tEpoch 10/100 - Train loss: 0.0471 - Val accuracy: 0.9873 - Val loss: 0.0413 - Val F1: 0.9873 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.0109 - Val accuracy: 1.0000 - Val loss: 0.0111 - Val F1: 1.0000 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.0073 - Val accuracy: 1.0000 - Val loss: 0.0041 - Val F1: 1.0000 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.0042 - Val accuracy: 1.0000 - Val loss: 0.0034 - Val F1: 1.0000 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.0022 - Val accuracy: 1.0000 - Val loss: 0.0027 - Val F1: 1.0000 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.0039 - Val accuracy: 1.0000 - Val loss: 0.0042 - Val F1: 1.0000 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0010 - Val accuracy: 1.0000 - Val loss: 0.0014 - Val F1: 1.0000 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0022 - Val accuracy: 1.0000 - Val loss: 0.0013 - Val F1: 1.0000 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0011 - Val accuracy: 1.0000 - Val loss: 0.0012 - Val F1: 1.0000 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0014 - Val accuracy: 1.0000 - Val loss: 0.0013 - Val F1: 1.0000 - LR: 0.00e+00\n","\tBest epoch: 98 - Best val accuracy: 1.0000 - Best val loss: 0.0012 - Best val F1: 1.0000\n","\n","Source class: WAL | Domain: 34 | Accuracy: 0.7619 | Loss: 1.5865 | F1: 0.6848\n","\n","Domain: 35\n","x_syn_dom.shape: (444, 3, 128) | np.unique(y_syn_dom): [0 1 2 3]\n","x_dp_dom.shape: (159, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","x_syn_dom.shape: (388, 3, 128) | np.unique(y_syn_dom): [0 1 2 3]\n","x_dp_dom.shape: (104, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Training on synthetic data...\n","\tEpoch 10/100 - Train loss: 0.2009 - Val accuracy: 0.9744 - Val loss: 0.1851 - Val F1: 0.9736 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.0186 - Val accuracy: 1.0000 - Val loss: 0.0108 - Val F1: 1.0000 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.0045 - Val accuracy: 1.0000 - Val loss: 0.0033 - Val F1: 1.0000 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.0031 - Val accuracy: 1.0000 - Val loss: 0.0018 - Val F1: 1.0000 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.0018 - Val accuracy: 1.0000 - Val loss: 0.0013 - Val F1: 1.0000 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.0016 - Val accuracy: 1.0000 - Val loss: 0.0009 - Val F1: 1.0000 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0027 - Val accuracy: 1.0000 - Val loss: 0.0008 - Val F1: 1.0000 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0013 - Val accuracy: 1.0000 - Val loss: 0.0005 - Val F1: 1.0000 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0025 - Val accuracy: 1.0000 - Val loss: 0.0005 - Val F1: 1.0000 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0008 - Val accuracy: 1.0000 - Val loss: 0.0005 - Val F1: 1.0000 - LR: 0.00e+00\n","\tBest epoch: 97 - Best val accuracy: 1.0000 - Best val loss: 0.0005 - Best val F1: 1.0000\n","\n","Source class: WAL | Domain: 35 | Accuracy: 0.8077 | Loss: 1.8116 | F1: 0.7261\n","\n","Domain: 36\n","x_syn_dom.shape: (448, 3, 128) | np.unique(y_syn_dom): [0 1 2 3]\n","x_dp_dom.shape: (155, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","x_syn_dom.shape: (392, 3, 128) | np.unique(y_syn_dom): [0 1 2 3]\n","x_dp_dom.shape: (99, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Training on synthetic data...\n","\tEpoch 10/100 - Train loss: 0.1278 - Val accuracy: 0.9747 - Val loss: 0.1248 - Val F1: 0.9752 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.0156 - Val accuracy: 1.0000 - Val loss: 0.0135 - Val F1: 1.0000 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.0068 - Val accuracy: 1.0000 - Val loss: 0.0035 - Val F1: 1.0000 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.0042 - Val accuracy: 1.0000 - Val loss: 0.0020 - Val F1: 1.0000 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.0022 - Val accuracy: 1.0000 - Val loss: 0.0015 - Val F1: 1.0000 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.0018 - Val accuracy: 1.0000 - Val loss: 0.0012 - Val F1: 1.0000 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0018 - Val accuracy: 1.0000 - Val loss: 0.0012 - Val F1: 1.0000 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0011 - Val accuracy: 1.0000 - Val loss: 0.0013 - Val F1: 1.0000 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0062 - Val accuracy: 1.0000 - Val loss: 0.0007 - Val F1: 1.0000 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0018 - Val accuracy: 1.0000 - Val loss: 0.0007 - Val F1: 1.0000 - LR: 0.00e+00\n","\tBest epoch: 72 - Best val accuracy: 1.0000 - Best val loss: 0.0006 - Best val F1: 1.0000\n","\n","Source class: WAL | Domain: 36 | Accuracy: 0.8485 | Loss: 0.8783 | F1: 0.7817\n","\n","Domain: 37\n","x_syn_dom.shape: (448, 3, 128) | np.unique(y_syn_dom): [0 1 2 3]\n","x_dp_dom.shape: (154, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","x_syn_dom.shape: (392, 3, 128) | np.unique(y_syn_dom): [0 1 2 3]\n","x_dp_dom.shape: (98, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Training on synthetic data...\n","\tEpoch 10/100 - Train loss: 0.2831 - Val accuracy: 0.8861 - Val loss: 0.2868 - Val F1: 0.8546 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.0355 - Val accuracy: 1.0000 - Val loss: 0.0449 - Val F1: 1.0000 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.0106 - Val accuracy: 1.0000 - Val loss: 0.0150 - Val F1: 1.0000 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.0068 - Val accuracy: 1.0000 - Val loss: 0.0099 - Val F1: 1.0000 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.0033 - Val accuracy: 1.0000 - Val loss: 0.0056 - Val F1: 1.0000 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.0036 - Val accuracy: 1.0000 - Val loss: 0.0046 - Val F1: 1.0000 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0038 - Val accuracy: 1.0000 - Val loss: 0.0034 - Val F1: 1.0000 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0016 - Val accuracy: 1.0000 - Val loss: 0.0038 - Val F1: 1.0000 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0015 - Val accuracy: 1.0000 - Val loss: 0.0031 - Val F1: 1.0000 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0022 - Val accuracy: 1.0000 - Val loss: 0.0027 - Val F1: 1.0000 - LR: 0.00e+00\n","\tBest epoch: 99 - Best val accuracy: 1.0000 - Best val loss: 0.0026 - Best val F1: 1.0000\n","\n","Source class: WAL | Domain: 37 | Accuracy: 0.8980 | Loss: 0.4497 | F1: 0.8722\n","\n","Domain: 38\n","x_syn_dom.shape: (444, 3, 128) | np.unique(y_syn_dom): [0 1 2 3]\n","x_dp_dom.shape: (158, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","x_syn_dom.shape: (388, 3, 128) | np.unique(y_syn_dom): [0 1 2 3]\n","x_dp_dom.shape: (103, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Training on synthetic data...\n","\tEpoch 10/100 - Train loss: 0.0716 - Val accuracy: 0.9872 - Val loss: 0.0557 - Val F1: 0.9872 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.0189 - Val accuracy: 0.9872 - Val loss: 0.0192 - Val F1: 0.9872 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.0121 - Val accuracy: 0.9872 - Val loss: 0.0199 - Val F1: 0.9872 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.0096 - Val accuracy: 0.9872 - Val loss: 0.0164 - Val F1: 0.9872 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.0049 - Val accuracy: 1.0000 - Val loss: 0.0086 - Val F1: 1.0000 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.0061 - Val accuracy: 1.0000 - Val loss: 0.0044 - Val F1: 1.0000 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0030 - Val accuracy: 1.0000 - Val loss: 0.0045 - Val F1: 1.0000 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0023 - Val accuracy: 1.0000 - Val loss: 0.0059 - Val F1: 1.0000 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0038 - Val accuracy: 1.0000 - Val loss: 0.0052 - Val F1: 1.0000 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0097 - Val accuracy: 1.0000 - Val loss: 0.0049 - Val F1: 1.0000 - LR: 0.00e+00\n","\tBest epoch: 94 - Best val accuracy: 1.0000 - Best val loss: 0.0039 - Best val F1: 1.0000\n","\n","Source class: WAL | Domain: 38 | Accuracy: 0.7087 | Loss: 2.4216 | F1: 0.7084\n","\n","Domain: 39\n","x_syn_dom.shape: (444, 3, 128) | np.unique(y_syn_dom): [0 1 2 3]\n","x_dp_dom.shape: (165, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","x_syn_dom.shape: (388, 3, 128) | np.unique(y_syn_dom): [0 1 2 3]\n","x_dp_dom.shape: (110, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Training on synthetic data...\n","\tEpoch 10/100 - Train loss: 0.2170 - Val accuracy: 1.0000 - Val loss: 0.1674 - Val F1: 1.0000 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.0186 - Val accuracy: 1.0000 - Val loss: 0.0147 - Val F1: 1.0000 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.0085 - Val accuracy: 1.0000 - Val loss: 0.0060 - Val F1: 1.0000 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.0031 - Val accuracy: 1.0000 - Val loss: 0.0035 - Val F1: 1.0000 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.0024 - Val accuracy: 1.0000 - Val loss: 0.0023 - Val F1: 1.0000 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.0022 - Val accuracy: 1.0000 - Val loss: 0.0016 - Val F1: 1.0000 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0015 - Val accuracy: 1.0000 - Val loss: 0.0013 - Val F1: 1.0000 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0013 - Val accuracy: 1.0000 - Val loss: 0.0014 - Val F1: 1.0000 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0014 - Val accuracy: 1.0000 - Val loss: 0.0012 - Val F1: 1.0000 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0018 - Val accuracy: 1.0000 - Val loss: 0.0012 - Val F1: 1.0000 - LR: 0.00e+00\n","\tBest epoch: 98 - Best val accuracy: 1.0000 - Best val loss: 0.0010 - Best val F1: 1.0000\n","\n","Source class: WAL | Domain: 39 | Accuracy: 0.7636 | Loss: 1.7700 | F1: 0.7192\n","\n","Domain: 40\n","x_syn_dom.shape: (444, 3, 128) | np.unique(y_syn_dom): [0 1 2 3]\n","x_dp_dom.shape: (155, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","x_syn_dom.shape: (388, 3, 128) | np.unique(y_syn_dom): [0 1 2 3]\n","x_dp_dom.shape: (100, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Training on synthetic data...\n","\tEpoch 10/100 - Train loss: 0.1130 - Val accuracy: 1.0000 - Val loss: 0.0930 - Val F1: 1.0000 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.0177 - Val accuracy: 1.0000 - Val loss: 0.0169 - Val F1: 1.0000 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.0082 - Val accuracy: 1.0000 - Val loss: 0.0057 - Val F1: 1.0000 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.0037 - Val accuracy: 1.0000 - Val loss: 0.0033 - Val F1: 1.0000 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.0026 - Val accuracy: 1.0000 - Val loss: 0.0028 - Val F1: 1.0000 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.0019 - Val accuracy: 1.0000 - Val loss: 0.0017 - Val F1: 1.0000 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0014 - Val accuracy: 1.0000 - Val loss: 0.0015 - Val F1: 1.0000 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0683 - Val accuracy: 1.0000 - Val loss: 0.0014 - Val F1: 1.0000 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0017 - Val accuracy: 1.0000 - Val loss: 0.0015 - Val F1: 1.0000 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0013 - Val accuracy: 1.0000 - Val loss: 0.0014 - Val F1: 1.0000 - LR: 0.00e+00\n","\tBest epoch: 79 - Best val accuracy: 1.0000 - Best val loss: 0.0011 - Best val F1: 1.0000\n","\n","Source class: WAL | Domain: 40 | Accuracy: 0.7900 | Loss: 0.7666 | F1: 0.7339\n","\n","Domain: 41\n","x_syn_dom.shape: (444, 3, 128) | np.unique(y_syn_dom): [0 1 2 3]\n","x_dp_dom.shape: (156, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","x_syn_dom.shape: (388, 3, 128) | np.unique(y_syn_dom): [0 1 2 3]\n","x_dp_dom.shape: (101, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Training on synthetic data...\n","\tEpoch 10/100 - Train loss: 0.1151 - Val accuracy: 0.9872 - Val loss: 0.0707 - Val F1: 0.9872 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.0392 - Val accuracy: 0.9872 - Val loss: 0.0333 - Val F1: 0.9872 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.0226 - Val accuracy: 0.9872 - Val loss: 0.0278 - Val F1: 0.9872 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.0138 - Val accuracy: 0.9872 - Val loss: 0.0270 - Val F1: 0.9872 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.0078 - Val accuracy: 0.9872 - Val loss: 0.0275 - Val F1: 0.9872 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.0077 - Val accuracy: 0.9872 - Val loss: 0.0242 - Val F1: 0.9872 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0048 - Val accuracy: 0.9872 - Val loss: 0.0317 - Val F1: 0.9872 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0137 - Val accuracy: 0.9872 - Val loss: 0.0358 - Val F1: 0.9872 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0041 - Val accuracy: 0.9872 - Val loss: 0.0297 - Val F1: 0.9872 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0039 - Val accuracy: 0.9872 - Val loss: 0.0317 - Val F1: 0.9872 - LR: 0.00e+00\n","\tBest epoch: 62 - Best val accuracy: 0.9872 - Best val loss: 0.0202 - Best val F1: 0.9872\n","\n","Source class: WAL | Domain: 41 | Accuracy: 0.7723 | Loss: 2.1295 | F1: 0.7200\n","\n","Domain: 42\n","x_syn_dom.shape: (448, 3, 128) | np.unique(y_syn_dom): [0 1 2 3]\n","x_dp_dom.shape: (158, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","x_syn_dom.shape: (392, 3, 128) | np.unique(y_syn_dom): [0 1 2 3]\n","x_dp_dom.shape: (102, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Training on synthetic data...\n","\tEpoch 10/100 - Train loss: 0.1539 - Val accuracy: 1.0000 - Val loss: 0.1731 - Val F1: 1.0000 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.0146 - Val accuracy: 1.0000 - Val loss: 0.0150 - Val F1: 1.0000 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.0052 - Val accuracy: 1.0000 - Val loss: 0.0067 - Val F1: 1.0000 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.0057 - Val accuracy: 1.0000 - Val loss: 0.0035 - Val F1: 1.0000 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.0033 - Val accuracy: 1.0000 - Val loss: 0.0022 - Val F1: 1.0000 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.0025 - Val accuracy: 1.0000 - Val loss: 0.0015 - Val F1: 1.0000 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0024 - Val accuracy: 1.0000 - Val loss: 0.0017 - Val F1: 1.0000 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0015 - Val accuracy: 1.0000 - Val loss: 0.0012 - Val F1: 1.0000 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0027 - Val accuracy: 1.0000 - Val loss: 0.0011 - Val F1: 1.0000 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0045 - Val accuracy: 1.0000 - Val loss: 0.0011 - Val F1: 1.0000 - LR: 0.00e+00\n","\tBest epoch: 99 - Best val accuracy: 1.0000 - Best val loss: 0.0009 - Best val F1: 1.0000\n","\n","Source class: WAL | Domain: 42 | Accuracy: 0.6471 | Loss: 1.5655 | F1: 0.5160\n","\n","Domain: 43\n","x_syn_dom.shape: (444, 3, 128) | np.unique(y_syn_dom): [0 1 2 3]\n","x_dp_dom.shape: (153, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","x_syn_dom.shape: (388, 3, 128) | np.unique(y_syn_dom): [0 1 2 3]\n","x_dp_dom.shape: (98, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Training on synthetic data...\n","\tEpoch 10/100 - Train loss: 0.0337 - Val accuracy: 0.9872 - Val loss: 0.0384 - Val F1: 0.9872 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.0093 - Val accuracy: 0.9872 - Val loss: 0.0350 - Val F1: 0.9872 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.0037 - Val accuracy: 0.9872 - Val loss: 0.0458 - Val F1: 0.9872 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.0026 - Val accuracy: 0.9872 - Val loss: 0.0440 - Val F1: 0.9872 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.0020 - Val accuracy: 0.9872 - Val loss: 0.0416 - Val F1: 0.9872 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.0024 - Val accuracy: 0.9872 - Val loss: 0.0451 - Val F1: 0.9872 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0030 - Val accuracy: 0.9872 - Val loss: 0.0504 - Val F1: 0.9872 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0013 - Val accuracy: 0.9872 - Val loss: 0.0492 - Val F1: 0.9872 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0018 - Val accuracy: 0.9872 - Val loss: 0.0498 - Val F1: 0.9872 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0022 - Val accuracy: 0.9872 - Val loss: 0.0540 - Val F1: 0.9872 - LR: 0.00e+00\n","\tBest epoch: 17 - Best val accuracy: 0.9872 - Best val loss: 0.0211 - Best val F1: 0.9872\n","\n","Source class: WAL | Domain: 43 | Accuracy: 0.8265 | Loss: 1.0259 | F1: 0.7837\n","\n","Domain: 44\n","x_syn_dom.shape: (444, 3, 128) | np.unique(y_syn_dom): [0 1 2 3]\n","x_dp_dom.shape: (153, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","x_syn_dom.shape: (388, 3, 128) | np.unique(y_syn_dom): [0 1 2 3]\n","x_dp_dom.shape: (98, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Training on synthetic data...\n","\tEpoch 10/100 - Train loss: 0.1315 - Val accuracy: 1.0000 - Val loss: 0.1103 - Val F1: 1.0000 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.0299 - Val accuracy: 1.0000 - Val loss: 0.0138 - Val F1: 1.0000 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.0104 - Val accuracy: 1.0000 - Val loss: 0.0058 - Val F1: 1.0000 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.0040 - Val accuracy: 1.0000 - Val loss: 0.0037 - Val F1: 1.0000 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.0067 - Val accuracy: 1.0000 - Val loss: 0.0030 - Val F1: 1.0000 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.0035 - Val accuracy: 1.0000 - Val loss: 0.0024 - Val F1: 1.0000 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0027 - Val accuracy: 1.0000 - Val loss: 0.0025 - Val F1: 1.0000 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0018 - Val accuracy: 1.0000 - Val loss: 0.0020 - Val F1: 1.0000 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0014 - Val accuracy: 1.0000 - Val loss: 0.0015 - Val F1: 1.0000 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0023 - Val accuracy: 1.0000 - Val loss: 0.0014 - Val F1: 1.0000 - LR: 0.00e+00\n","\tBest epoch: 87 - Best val accuracy: 1.0000 - Best val loss: 0.0013 - Best val F1: 1.0000\n","\n","Source class: WAL | Domain: 44 | Accuracy: 0.8878 | Loss: 0.4457 | F1: 0.8489\n","\n","Domain: 45\n","x_syn_dom.shape: (444, 3, 128) | np.unique(y_syn_dom): [0 1 2 3]\n","x_dp_dom.shape: (163, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","x_syn_dom.shape: (388, 3, 128) | np.unique(y_syn_dom): [0 1 2 3]\n","x_dp_dom.shape: (108, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Training on synthetic data...\n","\tEpoch 10/100 - Train loss: 0.1027 - Val accuracy: 1.0000 - Val loss: 0.0603 - Val F1: 1.0000 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.0167 - Val accuracy: 1.0000 - Val loss: 0.0083 - Val F1: 1.0000 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.0064 - Val accuracy: 1.0000 - Val loss: 0.0040 - Val F1: 1.0000 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.0085 - Val accuracy: 1.0000 - Val loss: 0.0017 - Val F1: 1.0000 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.0048 - Val accuracy: 1.0000 - Val loss: 0.0012 - Val F1: 1.0000 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.0032 - Val accuracy: 1.0000 - Val loss: 0.0009 - Val F1: 1.0000 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0015 - Val accuracy: 1.0000 - Val loss: 0.0008 - Val F1: 1.0000 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0013 - Val accuracy: 1.0000 - Val loss: 0.0006 - Val F1: 1.0000 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0015 - Val accuracy: 1.0000 - Val loss: 0.0006 - Val F1: 1.0000 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0035 - Val accuracy: 1.0000 - Val loss: 0.0006 - Val F1: 1.0000 - LR: 0.00e+00\n","\tBest epoch: 95 - Best val accuracy: 1.0000 - Best val loss: 0.0005 - Best val F1: 1.0000\n","\n","Source class: WAL | Domain: 45 | Accuracy: 0.8796 | Loss: 0.4526 | F1: 0.8503\n","\n","Domain: 46\n","x_syn_dom.shape: (448, 3, 128) | np.unique(y_syn_dom): [0 1 2 3]\n","x_dp_dom.shape: (160, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","x_syn_dom.shape: (392, 3, 128) | np.unique(y_syn_dom): [0 1 2 3]\n","x_dp_dom.shape: (104, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Training on synthetic data...\n","\tEpoch 10/100 - Train loss: 0.1194 - Val accuracy: 1.0000 - Val loss: 0.1129 - Val F1: 1.0000 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.0145 - Val accuracy: 1.0000 - Val loss: 0.0133 - Val F1: 1.0000 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.0088 - Val accuracy: 1.0000 - Val loss: 0.0048 - Val F1: 1.0000 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.0029 - Val accuracy: 1.0000 - Val loss: 0.0030 - Val F1: 1.0000 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.0026 - Val accuracy: 1.0000 - Val loss: 0.0020 - Val F1: 1.0000 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.0029 - Val accuracy: 1.0000 - Val loss: 0.0016 - Val F1: 1.0000 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0015 - Val accuracy: 1.0000 - Val loss: 0.0012 - Val F1: 1.0000 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0012 - Val accuracy: 1.0000 - Val loss: 0.0012 - Val F1: 1.0000 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0009 - Val accuracy: 1.0000 - Val loss: 0.0011 - Val F1: 1.0000 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0010 - Val accuracy: 1.0000 - Val loss: 0.0010 - Val F1: 1.0000 - LR: 0.00e+00\n","\tBest epoch: 98 - Best val accuracy: 1.0000 - Best val loss: 0.0009 - Best val F1: 1.0000\n","\n","Source class: WAL | Domain: 46 | Accuracy: 0.8269 | Loss: 0.8085 | F1: 0.7717\n","\n","Domain: 47\n","x_syn_dom.shape: (444, 3, 128) | np.unique(y_syn_dom): [0 1 2 3]\n","x_dp_dom.shape: (155, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","x_syn_dom.shape: (388, 3, 128) | np.unique(y_syn_dom): [0 1 2 3]\n","x_dp_dom.shape: (100, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Training on synthetic data...\n","\tEpoch 10/100 - Train loss: 0.1785 - Val accuracy: 0.9744 - Val loss: 0.1554 - Val F1: 0.9734 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.0153 - Val accuracy: 1.0000 - Val loss: 0.0112 - Val F1: 1.0000 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.0074 - Val accuracy: 1.0000 - Val loss: 0.0034 - Val F1: 1.0000 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.0054 - Val accuracy: 1.0000 - Val loss: 0.0021 - Val F1: 1.0000 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.0028 - Val accuracy: 1.0000 - Val loss: 0.0012 - Val F1: 1.0000 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.0018 - Val accuracy: 1.0000 - Val loss: 0.0009 - Val F1: 1.0000 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0017 - Val accuracy: 1.0000 - Val loss: 0.0007 - Val F1: 1.0000 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0018 - Val accuracy: 1.0000 - Val loss: 0.0008 - Val F1: 1.0000 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0020 - Val accuracy: 1.0000 - Val loss: 0.0005 - Val F1: 1.0000 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0013 - Val accuracy: 1.0000 - Val loss: 0.0005 - Val F1: 1.0000 - LR: 0.00e+00\n","\tBest epoch: 92 - Best val accuracy: 1.0000 - Best val loss: 0.0005 - Best val F1: 1.0000\n","\n","Source class: WAL | Domain: 47 | Accuracy: 0.8900 | Loss: 0.4125 | F1: 0.8496\n","\n","Domain: 48\n","x_syn_dom.shape: (444, 3, 128) | np.unique(y_syn_dom): [0 1 2 3]\n","x_dp_dom.shape: (159, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","x_syn_dom.shape: (388, 3, 128) | np.unique(y_syn_dom): [0 1 2 3]\n","x_dp_dom.shape: (104, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Training on synthetic data...\n","\tEpoch 10/100 - Train loss: 0.0899 - Val accuracy: 1.0000 - Val loss: 0.0596 - Val F1: 1.0000 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.0137 - Val accuracy: 1.0000 - Val loss: 0.0079 - Val F1: 1.0000 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.0109 - Val accuracy: 1.0000 - Val loss: 0.0034 - Val F1: 1.0000 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.0065 - Val accuracy: 1.0000 - Val loss: 0.0016 - Val F1: 1.0000 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.0041 - Val accuracy: 1.0000 - Val loss: 0.0010 - Val F1: 1.0000 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.0021 - Val accuracy: 1.0000 - Val loss: 0.0008 - Val F1: 1.0000 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0030 - Val accuracy: 1.0000 - Val loss: 0.0006 - Val F1: 1.0000 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0023 - Val accuracy: 1.0000 - Val loss: 0.0006 - Val F1: 1.0000 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0015 - Val accuracy: 1.0000 - Val loss: 0.0005 - Val F1: 1.0000 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0012 - Val accuracy: 1.0000 - Val loss: 0.0005 - Val F1: 1.0000 - LR: 0.00e+00\n","\tBest epoch: 96 - Best val accuracy: 1.0000 - Best val loss: 0.0005 - Best val F1: 1.0000\n","\n","Source class: WAL | Domain: 48 | Accuracy: 0.9135 | Loss: 0.3256 | F1: 0.8930\n","\n","Domain: 49\n","x_syn_dom.shape: (444, 3, 128) | np.unique(y_syn_dom): [0 1 2 3]\n","x_dp_dom.shape: (164, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","x_syn_dom.shape: (388, 3, 128) | np.unique(y_syn_dom): [0 1 2 3]\n","x_dp_dom.shape: (109, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Training on synthetic data...\n","\tEpoch 10/100 - Train loss: 0.1309 - Val accuracy: 0.9615 - Val loss: 0.1585 - Val F1: 0.9616 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.0135 - Val accuracy: 1.0000 - Val loss: 0.0217 - Val F1: 1.0000 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.0059 - Val accuracy: 1.0000 - Val loss: 0.0070 - Val F1: 1.0000 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.0042 - Val accuracy: 1.0000 - Val loss: 0.0071 - Val F1: 1.0000 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.0021 - Val accuracy: 1.0000 - Val loss: 0.0033 - Val F1: 1.0000 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.0013 - Val accuracy: 1.0000 - Val loss: 0.0022 - Val F1: 1.0000 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0014 - Val accuracy: 1.0000 - Val loss: 0.0016 - Val F1: 1.0000 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0015 - Val accuracy: 1.0000 - Val loss: 0.0016 - Val F1: 1.0000 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0017 - Val accuracy: 1.0000 - Val loss: 0.0014 - Val F1: 1.0000 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0016 - Val accuracy: 1.0000 - Val loss: 0.0012 - Val F1: 1.0000 - LR: 0.00e+00\n","\tBest epoch: 96 - Best val accuracy: 1.0000 - Best val loss: 0.0011 - Best val F1: 1.0000\n","\n","Source class: WAL | Domain: 49 | Accuracy: 0.6789 | Loss: 1.6151 | F1: 0.6025\n","\n","Domain: 50\n","x_syn_dom.shape: (444, 3, 128) | np.unique(y_syn_dom): [0 1 2 3]\n","x_dp_dom.shape: (153, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","x_syn_dom.shape: (388, 3, 128) | np.unique(y_syn_dom): [0 1 2 3]\n","x_dp_dom.shape: (98, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Training on synthetic data...\n","\tEpoch 10/100 - Train loss: 0.0800 - Val accuracy: 1.0000 - Val loss: 0.0433 - Val F1: 1.0000 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.0126 - Val accuracy: 1.0000 - Val loss: 0.0071 - Val F1: 1.0000 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.0066 - Val accuracy: 1.0000 - Val loss: 0.0024 - Val F1: 1.0000 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.0031 - Val accuracy: 1.0000 - Val loss: 0.0016 - Val F1: 1.0000 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.0024 - Val accuracy: 1.0000 - Val loss: 0.0008 - Val F1: 1.0000 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.0027 - Val accuracy: 1.0000 - Val loss: 0.0007 - Val F1: 1.0000 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0018 - Val accuracy: 1.0000 - Val loss: 0.0005 - Val F1: 1.0000 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0011 - Val accuracy: 1.0000 - Val loss: 0.0005 - Val F1: 1.0000 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0013 - Val accuracy: 1.0000 - Val loss: 0.0004 - Val F1: 1.0000 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0014 - Val accuracy: 1.0000 - Val loss: 0.0004 - Val F1: 1.0000 - LR: 0.00e+00\n","\tBest epoch: 86 - Best val accuracy: 1.0000 - Best val loss: 0.0004 - Best val F1: 1.0000\n","\n","Source class: WAL | Domain: 50 | Accuracy: 0.9286 | Loss: 0.2726 | F1: 0.8964\n","\n","Domain: 51\n","x_syn_dom.shape: (444, 3, 128) | np.unique(y_syn_dom): [0 1 2 3]\n","x_dp_dom.shape: (157, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","x_syn_dom.shape: (388, 3, 128) | np.unique(y_syn_dom): [0 1 2 3]\n","x_dp_dom.shape: (102, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Training on synthetic data...\n","\tEpoch 10/100 - Train loss: 0.1302 - Val accuracy: 0.9744 - Val loss: 0.1445 - Val F1: 0.9745 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.0142 - Val accuracy: 1.0000 - Val loss: 0.0217 - Val F1: 1.0000 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.0075 - Val accuracy: 1.0000 - Val loss: 0.0087 - Val F1: 1.0000 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.0033 - Val accuracy: 1.0000 - Val loss: 0.0054 - Val F1: 1.0000 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.0037 - Val accuracy: 1.0000 - Val loss: 0.0058 - Val F1: 1.0000 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.0180 - Val accuracy: 1.0000 - Val loss: 0.0035 - Val F1: 1.0000 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0032 - Val accuracy: 1.0000 - Val loss: 0.0022 - Val F1: 1.0000 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0024 - Val accuracy: 1.0000 - Val loss: 0.0033 - Val F1: 1.0000 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0016 - Val accuracy: 1.0000 - Val loss: 0.0023 - Val F1: 1.0000 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0017 - Val accuracy: 1.0000 - Val loss: 0.0018 - Val F1: 1.0000 - LR: 0.00e+00\n","\tBest epoch: 88 - Best val accuracy: 1.0000 - Best val loss: 0.0017 - Best val F1: 1.0000\n","\n","Source class: WAL | Domain: 51 | Accuracy: 0.9118 | Loss: 0.7877 | F1: 0.8824\n","\n","Domain: 52\n","x_syn_dom.shape: (444, 3, 128) | np.unique(y_syn_dom): [0 1 2 3]\n","x_dp_dom.shape: (153, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","x_syn_dom.shape: (388, 3, 128) | np.unique(y_syn_dom): [0 1 2 3]\n","x_dp_dom.shape: (98, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Training on synthetic data...\n","\tEpoch 10/100 - Train loss: 0.0882 - Val accuracy: 1.0000 - Val loss: 0.0477 - Val F1: 1.0000 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.0132 - Val accuracy: 1.0000 - Val loss: 0.0057 - Val F1: 1.0000 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.0062 - Val accuracy: 1.0000 - Val loss: 0.0021 - Val F1: 1.0000 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.0142 - Val accuracy: 1.0000 - Val loss: 0.0012 - Val F1: 1.0000 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.0030 - Val accuracy: 1.0000 - Val loss: 0.0007 - Val F1: 1.0000 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.0020 - Val accuracy: 1.0000 - Val loss: 0.0005 - Val F1: 1.0000 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0026 - Val accuracy: 1.0000 - Val loss: 0.0004 - Val F1: 1.0000 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0019 - Val accuracy: 1.0000 - Val loss: 0.0004 - Val F1: 1.0000 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0019 - Val accuracy: 1.0000 - Val loss: 0.0003 - Val F1: 1.0000 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0018 - Val accuracy: 1.0000 - Val loss: 0.0004 - Val F1: 1.0000 - LR: 0.00e+00\n","\tBest epoch: 98 - Best val accuracy: 1.0000 - Best val loss: 0.0003 - Best val F1: 1.0000\n","\n","Source class: WAL | Domain: 52 | Accuracy: 0.8878 | Loss: 0.6964 | F1: 0.8657\n","\n","Domain: 53\n","x_syn_dom.shape: (444, 3, 128) | np.unique(y_syn_dom): [0 1 2 3]\n","x_dp_dom.shape: (159, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","x_syn_dom.shape: (388, 3, 128) | np.unique(y_syn_dom): [0 1 2 3]\n","x_dp_dom.shape: (104, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Training on synthetic data...\n","\tEpoch 10/100 - Train loss: 0.0332 - Val accuracy: 1.0000 - Val loss: 0.0424 - Val F1: 1.0000 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.0188 - Val accuracy: 1.0000 - Val loss: 0.0116 - Val F1: 1.0000 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.0093 - Val accuracy: 1.0000 - Val loss: 0.0045 - Val F1: 1.0000 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.0039 - Val accuracy: 1.0000 - Val loss: 0.0041 - Val F1: 1.0000 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.0047 - Val accuracy: 1.0000 - Val loss: 0.0020 - Val F1: 1.0000 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.0025 - Val accuracy: 1.0000 - Val loss: 0.0031 - Val F1: 1.0000 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0035 - Val accuracy: 1.0000 - Val loss: 0.0025 - Val F1: 1.0000 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0010 - Val accuracy: 1.0000 - Val loss: 0.0018 - Val F1: 1.0000 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0009 - Val accuracy: 1.0000 - Val loss: 0.0016 - Val F1: 1.0000 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0015 - Val accuracy: 1.0000 - Val loss: 0.0021 - Val F1: 1.0000 - LR: 0.00e+00\n","\tBest epoch: 96 - Best val accuracy: 1.0000 - Best val loss: 0.0013 - Best val F1: 1.0000\n","\n","Source class: WAL | Domain: 53 | Accuracy: 0.8558 | Loss: 0.8469 | F1: 0.8187\n","\n","Domain: 54\n","x_syn_dom.shape: (444, 3, 128) | np.unique(y_syn_dom): [0 1 2 3]\n","x_dp_dom.shape: (153, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","x_syn_dom.shape: (388, 3, 128) | np.unique(y_syn_dom): [0 1 2 3]\n","x_dp_dom.shape: (98, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Training on synthetic data...\n","\tEpoch 10/100 - Train loss: 0.1836 - Val accuracy: 1.0000 - Val loss: 0.1721 - Val F1: 1.0000 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.0142 - Val accuracy: 1.0000 - Val loss: 0.0128 - Val F1: 1.0000 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.0076 - Val accuracy: 1.0000 - Val loss: 0.0048 - Val F1: 1.0000 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.0049 - Val accuracy: 1.0000 - Val loss: 0.0033 - Val F1: 1.0000 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.0026 - Val accuracy: 1.0000 - Val loss: 0.0023 - Val F1: 1.0000 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.0255 - Val accuracy: 1.0000 - Val loss: 0.0013 - Val F1: 1.0000 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0013 - Val accuracy: 1.0000 - Val loss: 0.0011 - Val F1: 1.0000 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0018 - Val accuracy: 1.0000 - Val loss: 0.0010 - Val F1: 1.0000 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0013 - Val accuracy: 1.0000 - Val loss: 0.0010 - Val F1: 1.0000 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0009 - Val accuracy: 1.0000 - Val loss: 0.0009 - Val F1: 1.0000 - LR: 0.00e+00\n","\tBest epoch: 97 - Best val accuracy: 1.0000 - Best val loss: 0.0009 - Best val F1: 1.0000\n","\n","Source class: WAL | Domain: 54 | Accuracy: 0.8980 | Loss: 0.4487 | F1: 0.8842\n","\n","Domain: 55\n","x_syn_dom.shape: (444, 3, 128) | np.unique(y_syn_dom): [0 1 2 3]\n","x_dp_dom.shape: (160, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","x_syn_dom.shape: (388, 3, 128) | np.unique(y_syn_dom): [0 1 2 3]\n","x_dp_dom.shape: (105, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Training on synthetic data...\n","\tEpoch 10/100 - Train loss: 0.1052 - Val accuracy: 1.0000 - Val loss: 0.1055 - Val F1: 1.0000 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.0119 - Val accuracy: 1.0000 - Val loss: 0.0142 - Val F1: 1.0000 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.0073 - Val accuracy: 1.0000 - Val loss: 0.0062 - Val F1: 1.0000 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.0031 - Val accuracy: 1.0000 - Val loss: 0.0030 - Val F1: 1.0000 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.0066 - Val accuracy: 1.0000 - Val loss: 0.0018 - Val F1: 1.0000 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.0022 - Val accuracy: 1.0000 - Val loss: 0.0014 - Val F1: 1.0000 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0027 - Val accuracy: 1.0000 - Val loss: 0.0016 - Val F1: 1.0000 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0017 - Val accuracy: 1.0000 - Val loss: 0.0010 - Val F1: 1.0000 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0012 - Val accuracy: 1.0000 - Val loss: 0.0010 - Val F1: 1.0000 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0012 - Val accuracy: 1.0000 - Val loss: 0.0011 - Val F1: 1.0000 - LR: 0.00e+00\n","\tBest epoch: 91 - Best val accuracy: 1.0000 - Best val loss: 0.0009 - Best val F1: 1.0000\n","\n","Source class: WAL | Domain: 55 | Accuracy: 0.9143 | Loss: 0.4552 | F1: 0.8872\n","\n","Domain: 56\n","x_syn_dom.shape: (444, 3, 128) | np.unique(y_syn_dom): [0 1 2 3]\n","x_dp_dom.shape: (153, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","x_syn_dom.shape: (388, 3, 128) | np.unique(y_syn_dom): [0 1 2 3]\n","x_dp_dom.shape: (98, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Training on synthetic data...\n","\tEpoch 10/100 - Train loss: 0.2090 - Val accuracy: 0.9872 - Val loss: 0.1626 - Val F1: 0.9873 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.0299 - Val accuracy: 1.0000 - Val loss: 0.0179 - Val F1: 1.0000 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.0075 - Val accuracy: 1.0000 - Val loss: 0.0070 - Val F1: 1.0000 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.0088 - Val accuracy: 1.0000 - Val loss: 0.0046 - Val F1: 1.0000 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.0044 - Val accuracy: 1.0000 - Val loss: 0.0024 - Val F1: 1.0000 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.0021 - Val accuracy: 1.0000 - Val loss: 0.0023 - Val F1: 1.0000 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0016 - Val accuracy: 1.0000 - Val loss: 0.0015 - Val F1: 1.0000 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0013 - Val accuracy: 1.0000 - Val loss: 0.0018 - Val F1: 1.0000 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0015 - Val accuracy: 1.0000 - Val loss: 0.0012 - Val F1: 1.0000 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0029 - Val accuracy: 1.0000 - Val loss: 0.0015 - Val F1: 1.0000 - LR: 0.00e+00\n","\tBest epoch: 86 - Best val accuracy: 1.0000 - Best val loss: 0.0011 - Best val F1: 1.0000\n","\n","Source class: WAL | Domain: 56 | Accuracy: 0.8673 | Loss: 0.6636 | F1: 0.8220\n","\n","Domain: 57\n","x_syn_dom.shape: (444, 3, 128) | np.unique(y_syn_dom): [0 1 2 3]\n","x_dp_dom.shape: (153, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","x_syn_dom.shape: (388, 3, 128) | np.unique(y_syn_dom): [0 1 2 3]\n","x_dp_dom.shape: (98, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Training on synthetic data...\n","\tEpoch 10/100 - Train loss: 0.0709 - Val accuracy: 1.0000 - Val loss: 0.0362 - Val F1: 1.0000 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.0146 - Val accuracy: 1.0000 - Val loss: 0.0052 - Val F1: 1.0000 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.0067 - Val accuracy: 1.0000 - Val loss: 0.0022 - Val F1: 1.0000 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.0039 - Val accuracy: 1.0000 - Val loss: 0.0012 - Val F1: 1.0000 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.0019 - Val accuracy: 1.0000 - Val loss: 0.0009 - Val F1: 1.0000 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.0016 - Val accuracy: 1.0000 - Val loss: 0.0009 - Val F1: 1.0000 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0029 - Val accuracy: 1.0000 - Val loss: 0.0005 - Val F1: 1.0000 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0013 - Val accuracy: 1.0000 - Val loss: 0.0005 - Val F1: 1.0000 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0016 - Val accuracy: 1.0000 - Val loss: 0.0004 - Val F1: 1.0000 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0033 - Val accuracy: 1.0000 - Val loss: 0.0004 - Val F1: 1.0000 - LR: 0.00e+00\n","\tBest epoch: 92 - Best val accuracy: 1.0000 - Best val loss: 0.0003 - Best val F1: 1.0000\n","\n","Source class: WAL | Domain: 57 | Accuracy: 0.8571 | Loss: 0.3729 | F1: 0.7918\n","\n","Domain: 58\n","x_syn_dom.shape: (444, 3, 128) | np.unique(y_syn_dom): [0 1 2 3]\n","x_dp_dom.shape: (149, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","x_syn_dom.shape: (388, 3, 128) | np.unique(y_syn_dom): [0 1 2 3]\n","x_dp_dom.shape: (94, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Training on synthetic data...\n","\tEpoch 10/100 - Train loss: 0.2159 - Val accuracy: 0.9744 - Val loss: 0.2159 - Val F1: 0.9745 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.0322 - Val accuracy: 1.0000 - Val loss: 0.0269 - Val F1: 1.0000 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.0196 - Val accuracy: 1.0000 - Val loss: 0.0102 - Val F1: 1.0000 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.0064 - Val accuracy: 1.0000 - Val loss: 0.0045 - Val F1: 1.0000 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.0083 - Val accuracy: 1.0000 - Val loss: 0.0029 - Val F1: 1.0000 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.0045 - Val accuracy: 1.0000 - Val loss: 0.0026 - Val F1: 1.0000 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0015 - Val accuracy: 1.0000 - Val loss: 0.0019 - Val F1: 1.0000 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0043 - Val accuracy: 1.0000 - Val loss: 0.0024 - Val F1: 1.0000 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0164 - Val accuracy: 1.0000 - Val loss: 0.0014 - Val F1: 1.0000 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0028 - Val accuracy: 1.0000 - Val loss: 0.0019 - Val F1: 1.0000 - LR: 0.00e+00\n","\tBest epoch: 98 - Best val accuracy: 1.0000 - Best val loss: 0.0013 - Best val F1: 1.0000\n","\n","Source class: WAL | Domain: 58 | Accuracy: 0.9149 | Loss: 0.3200 | F1: 0.8943\n","\n","Domain: 59\n","x_syn_dom.shape: (444, 3, 128) | np.unique(y_syn_dom): [0 1 2 3]\n","x_dp_dom.shape: (154, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","x_syn_dom.shape: (388, 3, 128) | np.unique(y_syn_dom): [0 1 2 3]\n","x_dp_dom.shape: (99, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Training on synthetic data...\n","\tEpoch 10/100 - Train loss: 0.0661 - Val accuracy: 1.0000 - Val loss: 0.0478 - Val F1: 1.0000 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.0170 - Val accuracy: 1.0000 - Val loss: 0.0106 - Val F1: 1.0000 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.0055 - Val accuracy: 1.0000 - Val loss: 0.0043 - Val F1: 1.0000 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.0053 - Val accuracy: 1.0000 - Val loss: 0.0020 - Val F1: 1.0000 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.0022 - Val accuracy: 1.0000 - Val loss: 0.0015 - Val F1: 1.0000 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.0025 - Val accuracy: 1.0000 - Val loss: 0.0014 - Val F1: 1.0000 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0012 - Val accuracy: 1.0000 - Val loss: 0.0013 - Val F1: 1.0000 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0016 - Val accuracy: 1.0000 - Val loss: 0.0012 - Val F1: 1.0000 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0022 - Val accuracy: 1.0000 - Val loss: 0.0010 - Val F1: 1.0000 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0015 - Val accuracy: 1.0000 - Val loss: 0.0010 - Val F1: 1.0000 - LR: 0.00e+00\n","\tBest epoch: 88 - Best val accuracy: 1.0000 - Best val loss: 0.0008 - Best val F1: 1.0000\n","\n","Source class: WAL | Domain: 59 | Accuracy: 0.9091 | Loss: 0.2671 | F1: 0.8950\n","\n","Domain: 60\n","x_syn_dom.shape: (444, 3, 128) | np.unique(y_syn_dom): [0 1 2 3]\n","x_dp_dom.shape: (158, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","x_syn_dom.shape: (388, 3, 128) | np.unique(y_syn_dom): [0 1 2 3]\n","x_dp_dom.shape: (103, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Training on synthetic data...\n","\tEpoch 10/100 - Train loss: 0.0332 - Val accuracy: 1.0000 - Val loss: 0.0103 - Val F1: 1.0000 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.0098 - Val accuracy: 1.0000 - Val loss: 0.0030 - Val F1: 1.0000 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.0081 - Val accuracy: 1.0000 - Val loss: 0.0015 - Val F1: 1.0000 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.0063 - Val accuracy: 1.0000 - Val loss: 0.0018 - Val F1: 1.0000 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.0036 - Val accuracy: 1.0000 - Val loss: 0.0015 - Val F1: 1.0000 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.0017 - Val accuracy: 1.0000 - Val loss: 0.0007 - Val F1: 1.0000 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0050 - Val accuracy: 1.0000 - Val loss: 0.0006 - Val F1: 1.0000 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0012 - Val accuracy: 1.0000 - Val loss: 0.0007 - Val F1: 1.0000 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0019 - Val accuracy: 1.0000 - Val loss: 0.0009 - Val F1: 1.0000 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0018 - Val accuracy: 1.0000 - Val loss: 0.0005 - Val F1: 1.0000 - LR: 0.00e+00\n","\tBest epoch: 89 - Best val accuracy: 1.0000 - Best val loss: 0.0004 - Best val F1: 1.0000\n","\n","Source class: WAL | Domain: 60 | Accuracy: 0.7476 | Loss: 2.2480 | F1: 0.6743\n","\n","Domain: 61\n","x_syn_dom.shape: (444, 3, 128) | np.unique(y_syn_dom): [0 1 2 3]\n","x_dp_dom.shape: (158, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","x_syn_dom.shape: (388, 3, 128) | np.unique(y_syn_dom): [0 1 2 3]\n","x_dp_dom.shape: (103, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Training on synthetic data...\n","\tEpoch 10/100 - Train loss: 0.1302 - Val accuracy: 1.0000 - Val loss: 0.1060 - Val F1: 1.0000 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.0243 - Val accuracy: 1.0000 - Val loss: 0.0128 - Val F1: 1.0000 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.0073 - Val accuracy: 1.0000 - Val loss: 0.0040 - Val F1: 1.0000 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.0127 - Val accuracy: 1.0000 - Val loss: 0.0026 - Val F1: 1.0000 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.0025 - Val accuracy: 1.0000 - Val loss: 0.0017 - Val F1: 1.0000 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.0026 - Val accuracy: 1.0000 - Val loss: 0.0015 - Val F1: 1.0000 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0015 - Val accuracy: 1.0000 - Val loss: 0.0010 - Val F1: 1.0000 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0012 - Val accuracy: 1.0000 - Val loss: 0.0009 - Val F1: 1.0000 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0025 - Val accuracy: 1.0000 - Val loss: 0.0007 - Val F1: 1.0000 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0014 - Val accuracy: 1.0000 - Val loss: 0.0008 - Val F1: 1.0000 - LR: 0.00e+00\n","\tBest epoch: 94 - Best val accuracy: 1.0000 - Best val loss: 0.0007 - Best val F1: 1.0000\n","\n","Source class: WAL | Domain: 61 | Accuracy: 0.6311 | Loss: 2.1606 | F1: 0.5396\n","\n","Domain: 62\n","x_syn_dom.shape: (444, 3, 128) | np.unique(y_syn_dom): [0 1 2 3]\n","x_dp_dom.shape: (158, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","x_syn_dom.shape: (388, 3, 128) | np.unique(y_syn_dom): [0 1 2 3]\n","x_dp_dom.shape: (103, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Training on synthetic data...\n","\tEpoch 10/100 - Train loss: 0.0918 - Val accuracy: 1.0000 - Val loss: 0.0743 - Val F1: 1.0000 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.0109 - Val accuracy: 1.0000 - Val loss: 0.0062 - Val F1: 1.0000 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.0040 - Val accuracy: 1.0000 - Val loss: 0.0026 - Val F1: 1.0000 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.0030 - Val accuracy: 1.0000 - Val loss: 0.0014 - Val F1: 1.0000 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.0020 - Val accuracy: 1.0000 - Val loss: 0.0010 - Val F1: 1.0000 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.0020 - Val accuracy: 1.0000 - Val loss: 0.0007 - Val F1: 1.0000 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0012 - Val accuracy: 1.0000 - Val loss: 0.0006 - Val F1: 1.0000 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0018 - Val accuracy: 1.0000 - Val loss: 0.0006 - Val F1: 1.0000 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0008 - Val accuracy: 1.0000 - Val loss: 0.0007 - Val F1: 1.0000 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0032 - Val accuracy: 1.0000 - Val loss: 0.0006 - Val F1: 1.0000 - LR: 0.00e+00\n","\tBest epoch: 83 - Best val accuracy: 1.0000 - Best val loss: 0.0005 - Best val F1: 1.0000\n","\n","Source class: WAL | Domain: 62 | Accuracy: 0.8155 | Loss: 1.0319 | F1: 0.7391\n","\n","Domain: 63\n","x_syn_dom.shape: (444, 3, 128) | np.unique(y_syn_dom): [0 1 2 3]\n","x_dp_dom.shape: (153, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","x_syn_dom.shape: (388, 3, 128) | np.unique(y_syn_dom): [0 1 2 3]\n","x_dp_dom.shape: (98, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Training on synthetic data...\n","\tEpoch 10/100 - Train loss: 0.0826 - Val accuracy: 1.0000 - Val loss: 0.0574 - Val F1: 1.0000 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.0182 - Val accuracy: 1.0000 - Val loss: 0.0083 - Val F1: 1.0000 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.0075 - Val accuracy: 1.0000 - Val loss: 0.0034 - Val F1: 1.0000 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.0050 - Val accuracy: 1.0000 - Val loss: 0.0019 - Val F1: 1.0000 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.0050 - Val accuracy: 1.0000 - Val loss: 0.0012 - Val F1: 1.0000 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.0039 - Val accuracy: 1.0000 - Val loss: 0.0010 - Val F1: 1.0000 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0015 - Val accuracy: 1.0000 - Val loss: 0.0008 - Val F1: 1.0000 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0014 - Val accuracy: 1.0000 - Val loss: 0.0006 - Val F1: 1.0000 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0014 - Val accuracy: 1.0000 - Val loss: 0.0006 - Val F1: 1.0000 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0016 - Val accuracy: 1.0000 - Val loss: 0.0005 - Val F1: 1.0000 - LR: 0.00e+00\n","\tBest epoch: 100 - Best val accuracy: 1.0000 - Best val loss: 0.0005 - Best val F1: 1.0000\n","\n","Source class: WAL | Domain: 63 | Accuracy: 0.6224 | Loss: 1.6419 | F1: 0.5194\n","\n","Domain: 64\n","x_syn_dom.shape: (448, 3, 128) | np.unique(y_syn_dom): [0 1 2 3]\n","x_dp_dom.shape: (154, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","x_syn_dom.shape: (392, 3, 128) | np.unique(y_syn_dom): [0 1 2 3]\n","x_dp_dom.shape: (98, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Training on synthetic data...\n","\tEpoch 10/100 - Train loss: 0.1477 - Val accuracy: 1.0000 - Val loss: 0.1113 - Val F1: 1.0000 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.0155 - Val accuracy: 1.0000 - Val loss: 0.0126 - Val F1: 1.0000 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.0085 - Val accuracy: 1.0000 - Val loss: 0.0038 - Val F1: 1.0000 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.0046 - Val accuracy: 1.0000 - Val loss: 0.0024 - Val F1: 1.0000 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.0022 - Val accuracy: 1.0000 - Val loss: 0.0013 - Val F1: 1.0000 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.0051 - Val accuracy: 1.0000 - Val loss: 0.0016 - Val F1: 1.0000 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0027 - Val accuracy: 1.0000 - Val loss: 0.0011 - Val F1: 1.0000 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0019 - Val accuracy: 1.0000 - Val loss: 0.0006 - Val F1: 1.0000 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0026 - Val accuracy: 1.0000 - Val loss: 0.0006 - Val F1: 1.0000 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0012 - Val accuracy: 1.0000 - Val loss: 0.0005 - Val F1: 1.0000 - LR: 0.00e+00\n","\tBest epoch: 100 - Best val accuracy: 1.0000 - Best val loss: 0.0005 - Best val F1: 1.0000\n","\n","Source class: WAL | Domain: 64 | Accuracy: 0.9490 | Loss: 0.2110 | F1: 0.9415\n","\n","Domain: 65\n","x_syn_dom.shape: (444, 3, 128) | np.unique(y_syn_dom): [0 1 2 3]\n","x_dp_dom.shape: (161, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","x_syn_dom.shape: (388, 3, 128) | np.unique(y_syn_dom): [0 1 2 3]\n","x_dp_dom.shape: (106, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Training on synthetic data...\n","\tEpoch 10/100 - Train loss: 0.2146 - Val accuracy: 1.0000 - Val loss: 0.2469 - Val F1: 1.0000 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.0206 - Val accuracy: 1.0000 - Val loss: 0.0233 - Val F1: 1.0000 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.0122 - Val accuracy: 1.0000 - Val loss: 0.0106 - Val F1: 1.0000 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.0071 - Val accuracy: 1.0000 - Val loss: 0.0111 - Val F1: 1.0000 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.0033 - Val accuracy: 1.0000 - Val loss: 0.0086 - Val F1: 1.0000 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.0038 - Val accuracy: 1.0000 - Val loss: 0.0037 - Val F1: 1.0000 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0019 - Val accuracy: 1.0000 - Val loss: 0.0072 - Val F1: 1.0000 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0019 - Val accuracy: 1.0000 - Val loss: 0.0055 - Val F1: 1.0000 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0030 - Val accuracy: 1.0000 - Val loss: 0.0033 - Val F1: 1.0000 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0029 - Val accuracy: 1.0000 - Val loss: 0.0062 - Val F1: 1.0000 - LR: 0.00e+00\n","\tBest epoch: 83 - Best val accuracy: 1.0000 - Best val loss: 0.0032 - Best val F1: 1.0000\n","\n","Source class: WAL | Domain: 65 | Accuracy: 0.8208 | Loss: 0.9530 | F1: 0.7802\n","\n","Domain: 66\n","x_syn_dom.shape: (444, 3, 128) | np.unique(y_syn_dom): [0 1 2 3]\n","x_dp_dom.shape: (153, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","x_syn_dom.shape: (388, 3, 128) | np.unique(y_syn_dom): [0 1 2 3]\n","x_dp_dom.shape: (98, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Training on synthetic data...\n","\tEpoch 10/100 - Train loss: 0.0789 - Val accuracy: 1.0000 - Val loss: 0.0446 - Val F1: 1.0000 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.0267 - Val accuracy: 1.0000 - Val loss: 0.0085 - Val F1: 1.0000 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.0111 - Val accuracy: 1.0000 - Val loss: 0.0055 - Val F1: 1.0000 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.0068 - Val accuracy: 1.0000 - Val loss: 0.0023 - Val F1: 1.0000 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.0044 - Val accuracy: 1.0000 - Val loss: 0.0015 - Val F1: 1.0000 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.0040 - Val accuracy: 1.0000 - Val loss: 0.0011 - Val F1: 1.0000 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0029 - Val accuracy: 1.0000 - Val loss: 0.0010 - Val F1: 1.0000 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0014 - Val accuracy: 1.0000 - Val loss: 0.0008 - Val F1: 1.0000 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0019 - Val accuracy: 1.0000 - Val loss: 0.0007 - Val F1: 1.0000 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0020 - Val accuracy: 1.0000 - Val loss: 0.0008 - Val F1: 1.0000 - LR: 0.00e+00\n","\tBest epoch: 90 - Best val accuracy: 1.0000 - Best val loss: 0.0007 - Best val F1: 1.0000\n","\n","Source class: WAL | Domain: 66 | Accuracy: 0.8776 | Loss: 2.1680 | F1: 0.8385\n","\n","Domain: 67\n","x_syn_dom.shape: (444, 3, 128) | np.unique(y_syn_dom): [0 1 2 3]\n","x_dp_dom.shape: (153, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","x_syn_dom.shape: (388, 3, 128) | np.unique(y_syn_dom): [0 1 2 3]\n","x_dp_dom.shape: (98, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Training on synthetic data...\n","\tEpoch 10/100 - Train loss: 0.1669 - Val accuracy: 0.9872 - Val loss: 0.1653 - Val F1: 0.9872 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.0313 - Val accuracy: 0.9872 - Val loss: 0.0492 - Val F1: 0.9872 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.0207 - Val accuracy: 1.0000 - Val loss: 0.0146 - Val F1: 1.0000 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.0098 - Val accuracy: 1.0000 - Val loss: 0.0141 - Val F1: 1.0000 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.0123 - Val accuracy: 1.0000 - Val loss: 0.0126 - Val F1: 1.0000 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.0040 - Val accuracy: 1.0000 - Val loss: 0.0083 - Val F1: 1.0000 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0041 - Val accuracy: 1.0000 - Val loss: 0.0096 - Val F1: 1.0000 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0069 - Val accuracy: 1.0000 - Val loss: 0.0059 - Val F1: 1.0000 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0076 - Val accuracy: 1.0000 - Val loss: 0.0056 - Val F1: 1.0000 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0041 - Val accuracy: 0.9872 - Val loss: 0.0123 - Val F1: 0.9872 - LR: 0.00e+00\n","\tBest epoch: 81 - Best val accuracy: 1.0000 - Best val loss: 0.0044 - Best val F1: 1.0000\n","\n","Source class: WAL | Domain: 67 | Accuracy: 0.8673 | Loss: 0.5640 | F1: 0.8320\n","\n","Domain: 68\n","x_syn_dom.shape: (444, 3, 128) | np.unique(y_syn_dom): [0 1 2 3]\n","x_dp_dom.shape: (154, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","x_syn_dom.shape: (388, 3, 128) | np.unique(y_syn_dom): [0 1 2 3]\n","x_dp_dom.shape: (99, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Training on synthetic data...\n","\tEpoch 10/100 - Train loss: 0.1173 - Val accuracy: 0.9872 - Val loss: 0.1102 - Val F1: 0.9870 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.0226 - Val accuracy: 1.0000 - Val loss: 0.0177 - Val F1: 1.0000 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.0166 - Val accuracy: 1.0000 - Val loss: 0.0073 - Val F1: 1.0000 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.0101 - Val accuracy: 1.0000 - Val loss: 0.0070 - Val F1: 1.0000 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.0032 - Val accuracy: 1.0000 - Val loss: 0.0035 - Val F1: 1.0000 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.0039 - Val accuracy: 1.0000 - Val loss: 0.0032 - Val F1: 1.0000 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0096 - Val accuracy: 1.0000 - Val loss: 0.0033 - Val F1: 1.0000 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0030 - Val accuracy: 1.0000 - Val loss: 0.0026 - Val F1: 1.0000 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0025 - Val accuracy: 1.0000 - Val loss: 0.0023 - Val F1: 1.0000 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0015 - Val accuracy: 1.0000 - Val loss: 0.0024 - Val F1: 1.0000 - LR: 0.00e+00\n","\tBest epoch: 97 - Best val accuracy: 1.0000 - Best val loss: 0.0019 - Best val F1: 1.0000\n","\n","Source class: WAL | Domain: 68 | Accuracy: 0.8788 | Loss: 0.3329 | F1: 0.8639\n","\n","Domain: 69\n","x_syn_dom.shape: (444, 3, 128) | np.unique(y_syn_dom): [0 1 2 3]\n","x_dp_dom.shape: (153, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","x_syn_dom.shape: (388, 3, 128) | np.unique(y_syn_dom): [0 1 2 3]\n","x_dp_dom.shape: (98, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Training on synthetic data...\n","\tEpoch 10/100 - Train loss: 0.1295 - Val accuracy: 0.9615 - Val loss: 0.1527 - Val F1: 0.9613 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.0159 - Val accuracy: 1.0000 - Val loss: 0.0181 - Val F1: 1.0000 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.0101 - Val accuracy: 1.0000 - Val loss: 0.0070 - Val F1: 1.0000 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.0048 - Val accuracy: 1.0000 - Val loss: 0.0039 - Val F1: 1.0000 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.0054 - Val accuracy: 1.0000 - Val loss: 0.0024 - Val F1: 1.0000 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.0037 - Val accuracy: 1.0000 - Val loss: 0.0046 - Val F1: 1.0000 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0020 - Val accuracy: 1.0000 - Val loss: 0.0018 - Val F1: 1.0000 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0012 - Val accuracy: 1.0000 - Val loss: 0.0019 - Val F1: 1.0000 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0017 - Val accuracy: 1.0000 - Val loss: 0.0016 - Val F1: 1.0000 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0021 - Val accuracy: 1.0000 - Val loss: 0.0017 - Val F1: 1.0000 - LR: 0.00e+00\n","\tBest epoch: 93 - Best val accuracy: 1.0000 - Best val loss: 0.0010 - Best val F1: 1.0000\n","\n","Source class: WAL | Domain: 69 | Accuracy: 0.8571 | Loss: 0.7531 | F1: 0.8060\n","\n","Domain: 70\n","x_syn_dom.shape: (444, 3, 128) | np.unique(y_syn_dom): [0 1 2 3]\n","x_dp_dom.shape: (153, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","x_syn_dom.shape: (388, 3, 128) | np.unique(y_syn_dom): [0 1 2 3]\n","x_dp_dom.shape: (98, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Training on synthetic data...\n","\tEpoch 10/100 - Train loss: 0.1949 - Val accuracy: 0.9231 - Val loss: 0.2467 - Val F1: 0.9217 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.0426 - Val accuracy: 0.9744 - Val loss: 0.1015 - Val F1: 0.9742 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.0167 - Val accuracy: 0.9872 - Val loss: 0.0934 - Val F1: 0.9872 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.0076 - Val accuracy: 0.9872 - Val loss: 0.0894 - Val F1: 0.9872 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.0067 - Val accuracy: 0.9744 - Val loss: 0.1014 - Val F1: 0.9742 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.0039 - Val accuracy: 0.9872 - Val loss: 0.0886 - Val F1: 0.9872 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0049 - Val accuracy: 0.9872 - Val loss: 0.0991 - Val F1: 0.9872 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0015 - Val accuracy: 0.9872 - Val loss: 0.0947 - Val F1: 0.9872 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0027 - Val accuracy: 0.9872 - Val loss: 0.0931 - Val F1: 0.9872 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0538 - Val accuracy: 0.9872 - Val loss: 0.0881 - Val F1: 0.9872 - LR: 0.00e+00\n","\tBest epoch: 25 - Best val accuracy: 0.9872 - Best val loss: 0.0745 - Best val F1: 0.9872\n","\n","Source class: WAL | Domain: 70 | Accuracy: 0.6735 | Loss: 1.3539 | F1: 0.6005\n","\n","Domain: 71\n","x_syn_dom.shape: (444, 3, 128) | np.unique(y_syn_dom): [0 1 2 3]\n","x_dp_dom.shape: (155, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","x_syn_dom.shape: (388, 3, 128) | np.unique(y_syn_dom): [0 1 2 3]\n","x_dp_dom.shape: (100, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Training on synthetic data...\n","\tEpoch 10/100 - Train loss: 0.1737 - Val accuracy: 0.9744 - Val loss: 0.1310 - Val F1: 0.9745 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.0160 - Val accuracy: 1.0000 - Val loss: 0.0209 - Val F1: 1.0000 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.0052 - Val accuracy: 1.0000 - Val loss: 0.0092 - Val F1: 1.0000 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.0035 - Val accuracy: 1.0000 - Val loss: 0.0049 - Val F1: 1.0000 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.0040 - Val accuracy: 1.0000 - Val loss: 0.0042 - Val F1: 1.0000 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.0047 - Val accuracy: 1.0000 - Val loss: 0.0025 - Val F1: 1.0000 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0014 - Val accuracy: 1.0000 - Val loss: 0.0019 - Val F1: 1.0000 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0033 - Val accuracy: 1.0000 - Val loss: 0.0016 - Val F1: 1.0000 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0013 - Val accuracy: 1.0000 - Val loss: 0.0015 - Val F1: 1.0000 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0013 - Val accuracy: 1.0000 - Val loss: 0.0014 - Val F1: 1.0000 - LR: 0.00e+00\n","\tBest epoch: 98 - Best val accuracy: 1.0000 - Best val loss: 0.0013 - Best val F1: 1.0000\n","\n","Source class: WAL | Domain: 71 | Accuracy: 0.9000 | Loss: 0.5917 | F1: 0.8587\n","\n","Domain: 72\n","x_syn_dom.shape: (444, 3, 128) | np.unique(y_syn_dom): [0 1 2 3]\n","x_dp_dom.shape: (153, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","x_syn_dom.shape: (388, 3, 128) | np.unique(y_syn_dom): [0 1 2 3]\n","x_dp_dom.shape: (98, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Training on synthetic data...\n","\tEpoch 10/100 - Train loss: 0.1145 - Val accuracy: 1.0000 - Val loss: 0.0568 - Val F1: 1.0000 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.0332 - Val accuracy: 1.0000 - Val loss: 0.0113 - Val F1: 1.0000 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.0058 - Val accuracy: 1.0000 - Val loss: 0.0035 - Val F1: 1.0000 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.0054 - Val accuracy: 1.0000 - Val loss: 0.0019 - Val F1: 1.0000 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.0033 - Val accuracy: 1.0000 - Val loss: 0.0013 - Val F1: 1.0000 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.0040 - Val accuracy: 1.0000 - Val loss: 0.0010 - Val F1: 1.0000 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0022 - Val accuracy: 1.0000 - Val loss: 0.0008 - Val F1: 1.0000 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0020 - Val accuracy: 1.0000 - Val loss: 0.0008 - Val F1: 1.0000 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0016 - Val accuracy: 1.0000 - Val loss: 0.0006 - Val F1: 1.0000 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0009 - Val accuracy: 1.0000 - Val loss: 0.0006 - Val F1: 1.0000 - LR: 0.00e+00\n","\tBest epoch: 89 - Best val accuracy: 1.0000 - Best val loss: 0.0006 - Best val F1: 1.0000\n","\n","Source class: WAL | Domain: 72 | Accuracy: 0.8878 | Loss: 0.5307 | F1: 0.8625\n","\n","Domain: 73\n","x_syn_dom.shape: (444, 3, 128) | np.unique(y_syn_dom): [0 1 2 3]\n","x_dp_dom.shape: (152, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","x_syn_dom.shape: (388, 3, 128) | np.unique(y_syn_dom): [0 1 2 3]\n","x_dp_dom.shape: (97, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Training on synthetic data...\n","\tEpoch 10/100 - Train loss: 0.0538 - Val accuracy: 1.0000 - Val loss: 0.0190 - Val F1: 1.0000 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.0107 - Val accuracy: 1.0000 - Val loss: 0.0045 - Val F1: 1.0000 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.0095 - Val accuracy: 1.0000 - Val loss: 0.0022 - Val F1: 1.0000 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.0055 - Val accuracy: 1.0000 - Val loss: 0.0018 - Val F1: 1.0000 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.0025 - Val accuracy: 1.0000 - Val loss: 0.0008 - Val F1: 1.0000 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.0015 - Val accuracy: 1.0000 - Val loss: 0.0008 - Val F1: 1.0000 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0014 - Val accuracy: 1.0000 - Val loss: 0.0007 - Val F1: 1.0000 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0014 - Val accuracy: 1.0000 - Val loss: 0.0005 - Val F1: 1.0000 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0009 - Val accuracy: 1.0000 - Val loss: 0.0005 - Val F1: 1.0000 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0058 - Val accuracy: 1.0000 - Val loss: 0.0004 - Val F1: 1.0000 - LR: 0.00e+00\n","\tBest epoch: 100 - Best val accuracy: 1.0000 - Best val loss: 0.0004 - Best val F1: 1.0000\n","\n","Source class: WAL | Domain: 73 | Accuracy: 0.6186 | Loss: 2.3470 | F1: 0.5061\n","\n","Domain: 74\n","x_syn_dom.shape: (444, 3, 128) | np.unique(y_syn_dom): [0 1 2 3]\n","x_dp_dom.shape: (146, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","x_syn_dom.shape: (388, 3, 128) | np.unique(y_syn_dom): [0 1 2 3]\n","x_dp_dom.shape: (91, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Training on synthetic data...\n","\tEpoch 10/100 - Train loss: 0.0865 - Val accuracy: 1.0000 - Val loss: 0.0510 - Val F1: 1.0000 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.0207 - Val accuracy: 1.0000 - Val loss: 0.0051 - Val F1: 1.0000 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.0051 - Val accuracy: 1.0000 - Val loss: 0.0022 - Val F1: 1.0000 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.0037 - Val accuracy: 1.0000 - Val loss: 0.0015 - Val F1: 1.0000 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.0025 - Val accuracy: 1.0000 - Val loss: 0.0010 - Val F1: 1.0000 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.0019 - Val accuracy: 1.0000 - Val loss: 0.0008 - Val F1: 1.0000 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0026 - Val accuracy: 1.0000 - Val loss: 0.0005 - Val F1: 1.0000 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0014 - Val accuracy: 1.0000 - Val loss: 0.0005 - Val F1: 1.0000 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0012 - Val accuracy: 1.0000 - Val loss: 0.0005 - Val F1: 1.0000 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0011 - Val accuracy: 1.0000 - Val loss: 0.0004 - Val F1: 1.0000 - LR: 0.00e+00\n","\tBest epoch: 87 - Best val accuracy: 1.0000 - Best val loss: 0.0004 - Best val F1: 1.0000\n","\n","Source class: WAL | Domain: 74 | Accuracy: 0.9121 | Loss: 0.7691 | F1: 0.8770\n","\n","Domain: 75\n","x_syn_dom.shape: (444, 3, 128) | np.unique(y_syn_dom): [0 1 2 3]\n","x_dp_dom.shape: (153, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","x_syn_dom.shape: (388, 3, 128) | np.unique(y_syn_dom): [0 1 2 3]\n","x_dp_dom.shape: (98, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Training on synthetic data...\n","\tEpoch 10/100 - Train loss: 0.0935 - Val accuracy: 1.0000 - Val loss: 0.0644 - Val F1: 1.0000 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.0160 - Val accuracy: 1.0000 - Val loss: 0.0078 - Val F1: 1.0000 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.0058 - Val accuracy: 1.0000 - Val loss: 0.0026 - Val F1: 1.0000 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.0090 - Val accuracy: 1.0000 - Val loss: 0.0016 - Val F1: 1.0000 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.0023 - Val accuracy: 1.0000 - Val loss: 0.0010 - Val F1: 1.0000 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.0026 - Val accuracy: 1.0000 - Val loss: 0.0007 - Val F1: 1.0000 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0017 - Val accuracy: 1.0000 - Val loss: 0.0006 - Val F1: 1.0000 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0014 - Val accuracy: 1.0000 - Val loss: 0.0004 - Val F1: 1.0000 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0010 - Val accuracy: 1.0000 - Val loss: 0.0005 - Val F1: 1.0000 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0011 - Val accuracy: 1.0000 - Val loss: 0.0004 - Val F1: 1.0000 - LR: 0.00e+00\n","\tBest epoch: 100 - Best val accuracy: 1.0000 - Best val loss: 0.0004 - Best val F1: 1.0000\n","\n","Source class: WAL | Domain: 75 | Accuracy: 0.8980 | Loss: 0.2912 | F1: 0.8623\n","\n","Mean accuracy: 0.8282 +- 0.0908\n","Mean F1: 0.7835 +- 0.1150\n","\n"]}],"source":["def compute_TSTR_Syn(dataset):\n","    accs = []\n","    f1s = []\n","\n","    for src_class in config[dataset]['class_names']:\n","        if src_class != 'WAL':\n","            continue\n","\n","        print(f\"Source class: {src_class}\\n\")\n","\n","        for domain in range(config[dataset]['num_df_domains'], config[dataset]['num_df_domains'] + config[dataset]['num_dp_domains']):\n","            print(f\"Domain: {domain}\")\n","\n","            # Load synthetic data\n","            x_syn_dom, y_syn_dom, k_syn_dom = get_syn_data(dataset, syn_name, src_class, domain)\n","            print(f'x_syn_dom.shape: {x_syn_dom.shape} | np.unique(y_syn_dom): {np.unique(y_syn_dom)}')\n","\n","            # Load Dp data\n","            x_dp_dom, y_dp_dom, k_dp_dom = get_data(dataset, 'dp', src_class, domain)\n","            print(f'x_dp_dom.shape: {x_dp_dom.shape} | np.unique(y_dp_dom): {np.unique(y_dp_dom)}\\n')\n","\n","\n","            y0_indices_syn = np.where(y_syn_dom == 0)[0]\n","            y0_indices_dp = np.where(y_dp_dom == 0)[0]\n","            assert np.array_equal(y0_indices_syn, y0_indices_dp), \"Labels do not match\"\n","            assert np.array_equal(y_syn_dom[y0_indices_syn], y_dp_dom[y0_indices_dp]), \"Labels do not match\"\n","\n","            y0_indices_train, y0_indices_test = train_test_split(y0_indices_syn, test_size=0.5, shuffle=True, random_state=seed)\n","\n","            x_syn_dom_y0, y_syn_dom_y0 = x_syn_dom[y0_indices_train], y_syn_dom[y0_indices_train]\n","            x_dp_dom_y0, y_dp_dom_y0 = x_dp_dom[y0_indices_test], y_dp_dom[y0_indices_test]\n","\n","            x_syn_dom = np.concatenate([x_syn_dom_y0, x_syn_dom[y_syn_dom != 0]])\n","            y_syn_dom = np.concatenate([y_syn_dom_y0, y_syn_dom[y_syn_dom != 0]])\n","            x_dp_dom = np.concatenate([x_dp_dom_y0, x_dp_dom[y_dp_dom != 0]])\n","            y_dp_dom = np.concatenate([y_dp_dom_y0, y_dp_dom[y_dp_dom != 0]])\n","\n","            print(f'x_syn_dom.shape: {x_syn_dom.shape} | np.unique(y_syn_dom): {np.unique(y_syn_dom)}')\n","            print(f'x_dp_dom.shape: {x_dp_dom.shape} | np.unique(y_dp_dom): {np.unique(y_dp_dom)}\\n')\n","\n","            # Train on synthetic data and evaluate on Dp data\n","            print('Training on synthetic data...')\n","            acc, loss, f1 = train_and_test(x_syn_dom, y_syn_dom, x_dp_dom, y_dp_dom, dataset, num_epochs=num_epochs)\n","            save_scores(src_class, domain, acc, loss, f1, 'Syn', dataset)\n","            accs.append(acc)\n","            f1s.append(f1)\n","            print(f'Source class: {src_class} | Domain: {domain} | Accuracy: {acc:.4f} | Loss: {loss:.4f} | F1: {f1:.4f}\\n')\n","\n","    print(f\"Mean accuracy: {np.mean(accs):.4f} +- {np.std(accs):.4f}\")\n","    print(f\"Mean F1: {np.mean(f1s):.4f} +- {np.std(f1s):.4f}\\n\")\n","\n","\n","\n","compute_TSTR_Syn('realworld_mobiact')"]},{"cell_type":"code","execution_count":6,"metadata":{"executionInfo":{"elapsed":662984,"status":"ok","timestamp":1732699330931,"user":{"displayName":"Pietro Pietro","userId":"08339472013712676764"},"user_tz":-60},"id":"iKHIjEk_0q0O","colab":{"base_uri":"https://localhost:8080/"},"outputId":"09b46064-6a8b-4a00-a613-12a1c1d25766"},"outputs":[{"output_type":"stream","name":"stdout","text":["Source class: WAL\n","\n","Domain: 15\n","x_syn_dom.shape: (444, 3, 128) | np.unique(y_syn_dom): [0 1 2 3]\n","x_dp_dom.shape: (161, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","x_syn_dom.shape: (388, 3, 128) | np.unique(y_syn_dom): [0 1 2 3]\n","x_dp_dom.shape: (106, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Training on synthetic data...\n","\tEpoch 10/100 - Train loss: 0.5224 - Val accuracy: 0.2949 - Val loss: 5.6096 - Val F1: 0.1343 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.2376 - Val accuracy: 0.3077 - Val loss: 2.7153 - Val F1: 0.1625 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.1604 - Val accuracy: 0.2949 - Val loss: 4.8973 - Val F1: 0.1384 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.0854 - Val accuracy: 0.3333 - Val loss: 3.5303 - Val F1: 0.1973 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.0699 - Val accuracy: 0.4231 - Val loss: 2.8910 - Val F1: 0.3393 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.0428 - Val accuracy: 0.5000 - Val loss: 2.9469 - Val F1: 0.4246 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0504 - Val accuracy: 0.4744 - Val loss: 3.2024 - Val F1: 0.3934 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0559 - Val accuracy: 0.4615 - Val loss: 2.9339 - Val F1: 0.3857 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0388 - Val accuracy: 0.3333 - Val loss: 3.9240 - Val F1: 0.2020 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0597 - Val accuracy: 0.3205 - Val loss: 4.7633 - Val F1: 0.1794 - LR: 0.00e+00\n","\tBest epoch: 2 - Best val accuracy: 0.2949 - Best val loss: 1.2633 - Best val F1: 0.1775\n","\n","Source class: WAL | Domain: 15 | Accuracy: 0.3113 | Loss: 3.2140 | F1: 0.1987\n","\n","Domain: 16\n","x_syn_dom.shape: (444, 3, 128) | np.unique(y_syn_dom): [0 1 2 3]\n","x_dp_dom.shape: (165, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","x_syn_dom.shape: (388, 3, 128) | np.unique(y_syn_dom): [0 1 2 3]\n","x_dp_dom.shape: (110, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Training on synthetic data...\n","\tEpoch 10/100 - Train loss: 0.5595 - Val accuracy: 0.5385 - Val loss: 1.5912 - Val F1: 0.4022 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.2437 - Val accuracy: 0.5769 - Val loss: 2.1480 - Val F1: 0.4560 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.2054 - Val accuracy: 0.5769 - Val loss: 4.9394 - Val F1: 0.4560 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.1618 - Val accuracy: 0.5128 - Val loss: 2.2777 - Val F1: 0.3770 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.1397 - Val accuracy: 0.4615 - Val loss: 2.7686 - Val F1: 0.3330 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.1067 - Val accuracy: 0.2949 - Val loss: 3.1804 - Val F1: 0.1343 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.1117 - Val accuracy: 0.2949 - Val loss: 3.4241 - Val F1: 0.1343 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.1205 - Val accuracy: 0.2949 - Val loss: 2.6794 - Val F1: 0.1343 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.1770 - Val accuracy: 0.2949 - Val loss: 3.2051 - Val F1: 0.1343 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0757 - Val accuracy: 0.2949 - Val loss: 3.6861 - Val F1: 0.1343 - LR: 0.00e+00\n","\tBest epoch: 14 - Best val accuracy: 0.5385 - Best val loss: 0.9644 - Best val F1: 0.4118\n","\n","Source class: WAL | Domain: 16 | Accuracy: 0.2727 | Loss: 4.5264 | F1: 0.1443\n","\n","Domain: 17\n","x_syn_dom.shape: (444, 3, 128) | np.unique(y_syn_dom): [0 1 2 3]\n","x_dp_dom.shape: (164, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","x_syn_dom.shape: (388, 3, 128) | np.unique(y_syn_dom): [0 1 2 3]\n","x_dp_dom.shape: (109, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Training on synthetic data...\n","\tEpoch 10/100 - Train loss: 0.5390 - Val accuracy: 0.5897 - Val loss: 0.8751 - Val F1: 0.4827 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.2433 - Val accuracy: 0.8333 - Val loss: 0.5145 - Val F1: 0.8239 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.1296 - Val accuracy: 0.7051 - Val loss: 0.8558 - Val F1: 0.6211 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.1241 - Val accuracy: 0.4359 - Val loss: 3.3545 - Val F1: 0.3419 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.0818 - Val accuracy: 0.7051 - Val loss: 2.2047 - Val F1: 0.6070 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.0404 - Val accuracy: 0.6026 - Val loss: 2.3084 - Val F1: 0.5037 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0755 - Val accuracy: 0.4359 - Val loss: 3.2240 - Val F1: 0.3419 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0516 - Val accuracy: 0.5769 - Val loss: 2.5176 - Val F1: 0.4560 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0379 - Val accuracy: 0.7051 - Val loss: 2.2750 - Val F1: 0.6089 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.1114 - Val accuracy: 0.5128 - Val loss: 2.8638 - Val F1: 0.4642 - LR: 0.00e+00\n","\tBest epoch: 22 - Best val accuracy: 0.8590 - Best val loss: 0.4504 - Best val F1: 0.8500\n","\n","Source class: WAL | Domain: 17 | Accuracy: 0.7431 | Loss: 1.6668 | F1: 0.6955\n","\n","Domain: 18\n","x_syn_dom.shape: (448, 3, 128) | np.unique(y_syn_dom): [0 1 2 3]\n","x_dp_dom.shape: (166, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","x_syn_dom.shape: (392, 3, 128) | np.unique(y_syn_dom): [0 1 2 3]\n","x_dp_dom.shape: (110, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Training on synthetic data...\n","\tEpoch 10/100 - Train loss: 0.4336 - Val accuracy: 0.2911 - Val loss: 3.8706 - Val F1: 0.1313 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.2150 - Val accuracy: 0.2911 - Val loss: 5.5149 - Val F1: 0.1313 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.1123 - Val accuracy: 0.2911 - Val loss: 6.2127 - Val F1: 0.1313 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.0781 - Val accuracy: 0.2911 - Val loss: 3.7273 - Val F1: 0.1614 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.0414 - Val accuracy: 0.2911 - Val loss: 7.7894 - Val F1: 0.1313 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.0327 - Val accuracy: 0.2911 - Val loss: 8.2402 - Val F1: 0.1313 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0293 - Val accuracy: 0.2911 - Val loss: 8.5749 - Val F1: 0.1313 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0639 - Val accuracy: 0.2911 - Val loss: 6.7298 - Val F1: 0.1522 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0416 - Val accuracy: 0.2911 - Val loss: 8.1526 - Val F1: 0.1353 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0532 - Val accuracy: 0.2911 - Val loss: 6.7376 - Val F1: 0.1695 - LR: 0.00e+00\n","\tBest epoch: 3 - Best val accuracy: 0.3165 - Best val loss: 1.1271 - Best val F1: 0.1933\n","\n","Source class: WAL | Domain: 18 | Accuracy: 0.2545 | Loss: 3.1765 | F1: 0.1273\n","\n","Domain: 19\n","x_syn_dom.shape: (444, 3, 128) | np.unique(y_syn_dom): [0 1 2 3]\n","x_dp_dom.shape: (165, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","x_syn_dom.shape: (388, 3, 128) | np.unique(y_syn_dom): [0 1 2 3]\n","x_dp_dom.shape: (110, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Training on synthetic data...\n","\tEpoch 10/100 - Train loss: 0.3559 - Val accuracy: 0.6026 - Val loss: 0.7379 - Val F1: 0.5074 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.1737 - Val accuracy: 0.5641 - Val loss: 0.7904 - Val F1: 0.4129 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.0871 - Val accuracy: 0.5769 - Val loss: 2.7800 - Val F1: 0.4560 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.0816 - Val accuracy: 0.5769 - Val loss: 3.2008 - Val F1: 0.4560 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.0442 - Val accuracy: 0.5769 - Val loss: 3.2829 - Val F1: 0.4560 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.0138 - Val accuracy: 0.5769 - Val loss: 3.8201 - Val F1: 0.4560 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0408 - Val accuracy: 0.5769 - Val loss: 3.7518 - Val F1: 0.4560 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0824 - Val accuracy: 0.5769 - Val loss: 3.0851 - Val F1: 0.4560 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0349 - Val accuracy: 0.5769 - Val loss: 3.6315 - Val F1: 0.4560 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0165 - Val accuracy: 0.5769 - Val loss: 3.8122 - Val F1: 0.4560 - LR: 0.00e+00\n","\tBest epoch: 11 - Best val accuracy: 0.8590 - Best val loss: 0.6190 - Best val F1: 0.7963\n","\n","Source class: WAL | Domain: 19 | Accuracy: 0.3727 | Loss: 6.0865 | F1: 0.2869\n","\n","Domain: 20\n","x_syn_dom.shape: (444, 3, 128) | np.unique(y_syn_dom): [0 1 2 3]\n","x_dp_dom.shape: (162, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","x_syn_dom.shape: (388, 3, 128) | np.unique(y_syn_dom): [0 1 2 3]\n","x_dp_dom.shape: (107, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Training on synthetic data...\n","\tEpoch 10/100 - Train loss: 0.4911 - Val accuracy: 0.2949 - Val loss: 6.3706 - Val F1: 0.1343 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.3430 - Val accuracy: 0.2949 - Val loss: 8.0795 - Val F1: 0.1343 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.0992 - Val accuracy: 0.2949 - Val loss: 7.2160 - Val F1: 0.1343 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.1090 - Val accuracy: 0.2949 - Val loss: 7.8679 - Val F1: 0.1343 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.1030 - Val accuracy: 0.2949 - Val loss: 9.2027 - Val F1: 0.1343 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.0938 - Val accuracy: 0.2949 - Val loss: 9.3008 - Val F1: 0.1343 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0786 - Val accuracy: 0.2949 - Val loss: 9.0242 - Val F1: 0.1343 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0600 - Val accuracy: 0.2949 - Val loss: 9.1181 - Val F1: 0.1343 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0367 - Val accuracy: 0.2949 - Val loss: 11.0812 - Val F1: 0.1343 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0833 - Val accuracy: 0.2949 - Val loss: 9.4148 - Val F1: 0.1343 - LR: 0.00e+00\n","\tBest epoch: 2 - Best val accuracy: 0.3718 - Best val loss: 1.2373 - Best val F1: 0.2967\n","\n","Source class: WAL | Domain: 20 | Accuracy: 0.2617 | Loss: 9.5168 | F1: 0.1085\n","\n","Domain: 21\n","x_syn_dom.shape: (448, 3, 128) | np.unique(y_syn_dom): [0 1 2 3]\n","x_dp_dom.shape: (159, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","x_syn_dom.shape: (392, 3, 128) | np.unique(y_syn_dom): [0 1 2 3]\n","x_dp_dom.shape: (103, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Training on synthetic data...\n","\tEpoch 10/100 - Train loss: 0.4075 - Val accuracy: 0.3291 - Val loss: 1.4881 - Val F1: 0.2039 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.1842 - Val accuracy: 0.2911 - Val loss: 3.1337 - Val F1: 0.1313 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.1073 - Val accuracy: 0.2911 - Val loss: 5.8451 - Val F1: 0.1313 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.0787 - Val accuracy: 0.2911 - Val loss: 8.3479 - Val F1: 0.1313 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.1144 - Val accuracy: 0.2911 - Val loss: 8.2477 - Val F1: 0.1313 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.0391 - Val accuracy: 0.2911 - Val loss: 7.7770 - Val F1: 0.1313 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0347 - Val accuracy: 0.2911 - Val loss: 8.5347 - Val F1: 0.1313 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0289 - Val accuracy: 0.2911 - Val loss: 9.0520 - Val F1: 0.1313 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0651 - Val accuracy: 0.2911 - Val loss: 10.3353 - Val F1: 0.1313 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0198 - Val accuracy: 0.2911 - Val loss: 8.9132 - Val F1: 0.1313 - LR: 0.00e+00\n","\tBest epoch: 3 - Best val accuracy: 0.4177 - Best val loss: 1.0288 - Best val F1: 0.2981\n","\n","Source class: WAL | Domain: 21 | Accuracy: 0.2718 | Loss: 7.0464 | F1: 0.1162\n","\n","Domain: 22\n","x_syn_dom.shape: (444, 3, 128) | np.unique(y_syn_dom): [0 1 2 3]\n","x_dp_dom.shape: (165, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","x_syn_dom.shape: (388, 3, 128) | np.unique(y_syn_dom): [0 1 2 3]\n","x_dp_dom.shape: (110, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Training on synthetic data...\n","\tEpoch 10/100 - Train loss: 0.4501 - Val accuracy: 0.2949 - Val loss: 6.3617 - Val F1: 0.1343 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.1506 - Val accuracy: 0.2949 - Val loss: 9.4333 - Val F1: 0.1343 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.0729 - Val accuracy: 0.2949 - Val loss: 9.1195 - Val F1: 0.1343 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.0643 - Val accuracy: 0.2949 - Val loss: 8.5257 - Val F1: 0.1343 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.0561 - Val accuracy: 0.2949 - Val loss: 12.5122 - Val F1: 0.1343 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.0378 - Val accuracy: 0.2949 - Val loss: 14.2690 - Val F1: 0.1343 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0362 - Val accuracy: 0.2949 - Val loss: 13.1650 - Val F1: 0.1343 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0535 - Val accuracy: 0.2949 - Val loss: 12.9307 - Val F1: 0.1343 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0311 - Val accuracy: 0.2949 - Val loss: 11.7205 - Val F1: 0.1343 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0290 - Val accuracy: 0.2949 - Val loss: 12.3982 - Val F1: 0.1343 - LR: 0.00e+00\n","\tBest epoch: 2 - Best val accuracy: 0.6667 - Best val loss: 1.0945 - Best val F1: 0.5840\n","\n","Source class: WAL | Domain: 22 | Accuracy: 0.2545 | Loss: 9.5957 | F1: 0.1033\n","\n","Domain: 23\n","x_syn_dom.shape: (448, 3, 128) | np.unique(y_syn_dom): [0 1 2 3]\n","x_dp_dom.shape: (164, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","x_syn_dom.shape: (392, 3, 128) | np.unique(y_syn_dom): [0 1 2 3]\n","x_dp_dom.shape: (108, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Training on synthetic data...\n","\tEpoch 10/100 - Train loss: 0.3137 - Val accuracy: 0.2911 - Val loss: 2.5489 - Val F1: 0.1381 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.1725 - Val accuracy: 0.3038 - Val loss: 2.8106 - Val F1: 0.1823 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.0880 - Val accuracy: 0.2911 - Val loss: 3.5967 - Val F1: 0.1410 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.0779 - Val accuracy: 0.3038 - Val loss: 2.9668 - Val F1: 0.1918 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.0769 - Val accuracy: 0.2911 - Val loss: 3.1201 - Val F1: 0.1367 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.0362 - Val accuracy: 0.2911 - Val loss: 3.3525 - Val F1: 0.1717 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0677 - Val accuracy: 0.2911 - Val loss: 2.6124 - Val F1: 0.1539 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0334 - Val accuracy: 0.2911 - Val loss: 2.7638 - Val F1: 0.1381 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0283 - Val accuracy: 0.2911 - Val loss: 3.8770 - Val F1: 0.1594 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0622 - Val accuracy: 0.3291 - Val loss: 4.0438 - Val F1: 0.2461 - LR: 0.00e+00\n","\tBest epoch: 3 - Best val accuracy: 0.5570 - Best val loss: 0.9466 - Best val F1: 0.4162\n","\n","Source class: WAL | Domain: 23 | Accuracy: 0.3796 | Loss: 3.0189 | F1: 0.2917\n","\n","Domain: 24\n","x_syn_dom.shape: (444, 3, 128) | np.unique(y_syn_dom): [0 1 2 3]\n","x_dp_dom.shape: (162, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","x_syn_dom.shape: (388, 3, 128) | np.unique(y_syn_dom): [0 1 2 3]\n","x_dp_dom.shape: (107, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Training on synthetic data...\n","\tEpoch 10/100 - Train loss: 0.4417 - Val accuracy: 0.5769 - Val loss: 1.2989 - Val F1: 0.4560 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.1966 - Val accuracy: 0.5769 - Val loss: 1.1363 - Val F1: 0.4560 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.0847 - Val accuracy: 0.6026 - Val loss: 1.0226 - Val F1: 0.5033 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.0871 - Val accuracy: 0.5769 - Val loss: 1.7660 - Val F1: 0.4560 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.0722 - Val accuracy: 0.5769 - Val loss: 2.3510 - Val F1: 0.4560 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.0242 - Val accuracy: 0.5769 - Val loss: 3.0864 - Val F1: 0.4560 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0271 - Val accuracy: 0.5769 - Val loss: 2.4556 - Val F1: 0.4560 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0335 - Val accuracy: 0.5769 - Val loss: 2.6498 - Val F1: 0.4560 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0291 - Val accuracy: 0.5769 - Val loss: 2.9448 - Val F1: 0.4560 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.1388 - Val accuracy: 0.5769 - Val loss: 1.8296 - Val F1: 0.4560 - LR: 0.00e+00\n","\tBest epoch: 22 - Best val accuracy: 0.8205 - Best val loss: 0.7163 - Best val F1: 0.7677\n","\n","Source class: WAL | Domain: 24 | Accuracy: 0.3925 | Loss: 4.4324 | F1: 0.3350\n","\n","Domain: 25\n","x_syn_dom.shape: (448, 3, 128) | np.unique(y_syn_dom): [0 1 2 3]\n","x_dp_dom.shape: (166, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","x_syn_dom.shape: (392, 3, 128) | np.unique(y_syn_dom): [0 1 2 3]\n","x_dp_dom.shape: (110, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Training on synthetic data...\n","\tEpoch 10/100 - Train loss: 0.4576 - Val accuracy: 0.2911 - Val loss: 5.9494 - Val F1: 0.1313 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.1100 - Val accuracy: 0.2911 - Val loss: 3.5183 - Val F1: 0.1313 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.0919 - Val accuracy: 0.2911 - Val loss: 4.3135 - Val F1: 0.1313 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.0793 - Val accuracy: 0.2911 - Val loss: 4.6766 - Val F1: 0.1313 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.0430 - Val accuracy: 0.2911 - Val loss: 6.5361 - Val F1: 0.1313 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.0362 - Val accuracy: 0.2911 - Val loss: 6.2004 - Val F1: 0.1313 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0590 - Val accuracy: 0.2911 - Val loss: 5.6240 - Val F1: 0.1313 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0306 - Val accuracy: 0.2911 - Val loss: 6.2973 - Val F1: 0.1313 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0369 - Val accuracy: 0.2911 - Val loss: 5.1492 - Val F1: 0.1313 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0455 - Val accuracy: 0.2911 - Val loss: 7.3705 - Val F1: 0.1313 - LR: 0.00e+00\n","\tBest epoch: 2 - Best val accuracy: 0.3797 - Best val loss: 1.2390 - Best val F1: 0.2887\n","\n","Source class: WAL | Domain: 25 | Accuracy: 0.2545 | Loss: 6.2447 | F1: 0.1088\n","\n","Domain: 26\n","x_syn_dom.shape: (444, 3, 128) | np.unique(y_syn_dom): [0 1 2 3]\n","x_dp_dom.shape: (153, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","x_syn_dom.shape: (388, 3, 128) | np.unique(y_syn_dom): [0 1 2 3]\n","x_dp_dom.shape: (98, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Training on synthetic data...\n","\tEpoch 10/100 - Train loss: 0.3541 - Val accuracy: 0.3974 - Val loss: 0.9853 - Val F1: 0.3077 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.1548 - Val accuracy: 0.7564 - Val loss: 0.5053 - Val F1: 0.7112 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.0914 - Val accuracy: 0.6410 - Val loss: 1.1590 - Val F1: 0.5717 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.0954 - Val accuracy: 0.6154 - Val loss: 1.2608 - Val F1: 0.5303 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.0518 - Val accuracy: 0.6282 - Val loss: 1.3113 - Val F1: 0.5517 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.0234 - Val accuracy: 0.6026 - Val loss: 1.3876 - Val F1: 0.5074 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0191 - Val accuracy: 0.7564 - Val loss: 0.9835 - Val F1: 0.7112 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0626 - Val accuracy: 0.6410 - Val loss: 1.0237 - Val F1: 0.5717 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0249 - Val accuracy: 0.7308 - Val loss: 0.9831 - Val F1: 0.6849 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0842 - Val accuracy: 0.6026 - Val loss: 1.3356 - Val F1: 0.5074 - LR: 0.00e+00\n","\tBest epoch: 13 - Best val accuracy: 0.8590 - Best val loss: 0.3737 - Best val F1: 0.8026\n","\n","Source class: WAL | Domain: 26 | Accuracy: 0.3367 | Loss: 2.9329 | F1: 0.2783\n","\n","Domain: 27\n","x_syn_dom.shape: (444, 3, 128) | np.unique(y_syn_dom): [0 1 2 3]\n","x_dp_dom.shape: (165, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","x_syn_dom.shape: (388, 3, 128) | np.unique(y_syn_dom): [0 1 2 3]\n","x_dp_dom.shape: (110, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Training on synthetic data...\n","\tEpoch 10/100 - Train loss: 0.4930 - Val accuracy: 0.2949 - Val loss: 5.1768 - Val F1: 0.1343 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.2028 - Val accuracy: 0.4359 - Val loss: 5.2559 - Val F1: 0.3363 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.1192 - Val accuracy: 0.4359 - Val loss: 6.4764 - Val F1: 0.3419 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.0645 - Val accuracy: 0.4359 - Val loss: 7.7903 - Val F1: 0.3419 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.0547 - Val accuracy: 0.4359 - Val loss: 7.1578 - Val F1: 0.3419 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.0471 - Val accuracy: 0.4359 - Val loss: 5.3578 - Val F1: 0.3419 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0244 - Val accuracy: 0.4359 - Val loss: 6.6164 - Val F1: 0.3419 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0363 - Val accuracy: 0.4359 - Val loss: 7.7913 - Val F1: 0.3419 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0150 - Val accuracy: 0.4359 - Val loss: 9.9609 - Val F1: 0.3419 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0125 - Val accuracy: 0.4359 - Val loss: 8.9640 - Val F1: 0.3419 - LR: 0.00e+00\n","\tBest epoch: 2 - Best val accuracy: 0.5769 - Best val loss: 1.0746 - Best val F1: 0.4560\n","\n","Source class: WAL | Domain: 27 | Accuracy: 0.7364 | Loss: 3.9674 | F1: 0.6445\n","\n","Domain: 28\n","x_syn_dom.shape: (444, 3, 128) | np.unique(y_syn_dom): [0 1 2 3]\n","x_dp_dom.shape: (153, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","x_syn_dom.shape: (388, 3, 128) | np.unique(y_syn_dom): [0 1 2 3]\n","x_dp_dom.shape: (98, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Training on synthetic data...\n","\tEpoch 10/100 - Train loss: 0.5131 - Val accuracy: 0.2949 - Val loss: 4.3851 - Val F1: 0.1343 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.1633 - Val accuracy: 0.2949 - Val loss: 3.4047 - Val F1: 0.1343 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.0687 - Val accuracy: 0.3846 - Val loss: 1.5464 - Val F1: 0.2966 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.0648 - Val accuracy: 0.2949 - Val loss: 2.9518 - Val F1: 0.1343 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.0350 - Val accuracy: 0.4103 - Val loss: 2.1362 - Val F1: 0.3112 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.0219 - Val accuracy: 0.5769 - Val loss: 1.6638 - Val F1: 0.4279 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0787 - Val accuracy: 0.5256 - Val loss: 1.9103 - Val F1: 0.4057 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0270 - Val accuracy: 0.3462 - Val loss: 2.5586 - Val F1: 0.2266 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0420 - Val accuracy: 0.5769 - Val loss: 2.0854 - Val F1: 0.4260 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0187 - Val accuracy: 0.5769 - Val loss: 2.1694 - Val F1: 0.4241 - LR: 0.00e+00\n","\tBest epoch: 2 - Best val accuracy: 0.3846 - Best val loss: 1.1008 - Best val F1: 0.2873\n","\n","Source class: WAL | Domain: 28 | Accuracy: 0.3265 | Loss: 3.3893 | F1: 0.1737\n","\n","Domain: 29\n","x_syn_dom.shape: (444, 3, 128) | np.unique(y_syn_dom): [0 1 2 3]\n","x_dp_dom.shape: (153, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","x_syn_dom.shape: (388, 3, 128) | np.unique(y_syn_dom): [0 1 2 3]\n","x_dp_dom.shape: (98, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Training on synthetic data...\n","\tEpoch 10/100 - Train loss: 0.3418 - Val accuracy: 0.4872 - Val loss: 2.4151 - Val F1: 0.3604 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.1754 - Val accuracy: 0.5769 - Val loss: 3.0855 - Val F1: 0.4560 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.0591 - Val accuracy: 0.5769 - Val loss: 3.8119 - Val F1: 0.4383 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.0349 - Val accuracy: 0.5769 - Val loss: 3.1259 - Val F1: 0.4445 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.0465 - Val accuracy: 0.5769 - Val loss: 2.7434 - Val F1: 0.4383 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.0355 - Val accuracy: 0.3077 - Val loss: 3.1703 - Val F1: 0.1827 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0431 - Val accuracy: 0.6026 - Val loss: 2.0558 - Val F1: 0.5531 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0225 - Val accuracy: 0.4615 - Val loss: 2.6056 - Val F1: 0.3390 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0311 - Val accuracy: 0.6795 - Val loss: 1.5226 - Val F1: 0.6182 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0298 - Val accuracy: 0.2949 - Val loss: 2.9054 - Val F1: 0.1541 - LR: 0.00e+00\n","\tBest epoch: 2 - Best val accuracy: 0.2821 - Best val loss: 1.3226 - Best val F1: 0.1477\n","\n","Source class: WAL | Domain: 29 | Accuracy: 0.3878 | Loss: 5.4960 | F1: 0.2535\n","\n","Domain: 30\n","x_syn_dom.shape: (444, 3, 128) | np.unique(y_syn_dom): [0 1 2 3]\n","x_dp_dom.shape: (161, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","x_syn_dom.shape: (388, 3, 128) | np.unique(y_syn_dom): [0 1 2 3]\n","x_dp_dom.shape: (106, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Training on synthetic data...\n","\tEpoch 10/100 - Train loss: 0.5148 - Val accuracy: 0.8205 - Val loss: 0.6138 - Val F1: 0.7664 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.2535 - Val accuracy: 0.8077 - Val loss: 0.6680 - Val F1: 0.7822 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.2355 - Val accuracy: 0.7564 - Val loss: 0.6619 - Val F1: 0.7365 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.1801 - Val accuracy: 0.7821 - Val loss: 0.7479 - Val F1: 0.7688 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.1370 - Val accuracy: 0.7821 - Val loss: 0.7078 - Val F1: 0.7781 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.1208 - Val accuracy: 0.6923 - Val loss: 0.9864 - Val F1: 0.6919 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.1338 - Val accuracy: 0.7821 - Val loss: 0.5895 - Val F1: 0.7767 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.1158 - Val accuracy: 0.6667 - Val loss: 1.0305 - Val F1: 0.6573 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0830 - Val accuracy: 0.7436 - Val loss: 0.7072 - Val F1: 0.7325 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0726 - Val accuracy: 0.7179 - Val loss: 0.8845 - Val F1: 0.7289 - LR: 0.00e+00\n","\tBest epoch: 70 - Best val accuracy: 0.7821 - Best val loss: 0.5895 - Best val F1: 0.7767\n","\n","Source class: WAL | Domain: 30 | Accuracy: 0.5283 | Loss: 2.2486 | F1: 0.5083\n","\n","Domain: 31\n","x_syn_dom.shape: (444, 3, 128) | np.unique(y_syn_dom): [0 1 2 3]\n","x_dp_dom.shape: (154, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","x_syn_dom.shape: (388, 3, 128) | np.unique(y_syn_dom): [0 1 2 3]\n","x_dp_dom.shape: (99, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Training on synthetic data...\n","\tEpoch 10/100 - Train loss: 0.1348 - Val accuracy: 0.7949 - Val loss: 0.6433 - Val F1: 0.7371 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.0844 - Val accuracy: 0.6154 - Val loss: 0.6928 - Val F1: 0.5026 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.1355 - Val accuracy: 0.8846 - Val loss: 0.2941 - Val F1: 0.8791 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.0223 - Val accuracy: 0.8718 - Val loss: 0.3583 - Val F1: 0.8676 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.0263 - Val accuracy: 0.9487 - Val loss: 0.2218 - Val F1: 0.9484 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.0239 - Val accuracy: 0.9359 - Val loss: 0.1785 - Val F1: 0.9351 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0106 - Val accuracy: 0.9872 - Val loss: 0.1037 - Val F1: 0.9870 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0748 - Val accuracy: 0.8462 - Val loss: 0.2687 - Val F1: 0.8041 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0180 - Val accuracy: 0.9359 - Val loss: 0.2047 - Val F1: 0.9353 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0189 - Val accuracy: 0.9744 - Val loss: 0.1096 - Val F1: 0.9743 - LR: 0.00e+00\n","\tBest epoch: 69 - Best val accuracy: 0.9872 - Best val loss: 0.0765 - Best val F1: 0.9872\n","\n","Source class: WAL | Domain: 31 | Accuracy: 0.8586 | Loss: 0.6692 | F1: 0.8011\n","\n","Domain: 32\n","x_syn_dom.shape: (444, 3, 128) | np.unique(y_syn_dom): [0 1 2 3]\n","x_dp_dom.shape: (163, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","x_syn_dom.shape: (388, 3, 128) | np.unique(y_syn_dom): [0 1 2 3]\n","x_dp_dom.shape: (108, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Training on synthetic data...\n","\tEpoch 10/100 - Train loss: 0.5435 - Val accuracy: 0.4359 - Val loss: 2.3984 - Val F1: 0.3311 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.2364 - Val accuracy: 0.4359 - Val loss: 3.7301 - Val F1: 0.3011 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.1261 - Val accuracy: 0.4359 - Val loss: 4.4777 - Val F1: 0.3261 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.0822 - Val accuracy: 0.4359 - Val loss: 7.7221 - Val F1: 0.3419 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.0912 - Val accuracy: 0.4359 - Val loss: 7.7556 - Val F1: 0.3419 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.0482 - Val accuracy: 0.4359 - Val loss: 7.3277 - Val F1: 0.3419 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0653 - Val accuracy: 0.4359 - Val loss: 6.4977 - Val F1: 0.3419 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0550 - Val accuracy: 0.4359 - Val loss: 10.5287 - Val F1: 0.3419 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0931 - Val accuracy: 0.4359 - Val loss: 10.3361 - Val F1: 0.3419 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0270 - Val accuracy: 0.4359 - Val loss: 9.8183 - Val F1: 0.3419 - LR: 0.00e+00\n","\tBest epoch: 3 - Best val accuracy: 0.3590 - Best val loss: 1.0454 - Best val F1: 0.2453\n","\n","Source class: WAL | Domain: 32 | Accuracy: 0.7315 | Loss: 3.4483 | F1: 0.6457\n","\n","Domain: 33\n","x_syn_dom.shape: (448, 3, 128) | np.unique(y_syn_dom): [0 1 2 3]\n","x_dp_dom.shape: (156, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","x_syn_dom.shape: (392, 3, 128) | np.unique(y_syn_dom): [0 1 2 3]\n","x_dp_dom.shape: (100, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Training on synthetic data...\n","\tEpoch 10/100 - Train loss: 0.4367 - Val accuracy: 0.2911 - Val loss: 4.7244 - Val F1: 0.1313 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.1427 - Val accuracy: 0.3418 - Val loss: 2.6653 - Val F1: 0.2327 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.0760 - Val accuracy: 0.2911 - Val loss: 4.3397 - Val F1: 0.1522 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.0674 - Val accuracy: 0.2911 - Val loss: 4.6789 - Val F1: 0.1594 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.0133 - Val accuracy: 0.2911 - Val loss: 4.7885 - Val F1: 0.1539 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.0289 - Val accuracy: 0.2911 - Val loss: 4.5127 - Val F1: 0.1472 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0319 - Val accuracy: 0.2911 - Val loss: 3.6830 - Val F1: 0.1594 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0340 - Val accuracy: 0.2911 - Val loss: 4.1794 - Val F1: 0.1653 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0278 - Val accuracy: 0.3291 - Val loss: 4.6115 - Val F1: 0.2024 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0174 - Val accuracy: 0.2911 - Val loss: 5.0181 - Val F1: 0.1653 - LR: 0.00e+00\n","\tBest epoch: 2 - Best val accuracy: 0.4810 - Best val loss: 1.1969 - Best val F1: 0.4513\n","\n","Source class: WAL | Domain: 33 | Accuracy: 0.2900 | Loss: 2.7478 | F1: 0.1499\n","\n","Domain: 34\n","x_syn_dom.shape: (448, 3, 128) | np.unique(y_syn_dom): [0 1 2 3]\n","x_dp_dom.shape: (161, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","x_syn_dom.shape: (392, 3, 128) | np.unique(y_syn_dom): [0 1 2 3]\n","x_dp_dom.shape: (105, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Training on synthetic data...\n","\tEpoch 10/100 - Train loss: 0.1371 - Val accuracy: 0.3671 - Val loss: 2.3275 - Val F1: 0.2333 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.0507 - Val accuracy: 0.3671 - Val loss: 1.4899 - Val F1: 0.3081 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.0368 - Val accuracy: 0.3544 - Val loss: 1.6128 - Val F1: 0.3065 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.0344 - Val accuracy: 0.3544 - Val loss: 2.9474 - Val F1: 0.2571 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.0354 - Val accuracy: 0.4051 - Val loss: 2.7384 - Val F1: 0.3026 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.0377 - Val accuracy: 0.4304 - Val loss: 4.2896 - Val F1: 0.2761 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0441 - Val accuracy: 0.4430 - Val loss: 3.6896 - Val F1: 0.3215 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0146 - Val accuracy: 0.4430 - Val loss: 2.9348 - Val F1: 0.3090 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0149 - Val accuracy: 0.4304 - Val loss: 3.6805 - Val F1: 0.2895 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0258 - Val accuracy: 0.4177 - Val loss: 2.7485 - Val F1: 0.2836 - LR: 0.00e+00\n","\tBest epoch: 12 - Best val accuracy: 0.4430 - Best val loss: 1.1428 - Best val F1: 0.4015\n","\n","Source class: WAL | Domain: 34 | Accuracy: 0.6000 | Loss: 2.8775 | F1: 0.5904\n","\n","Domain: 35\n","x_syn_dom.shape: (444, 3, 128) | np.unique(y_syn_dom): [0 1 2 3]\n","x_dp_dom.shape: (159, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","x_syn_dom.shape: (388, 3, 128) | np.unique(y_syn_dom): [0 1 2 3]\n","x_dp_dom.shape: (104, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Training on synthetic data...\n","\tEpoch 10/100 - Train loss: 0.5731 - Val accuracy: 0.2949 - Val loss: 4.0363 - Val F1: 0.1343 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.2669 - Val accuracy: 0.2949 - Val loss: 2.7719 - Val F1: 0.1343 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.1083 - Val accuracy: 0.2949 - Val loss: 3.4046 - Val F1: 0.1343 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.1194 - Val accuracy: 0.2949 - Val loss: 4.1615 - Val F1: 0.1343 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.1083 - Val accuracy: 0.2949 - Val loss: 4.7170 - Val F1: 0.1343 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.0639 - Val accuracy: 0.2949 - Val loss: 4.9329 - Val F1: 0.1343 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0519 - Val accuracy: 0.2949 - Val loss: 5.3506 - Val F1: 0.1343 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0407 - Val accuracy: 0.2949 - Val loss: 4.3379 - Val F1: 0.1343 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0404 - Val accuracy: 0.2949 - Val loss: 5.0213 - Val F1: 0.1343 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0445 - Val accuracy: 0.2949 - Val loss: 5.0023 - Val F1: 0.1343 - LR: 0.00e+00\n","\tBest epoch: 2 - Best val accuracy: 0.5769 - Best val loss: 1.1572 - Best val F1: 0.4560\n","\n","Source class: WAL | Domain: 35 | Accuracy: 0.2692 | Loss: 5.7628 | F1: 0.1142\n","\n","Domain: 36\n","x_syn_dom.shape: (448, 3, 128) | np.unique(y_syn_dom): [0 1 2 3]\n","x_dp_dom.shape: (155, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","x_syn_dom.shape: (392, 3, 128) | np.unique(y_syn_dom): [0 1 2 3]\n","x_dp_dom.shape: (99, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Training on synthetic data...\n","\tEpoch 10/100 - Train loss: 0.4653 - Val accuracy: 0.3165 - Val loss: 1.5336 - Val F1: 0.1904 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.1622 - Val accuracy: 0.2911 - Val loss: 2.7688 - Val F1: 0.1440 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.1031 - Val accuracy: 0.5063 - Val loss: 1.9406 - Val F1: 0.4436 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.0619 - Val accuracy: 0.6709 - Val loss: 2.3645 - Val F1: 0.5725 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.0513 - Val accuracy: 0.5696 - Val loss: 2.3451 - Val F1: 0.4483 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.0745 - Val accuracy: 0.4304 - Val loss: 5.0000 - Val F1: 0.3369 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0401 - Val accuracy: 0.7089 - Val loss: 2.7337 - Val F1: 0.6037 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0707 - Val accuracy: 0.6835 - Val loss: 2.9742 - Val F1: 0.5820 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0309 - Val accuracy: 0.6456 - Val loss: 2.8662 - Val F1: 0.5523 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0310 - Val accuracy: 0.6329 - Val loss: 2.8115 - Val F1: 0.5272 - LR: 0.00e+00\n","\tBest epoch: 17 - Best val accuracy: 0.6835 - Best val loss: 0.6559 - Best val F1: 0.6176\n","\n","Source class: WAL | Domain: 36 | Accuracy: 0.6566 | Loss: 1.4249 | F1: 0.6633\n","\n","Domain: 37\n","x_syn_dom.shape: (448, 3, 128) | np.unique(y_syn_dom): [0 1 2 3]\n","x_dp_dom.shape: (154, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","x_syn_dom.shape: (392, 3, 128) | np.unique(y_syn_dom): [0 1 2 3]\n","x_dp_dom.shape: (98, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Training on synthetic data...\n","\tEpoch 10/100 - Train loss: 0.5270 - Val accuracy: 0.2911 - Val loss: 5.7849 - Val F1: 0.1313 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.2301 - Val accuracy: 0.2911 - Val loss: 5.1307 - Val F1: 0.1313 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.1111 - Val accuracy: 0.5823 - Val loss: 2.8566 - Val F1: 0.4566 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.0781 - Val accuracy: 0.5696 - Val loss: 3.8005 - Val F1: 0.4386 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.1113 - Val accuracy: 0.4937 - Val loss: 2.6264 - Val F1: 0.3620 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.0639 - Val accuracy: 0.3544 - Val loss: 2.4188 - Val F1: 0.2321 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0569 - Val accuracy: 0.2911 - Val loss: 3.9338 - Val F1: 0.1313 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0362 - Val accuracy: 0.2911 - Val loss: 4.4491 - Val F1: 0.1313 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0477 - Val accuracy: 0.6709 - Val loss: 1.3771 - Val F1: 0.5972 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0293 - Val accuracy: 0.3671 - Val loss: 2.0383 - Val F1: 0.2756 - LR: 0.00e+00\n","\tBest epoch: 2 - Best val accuracy: 0.5823 - Best val loss: 1.0980 - Best val F1: 0.4607\n","\n","Source class: WAL | Domain: 37 | Accuracy: 0.2959 | Loss: 5.4391 | F1: 0.1493\n","\n","Domain: 38\n","x_syn_dom.shape: (444, 3, 128) | np.unique(y_syn_dom): [0 1 2 3]\n","x_dp_dom.shape: (158, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","x_syn_dom.shape: (388, 3, 128) | np.unique(y_syn_dom): [0 1 2 3]\n","x_dp_dom.shape: (103, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Training on synthetic data...\n","\tEpoch 10/100 - Train loss: 0.2196 - Val accuracy: 0.3077 - Val loss: 1.5963 - Val F1: 0.1792 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.1244 - Val accuracy: 0.5000 - Val loss: 0.9149 - Val F1: 0.4241 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.0665 - Val accuracy: 0.8462 - Val loss: 0.7047 - Val F1: 0.7876 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.0465 - Val accuracy: 0.8718 - Val loss: 0.5651 - Val F1: 0.8419 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.0609 - Val accuracy: 0.4744 - Val loss: 1.0225 - Val F1: 0.3492 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.0469 - Val accuracy: 0.5000 - Val loss: 0.8310 - Val F1: 0.4145 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0614 - Val accuracy: 0.3590 - Val loss: 1.1342 - Val F1: 0.2646 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0163 - Val accuracy: 0.5000 - Val loss: 0.7531 - Val F1: 0.4603 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0214 - Val accuracy: 0.6026 - Val loss: 0.6822 - Val F1: 0.5628 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0346 - Val accuracy: 0.5641 - Val loss: 0.7197 - Val F1: 0.5276 - LR: 0.00e+00\n","\tBest epoch: 40 - Best val accuracy: 0.8718 - Best val loss: 0.5651 - Best val F1: 0.8419\n","\n","Source class: WAL | Domain: 38 | Accuracy: 0.7864 | Loss: 1.0657 | F1: 0.7965\n","\n","Domain: 39\n","x_syn_dom.shape: (444, 3, 128) | np.unique(y_syn_dom): [0 1 2 3]\n","x_dp_dom.shape: (165, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","x_syn_dom.shape: (388, 3, 128) | np.unique(y_syn_dom): [0 1 2 3]\n","x_dp_dom.shape: (110, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Training on synthetic data...\n","\tEpoch 10/100 - Train loss: 0.5280 - Val accuracy: 0.2949 - Val loss: 4.1531 - Val F1: 0.1343 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.2238 - Val accuracy: 0.2949 - Val loss: 7.6401 - Val F1: 0.1343 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.2293 - Val accuracy: 0.2949 - Val loss: 6.6247 - Val F1: 0.1356 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.0671 - Val accuracy: 0.2949 - Val loss: 9.5291 - Val F1: 0.1343 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.0938 - Val accuracy: 0.2949 - Val loss: 9.6666 - Val F1: 0.1343 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.0578 - Val accuracy: 0.2949 - Val loss: 11.1107 - Val F1: 0.1343 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0300 - Val accuracy: 0.2949 - Val loss: 10.8072 - Val F1: 0.1343 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0412 - Val accuracy: 0.2949 - Val loss: 10.2684 - Val F1: 0.1343 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0603 - Val accuracy: 0.2949 - Val loss: 10.5803 - Val F1: 0.1343 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0721 - Val accuracy: 0.2949 - Val loss: 10.9811 - Val F1: 0.1343 - LR: 0.00e+00\n","\tBest epoch: 2 - Best val accuracy: 0.2949 - Best val loss: 1.2626 - Best val F1: 0.1343\n","\n","Source class: WAL | Domain: 39 | Accuracy: 0.2545 | Loss: 9.9741 | F1: 0.1033\n","\n","Domain: 40\n","x_syn_dom.shape: (444, 3, 128) | np.unique(y_syn_dom): [0 1 2 3]\n","x_dp_dom.shape: (155, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","x_syn_dom.shape: (388, 3, 128) | np.unique(y_syn_dom): [0 1 2 3]\n","x_dp_dom.shape: (100, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Training on synthetic data...\n","\tEpoch 10/100 - Train loss: 0.4759 - Val accuracy: 0.4359 - Val loss: 2.2545 - Val F1: 0.3419 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.2011 - Val accuracy: 0.4359 - Val loss: 4.0529 - Val F1: 0.3419 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.1094 - Val accuracy: 0.4359 - Val loss: 5.4717 - Val F1: 0.3419 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.0532 - Val accuracy: 0.4359 - Val loss: 6.4778 - Val F1: 0.3419 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.0606 - Val accuracy: 0.4359 - Val loss: 7.0005 - Val F1: 0.3419 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.0414 - Val accuracy: 0.4359 - Val loss: 6.4713 - Val F1: 0.3419 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0262 - Val accuracy: 0.4359 - Val loss: 6.4069 - Val F1: 0.3419 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0342 - Val accuracy: 0.4359 - Val loss: 8.2968 - Val F1: 0.3419 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0395 - Val accuracy: 0.4359 - Val loss: 7.2265 - Val F1: 0.3419 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0222 - Val accuracy: 0.4359 - Val loss: 8.0734 - Val F1: 0.3419 - LR: 0.00e+00\n","\tBest epoch: 3 - Best val accuracy: 0.5769 - Best val loss: 0.9986 - Best val F1: 0.4560\n","\n","Source class: WAL | Domain: 40 | Accuracy: 0.8400 | Loss: 2.3611 | F1: 0.7689\n","\n","Domain: 41\n","x_syn_dom.shape: (444, 3, 128) | np.unique(y_syn_dom): [0 1 2 3]\n","x_dp_dom.shape: (156, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","x_syn_dom.shape: (388, 3, 128) | np.unique(y_syn_dom): [0 1 2 3]\n","x_dp_dom.shape: (101, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Training on synthetic data...\n","\tEpoch 10/100 - Train loss: 0.2876 - Val accuracy: 0.3077 - Val loss: 1.6664 - Val F1: 0.2055 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.0940 - Val accuracy: 0.3462 - Val loss: 1.4497 - Val F1: 0.2504 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.1438 - Val accuracy: 0.4103 - Val loss: 1.0334 - Val F1: 0.3362 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.0508 - Val accuracy: 0.2949 - Val loss: 1.4832 - Val F1: 0.2024 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.0859 - Val accuracy: 0.4744 - Val loss: 1.0124 - Val F1: 0.4325 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.0379 - Val accuracy: 0.5769 - Val loss: 0.8789 - Val F1: 0.5316 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0303 - Val accuracy: 0.3590 - Val loss: 1.4382 - Val F1: 0.2755 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0403 - Val accuracy: 0.7179 - Val loss: 0.7014 - Val F1: 0.6565 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0318 - Val accuracy: 0.5769 - Val loss: 0.8797 - Val F1: 0.5521 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0348 - Val accuracy: 0.4103 - Val loss: 1.2603 - Val F1: 0.3171 - LR: 0.00e+00\n","\tBest epoch: 47 - Best val accuracy: 0.6923 - Best val loss: 0.5923 - Best val F1: 0.6770\n","\n","Source class: WAL | Domain: 41 | Accuracy: 0.3861 | Loss: 3.2210 | F1: 0.3232\n","\n","Domain: 42\n","x_syn_dom.shape: (448, 3, 128) | np.unique(y_syn_dom): [0 1 2 3]\n","x_dp_dom.shape: (158, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","x_syn_dom.shape: (392, 3, 128) | np.unique(y_syn_dom): [0 1 2 3]\n","x_dp_dom.shape: (102, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Training on synthetic data...\n","\tEpoch 10/100 - Train loss: 0.3258 - Val accuracy: 0.2911 - Val loss: 5.0893 - Val F1: 0.1313 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.1666 - Val accuracy: 0.2911 - Val loss: 3.5731 - Val F1: 0.1326 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.1058 - Val accuracy: 0.2911 - Val loss: 3.2443 - Val F1: 0.1425 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.0602 - Val accuracy: 0.2911 - Val loss: 4.1111 - Val F1: 0.1313 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.1013 - Val accuracy: 0.2911 - Val loss: 3.5595 - Val F1: 0.1313 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.0570 - Val accuracy: 0.2911 - Val loss: 5.0568 - Val F1: 0.1313 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0374 - Val accuracy: 0.2911 - Val loss: 3.6592 - Val F1: 0.1313 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0416 - Val accuracy: 0.2911 - Val loss: 4.7076 - Val F1: 0.1313 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0507 - Val accuracy: 0.2911 - Val loss: 4.6735 - Val F1: 0.1313 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0369 - Val accuracy: 0.2911 - Val loss: 4.1245 - Val F1: 0.1313 - LR: 0.00e+00\n","\tBest epoch: 2 - Best val accuracy: 0.5823 - Best val loss: 1.1213 - Best val F1: 0.4607\n","\n","Source class: WAL | Domain: 42 | Accuracy: 0.2745 | Loss: 5.8803 | F1: 0.1183\n","\n","Domain: 43\n","x_syn_dom.shape: (444, 3, 128) | np.unique(y_syn_dom): [0 1 2 3]\n","x_dp_dom.shape: (153, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","x_syn_dom.shape: (388, 3, 128) | np.unique(y_syn_dom): [0 1 2 3]\n","x_dp_dom.shape: (98, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Training on synthetic data...\n","\tEpoch 10/100 - Train loss: 0.1463 - Val accuracy: 0.5897 - Val loss: 0.9907 - Val F1: 0.4805 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.0587 - Val accuracy: 0.6410 - Val loss: 0.7237 - Val F1: 0.5764 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.0423 - Val accuracy: 0.6538 - Val loss: 0.7054 - Val F1: 0.5901 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.0281 - Val accuracy: 0.7179 - Val loss: 0.6247 - Val F1: 0.6080 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.0792 - Val accuracy: 0.6538 - Val loss: 0.7945 - Val F1: 0.5735 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.0359 - Val accuracy: 0.7308 - Val loss: 0.7302 - Val F1: 0.6598 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0127 - Val accuracy: 0.7179 - Val loss: 0.5986 - Val F1: 0.6492 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0181 - Val accuracy: 0.6795 - Val loss: 0.6302 - Val F1: 0.6129 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0223 - Val accuracy: 0.7308 - Val loss: 0.5038 - Val F1: 0.6552 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0118 - Val accuracy: 0.7179 - Val loss: 0.6288 - Val F1: 0.6492 - LR: 0.00e+00\n","\tBest epoch: 52 - Best val accuracy: 0.8077 - Best val loss: 0.3350 - Best val F1: 0.7826\n","\n","Source class: WAL | Domain: 43 | Accuracy: 0.8061 | Loss: 0.8585 | F1: 0.7740\n","\n","Domain: 44\n","x_syn_dom.shape: (444, 3, 128) | np.unique(y_syn_dom): [0 1 2 3]\n","x_dp_dom.shape: (153, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","x_syn_dom.shape: (388, 3, 128) | np.unique(y_syn_dom): [0 1 2 3]\n","x_dp_dom.shape: (98, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Training on synthetic data...\n","\tEpoch 10/100 - Train loss: 0.6001 - Val accuracy: 0.2949 - Val loss: 3.5928 - Val F1: 0.1343 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.2684 - Val accuracy: 0.3205 - Val loss: 2.5193 - Val F1: 0.1840 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.1927 - Val accuracy: 0.2949 - Val loss: 5.3939 - Val F1: 0.1343 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.1259 - Val accuracy: 0.2949 - Val loss: 4.7342 - Val F1: 0.1343 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.1050 - Val accuracy: 0.3077 - Val loss: 3.9036 - Val F1: 0.1602 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.0938 - Val accuracy: 0.3333 - Val loss: 4.1774 - Val F1: 0.2061 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0887 - Val accuracy: 0.4231 - Val loss: 3.2949 - Val F1: 0.3153 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0777 - Val accuracy: 0.2949 - Val loss: 5.4973 - Val F1: 0.1343 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0962 - Val accuracy: 0.2949 - Val loss: 5.7633 - Val F1: 0.1343 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0443 - Val accuracy: 0.2949 - Val loss: 6.6771 - Val F1: 0.1343 - LR: 0.00e+00\n","\tBest epoch: 2 - Best val accuracy: 0.2821 - Best val loss: 1.2744 - Best val F1: 0.1241\n","\n","Source class: WAL | Domain: 44 | Accuracy: 0.2857 | Loss: 6.8891 | F1: 0.1270\n","\n","Domain: 45\n","x_syn_dom.shape: (444, 3, 128) | np.unique(y_syn_dom): [0 1 2 3]\n","x_dp_dom.shape: (163, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","x_syn_dom.shape: (388, 3, 128) | np.unique(y_syn_dom): [0 1 2 3]\n","x_dp_dom.shape: (108, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Training on synthetic data...\n","\tEpoch 10/100 - Train loss: 0.5288 - Val accuracy: 0.2949 - Val loss: 6.3359 - Val F1: 0.1343 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.1254 - Val accuracy: 0.2949 - Val loss: 5.9559 - Val F1: 0.1343 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.0647 - Val accuracy: 0.2949 - Val loss: 8.9685 - Val F1: 0.1343 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.1102 - Val accuracy: 0.2949 - Val loss: 11.1711 - Val F1: 0.1343 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.0530 - Val accuracy: 0.3205 - Val loss: 5.2972 - Val F1: 0.2150 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.0378 - Val accuracy: 0.2949 - Val loss: 10.1155 - Val F1: 0.1343 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0173 - Val accuracy: 0.2949 - Val loss: 10.8112 - Val F1: 0.1343 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0758 - Val accuracy: 0.2949 - Val loss: 6.0405 - Val F1: 0.1696 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0485 - Val accuracy: 0.2949 - Val loss: 8.1688 - Val F1: 0.1343 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0108 - Val accuracy: 0.2949 - Val loss: 9.1189 - Val F1: 0.1343 - LR: 0.00e+00\n","\tBest epoch: 2 - Best val accuracy: 0.4487 - Best val loss: 1.2467 - Best val F1: 0.3975\n","\n","Source class: WAL | Domain: 45 | Accuracy: 0.2593 | Loss: 7.1667 | F1: 0.1092\n","\n","Domain: 46\n","x_syn_dom.shape: (448, 3, 128) | np.unique(y_syn_dom): [0 1 2 3]\n","x_dp_dom.shape: (160, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","x_syn_dom.shape: (392, 3, 128) | np.unique(y_syn_dom): [0 1 2 3]\n","x_dp_dom.shape: (104, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Training on synthetic data...\n","\tEpoch 10/100 - Train loss: 0.5728 - Val accuracy: 0.2911 - Val loss: 7.7060 - Val F1: 0.1313 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.3181 - Val accuracy: 0.2911 - Val loss: 8.2673 - Val F1: 0.1313 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.1551 - Val accuracy: 0.2911 - Val loss: 8.3805 - Val F1: 0.1313 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.0833 - Val accuracy: 0.2911 - Val loss: 7.4025 - Val F1: 0.1313 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.0587 - Val accuracy: 0.2911 - Val loss: 9.8406 - Val F1: 0.1313 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.0681 - Val accuracy: 0.2911 - Val loss: 7.3323 - Val F1: 0.1313 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0422 - Val accuracy: 0.2911 - Val loss: 8.4506 - Val F1: 0.1313 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0567 - Val accuracy: 0.2911 - Val loss: 8.2730 - Val F1: 0.1313 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0313 - Val accuracy: 0.2911 - Val loss: 7.9594 - Val F1: 0.1313 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0398 - Val accuracy: 0.2911 - Val loss: 9.3416 - Val F1: 0.1313 - LR: 0.00e+00\n","\tBest epoch: 2 - Best val accuracy: 0.2911 - Best val loss: 1.2786 - Best val F1: 0.1313\n","\n","Source class: WAL | Domain: 46 | Accuracy: 0.2692 | Loss: 8.2500 | F1: 0.1142\n","\n","Domain: 47\n","x_syn_dom.shape: (444, 3, 128) | np.unique(y_syn_dom): [0 1 2 3]\n","x_dp_dom.shape: (155, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","x_syn_dom.shape: (388, 3, 128) | np.unique(y_syn_dom): [0 1 2 3]\n","x_dp_dom.shape: (100, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Training on synthetic data...\n","\tEpoch 10/100 - Train loss: 0.5858 - Val accuracy: 0.2949 - Val loss: 6.7902 - Val F1: 0.1343 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.2363 - Val accuracy: 0.2949 - Val loss: 5.6394 - Val F1: 0.1343 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.1226 - Val accuracy: 0.2949 - Val loss: 8.1798 - Val F1: 0.1343 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.0861 - Val accuracy: 0.2949 - Val loss: 7.0396 - Val F1: 0.1343 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.0573 - Val accuracy: 0.2949 - Val loss: 5.9611 - Val F1: 0.1343 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.0846 - Val accuracy: 0.2949 - Val loss: 8.3125 - Val F1: 0.1343 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0335 - Val accuracy: 0.2949 - Val loss: 9.5138 - Val F1: 0.1343 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0364 - Val accuracy: 0.2949 - Val loss: 7.4010 - Val F1: 0.1343 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0555 - Val accuracy: 0.2949 - Val loss: 6.9926 - Val F1: 0.1343 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0558 - Val accuracy: 0.2949 - Val loss: 8.7008 - Val F1: 0.1343 - LR: 0.00e+00\n","\tBest epoch: 2 - Best val accuracy: 0.3333 - Best val loss: 1.1911 - Best val F1: 0.2485\n","\n","Source class: WAL | Domain: 47 | Accuracy: 0.2800 | Loss: 7.4973 | F1: 0.1225\n","\n","Domain: 48\n","x_syn_dom.shape: (444, 3, 128) | np.unique(y_syn_dom): [0 1 2 3]\n","x_dp_dom.shape: (159, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","x_syn_dom.shape: (388, 3, 128) | np.unique(y_syn_dom): [0 1 2 3]\n","x_dp_dom.shape: (104, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Training on synthetic data...\n","\tEpoch 10/100 - Train loss: 0.3216 - Val accuracy: 0.5769 - Val loss: 2.7707 - Val F1: 0.5073 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.1708 - Val accuracy: 0.5769 - Val loss: 4.4721 - Val F1: 0.4356 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.0776 - Val accuracy: 0.5769 - Val loss: 4.8560 - Val F1: 0.4560 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.0766 - Val accuracy: 0.1667 - Val loss: 4.9492 - Val F1: 0.0833 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.0433 - Val accuracy: 0.3846 - Val loss: 5.9157 - Val F1: 0.3111 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.0504 - Val accuracy: 0.1410 - Val loss: 8.1709 - Val F1: 0.0349 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0431 - Val accuracy: 0.3846 - Val loss: 4.6329 - Val F1: 0.3031 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0270 - Val accuracy: 0.1410 - Val loss: 9.2779 - Val F1: 0.0349 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0463 - Val accuracy: 0.4231 - Val loss: 5.1558 - Val F1: 0.3346 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0362 - Val accuracy: 0.3718 - Val loss: 8.0868 - Val F1: 0.3026 - LR: 0.00e+00\n","\tBest epoch: 3 - Best val accuracy: 0.5769 - Best val loss: 1.0732 - Best val F1: 0.4560\n","\n","Source class: WAL | Domain: 48 | Accuracy: 0.8077 | Loss: 4.9013 | F1: 0.7261\n","\n","Domain: 49\n","x_syn_dom.shape: (444, 3, 128) | np.unique(y_syn_dom): [0 1 2 3]\n","x_dp_dom.shape: (164, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","x_syn_dom.shape: (388, 3, 128) | np.unique(y_syn_dom): [0 1 2 3]\n","x_dp_dom.shape: (109, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Training on synthetic data...\n","\tEpoch 10/100 - Train loss: 0.5510 - Val accuracy: 0.2949 - Val loss: 4.8687 - Val F1: 0.1343 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.2118 - Val accuracy: 0.2949 - Val loss: 8.1697 - Val F1: 0.1343 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.0792 - Val accuracy: 0.2949 - Val loss: 9.5555 - Val F1: 0.1343 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.0348 - Val accuracy: 0.2949 - Val loss: 9.5794 - Val F1: 0.1343 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.0618 - Val accuracy: 0.2949 - Val loss: 8.5803 - Val F1: 0.1474 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.0701 - Val accuracy: 0.2949 - Val loss: 9.8755 - Val F1: 0.1356 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0320 - Val accuracy: 0.2949 - Val loss: 8.2721 - Val F1: 0.1577 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0339 - Val accuracy: 0.2949 - Val loss: 10.0716 - Val F1: 0.1356 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0664 - Val accuracy: 0.2949 - Val loss: 9.6824 - Val F1: 0.1428 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0436 - Val accuracy: 0.3205 - Val loss: 9.4077 - Val F1: 0.2207 - LR: 0.00e+00\n","\tBest epoch: 2 - Best val accuracy: 0.2821 - Best val loss: 1.3237 - Best val F1: 0.1612\n","\n","Source class: WAL | Domain: 49 | Accuracy: 0.4495 | Loss: 4.5464 | F1: 0.3696\n","\n","Domain: 50\n","x_syn_dom.shape: (444, 3, 128) | np.unique(y_syn_dom): [0 1 2 3]\n","x_dp_dom.shape: (153, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","x_syn_dom.shape: (388, 3, 128) | np.unique(y_syn_dom): [0 1 2 3]\n","x_dp_dom.shape: (98, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Training on synthetic data...\n","\tEpoch 10/100 - Train loss: 0.3200 - Val accuracy: 0.2949 - Val loss: 4.4677 - Val F1: 0.1370 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.1523 - Val accuracy: 0.4872 - Val loss: 6.0345 - Val F1: 0.3554 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.0931 - Val accuracy: 0.5769 - Val loss: 7.2550 - Val F1: 0.4413 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.0811 - Val accuracy: 0.5769 - Val loss: 5.4671 - Val F1: 0.4260 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.0558 - Val accuracy: 0.3205 - Val loss: 6.4040 - Val F1: 0.2007 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.0665 - Val accuracy: 0.4231 - Val loss: 5.1552 - Val F1: 0.3010 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0352 - Val accuracy: 0.4615 - Val loss: 5.2137 - Val F1: 0.3342 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0332 - Val accuracy: 0.2949 - Val loss: 6.7535 - Val F1: 0.1370 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0138 - Val accuracy: 0.2949 - Val loss: 4.0139 - Val F1: 0.1809 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0166 - Val accuracy: 0.2949 - Val loss: 5.7365 - Val F1: 0.1559 - LR: 0.00e+00\n","\tBest epoch: 2 - Best val accuracy: 0.3205 - Best val loss: 1.2439 - Best val F1: 0.1960\n","\n","Source class: WAL | Domain: 50 | Accuracy: 0.2857 | Loss: 5.0995 | F1: 0.1368\n","\n","Domain: 51\n","x_syn_dom.shape: (444, 3, 128) | np.unique(y_syn_dom): [0 1 2 3]\n","x_dp_dom.shape: (157, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","x_syn_dom.shape: (388, 3, 128) | np.unique(y_syn_dom): [0 1 2 3]\n","x_dp_dom.shape: (102, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Training on synthetic data...\n","\tEpoch 10/100 - Train loss: 0.5121 - Val accuracy: 0.2949 - Val loss: 4.6184 - Val F1: 0.1343 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.2280 - Val accuracy: 0.2949 - Val loss: 6.4739 - Val F1: 0.1343 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.1455 - Val accuracy: 0.2949 - Val loss: 7.8000 - Val F1: 0.1343 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.0862 - Val accuracy: 0.2949 - Val loss: 9.9093 - Val F1: 0.1343 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.1320 - Val accuracy: 0.2949 - Val loss: 10.1760 - Val F1: 0.1343 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.0832 - Val accuracy: 0.2949 - Val loss: 9.1996 - Val F1: 0.1343 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0480 - Val accuracy: 0.2949 - Val loss: 11.3110 - Val F1: 0.1343 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0501 - Val accuracy: 0.2949 - Val loss: 12.8589 - Val F1: 0.1343 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0734 - Val accuracy: 0.2949 - Val loss: 10.4747 - Val F1: 0.1343 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0447 - Val accuracy: 0.2949 - Val loss: 12.1339 - Val F1: 0.1343 - LR: 0.00e+00\n","\tBest epoch: 2 - Best val accuracy: 0.2949 - Best val loss: 1.1774 - Best val F1: 0.1343\n","\n","Source class: WAL | Domain: 51 | Accuracy: 0.2745 | Loss: 9.5221 | F1: 0.1183\n","\n","Domain: 52\n","x_syn_dom.shape: (444, 3, 128) | np.unique(y_syn_dom): [0 1 2 3]\n","x_dp_dom.shape: (153, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","x_syn_dom.shape: (388, 3, 128) | np.unique(y_syn_dom): [0 1 2 3]\n","x_dp_dom.shape: (98, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Training on synthetic data...\n","\tEpoch 10/100 - Train loss: 0.3445 - Val accuracy: 0.2949 - Val loss: 2.2800 - Val F1: 0.1524 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.1012 - Val accuracy: 0.3077 - Val loss: 3.8284 - Val F1: 0.2315 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.0646 - Val accuracy: 0.3205 - Val loss: 4.9619 - Val F1: 0.2405 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.0388 - Val accuracy: 0.4231 - Val loss: 4.9920 - Val F1: 0.3320 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.0386 - Val accuracy: 0.4231 - Val loss: 5.8248 - Val F1: 0.3320 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.0201 - Val accuracy: 0.4359 - Val loss: 5.9774 - Val F1: 0.3419 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0125 - Val accuracy: 0.4359 - Val loss: 6.4962 - Val F1: 0.3419 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0085 - Val accuracy: 0.4359 - Val loss: 6.4625 - Val F1: 0.3419 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0128 - Val accuracy: 0.4359 - Val loss: 7.0334 - Val F1: 0.3419 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0183 - Val accuracy: 0.4359 - Val loss: 7.1107 - Val F1: 0.3419 - LR: 0.00e+00\n","\tBest epoch: 3 - Best val accuracy: 0.2949 - Best val loss: 1.2244 - Best val F1: 0.1541\n","\n","Source class: WAL | Domain: 52 | Accuracy: 0.8469 | Loss: 1.6127 | F1: 0.7845\n","\n","Domain: 53\n","x_syn_dom.shape: (444, 3, 128) | np.unique(y_syn_dom): [0 1 2 3]\n","x_dp_dom.shape: (159, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","x_syn_dom.shape: (388, 3, 128) | np.unique(y_syn_dom): [0 1 2 3]\n","x_dp_dom.shape: (104, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Training on synthetic data...\n","\tEpoch 10/100 - Train loss: 0.1684 - Val accuracy: 0.6538 - Val loss: 0.8264 - Val F1: 0.5640 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.0482 - Val accuracy: 0.7436 - Val loss: 0.5160 - Val F1: 0.7249 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.0614 - Val accuracy: 0.7308 - Val loss: 0.5379 - Val F1: 0.7161 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.0377 - Val accuracy: 0.8462 - Val loss: 0.3143 - Val F1: 0.8449 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.0213 - Val accuracy: 0.8333 - Val loss: 0.3514 - Val F1: 0.8319 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.0101 - Val accuracy: 0.7949 - Val loss: 0.5446 - Val F1: 0.7667 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0224 - Val accuracy: 0.7692 - Val loss: 0.4832 - Val F1: 0.7590 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0067 - Val accuracy: 0.8462 - Val loss: 0.3711 - Val F1: 0.8381 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0140 - Val accuracy: 0.8205 - Val loss: 0.4666 - Val F1: 0.8050 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0072 - Val accuracy: 0.8333 - Val loss: 0.4124 - Val F1: 0.8246 - LR: 0.00e+00\n","\tBest epoch: 39 - Best val accuracy: 0.8846 - Best val loss: 0.2705 - Best val F1: 0.8842\n","\n","Source class: WAL | Domain: 53 | Accuracy: 0.9231 | Loss: 0.3119 | F1: 0.9162\n","\n","Domain: 54\n","x_syn_dom.shape: (444, 3, 128) | np.unique(y_syn_dom): [0 1 2 3]\n","x_dp_dom.shape: (153, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","x_syn_dom.shape: (388, 3, 128) | np.unique(y_syn_dom): [0 1 2 3]\n","x_dp_dom.shape: (98, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Training on synthetic data...\n","\tEpoch 10/100 - Train loss: 0.4617 - Val accuracy: 0.2949 - Val loss: 2.1155 - Val F1: 0.1459 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.1732 - Val accuracy: 0.5769 - Val loss: 2.4151 - Val F1: 0.4560 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.1034 - Val accuracy: 0.4744 - Val loss: 2.6874 - Val F1: 0.3555 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.0663 - Val accuracy: 0.4744 - Val loss: 2.9464 - Val F1: 0.3555 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.0798 - Val accuracy: 0.5769 - Val loss: 3.0200 - Val F1: 0.4413 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.0521 - Val accuracy: 0.4615 - Val loss: 3.0501 - Val F1: 0.3495 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.1071 - Val accuracy: 0.5769 - Val loss: 3.1356 - Val F1: 0.4560 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0306 - Val accuracy: 0.5769 - Val loss: 3.0073 - Val F1: 0.4274 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0577 - Val accuracy: 0.4615 - Val loss: 2.9312 - Val F1: 0.3401 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0372 - Val accuracy: 0.5769 - Val loss: 3.5347 - Val F1: 0.4481 - LR: 0.00e+00\n","\tBest epoch: 2 - Best val accuracy: 0.2949 - Best val loss: 1.2694 - Best val F1: 0.1689\n","\n","Source class: WAL | Domain: 54 | Accuracy: 0.2959 | Loss: 7.1868 | F1: 0.2158\n","\n","Domain: 55\n","x_syn_dom.shape: (444, 3, 128) | np.unique(y_syn_dom): [0 1 2 3]\n","x_dp_dom.shape: (160, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","x_syn_dom.shape: (388, 3, 128) | np.unique(y_syn_dom): [0 1 2 3]\n","x_dp_dom.shape: (105, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Training on synthetic data...\n","\tEpoch 10/100 - Train loss: 0.3945 - Val accuracy: 0.2949 - Val loss: 2.5114 - Val F1: 0.1343 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.1437 - Val accuracy: 0.3462 - Val loss: 1.6266 - Val F1: 0.2266 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.0490 - Val accuracy: 0.6154 - Val loss: 0.9279 - Val F1: 0.5282 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.0325 - Val accuracy: 0.2949 - Val loss: 2.6492 - Val F1: 0.1356 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.0261 - Val accuracy: 0.2949 - Val loss: 3.7108 - Val F1: 0.1343 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.0225 - Val accuracy: 0.2949 - Val loss: 4.3749 - Val F1: 0.1343 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0248 - Val accuracy: 0.3590 - Val loss: 2.0193 - Val F1: 0.2622 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0392 - Val accuracy: 0.2949 - Val loss: 5.7896 - Val F1: 0.1384 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0164 - Val accuracy: 0.2949 - Val loss: 5.5608 - Val F1: 0.1343 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0093 - Val accuracy: 0.3462 - Val loss: 2.2824 - Val F1: 0.2445 - LR: 0.00e+00\n","\tBest epoch: 28 - Best val accuracy: 0.5769 - Best val loss: 0.8420 - Best val F1: 0.4366\n","\n","Source class: WAL | Domain: 55 | Accuracy: 0.2952 | Loss: 2.1741 | F1: 0.1797\n","\n","Domain: 56\n","x_syn_dom.shape: (444, 3, 128) | np.unique(y_syn_dom): [0 1 2 3]\n","x_dp_dom.shape: (153, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","x_syn_dom.shape: (388, 3, 128) | np.unique(y_syn_dom): [0 1 2 3]\n","x_dp_dom.shape: (98, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Training on synthetic data...\n","\tEpoch 10/100 - Train loss: 0.4936 - Val accuracy: 0.2949 - Val loss: 5.0655 - Val F1: 0.1343 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.1937 - Val accuracy: 0.2949 - Val loss: 5.3193 - Val F1: 0.1343 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.1155 - Val accuracy: 0.2949 - Val loss: 9.1636 - Val F1: 0.1343 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.0697 - Val accuracy: 0.2949 - Val loss: 9.5745 - Val F1: 0.1343 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.0662 - Val accuracy: 0.2949 - Val loss: 8.8537 - Val F1: 0.1343 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.0481 - Val accuracy: 0.2949 - Val loss: 5.4704 - Val F1: 0.1356 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0350 - Val accuracy: 0.2949 - Val loss: 7.2923 - Val F1: 0.1343 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0732 - Val accuracy: 0.2949 - Val loss: 10.6562 - Val F1: 0.1343 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0401 - Val accuracy: 0.2949 - Val loss: 7.4233 - Val F1: 0.1343 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0406 - Val accuracy: 0.2949 - Val loss: 8.7853 - Val F1: 0.1343 - LR: 0.00e+00\n","\tBest epoch: 2 - Best val accuracy: 0.6410 - Best val loss: 1.0589 - Best val F1: 0.5846\n","\n","Source class: WAL | Domain: 56 | Accuracy: 0.2857 | Loss: 6.9620 | F1: 0.1270\n","\n","Domain: 57\n","x_syn_dom.shape: (444, 3, 128) | np.unique(y_syn_dom): [0 1 2 3]\n","x_dp_dom.shape: (153, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","x_syn_dom.shape: (388, 3, 128) | np.unique(y_syn_dom): [0 1 2 3]\n","x_dp_dom.shape: (98, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Training on synthetic data...\n","\tEpoch 10/100 - Train loss: 0.4334 - Val accuracy: 0.2949 - Val loss: 2.9523 - Val F1: 0.1343 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.1930 - Val accuracy: 0.3077 - Val loss: 1.7935 - Val F1: 0.2017 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.0818 - Val accuracy: 0.3333 - Val loss: 1.5352 - Val F1: 0.2372 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.0549 - Val accuracy: 0.2949 - Val loss: 3.6862 - Val F1: 0.1809 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.0727 - Val accuracy: 0.3077 - Val loss: 4.3864 - Val F1: 0.2087 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.0773 - Val accuracy: 0.2949 - Val loss: 4.6123 - Val F1: 0.1809 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0670 - Val accuracy: 0.3077 - Val loss: 3.7109 - Val F1: 0.2031 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0279 - Val accuracy: 0.3205 - Val loss: 4.2130 - Val F1: 0.2301 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0187 - Val accuracy: 0.3077 - Val loss: 3.5194 - Val F1: 0.2031 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0463 - Val accuracy: 0.3205 - Val loss: 4.1765 - Val F1: 0.2123 - LR: 0.00e+00\n","\tBest epoch: 24 - Best val accuracy: 0.5513 - Best val loss: 0.8243 - Best val F1: 0.5595\n","\n","Source class: WAL | Domain: 57 | Accuracy: 0.4286 | Loss: 2.3446 | F1: 0.3602\n","\n","Domain: 58\n","x_syn_dom.shape: (444, 3, 128) | np.unique(y_syn_dom): [0 1 2 3]\n","x_dp_dom.shape: (149, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","x_syn_dom.shape: (388, 3, 128) | np.unique(y_syn_dom): [0 1 2 3]\n","x_dp_dom.shape: (94, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Training on synthetic data...\n","\tEpoch 10/100 - Train loss: 0.5356 - Val accuracy: 0.2949 - Val loss: 2.5335 - Val F1: 0.1343 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.3446 - Val accuracy: 0.3205 - Val loss: 1.2834 - Val F1: 0.2096 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.2483 - Val accuracy: 0.2949 - Val loss: 2.2861 - Val F1: 0.1559 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.1580 - Val accuracy: 0.2949 - Val loss: 2.6335 - Val F1: 0.1491 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.0784 - Val accuracy: 0.2949 - Val loss: 2.6659 - Val F1: 0.1384 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.1052 - Val accuracy: 0.2949 - Val loss: 3.1460 - Val F1: 0.1343 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0705 - Val accuracy: 0.2949 - Val loss: 3.3337 - Val F1: 0.1356 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0484 - Val accuracy: 0.2949 - Val loss: 2.6524 - Val F1: 0.1559 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0926 - Val accuracy: 0.2949 - Val loss: 3.3016 - Val F1: 0.1343 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0775 - Val accuracy: 0.2949 - Val loss: 2.2260 - Val F1: 0.1675 - LR: 0.00e+00\n","\tBest epoch: 2 - Best val accuracy: 0.5641 - Best val loss: 1.1189 - Best val F1: 0.4474\n","\n","Source class: WAL | Domain: 58 | Accuracy: 0.3617 | Loss: 1.5064 | F1: 0.2585\n","\n","Domain: 59\n","x_syn_dom.shape: (444, 3, 128) | np.unique(y_syn_dom): [0 1 2 3]\n","x_dp_dom.shape: (154, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","x_syn_dom.shape: (388, 3, 128) | np.unique(y_syn_dom): [0 1 2 3]\n","x_dp_dom.shape: (99, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Training on synthetic data...\n","\tEpoch 10/100 - Train loss: 0.4867 - Val accuracy: 0.2949 - Val loss: 3.7091 - Val F1: 0.1343 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.1356 - Val accuracy: 0.2949 - Val loss: 3.0895 - Val F1: 0.1343 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.0977 - Val accuracy: 0.3333 - Val loss: 2.9965 - Val F1: 0.2061 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.0301 - Val accuracy: 0.3590 - Val loss: 3.2386 - Val F1: 0.2458 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.0219 - Val accuracy: 0.3205 - Val loss: 3.6861 - Val F1: 0.1840 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.0595 - Val accuracy: 0.5769 - Val loss: 3.2422 - Val F1: 0.4366 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0239 - Val accuracy: 0.5769 - Val loss: 3.6610 - Val F1: 0.4537 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0386 - Val accuracy: 0.5769 - Val loss: 2.9349 - Val F1: 0.4221 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0114 - Val accuracy: 0.5513 - Val loss: 3.7039 - Val F1: 0.4361 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0320 - Val accuracy: 0.5128 - Val loss: 3.9502 - Val F1: 0.4074 - LR: 0.00e+00\n","\tBest epoch: 2 - Best val accuracy: 0.2821 - Best val loss: 1.2886 - Best val F1: 0.1532\n","\n","Source class: WAL | Domain: 59 | Accuracy: 0.2929 | Loss: 4.1641 | F1: 0.1489\n","\n","Domain: 60\n","x_syn_dom.shape: (444, 3, 128) | np.unique(y_syn_dom): [0 1 2 3]\n","x_dp_dom.shape: (158, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","x_syn_dom.shape: (388, 3, 128) | np.unique(y_syn_dom): [0 1 2 3]\n","x_dp_dom.shape: (103, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Training on synthetic data...\n","\tEpoch 10/100 - Train loss: 0.1254 - Val accuracy: 0.8462 - Val loss: 0.3962 - Val F1: 0.8250 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.1085 - Val accuracy: 0.9231 - Val loss: 0.2286 - Val F1: 0.9210 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.1381 - Val accuracy: 0.9359 - Val loss: 0.2225 - Val F1: 0.9350 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.0761 - Val accuracy: 0.7949 - Val loss: 0.5061 - Val F1: 0.7636 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.0539 - Val accuracy: 0.8974 - Val loss: 0.3213 - Val F1: 0.8939 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.0276 - Val accuracy: 0.8205 - Val loss: 0.4419 - Val F1: 0.8003 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0364 - Val accuracy: 0.7179 - Val loss: 0.6352 - Val F1: 0.6045 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0451 - Val accuracy: 0.7179 - Val loss: 0.6945 - Val F1: 0.6035 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0154 - Val accuracy: 0.7949 - Val loss: 0.4959 - Val F1: 0.7610 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0207 - Val accuracy: 0.7308 - Val loss: 0.5370 - Val F1: 0.6361 - LR: 0.00e+00\n","\tBest epoch: 31 - Best val accuracy: 0.9615 - Best val loss: 0.1917 - Best val F1: 0.9614\n","\n","Source class: WAL | Domain: 60 | Accuracy: 0.7961 | Loss: 1.2676 | F1: 0.7196\n","\n","Domain: 61\n","x_syn_dom.shape: (444, 3, 128) | np.unique(y_syn_dom): [0 1 2 3]\n","x_dp_dom.shape: (158, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","x_syn_dom.shape: (388, 3, 128) | np.unique(y_syn_dom): [0 1 2 3]\n","x_dp_dom.shape: (103, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Training on synthetic data...\n","\tEpoch 10/100 - Train loss: 0.3593 - Val accuracy: 0.3718 - Val loss: 1.9739 - Val F1: 0.2535 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.1396 - Val accuracy: 0.3205 - Val loss: 1.2915 - Val F1: 0.2007 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.0574 - Val accuracy: 0.4359 - Val loss: 1.6952 - Val F1: 0.3422 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.0390 - Val accuracy: 0.5256 - Val loss: 1.5187 - Val F1: 0.4173 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.0374 - Val accuracy: 0.2949 - Val loss: 2.9732 - Val F1: 0.1428 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.0281 - Val accuracy: 0.3590 - Val loss: 2.8009 - Val F1: 0.2674 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0449 - Val accuracy: 0.2949 - Val loss: 3.3996 - Val F1: 0.1833 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0627 - Val accuracy: 0.2949 - Val loss: 3.2437 - Val F1: 0.1762 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0237 - Val accuracy: 0.2949 - Val loss: 3.2732 - Val F1: 0.1696 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0138 - Val accuracy: 0.2949 - Val loss: 2.8582 - Val F1: 0.1739 - LR: 0.00e+00\n","\tBest epoch: 38 - Best val accuracy: 0.7692 - Best val loss: 0.7424 - Best val F1: 0.7081\n","\n","Source class: WAL | Domain: 61 | Accuracy: 0.2816 | Loss: 2.4864 | F1: 0.1387\n","\n","Domain: 62\n","x_syn_dom.shape: (444, 3, 128) | np.unique(y_syn_dom): [0 1 2 3]\n","x_dp_dom.shape: (158, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","x_syn_dom.shape: (388, 3, 128) | np.unique(y_syn_dom): [0 1 2 3]\n","x_dp_dom.shape: (103, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Training on synthetic data...\n","\tEpoch 10/100 - Train loss: 0.5545 - Val accuracy: 0.2949 - Val loss: 2.8088 - Val F1: 0.1343 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.1405 - Val accuracy: 0.4359 - Val loss: 2.7399 - Val F1: 0.3419 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.1007 - Val accuracy: 0.4359 - Val loss: 5.4781 - Val F1: 0.3419 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.0849 - Val accuracy: 0.4615 - Val loss: 1.9127 - Val F1: 0.3904 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.0876 - Val accuracy: 0.4359 - Val loss: 4.1581 - Val F1: 0.3419 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.0337 - Val accuracy: 0.4359 - Val loss: 5.2260 - Val F1: 0.3419 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0228 - Val accuracy: 0.4359 - Val loss: 4.7929 - Val F1: 0.3419 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0373 - Val accuracy: 0.4359 - Val loss: 5.1347 - Val F1: 0.3419 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0501 - Val accuracy: 0.4359 - Val loss: 7.5159 - Val F1: 0.3419 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0692 - Val accuracy: 0.4359 - Val loss: 6.6496 - Val F1: 0.3419 - LR: 0.00e+00\n","\tBest epoch: 3 - Best val accuracy: 0.5769 - Best val loss: 0.9701 - Best val F1: 0.4560\n","\n","Source class: WAL | Domain: 62 | Accuracy: 0.8155 | Loss: 3.6825 | F1: 0.7367\n","\n","Domain: 63\n","x_syn_dom.shape: (444, 3, 128) | np.unique(y_syn_dom): [0 1 2 3]\n","x_dp_dom.shape: (153, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","x_syn_dom.shape: (388, 3, 128) | np.unique(y_syn_dom): [0 1 2 3]\n","x_dp_dom.shape: (98, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Training on synthetic data...\n","\tEpoch 10/100 - Train loss: 0.4399 - Val accuracy: 0.2949 - Val loss: 5.6168 - Val F1: 0.1343 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.1900 - Val accuracy: 0.2949 - Val loss: 5.8192 - Val F1: 0.1343 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.0692 - Val accuracy: 0.2949 - Val loss: 6.4674 - Val F1: 0.1343 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.0450 - Val accuracy: 0.2949 - Val loss: 7.7862 - Val F1: 0.1343 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.1155 - Val accuracy: 0.2949 - Val loss: 7.7302 - Val F1: 0.1343 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.0430 - Val accuracy: 0.2949 - Val loss: 8.6418 - Val F1: 0.1343 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0288 - Val accuracy: 0.2949 - Val loss: 8.6058 - Val F1: 0.1343 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0559 - Val accuracy: 0.2949 - Val loss: 7.5213 - Val F1: 0.1343 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0278 - Val accuracy: 0.2949 - Val loss: 9.9956 - Val F1: 0.1343 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0210 - Val accuracy: 0.2949 - Val loss: 10.3546 - Val F1: 0.1343 - LR: 0.00e+00\n","\tBest epoch: 2 - Best val accuracy: 0.2821 - Best val loss: 1.3172 - Best val F1: 0.1410\n","\n","Source class: WAL | Domain: 63 | Accuracy: 0.2959 | Loss: 8.6920 | F1: 0.1459\n","\n","Domain: 64\n","x_syn_dom.shape: (448, 3, 128) | np.unique(y_syn_dom): [0 1 2 3]\n","x_dp_dom.shape: (154, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","x_syn_dom.shape: (392, 3, 128) | np.unique(y_syn_dom): [0 1 2 3]\n","x_dp_dom.shape: (98, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Training on synthetic data...\n","\tEpoch 10/100 - Train loss: 0.3884 - Val accuracy: 0.4430 - Val loss: 1.5308 - Val F1: 0.3204 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.1429 - Val accuracy: 0.5190 - Val loss: 1.7319 - Val F1: 0.3833 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.0992 - Val accuracy: 0.3671 - Val loss: 4.3158 - Val F1: 0.2895 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.0437 - Val accuracy: 0.5823 - Val loss: 2.7800 - Val F1: 0.4607 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.0354 - Val accuracy: 0.5823 - Val loss: 4.0362 - Val F1: 0.4607 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.0278 - Val accuracy: 0.5443 - Val loss: 3.4016 - Val F1: 0.4341 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0514 - Val accuracy: 0.3924 - Val loss: 5.9785 - Val F1: 0.2985 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0226 - Val accuracy: 0.3165 - Val loss: 3.2488 - Val F1: 0.2033 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0197 - Val accuracy: 0.4304 - Val loss: 3.8947 - Val F1: 0.3093 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0170 - Val accuracy: 0.3291 - Val loss: 5.1793 - Val F1: 0.2324 - LR: 0.00e+00\n","\tBest epoch: 3 - Best val accuracy: 0.3797 - Best val loss: 1.1070 - Best val F1: 0.2618\n","\n","Source class: WAL | Domain: 64 | Accuracy: 0.4388 | Loss: 3.1017 | F1: 0.3666\n","\n","Domain: 65\n","x_syn_dom.shape: (444, 3, 128) | np.unique(y_syn_dom): [0 1 2 3]\n","x_dp_dom.shape: (161, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","x_syn_dom.shape: (388, 3, 128) | np.unique(y_syn_dom): [0 1 2 3]\n","x_dp_dom.shape: (106, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Training on synthetic data...\n","\tEpoch 10/100 - Train loss: 0.6249 - Val accuracy: 0.5769 - Val loss: 1.9064 - Val F1: 0.4560 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.2446 - Val accuracy: 0.5385 - Val loss: 2.3030 - Val F1: 0.4294 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.1000 - Val accuracy: 0.4487 - Val loss: 1.2077 - Val F1: 0.3716 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.0889 - Val accuracy: 0.3077 - Val loss: 1.8666 - Val F1: 0.1625 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.0931 - Val accuracy: 0.6410 - Val loss: 1.5170 - Val F1: 0.5385 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.0358 - Val accuracy: 0.3333 - Val loss: 2.6301 - Val F1: 0.2037 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0628 - Val accuracy: 0.3974 - Val loss: 2.9611 - Val F1: 0.2825 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0363 - Val accuracy: 0.3333 - Val loss: 2.8174 - Val F1: 0.2075 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0405 - Val accuracy: 0.3333 - Val loss: 2.1840 - Val F1: 0.2037 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0801 - Val accuracy: 0.3205 - Val loss: 3.1047 - Val F1: 0.1805 - LR: 0.00e+00\n","\tBest epoch: 35 - Best val accuracy: 0.7436 - Best val loss: 0.9009 - Best val F1: 0.6949\n","\n","Source class: WAL | Domain: 65 | Accuracy: 0.2830 | Loss: 2.5899 | F1: 0.1508\n","\n","Domain: 66\n","x_syn_dom.shape: (444, 3, 128) | np.unique(y_syn_dom): [0 1 2 3]\n","x_dp_dom.shape: (153, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","x_syn_dom.shape: (388, 3, 128) | np.unique(y_syn_dom): [0 1 2 3]\n","x_dp_dom.shape: (98, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Training on synthetic data...\n","\tEpoch 10/100 - Train loss: 0.3806 - Val accuracy: 0.2949 - Val loss: 4.6163 - Val F1: 0.1634 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.1832 - Val accuracy: 0.3974 - Val loss: 5.5008 - Val F1: 0.3193 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.1346 - Val accuracy: 0.2949 - Val loss: 8.5807 - Val F1: 0.2425 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.1103 - Val accuracy: 0.1667 - Val loss: 9.6840 - Val F1: 0.0828 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.0512 - Val accuracy: 0.1410 - Val loss: 12.0414 - Val F1: 0.0349 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.1143 - Val accuracy: 0.1410 - Val loss: 14.1772 - Val F1: 0.0349 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0566 - Val accuracy: 0.1410 - Val loss: 11.1449 - Val F1: 0.0349 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0506 - Val accuracy: 0.1410 - Val loss: 16.3781 - Val F1: 0.0349 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0627 - Val accuracy: 0.1410 - Val loss: 11.8699 - Val F1: 0.0349 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0238 - Val accuracy: 0.1410 - Val loss: 12.4196 - Val F1: 0.0349 - LR: 0.00e+00\n","\tBest epoch: 1 - Best val accuracy: 0.2821 - Best val loss: 1.3997 - Best val F1: 0.1241\n","\n","Source class: WAL | Domain: 66 | Accuracy: 0.9082 | Loss: 0.8874 | F1: 0.8749\n","\n","Domain: 67\n","x_syn_dom.shape: (444, 3, 128) | np.unique(y_syn_dom): [0 1 2 3]\n","x_dp_dom.shape: (153, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","x_syn_dom.shape: (388, 3, 128) | np.unique(y_syn_dom): [0 1 2 3]\n","x_dp_dom.shape: (98, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Training on synthetic data...\n","\tEpoch 10/100 - Train loss: 0.4463 - Val accuracy: 0.8590 - Val loss: 0.7318 - Val F1: 0.8005 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.2179 - Val accuracy: 0.5769 - Val loss: 1.1303 - Val F1: 0.4560 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.1815 - Val accuracy: 0.5256 - Val loss: 1.6358 - Val F1: 0.3886 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.1159 - Val accuracy: 0.5128 - Val loss: 1.1807 - Val F1: 0.3937 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.1075 - Val accuracy: 0.5513 - Val loss: 1.2162 - Val F1: 0.4147 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.0736 - Val accuracy: 0.6154 - Val loss: 0.8242 - Val F1: 0.5319 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.1089 - Val accuracy: 0.2949 - Val loss: 1.5344 - Val F1: 0.1717 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0600 - Val accuracy: 0.3846 - Val loss: 1.3192 - Val F1: 0.2670 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0873 - Val accuracy: 0.5128 - Val loss: 1.0771 - Val F1: 0.3994 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0410 - Val accuracy: 0.5000 - Val loss: 1.1242 - Val F1: 0.3693 - LR: 0.00e+00\n","\tBest epoch: 58 - Best val accuracy: 0.7308 - Best val loss: 0.6786 - Best val F1: 0.6816\n","\n","Source class: WAL | Domain: 67 | Accuracy: 0.3469 | Loss: 1.8531 | F1: 0.2097\n","\n","Domain: 68\n","x_syn_dom.shape: (444, 3, 128) | np.unique(y_syn_dom): [0 1 2 3]\n","x_dp_dom.shape: (154, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","x_syn_dom.shape: (388, 3, 128) | np.unique(y_syn_dom): [0 1 2 3]\n","x_dp_dom.shape: (99, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Training on synthetic data...\n","\tEpoch 10/100 - Train loss: 0.3886 - Val accuracy: 0.5641 - Val loss: 1.1226 - Val F1: 0.4252 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.1522 - Val accuracy: 0.5769 - Val loss: 1.7150 - Val F1: 0.4445 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.1014 - Val accuracy: 0.7179 - Val loss: 1.3464 - Val F1: 0.6709 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.0889 - Val accuracy: 0.5769 - Val loss: 1.7740 - Val F1: 0.4356 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.0679 - Val accuracy: 0.6410 - Val loss: 1.8887 - Val F1: 0.5582 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.0363 - Val accuracy: 0.6795 - Val loss: 1.4991 - Val F1: 0.6182 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0612 - Val accuracy: 0.6410 - Val loss: 1.6730 - Val F1: 0.5643 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0279 - Val accuracy: 0.5897 - Val loss: 1.9964 - Val F1: 0.4701 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0315 - Val accuracy: 0.6154 - Val loss: 1.9332 - Val F1: 0.5185 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0215 - Val accuracy: 0.6026 - Val loss: 2.2381 - Val F1: 0.4931 - LR: 0.00e+00\n","\tBest epoch: 5 - Best val accuracy: 0.6410 - Best val loss: 0.7489 - Best val F1: 0.5611\n","\n","Source class: WAL | Domain: 68 | Accuracy: 0.3838 | Loss: 5.7769 | F1: 0.2609\n","\n","Domain: 69\n","x_syn_dom.shape: (444, 3, 128) | np.unique(y_syn_dom): [0 1 2 3]\n","x_dp_dom.shape: (153, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","x_syn_dom.shape: (388, 3, 128) | np.unique(y_syn_dom): [0 1 2 3]\n","x_dp_dom.shape: (98, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Training on synthetic data...\n","\tEpoch 10/100 - Train loss: 0.3874 - Val accuracy: 0.5769 - Val loss: 1.5555 - Val F1: 0.4560 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.1518 - Val accuracy: 0.5769 - Val loss: 1.4907 - Val F1: 0.4560 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.0985 - Val accuracy: 0.3462 - Val loss: 2.0925 - Val F1: 0.2198 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.0428 - Val accuracy: 0.7564 - Val loss: 0.5328 - Val F1: 0.7260 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.0320 - Val accuracy: 0.6923 - Val loss: 0.8040 - Val F1: 0.6272 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.0578 - Val accuracy: 0.7821 - Val loss: 0.5461 - Val F1: 0.7565 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0301 - Val accuracy: 0.7179 - Val loss: 0.6733 - Val F1: 0.6574 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0365 - Val accuracy: 0.7308 - Val loss: 0.7216 - Val F1: 0.6733 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0574 - Val accuracy: 0.4744 - Val loss: 1.2999 - Val F1: 0.3960 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0576 - Val accuracy: 0.6282 - Val loss: 1.4868 - Val F1: 0.5377 - LR: 0.00e+00\n","\tBest epoch: 61 - Best val accuracy: 0.8333 - Best val loss: 0.3980 - Best val F1: 0.8180\n","\n","Source class: WAL | Domain: 69 | Accuracy: 0.5102 | Loss: 1.3135 | F1: 0.5483\n","\n","Domain: 70\n","x_syn_dom.shape: (444, 3, 128) | np.unique(y_syn_dom): [0 1 2 3]\n","x_dp_dom.shape: (153, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","x_syn_dom.shape: (388, 3, 128) | np.unique(y_syn_dom): [0 1 2 3]\n","x_dp_dom.shape: (98, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Training on synthetic data...\n","\tEpoch 10/100 - Train loss: 0.4187 - Val accuracy: 0.2949 - Val loss: 4.3227 - Val F1: 0.1343 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.2761 - Val accuracy: 0.2949 - Val loss: 5.6602 - Val F1: 0.1343 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.1372 - Val accuracy: 0.2949 - Val loss: 7.7968 - Val F1: 0.1343 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.0696 - Val accuracy: 0.2949 - Val loss: 8.1280 - Val F1: 0.1559 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.0941 - Val accuracy: 0.3077 - Val loss: 7.6213 - Val F1: 0.1716 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.0497 - Val accuracy: 0.3077 - Val loss: 9.0821 - Val F1: 0.1842 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0731 - Val accuracy: 0.3077 - Val loss: 7.7042 - Val F1: 0.1659 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0272 - Val accuracy: 0.3462 - Val loss: 7.8696 - Val F1: 0.2354 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0489 - Val accuracy: 0.3333 - Val loss: 6.8765 - Val F1: 0.2095 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0411 - Val accuracy: 0.3077 - Val loss: 8.2880 - Val F1: 0.1863 - LR: 0.00e+00\n","\tBest epoch: 2 - Best val accuracy: 0.5128 - Best val loss: 1.2168 - Best val F1: 0.4851\n","\n","Source class: WAL | Domain: 70 | Accuracy: 0.2959 | Loss: 2.7472 | F1: 0.1481\n","\n","Domain: 71\n","x_syn_dom.shape: (444, 3, 128) | np.unique(y_syn_dom): [0 1 2 3]\n","x_dp_dom.shape: (155, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","x_syn_dom.shape: (388, 3, 128) | np.unique(y_syn_dom): [0 1 2 3]\n","x_dp_dom.shape: (100, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Training on synthetic data...\n","\tEpoch 10/100 - Train loss: 0.4400 - Val accuracy: 0.5769 - Val loss: 1.3486 - Val F1: 0.4560 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.2012 - Val accuracy: 0.3333 - Val loss: 1.2354 - Val F1: 0.2371 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.1097 - Val accuracy: 0.4359 - Val loss: 2.5198 - Val F1: 0.3419 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.0460 - Val accuracy: 0.4359 - Val loss: 3.7702 - Val F1: 0.3419 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.0523 - Val accuracy: 0.4359 - Val loss: 5.0158 - Val F1: 0.3419 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.0350 - Val accuracy: 0.4359 - Val loss: 4.7441 - Val F1: 0.3419 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0452 - Val accuracy: 0.4359 - Val loss: 5.8147 - Val F1: 0.3419 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0411 - Val accuracy: 0.4359 - Val loss: 5.7418 - Val F1: 0.3419 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0244 - Val accuracy: 0.4359 - Val loss: 5.5136 - Val F1: 0.3419 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0294 - Val accuracy: 0.4359 - Val loss: 4.6780 - Val F1: 0.3419 - LR: 0.00e+00\n","\tBest epoch: 3 - Best val accuracy: 0.5769 - Best val loss: 1.0256 - Best val F1: 0.4560\n","\n","Source class: WAL | Domain: 71 | Accuracy: 0.8400 | Loss: 1.5059 | F1: 0.7689\n","\n","Domain: 72\n","x_syn_dom.shape: (444, 3, 128) | np.unique(y_syn_dom): [0 1 2 3]\n","x_dp_dom.shape: (153, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","x_syn_dom.shape: (388, 3, 128) | np.unique(y_syn_dom): [0 1 2 3]\n","x_dp_dom.shape: (98, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Training on synthetic data...\n","\tEpoch 10/100 - Train loss: 0.3610 - Val accuracy: 0.2949 - Val loss: 3.0748 - Val F1: 0.1343 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.1243 - Val accuracy: 0.6923 - Val loss: 0.9527 - Val F1: 0.5954 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.0980 - Val accuracy: 0.6795 - Val loss: 1.5400 - Val F1: 0.5986 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.0944 - Val accuracy: 0.6923 - Val loss: 2.0129 - Val F1: 0.5990 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.0805 - Val accuracy: 0.6282 - Val loss: 2.0634 - Val F1: 0.5338 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.0676 - Val accuracy: 0.4487 - Val loss: 2.9207 - Val F1: 0.3671 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0590 - Val accuracy: 0.4359 - Val loss: 3.9044 - Val F1: 0.3419 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0332 - Val accuracy: 0.6410 - Val loss: 2.3281 - Val F1: 0.5470 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0486 - Val accuracy: 0.6795 - Val loss: 2.3526 - Val F1: 0.5831 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0401 - Val accuracy: 0.4615 - Val loss: 3.2056 - Val F1: 0.3892 - LR: 0.00e+00\n","\tBest epoch: 15 - Best val accuracy: 0.6923 - Best val loss: 0.5903 - Best val F1: 0.6323\n","\n","Source class: WAL | Domain: 72 | Accuracy: 0.8571 | Loss: 1.5762 | F1: 0.7937\n","\n","Domain: 73\n","x_syn_dom.shape: (444, 3, 128) | np.unique(y_syn_dom): [0 1 2 3]\n","x_dp_dom.shape: (152, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","x_syn_dom.shape: (388, 3, 128) | np.unique(y_syn_dom): [0 1 2 3]\n","x_dp_dom.shape: (97, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Training on synthetic data...\n","\tEpoch 10/100 - Train loss: 0.1225 - Val accuracy: 0.8333 - Val loss: 0.4876 - Val F1: 0.7764 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.0560 - Val accuracy: 0.8590 - Val loss: 0.5129 - Val F1: 0.8021 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.0460 - Val accuracy: 0.6154 - Val loss: 0.6062 - Val F1: 0.5066 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.0124 - Val accuracy: 0.7308 - Val loss: 0.5865 - Val F1: 0.6669 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.0286 - Val accuracy: 0.8205 - Val loss: 0.5368 - Val F1: 0.7634 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.0130 - Val accuracy: 0.8718 - Val loss: 0.2923 - Val F1: 0.8620 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0127 - Val accuracy: 0.8846 - Val loss: 0.3006 - Val F1: 0.8783 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0117 - Val accuracy: 0.7821 - Val loss: 0.3951 - Val F1: 0.7681 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0051 - Val accuracy: 0.8205 - Val loss: 0.3242 - Val F1: 0.8093 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0094 - Val accuracy: 0.9231 - Val loss: 0.1997 - Val F1: 0.9210 - LR: 0.00e+00\n","\tBest epoch: 76 - Best val accuracy: 0.9103 - Best val loss: 0.1823 - Best val F1: 0.9064\n","\n","Source class: WAL | Domain: 73 | Accuracy: 0.7835 | Loss: 0.8189 | F1: 0.7265\n","\n","Domain: 74\n","x_syn_dom.shape: (444, 3, 128) | np.unique(y_syn_dom): [0 1 2 3]\n","x_dp_dom.shape: (146, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","x_syn_dom.shape: (388, 3, 128) | np.unique(y_syn_dom): [0 1 2 3]\n","x_dp_dom.shape: (91, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Training on synthetic data...\n","\tEpoch 10/100 - Train loss: 0.3499 - Val accuracy: 0.2949 - Val loss: 4.4257 - Val F1: 0.1343 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.0990 - Val accuracy: 0.2949 - Val loss: 7.0663 - Val F1: 0.1343 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.0747 - Val accuracy: 0.2949 - Val loss: 7.0596 - Val F1: 0.1343 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.0424 - Val accuracy: 0.2949 - Val loss: 5.2540 - Val F1: 0.1343 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.0194 - Val accuracy: 0.2949 - Val loss: 6.7333 - Val F1: 0.1343 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.0112 - Val accuracy: 0.2949 - Val loss: 7.1269 - Val F1: 0.1343 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0094 - Val accuracy: 0.2949 - Val loss: 7.3931 - Val F1: 0.1343 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0308 - Val accuracy: 0.2949 - Val loss: 8.4384 - Val F1: 0.1343 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0240 - Val accuracy: 0.2949 - Val loss: 9.0528 - Val F1: 0.1343 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0090 - Val accuracy: 0.2949 - Val loss: 8.0426 - Val F1: 0.1343 - LR: 0.00e+00\n","\tBest epoch: 2 - Best val accuracy: 0.2821 - Best val loss: 1.3659 - Best val F1: 0.1279\n","\n","Source class: WAL | Domain: 74 | Accuracy: 0.3077 | Loss: 8.2030 | F1: 0.1448\n","\n","Domain: 75\n","x_syn_dom.shape: (444, 3, 128) | np.unique(y_syn_dom): [0 1 2 3]\n","x_dp_dom.shape: (153, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","x_syn_dom.shape: (388, 3, 128) | np.unique(y_syn_dom): [0 1 2 3]\n","x_dp_dom.shape: (98, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Training on synthetic data...\n","\tEpoch 10/100 - Train loss: 0.5466 - Val accuracy: 0.2949 - Val loss: 2.5623 - Val F1: 0.1343 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.1496 - Val accuracy: 0.2949 - Val loss: 2.2561 - Val F1: 0.1717 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.0787 - Val accuracy: 0.3462 - Val loss: 2.8978 - Val F1: 0.2585 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.0822 - Val accuracy: 0.4103 - Val loss: 4.9305 - Val F1: 0.3222 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.0475 - Val accuracy: 0.4359 - Val loss: 4.5942 - Val F1: 0.3419 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.0332 - Val accuracy: 0.3590 - Val loss: 5.3853 - Val F1: 0.2600 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0367 - Val accuracy: 0.4231 - Val loss: 5.0333 - Val F1: 0.3320 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0223 - Val accuracy: 0.3205 - Val loss: 4.7284 - Val F1: 0.2123 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0146 - Val accuracy: 0.3205 - Val loss: 3.8147 - Val F1: 0.2237 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0098 - Val accuracy: 0.3462 - Val loss: 5.6305 - Val F1: 0.2413 - LR: 0.00e+00\n","\tBest epoch: 3 - Best val accuracy: 0.5769 - Best val loss: 1.1073 - Best val F1: 0.4560\n","\n","Source class: WAL | Domain: 75 | Accuracy: 0.6429 | Loss: 2.1386 | F1: 0.5887\n","\n","Mean accuracy: 0.4683 +- 0.2277\n","Mean F1: 0.3690 +- 0.2680\n","\n"]}],"source":["def compute_TSTR_Syn_aug(dataset):\n","    accs = []\n","    f1s = []\n","\n","    for src_class in config[dataset]['class_names']:\n","        if src_class != 'WAL':\n","            continue\n","\n","        print(f\"Source class: {src_class}\\n\")\n","\n","        for domain in range(config[dataset]['num_df_domains'], config[dataset]['num_df_domains'] + config[dataset]['num_dp_domains']):\n","            print(f\"Domain: {domain}\")\n","\n","            # Load synthetic data\n","            x_syn_dom, y_syn_dom, k_syn_dom = get_syn_data(dataset, syn_name, src_class, domain)\n","            print(f'x_syn_dom.shape: {x_syn_dom.shape} | np.unique(y_syn_dom): {np.unique(y_syn_dom)}')\n","\n","            # Load Dp data\n","            x_dp_dom, y_dp_dom, k_dp_dom = get_data(dataset, 'dp', src_class, domain)\n","            print(f'x_dp_dom.shape: {x_dp_dom.shape} | np.unique(y_dp_dom): {np.unique(y_dp_dom)}\\n')\n","\n","            y0_indices_syn = np.where(y_syn_dom == 0)[0]\n","            y0_indices_dp = np.where(y_dp_dom == 0)[0]\n","            assert np.array_equal(y0_indices_syn, y0_indices_dp), \"Labels do not match\"\n","            assert np.array_equal(y_syn_dom[y0_indices_syn], y_dp_dom[y0_indices_dp]), \"Labels do not match\"\n","\n","            y0_indices_train, y0_indices_test = train_test_split(y0_indices_syn, test_size=0.5, shuffle=True, random_state=seed)\n","\n","            x_syn_dom_y0, y_syn_dom_y0 = x_syn_dom[y0_indices_train], y_syn_dom[y0_indices_train]\n","            x_dp_dom_y0, y_dp_dom_y0 = x_dp_dom[y0_indices_test], y_dp_dom[y0_indices_test]\n","\n","            x_syn_dom = np.concatenate([x_syn_dom_y0, x_syn_dom[y_syn_dom != 0]])\n","            y_syn_dom = np.concatenate([y_syn_dom_y0, y_syn_dom[y_syn_dom != 0]])\n","            x_dp_dom = np.concatenate([x_dp_dom_y0, x_dp_dom[y_dp_dom != 0]])\n","            y_dp_dom = np.concatenate([y_dp_dom_y0, y_dp_dom[y_dp_dom != 0]])\n","\n","            print(f'x_syn_dom.shape: {x_syn_dom.shape} | np.unique(y_syn_dom): {np.unique(y_syn_dom)}')\n","            print(f'x_dp_dom.shape: {x_dp_dom.shape} | np.unique(y_dp_dom): {np.unique(y_dp_dom)}\\n')\n","\n","            # Train on synthetic data and evaluate on Dp data\n","            print('Training on synthetic data...')\n","            acc, loss, f1 = train_and_test(x_syn_dom, y_syn_dom, x_dp_dom, y_dp_dom, dataset, num_epochs=num_epochs, augment=True)\n","            save_scores(src_class, domain, acc, loss, f1, 'Syn_aug', dataset)\n","            accs.append(acc)\n","            f1s.append(f1)\n","            print(f'Source class: {src_class} | Domain: {domain} | Accuracy: {acc:.4f} | Loss: {loss:.4f} | F1: {f1:.4f}\\n')\n","\n","    print(f\"Mean accuracy: {np.mean(accs):.4f} +- {np.std(accs):.4f}\")\n","    print(f\"Mean F1: {np.mean(f1s):.4f} +- {np.std(f1s):.4f}\\n\")\n","\n","\n","\n","\n","compute_TSTR_Syn_aug('realworld_mobiact')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"KKvjK_PAMxLm"},"outputs":[],"source":["# def compute_TSTR_Syn_all(dataset):\n","#     accs = []\n","\n","#     for src_class in config[dataset]['class_names']:\n","#         if src_class != 'WAL':\n","#             continue\n","\n","#         print(f\"Source class: {src_class}\\n\")\n","\n","#         # Load synthetic data\n","#         x_syn, y_syn, k_syn = get_syn_data(dataset, syn_name, src_class)\n","#         print(f'x_syn.shape: {x_syn.shape} | np.unique(y_syn): {np.unique(y_syn)}')\n","\n","#         # Load Dp data\n","#         x_dp, y_dp, k_dp = get_data(dataset, 'dp', src_class)\n","#         print(f'x_dp.shape: {x_dp.shape} | np.unique(y_dp): {np.unique(y_dp)}\\n')\n","\n","#         # Train on synthetic data and evaluate on Dp data\n","#         print('Training on synthetic data...')\n","#         acc, loss = train_and_test(x_syn, y_syn, x_dp, y_dp, dataset, num_epochs=num_epochs)\n","#         save_scores(src_class, 100, acc, loss, 'Syn_all', dataset)\n","#         accs.append(acc)\n","#         print(f'Source class: {src_class} | Domain: All | Accuracy: {acc:.4f} | Loss: {loss:.4f}\\n')\n","\n","#     print(f\"Mean accuracy: {np.mean(accs):.4f}\\n\")\n","\n","\n","\n","\n","# compute_TSTR_Syn_all('realworld_mobiact')"]},{"cell_type":"code","execution_count":7,"metadata":{"executionInfo":{"elapsed":433765,"status":"ok","timestamp":1732699764638,"user":{"displayName":"Pietro Pietro","userId":"08339472013712676764"},"user_tz":-60},"id":"LA71th1bCPto","colab":{"base_uri":"https://localhost:8080/"},"outputId":"b65c733e-9333-4ccc-8121-88fce7aa3247"},"outputs":[{"output_type":"stream","name":"stdout","text":["Source class: WAL\n","\n","x_df.shape: (11783, 3, 128) | np.unique(y_df): [0 1 2 3]\n","\n","Training on Df data...\n","\tEpoch 10/100 - Train loss: 0.1016 - Val accuracy: 0.9516 - Val loss: 0.1390 - Val F1: 0.9517 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.0415 - Val accuracy: 0.9525 - Val loss: 0.1329 - Val F1: 0.9525 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.0205 - Val accuracy: 0.9546 - Val loss: 0.1509 - Val F1: 0.9546 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.0109 - Val accuracy: 0.9529 - Val loss: 0.1579 - Val F1: 0.9529 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.0052 - Val accuracy: 0.9601 - Val loss: 0.1680 - Val F1: 0.9601 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.0043 - Val accuracy: 0.9593 - Val loss: 0.1789 - Val F1: 0.9593 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0027 - Val accuracy: 0.9610 - Val loss: 0.1837 - Val F1: 0.9610 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0022 - Val accuracy: 0.9588 - Val loss: 0.1766 - Val F1: 0.9589 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0013 - Val accuracy: 0.9605 - Val loss: 0.1845 - Val F1: 0.9606 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0012 - Val accuracy: 0.9605 - Val loss: 0.1939 - Val F1: 0.9606 - LR: 0.00e+00\n","\tBest epoch: 15 - Best val accuracy: 0.9571 - Best val loss: 0.1279 - Best val F1: 0.9572\n","\n","Domain: 15\n","x_syn_dom.shape: (444, 3, 128) | np.unique(y_syn_dom): [0 1 2 3]\n","x_dp_dom.shape: (161, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","x_syn_dom.shape: (388, 3, 128) | np.unique(y_syn_dom): [0 1 2 3]\n","x_dp_dom.shape: (106, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Fine-tuning on synthetic data...\n","\tEpoch 10/100 - Train loss: 1.6200 - Val accuracy: 0.6410 - Val loss: 1.6645 - Val F1: 0.6379 - LR: 9.00e-06\n","\tEpoch 20/100 - Train loss: 1.3464 - Val accuracy: 0.6410 - Val loss: 1.5404 - Val F1: 0.6379 - LR: 8.00e-06\n","\tEpoch 30/100 - Train loss: 1.4183 - Val accuracy: 0.6667 - Val loss: 1.4681 - Val F1: 0.6594 - LR: 7.00e-06\n","\tEpoch 40/100 - Train loss: 1.3208 - Val accuracy: 0.6923 - Val loss: 1.3438 - Val F1: 0.6951 - LR: 6.00e-06\n","\tEpoch 50/100 - Train loss: 1.3366 - Val accuracy: 0.6923 - Val loss: 1.2878 - Val F1: 0.6985 - LR: 5.00e-06\n","\tEpoch 60/100 - Train loss: 1.1339 - Val accuracy: 0.7179 - Val loss: 1.2716 - Val F1: 0.7211 - LR: 4.00e-06\n","\tEpoch 70/100 - Train loss: 1.1884 - Val accuracy: 0.7051 - Val loss: 1.2506 - Val F1: 0.7059 - LR: 3.00e-06\n","\tEpoch 80/100 - Train loss: 1.1564 - Val accuracy: 0.7179 - Val loss: 1.2097 - Val F1: 0.7211 - LR: 2.00e-06\n","\tEpoch 90/100 - Train loss: 1.0332 - Val accuracy: 0.7179 - Val loss: 1.1905 - Val F1: 0.7230 - LR: 1.00e-06\n","\tEpoch 100/100 - Train loss: 1.1074 - Val accuracy: 0.7179 - Val loss: 1.1930 - Val F1: 0.7230 - LR: 0.00e+00\n","\tBest epoch: 93 - Best val accuracy: 0.7179 - Best val loss: 1.1760 - Best val F1: 0.7252\n","\n","Source class: WAL | Domain: 15 | Accuracy: 0.5283 | Loss: 3.3761 | F1: 0.5374\n","\n","Domain: 16\n","x_syn_dom.shape: (444, 3, 128) | np.unique(y_syn_dom): [0 1 2 3]\n","x_dp_dom.shape: (165, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","x_syn_dom.shape: (388, 3, 128) | np.unique(y_syn_dom): [0 1 2 3]\n","x_dp_dom.shape: (110, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Fine-tuning on synthetic data...\n","\tEpoch 10/100 - Train loss: 1.6552 - Val accuracy: 0.6154 - Val loss: 2.2779 - Val F1: 0.6136 - LR: 9.00e-06\n","\tEpoch 20/100 - Train loss: 1.6189 - Val accuracy: 0.6282 - Val loss: 2.1063 - Val F1: 0.6221 - LR: 8.00e-06\n","\tEpoch 30/100 - Train loss: 1.3580 - Val accuracy: 0.6538 - Val loss: 2.0531 - Val F1: 0.6464 - LR: 7.00e-06\n","\tEpoch 40/100 - Train loss: 1.3118 - Val accuracy: 0.6667 - Val loss: 1.9573 - Val F1: 0.6551 - LR: 6.00e-06\n","\tEpoch 50/100 - Train loss: 1.2140 - Val accuracy: 0.6667 - Val loss: 1.9202 - Val F1: 0.6629 - LR: 5.00e-06\n","\tEpoch 60/100 - Train loss: 1.2208 - Val accuracy: 0.6667 - Val loss: 1.8899 - Val F1: 0.6629 - LR: 4.00e-06\n","\tEpoch 70/100 - Train loss: 1.3320 - Val accuracy: 0.6795 - Val loss: 1.8297 - Val F1: 0.6723 - LR: 3.00e-06\n","\tEpoch 80/100 - Train loss: 1.1299 - Val accuracy: 0.6538 - Val loss: 1.7975 - Val F1: 0.6534 - LR: 2.00e-06\n","\tEpoch 90/100 - Train loss: 1.1878 - Val accuracy: 0.6795 - Val loss: 1.8060 - Val F1: 0.6723 - LR: 1.00e-06\n","\tEpoch 100/100 - Train loss: 1.0501 - Val accuracy: 0.6667 - Val loss: 1.7759 - Val F1: 0.6551 - LR: 0.00e+00\n","\tBest epoch: 87 - Best val accuracy: 0.6667 - Best val loss: 1.7039 - Best val F1: 0.6611\n","\n","Source class: WAL | Domain: 16 | Accuracy: 0.5000 | Loss: 2.0000 | F1: 0.5353\n","\n","Domain: 17\n","x_syn_dom.shape: (444, 3, 128) | np.unique(y_syn_dom): [0 1 2 3]\n","x_dp_dom.shape: (164, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","x_syn_dom.shape: (388, 3, 128) | np.unique(y_syn_dom): [0 1 2 3]\n","x_dp_dom.shape: (109, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Fine-tuning on synthetic data...\n","\tEpoch 10/100 - Train loss: 1.1563 - Val accuracy: 0.7179 - Val loss: 0.9452 - Val F1: 0.7036 - LR: 9.00e-06\n","\tEpoch 20/100 - Train loss: 0.9930 - Val accuracy: 0.7051 - Val loss: 0.8845 - Val F1: 0.7075 - LR: 8.00e-06\n","\tEpoch 30/100 - Train loss: 1.0264 - Val accuracy: 0.7436 - Val loss: 0.8352 - Val F1: 0.7406 - LR: 7.00e-06\n","\tEpoch 40/100 - Train loss: 1.0734 - Val accuracy: 0.7436 - Val loss: 0.8326 - Val F1: 0.7329 - LR: 6.00e-06\n","\tEpoch 50/100 - Train loss: 0.9830 - Val accuracy: 0.7179 - Val loss: 0.8190 - Val F1: 0.7126 - LR: 5.00e-06\n","\tEpoch 60/100 - Train loss: 0.7994 - Val accuracy: 0.7308 - Val loss: 0.7876 - Val F1: 0.7239 - LR: 4.00e-06\n","\tEpoch 70/100 - Train loss: 0.9652 - Val accuracy: 0.7436 - Val loss: 0.7670 - Val F1: 0.7406 - LR: 3.00e-06\n","\tEpoch 80/100 - Train loss: 0.8503 - Val accuracy: 0.7308 - Val loss: 0.7629 - Val F1: 0.7250 - LR: 2.00e-06\n","\tEpoch 90/100 - Train loss: 0.8070 - Val accuracy: 0.7308 - Val loss: 0.7617 - Val F1: 0.7250 - LR: 1.00e-06\n","\tEpoch 100/100 - Train loss: 0.9910 - Val accuracy: 0.7692 - Val loss: 0.7570 - Val F1: 0.7697 - LR: 0.00e+00\n","\tBest epoch: 88 - Best val accuracy: 0.7564 - Best val loss: 0.7532 - Best val F1: 0.7537\n","\n","Source class: WAL | Domain: 17 | Accuracy: 0.4128 | Loss: 2.4915 | F1: 0.4408\n","\n","Domain: 18\n","x_syn_dom.shape: (448, 3, 128) | np.unique(y_syn_dom): [0 1 2 3]\n","x_dp_dom.shape: (166, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","x_syn_dom.shape: (392, 3, 128) | np.unique(y_syn_dom): [0 1 2 3]\n","x_dp_dom.shape: (110, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Fine-tuning on synthetic data...\n","\tEpoch 10/100 - Train loss: 1.0848 - Val accuracy: 0.7848 - Val loss: 0.7929 - Val F1: 0.7792 - LR: 9.00e-06\n","\tEpoch 20/100 - Train loss: 1.0860 - Val accuracy: 0.7848 - Val loss: 0.7423 - Val F1: 0.7792 - LR: 8.00e-06\n","\tEpoch 30/100 - Train loss: 0.8878 - Val accuracy: 0.7848 - Val loss: 0.7098 - Val F1: 0.7792 - LR: 7.00e-06\n","\tEpoch 40/100 - Train loss: 1.0352 - Val accuracy: 0.7848 - Val loss: 0.6628 - Val F1: 0.7792 - LR: 6.00e-06\n","\tEpoch 50/100 - Train loss: 0.8158 - Val accuracy: 0.7848 - Val loss: 0.6627 - Val F1: 0.7792 - LR: 5.00e-06\n","\tEpoch 60/100 - Train loss: 0.7991 - Val accuracy: 0.7848 - Val loss: 0.6302 - Val F1: 0.7792 - LR: 4.00e-06\n","\tEpoch 70/100 - Train loss: 0.8063 - Val accuracy: 0.7848 - Val loss: 0.6177 - Val F1: 0.7792 - LR: 3.00e-06\n","\tEpoch 80/100 - Train loss: 0.9328 - Val accuracy: 0.7975 - Val loss: 0.6415 - Val F1: 0.7900 - LR: 2.00e-06\n","\tEpoch 90/100 - Train loss: 0.6796 - Val accuracy: 0.7848 - Val loss: 0.6083 - Val F1: 0.7792 - LR: 1.00e-06\n","\tEpoch 100/100 - Train loss: 0.8033 - Val accuracy: 0.7848 - Val loss: 0.6107 - Val F1: 0.7792 - LR: 0.00e+00\n","\tBest epoch: 75 - Best val accuracy: 0.7848 - Best val loss: 0.5952 - Best val F1: 0.7810\n","\n","Source class: WAL | Domain: 18 | Accuracy: 0.6000 | Loss: 1.6870 | F1: 0.6441\n","\n","Domain: 19\n","x_syn_dom.shape: (444, 3, 128) | np.unique(y_syn_dom): [0 1 2 3]\n","x_dp_dom.shape: (165, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","x_syn_dom.shape: (388, 3, 128) | np.unique(y_syn_dom): [0 1 2 3]\n","x_dp_dom.shape: (110, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Fine-tuning on synthetic data...\n","\tEpoch 10/100 - Train loss: 0.9098 - Val accuracy: 0.8205 - Val loss: 0.5659 - Val F1: 0.7913 - LR: 9.00e-06\n","\tEpoch 20/100 - Train loss: 0.7001 - Val accuracy: 0.8462 - Val loss: 0.4556 - Val F1: 0.8312 - LR: 8.00e-06\n","\tEpoch 30/100 - Train loss: 0.7375 - Val accuracy: 0.8333 - Val loss: 0.4417 - Val F1: 0.8182 - LR: 7.00e-06\n","\tEpoch 40/100 - Train loss: 0.5974 - Val accuracy: 0.8462 - Val loss: 0.4069 - Val F1: 0.8312 - LR: 6.00e-06\n","\tEpoch 50/100 - Train loss: 0.6907 - Val accuracy: 0.8462 - Val loss: 0.3726 - Val F1: 0.8312 - LR: 5.00e-06\n","\tEpoch 60/100 - Train loss: 0.5500 - Val accuracy: 0.8462 - Val loss: 0.3636 - Val F1: 0.8312 - LR: 4.00e-06\n","\tEpoch 70/100 - Train loss: 0.5266 - Val accuracy: 0.8333 - Val loss: 0.3434 - Val F1: 0.8182 - LR: 3.00e-06\n","\tEpoch 80/100 - Train loss: 0.6294 - Val accuracy: 0.8462 - Val loss: 0.3382 - Val F1: 0.8312 - LR: 2.00e-06\n","\tEpoch 90/100 - Train loss: 0.5559 - Val accuracy: 0.8462 - Val loss: 0.3491 - Val F1: 0.8312 - LR: 1.00e-06\n","\tEpoch 100/100 - Train loss: 0.5414 - Val accuracy: 0.8333 - Val loss: 0.3549 - Val F1: 0.8182 - LR: 0.00e+00\n","\tBest epoch: 71 - Best val accuracy: 0.8462 - Best val loss: 0.3165 - Best val F1: 0.8312\n","\n","Source class: WAL | Domain: 19 | Accuracy: 0.3727 | Loss: 2.2093 | F1: 0.4243\n","\n","Domain: 20\n","x_syn_dom.shape: (444, 3, 128) | np.unique(y_syn_dom): [0 1 2 3]\n","x_dp_dom.shape: (162, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","x_syn_dom.shape: (388, 3, 128) | np.unique(y_syn_dom): [0 1 2 3]\n","x_dp_dom.shape: (107, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Fine-tuning on synthetic data...\n","\tEpoch 10/100 - Train loss: 1.1821 - Val accuracy: 0.6923 - Val loss: 1.3921 - Val F1: 0.6982 - LR: 9.00e-06\n","\tEpoch 20/100 - Train loss: 1.1611 - Val accuracy: 0.6923 - Val loss: 1.2506 - Val F1: 0.6952 - LR: 8.00e-06\n","\tEpoch 30/100 - Train loss: 1.1450 - Val accuracy: 0.7179 - Val loss: 1.1428 - Val F1: 0.7148 - LR: 7.00e-06\n","\tEpoch 40/100 - Train loss: 1.0190 - Val accuracy: 0.7436 - Val loss: 1.0499 - Val F1: 0.7438 - LR: 6.00e-06\n","\tEpoch 50/100 - Train loss: 1.0895 - Val accuracy: 0.7308 - Val loss: 1.0568 - Val F1: 0.7304 - LR: 5.00e-06\n","\tEpoch 60/100 - Train loss: 1.0070 - Val accuracy: 0.7308 - Val loss: 1.0124 - Val F1: 0.7304 - LR: 4.00e-06\n","\tEpoch 70/100 - Train loss: 0.8942 - Val accuracy: 0.7179 - Val loss: 0.9893 - Val F1: 0.7183 - LR: 3.00e-06\n","\tEpoch 80/100 - Train loss: 1.0239 - Val accuracy: 0.7564 - Val loss: 0.9067 - Val F1: 0.7607 - LR: 2.00e-06\n","\tEpoch 90/100 - Train loss: 1.1405 - Val accuracy: 0.7564 - Val loss: 0.8983 - Val F1: 0.7553 - LR: 1.00e-06\n","\tEpoch 100/100 - Train loss: 0.9240 - Val accuracy: 0.7692 - Val loss: 0.9170 - Val F1: 0.7685 - LR: 0.00e+00\n","\tBest epoch: 89 - Best val accuracy: 0.7564 - Best val loss: 0.8915 - Best val F1: 0.7580\n","\n","Source class: WAL | Domain: 20 | Accuracy: 0.5888 | Loss: 2.1402 | F1: 0.6194\n","\n","Domain: 21\n","x_syn_dom.shape: (448, 3, 128) | np.unique(y_syn_dom): [0 1 2 3]\n","x_dp_dom.shape: (159, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","x_syn_dom.shape: (392, 3, 128) | np.unique(y_syn_dom): [0 1 2 3]\n","x_dp_dom.shape: (103, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Fine-tuning on synthetic data...\n","\tEpoch 10/100 - Train loss: 1.3872 - Val accuracy: 0.7595 - Val loss: 1.4336 - Val F1: 0.7547 - LR: 9.00e-06\n","\tEpoch 20/100 - Train loss: 1.3102 - Val accuracy: 0.7468 - Val loss: 1.2870 - Val F1: 0.7491 - LR: 8.00e-06\n","\tEpoch 30/100 - Train loss: 1.0206 - Val accuracy: 0.7468 - Val loss: 1.2464 - Val F1: 0.7491 - LR: 7.00e-06\n","\tEpoch 40/100 - Train loss: 1.0273 - Val accuracy: 0.7342 - Val loss: 1.1733 - Val F1: 0.7391 - LR: 6.00e-06\n","\tEpoch 50/100 - Train loss: 1.2086 - Val accuracy: 0.7468 - Val loss: 1.1439 - Val F1: 0.7518 - LR: 5.00e-06\n","\tEpoch 60/100 - Train loss: 0.9089 - Val accuracy: 0.7468 - Val loss: 1.0990 - Val F1: 0.7518 - LR: 4.00e-06\n","\tEpoch 70/100 - Train loss: 0.9239 - Val accuracy: 0.7468 - Val loss: 1.0688 - Val F1: 0.7518 - LR: 3.00e-06\n","\tEpoch 80/100 - Train loss: 0.8881 - Val accuracy: 0.7468 - Val loss: 1.0595 - Val F1: 0.7518 - LR: 2.00e-06\n","\tEpoch 90/100 - Train loss: 0.8873 - Val accuracy: 0.7468 - Val loss: 1.0472 - Val F1: 0.7518 - LR: 1.00e-06\n","\tEpoch 100/100 - Train loss: 0.9317 - Val accuracy: 0.7468 - Val loss: 1.0354 - Val F1: 0.7518 - LR: 0.00e+00\n","\tBest epoch: 100 - Best val accuracy: 0.7468 - Best val loss: 1.0354 - Best val F1: 0.7518\n","\n","Source class: WAL | Domain: 21 | Accuracy: 0.4466 | Loss: 2.4713 | F1: 0.5113\n","\n","Domain: 22\n","x_syn_dom.shape: (444, 3, 128) | np.unique(y_syn_dom): [0 1 2 3]\n","x_dp_dom.shape: (165, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","x_syn_dom.shape: (388, 3, 128) | np.unique(y_syn_dom): [0 1 2 3]\n","x_dp_dom.shape: (110, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Fine-tuning on synthetic data...\n","\tEpoch 10/100 - Train loss: 1.4306 - Val accuracy: 0.7436 - Val loss: 1.2538 - Val F1: 0.7387 - LR: 9.00e-06\n","\tEpoch 20/100 - Train loss: 1.4035 - Val accuracy: 0.7564 - Val loss: 1.1578 - Val F1: 0.7530 - LR: 8.00e-06\n","\tEpoch 30/100 - Train loss: 1.3394 - Val accuracy: 0.7564 - Val loss: 1.0909 - Val F1: 0.7535 - LR: 7.00e-06\n","\tEpoch 40/100 - Train loss: 1.2510 - Val accuracy: 0.7692 - Val loss: 1.0317 - Val F1: 0.7632 - LR: 6.00e-06\n","\tEpoch 50/100 - Train loss: 1.2330 - Val accuracy: 0.7821 - Val loss: 1.0363 - Val F1: 0.7768 - LR: 5.00e-06\n","\tEpoch 60/100 - Train loss: 1.1846 - Val accuracy: 0.7692 - Val loss: 0.9741 - Val F1: 0.7632 - LR: 4.00e-06\n","\tEpoch 70/100 - Train loss: 1.1672 - Val accuracy: 0.7821 - Val loss: 0.9786 - Val F1: 0.7771 - LR: 3.00e-06\n","\tEpoch 80/100 - Train loss: 1.1683 - Val accuracy: 0.7821 - Val loss: 0.9691 - Val F1: 0.7771 - LR: 2.00e-06\n","\tEpoch 90/100 - Train loss: 1.1137 - Val accuracy: 0.7692 - Val loss: 0.9510 - Val F1: 0.7632 - LR: 1.00e-06\n","\tEpoch 100/100 - Train loss: 1.0333 - Val accuracy: 0.7821 - Val loss: 0.9303 - Val F1: 0.7759 - LR: 0.00e+00\n","\tBest epoch: 88 - Best val accuracy: 0.7821 - Best val loss: 0.8965 - Best val F1: 0.7771\n","\n","Source class: WAL | Domain: 22 | Accuracy: 0.5273 | Loss: 2.3769 | F1: 0.5455\n","\n","Domain: 23\n","x_syn_dom.shape: (448, 3, 128) | np.unique(y_syn_dom): [0 1 2 3]\n","x_dp_dom.shape: (164, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","x_syn_dom.shape: (392, 3, 128) | np.unique(y_syn_dom): [0 1 2 3]\n","x_dp_dom.shape: (108, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Fine-tuning on synthetic data...\n","\tEpoch 10/100 - Train loss: 2.4418 - Val accuracy: 0.6203 - Val loss: 1.7948 - Val F1: 0.6146 - LR: 9.00e-06\n","\tEpoch 20/100 - Train loss: 1.9766 - Val accuracy: 0.6203 - Val loss: 1.6484 - Val F1: 0.6193 - LR: 8.00e-06\n","\tEpoch 30/100 - Train loss: 2.0025 - Val accuracy: 0.6329 - Val loss: 1.4970 - Val F1: 0.6322 - LR: 7.00e-06\n","\tEpoch 40/100 - Train loss: 1.7334 - Val accuracy: 0.6456 - Val loss: 1.3561 - Val F1: 0.6481 - LR: 6.00e-06\n","\tEpoch 50/100 - Train loss: 1.5084 - Val accuracy: 0.6835 - Val loss: 1.2994 - Val F1: 0.6813 - LR: 5.00e-06\n","\tEpoch 60/100 - Train loss: 1.5476 - Val accuracy: 0.6582 - Val loss: 1.2250 - Val F1: 0.6602 - LR: 4.00e-06\n","\tEpoch 70/100 - Train loss: 1.6370 - Val accuracy: 0.6709 - Val loss: 1.1641 - Val F1: 0.6722 - LR: 3.00e-06\n","\tEpoch 80/100 - Train loss: 1.5559 - Val accuracy: 0.6835 - Val loss: 1.1506 - Val F1: 0.6813 - LR: 2.00e-06\n","\tEpoch 90/100 - Train loss: 1.5699 - Val accuracy: 0.6835 - Val loss: 1.1175 - Val F1: 0.6813 - LR: 1.00e-06\n","\tEpoch 100/100 - Train loss: 1.4550 - Val accuracy: 0.6835 - Val loss: 1.0928 - Val F1: 0.6813 - LR: 0.00e+00\n","\tBest epoch: 100 - Best val accuracy: 0.6835 - Best val loss: 1.0928 - Best val F1: 0.6813\n","\n","Source class: WAL | Domain: 23 | Accuracy: 0.5463 | Loss: 2.0707 | F1: 0.5767\n","\n","Domain: 24\n","x_syn_dom.shape: (444, 3, 128) | np.unique(y_syn_dom): [0 1 2 3]\n","x_dp_dom.shape: (162, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","x_syn_dom.shape: (388, 3, 128) | np.unique(y_syn_dom): [0 1 2 3]\n","x_dp_dom.shape: (107, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Fine-tuning on synthetic data...\n","\tEpoch 10/100 - Train loss: 1.7412 - Val accuracy: 0.7308 - Val loss: 1.1119 - Val F1: 0.7205 - LR: 9.00e-06\n","\tEpoch 20/100 - Train loss: 1.6629 - Val accuracy: 0.7179 - Val loss: 0.9465 - Val F1: 0.7148 - LR: 8.00e-06\n","\tEpoch 30/100 - Train loss: 1.6356 - Val accuracy: 0.7692 - Val loss: 0.9019 - Val F1: 0.7706 - LR: 7.00e-06\n","\tEpoch 40/100 - Train loss: 1.6257 - Val accuracy: 0.7821 - Val loss: 0.9235 - Val F1: 0.7824 - LR: 6.00e-06\n","\tEpoch 50/100 - Train loss: 1.3922 - Val accuracy: 0.7949 - Val loss: 0.8824 - Val F1: 0.7945 - LR: 5.00e-06\n","\tEpoch 60/100 - Train loss: 1.3374 - Val accuracy: 0.7821 - Val loss: 0.9200 - Val F1: 0.7820 - LR: 4.00e-06\n","\tEpoch 70/100 - Train loss: 1.3208 - Val accuracy: 0.7821 - Val loss: 0.7901 - Val F1: 0.7853 - LR: 3.00e-06\n","\tEpoch 80/100 - Train loss: 1.0837 - Val accuracy: 0.7692 - Val loss: 0.7677 - Val F1: 0.7715 - LR: 2.00e-06\n","\tEpoch 90/100 - Train loss: 1.2988 - Val accuracy: 0.7949 - Val loss: 0.7653 - Val F1: 0.7945 - LR: 1.00e-06\n","\tEpoch 100/100 - Train loss: 1.3361 - Val accuracy: 0.7821 - Val loss: 0.7286 - Val F1: 0.7803 - LR: 0.00e+00\n","\tBest epoch: 96 - Best val accuracy: 0.7692 - Best val loss: 0.7278 - Best val F1: 0.7759\n","\n","Source class: WAL | Domain: 24 | Accuracy: 0.4112 | Loss: 3.1445 | F1: 0.4229\n","\n","Domain: 25\n","x_syn_dom.shape: (448, 3, 128) | np.unique(y_syn_dom): [0 1 2 3]\n","x_dp_dom.shape: (166, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","x_syn_dom.shape: (392, 3, 128) | np.unique(y_syn_dom): [0 1 2 3]\n","x_dp_dom.shape: (110, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Fine-tuning on synthetic data...\n","\tEpoch 10/100 - Train loss: 0.9414 - Val accuracy: 0.8101 - Val loss: 0.5427 - Val F1: 0.8124 - LR: 9.00e-06\n","\tEpoch 20/100 - Train loss: 0.7697 - Val accuracy: 0.8354 - Val loss: 0.5016 - Val F1: 0.8331 - LR: 8.00e-06\n","\tEpoch 30/100 - Train loss: 0.7690 - Val accuracy: 0.8481 - Val loss: 0.4569 - Val F1: 0.8481 - LR: 7.00e-06\n","\tEpoch 40/100 - Train loss: 0.6796 - Val accuracy: 0.8608 - Val loss: 0.4296 - Val F1: 0.8623 - LR: 6.00e-06\n","\tEpoch 50/100 - Train loss: 0.6249 - Val accuracy: 0.8481 - Val loss: 0.4133 - Val F1: 0.8481 - LR: 5.00e-06\n","\tEpoch 60/100 - Train loss: 0.5539 - Val accuracy: 0.8608 - Val loss: 0.3888 - Val F1: 0.8623 - LR: 4.00e-06\n","\tEpoch 70/100 - Train loss: 0.6001 - Val accuracy: 0.8734 - Val loss: 0.3802 - Val F1: 0.8759 - LR: 3.00e-06\n","\tEpoch 80/100 - Train loss: 0.5860 - Val accuracy: 0.8481 - Val loss: 0.3803 - Val F1: 0.8511 - LR: 2.00e-06\n","\tEpoch 90/100 - Train loss: 0.5713 - Val accuracy: 0.8734 - Val loss: 0.3641 - Val F1: 0.8759 - LR: 1.00e-06\n","\tEpoch 100/100 - Train loss: 0.6636 - Val accuracy: 0.8608 - Val loss: 0.3673 - Val F1: 0.8646 - LR: 0.00e+00\n","\tBest epoch: 86 - Best val accuracy: 0.8608 - Best val loss: 0.3619 - Best val F1: 0.8646\n","\n","Source class: WAL | Domain: 25 | Accuracy: 0.5273 | Loss: 1.7024 | F1: 0.5504\n","\n","Domain: 26\n","x_syn_dom.shape: (444, 3, 128) | np.unique(y_syn_dom): [0 1 2 3]\n","x_dp_dom.shape: (153, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","x_syn_dom.shape: (388, 3, 128) | np.unique(y_syn_dom): [0 1 2 3]\n","x_dp_dom.shape: (98, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Fine-tuning on synthetic data...\n","\tEpoch 10/100 - Train loss: 1.4316 - Val accuracy: 0.7179 - Val loss: 1.0338 - Val F1: 0.7239 - LR: 9.00e-06\n","\tEpoch 20/100 - Train loss: 1.2478 - Val accuracy: 0.7179 - Val loss: 0.9476 - Val F1: 0.7239 - LR: 8.00e-06\n","\tEpoch 30/100 - Train loss: 1.0901 - Val accuracy: 0.7179 - Val loss: 0.8871 - Val F1: 0.7239 - LR: 7.00e-06\n","\tEpoch 40/100 - Train loss: 1.1539 - Val accuracy: 0.7179 - Val loss: 0.8393 - Val F1: 0.7239 - LR: 6.00e-06\n","\tEpoch 50/100 - Train loss: 0.9889 - Val accuracy: 0.7436 - Val loss: 0.7997 - Val F1: 0.7411 - LR: 5.00e-06\n","\tEpoch 60/100 - Train loss: 0.9314 - Val accuracy: 0.7436 - Val loss: 0.7676 - Val F1: 0.7436 - LR: 4.00e-06\n","\tEpoch 70/100 - Train loss: 0.9213 - Val accuracy: 0.7179 - Val loss: 0.7556 - Val F1: 0.7245 - LR: 3.00e-06\n","\tEpoch 80/100 - Train loss: 0.9997 - Val accuracy: 0.7308 - Val loss: 0.7435 - Val F1: 0.7346 - LR: 2.00e-06\n","\tEpoch 90/100 - Train loss: 0.9293 - Val accuracy: 0.7308 - Val loss: 0.7466 - Val F1: 0.7379 - LR: 1.00e-06\n","\tEpoch 100/100 - Train loss: 0.9264 - Val accuracy: 0.7179 - Val loss: 0.7135 - Val F1: 0.7220 - LR: 0.00e+00\n","\tBest epoch: 94 - Best val accuracy: 0.7308 - Best val loss: 0.7120 - Best val F1: 0.7322\n","\n","Source class: WAL | Domain: 26 | Accuracy: 0.2959 | Loss: 3.4822 | F1: 0.3710\n","\n","Domain: 27\n","x_syn_dom.shape: (444, 3, 128) | np.unique(y_syn_dom): [0 1 2 3]\n","x_dp_dom.shape: (165, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","x_syn_dom.shape: (388, 3, 128) | np.unique(y_syn_dom): [0 1 2 3]\n","x_dp_dom.shape: (110, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Fine-tuning on synthetic data...\n","\tEpoch 10/100 - Train loss: 1.7369 - Val accuracy: 0.5769 - Val loss: 2.1670 - Val F1: 0.5698 - LR: 9.00e-06\n","\tEpoch 20/100 - Train loss: 1.5276 - Val accuracy: 0.5897 - Val loss: 2.0887 - Val F1: 0.5816 - LR: 8.00e-06\n","\tEpoch 30/100 - Train loss: 1.4501 - Val accuracy: 0.6410 - Val loss: 1.9955 - Val F1: 0.6230 - LR: 7.00e-06\n","\tEpoch 40/100 - Train loss: 1.1881 - Val accuracy: 0.6538 - Val loss: 1.8759 - Val F1: 0.6329 - LR: 6.00e-06\n","\tEpoch 50/100 - Train loss: 1.2332 - Val accuracy: 0.6154 - Val loss: 1.7838 - Val F1: 0.6036 - LR: 5.00e-06\n","\tEpoch 60/100 - Train loss: 1.1349 - Val accuracy: 0.6282 - Val loss: 1.7238 - Val F1: 0.6107 - LR: 4.00e-06\n","\tEpoch 70/100 - Train loss: 1.0568 - Val accuracy: 0.6282 - Val loss: 1.6313 - Val F1: 0.6118 - LR: 3.00e-06\n","\tEpoch 80/100 - Train loss: 1.2226 - Val accuracy: 0.6154 - Val loss: 1.6453 - Val F1: 0.5974 - LR: 2.00e-06\n","\tEpoch 90/100 - Train loss: 1.0545 - Val accuracy: 0.6410 - Val loss: 1.6248 - Val F1: 0.6190 - LR: 1.00e-06\n","\tEpoch 100/100 - Train loss: 1.1708 - Val accuracy: 0.6154 - Val loss: 1.5913 - Val F1: 0.5996 - LR: 0.00e+00\n","\tBest epoch: 97 - Best val accuracy: 0.6282 - Best val loss: 1.5726 - Best val F1: 0.6118\n","\n","Source class: WAL | Domain: 27 | Accuracy: 0.4636 | Loss: 3.8851 | F1: 0.4589\n","\n","Domain: 28\n","x_syn_dom.shape: (444, 3, 128) | np.unique(y_syn_dom): [0 1 2 3]\n","x_dp_dom.shape: (153, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","x_syn_dom.shape: (388, 3, 128) | np.unique(y_syn_dom): [0 1 2 3]\n","x_dp_dom.shape: (98, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Fine-tuning on synthetic data...\n","\tEpoch 10/100 - Train loss: 2.2484 - Val accuracy: 0.6923 - Val loss: 1.8105 - Val F1: 0.6831 - LR: 9.00e-06\n","\tEpoch 20/100 - Train loss: 1.7261 - Val accuracy: 0.6923 - Val loss: 1.6750 - Val F1: 0.6818 - LR: 8.00e-06\n","\tEpoch 30/100 - Train loss: 1.8762 - Val accuracy: 0.6923 - Val loss: 1.5835 - Val F1: 0.6818 - LR: 7.00e-06\n","\tEpoch 40/100 - Train loss: 1.7079 - Val accuracy: 0.6923 - Val loss: 1.5268 - Val F1: 0.6818 - LR: 6.00e-06\n","\tEpoch 50/100 - Train loss: 1.5779 - Val accuracy: 0.7179 - Val loss: 1.4424 - Val F1: 0.7022 - LR: 5.00e-06\n","\tEpoch 60/100 - Train loss: 1.5382 - Val accuracy: 0.7179 - Val loss: 1.3663 - Val F1: 0.7111 - LR: 4.00e-06\n","\tEpoch 70/100 - Train loss: 1.4951 - Val accuracy: 0.7179 - Val loss: 1.3532 - Val F1: 0.7022 - LR: 3.00e-06\n","\tEpoch 80/100 - Train loss: 1.4390 - Val accuracy: 0.7308 - Val loss: 1.3289 - Val F1: 0.7208 - LR: 2.00e-06\n","\tEpoch 90/100 - Train loss: 1.5170 - Val accuracy: 0.7308 - Val loss: 1.3008 - Val F1: 0.7208 - LR: 1.00e-06\n","\tEpoch 100/100 - Train loss: 1.3081 - Val accuracy: 0.7436 - Val loss: 1.2867 - Val F1: 0.7324 - LR: 0.00e+00\n","\tBest epoch: 100 - Best val accuracy: 0.7436 - Best val loss: 1.2867 - Best val F1: 0.7324\n","\n","Source class: WAL | Domain: 28 | Accuracy: 0.3776 | Loss: 4.8328 | F1: 0.3766\n","\n","Domain: 29\n","x_syn_dom.shape: (444, 3, 128) | np.unique(y_syn_dom): [0 1 2 3]\n","x_dp_dom.shape: (153, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","x_syn_dom.shape: (388, 3, 128) | np.unique(y_syn_dom): [0 1 2 3]\n","x_dp_dom.shape: (98, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Fine-tuning on synthetic data...\n","\tEpoch 10/100 - Train loss: 1.6584 - Val accuracy: 0.7051 - Val loss: 1.2605 - Val F1: 0.6942 - LR: 9.00e-06\n","\tEpoch 20/100 - Train loss: 1.3886 - Val accuracy: 0.7308 - Val loss: 1.1266 - Val F1: 0.7287 - LR: 8.00e-06\n","\tEpoch 30/100 - Train loss: 1.2273 - Val accuracy: 0.7436 - Val loss: 1.0492 - Val F1: 0.7405 - LR: 7.00e-06\n","\tEpoch 40/100 - Train loss: 1.0667 - Val accuracy: 0.7436 - Val loss: 0.9874 - Val F1: 0.7405 - LR: 6.00e-06\n","\tEpoch 50/100 - Train loss: 1.1454 - Val accuracy: 0.7436 - Val loss: 0.9135 - Val F1: 0.7405 - LR: 5.00e-06\n","\tEpoch 60/100 - Train loss: 1.0997 - Val accuracy: 0.7436 - Val loss: 0.8615 - Val F1: 0.7378 - LR: 4.00e-06\n","\tEpoch 70/100 - Train loss: 1.2400 - Val accuracy: 0.7564 - Val loss: 0.8485 - Val F1: 0.7493 - LR: 3.00e-06\n","\tEpoch 80/100 - Train loss: 1.0940 - Val accuracy: 0.7564 - Val loss: 0.8326 - Val F1: 0.7493 - LR: 2.00e-06\n","\tEpoch 90/100 - Train loss: 1.0562 - Val accuracy: 0.7692 - Val loss: 0.8164 - Val F1: 0.7589 - LR: 1.00e-06\n","\tEpoch 100/100 - Train loss: 1.1408 - Val accuracy: 0.7436 - Val loss: 0.8162 - Val F1: 0.7405 - LR: 0.00e+00\n","\tBest epoch: 94 - Best val accuracy: 0.7436 - Best val loss: 0.7967 - Best val F1: 0.7410\n","\n","Source class: WAL | Domain: 29 | Accuracy: 0.3367 | Loss: 2.8106 | F1: 0.4151\n","\n","Domain: 30\n","x_syn_dom.shape: (444, 3, 128) | np.unique(y_syn_dom): [0 1 2 3]\n","x_dp_dom.shape: (161, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","x_syn_dom.shape: (388, 3, 128) | np.unique(y_syn_dom): [0 1 2 3]\n","x_dp_dom.shape: (106, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Fine-tuning on synthetic data...\n","\tEpoch 10/100 - Train loss: 2.1233 - Val accuracy: 0.6282 - Val loss: 2.2317 - Val F1: 0.6430 - LR: 9.00e-06\n","\tEpoch 20/100 - Train loss: 1.7395 - Val accuracy: 0.6026 - Val loss: 1.9795 - Val F1: 0.6337 - LR: 8.00e-06\n","\tEpoch 30/100 - Train loss: 1.5366 - Val accuracy: 0.6154 - Val loss: 1.8699 - Val F1: 0.6337 - LR: 7.00e-06\n","\tEpoch 40/100 - Train loss: 1.6554 - Val accuracy: 0.6282 - Val loss: 1.6683 - Val F1: 0.6470 - LR: 6.00e-06\n","\tEpoch 50/100 - Train loss: 1.3230 - Val accuracy: 0.6795 - Val loss: 1.6136 - Val F1: 0.6921 - LR: 5.00e-06\n","\tEpoch 60/100 - Train loss: 1.2351 - Val accuracy: 0.6154 - Val loss: 1.5321 - Val F1: 0.6337 - LR: 4.00e-06\n","\tEpoch 70/100 - Train loss: 1.2610 - Val accuracy: 0.6282 - Val loss: 1.4485 - Val F1: 0.6464 - LR: 3.00e-06\n","\tEpoch 80/100 - Train loss: 1.1914 - Val accuracy: 0.6154 - Val loss: 1.4605 - Val F1: 0.6337 - LR: 2.00e-06\n","\tEpoch 90/100 - Train loss: 1.2803 - Val accuracy: 0.6410 - Val loss: 1.4204 - Val F1: 0.6585 - LR: 1.00e-06\n","\tEpoch 100/100 - Train loss: 1.1009 - Val accuracy: 0.6154 - Val loss: 1.4230 - Val F1: 0.6344 - LR: 0.00e+00\n","\tBest epoch: 99 - Best val accuracy: 0.6538 - Best val loss: 1.3255 - Best val F1: 0.6694\n","\n","Source class: WAL | Domain: 30 | Accuracy: 0.3585 | Loss: 5.9328 | F1: 0.3712\n","\n","Domain: 31\n","x_syn_dom.shape: (444, 3, 128) | np.unique(y_syn_dom): [0 1 2 3]\n","x_dp_dom.shape: (154, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","x_syn_dom.shape: (388, 3, 128) | np.unique(y_syn_dom): [0 1 2 3]\n","x_dp_dom.shape: (99, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Fine-tuning on synthetic data...\n","\tEpoch 10/100 - Train loss: 2.2231 - Val accuracy: 0.7308 - Val loss: 2.1451 - Val F1: 0.7069 - LR: 9.00e-06\n","\tEpoch 20/100 - Train loss: 1.7168 - Val accuracy: 0.7436 - Val loss: 1.4874 - Val F1: 0.7257 - LR: 8.00e-06\n","\tEpoch 30/100 - Train loss: 1.2549 - Val accuracy: 0.7308 - Val loss: 1.1205 - Val F1: 0.7206 - LR: 7.00e-06\n","\tEpoch 40/100 - Train loss: 0.9729 - Val accuracy: 0.7949 - Val loss: 0.6338 - Val F1: 0.7983 - LR: 6.00e-06\n","\tEpoch 50/100 - Train loss: 0.7125 - Val accuracy: 0.8205 - Val loss: 0.4835 - Val F1: 0.8209 - LR: 5.00e-06\n","\tEpoch 60/100 - Train loss: 0.6253 - Val accuracy: 0.8718 - Val loss: 0.3953 - Val F1: 0.8738 - LR: 4.00e-06\n","\tEpoch 70/100 - Train loss: 0.4650 - Val accuracy: 0.8718 - Val loss: 0.3703 - Val F1: 0.8738 - LR: 3.00e-06\n","\tEpoch 80/100 - Train loss: 0.4635 - Val accuracy: 0.8718 - Val loss: 0.3387 - Val F1: 0.8738 - LR: 2.00e-06\n","\tEpoch 90/100 - Train loss: 0.3825 - Val accuracy: 0.9103 - Val loss: 0.3314 - Val F1: 0.9094 - LR: 1.00e-06\n","\tEpoch 100/100 - Train loss: 0.3819 - Val accuracy: 0.8718 - Val loss: 0.3153 - Val F1: 0.8738 - LR: 0.00e+00\n","\tBest epoch: 97 - Best val accuracy: 0.8974 - Best val loss: 0.2740 - Best val F1: 0.8977\n","\n","Source class: WAL | Domain: 31 | Accuracy: 0.8081 | Loss: 2.1979 | F1: 0.7592\n","\n","Domain: 32\n","x_syn_dom.shape: (444, 3, 128) | np.unique(y_syn_dom): [0 1 2 3]\n","x_dp_dom.shape: (163, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","x_syn_dom.shape: (388, 3, 128) | np.unique(y_syn_dom): [0 1 2 3]\n","x_dp_dom.shape: (108, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Fine-tuning on synthetic data...\n","\tEpoch 10/100 - Train loss: 1.0029 - Val accuracy: 0.7949 - Val loss: 0.9419 - Val F1: 0.7807 - LR: 9.00e-06\n","\tEpoch 20/100 - Train loss: 1.0477 - Val accuracy: 0.7821 - Val loss: 0.9137 - Val F1: 0.7721 - LR: 8.00e-06\n","\tEpoch 30/100 - Train loss: 0.9106 - Val accuracy: 0.8077 - Val loss: 0.8726 - Val F1: 0.7926 - LR: 7.00e-06\n","\tEpoch 40/100 - Train loss: 0.8781 - Val accuracy: 0.8077 - Val loss: 0.8436 - Val F1: 0.7926 - LR: 6.00e-06\n","\tEpoch 50/100 - Train loss: 0.6605 - Val accuracy: 0.8077 - Val loss: 0.8067 - Val F1: 0.7926 - LR: 5.00e-06\n","\tEpoch 60/100 - Train loss: 0.8332 - Val accuracy: 0.8077 - Val loss: 0.7600 - Val F1: 0.7926 - LR: 4.00e-06\n","\tEpoch 70/100 - Train loss: 0.6862 - Val accuracy: 0.8077 - Val loss: 0.7401 - Val F1: 0.7926 - LR: 3.00e-06\n","\tEpoch 80/100 - Train loss: 0.8008 - Val accuracy: 0.8333 - Val loss: 0.7324 - Val F1: 0.8111 - LR: 2.00e-06\n","\tEpoch 90/100 - Train loss: 0.8149 - Val accuracy: 0.8333 - Val loss: 0.7400 - Val F1: 0.8111 - LR: 1.00e-06\n","\tEpoch 100/100 - Train loss: 0.8154 - Val accuracy: 0.8205 - Val loss: 0.7482 - Val F1: 0.8019 - LR: 0.00e+00\n","\tBest epoch: 94 - Best val accuracy: 0.8077 - Best val loss: 0.7051 - Best val F1: 0.7926\n","\n","Source class: WAL | Domain: 32 | Accuracy: 0.5741 | Loss: 1.8695 | F1: 0.6198\n","\n","Domain: 33\n","x_syn_dom.shape: (448, 3, 128) | np.unique(y_syn_dom): [0 1 2 3]\n","x_dp_dom.shape: (156, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","x_syn_dom.shape: (392, 3, 128) | np.unique(y_syn_dom): [0 1 2 3]\n","x_dp_dom.shape: (100, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Fine-tuning on synthetic data...\n","\tEpoch 10/100 - Train loss: 1.3258 - Val accuracy: 0.7342 - Val loss: 1.0404 - Val F1: 0.7287 - LR: 9.00e-06\n","\tEpoch 20/100 - Train loss: 1.0770 - Val accuracy: 0.7342 - Val loss: 0.8774 - Val F1: 0.7287 - LR: 8.00e-06\n","\tEpoch 30/100 - Train loss: 1.3002 - Val accuracy: 0.7595 - Val loss: 0.7680 - Val F1: 0.7595 - LR: 7.00e-06\n","\tEpoch 40/100 - Train loss: 1.0912 - Val accuracy: 0.7595 - Val loss: 0.7089 - Val F1: 0.7595 - LR: 6.00e-06\n","\tEpoch 50/100 - Train loss: 0.9587 - Val accuracy: 0.7595 - Val loss: 0.6747 - Val F1: 0.7595 - LR: 5.00e-06\n","\tEpoch 60/100 - Train loss: 0.9062 - Val accuracy: 0.7595 - Val loss: 0.6363 - Val F1: 0.7595 - LR: 4.00e-06\n","\tEpoch 70/100 - Train loss: 0.9351 - Val accuracy: 0.7595 - Val loss: 0.6054 - Val F1: 0.7595 - LR: 3.00e-06\n","\tEpoch 80/100 - Train loss: 0.8671 - Val accuracy: 0.7722 - Val loss: 0.6102 - Val F1: 0.7737 - LR: 2.00e-06\n","\tEpoch 90/100 - Train loss: 0.8339 - Val accuracy: 0.7722 - Val loss: 0.5890 - Val F1: 0.7757 - LR: 1.00e-06\n","\tEpoch 100/100 - Train loss: 0.7126 - Val accuracy: 0.7848 - Val loss: 0.5750 - Val F1: 0.7843 - LR: 0.00e+00\n","\tBest epoch: 100 - Best val accuracy: 0.7848 - Best val loss: 0.5750 - Best val F1: 0.7843\n","\n","Source class: WAL | Domain: 33 | Accuracy: 0.4500 | Loss: 2.8005 | F1: 0.4919\n","\n","Domain: 34\n","x_syn_dom.shape: (448, 3, 128) | np.unique(y_syn_dom): [0 1 2 3]\n","x_dp_dom.shape: (161, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","x_syn_dom.shape: (392, 3, 128) | np.unique(y_syn_dom): [0 1 2 3]\n","x_dp_dom.shape: (105, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Fine-tuning on synthetic data...\n","\tEpoch 10/100 - Train loss: 2.0919 - Val accuracy: 0.6203 - Val loss: 1.9418 - Val F1: 0.6146 - LR: 9.00e-06\n","\tEpoch 20/100 - Train loss: 1.5573 - Val accuracy: 0.6835 - Val loss: 1.3693 - Val F1: 0.6751 - LR: 8.00e-06\n","\tEpoch 30/100 - Train loss: 1.1713 - Val accuracy: 0.7342 - Val loss: 1.0360 - Val F1: 0.7305 - LR: 7.00e-06\n","\tEpoch 40/100 - Train loss: 0.9789 - Val accuracy: 0.7468 - Val loss: 0.8304 - Val F1: 0.7394 - LR: 6.00e-06\n","\tEpoch 50/100 - Train loss: 0.9164 - Val accuracy: 0.8101 - Val loss: 0.6630 - Val F1: 0.8049 - LR: 5.00e-06\n","\tEpoch 60/100 - Train loss: 0.7746 - Val accuracy: 0.8101 - Val loss: 0.6146 - Val F1: 0.8049 - LR: 4.00e-06\n","\tEpoch 70/100 - Train loss: 0.5984 - Val accuracy: 0.8101 - Val loss: 0.5777 - Val F1: 0.8049 - LR: 3.00e-06\n","\tEpoch 80/100 - Train loss: 0.6831 - Val accuracy: 0.8101 - Val loss: 0.5166 - Val F1: 0.8055 - LR: 2.00e-06\n","\tEpoch 90/100 - Train loss: 0.7354 - Val accuracy: 0.8101 - Val loss: 0.5021 - Val F1: 0.8049 - LR: 1.00e-06\n","\tEpoch 100/100 - Train loss: 0.5687 - Val accuracy: 0.8101 - Val loss: 0.4816 - Val F1: 0.8055 - LR: 0.00e+00\n","\tBest epoch: 99 - Best val accuracy: 0.8228 - Best val loss: 0.4705 - Best val F1: 0.8177\n","\n","Source class: WAL | Domain: 34 | Accuracy: 0.7238 | Loss: 5.9045 | F1: 0.6652\n","\n","Domain: 35\n","x_syn_dom.shape: (444, 3, 128) | np.unique(y_syn_dom): [0 1 2 3]\n","x_dp_dom.shape: (159, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","x_syn_dom.shape: (388, 3, 128) | np.unique(y_syn_dom): [0 1 2 3]\n","x_dp_dom.shape: (104, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Fine-tuning on synthetic data...\n","\tEpoch 10/100 - Train loss: 0.5634 - Val accuracy: 0.8590 - Val loss: 0.4744 - Val F1: 0.8586 - LR: 9.00e-06\n","\tEpoch 20/100 - Train loss: 0.7593 - Val accuracy: 0.8333 - Val loss: 0.4573 - Val F1: 0.8360 - LR: 8.00e-06\n","\tEpoch 30/100 - Train loss: 0.5419 - Val accuracy: 0.8333 - Val loss: 0.4422 - Val F1: 0.8349 - LR: 7.00e-06\n","\tEpoch 40/100 - Train loss: 0.5253 - Val accuracy: 0.8718 - Val loss: 0.4088 - Val F1: 0.8721 - LR: 6.00e-06\n","\tEpoch 50/100 - Train loss: 0.4737 - Val accuracy: 0.8333 - Val loss: 0.3950 - Val F1: 0.8333 - LR: 5.00e-06\n","\tEpoch 60/100 - Train loss: 0.5205 - Val accuracy: 0.8590 - Val loss: 0.3756 - Val F1: 0.8599 - LR: 4.00e-06\n","\tEpoch 70/100 - Train loss: 0.6094 - Val accuracy: 0.8462 - Val loss: 0.4074 - Val F1: 0.8461 - LR: 3.00e-06\n","\tEpoch 80/100 - Train loss: 0.3675 - Val accuracy: 0.8462 - Val loss: 0.3753 - Val F1: 0.8468 - LR: 2.00e-06\n","\tEpoch 90/100 - Train loss: 0.4437 - Val accuracy: 0.8718 - Val loss: 0.3740 - Val F1: 0.8692 - LR: 1.00e-06\n","\tEpoch 100/100 - Train loss: 0.6022 - Val accuracy: 0.8333 - Val loss: 0.3972 - Val F1: 0.8365 - LR: 0.00e+00\n","\tBest epoch: 98 - Best val accuracy: 0.8590 - Best val loss: 0.3662 - Best val F1: 0.8588\n","\n","Source class: WAL | Domain: 35 | Accuracy: 0.7500 | Loss: 1.5188 | F1: 0.7930\n","\n","Domain: 36\n","x_syn_dom.shape: (448, 3, 128) | np.unique(y_syn_dom): [0 1 2 3]\n","x_dp_dom.shape: (155, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","x_syn_dom.shape: (392, 3, 128) | np.unique(y_syn_dom): [0 1 2 3]\n","x_dp_dom.shape: (99, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Fine-tuning on synthetic data...\n","\tEpoch 10/100 - Train loss: 1.3135 - Val accuracy: 0.8101 - Val loss: 0.7966 - Val F1: 0.8090 - LR: 9.00e-06\n","\tEpoch 20/100 - Train loss: 1.3421 - Val accuracy: 0.8101 - Val loss: 0.7038 - Val F1: 0.8125 - LR: 8.00e-06\n","\tEpoch 30/100 - Train loss: 1.0885 - Val accuracy: 0.8228 - Val loss: 0.6453 - Val F1: 0.8222 - LR: 7.00e-06\n","\tEpoch 40/100 - Train loss: 1.1531 - Val accuracy: 0.8101 - Val loss: 0.6121 - Val F1: 0.8125 - LR: 6.00e-06\n","\tEpoch 50/100 - Train loss: 0.8906 - Val accuracy: 0.8228 - Val loss: 0.5939 - Val F1: 0.8222 - LR: 5.00e-06\n","\tEpoch 60/100 - Train loss: 0.9440 - Val accuracy: 0.8101 - Val loss: 0.5347 - Val F1: 0.8137 - LR: 4.00e-06\n","\tEpoch 70/100 - Train loss: 0.8984 - Val accuracy: 0.8228 - Val loss: 0.5725 - Val F1: 0.8222 - LR: 3.00e-06\n","\tEpoch 80/100 - Train loss: 0.9515 - Val accuracy: 0.8228 - Val loss: 0.5385 - Val F1: 0.8222 - LR: 2.00e-06\n","\tEpoch 90/100 - Train loss: 0.8726 - Val accuracy: 0.8101 - Val loss: 0.5300 - Val F1: 0.8125 - LR: 1.00e-06\n","\tEpoch 100/100 - Train loss: 1.0147 - Val accuracy: 0.8228 - Val loss: 0.5423 - Val F1: 0.8222 - LR: 0.00e+00\n","\tBest epoch: 74 - Best val accuracy: 0.8101 - Best val loss: 0.5279 - Best val F1: 0.8125\n","\n","Source class: WAL | Domain: 36 | Accuracy: 0.6061 | Loss: 1.9383 | F1: 0.6805\n","\n","Domain: 37\n","x_syn_dom.shape: (448, 3, 128) | np.unique(y_syn_dom): [0 1 2 3]\n","x_dp_dom.shape: (154, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","x_syn_dom.shape: (392, 3, 128) | np.unique(y_syn_dom): [0 1 2 3]\n","x_dp_dom.shape: (98, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Fine-tuning on synthetic data...\n","\tEpoch 10/100 - Train loss: 1.5688 - Val accuracy: 0.7468 - Val loss: 0.9365 - Val F1: 0.7451 - LR: 9.00e-06\n","\tEpoch 20/100 - Train loss: 1.3798 - Val accuracy: 0.7595 - Val loss: 0.8397 - Val F1: 0.7584 - LR: 8.00e-06\n","\tEpoch 30/100 - Train loss: 1.1963 - Val accuracy: 0.7342 - Val loss: 0.8241 - Val F1: 0.7386 - LR: 7.00e-06\n","\tEpoch 40/100 - Train loss: 1.2499 - Val accuracy: 0.7595 - Val loss: 0.7940 - Val F1: 0.7556 - LR: 6.00e-06\n","\tEpoch 50/100 - Train loss: 1.2139 - Val accuracy: 0.7722 - Val loss: 0.7604 - Val F1: 0.7705 - LR: 5.00e-06\n","\tEpoch 60/100 - Train loss: 1.1951 - Val accuracy: 0.7595 - Val loss: 0.7544 - Val F1: 0.7685 - LR: 4.00e-06\n","\tEpoch 70/100 - Train loss: 1.1270 - Val accuracy: 0.7722 - Val loss: 0.7258 - Val F1: 0.7775 - LR: 3.00e-06\n","\tEpoch 80/100 - Train loss: 1.1225 - Val accuracy: 0.7722 - Val loss: 0.7767 - Val F1: 0.7788 - LR: 2.00e-06\n","\tEpoch 90/100 - Train loss: 1.0984 - Val accuracy: 0.7722 - Val loss: 0.7178 - Val F1: 0.7775 - LR: 1.00e-06\n","\tEpoch 100/100 - Train loss: 1.1905 - Val accuracy: 0.7722 - Val loss: 0.7548 - Val F1: 0.7775 - LR: 0.00e+00\n","\tBest epoch: 87 - Best val accuracy: 0.7848 - Best val loss: 0.6954 - Best val F1: 0.7884\n","\n","Source class: WAL | Domain: 37 | Accuracy: 0.4796 | Loss: 3.4303 | F1: 0.5288\n","\n","Domain: 38\n","x_syn_dom.shape: (444, 3, 128) | np.unique(y_syn_dom): [0 1 2 3]\n","x_dp_dom.shape: (158, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","x_syn_dom.shape: (388, 3, 128) | np.unique(y_syn_dom): [0 1 2 3]\n","x_dp_dom.shape: (103, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Fine-tuning on synthetic data...\n","\tEpoch 10/100 - Train loss: 3.6394 - Val accuracy: 0.5128 - Val loss: 3.5157 - Val F1: 0.4827 - LR: 9.00e-06\n","\tEpoch 20/100 - Train loss: 3.0181 - Val accuracy: 0.5385 - Val loss: 2.8992 - Val F1: 0.5174 - LR: 8.00e-06\n","\tEpoch 30/100 - Train loss: 2.6619 - Val accuracy: 0.5641 - Val loss: 2.3751 - Val F1: 0.5469 - LR: 7.00e-06\n","\tEpoch 40/100 - Train loss: 2.3589 - Val accuracy: 0.5641 - Val loss: 1.9682 - Val F1: 0.5492 - LR: 6.00e-06\n","\tEpoch 50/100 - Train loss: 1.8992 - Val accuracy: 0.5513 - Val loss: 1.6164 - Val F1: 0.5293 - LR: 5.00e-06\n","\tEpoch 60/100 - Train loss: 1.5680 - Val accuracy: 0.6154 - Val loss: 1.4054 - Val F1: 0.6002 - LR: 4.00e-06\n","\tEpoch 70/100 - Train loss: 1.3734 - Val accuracy: 0.6154 - Val loss: 1.2539 - Val F1: 0.6160 - LR: 3.00e-06\n","\tEpoch 80/100 - Train loss: 1.4790 - Val accuracy: 0.6282 - Val loss: 1.1309 - Val F1: 0.6316 - LR: 2.00e-06\n","\tEpoch 90/100 - Train loss: 1.2975 - Val accuracy: 0.6667 - Val loss: 1.0563 - Val F1: 0.6692 - LR: 1.00e-06\n","\tEpoch 100/100 - Train loss: 1.2933 - Val accuracy: 0.6538 - Val loss: 1.0510 - Val F1: 0.6532 - LR: 0.00e+00\n","\tBest epoch: 98 - Best val accuracy: 0.6282 - Best val loss: 1.0283 - Best val F1: 0.6229\n","\n","Source class: WAL | Domain: 38 | Accuracy: 0.4660 | Loss: 4.3517 | F1: 0.4423\n","\n","Domain: 39\n","x_syn_dom.shape: (444, 3, 128) | np.unique(y_syn_dom): [0 1 2 3]\n","x_dp_dom.shape: (165, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","x_syn_dom.shape: (388, 3, 128) | np.unique(y_syn_dom): [0 1 2 3]\n","x_dp_dom.shape: (110, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Fine-tuning on synthetic data...\n","\tEpoch 10/100 - Train loss: 1.9281 - Val accuracy: 0.6026 - Val loss: 1.7933 - Val F1: 0.6006 - LR: 9.00e-06\n","\tEpoch 20/100 - Train loss: 1.8413 - Val accuracy: 0.6282 - Val loss: 1.7027 - Val F1: 0.6257 - LR: 8.00e-06\n","\tEpoch 30/100 - Train loss: 1.7141 - Val accuracy: 0.6410 - Val loss: 1.5381 - Val F1: 0.6406 - LR: 7.00e-06\n","\tEpoch 40/100 - Train loss: 1.4007 - Val accuracy: 0.6410 - Val loss: 1.4339 - Val F1: 0.6406 - LR: 6.00e-06\n","\tEpoch 50/100 - Train loss: 1.5070 - Val accuracy: 0.6410 - Val loss: 1.3804 - Val F1: 0.6406 - LR: 5.00e-06\n","\tEpoch 60/100 - Train loss: 1.4130 - Val accuracy: 0.6410 - Val loss: 1.3141 - Val F1: 0.6406 - LR: 4.00e-06\n","\tEpoch 70/100 - Train loss: 1.4514 - Val accuracy: 0.6538 - Val loss: 1.2317 - Val F1: 0.6514 - LR: 3.00e-06\n","\tEpoch 80/100 - Train loss: 1.3529 - Val accuracy: 0.6538 - Val loss: 1.2596 - Val F1: 0.6551 - LR: 2.00e-06\n","\tEpoch 90/100 - Train loss: 1.3748 - Val accuracy: 0.6667 - Val loss: 1.2671 - Val F1: 0.6691 - LR: 1.00e-06\n","\tEpoch 100/100 - Train loss: 1.2697 - Val accuracy: 0.6667 - Val loss: 1.2210 - Val F1: 0.6674 - LR: 0.00e+00\n","\tBest epoch: 87 - Best val accuracy: 0.6667 - Best val loss: 1.2132 - Best val F1: 0.6674\n","\n","Source class: WAL | Domain: 39 | Accuracy: 0.3636 | Loss: 10.3194 | F1: 0.3804\n","\n","Domain: 40\n","x_syn_dom.shape: (444, 3, 128) | np.unique(y_syn_dom): [0 1 2 3]\n","x_dp_dom.shape: (155, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","x_syn_dom.shape: (388, 3, 128) | np.unique(y_syn_dom): [0 1 2 3]\n","x_dp_dom.shape: (100, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Fine-tuning on synthetic data...\n","\tEpoch 10/100 - Train loss: 2.0586 - Val accuracy: 0.6538 - Val loss: 1.7346 - Val F1: 0.6445 - LR: 9.00e-06\n","\tEpoch 20/100 - Train loss: 1.8350 - Val accuracy: 0.6282 - Val loss: 1.5545 - Val F1: 0.6233 - LR: 8.00e-06\n","\tEpoch 30/100 - Train loss: 1.5397 - Val accuracy: 0.6410 - Val loss: 1.4216 - Val F1: 0.6375 - LR: 7.00e-06\n","\tEpoch 40/100 - Train loss: 1.5912 - Val accuracy: 0.6538 - Val loss: 1.2957 - Val F1: 0.6505 - LR: 6.00e-06\n","\tEpoch 50/100 - Train loss: 1.4267 - Val accuracy: 0.6538 - Val loss: 1.2238 - Val F1: 0.6505 - LR: 5.00e-06\n","\tEpoch 60/100 - Train loss: 1.4508 - Val accuracy: 0.6667 - Val loss: 1.1525 - Val F1: 0.6640 - LR: 4.00e-06\n","\tEpoch 70/100 - Train loss: 1.2268 - Val accuracy: 0.6795 - Val loss: 1.1096 - Val F1: 0.6772 - LR: 3.00e-06\n","\tEpoch 80/100 - Train loss: 1.2026 - Val accuracy: 0.6667 - Val loss: 1.0876 - Val F1: 0.6657 - LR: 2.00e-06\n","\tEpoch 90/100 - Train loss: 1.0925 - Val accuracy: 0.6923 - Val loss: 1.0496 - Val F1: 0.6911 - LR: 1.00e-06\n","\tEpoch 100/100 - Train loss: 1.1422 - Val accuracy: 0.6795 - Val loss: 1.0633 - Val F1: 0.6772 - LR: 0.00e+00\n","\tBest epoch: 92 - Best val accuracy: 0.6923 - Best val loss: 1.0384 - Best val F1: 0.6914\n","\n","Source class: WAL | Domain: 40 | Accuracy: 0.5900 | Loss: 1.9725 | F1: 0.6459\n","\n","Domain: 41\n","x_syn_dom.shape: (444, 3, 128) | np.unique(y_syn_dom): [0 1 2 3]\n","x_dp_dom.shape: (156, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","x_syn_dom.shape: (388, 3, 128) | np.unique(y_syn_dom): [0 1 2 3]\n","x_dp_dom.shape: (101, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Fine-tuning on synthetic data...\n","\tEpoch 10/100 - Train loss: 1.7454 - Val accuracy: 0.7179 - Val loss: 1.1021 - Val F1: 0.7303 - LR: 9.00e-06\n","\tEpoch 20/100 - Train loss: 1.5471 - Val accuracy: 0.7564 - Val loss: 0.9761 - Val F1: 0.7648 - LR: 8.00e-06\n","\tEpoch 30/100 - Train loss: 1.3715 - Val accuracy: 0.7436 - Val loss: 0.9132 - Val F1: 0.7555 - LR: 7.00e-06\n","\tEpoch 40/100 - Train loss: 1.0378 - Val accuracy: 0.7949 - Val loss: 0.8396 - Val F1: 0.8065 - LR: 6.00e-06\n","\tEpoch 50/100 - Train loss: 1.3364 - Val accuracy: 0.7949 - Val loss: 0.8137 - Val F1: 0.8065 - LR: 5.00e-06\n","\tEpoch 60/100 - Train loss: 1.0871 - Val accuracy: 0.7821 - Val loss: 0.7847 - Val F1: 0.7944 - LR: 4.00e-06\n","\tEpoch 70/100 - Train loss: 0.9526 - Val accuracy: 0.8077 - Val loss: 0.7306 - Val F1: 0.8157 - LR: 3.00e-06\n","\tEpoch 80/100 - Train loss: 1.0127 - Val accuracy: 0.8333 - Val loss: 0.6904 - Val F1: 0.8411 - LR: 2.00e-06\n","\tEpoch 90/100 - Train loss: 0.9792 - Val accuracy: 0.8205 - Val loss: 0.7264 - Val F1: 0.8307 - LR: 1.00e-06\n","\tEpoch 100/100 - Train loss: 1.1183 - Val accuracy: 0.8077 - Val loss: 0.7105 - Val F1: 0.8172 - LR: 0.00e+00\n","\tBest epoch: 92 - Best val accuracy: 0.8333 - Best val loss: 0.6827 - Best val F1: 0.8411\n","\n","Source class: WAL | Domain: 41 | Accuracy: 0.3366 | Loss: 5.8643 | F1: 0.2949\n","\n","Domain: 42\n","x_syn_dom.shape: (448, 3, 128) | np.unique(y_syn_dom): [0 1 2 3]\n","x_dp_dom.shape: (158, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","x_syn_dom.shape: (392, 3, 128) | np.unique(y_syn_dom): [0 1 2 3]\n","x_dp_dom.shape: (102, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Fine-tuning on synthetic data...\n","\tEpoch 10/100 - Train loss: 2.7147 - Val accuracy: 0.6582 - Val loss: 2.1185 - Val F1: 0.6466 - LR: 9.00e-06\n","\tEpoch 20/100 - Train loss: 2.3303 - Val accuracy: 0.6456 - Val loss: 1.8941 - Val F1: 0.6502 - LR: 8.00e-06\n","\tEpoch 30/100 - Train loss: 1.9386 - Val accuracy: 0.6456 - Val loss: 1.7247 - Val F1: 0.6502 - LR: 7.00e-06\n","\tEpoch 40/100 - Train loss: 2.0302 - Val accuracy: 0.6582 - Val loss: 1.6071 - Val F1: 0.6633 - LR: 6.00e-06\n","\tEpoch 50/100 - Train loss: 1.8963 - Val accuracy: 0.6709 - Val loss: 1.5023 - Val F1: 0.6671 - LR: 5.00e-06\n","\tEpoch 60/100 - Train loss: 1.6086 - Val accuracy: 0.6582 - Val loss: 1.4185 - Val F1: 0.6537 - LR: 4.00e-06\n","\tEpoch 70/100 - Train loss: 1.6506 - Val accuracy: 0.6835 - Val loss: 1.3508 - Val F1: 0.6803 - LR: 3.00e-06\n","\tEpoch 80/100 - Train loss: 1.4745 - Val accuracy: 0.6962 - Val loss: 1.3098 - Val F1: 0.6885 - LR: 2.00e-06\n","\tEpoch 90/100 - Train loss: 1.6783 - Val accuracy: 0.6962 - Val loss: 1.2892 - Val F1: 0.6885 - LR: 1.00e-06\n","\tEpoch 100/100 - Train loss: 1.5292 - Val accuracy: 0.6962 - Val loss: 1.2713 - Val F1: 0.6885 - LR: 0.00e+00\n","\tBest epoch: 98 - Best val accuracy: 0.6709 - Best val loss: 1.2680 - Best val F1: 0.6626\n","\n","Source class: WAL | Domain: 42 | Accuracy: 0.1765 | Loss: 7.6137 | F1: 0.1932\n","\n","Domain: 43\n","x_syn_dom.shape: (444, 3, 128) | np.unique(y_syn_dom): [0 1 2 3]\n","x_dp_dom.shape: (153, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","x_syn_dom.shape: (388, 3, 128) | np.unique(y_syn_dom): [0 1 2 3]\n","x_dp_dom.shape: (98, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Fine-tuning on synthetic data...\n","\tEpoch 10/100 - Train loss: 2.3173 - Val accuracy: 0.7308 - Val loss: 2.5271 - Val F1: 0.7030 - LR: 9.00e-06\n","\tEpoch 20/100 - Train loss: 1.4232 - Val accuracy: 0.6795 - Val loss: 1.8178 - Val F1: 0.6520 - LR: 8.00e-06\n","\tEpoch 30/100 - Train loss: 0.9180 - Val accuracy: 0.7564 - Val loss: 1.1628 - Val F1: 0.7324 - LR: 7.00e-06\n","\tEpoch 40/100 - Train loss: 0.6539 - Val accuracy: 0.8077 - Val loss: 0.9622 - Val F1: 0.7981 - LR: 6.00e-06\n","\tEpoch 50/100 - Train loss: 0.4328 - Val accuracy: 0.8333 - Val loss: 0.8031 - Val F1: 0.8303 - LR: 5.00e-06\n","\tEpoch 60/100 - Train loss: 0.4396 - Val accuracy: 0.8718 - Val loss: 0.7061 - Val F1: 0.8718 - LR: 4.00e-06\n","\tEpoch 70/100 - Train loss: 0.4249 - Val accuracy: 0.8974 - Val loss: 0.6524 - Val F1: 0.8981 - LR: 3.00e-06\n","\tEpoch 80/100 - Train loss: 0.3959 - Val accuracy: 0.8974 - Val loss: 0.5897 - Val F1: 0.8974 - LR: 2.00e-06\n","\tEpoch 90/100 - Train loss: 0.3211 - Val accuracy: 0.9231 - Val loss: 0.6156 - Val F1: 0.9235 - LR: 1.00e-06\n","\tEpoch 100/100 - Train loss: 0.3476 - Val accuracy: 0.8846 - Val loss: 0.6667 - Val F1: 0.8856 - LR: 0.00e+00\n","\tBest epoch: 80 - Best val accuracy: 0.8974 - Best val loss: 0.5897 - Best val F1: 0.8974\n","\n","Source class: WAL | Domain: 43 | Accuracy: 0.7347 | Loss: 1.2157 | F1: 0.7127\n","\n","Domain: 44\n","x_syn_dom.shape: (444, 3, 128) | np.unique(y_syn_dom): [0 1 2 3]\n","x_dp_dom.shape: (153, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","x_syn_dom.shape: (388, 3, 128) | np.unique(y_syn_dom): [0 1 2 3]\n","x_dp_dom.shape: (98, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Fine-tuning on synthetic data...\n","\tEpoch 10/100 - Train loss: 0.9441 - Val accuracy: 0.8077 - Val loss: 0.7630 - Val F1: 0.8077 - LR: 9.00e-06\n","\tEpoch 20/100 - Train loss: 0.9056 - Val accuracy: 0.8077 - Val loss: 0.7165 - Val F1: 0.8076 - LR: 8.00e-06\n","\tEpoch 30/100 - Train loss: 0.8285 - Val accuracy: 0.8205 - Val loss: 0.6854 - Val F1: 0.8205 - LR: 7.00e-06\n","\tEpoch 40/100 - Train loss: 0.7721 - Val accuracy: 0.8205 - Val loss: 0.6623 - Val F1: 0.8245 - LR: 6.00e-06\n","\tEpoch 50/100 - Train loss: 0.6142 - Val accuracy: 0.8333 - Val loss: 0.6288 - Val F1: 0.8354 - LR: 5.00e-06\n","\tEpoch 60/100 - Train loss: 0.7259 - Val accuracy: 0.8205 - Val loss: 0.6176 - Val F1: 0.8245 - LR: 4.00e-06\n","\tEpoch 70/100 - Train loss: 0.6257 - Val accuracy: 0.8333 - Val loss: 0.5839 - Val F1: 0.8354 - LR: 3.00e-06\n","\tEpoch 80/100 - Train loss: 0.8618 - Val accuracy: 0.8205 - Val loss: 0.6070 - Val F1: 0.8245 - LR: 2.00e-06\n","\tEpoch 90/100 - Train loss: 0.5808 - Val accuracy: 0.8205 - Val loss: 0.5703 - Val F1: 0.8208 - LR: 1.00e-06\n","\tEpoch 100/100 - Train loss: 0.5114 - Val accuracy: 0.8205 - Val loss: 0.6003 - Val F1: 0.8272 - LR: 0.00e+00\n","\tBest epoch: 96 - Best val accuracy: 0.8205 - Best val loss: 0.5667 - Best val F1: 0.8208\n","\n","Source class: WAL | Domain: 44 | Accuracy: 0.6224 | Loss: 2.2229 | F1: 0.6623\n","\n","Domain: 45\n","x_syn_dom.shape: (444, 3, 128) | np.unique(y_syn_dom): [0 1 2 3]\n","x_dp_dom.shape: (163, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","x_syn_dom.shape: (388, 3, 128) | np.unique(y_syn_dom): [0 1 2 3]\n","x_dp_dom.shape: (108, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Fine-tuning on synthetic data...\n","\tEpoch 10/100 - Train loss: 1.0375 - Val accuracy: 0.7949 - Val loss: 0.6804 - Val F1: 0.7976 - LR: 9.00e-06\n","\tEpoch 20/100 - Train loss: 0.9230 - Val accuracy: 0.7949 - Val loss: 0.5999 - Val F1: 0.7976 - LR: 8.00e-06\n","\tEpoch 30/100 - Train loss: 0.8128 - Val accuracy: 0.8205 - Val loss: 0.5789 - Val F1: 0.8195 - LR: 7.00e-06\n","\tEpoch 40/100 - Train loss: 0.6709 - Val accuracy: 0.8462 - Val loss: 0.5120 - Val F1: 0.8440 - LR: 6.00e-06\n","\tEpoch 50/100 - Train loss: 0.8337 - Val accuracy: 0.8333 - Val loss: 0.4849 - Val F1: 0.8321 - LR: 5.00e-06\n","\tEpoch 60/100 - Train loss: 0.7543 - Val accuracy: 0.8462 - Val loss: 0.4957 - Val F1: 0.8440 - LR: 4.00e-06\n","\tEpoch 70/100 - Train loss: 0.7647 - Val accuracy: 0.8333 - Val loss: 0.4723 - Val F1: 0.8322 - LR: 3.00e-06\n","\tEpoch 80/100 - Train loss: 0.7201 - Val accuracy: 0.8462 - Val loss: 0.4867 - Val F1: 0.8449 - LR: 2.00e-06\n","\tEpoch 90/100 - Train loss: 0.6617 - Val accuracy: 0.8333 - Val loss: 0.4714 - Val F1: 0.8336 - LR: 1.00e-06\n","\tEpoch 100/100 - Train loss: 0.6487 - Val accuracy: 0.8333 - Val loss: 0.4617 - Val F1: 0.8336 - LR: 0.00e+00\n","\tBest epoch: 71 - Best val accuracy: 0.8333 - Best val loss: 0.4416 - Best val F1: 0.8322\n","\n","Source class: WAL | Domain: 45 | Accuracy: 0.6204 | Loss: 1.3991 | F1: 0.6596\n","\n","Domain: 46\n","x_syn_dom.shape: (448, 3, 128) | np.unique(y_syn_dom): [0 1 2 3]\n","x_dp_dom.shape: (160, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","x_syn_dom.shape: (392, 3, 128) | np.unique(y_syn_dom): [0 1 2 3]\n","x_dp_dom.shape: (104, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Fine-tuning on synthetic data...\n","\tEpoch 10/100 - Train loss: 0.8803 - Val accuracy: 0.6962 - Val loss: 0.8954 - Val F1: 0.6893 - LR: 9.00e-06\n","\tEpoch 20/100 - Train loss: 0.7471 - Val accuracy: 0.7342 - Val loss: 0.8076 - Val F1: 0.7287 - LR: 8.00e-06\n","\tEpoch 30/100 - Train loss: 0.8298 - Val accuracy: 0.7468 - Val loss: 0.7825 - Val F1: 0.7414 - LR: 7.00e-06\n","\tEpoch 40/100 - Train loss: 0.7269 - Val accuracy: 0.7342 - Val loss: 0.7617 - Val F1: 0.7309 - LR: 6.00e-06\n","\tEpoch 50/100 - Train loss: 0.7012 - Val accuracy: 0.7595 - Val loss: 0.7434 - Val F1: 0.7539 - LR: 5.00e-06\n","\tEpoch 60/100 - Train loss: 0.6230 - Val accuracy: 0.7468 - Val loss: 0.7419 - Val F1: 0.7438 - LR: 4.00e-06\n","\tEpoch 70/100 - Train loss: 0.6406 - Val accuracy: 0.7468 - Val loss: 0.7251 - Val F1: 0.7438 - LR: 3.00e-06\n","\tEpoch 80/100 - Train loss: 0.6291 - Val accuracy: 0.7468 - Val loss: 0.7137 - Val F1: 0.7438 - LR: 2.00e-06\n","\tEpoch 90/100 - Train loss: 0.7167 - Val accuracy: 0.7468 - Val loss: 0.7174 - Val F1: 0.7438 - LR: 1.00e-06\n","\tEpoch 100/100 - Train loss: 0.6464 - Val accuracy: 0.7468 - Val loss: 0.7047 - Val F1: 0.7438 - LR: 0.00e+00\n","\tBest epoch: 83 - Best val accuracy: 0.7468 - Best val loss: 0.6947 - Best val F1: 0.7438\n","\n","Source class: WAL | Domain: 46 | Accuracy: 0.6154 | Loss: 1.2433 | F1: 0.6442\n","\n","Domain: 47\n","x_syn_dom.shape: (444, 3, 128) | np.unique(y_syn_dom): [0 1 2 3]\n","x_dp_dom.shape: (155, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","x_syn_dom.shape: (388, 3, 128) | np.unique(y_syn_dom): [0 1 2 3]\n","x_dp_dom.shape: (100, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Fine-tuning on synthetic data...\n","\tEpoch 10/100 - Train loss: 0.9815 - Val accuracy: 0.7308 - Val loss: 1.0644 - Val F1: 0.7469 - LR: 9.00e-06\n","\tEpoch 20/100 - Train loss: 1.0830 - Val accuracy: 0.7436 - Val loss: 0.9906 - Val F1: 0.7523 - LR: 8.00e-06\n","\tEpoch 30/100 - Train loss: 0.9480 - Val accuracy: 0.7692 - Val loss: 0.9989 - Val F1: 0.7818 - LR: 7.00e-06\n","\tEpoch 40/100 - Train loss: 0.7424 - Val accuracy: 0.7821 - Val loss: 0.9085 - Val F1: 0.7850 - LR: 6.00e-06\n","\tEpoch 50/100 - Train loss: 0.8092 - Val accuracy: 0.7821 - Val loss: 0.8803 - Val F1: 0.7865 - LR: 5.00e-06\n","\tEpoch 60/100 - Train loss: 0.7900 - Val accuracy: 0.7821 - Val loss: 0.8186 - Val F1: 0.7898 - LR: 4.00e-06\n","\tEpoch 70/100 - Train loss: 0.8769 - Val accuracy: 0.7949 - Val loss: 0.8469 - Val F1: 0.8044 - LR: 3.00e-06\n","\tEpoch 80/100 - Train loss: 0.7971 - Val accuracy: 0.7949 - Val loss: 0.8069 - Val F1: 0.7999 - LR: 2.00e-06\n","\tEpoch 90/100 - Train loss: 0.6700 - Val accuracy: 0.7821 - Val loss: 0.8123 - Val F1: 0.7898 - LR: 1.00e-06\n","\tEpoch 100/100 - Train loss: 0.7183 - Val accuracy: 0.7949 - Val loss: 0.7914 - Val F1: 0.7999 - LR: 0.00e+00\n","\tBest epoch: 94 - Best val accuracy: 0.7949 - Best val loss: 0.7729 - Best val F1: 0.7999\n","\n","Source class: WAL | Domain: 47 | Accuracy: 0.5400 | Loss: 2.1312 | F1: 0.6174\n","\n","Domain: 48\n","x_syn_dom.shape: (444, 3, 128) | np.unique(y_syn_dom): [0 1 2 3]\n","x_dp_dom.shape: (159, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","x_syn_dom.shape: (388, 3, 128) | np.unique(y_syn_dom): [0 1 2 3]\n","x_dp_dom.shape: (104, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Fine-tuning on synthetic data...\n","\tEpoch 10/100 - Train loss: 1.0446 - Val accuracy: 0.8205 - Val loss: 0.7687 - Val F1: 0.8196 - LR: 9.00e-06\n","\tEpoch 20/100 - Train loss: 0.9630 - Val accuracy: 0.8077 - Val loss: 0.6814 - Val F1: 0.8044 - LR: 8.00e-06\n","\tEpoch 30/100 - Train loss: 0.9022 - Val accuracy: 0.8205 - Val loss: 0.6051 - Val F1: 0.8193 - LR: 7.00e-06\n","\tEpoch 40/100 - Train loss: 0.7824 - Val accuracy: 0.8462 - Val loss: 0.5531 - Val F1: 0.8444 - LR: 6.00e-06\n","\tEpoch 50/100 - Train loss: 0.7401 - Val accuracy: 0.8462 - Val loss: 0.5482 - Val F1: 0.8509 - LR: 5.00e-06\n","\tEpoch 60/100 - Train loss: 0.7421 - Val accuracy: 0.8590 - Val loss: 0.4831 - Val F1: 0.8599 - LR: 4.00e-06\n","\tEpoch 70/100 - Train loss: 0.7539 - Val accuracy: 0.8718 - Val loss: 0.4653 - Val F1: 0.8727 - LR: 3.00e-06\n","\tEpoch 80/100 - Train loss: 0.7130 - Val accuracy: 0.8718 - Val loss: 0.4487 - Val F1: 0.8727 - LR: 2.00e-06\n","\tEpoch 90/100 - Train loss: 0.6671 - Val accuracy: 0.8462 - Val loss: 0.4457 - Val F1: 0.8464 - LR: 1.00e-06\n","\tEpoch 100/100 - Train loss: 0.6248 - Val accuracy: 0.8718 - Val loss: 0.4558 - Val F1: 0.8727 - LR: 0.00e+00\n","\tBest epoch: 79 - Best val accuracy: 0.8590 - Best val loss: 0.4389 - Best val F1: 0.8590\n","\n","Source class: WAL | Domain: 48 | Accuracy: 0.5288 | Loss: 3.4304 | F1: 0.5746\n","\n","Domain: 49\n","x_syn_dom.shape: (444, 3, 128) | np.unique(y_syn_dom): [0 1 2 3]\n","x_dp_dom.shape: (164, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","x_syn_dom.shape: (388, 3, 128) | np.unique(y_syn_dom): [0 1 2 3]\n","x_dp_dom.shape: (109, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Fine-tuning on synthetic data...\n","\tEpoch 10/100 - Train loss: 1.1646 - Val accuracy: 0.8718 - Val loss: 0.5229 - Val F1: 0.8546 - LR: 9.00e-06\n","\tEpoch 20/100 - Train loss: 0.9892 - Val accuracy: 0.8718 - Val loss: 0.4513 - Val F1: 0.8528 - LR: 8.00e-06\n","\tEpoch 30/100 - Train loss: 1.0659 - Val accuracy: 0.8718 - Val loss: 0.4259 - Val F1: 0.8546 - LR: 7.00e-06\n","\tEpoch 40/100 - Train loss: 0.8008 - Val accuracy: 0.8846 - Val loss: 0.3895 - Val F1: 0.8640 - LR: 6.00e-06\n","\tEpoch 50/100 - Train loss: 0.8170 - Val accuracy: 0.8846 - Val loss: 0.3840 - Val F1: 0.8640 - LR: 5.00e-06\n","\tEpoch 60/100 - Train loss: 0.8433 - Val accuracy: 0.9103 - Val loss: 0.3454 - Val F1: 0.8994 - LR: 4.00e-06\n","\tEpoch 70/100 - Train loss: 1.0157 - Val accuracy: 0.9103 - Val loss: 0.3406 - Val F1: 0.8994 - LR: 3.00e-06\n","\tEpoch 80/100 - Train loss: 0.8841 - Val accuracy: 0.8846 - Val loss: 0.3761 - Val F1: 0.8650 - LR: 2.00e-06\n","\tEpoch 90/100 - Train loss: 0.7667 - Val accuracy: 0.8974 - Val loss: 0.3360 - Val F1: 0.8829 - LR: 1.00e-06\n","\tEpoch 100/100 - Train loss: 0.7029 - Val accuracy: 0.8974 - Val loss: 0.3373 - Val F1: 0.8829 - LR: 0.00e+00\n","\tBest epoch: 87 - Best val accuracy: 0.8974 - Best val loss: 0.3237 - Best val F1: 0.8829\n","\n","Source class: WAL | Domain: 49 | Accuracy: 0.5413 | Loss: 2.0866 | F1: 0.5805\n","\n","Domain: 50\n","x_syn_dom.shape: (444, 3, 128) | np.unique(y_syn_dom): [0 1 2 3]\n","x_dp_dom.shape: (153, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","x_syn_dom.shape: (388, 3, 128) | np.unique(y_syn_dom): [0 1 2 3]\n","x_dp_dom.shape: (98, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Fine-tuning on synthetic data...\n","\tEpoch 10/100 - Train loss: 1.5868 - Val accuracy: 0.6795 - Val loss: 1.5540 - Val F1: 0.6600 - LR: 9.00e-06\n","\tEpoch 20/100 - Train loss: 1.3904 - Val accuracy: 0.6923 - Val loss: 1.4038 - Val F1: 0.6891 - LR: 8.00e-06\n","\tEpoch 30/100 - Train loss: 1.4251 - Val accuracy: 0.7179 - Val loss: 1.3149 - Val F1: 0.7156 - LR: 7.00e-06\n","\tEpoch 40/100 - Train loss: 1.1412 - Val accuracy: 0.7436 - Val loss: 1.2078 - Val F1: 0.7466 - LR: 6.00e-06\n","\tEpoch 50/100 - Train loss: 1.1574 - Val accuracy: 0.7436 - Val loss: 1.1840 - Val F1: 0.7466 - LR: 5.00e-06\n","\tEpoch 60/100 - Train loss: 0.8532 - Val accuracy: 0.7436 - Val loss: 1.1822 - Val F1: 0.7533 - LR: 4.00e-06\n","\tEpoch 70/100 - Train loss: 0.9767 - Val accuracy: 0.7564 - Val loss: 1.1088 - Val F1: 0.7612 - LR: 3.00e-06\n","\tEpoch 80/100 - Train loss: 0.8556 - Val accuracy: 0.7564 - Val loss: 1.0950 - Val F1: 0.7552 - LR: 2.00e-06\n","\tEpoch 90/100 - Train loss: 0.7660 - Val accuracy: 0.7564 - Val loss: 1.0562 - Val F1: 0.7562 - LR: 1.00e-06\n","\tEpoch 100/100 - Train loss: 0.8426 - Val accuracy: 0.7564 - Val loss: 1.0790 - Val F1: 0.7612 - LR: 0.00e+00\n","\tBest epoch: 99 - Best val accuracy: 0.7308 - Best val loss: 1.0376 - Best val F1: 0.7361\n","\n","Source class: WAL | Domain: 50 | Accuracy: 0.5714 | Loss: 2.1516 | F1: 0.5824\n","\n","Domain: 51\n","x_syn_dom.shape: (444, 3, 128) | np.unique(y_syn_dom): [0 1 2 3]\n","x_dp_dom.shape: (157, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","x_syn_dom.shape: (388, 3, 128) | np.unique(y_syn_dom): [0 1 2 3]\n","x_dp_dom.shape: (102, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Fine-tuning on synthetic data...\n","\tEpoch 10/100 - Train loss: 1.4542 - Val accuracy: 0.6410 - Val loss: 1.1620 - Val F1: 0.6471 - LR: 9.00e-06\n","\tEpoch 20/100 - Train loss: 1.4930 - Val accuracy: 0.6667 - Val loss: 1.1072 - Val F1: 0.6676 - LR: 8.00e-06\n","\tEpoch 30/100 - Train loss: 1.2926 - Val accuracy: 0.6667 - Val loss: 1.0526 - Val F1: 0.6694 - LR: 7.00e-06\n","\tEpoch 40/100 - Train loss: 1.2567 - Val accuracy: 0.6923 - Val loss: 1.0141 - Val F1: 0.6913 - LR: 6.00e-06\n","\tEpoch 50/100 - Train loss: 1.0578 - Val accuracy: 0.6795 - Val loss: 0.9691 - Val F1: 0.6787 - LR: 5.00e-06\n","\tEpoch 60/100 - Train loss: 1.3551 - Val accuracy: 0.6923 - Val loss: 0.9602 - Val F1: 0.6879 - LR: 4.00e-06\n","\tEpoch 70/100 - Train loss: 1.0506 - Val accuracy: 0.6923 - Val loss: 0.9459 - Val F1: 0.6820 - LR: 3.00e-06\n","\tEpoch 80/100 - Train loss: 1.1243 - Val accuracy: 0.6923 - Val loss: 0.9281 - Val F1: 0.6879 - LR: 2.00e-06\n","\tEpoch 90/100 - Train loss: 1.0116 - Val accuracy: 0.7308 - Val loss: 0.9034 - Val F1: 0.7271 - LR: 1.00e-06\n","\tEpoch 100/100 - Train loss: 1.2012 - Val accuracy: 0.7308 - Val loss: 0.9002 - Val F1: 0.7271 - LR: 0.00e+00\n","\tBest epoch: 84 - Best val accuracy: 0.7179 - Best val loss: 0.8960 - Best val F1: 0.7089\n","\n","Source class: WAL | Domain: 51 | Accuracy: 0.4902 | Loss: 3.5071 | F1: 0.5334\n","\n","Domain: 52\n","x_syn_dom.shape: (444, 3, 128) | np.unique(y_syn_dom): [0 1 2 3]\n","x_dp_dom.shape: (153, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","x_syn_dom.shape: (388, 3, 128) | np.unique(y_syn_dom): [0 1 2 3]\n","x_dp_dom.shape: (98, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Fine-tuning on synthetic data...\n","\tEpoch 10/100 - Train loss: 1.7936 - Val accuracy: 0.7821 - Val loss: 1.1829 - Val F1: 0.7827 - LR: 9.00e-06\n","\tEpoch 20/100 - Train loss: 1.2661 - Val accuracy: 0.7564 - Val loss: 1.0937 - Val F1: 0.7561 - LR: 8.00e-06\n","\tEpoch 30/100 - Train loss: 1.2111 - Val accuracy: 0.7692 - Val loss: 1.0074 - Val F1: 0.7636 - LR: 7.00e-06\n","\tEpoch 40/100 - Train loss: 1.0875 - Val accuracy: 0.7821 - Val loss: 0.9623 - Val F1: 0.7827 - LR: 6.00e-06\n","\tEpoch 50/100 - Train loss: 1.2741 - Val accuracy: 0.7821 - Val loss: 0.9208 - Val F1: 0.7794 - LR: 5.00e-06\n","\tEpoch 60/100 - Train loss: 0.9926 - Val accuracy: 0.7821 - Val loss: 0.9110 - Val F1: 0.7794 - LR: 4.00e-06\n","\tEpoch 70/100 - Train loss: 0.9776 - Val accuracy: 0.7821 - Val loss: 0.8701 - Val F1: 0.7803 - LR: 3.00e-06\n","\tEpoch 80/100 - Train loss: 0.8443 - Val accuracy: 0.7821 - Val loss: 0.8831 - Val F1: 0.7794 - LR: 2.00e-06\n","\tEpoch 90/100 - Train loss: 0.9416 - Val accuracy: 0.7949 - Val loss: 0.8684 - Val F1: 0.7894 - LR: 1.00e-06\n","\tEpoch 100/100 - Train loss: 1.0258 - Val accuracy: 0.7821 - Val loss: 0.8737 - Val F1: 0.7834 - LR: 0.00e+00\n","\tBest epoch: 92 - Best val accuracy: 0.7949 - Best val loss: 0.8352 - Best val F1: 0.7894\n","\n","Source class: WAL | Domain: 52 | Accuracy: 0.4490 | Loss: 2.5352 | F1: 0.5045\n","\n","Domain: 53\n","x_syn_dom.shape: (444, 3, 128) | np.unique(y_syn_dom): [0 1 2 3]\n","x_dp_dom.shape: (159, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","x_syn_dom.shape: (388, 3, 128) | np.unique(y_syn_dom): [0 1 2 3]\n","x_dp_dom.shape: (104, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Fine-tuning on synthetic data...\n","\tEpoch 10/100 - Train loss: 2.9997 - Val accuracy: 0.6795 - Val loss: 3.0344 - Val F1: 0.6726 - LR: 9.00e-06\n","\tEpoch 20/100 - Train loss: 2.2790 - Val accuracy: 0.6667 - Val loss: 2.3200 - Val F1: 0.6658 - LR: 8.00e-06\n","\tEpoch 30/100 - Train loss: 1.5531 - Val accuracy: 0.7051 - Val loss: 1.6629 - Val F1: 0.6852 - LR: 7.00e-06\n","\tEpoch 40/100 - Train loss: 1.1202 - Val accuracy: 0.7179 - Val loss: 1.3272 - Val F1: 0.7133 - LR: 6.00e-06\n","\tEpoch 50/100 - Train loss: 1.0532 - Val accuracy: 0.7436 - Val loss: 0.9774 - Val F1: 0.7325 - LR: 5.00e-06\n","\tEpoch 60/100 - Train loss: 0.8832 - Val accuracy: 0.7692 - Val loss: 0.8361 - Val F1: 0.7541 - LR: 4.00e-06\n","\tEpoch 70/100 - Train loss: 0.9162 - Val accuracy: 0.7564 - Val loss: 0.7662 - Val F1: 0.7480 - LR: 3.00e-06\n","\tEpoch 80/100 - Train loss: 0.6799 - Val accuracy: 0.8205 - Val loss: 0.6918 - Val F1: 0.8217 - LR: 2.00e-06\n","\tEpoch 90/100 - Train loss: 0.7820 - Val accuracy: 0.8333 - Val loss: 0.5843 - Val F1: 0.8324 - LR: 1.00e-06\n","\tEpoch 100/100 - Train loss: 0.5759 - Val accuracy: 0.8333 - Val loss: 0.6122 - Val F1: 0.8324 - LR: 0.00e+00\n","\tBest epoch: 96 - Best val accuracy: 0.8333 - Best val loss: 0.5334 - Best val F1: 0.8324\n","\n","Source class: WAL | Domain: 53 | Accuracy: 0.7212 | Loss: 1.5515 | F1: 0.7134\n","\n","Domain: 54\n","x_syn_dom.shape: (444, 3, 128) | np.unique(y_syn_dom): [0 1 2 3]\n","x_dp_dom.shape: (153, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","x_syn_dom.shape: (388, 3, 128) | np.unique(y_syn_dom): [0 1 2 3]\n","x_dp_dom.shape: (98, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Fine-tuning on synthetic data...\n","\tEpoch 10/100 - Train loss: 1.8000 - Val accuracy: 0.7436 - Val loss: 1.1476 - Val F1: 0.7225 - LR: 9.00e-06\n","\tEpoch 20/100 - Train loss: 1.5177 - Val accuracy: 0.7436 - Val loss: 1.0578 - Val F1: 0.7264 - LR: 8.00e-06\n","\tEpoch 30/100 - Train loss: 1.4958 - Val accuracy: 0.7692 - Val loss: 0.9834 - Val F1: 0.7576 - LR: 7.00e-06\n","\tEpoch 40/100 - Train loss: 1.3475 - Val accuracy: 0.7564 - Val loss: 0.9249 - Val F1: 0.7382 - LR: 6.00e-06\n","\tEpoch 50/100 - Train loss: 1.1875 - Val accuracy: 0.7564 - Val loss: 0.8852 - Val F1: 0.7382 - LR: 5.00e-06\n","\tEpoch 60/100 - Train loss: 1.2885 - Val accuracy: 0.7692 - Val loss: 0.8362 - Val F1: 0.7576 - LR: 4.00e-06\n","\tEpoch 70/100 - Train loss: 1.2646 - Val accuracy: 0.7821 - Val loss: 0.8094 - Val F1: 0.7747 - LR: 3.00e-06\n","\tEpoch 80/100 - Train loss: 1.1870 - Val accuracy: 0.7692 - Val loss: 0.8012 - Val F1: 0.7575 - LR: 2.00e-06\n","\tEpoch 90/100 - Train loss: 1.0601 - Val accuracy: 0.7821 - Val loss: 0.7804 - Val F1: 0.7698 - LR: 1.00e-06\n","\tEpoch 100/100 - Train loss: 1.0732 - Val accuracy: 0.7692 - Val loss: 0.7875 - Val F1: 0.7572 - LR: 0.00e+00\n","\tBest epoch: 98 - Best val accuracy: 0.7692 - Best val loss: 0.7705 - Best val F1: 0.7575\n","\n","Source class: WAL | Domain: 54 | Accuracy: 0.5204 | Loss: 3.5321 | F1: 0.5550\n","\n","Domain: 55\n","x_syn_dom.shape: (444, 3, 128) | np.unique(y_syn_dom): [0 1 2 3]\n","x_dp_dom.shape: (160, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","x_syn_dom.shape: (388, 3, 128) | np.unique(y_syn_dom): [0 1 2 3]\n","x_dp_dom.shape: (105, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Fine-tuning on synthetic data...\n","\tEpoch 10/100 - Train loss: 1.0293 - Val accuracy: 0.7821 - Val loss: 0.6093 - Val F1: 0.7811 - LR: 9.00e-06\n","\tEpoch 20/100 - Train loss: 0.9265 - Val accuracy: 0.8077 - Val loss: 0.5733 - Val F1: 0.8070 - LR: 8.00e-06\n","\tEpoch 30/100 - Train loss: 0.8918 - Val accuracy: 0.7949 - Val loss: 0.5303 - Val F1: 0.7904 - LR: 7.00e-06\n","\tEpoch 40/100 - Train loss: 0.8739 - Val accuracy: 0.8077 - Val loss: 0.5263 - Val F1: 0.8070 - LR: 6.00e-06\n","\tEpoch 50/100 - Train loss: 0.7263 - Val accuracy: 0.8077 - Val loss: 0.4922 - Val F1: 0.8070 - LR: 5.00e-06\n","\tEpoch 60/100 - Train loss: 0.7860 - Val accuracy: 0.8077 - Val loss: 0.4596 - Val F1: 0.8070 - LR: 4.00e-06\n","\tEpoch 70/100 - Train loss: 0.7312 - Val accuracy: 0.8205 - Val loss: 0.4358 - Val F1: 0.8205 - LR: 3.00e-06\n","\tEpoch 80/100 - Train loss: 0.5875 - Val accuracy: 0.8205 - Val loss: 0.4248 - Val F1: 0.8205 - LR: 2.00e-06\n","\tEpoch 90/100 - Train loss: 0.7526 - Val accuracy: 0.8333 - Val loss: 0.4092 - Val F1: 0.8313 - LR: 1.00e-06\n","\tEpoch 100/100 - Train loss: 0.7171 - Val accuracy: 0.8333 - Val loss: 0.4141 - Val F1: 0.8313 - LR: 0.00e+00\n","\tBest epoch: 81 - Best val accuracy: 0.8333 - Best val loss: 0.4027 - Best val F1: 0.8313\n","\n","Source class: WAL | Domain: 55 | Accuracy: 0.5143 | Loss: 2.0605 | F1: 0.5569\n","\n","Domain: 56\n","x_syn_dom.shape: (444, 3, 128) | np.unique(y_syn_dom): [0 1 2 3]\n","x_dp_dom.shape: (153, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","x_syn_dom.shape: (388, 3, 128) | np.unique(y_syn_dom): [0 1 2 3]\n","x_dp_dom.shape: (98, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Fine-tuning on synthetic data...\n","\tEpoch 10/100 - Train loss: 1.5675 - Val accuracy: 0.7051 - Val loss: 1.0524 - Val F1: 0.6970 - LR: 9.00e-06\n","\tEpoch 20/100 - Train loss: 1.3948 - Val accuracy: 0.7051 - Val loss: 0.9571 - Val F1: 0.6962 - LR: 8.00e-06\n","\tEpoch 30/100 - Train loss: 1.5002 - Val accuracy: 0.7564 - Val loss: 0.8579 - Val F1: 0.7506 - LR: 7.00e-06\n","\tEpoch 40/100 - Train loss: 1.3236 - Val accuracy: 0.7564 - Val loss: 0.7800 - Val F1: 0.7530 - LR: 6.00e-06\n","\tEpoch 50/100 - Train loss: 1.3787 - Val accuracy: 0.7564 - Val loss: 0.7463 - Val F1: 0.7506 - LR: 5.00e-06\n","\tEpoch 60/100 - Train loss: 1.3195 - Val accuracy: 0.7692 - Val loss: 0.6828 - Val F1: 0.7626 - LR: 4.00e-06\n","\tEpoch 70/100 - Train loss: 0.9596 - Val accuracy: 0.7949 - Val loss: 0.6402 - Val F1: 0.7908 - LR: 3.00e-06\n","\tEpoch 80/100 - Train loss: 1.1846 - Val accuracy: 0.7821 - Val loss: 0.6627 - Val F1: 0.7751 - LR: 2.00e-06\n","\tEpoch 90/100 - Train loss: 1.0237 - Val accuracy: 0.7821 - Val loss: 0.6454 - Val F1: 0.7730 - LR: 1.00e-06\n","\tEpoch 100/100 - Train loss: 1.0787 - Val accuracy: 0.7821 - Val loss: 0.6267 - Val F1: 0.7730 - LR: 0.00e+00\n","\tBest epoch: 86 - Best val accuracy: 0.7949 - Best val loss: 0.6122 - Best val F1: 0.7887\n","\n","Source class: WAL | Domain: 56 | Accuracy: 0.4490 | Loss: 2.3191 | F1: 0.4891\n","\n","Domain: 57\n","x_syn_dom.shape: (444, 3, 128) | np.unique(y_syn_dom): [0 1 2 3]\n","x_dp_dom.shape: (153, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","x_syn_dom.shape: (388, 3, 128) | np.unique(y_syn_dom): [0 1 2 3]\n","x_dp_dom.shape: (98, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Fine-tuning on synthetic data...\n","\tEpoch 10/100 - Train loss: 1.6540 - Val accuracy: 0.6795 - Val loss: 1.1089 - Val F1: 0.6922 - LR: 9.00e-06\n","\tEpoch 20/100 - Train loss: 1.1457 - Val accuracy: 0.7051 - Val loss: 1.0142 - Val F1: 0.7096 - LR: 8.00e-06\n","\tEpoch 30/100 - Train loss: 1.2064 - Val accuracy: 0.7051 - Val loss: 0.9537 - Val F1: 0.7096 - LR: 7.00e-06\n","\tEpoch 40/100 - Train loss: 1.1099 - Val accuracy: 0.7179 - Val loss: 0.9309 - Val F1: 0.7220 - LR: 6.00e-06\n","\tEpoch 50/100 - Train loss: 1.1360 - Val accuracy: 0.7179 - Val loss: 0.8565 - Val F1: 0.7246 - LR: 5.00e-06\n","\tEpoch 60/100 - Train loss: 0.9432 - Val accuracy: 0.7436 - Val loss: 0.8160 - Val F1: 0.7433 - LR: 4.00e-06\n","\tEpoch 70/100 - Train loss: 1.1011 - Val accuracy: 0.7436 - Val loss: 0.7789 - Val F1: 0.7534 - LR: 3.00e-06\n","\tEpoch 80/100 - Train loss: 1.0675 - Val accuracy: 0.7308 - Val loss: 0.7843 - Val F1: 0.7409 - LR: 2.00e-06\n","\tEpoch 90/100 - Train loss: 0.9797 - Val accuracy: 0.7692 - Val loss: 0.8110 - Val F1: 0.7627 - LR: 1.00e-06\n","\tEpoch 100/100 - Train loss: 0.8624 - Val accuracy: 0.7308 - Val loss: 0.7812 - Val F1: 0.7409 - LR: 0.00e+00\n","\tBest epoch: 94 - Best val accuracy: 0.7564 - Best val loss: 0.7536 - Best val F1: 0.7634\n","\n","Source class: WAL | Domain: 57 | Accuracy: 0.4082 | Loss: 3.1189 | F1: 0.4628\n","\n","Domain: 58\n","x_syn_dom.shape: (444, 3, 128) | np.unique(y_syn_dom): [0 1 2 3]\n","x_dp_dom.shape: (149, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","x_syn_dom.shape: (388, 3, 128) | np.unique(y_syn_dom): [0 1 2 3]\n","x_dp_dom.shape: (94, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Fine-tuning on synthetic data...\n","\tEpoch 10/100 - Train loss: 2.4675 - Val accuracy: 0.6410 - Val loss: 2.0682 - Val F1: 0.6292 - LR: 9.00e-06\n","\tEpoch 20/100 - Train loss: 2.1720 - Val accuracy: 0.6410 - Val loss: 1.8610 - Val F1: 0.6379 - LR: 8.00e-06\n","\tEpoch 30/100 - Train loss: 2.2401 - Val accuracy: 0.6282 - Val loss: 1.7490 - Val F1: 0.6303 - LR: 7.00e-06\n","\tEpoch 40/100 - Train loss: 1.8815 - Val accuracy: 0.6026 - Val loss: 1.6486 - Val F1: 0.6110 - LR: 6.00e-06\n","\tEpoch 50/100 - Train loss: 1.9450 - Val accuracy: 0.6154 - Val loss: 1.5330 - Val F1: 0.6106 - LR: 5.00e-06\n","\tEpoch 60/100 - Train loss: 1.7761 - Val accuracy: 0.6538 - Val loss: 1.4903 - Val F1: 0.6508 - LR: 4.00e-06\n","\tEpoch 70/100 - Train loss: 1.7906 - Val accuracy: 0.6410 - Val loss: 1.4272 - Val F1: 0.6472 - LR: 3.00e-06\n","\tEpoch 80/100 - Train loss: 1.7014 - Val accuracy: 0.6282 - Val loss: 1.4172 - Val F1: 0.6262 - LR: 2.00e-06\n","\tEpoch 90/100 - Train loss: 1.6034 - Val accuracy: 0.6410 - Val loss: 1.3952 - Val F1: 0.6361 - LR: 1.00e-06\n","\tEpoch 100/100 - Train loss: 1.6142 - Val accuracy: 0.6538 - Val loss: 1.3938 - Val F1: 0.6608 - LR: 0.00e+00\n","\tBest epoch: 92 - Best val accuracy: 0.6410 - Best val loss: 1.3794 - Best val F1: 0.6323\n","\n","Source class: WAL | Domain: 58 | Accuracy: 0.5213 | Loss: 2.4295 | F1: 0.5716\n","\n","Domain: 59\n","x_syn_dom.shape: (444, 3, 128) | np.unique(y_syn_dom): [0 1 2 3]\n","x_dp_dom.shape: (154, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","x_syn_dom.shape: (388, 3, 128) | np.unique(y_syn_dom): [0 1 2 3]\n","x_dp_dom.shape: (99, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Fine-tuning on synthetic data...\n","\tEpoch 10/100 - Train loss: 1.1560 - Val accuracy: 0.6667 - Val loss: 1.2697 - Val F1: 0.6607 - LR: 9.00e-06\n","\tEpoch 20/100 - Train loss: 0.9274 - Val accuracy: 0.7051 - Val loss: 1.1180 - Val F1: 0.6971 - LR: 8.00e-06\n","\tEpoch 30/100 - Train loss: 0.7144 - Val accuracy: 0.7308 - Val loss: 1.0208 - Val F1: 0.7252 - LR: 7.00e-06\n","\tEpoch 40/100 - Train loss: 0.7914 - Val accuracy: 0.7308 - Val loss: 0.9576 - Val F1: 0.7272 - LR: 6.00e-06\n","\tEpoch 50/100 - Train loss: 0.8184 - Val accuracy: 0.7308 - Val loss: 0.8859 - Val F1: 0.7272 - LR: 5.00e-06\n","\tEpoch 60/100 - Train loss: 0.7555 - Val accuracy: 0.7564 - Val loss: 0.8756 - Val F1: 0.7482 - LR: 4.00e-06\n","\tEpoch 70/100 - Train loss: 0.6024 - Val accuracy: 0.7436 - Val loss: 0.8075 - Val F1: 0.7396 - LR: 3.00e-06\n","\tEpoch 80/100 - Train loss: 0.6125 - Val accuracy: 0.7436 - Val loss: 0.8095 - Val F1: 0.7396 - LR: 2.00e-06\n","\tEpoch 90/100 - Train loss: 0.5021 - Val accuracy: 0.7564 - Val loss: 0.7923 - Val F1: 0.7482 - LR: 1.00e-06\n","\tEpoch 100/100 - Train loss: 0.6967 - Val accuracy: 0.7436 - Val loss: 0.7921 - Val F1: 0.7385 - LR: 0.00e+00\n","\tBest epoch: 92 - Best val accuracy: 0.7436 - Best val loss: 0.7768 - Best val F1: 0.7403\n","\n","Source class: WAL | Domain: 59 | Accuracy: 0.6768 | Loss: 1.5428 | F1: 0.7027\n","\n","Domain: 60\n","x_syn_dom.shape: (444, 3, 128) | np.unique(y_syn_dom): [0 1 2 3]\n","x_dp_dom.shape: (158, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","x_syn_dom.shape: (388, 3, 128) | np.unique(y_syn_dom): [0 1 2 3]\n","x_dp_dom.shape: (103, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Fine-tuning on synthetic data...\n","\tEpoch 10/100 - Train loss: 2.6955 - Val accuracy: 0.7179 - Val loss: 2.2060 - Val F1: 0.7018 - LR: 9.00e-06\n","\tEpoch 20/100 - Train loss: 2.1768 - Val accuracy: 0.7308 - Val loss: 1.4858 - Val F1: 0.7155 - LR: 8.00e-06\n","\tEpoch 30/100 - Train loss: 1.4342 - Val accuracy: 0.7308 - Val loss: 0.9359 - Val F1: 0.7217 - LR: 7.00e-06\n","\tEpoch 40/100 - Train loss: 1.0268 - Val accuracy: 0.8333 - Val loss: 0.6434 - Val F1: 0.8397 - LR: 6.00e-06\n","\tEpoch 50/100 - Train loss: 0.8822 - Val accuracy: 0.8333 - Val loss: 0.5082 - Val F1: 0.8397 - LR: 5.00e-06\n","\tEpoch 60/100 - Train loss: 0.7633 - Val accuracy: 0.8974 - Val loss: 0.4216 - Val F1: 0.9009 - LR: 4.00e-06\n","\tEpoch 70/100 - Train loss: 0.6901 - Val accuracy: 0.9103 - Val loss: 0.3577 - Val F1: 0.9138 - LR: 3.00e-06\n","\tEpoch 80/100 - Train loss: 0.5310 - Val accuracy: 0.8846 - Val loss: 0.4153 - Val F1: 0.8897 - LR: 2.00e-06\n","\tEpoch 90/100 - Train loss: 0.5024 - Val accuracy: 0.9103 - Val loss: 0.3440 - Val F1: 0.9118 - LR: 1.00e-06\n","\tEpoch 100/100 - Train loss: 0.5746 - Val accuracy: 0.9103 - Val loss: 0.3150 - Val F1: 0.9118 - LR: 0.00e+00\n","\tBest epoch: 97 - Best val accuracy: 0.9359 - Best val loss: 0.2852 - Best val F1: 0.9369\n","\n","Source class: WAL | Domain: 60 | Accuracy: 0.6214 | Loss: 4.9580 | F1: 0.5536\n","\n","Domain: 61\n","x_syn_dom.shape: (444, 3, 128) | np.unique(y_syn_dom): [0 1 2 3]\n","x_dp_dom.shape: (158, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","x_syn_dom.shape: (388, 3, 128) | np.unique(y_syn_dom): [0 1 2 3]\n","x_dp_dom.shape: (103, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Fine-tuning on synthetic data...\n","\tEpoch 10/100 - Train loss: 1.4782 - Val accuracy: 0.7436 - Val loss: 0.9229 - Val F1: 0.7480 - LR: 9.00e-06\n","\tEpoch 20/100 - Train loss: 1.1986 - Val accuracy: 0.7436 - Val loss: 0.8842 - Val F1: 0.7432 - LR: 8.00e-06\n","\tEpoch 30/100 - Train loss: 1.0319 - Val accuracy: 0.7692 - Val loss: 0.8121 - Val F1: 0.7690 - LR: 7.00e-06\n","\tEpoch 40/100 - Train loss: 1.1357 - Val accuracy: 0.7564 - Val loss: 0.7853 - Val F1: 0.7557 - LR: 6.00e-06\n","\tEpoch 50/100 - Train loss: 0.8618 - Val accuracy: 0.7821 - Val loss: 0.7519 - Val F1: 0.7840 - LR: 5.00e-06\n","\tEpoch 60/100 - Train loss: 0.8922 - Val accuracy: 0.7949 - Val loss: 0.7214 - Val F1: 0.7954 - LR: 4.00e-06\n","\tEpoch 70/100 - Train loss: 0.9956 - Val accuracy: 0.7821 - Val loss: 0.6964 - Val F1: 0.7805 - LR: 3.00e-06\n","\tEpoch 80/100 - Train loss: 0.8485 - Val accuracy: 0.8077 - Val loss: 0.6912 - Val F1: 0.8069 - LR: 2.00e-06\n","\tEpoch 90/100 - Train loss: 0.7948 - Val accuracy: 0.7949 - Val loss: 0.6819 - Val F1: 0.7918 - LR: 1.00e-06\n","\tEpoch 100/100 - Train loss: 0.7578 - Val accuracy: 0.8077 - Val loss: 0.6729 - Val F1: 0.8069 - LR: 0.00e+00\n","\tBest epoch: 100 - Best val accuracy: 0.8077 - Best val loss: 0.6729 - Best val F1: 0.8069\n","\n","Source class: WAL | Domain: 61 | Accuracy: 0.4854 | Loss: 2.6195 | F1: 0.5521\n","\n","Domain: 62\n","x_syn_dom.shape: (444, 3, 128) | np.unique(y_syn_dom): [0 1 2 3]\n","x_dp_dom.shape: (158, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","x_syn_dom.shape: (388, 3, 128) | np.unique(y_syn_dom): [0 1 2 3]\n","x_dp_dom.shape: (103, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Fine-tuning on synthetic data...\n","\tEpoch 10/100 - Train loss: 0.6893 - Val accuracy: 0.8846 - Val loss: 0.2684 - Val F1: 0.8863 - LR: 9.00e-06\n","\tEpoch 20/100 - Train loss: 0.5804 - Val accuracy: 0.9103 - Val loss: 0.2145 - Val F1: 0.9111 - LR: 8.00e-06\n","\tEpoch 30/100 - Train loss: 0.5884 - Val accuracy: 0.9103 - Val loss: 0.1795 - Val F1: 0.9112 - LR: 7.00e-06\n","\tEpoch 40/100 - Train loss: 0.4050 - Val accuracy: 0.9231 - Val loss: 0.1684 - Val F1: 0.9233 - LR: 6.00e-06\n","\tEpoch 50/100 - Train loss: 0.4888 - Val accuracy: 0.9231 - Val loss: 0.1413 - Val F1: 0.9240 - LR: 5.00e-06\n","\tEpoch 60/100 - Train loss: 0.4504 - Val accuracy: 0.9359 - Val loss: 0.1389 - Val F1: 0.9363 - LR: 4.00e-06\n","\tEpoch 70/100 - Train loss: 0.4214 - Val accuracy: 0.9359 - Val loss: 0.1286 - Val F1: 0.9363 - LR: 3.00e-06\n","\tEpoch 80/100 - Train loss: 0.5303 - Val accuracy: 0.9359 - Val loss: 0.1256 - Val F1: 0.9363 - LR: 2.00e-06\n","\tEpoch 90/100 - Train loss: 0.3720 - Val accuracy: 0.9359 - Val loss: 0.1215 - Val F1: 0.9363 - LR: 1.00e-06\n","\tEpoch 100/100 - Train loss: 0.4051 - Val accuracy: 0.9359 - Val loss: 0.1215 - Val F1: 0.9363 - LR: 0.00e+00\n","\tBest epoch: 89 - Best val accuracy: 0.9487 - Best val loss: 0.1121 - Best val F1: 0.9487\n","\n","Source class: WAL | Domain: 62 | Accuracy: 0.6019 | Loss: 1.5049 | F1: 0.6390\n","\n","Domain: 63\n","x_syn_dom.shape: (444, 3, 128) | np.unique(y_syn_dom): [0 1 2 3]\n","x_dp_dom.shape: (153, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","x_syn_dom.shape: (388, 3, 128) | np.unique(y_syn_dom): [0 1 2 3]\n","x_dp_dom.shape: (98, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Fine-tuning on synthetic data...\n","\tEpoch 10/100 - Train loss: 1.3449 - Val accuracy: 0.8077 - Val loss: 1.0394 - Val F1: 0.8017 - LR: 9.00e-06\n","\tEpoch 20/100 - Train loss: 1.3446 - Val accuracy: 0.8077 - Val loss: 0.9471 - Val F1: 0.8017 - LR: 8.00e-06\n","\tEpoch 30/100 - Train loss: 0.9928 - Val accuracy: 0.8205 - Val loss: 0.8808 - Val F1: 0.8123 - LR: 7.00e-06\n","\tEpoch 40/100 - Train loss: 0.9860 - Val accuracy: 0.8333 - Val loss: 0.8312 - Val F1: 0.8283 - LR: 6.00e-06\n","\tEpoch 50/100 - Train loss: 0.9542 - Val accuracy: 0.8462 - Val loss: 0.8003 - Val F1: 0.8392 - LR: 5.00e-06\n","\tEpoch 60/100 - Train loss: 0.8212 - Val accuracy: 0.8333 - Val loss: 0.7667 - Val F1: 0.8283 - LR: 4.00e-06\n","\tEpoch 70/100 - Train loss: 0.9127 - Val accuracy: 0.8718 - Val loss: 0.7599 - Val F1: 0.8591 - LR: 3.00e-06\n","\tEpoch 80/100 - Train loss: 0.8978 - Val accuracy: 0.8590 - Val loss: 0.7431 - Val F1: 0.8470 - LR: 2.00e-06\n","\tEpoch 90/100 - Train loss: 0.7602 - Val accuracy: 0.8718 - Val loss: 0.7274 - Val F1: 0.8591 - LR: 1.00e-06\n","\tEpoch 100/100 - Train loss: 0.8014 - Val accuracy: 0.8462 - Val loss: 0.7167 - Val F1: 0.8345 - LR: 0.00e+00\n","\tBest epoch: 89 - Best val accuracy: 0.8590 - Best val loss: 0.7153 - Best val F1: 0.8522\n","\n","Source class: WAL | Domain: 63 | Accuracy: 0.4796 | Loss: 2.4260 | F1: 0.5510\n","\n","Domain: 64\n","x_syn_dom.shape: (448, 3, 128) | np.unique(y_syn_dom): [0 1 2 3]\n","x_dp_dom.shape: (154, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","x_syn_dom.shape: (392, 3, 128) | np.unique(y_syn_dom): [0 1 2 3]\n","x_dp_dom.shape: (98, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Fine-tuning on synthetic data...\n","\tEpoch 10/100 - Train loss: 0.8314 - Val accuracy: 0.7975 - Val loss: 0.6034 - Val F1: 0.8003 - LR: 9.00e-06\n","\tEpoch 20/100 - Train loss: 0.7686 - Val accuracy: 0.7975 - Val loss: 0.5692 - Val F1: 0.8004 - LR: 8.00e-06\n","\tEpoch 30/100 - Train loss: 0.7353 - Val accuracy: 0.7975 - Val loss: 0.5535 - Val F1: 0.7977 - LR: 7.00e-06\n","\tEpoch 40/100 - Train loss: 0.6821 - Val accuracy: 0.8228 - Val loss: 0.5251 - Val F1: 0.8228 - LR: 6.00e-06\n","\tEpoch 50/100 - Train loss: 0.5811 - Val accuracy: 0.8101 - Val loss: 0.5291 - Val F1: 0.8103 - LR: 5.00e-06\n","\tEpoch 60/100 - Train loss: 0.6576 - Val accuracy: 0.8228 - Val loss: 0.5071 - Val F1: 0.8228 - LR: 4.00e-06\n","\tEpoch 70/100 - Train loss: 0.6000 - Val accuracy: 0.8228 - Val loss: 0.4975 - Val F1: 0.8250 - LR: 3.00e-06\n","\tEpoch 80/100 - Train loss: 0.6191 - Val accuracy: 0.8354 - Val loss: 0.5026 - Val F1: 0.8380 - LR: 2.00e-06\n","\tEpoch 90/100 - Train loss: 0.5966 - Val accuracy: 0.8228 - Val loss: 0.4942 - Val F1: 0.8250 - LR: 1.00e-06\n","\tEpoch 100/100 - Train loss: 0.4927 - Val accuracy: 0.8228 - Val loss: 0.4877 - Val F1: 0.8253 - LR: 0.00e+00\n","\tBest epoch: 97 - Best val accuracy: 0.8228 - Best val loss: 0.4820 - Best val F1: 0.8250\n","\n","Source class: WAL | Domain: 64 | Accuracy: 0.3673 | Loss: 4.2343 | F1: 0.4007\n","\n","Domain: 65\n","x_syn_dom.shape: (444, 3, 128) | np.unique(y_syn_dom): [0 1 2 3]\n","x_dp_dom.shape: (161, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","x_syn_dom.shape: (388, 3, 128) | np.unique(y_syn_dom): [0 1 2 3]\n","x_dp_dom.shape: (106, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Fine-tuning on synthetic data...\n","\tEpoch 10/100 - Train loss: 1.7349 - Val accuracy: 0.7436 - Val loss: 1.0305 - Val F1: 0.7411 - LR: 9.00e-06\n","\tEpoch 20/100 - Train loss: 1.1351 - Val accuracy: 0.7692 - Val loss: 0.9349 - Val F1: 0.7691 - LR: 8.00e-06\n","\tEpoch 30/100 - Train loss: 1.2316 - Val accuracy: 0.7949 - Val loss: 0.8665 - Val F1: 0.7969 - LR: 7.00e-06\n","\tEpoch 40/100 - Train loss: 1.2450 - Val accuracy: 0.7949 - Val loss: 0.7975 - Val F1: 0.7969 - LR: 6.00e-06\n","\tEpoch 50/100 - Train loss: 1.0653 - Val accuracy: 0.7949 - Val loss: 0.7750 - Val F1: 0.7992 - LR: 5.00e-06\n","\tEpoch 60/100 - Train loss: 1.2125 - Val accuracy: 0.7949 - Val loss: 0.7688 - Val F1: 0.8013 - LR: 4.00e-06\n","\tEpoch 70/100 - Train loss: 1.0884 - Val accuracy: 0.8077 - Val loss: 0.7461 - Val F1: 0.8103 - LR: 3.00e-06\n","\tEpoch 80/100 - Train loss: 0.9770 - Val accuracy: 0.8205 - Val loss: 0.7217 - Val F1: 0.8240 - LR: 2.00e-06\n","\tEpoch 90/100 - Train loss: 1.0040 - Val accuracy: 0.8077 - Val loss: 0.7577 - Val F1: 0.8108 - LR: 1.00e-06\n","\tEpoch 100/100 - Train loss: 0.9521 - Val accuracy: 0.8205 - Val loss: 0.7318 - Val F1: 0.8240 - LR: 0.00e+00\n","\tBest epoch: 79 - Best val accuracy: 0.7949 - Best val loss: 0.7006 - Best val F1: 0.8017\n","\n","Source class: WAL | Domain: 65 | Accuracy: 0.6226 | Loss: 3.2729 | F1: 0.6425\n","\n","Domain: 66\n","x_syn_dom.shape: (444, 3, 128) | np.unique(y_syn_dom): [0 1 2 3]\n","x_dp_dom.shape: (153, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","x_syn_dom.shape: (388, 3, 128) | np.unique(y_syn_dom): [0 1 2 3]\n","x_dp_dom.shape: (98, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Fine-tuning on synthetic data...\n","\tEpoch 10/100 - Train loss: 1.1512 - Val accuracy: 0.7179 - Val loss: 1.0271 - Val F1: 0.7170 - LR: 9.00e-06\n","\tEpoch 20/100 - Train loss: 1.3066 - Val accuracy: 0.7564 - Val loss: 0.9365 - Val F1: 0.7603 - LR: 8.00e-06\n","\tEpoch 30/100 - Train loss: 1.0051 - Val accuracy: 0.7821 - Val loss: 0.8744 - Val F1: 0.7829 - LR: 7.00e-06\n","\tEpoch 40/100 - Train loss: 1.0484 - Val accuracy: 0.8077 - Val loss: 0.7989 - Val F1: 0.8088 - LR: 6.00e-06\n","\tEpoch 50/100 - Train loss: 0.7966 - Val accuracy: 0.8077 - Val loss: 0.7720 - Val F1: 0.8088 - LR: 5.00e-06\n","\tEpoch 60/100 - Train loss: 0.9930 - Val accuracy: 0.8077 - Val loss: 0.7517 - Val F1: 0.8104 - LR: 4.00e-06\n","\tEpoch 70/100 - Train loss: 0.6617 - Val accuracy: 0.8205 - Val loss: 0.7190 - Val F1: 0.8245 - LR: 3.00e-06\n","\tEpoch 80/100 - Train loss: 0.7142 - Val accuracy: 0.8205 - Val loss: 0.7143 - Val F1: 0.8245 - LR: 2.00e-06\n","\tEpoch 90/100 - Train loss: 0.9365 - Val accuracy: 0.8205 - Val loss: 0.7133 - Val F1: 0.8245 - LR: 1.00e-06\n","\tEpoch 100/100 - Train loss: 0.7155 - Val accuracy: 0.8205 - Val loss: 0.7006 - Val F1: 0.8245 - LR: 0.00e+00\n","\tBest epoch: 95 - Best val accuracy: 0.8205 - Best val loss: 0.6849 - Best val F1: 0.8245\n","\n","Source class: WAL | Domain: 66 | Accuracy: 0.5510 | Loss: 6.0910 | F1: 0.5909\n","\n","Domain: 67\n","x_syn_dom.shape: (444, 3, 128) | np.unique(y_syn_dom): [0 1 2 3]\n","x_dp_dom.shape: (153, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","x_syn_dom.shape: (388, 3, 128) | np.unique(y_syn_dom): [0 1 2 3]\n","x_dp_dom.shape: (98, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Fine-tuning on synthetic data...\n","\tEpoch 10/100 - Train loss: 3.2927 - Val accuracy: 0.4744 - Val loss: 2.9970 - Val F1: 0.4815 - LR: 9.00e-06\n","\tEpoch 20/100 - Train loss: 2.9628 - Val accuracy: 0.4872 - Val loss: 2.7508 - Val F1: 0.5031 - LR: 8.00e-06\n","\tEpoch 30/100 - Train loss: 2.5547 - Val accuracy: 0.4872 - Val loss: 2.5276 - Val F1: 0.5031 - LR: 7.00e-06\n","\tEpoch 40/100 - Train loss: 2.4677 - Val accuracy: 0.4872 - Val loss: 2.3890 - Val F1: 0.5044 - LR: 6.00e-06\n","\tEpoch 50/100 - Train loss: 2.3277 - Val accuracy: 0.4872 - Val loss: 2.2490 - Val F1: 0.5062 - LR: 5.00e-06\n","\tEpoch 60/100 - Train loss: 1.9282 - Val accuracy: 0.4872 - Val loss: 2.1589 - Val F1: 0.5075 - LR: 4.00e-06\n","\tEpoch 70/100 - Train loss: 2.0619 - Val accuracy: 0.5256 - Val loss: 2.0474 - Val F1: 0.5409 - LR: 3.00e-06\n","\tEpoch 80/100 - Train loss: 1.9170 - Val accuracy: 0.5128 - Val loss: 2.0107 - Val F1: 0.5312 - LR: 2.00e-06\n","\tEpoch 90/100 - Train loss: 1.9802 - Val accuracy: 0.5000 - Val loss: 1.9880 - Val F1: 0.5181 - LR: 1.00e-06\n","\tEpoch 100/100 - Train loss: 1.8695 - Val accuracy: 0.5000 - Val loss: 1.9717 - Val F1: 0.5197 - LR: 0.00e+00\n","\tBest epoch: 95 - Best val accuracy: 0.5256 - Best val loss: 1.9523 - Best val F1: 0.5409\n","\n","Source class: WAL | Domain: 67 | Accuracy: 0.4286 | Loss: 3.8273 | F1: 0.4259\n","\n","Domain: 68\n","x_syn_dom.shape: (444, 3, 128) | np.unique(y_syn_dom): [0 1 2 3]\n","x_dp_dom.shape: (154, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","x_syn_dom.shape: (388, 3, 128) | np.unique(y_syn_dom): [0 1 2 3]\n","x_dp_dom.shape: (99, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Fine-tuning on synthetic data...\n","\tEpoch 10/100 - Train loss: 2.2691 - Val accuracy: 0.5769 - Val loss: 2.0771 - Val F1: 0.5873 - LR: 9.00e-06\n","\tEpoch 20/100 - Train loss: 2.1337 - Val accuracy: 0.5769 - Val loss: 1.9337 - Val F1: 0.5844 - LR: 8.00e-06\n","\tEpoch 30/100 - Train loss: 1.8659 - Val accuracy: 0.6282 - Val loss: 1.7923 - Val F1: 0.6345 - LR: 7.00e-06\n","\tEpoch 40/100 - Train loss: 1.6975 - Val accuracy: 0.6538 - Val loss: 1.6562 - Val F1: 0.6575 - LR: 6.00e-06\n","\tEpoch 50/100 - Train loss: 1.6561 - Val accuracy: 0.6410 - Val loss: 1.5920 - Val F1: 0.6467 - LR: 5.00e-06\n","\tEpoch 60/100 - Train loss: 1.5142 - Val accuracy: 0.6795 - Val loss: 1.5208 - Val F1: 0.6773 - LR: 4.00e-06\n","\tEpoch 70/100 - Train loss: 1.4373 - Val accuracy: 0.6538 - Val loss: 1.4716 - Val F1: 0.6575 - LR: 3.00e-06\n","\tEpoch 80/100 - Train loss: 1.3381 - Val accuracy: 0.6795 - Val loss: 1.4645 - Val F1: 0.6919 - LR: 2.00e-06\n","\tEpoch 90/100 - Train loss: 1.4706 - Val accuracy: 0.6923 - Val loss: 1.4439 - Val F1: 0.7005 - LR: 1.00e-06\n","\tEpoch 100/100 - Train loss: 1.4539 - Val accuracy: 0.6795 - Val loss: 1.4292 - Val F1: 0.6885 - LR: 0.00e+00\n","\tBest epoch: 98 - Best val accuracy: 0.6667 - Best val loss: 1.4139 - Best val F1: 0.6716\n","\n","Source class: WAL | Domain: 68 | Accuracy: 0.3636 | Loss: 4.0777 | F1: 0.4292\n","\n","Domain: 69\n","x_syn_dom.shape: (444, 3, 128) | np.unique(y_syn_dom): [0 1 2 3]\n","x_dp_dom.shape: (153, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","x_syn_dom.shape: (388, 3, 128) | np.unique(y_syn_dom): [0 1 2 3]\n","x_dp_dom.shape: (98, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Fine-tuning on synthetic data...\n","\tEpoch 10/100 - Train loss: 1.0602 - Val accuracy: 0.6923 - Val loss: 1.2252 - Val F1: 0.6914 - LR: 9.00e-06\n","\tEpoch 20/100 - Train loss: 1.2178 - Val accuracy: 0.6923 - Val loss: 1.1935 - Val F1: 0.6948 - LR: 8.00e-06\n","\tEpoch 30/100 - Train loss: 0.9944 - Val accuracy: 0.6795 - Val loss: 1.1195 - Val F1: 0.6805 - LR: 7.00e-06\n","\tEpoch 40/100 - Train loss: 0.8549 - Val accuracy: 0.6795 - Val loss: 1.0721 - Val F1: 0.6803 - LR: 6.00e-06\n","\tEpoch 50/100 - Train loss: 1.0132 - Val accuracy: 0.6923 - Val loss: 1.0392 - Val F1: 0.6943 - LR: 5.00e-06\n","\tEpoch 60/100 - Train loss: 1.0072 - Val accuracy: 0.6795 - Val loss: 1.0215 - Val F1: 0.6796 - LR: 4.00e-06\n","\tEpoch 70/100 - Train loss: 0.9756 - Val accuracy: 0.7051 - Val loss: 1.0006 - Val F1: 0.7057 - LR: 3.00e-06\n","\tEpoch 80/100 - Train loss: 0.9289 - Val accuracy: 0.7179 - Val loss: 0.9828 - Val F1: 0.7201 - LR: 2.00e-06\n","\tEpoch 90/100 - Train loss: 0.9489 - Val accuracy: 0.7051 - Val loss: 0.9567 - Val F1: 0.7057 - LR: 1.00e-06\n","\tEpoch 100/100 - Train loss: 0.8001 - Val accuracy: 0.7051 - Val loss: 0.9419 - Val F1: 0.7009 - LR: 0.00e+00\n","\tBest epoch: 100 - Best val accuracy: 0.7051 - Best val loss: 0.9419 - Best val F1: 0.7009\n","\n","Source class: WAL | Domain: 69 | Accuracy: 0.5306 | Loss: 2.5591 | F1: 0.5612\n","\n","Domain: 70\n","x_syn_dom.shape: (444, 3, 128) | np.unique(y_syn_dom): [0 1 2 3]\n","x_dp_dom.shape: (153, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","x_syn_dom.shape: (388, 3, 128) | np.unique(y_syn_dom): [0 1 2 3]\n","x_dp_dom.shape: (98, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Fine-tuning on synthetic data...\n","\tEpoch 10/100 - Train loss: 2.4069 - Val accuracy: 0.6410 - Val loss: 2.1984 - Val F1: 0.6375 - LR: 9.00e-06\n","\tEpoch 20/100 - Train loss: 2.0223 - Val accuracy: 0.6667 - Val loss: 2.0343 - Val F1: 0.6685 - LR: 8.00e-06\n","\tEpoch 30/100 - Train loss: 1.6486 - Val accuracy: 0.6538 - Val loss: 1.8974 - Val F1: 0.6606 - LR: 7.00e-06\n","\tEpoch 40/100 - Train loss: 1.8260 - Val accuracy: 0.6923 - Val loss: 1.8026 - Val F1: 0.6923 - LR: 6.00e-06\n","\tEpoch 50/100 - Train loss: 1.6501 - Val accuracy: 0.6923 - Val loss: 1.7229 - Val F1: 0.6923 - LR: 5.00e-06\n","\tEpoch 60/100 - Train loss: 1.6730 - Val accuracy: 0.6923 - Val loss: 1.6848 - Val F1: 0.6923 - LR: 4.00e-06\n","\tEpoch 70/100 - Train loss: 1.4498 - Val accuracy: 0.7051 - Val loss: 1.5819 - Val F1: 0.7068 - LR: 3.00e-06\n","\tEpoch 80/100 - Train loss: 1.4582 - Val accuracy: 0.7051 - Val loss: 1.5647 - Val F1: 0.7068 - LR: 2.00e-06\n","\tEpoch 90/100 - Train loss: 1.4701 - Val accuracy: 0.7051 - Val loss: 1.5121 - Val F1: 0.7068 - LR: 1.00e-06\n","\tEpoch 100/100 - Train loss: 1.4034 - Val accuracy: 0.7051 - Val loss: 1.4927 - Val F1: 0.7082 - LR: 0.00e+00\n","\tBest epoch: 100 - Best val accuracy: 0.7051 - Best val loss: 1.4927 - Best val F1: 0.7082\n","\n","Source class: WAL | Domain: 70 | Accuracy: 0.4694 | Loss: 6.1523 | F1: 0.5053\n","\n","Domain: 71\n","x_syn_dom.shape: (444, 3, 128) | np.unique(y_syn_dom): [0 1 2 3]\n","x_dp_dom.shape: (155, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","x_syn_dom.shape: (388, 3, 128) | np.unique(y_syn_dom): [0 1 2 3]\n","x_dp_dom.shape: (100, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Fine-tuning on synthetic data...\n","\tEpoch 10/100 - Train loss: 1.5656 - Val accuracy: 0.7051 - Val loss: 1.2580 - Val F1: 0.7066 - LR: 9.00e-06\n","\tEpoch 20/100 - Train loss: 1.3513 - Val accuracy: 0.6923 - Val loss: 1.2284 - Val F1: 0.6951 - LR: 8.00e-06\n","\tEpoch 30/100 - Train loss: 1.1416 - Val accuracy: 0.6923 - Val loss: 1.1556 - Val F1: 0.6958 - LR: 7.00e-06\n","\tEpoch 40/100 - Train loss: 0.9269 - Val accuracy: 0.7051 - Val loss: 1.1332 - Val F1: 0.7081 - LR: 6.00e-06\n","\tEpoch 50/100 - Train loss: 1.0969 - Val accuracy: 0.7051 - Val loss: 1.0733 - Val F1: 0.7055 - LR: 5.00e-06\n","\tEpoch 60/100 - Train loss: 1.1083 - Val accuracy: 0.7051 - Val loss: 1.0721 - Val F1: 0.7087 - LR: 4.00e-06\n","\tEpoch 70/100 - Train loss: 1.0818 - Val accuracy: 0.7051 - Val loss: 1.0437 - Val F1: 0.7095 - LR: 3.00e-06\n","\tEpoch 80/100 - Train loss: 1.0803 - Val accuracy: 0.7179 - Val loss: 1.0230 - Val F1: 0.7205 - LR: 2.00e-06\n","\tEpoch 90/100 - Train loss: 1.2258 - Val accuracy: 0.7179 - Val loss: 1.0115 - Val F1: 0.7229 - LR: 1.00e-06\n","\tEpoch 100/100 - Train loss: 1.2034 - Val accuracy: 0.7179 - Val loss: 1.0220 - Val F1: 0.7205 - LR: 0.00e+00\n","\tBest epoch: 92 - Best val accuracy: 0.7179 - Best val loss: 0.9972 - Best val F1: 0.7175\n","\n","Source class: WAL | Domain: 71 | Accuracy: 0.5600 | Loss: 1.6665 | F1: 0.6069\n","\n","Domain: 72\n","x_syn_dom.shape: (444, 3, 128) | np.unique(y_syn_dom): [0 1 2 3]\n","x_dp_dom.shape: (153, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","x_syn_dom.shape: (388, 3, 128) | np.unique(y_syn_dom): [0 1 2 3]\n","x_dp_dom.shape: (98, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Fine-tuning on synthetic data...\n","\tEpoch 10/100 - Train loss: 1.4265 - Val accuracy: 0.6923 - Val loss: 1.2855 - Val F1: 0.6851 - LR: 9.00e-06\n","\tEpoch 20/100 - Train loss: 1.3322 - Val accuracy: 0.7179 - Val loss: 1.1702 - Val F1: 0.7061 - LR: 8.00e-06\n","\tEpoch 30/100 - Train loss: 1.3491 - Val accuracy: 0.7308 - Val loss: 1.0902 - Val F1: 0.7260 - LR: 7.00e-06\n","\tEpoch 40/100 - Train loss: 1.1456 - Val accuracy: 0.7051 - Val loss: 1.0067 - Val F1: 0.7013 - LR: 6.00e-06\n","\tEpoch 50/100 - Train loss: 1.1977 - Val accuracy: 0.7436 - Val loss: 0.9785 - Val F1: 0.7356 - LR: 5.00e-06\n","\tEpoch 60/100 - Train loss: 1.1280 - Val accuracy: 0.7179 - Val loss: 0.9671 - Val F1: 0.7061 - LR: 4.00e-06\n","\tEpoch 70/100 - Train loss: 1.0276 - Val accuracy: 0.7308 - Val loss: 0.9512 - Val F1: 0.7237 - LR: 3.00e-06\n","\tEpoch 80/100 - Train loss: 0.9687 - Val accuracy: 0.7564 - Val loss: 0.9048 - Val F1: 0.7522 - LR: 2.00e-06\n","\tEpoch 90/100 - Train loss: 1.1852 - Val accuracy: 0.7436 - Val loss: 0.9145 - Val F1: 0.7356 - LR: 1.00e-06\n","\tEpoch 100/100 - Train loss: 1.4260 - Val accuracy: 0.7436 - Val loss: 0.8837 - Val F1: 0.7356 - LR: 0.00e+00\n","\tBest epoch: 86 - Best val accuracy: 0.7564 - Best val loss: 0.8763 - Best val F1: 0.7522\n","\n","Source class: WAL | Domain: 72 | Accuracy: 0.2857 | Loss: 3.9590 | F1: 0.3451\n","\n","Domain: 73\n","x_syn_dom.shape: (444, 3, 128) | np.unique(y_syn_dom): [0 1 2 3]\n","x_dp_dom.shape: (152, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","x_syn_dom.shape: (388, 3, 128) | np.unique(y_syn_dom): [0 1 2 3]\n","x_dp_dom.shape: (97, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Fine-tuning on synthetic data...\n","\tEpoch 10/100 - Train loss: 1.0512 - Val accuracy: 0.7949 - Val loss: 0.7865 - Val F1: 0.7784 - LR: 9.00e-06\n","\tEpoch 20/100 - Train loss: 0.6699 - Val accuracy: 0.8590 - Val loss: 0.4579 - Val F1: 0.8554 - LR: 8.00e-06\n","\tEpoch 30/100 - Train loss: 0.4646 - Val accuracy: 0.8846 - Val loss: 0.2862 - Val F1: 0.8850 - LR: 7.00e-06\n","\tEpoch 40/100 - Train loss: 0.3897 - Val accuracy: 0.8974 - Val loss: 0.1965 - Val F1: 0.8988 - LR: 6.00e-06\n","\tEpoch 50/100 - Train loss: 0.2829 - Val accuracy: 0.9359 - Val loss: 0.1303 - Val F1: 0.9359 - LR: 5.00e-06\n","\tEpoch 60/100 - Train loss: 0.3581 - Val accuracy: 0.9487 - Val loss: 0.1164 - Val F1: 0.9490 - LR: 4.00e-06\n","\tEpoch 70/100 - Train loss: 0.2021 - Val accuracy: 0.9487 - Val loss: 0.0981 - Val F1: 0.9491 - LR: 3.00e-06\n","\tEpoch 80/100 - Train loss: 0.2571 - Val accuracy: 0.9872 - Val loss: 0.0799 - Val F1: 0.9870 - LR: 2.00e-06\n","\tEpoch 90/100 - Train loss: 0.2308 - Val accuracy: 0.9872 - Val loss: 0.0809 - Val F1: 0.9870 - LR: 1.00e-06\n","\tEpoch 100/100 - Train loss: 0.2640 - Val accuracy: 0.9744 - Val loss: 0.0758 - Val F1: 0.9744 - LR: 0.00e+00\n","\tBest epoch: 92 - Best val accuracy: 0.9872 - Best val loss: 0.0710 - Best val F1: 0.9870\n","\n","Source class: WAL | Domain: 73 | Accuracy: 0.8041 | Loss: 2.2516 | F1: 0.7476\n","\n","Domain: 74\n","x_syn_dom.shape: (444, 3, 128) | np.unique(y_syn_dom): [0 1 2 3]\n","x_dp_dom.shape: (146, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","x_syn_dom.shape: (388, 3, 128) | np.unique(y_syn_dom): [0 1 2 3]\n","x_dp_dom.shape: (91, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Fine-tuning on synthetic data...\n","\tEpoch 10/100 - Train loss: 2.2907 - Val accuracy: 0.6667 - Val loss: 1.4838 - Val F1: 0.6670 - LR: 9.00e-06\n","\tEpoch 20/100 - Train loss: 2.1658 - Val accuracy: 0.6667 - Val loss: 1.3354 - Val F1: 0.6713 - LR: 8.00e-06\n","\tEpoch 30/100 - Train loss: 1.9955 - Val accuracy: 0.6923 - Val loss: 1.2156 - Val F1: 0.6952 - LR: 7.00e-06\n","\tEpoch 40/100 - Train loss: 1.8122 - Val accuracy: 0.7179 - Val loss: 1.1527 - Val F1: 0.7201 - LR: 6.00e-06\n","\tEpoch 50/100 - Train loss: 1.8733 - Val accuracy: 0.7051 - Val loss: 1.0596 - Val F1: 0.7106 - LR: 5.00e-06\n","\tEpoch 60/100 - Train loss: 1.5521 - Val accuracy: 0.7051 - Val loss: 1.0051 - Val F1: 0.7117 - LR: 4.00e-06\n","\tEpoch 70/100 - Train loss: 1.5182 - Val accuracy: 0.7436 - Val loss: 0.9473 - Val F1: 0.7494 - LR: 3.00e-06\n","\tEpoch 80/100 - Train loss: 1.5170 - Val accuracy: 0.7436 - Val loss: 0.9171 - Val F1: 0.7472 - LR: 2.00e-06\n","\tEpoch 90/100 - Train loss: 1.4233 - Val accuracy: 0.7564 - Val loss: 0.8931 - Val F1: 0.7573 - LR: 1.00e-06\n","\tEpoch 100/100 - Train loss: 1.4693 - Val accuracy: 0.7564 - Val loss: 0.8920 - Val F1: 0.7579 - LR: 0.00e+00\n","\tBest epoch: 97 - Best val accuracy: 0.7564 - Best val loss: 0.8838 - Best val F1: 0.7573\n","\n","Source class: WAL | Domain: 74 | Accuracy: 0.4396 | Loss: 3.7409 | F1: 0.5093\n","\n","Domain: 75\n","x_syn_dom.shape: (444, 3, 128) | np.unique(y_syn_dom): [0 1 2 3]\n","x_dp_dom.shape: (153, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","x_syn_dom.shape: (388, 3, 128) | np.unique(y_syn_dom): [0 1 2 3]\n","x_dp_dom.shape: (98, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Fine-tuning on synthetic data...\n","\tEpoch 10/100 - Train loss: 1.4050 - Val accuracy: 0.6795 - Val loss: 1.1118 - Val F1: 0.6803 - LR: 9.00e-06\n","\tEpoch 20/100 - Train loss: 1.2329 - Val accuracy: 0.7051 - Val loss: 1.0293 - Val F1: 0.7015 - LR: 8.00e-06\n","\tEpoch 30/100 - Train loss: 1.0566 - Val accuracy: 0.7051 - Val loss: 0.9533 - Val F1: 0.7062 - LR: 7.00e-06\n","\tEpoch 40/100 - Train loss: 1.1121 - Val accuracy: 0.7051 - Val loss: 0.9155 - Val F1: 0.7015 - LR: 6.00e-06\n","\tEpoch 50/100 - Train loss: 1.1198 - Val accuracy: 0.7179 - Val loss: 0.8810 - Val F1: 0.7170 - LR: 5.00e-06\n","\tEpoch 60/100 - Train loss: 0.9634 - Val accuracy: 0.7308 - Val loss: 0.8830 - Val F1: 0.7264 - LR: 4.00e-06\n","\tEpoch 70/100 - Train loss: 0.8566 - Val accuracy: 0.7179 - Val loss: 0.8122 - Val F1: 0.7202 - LR: 3.00e-06\n","\tEpoch 80/100 - Train loss: 0.9944 - Val accuracy: 0.7179 - Val loss: 0.8259 - Val F1: 0.7187 - LR: 2.00e-06\n","\tEpoch 90/100 - Train loss: 0.9211 - Val accuracy: 0.7179 - Val loss: 0.7991 - Val F1: 0.7187 - LR: 1.00e-06\n","\tEpoch 100/100 - Train loss: 0.9123 - Val accuracy: 0.7179 - Val loss: 0.8022 - Val F1: 0.7127 - LR: 0.00e+00\n","\tBest epoch: 93 - Best val accuracy: 0.7308 - Best val loss: 0.7801 - Best val F1: 0.7343\n","\n","Source class: WAL | Domain: 75 | Accuracy: 0.2551 | Loss: 4.0574 | F1: 0.2859\n","\n","Mean accuracy: 0.5083 +- 0.1304\n","Mean F1: 0.5371 +- 0.1224\n","\n"]}],"source":["def compute_TSTR_Df_Syn(dataset):\n","    accs = []\n","    f1s = []\n","\n","    for src_class in config[dataset]['class_names']:\n","        if src_class != 'WAL':\n","            continue\n","\n","        print(f\"Source class: {src_class}\\n\")\n","\n","        # Load Df data\n","        x_df, y_df, k_df = get_data(dataset, 'df', src_class)\n","        print(f'x_df.shape: {x_df.shape} | np.unique(y_df): {np.unique(y_df)}\\n')\n","\n","        # Train on Df data\n","        print('Training on Df data...')\n","        df_model = train_only(x_df, y_df, dataset, num_epochs=num_epochs)\n","\n","        for domain in range(config[dataset]['num_df_domains'], config[dataset]['num_df_domains'] + config[dataset]['num_dp_domains']):\n","            print(f\"Domain: {domain}\")\n","\n","            # Load synthetic data\n","            x_syn_dom, y_syn_dom, k_syn_dom = get_syn_data(dataset, syn_name, src_class, domain)\n","            print(f'x_syn_dom.shape: {x_syn_dom.shape} | np.unique(y_syn_dom): {np.unique(y_syn_dom)}')\n","\n","            # Load Dp data\n","            x_dp_dom, y_dp_dom, k_dp_dom = get_data(dataset, 'dp', src_class, domain)\n","            print(f'x_dp_dom.shape: {x_dp_dom.shape} | np.unique(y_dp_dom): {np.unique(y_dp_dom)}\\n')\n","\n","            y0_indices_syn = np.where(y_syn_dom == 0)[0]\n","            y0_indices_dp = np.where(y_dp_dom == 0)[0]\n","            assert np.array_equal(y0_indices_syn, y0_indices_dp), \"Labels do not match\"\n","            assert np.array_equal(y_syn_dom[y0_indices_syn], y_dp_dom[y0_indices_dp]), \"Labels do not match\"\n","\n","            y0_indices_train, y0_indices_test = train_test_split(y0_indices_syn, test_size=0.5, shuffle=True, random_state=seed)\n","\n","            x_syn_dom_y0, y_syn_dom_y0 = x_syn_dom[y0_indices_train], y_syn_dom[y0_indices_train]\n","            x_dp_dom_y0, y_dp_dom_y0 = x_dp_dom[y0_indices_test], y_dp_dom[y0_indices_test]\n","\n","            x_syn_dom = np.concatenate([x_syn_dom_y0, x_syn_dom[y_syn_dom != 0]])\n","            y_syn_dom = np.concatenate([y_syn_dom_y0, y_syn_dom[y_syn_dom != 0]])\n","            x_dp_dom = np.concatenate([x_dp_dom_y0, x_dp_dom[y_dp_dom != 0]])\n","            y_dp_dom = np.concatenate([y_dp_dom_y0, y_dp_dom[y_dp_dom != 0]])\n","\n","            print(f'x_syn_dom.shape: {x_syn_dom.shape} | np.unique(y_syn_dom): {np.unique(y_syn_dom)}')\n","            print(f'x_dp_dom.shape: {x_dp_dom.shape} | np.unique(y_dp_dom): {np.unique(y_dp_dom)}\\n')\n","\n","            # Fine-tune Df model on synthetic data and evaluate on Dp data\n","            print('Fine-tuning on synthetic data...')\n","            df_syn_model = fine_tune(copy.deepcopy(df_model), x_syn_dom, y_syn_dom, num_epochs=num_epochs)\n","            acc, loss, f1 = evaluate_model(df_syn_model, get_dataloader(x_dp_dom, y_dp_dom))\n","            save_scores(src_class, domain, acc, loss, f1, 'Df_Syn', dataset)\n","            accs.append(acc)\n","            f1s.append(f1)\n","            print(f'Source class: {src_class} | Domain: {domain} | Accuracy: {acc:.4f} | Loss: {loss:.4f} | F1: {f1:.4f}\\n')\n","\n","    print(f\"Mean accuracy: {np.mean(accs):.4f} +- {np.std(accs):.4f}\")\n","    print(f\"Mean F1: {np.mean(f1s):.4f} +- {np.std(f1s):.4f}\\n\")\n","\n","\n","\n","\n","compute_TSTR_Df_Syn('realworld_mobiact')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"WrQyLH7NMxLn"},"outputs":[],"source":["# def compute_TSTR_Df_Syn_all(dataset):\n","#     accs = []\n","\n","#     for src_class in config[dataset]['class_names']:\n","#         if src_class != 'WAL':\n","#             continue\n","\n","#         print(f\"Source class: {src_class}\\n\")\n","\n","#         # Load Df data\n","#         x_df, y_df, k_df = get_data(dataset, 'df', src_class)\n","#         print(f'x_df.shape: {x_df.shape} | np.unique(y_df): {np.unique(y_df)}\\n')\n","\n","#         # Train on Df data\n","#         print('Training on Df data...')\n","#         df_model = train_only(x_df, y_df, dataset, num_epochs=num_epochs)\n","\n","#         # Load synthetic data\n","#         x_syn, y_syn, k_syn = get_syn_data(dataset, syn_name, src_class)\n","#         print(f'x_syn.shape: {x_syn.shape} | np.unique(y_syn): {np.unique(y_syn)}')\n","\n","#         # Load Dp data\n","#         x_dp, y_dp, k_dp = get_data(dataset, 'dp', src_class)\n","#         print(f'x_dp.shape: {x_dp.shape} | np.unique(y_dp): {np.unique(y_dp)}\\n')\n","\n","#         # Fine-tune Df model on synthetic data and evaluate on Dp data\n","#         print('Fine-tuning on synthetic data...')\n","#         df_syn_model = fine_tune(copy.deepcopy(df_model), x_syn, y_syn, num_epochs=num_epochs)\n","#         acc, loss = evaluate_model(df_syn_model, get_dataloader(x_dp, y_dp))\n","#         save_scores(src_class, 100, acc, loss, 'Df_Syn_all', dataset)\n","#         accs.append(acc)\n","#         print(f'Source class: {src_class} | Domain: All | Accuracy: {acc:.4f} | Loss: {loss:.4f}\\n')\n","\n","#     print(f\"Mean accuracy: {np.mean(accs):.4f}\\n\")\n","\n","\n","\n","\n","# compute_TSTR_Df_Syn_all('realworld_mobiact')"]},{"cell_type":"code","execution_count":8,"metadata":{"executionInfo":{"elapsed":53918,"status":"ok","timestamp":1732704429225,"user":{"displayName":"Pietro Pietro","userId":"08339472013712676764"},"user_tz":-60},"id":"Y53G-W-A0q0P","colab":{"base_uri":"https://localhost:8080/"},"outputId":"e50f24b6-6163-44a3-910d-ad2974c63bf3"},"outputs":[{"output_type":"stream","name":"stdout","text":["Source class: WAL\n","\n","x_df.shape: (11783, 3, 128) | np.unique(y_df): [0 1 2 3]\n","\n","Domain: 15\n","x_syn_dom.shape: (444, 3, 128) | np.unique(y_syn_dom): [0 1 2 3]\n","x_dp_dom.shape: (161, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","x_syn_dom.shape: (388, 3, 128) | np.unique(y_syn_dom): [0 1 2 3]\n","x_dp_dom.shape: (106, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","x_df_syn.shape: (12171, 3, 128) | np.unique(y_df_syn): [0 1 2 3]\n","Training on Df plus synthetic data...\n","\tEpoch 10/100 - Train loss: 0.1042 - Val accuracy: 0.9470 - Val loss: 0.1457 - Val F1: 0.9470 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.0406 - Val accuracy: 0.9504 - Val loss: 0.1425 - Val F1: 0.9503 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.0194 - Val accuracy: 0.9563 - Val loss: 0.1559 - Val F1: 0.9563 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.0116 - Val accuracy: 0.9567 - Val loss: 0.1551 - Val F1: 0.9567 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.0070 - Val accuracy: 0.9563 - Val loss: 0.1706 - Val F1: 0.9563 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.0036 - Val accuracy: 0.9571 - Val loss: 0.1659 - Val F1: 0.9572 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0038 - Val accuracy: 0.9555 - Val loss: 0.1912 - Val F1: 0.9554 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0018 - Val accuracy: 0.9567 - Val loss: 0.1904 - Val F1: 0.9567 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0017 - Val accuracy: 0.9588 - Val loss: 0.2003 - Val F1: 0.9588 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0012 - Val accuracy: 0.9576 - Val loss: 0.1894 - Val F1: 0.9576 - LR: 0.00e+00\n","\tBest epoch: 15 - Best val accuracy: 0.9538 - Best val loss: 0.1294 - Best val F1: 0.9538\n","\n","Source class: WAL | Domain: 15 | Accuracy: 0.1132 | Loss: 23.1997 | F1: 0.0295\n","\n","Domain: 16\n","x_syn_dom.shape: (444, 3, 128) | np.unique(y_syn_dom): [0 1 2 3]\n","x_dp_dom.shape: (165, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","x_syn_dom.shape: (388, 3, 128) | np.unique(y_syn_dom): [0 1 2 3]\n","x_dp_dom.shape: (110, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","x_df_syn.shape: (12171, 3, 128) | np.unique(y_df_syn): [0 1 2 3]\n","Training on Df plus synthetic data...\n","\tEpoch 10/100 - Train loss: 0.1086 - Val accuracy: 0.9529 - Val loss: 0.1339 - Val F1: 0.9529 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.0432 - Val accuracy: 0.9584 - Val loss: 0.1175 - Val F1: 0.9585 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.0230 - Val accuracy: 0.9584 - Val loss: 0.1456 - Val F1: 0.9585 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.0106 - Val accuracy: 0.9610 - Val loss: 0.1570 - Val F1: 0.9610 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.0074 - Val accuracy: 0.9588 - Val loss: 0.1472 - Val F1: 0.9589 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.0054 - Val accuracy: 0.9614 - Val loss: 0.1529 - Val F1: 0.9614 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0033 - Val accuracy: 0.9584 - Val loss: 0.1551 - Val F1: 0.9585 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0031 - Val accuracy: 0.9610 - Val loss: 0.1712 - Val F1: 0.9610 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0034 - Val accuracy: 0.9610 - Val loss: 0.1656 - Val F1: 0.9610 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0013 - Val accuracy: 0.9618 - Val loss: 0.1715 - Val F1: 0.9619 - LR: 0.00e+00\n","\tBest epoch: 21 - Best val accuracy: 0.9601 - Best val loss: 0.1142 - Best val F1: 0.9602\n","\n","Source class: WAL | Domain: 16 | Accuracy: 0.2545 | Loss: 29.1271 | F1: 0.1033\n","\n","Domain: 17\n","x_syn_dom.shape: (444, 3, 128) | np.unique(y_syn_dom): [0 1 2 3]\n","x_dp_dom.shape: (164, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","x_syn_dom.shape: (388, 3, 128) | np.unique(y_syn_dom): [0 1 2 3]\n","x_dp_dom.shape: (109, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","x_df_syn.shape: (12171, 3, 128) | np.unique(y_df_syn): [0 1 2 3]\n","Training on Df plus synthetic data...\n","\tEpoch 10/100 - Train loss: 0.1003 - Val accuracy: 0.9431 - Val loss: 0.1590 - Val F1: 0.9432 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.0400 - Val accuracy: 0.9508 - Val loss: 0.1518 - Val F1: 0.9507 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.0196 - Val accuracy: 0.9521 - Val loss: 0.1681 - Val F1: 0.9521 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.0103 - Val accuracy: 0.9525 - Val loss: 0.1852 - Val F1: 0.9525 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.0053 - Val accuracy: 0.9529 - Val loss: 0.2032 - Val F1: 0.9529 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.0034 - Val accuracy: 0.9542 - Val loss: 0.2032 - Val F1: 0.9542 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0029 - Val accuracy: 0.9529 - Val loss: 0.2184 - Val F1: 0.9529 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0020 - Val accuracy: 0.9529 - Val loss: 0.2253 - Val F1: 0.9529 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0023 - Val accuracy: 0.9538 - Val loss: 0.2237 - Val F1: 0.9537 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0017 - Val accuracy: 0.9521 - Val loss: 0.2304 - Val F1: 0.9520 - LR: 0.00e+00\n","\tBest epoch: 18 - Best val accuracy: 0.9487 - Best val loss: 0.1454 - Best val F1: 0.9487\n","\n","Source class: WAL | Domain: 17 | Accuracy: 0.2477 | Loss: 19.2484 | F1: 0.1253\n","\n","Domain: 18\n","x_syn_dom.shape: (448, 3, 128) | np.unique(y_syn_dom): [0 1 2 3]\n","x_dp_dom.shape: (166, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","x_syn_dom.shape: (392, 3, 128) | np.unique(y_syn_dom): [0 1 2 3]\n","x_dp_dom.shape: (110, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","x_df_syn.shape: (12175, 3, 128) | np.unique(y_df_syn): [0 1 2 3]\n","Training on Df plus synthetic data...\n","\tEpoch 10/100 - Train loss: 0.0954 - Val accuracy: 0.9512 - Val loss: 0.1399 - Val F1: 0.9512 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.0383 - Val accuracy: 0.9567 - Val loss: 0.1452 - Val F1: 0.9568 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.0166 - Val accuracy: 0.9593 - Val loss: 0.1365 - Val F1: 0.9593 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.0082 - Val accuracy: 0.9614 - Val loss: 0.1420 - Val F1: 0.9614 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.0045 - Val accuracy: 0.9618 - Val loss: 0.1704 - Val F1: 0.9618 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.0049 - Val accuracy: 0.9622 - Val loss: 0.1808 - Val F1: 0.9622 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0024 - Val accuracy: 0.9601 - Val loss: 0.1779 - Val F1: 0.9601 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0017 - Val accuracy: 0.9648 - Val loss: 0.1678 - Val F1: 0.9648 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0015 - Val accuracy: 0.9618 - Val loss: 0.1741 - Val F1: 0.9618 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0013 - Val accuracy: 0.9610 - Val loss: 0.1807 - Val F1: 0.9610 - LR: 0.00e+00\n","\tBest epoch: 15 - Best val accuracy: 0.9580 - Best val loss: 0.1260 - Best val F1: 0.9580\n","\n","Source class: WAL | Domain: 18 | Accuracy: 0.3727 | Loss: 15.2917 | F1: 0.2644\n","\n","Domain: 19\n","x_syn_dom.shape: (444, 3, 128) | np.unique(y_syn_dom): [0 1 2 3]\n","x_dp_dom.shape: (165, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","x_syn_dom.shape: (388, 3, 128) | np.unique(y_syn_dom): [0 1 2 3]\n","x_dp_dom.shape: (110, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","x_df_syn.shape: (12171, 3, 128) | np.unique(y_df_syn): [0 1 2 3]\n","Training on Df plus synthetic data...\n","\tEpoch 10/100 - Train loss: 0.0918 - Val accuracy: 0.9512 - Val loss: 0.1294 - Val F1: 0.9513 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.0373 - Val accuracy: 0.9580 - Val loss: 0.1280 - Val F1: 0.9580 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.0147 - Val accuracy: 0.9584 - Val loss: 0.1275 - Val F1: 0.9585 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.0084 - Val accuracy: 0.9597 - Val loss: 0.1473 - Val F1: 0.9597 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.0062 - Val accuracy: 0.9614 - Val loss: 0.1727 - Val F1: 0.9614 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.0039 - Val accuracy: 0.9618 - Val loss: 0.1699 - Val F1: 0.9618 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0030 - Val accuracy: 0.9610 - Val loss: 0.1601 - Val F1: 0.9610 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0017 - Val accuracy: 0.9618 - Val loss: 0.1745 - Val F1: 0.9619 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0017 - Val accuracy: 0.9635 - Val loss: 0.1718 - Val F1: 0.9635 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0012 - Val accuracy: 0.9622 - Val loss: 0.1762 - Val F1: 0.9623 - LR: 0.00e+00\n","\tBest epoch: 23 - Best val accuracy: 0.9601 - Best val loss: 0.1209 - Best val F1: 0.9602\n","\n","Source class: WAL | Domain: 19 | Accuracy: 0.3727 | Loss: 16.4993 | F1: 0.2869\n","\n","Domain: 20\n","x_syn_dom.shape: (444, 3, 128) | np.unique(y_syn_dom): [0 1 2 3]\n","x_dp_dom.shape: (162, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","x_syn_dom.shape: (388, 3, 128) | np.unique(y_syn_dom): [0 1 2 3]\n","x_dp_dom.shape: (107, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","x_df_syn.shape: (12171, 3, 128) | np.unique(y_df_syn): [0 1 2 3]\n","Training on Df plus synthetic data...\n","\tEpoch 10/100 - Train loss: 0.0967 - Val accuracy: 0.9508 - Val loss: 0.1476 - Val F1: 0.9508 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.0332 - Val accuracy: 0.9550 - Val loss: 0.1305 - Val F1: 0.9550 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.0152 - Val accuracy: 0.9614 - Val loss: 0.1371 - Val F1: 0.9614 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.0105 - Val accuracy: 0.9601 - Val loss: 0.1519 - Val F1: 0.9601 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.0060 - Val accuracy: 0.9614 - Val loss: 0.1650 - Val F1: 0.9614 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.0036 - Val accuracy: 0.9631 - Val loss: 0.1560 - Val F1: 0.9631 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0023 - Val accuracy: 0.9639 - Val loss: 0.1635 - Val F1: 0.9639 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0023 - Val accuracy: 0.9597 - Val loss: 0.2036 - Val F1: 0.9597 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0011 - Val accuracy: 0.9614 - Val loss: 0.1855 - Val F1: 0.9614 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0013 - Val accuracy: 0.9614 - Val loss: 0.1857 - Val F1: 0.9614 - LR: 0.00e+00\n","\tBest epoch: 15 - Best val accuracy: 0.9584 - Best val loss: 0.1227 - Best val F1: 0.9585\n","\n","Source class: WAL | Domain: 20 | Accuracy: 0.3645 | Loss: 22.1604 | F1: 0.2559\n","\n","Domain: 21\n","x_syn_dom.shape: (448, 3, 128) | np.unique(y_syn_dom): [0 1 2 3]\n","x_dp_dom.shape: (159, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","x_syn_dom.shape: (392, 3, 128) | np.unique(y_syn_dom): [0 1 2 3]\n","x_dp_dom.shape: (103, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","x_df_syn.shape: (12175, 3, 128) | np.unique(y_df_syn): [0 1 2 3]\n","Training on Df plus synthetic data...\n","\tEpoch 10/100 - Train loss: 0.1068 - Val accuracy: 0.9478 - Val loss: 0.1468 - Val F1: 0.9479 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.0478 - Val accuracy: 0.9538 - Val loss: 0.1322 - Val F1: 0.9538 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.0214 - Val accuracy: 0.9588 - Val loss: 0.1365 - Val F1: 0.9588 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.0119 - Val accuracy: 0.9580 - Val loss: 0.1493 - Val F1: 0.9580 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.0097 - Val accuracy: 0.9550 - Val loss: 0.1622 - Val F1: 0.9550 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.0041 - Val accuracy: 0.9593 - Val loss: 0.1837 - Val F1: 0.9593 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0041 - Val accuracy: 0.9597 - Val loss: 0.1818 - Val F1: 0.9597 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0029 - Val accuracy: 0.9588 - Val loss: 0.1726 - Val F1: 0.9588 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0020 - Val accuracy: 0.9593 - Val loss: 0.1727 - Val F1: 0.9593 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0017 - Val accuracy: 0.9618 - Val loss: 0.1841 - Val F1: 0.9618 - LR: 0.00e+00\n","\tBest epoch: 16 - Best val accuracy: 0.9584 - Best val loss: 0.1266 - Best val F1: 0.9585\n","\n","Source class: WAL | Domain: 21 | Accuracy: 0.1942 | Loss: 25.1829 | F1: 0.1451\n","\n","Domain: 22\n","x_syn_dom.shape: (444, 3, 128) | np.unique(y_syn_dom): [0 1 2 3]\n","x_dp_dom.shape: (165, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","x_syn_dom.shape: (388, 3, 128) | np.unique(y_syn_dom): [0 1 2 3]\n","x_dp_dom.shape: (110, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","x_df_syn.shape: (12171, 3, 128) | np.unique(y_df_syn): [0 1 2 3]\n","Training on Df plus synthetic data...\n","\tEpoch 10/100 - Train loss: 0.1009 - Val accuracy: 0.9491 - Val loss: 0.1442 - Val F1: 0.9491 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.0373 - Val accuracy: 0.9555 - Val loss: 0.1321 - Val F1: 0.9555 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.0170 - Val accuracy: 0.9559 - Val loss: 0.1548 - Val F1: 0.9559 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.0088 - Val accuracy: 0.9584 - Val loss: 0.1508 - Val F1: 0.9584 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.0043 - Val accuracy: 0.9597 - Val loss: 0.1641 - Val F1: 0.9597 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.0039 - Val accuracy: 0.9631 - Val loss: 0.1735 - Val F1: 0.9631 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0028 - Val accuracy: 0.9605 - Val loss: 0.1801 - Val F1: 0.9605 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0035 - Val accuracy: 0.9601 - Val loss: 0.1862 - Val F1: 0.9601 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0011 - Val accuracy: 0.9605 - Val loss: 0.1957 - Val F1: 0.9605 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0011 - Val accuracy: 0.9627 - Val loss: 0.1940 - Val F1: 0.9627 - LR: 0.00e+00\n","\tBest epoch: 21 - Best val accuracy: 0.9576 - Best val loss: 0.1277 - Best val F1: 0.9576\n","\n","Source class: WAL | Domain: 22 | Accuracy: 0.1182 | Loss: 21.6083 | F1: 0.0254\n","\n","Domain: 23\n","x_syn_dom.shape: (448, 3, 128) | np.unique(y_syn_dom): [0 1 2 3]\n","x_dp_dom.shape: (164, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","x_syn_dom.shape: (392, 3, 128) | np.unique(y_syn_dom): [0 1 2 3]\n","x_dp_dom.shape: (108, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","x_df_syn.shape: (12175, 3, 128) | np.unique(y_df_syn): [0 1 2 3]\n","Training on Df plus synthetic data...\n","\tEpoch 10/100 - Train loss: 0.1053 - Val accuracy: 0.9559 - Val loss: 0.1329 - Val F1: 0.9559 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.0419 - Val accuracy: 0.9571 - Val loss: 0.1265 - Val F1: 0.9572 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.0191 - Val accuracy: 0.9567 - Val loss: 0.1448 - Val F1: 0.9566 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.0079 - Val accuracy: 0.9627 - Val loss: 0.1349 - Val F1: 0.9627 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.0058 - Val accuracy: 0.9605 - Val loss: 0.1512 - Val F1: 0.9605 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.0031 - Val accuracy: 0.9622 - Val loss: 0.1548 - Val F1: 0.9623 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0029 - Val accuracy: 0.9635 - Val loss: 0.1587 - Val F1: 0.9635 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0016 - Val accuracy: 0.9597 - Val loss: 0.1829 - Val F1: 0.9597 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0020 - Val accuracy: 0.9588 - Val loss: 0.1787 - Val F1: 0.9589 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0016 - Val accuracy: 0.9618 - Val loss: 0.1709 - Val F1: 0.9619 - LR: 0.00e+00\n","\tBest epoch: 22 - Best val accuracy: 0.9631 - Best val loss: 0.1217 - Best val F1: 0.9631\n","\n","Source class: WAL | Domain: 23 | Accuracy: 0.1574 | Loss: 29.9397 | F1: 0.0967\n","\n","Domain: 24\n","x_syn_dom.shape: (444, 3, 128) | np.unique(y_syn_dom): [0 1 2 3]\n","x_dp_dom.shape: (162, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","x_syn_dom.shape: (388, 3, 128) | np.unique(y_syn_dom): [0 1 2 3]\n","x_dp_dom.shape: (107, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","x_df_syn.shape: (12171, 3, 128) | np.unique(y_df_syn): [0 1 2 3]\n","Training on Df plus synthetic data...\n","\tEpoch 10/100 - Train loss: 0.0951 - Val accuracy: 0.9550 - Val loss: 0.1375 - Val F1: 0.9551 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.0430 - Val accuracy: 0.9521 - Val loss: 0.1351 - Val F1: 0.9521 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.0203 - Val accuracy: 0.9580 - Val loss: 0.1394 - Val F1: 0.9580 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.0101 - Val accuracy: 0.9605 - Val loss: 0.1545 - Val F1: 0.9605 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.0071 - Val accuracy: 0.9584 - Val loss: 0.1748 - Val F1: 0.9584 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.0040 - Val accuracy: 0.9601 - Val loss: 0.1683 - Val F1: 0.9602 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0037 - Val accuracy: 0.9584 - Val loss: 0.1886 - Val F1: 0.9584 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0037 - Val accuracy: 0.9622 - Val loss: 0.1830 - Val F1: 0.9623 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0019 - Val accuracy: 0.9618 - Val loss: 0.1847 - Val F1: 0.9618 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0015 - Val accuracy: 0.9610 - Val loss: 0.1889 - Val F1: 0.9610 - LR: 0.00e+00\n","\tBest epoch: 16 - Best val accuracy: 0.9563 - Best val loss: 0.1273 - Best val F1: 0.9563\n","\n","Source class: WAL | Domain: 24 | Accuracy: 0.3178 | Loss: 26.7792 | F1: 0.2621\n","\n","Domain: 25\n","x_syn_dom.shape: (448, 3, 128) | np.unique(y_syn_dom): [0 1 2 3]\n","x_dp_dom.shape: (166, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","x_syn_dom.shape: (392, 3, 128) | np.unique(y_syn_dom): [0 1 2 3]\n","x_dp_dom.shape: (110, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","x_df_syn.shape: (12175, 3, 128) | np.unique(y_df_syn): [0 1 2 3]\n","Training on Df plus synthetic data...\n","\tEpoch 10/100 - Train loss: 0.1030 - Val accuracy: 0.9508 - Val loss: 0.1429 - Val F1: 0.9508 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.0413 - Val accuracy: 0.9555 - Val loss: 0.1354 - Val F1: 0.9555 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.0152 - Val accuracy: 0.9538 - Val loss: 0.1592 - Val F1: 0.9538 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.0078 - Val accuracy: 0.9512 - Val loss: 0.1839 - Val F1: 0.9511 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.0053 - Val accuracy: 0.9559 - Val loss: 0.1801 - Val F1: 0.9559 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.0034 - Val accuracy: 0.9559 - Val loss: 0.1857 - Val F1: 0.9558 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0025 - Val accuracy: 0.9567 - Val loss: 0.1879 - Val F1: 0.9567 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0019 - Val accuracy: 0.9567 - Val loss: 0.2016 - Val F1: 0.9567 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0031 - Val accuracy: 0.9555 - Val loss: 0.1906 - Val F1: 0.9554 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0013 - Val accuracy: 0.9576 - Val loss: 0.2037 - Val F1: 0.9576 - LR: 0.00e+00\n","\tBest epoch: 15 - Best val accuracy: 0.9555 - Best val loss: 0.1343 - Best val F1: 0.9554\n","\n","Source class: WAL | Domain: 25 | Accuracy: 0.3727 | Loss: 41.3712 | F1: 0.2869\n","\n","Domain: 26\n","x_syn_dom.shape: (444, 3, 128) | np.unique(y_syn_dom): [0 1 2 3]\n","x_dp_dom.shape: (153, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","x_syn_dom.shape: (388, 3, 128) | np.unique(y_syn_dom): [0 1 2 3]\n","x_dp_dom.shape: (98, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","x_df_syn.shape: (12171, 3, 128) | np.unique(y_df_syn): [0 1 2 3]\n","Training on Df plus synthetic data...\n","\tEpoch 10/100 - Train loss: 0.1001 - Val accuracy: 0.9499 - Val loss: 0.1375 - Val F1: 0.9500 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.0413 - Val accuracy: 0.9576 - Val loss: 0.1193 - Val F1: 0.9576 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.0174 - Val accuracy: 0.9614 - Val loss: 0.1229 - Val F1: 0.9614 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.0090 - Val accuracy: 0.9605 - Val loss: 0.1349 - Val F1: 0.9606 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.0045 - Val accuracy: 0.9614 - Val loss: 0.1443 - Val F1: 0.9614 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.0038 - Val accuracy: 0.9571 - Val loss: 0.1700 - Val F1: 0.9572 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0026 - Val accuracy: 0.9597 - Val loss: 0.1563 - Val F1: 0.9598 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0018 - Val accuracy: 0.9588 - Val loss: 0.1538 - Val F1: 0.9589 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0015 - Val accuracy: 0.9584 - Val loss: 0.1648 - Val F1: 0.9585 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0068 - Val accuracy: 0.9610 - Val loss: 0.1707 - Val F1: 0.9610 - LR: 0.00e+00\n","\tBest epoch: 26 - Best val accuracy: 0.9614 - Best val loss: 0.1175 - Best val F1: 0.9614\n","\n","Source class: WAL | Domain: 26 | Accuracy: 0.0918 | Loss: 20.9762 | F1: 0.0519\n","\n","Domain: 27\n","x_syn_dom.shape: (444, 3, 128) | np.unique(y_syn_dom): [0 1 2 3]\n","x_dp_dom.shape: (165, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","x_syn_dom.shape: (388, 3, 128) | np.unique(y_syn_dom): [0 1 2 3]\n","x_dp_dom.shape: (110, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","x_df_syn.shape: (12171, 3, 128) | np.unique(y_df_syn): [0 1 2 3]\n","Training on Df plus synthetic data...\n","\tEpoch 10/100 - Train loss: 0.0925 - Val accuracy: 0.9516 - Val loss: 0.1368 - Val F1: 0.9517 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.0423 - Val accuracy: 0.9563 - Val loss: 0.1461 - Val F1: 0.9563 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.0169 - Val accuracy: 0.9550 - Val loss: 0.1647 - Val F1: 0.9551 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.0116 - Val accuracy: 0.9584 - Val loss: 0.1863 - Val F1: 0.9585 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.0070 - Val accuracy: 0.9588 - Val loss: 0.1809 - Val F1: 0.9589 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.0042 - Val accuracy: 0.9588 - Val loss: 0.1880 - Val F1: 0.9589 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0020 - Val accuracy: 0.9597 - Val loss: 0.1959 - Val F1: 0.9598 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0021 - Val accuracy: 0.9584 - Val loss: 0.2215 - Val F1: 0.9585 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0019 - Val accuracy: 0.9618 - Val loss: 0.2081 - Val F1: 0.9618 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0011 - Val accuracy: 0.9601 - Val loss: 0.2110 - Val F1: 0.9602 - LR: 0.00e+00\n","\tBest epoch: 16 - Best val accuracy: 0.9563 - Best val loss: 0.1342 - Best val F1: 0.9564\n","\n","Source class: WAL | Domain: 27 | Accuracy: 0.3636 | Loss: 19.6166 | F1: 0.2039\n","\n","Domain: 28\n","x_syn_dom.shape: (444, 3, 128) | np.unique(y_syn_dom): [0 1 2 3]\n","x_dp_dom.shape: (153, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","x_syn_dom.shape: (388, 3, 128) | np.unique(y_syn_dom): [0 1 2 3]\n","x_dp_dom.shape: (98, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","x_df_syn.shape: (12171, 3, 128) | np.unique(y_df_syn): [0 1 2 3]\n","Training on Df plus synthetic data...\n","\tEpoch 10/100 - Train loss: 0.1089 - Val accuracy: 0.9444 - Val loss: 0.1547 - Val F1: 0.9445 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.0475 - Val accuracy: 0.9546 - Val loss: 0.1299 - Val F1: 0.9547 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.0213 - Val accuracy: 0.9563 - Val loss: 0.1339 - Val F1: 0.9563 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.0108 - Val accuracy: 0.9550 - Val loss: 0.1680 - Val F1: 0.9549 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.0077 - Val accuracy: 0.9601 - Val loss: 0.1398 - Val F1: 0.9602 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.0045 - Val accuracy: 0.9576 - Val loss: 0.1830 - Val F1: 0.9576 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0030 - Val accuracy: 0.9605 - Val loss: 0.1676 - Val F1: 0.9606 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0038 - Val accuracy: 0.9597 - Val loss: 0.1744 - Val F1: 0.9597 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0029 - Val accuracy: 0.9593 - Val loss: 0.1661 - Val F1: 0.9593 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0017 - Val accuracy: 0.9614 - Val loss: 0.1628 - Val F1: 0.9614 - LR: 0.00e+00\n","\tBest epoch: 24 - Best val accuracy: 0.9584 - Best val loss: 0.1222 - Best val F1: 0.9585\n","\n","Source class: WAL | Domain: 28 | Accuracy: 0.2857 | Loss: 27.9966 | F1: 0.1270\n","\n","Domain: 29\n","x_syn_dom.shape: (444, 3, 128) | np.unique(y_syn_dom): [0 1 2 3]\n","x_dp_dom.shape: (153, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","x_syn_dom.shape: (388, 3, 128) | np.unique(y_syn_dom): [0 1 2 3]\n","x_dp_dom.shape: (98, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","x_df_syn.shape: (12171, 3, 128) | np.unique(y_df_syn): [0 1 2 3]\n","Training on Df plus synthetic data...\n","\tEpoch 10/100 - Train loss: 0.1111 - Val accuracy: 0.9431 - Val loss: 0.1504 - Val F1: 0.9432 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.0487 - Val accuracy: 0.9538 - Val loss: 0.1329 - Val F1: 0.9538 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.0205 - Val accuracy: 0.9571 - Val loss: 0.1411 - Val F1: 0.9572 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.0128 - Val accuracy: 0.9639 - Val loss: 0.1352 - Val F1: 0.9639 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.0075 - Val accuracy: 0.9563 - Val loss: 0.1677 - Val F1: 0.9564 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.0050 - Val accuracy: 0.9610 - Val loss: 0.1632 - Val F1: 0.9610 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0048 - Val accuracy: 0.9618 - Val loss: 0.1610 - Val F1: 0.9618 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0022 - Val accuracy: 0.9618 - Val loss: 0.1658 - Val F1: 0.9618 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0024 - Val accuracy: 0.9635 - Val loss: 0.1678 - Val F1: 0.9635 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0021 - Val accuracy: 0.9622 - Val loss: 0.1759 - Val F1: 0.9623 - LR: 0.00e+00\n","\tBest epoch: 22 - Best val accuracy: 0.9563 - Best val loss: 0.1284 - Best val F1: 0.9563\n","\n","Source class: WAL | Domain: 29 | Accuracy: 0.2755 | Loss: 16.2276 | F1: 0.2499\n","\n","Domain: 30\n","x_syn_dom.shape: (444, 3, 128) | np.unique(y_syn_dom): [0 1 2 3]\n","x_dp_dom.shape: (161, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","x_syn_dom.shape: (388, 3, 128) | np.unique(y_syn_dom): [0 1 2 3]\n","x_dp_dom.shape: (106, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","x_df_syn.shape: (12171, 3, 128) | np.unique(y_df_syn): [0 1 2 3]\n","Training on Df plus synthetic data...\n","\tEpoch 10/100 - Train loss: 0.1052 - Val accuracy: 0.9533 - Val loss: 0.1485 - Val F1: 0.9533 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.0475 - Val accuracy: 0.9605 - Val loss: 0.1296 - Val F1: 0.9606 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.0228 - Val accuracy: 0.9605 - Val loss: 0.1387 - Val F1: 0.9606 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.0178 - Val accuracy: 0.9588 - Val loss: 0.1412 - Val F1: 0.9589 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.0082 - Val accuracy: 0.9610 - Val loss: 0.1508 - Val F1: 0.9610 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.0049 - Val accuracy: 0.9618 - Val loss: 0.1570 - Val F1: 0.9618 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0034 - Val accuracy: 0.9618 - Val loss: 0.1586 - Val F1: 0.9618 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0028 - Val accuracy: 0.9601 - Val loss: 0.1661 - Val F1: 0.9601 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0021 - Val accuracy: 0.9639 - Val loss: 0.1738 - Val F1: 0.9639 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0020 - Val accuracy: 0.9627 - Val loss: 0.1772 - Val F1: 0.9627 - LR: 0.00e+00\n","\tBest epoch: 29 - Best val accuracy: 0.9610 - Best val loss: 0.1234 - Best val F1: 0.9610\n","\n","Source class: WAL | Domain: 30 | Accuracy: 0.3113 | Loss: 12.8764 | F1: 0.2297\n","\n","Domain: 31\n","x_syn_dom.shape: (444, 3, 128) | np.unique(y_syn_dom): [0 1 2 3]\n","x_dp_dom.shape: (154, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","x_syn_dom.shape: (388, 3, 128) | np.unique(y_syn_dom): [0 1 2 3]\n","x_dp_dom.shape: (99, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","x_df_syn.shape: (12171, 3, 128) | np.unique(y_df_syn): [0 1 2 3]\n","Training on Df plus synthetic data...\n","\tEpoch 10/100 - Train loss: 0.0947 - Val accuracy: 0.9512 - Val loss: 0.1446 - Val F1: 0.9513 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.0478 - Val accuracy: 0.9525 - Val loss: 0.1428 - Val F1: 0.9526 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.0223 - Val accuracy: 0.9525 - Val loss: 0.1426 - Val F1: 0.9525 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.0133 - Val accuracy: 0.9546 - Val loss: 0.1749 - Val F1: 0.9546 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.0068 - Val accuracy: 0.9529 - Val loss: 0.2042 - Val F1: 0.9530 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.0041 - Val accuracy: 0.9538 - Val loss: 0.1862 - Val F1: 0.9538 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0041 - Val accuracy: 0.9555 - Val loss: 0.1898 - Val F1: 0.9555 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0024 - Val accuracy: 0.9538 - Val loss: 0.2016 - Val F1: 0.9538 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0018 - Val accuracy: 0.9550 - Val loss: 0.2049 - Val F1: 0.9550 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0027 - Val accuracy: 0.9550 - Val loss: 0.2050 - Val F1: 0.9550 - LR: 0.00e+00\n","\tBest epoch: 21 - Best val accuracy: 0.9508 - Best val loss: 0.1335 - Best val F1: 0.9508\n","\n","Source class: WAL | Domain: 31 | Accuracy: 0.3434 | Loss: 24.7707 | F1: 0.2611\n","\n","Domain: 32\n","x_syn_dom.shape: (444, 3, 128) | np.unique(y_syn_dom): [0 1 2 3]\n","x_dp_dom.shape: (163, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","x_syn_dom.shape: (388, 3, 128) | np.unique(y_syn_dom): [0 1 2 3]\n","x_dp_dom.shape: (108, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","x_df_syn.shape: (12171, 3, 128) | np.unique(y_df_syn): [0 1 2 3]\n","Training on Df plus synthetic data...\n","\tEpoch 10/100 - Train loss: 0.0934 - Val accuracy: 0.9504 - Val loss: 0.1362 - Val F1: 0.9504 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.0378 - Val accuracy: 0.9580 - Val loss: 0.1380 - Val F1: 0.9580 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.0172 - Val accuracy: 0.9576 - Val loss: 0.1436 - Val F1: 0.9576 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.0095 - Val accuracy: 0.9614 - Val loss: 0.1355 - Val F1: 0.9614 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.0048 - Val accuracy: 0.9593 - Val loss: 0.1532 - Val F1: 0.9593 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.0040 - Val accuracy: 0.9588 - Val loss: 0.1703 - Val F1: 0.9589 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0032 - Val accuracy: 0.9618 - Val loss: 0.1563 - Val F1: 0.9618 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0030 - Val accuracy: 0.9622 - Val loss: 0.1707 - Val F1: 0.9623 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0016 - Val accuracy: 0.9631 - Val loss: 0.1668 - Val F1: 0.9631 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0011 - Val accuracy: 0.9605 - Val loss: 0.1693 - Val F1: 0.9606 - LR: 0.00e+00\n","\tBest epoch: 27 - Best val accuracy: 0.9588 - Best val loss: 0.1200 - Best val F1: 0.9588\n","\n","Source class: WAL | Domain: 32 | Accuracy: 0.1296 | Loss: 30.2372 | F1: 0.0440\n","\n","Domain: 33\n","x_syn_dom.shape: (448, 3, 128) | np.unique(y_syn_dom): [0 1 2 3]\n","x_dp_dom.shape: (156, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","x_syn_dom.shape: (392, 3, 128) | np.unique(y_syn_dom): [0 1 2 3]\n","x_dp_dom.shape: (100, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","x_df_syn.shape: (12175, 3, 128) | np.unique(y_df_syn): [0 1 2 3]\n","Training on Df plus synthetic data...\n","\tEpoch 10/100 - Train loss: 0.0949 - Val accuracy: 0.9567 - Val loss: 0.1234 - Val F1: 0.9568 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.0390 - Val accuracy: 0.9588 - Val loss: 0.1210 - Val F1: 0.9589 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.0177 - Val accuracy: 0.9618 - Val loss: 0.1188 - Val F1: 0.9618 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.0075 - Val accuracy: 0.9635 - Val loss: 0.1258 - Val F1: 0.9635 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.0068 - Val accuracy: 0.9639 - Val loss: 0.1427 - Val F1: 0.9640 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.0038 - Val accuracy: 0.9665 - Val loss: 0.1360 - Val F1: 0.9665 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0022 - Val accuracy: 0.9652 - Val loss: 0.1474 - Val F1: 0.9653 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0018 - Val accuracy: 0.9631 - Val loss: 0.1709 - Val F1: 0.9631 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0012 - Val accuracy: 0.9644 - Val loss: 0.1655 - Val F1: 0.9644 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0012 - Val accuracy: 0.9648 - Val loss: 0.1557 - Val F1: 0.9648 - LR: 0.00e+00\n","\tBest epoch: 18 - Best val accuracy: 0.9627 - Best val loss: 0.1129 - Best val F1: 0.9627\n","\n","Source class: WAL | Domain: 33 | Accuracy: 0.0700 | Loss: 26.8997 | F1: 0.0092\n","\n","Domain: 34\n","x_syn_dom.shape: (448, 3, 128) | np.unique(y_syn_dom): [0 1 2 3]\n","x_dp_dom.shape: (161, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","x_syn_dom.shape: (392, 3, 128) | np.unique(y_syn_dom): [0 1 2 3]\n","x_dp_dom.shape: (105, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","x_df_syn.shape: (12175, 3, 128) | np.unique(y_df_syn): [0 1 2 3]\n","Training on Df plus synthetic data...\n","\tEpoch 10/100 - Train loss: 0.0976 - Val accuracy: 0.9491 - Val loss: 0.1403 - Val F1: 0.9492 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.0450 - Val accuracy: 0.9563 - Val loss: 0.1262 - Val F1: 0.9564 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.0265 - Val accuracy: 0.9571 - Val loss: 0.1305 - Val F1: 0.9572 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.0098 - Val accuracy: 0.9601 - Val loss: 0.1335 - Val F1: 0.9602 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.0087 - Val accuracy: 0.9601 - Val loss: 0.1730 - Val F1: 0.9602 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.0033 - Val accuracy: 0.9588 - Val loss: 0.1543 - Val F1: 0.9589 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0023 - Val accuracy: 0.9610 - Val loss: 0.1612 - Val F1: 0.9610 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0019 - Val accuracy: 0.9614 - Val loss: 0.1539 - Val F1: 0.9614 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0018 - Val accuracy: 0.9635 - Val loss: 0.1516 - Val F1: 0.9635 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0013 - Val accuracy: 0.9618 - Val loss: 0.1603 - Val F1: 0.9619 - LR: 0.00e+00\n","\tBest epoch: 27 - Best val accuracy: 0.9593 - Best val loss: 0.1231 - Best val F1: 0.9593\n","\n","Source class: WAL | Domain: 34 | Accuracy: 0.6381 | Loss: 4.7572 | F1: 0.6444\n","\n","Domain: 35\n","x_syn_dom.shape: (444, 3, 128) | np.unique(y_syn_dom): [0 1 2 3]\n","x_dp_dom.shape: (159, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","x_syn_dom.shape: (388, 3, 128) | np.unique(y_syn_dom): [0 1 2 3]\n","x_dp_dom.shape: (104, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","x_df_syn.shape: (12171, 3, 128) | np.unique(y_df_syn): [0 1 2 3]\n","Training on Df plus synthetic data...\n","\tEpoch 10/100 - Train loss: 0.0907 - Val accuracy: 0.9491 - Val loss: 0.1425 - Val F1: 0.9491 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.0381 - Val accuracy: 0.9555 - Val loss: 0.1371 - Val F1: 0.9555 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.0155 - Val accuracy: 0.9550 - Val loss: 0.1644 - Val F1: 0.9551 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.0069 - Val accuracy: 0.9563 - Val loss: 0.1698 - Val F1: 0.9563 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.0057 - Val accuracy: 0.9563 - Val loss: 0.1634 - Val F1: 0.9563 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.0035 - Val accuracy: 0.9605 - Val loss: 0.1930 - Val F1: 0.9605 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0024 - Val accuracy: 0.9605 - Val loss: 0.2051 - Val F1: 0.9606 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0014 - Val accuracy: 0.9584 - Val loss: 0.2085 - Val F1: 0.9585 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0017 - Val accuracy: 0.9601 - Val loss: 0.2049 - Val F1: 0.9602 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0009 - Val accuracy: 0.9601 - Val loss: 0.1929 - Val F1: 0.9602 - LR: 0.00e+00\n","\tBest epoch: 16 - Best val accuracy: 0.9546 - Best val loss: 0.1299 - Best val F1: 0.9546\n","\n","Source class: WAL | Domain: 35 | Accuracy: 0.1250 | Loss: 31.3120 | F1: 0.0278\n","\n","Domain: 36\n","x_syn_dom.shape: (448, 3, 128) | np.unique(y_syn_dom): [0 1 2 3]\n","x_dp_dom.shape: (155, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","x_syn_dom.shape: (392, 3, 128) | np.unique(y_syn_dom): [0 1 2 3]\n","x_dp_dom.shape: (99, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","x_df_syn.shape: (12175, 3, 128) | np.unique(y_df_syn): [0 1 2 3]\n","Training on Df plus synthetic data...\n","\tEpoch 10/100 - Train loss: 0.0934 - Val accuracy: 0.9533 - Val loss: 0.1308 - Val F1: 0.9534 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.0447 - Val accuracy: 0.9555 - Val loss: 0.1426 - Val F1: 0.9555 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.0190 - Val accuracy: 0.9588 - Val loss: 0.1377 - Val F1: 0.9589 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.0117 - Val accuracy: 0.9576 - Val loss: 0.1605 - Val F1: 0.9576 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.0052 - Val accuracy: 0.9610 - Val loss: 0.1782 - Val F1: 0.9610 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.0036 - Val accuracy: 0.9593 - Val loss: 0.1639 - Val F1: 0.9593 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0041 - Val accuracy: 0.9601 - Val loss: 0.1748 - Val F1: 0.9602 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0034 - Val accuracy: 0.9605 - Val loss: 0.1807 - Val F1: 0.9606 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0017 - Val accuracy: 0.9601 - Val loss: 0.1855 - Val F1: 0.9602 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0015 - Val accuracy: 0.9584 - Val loss: 0.1838 - Val F1: 0.9585 - LR: 0.00e+00\n","\tBest epoch: 11 - Best val accuracy: 0.9529 - Best val loss: 0.1246 - Best val F1: 0.9529\n","\n","Source class: WAL | Domain: 36 | Accuracy: 0.1818 | Loss: 22.0412 | F1: 0.1623\n","\n","Domain: 37\n","x_syn_dom.shape: (448, 3, 128) | np.unique(y_syn_dom): [0 1 2 3]\n","x_dp_dom.shape: (154, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","x_syn_dom.shape: (392, 3, 128) | np.unique(y_syn_dom): [0 1 2 3]\n","x_dp_dom.shape: (98, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","x_df_syn.shape: (12175, 3, 128) | np.unique(y_df_syn): [0 1 2 3]\n","Training on Df plus synthetic data...\n","\tEpoch 10/100 - Train loss: 0.0954 - Val accuracy: 0.9533 - Val loss: 0.1330 - Val F1: 0.9534 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.0358 - Val accuracy: 0.9584 - Val loss: 0.1343 - Val F1: 0.9584 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.0178 - Val accuracy: 0.9605 - Val loss: 0.1369 - Val F1: 0.9605 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.0090 - Val accuracy: 0.9618 - Val loss: 0.1473 - Val F1: 0.9619 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.0050 - Val accuracy: 0.9618 - Val loss: 0.1546 - Val F1: 0.9618 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.0055 - Val accuracy: 0.9635 - Val loss: 0.1569 - Val F1: 0.9635 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0019 - Val accuracy: 0.9631 - Val loss: 0.1700 - Val F1: 0.9631 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0015 - Val accuracy: 0.9618 - Val loss: 0.1751 - Val F1: 0.9618 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0029 - Val accuracy: 0.9610 - Val loss: 0.1972 - Val F1: 0.9610 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0011 - Val accuracy: 0.9627 - Val loss: 0.1744 - Val F1: 0.9627 - LR: 0.00e+00\n","\tBest epoch: 21 - Best val accuracy: 0.9618 - Best val loss: 0.1198 - Best val F1: 0.9618\n","\n","Source class: WAL | Domain: 37 | Accuracy: 0.0918 | Loss: 32.4497 | F1: 0.0321\n","\n","Domain: 38\n","x_syn_dom.shape: (444, 3, 128) | np.unique(y_syn_dom): [0 1 2 3]\n","x_dp_dom.shape: (158, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","x_syn_dom.shape: (388, 3, 128) | np.unique(y_syn_dom): [0 1 2 3]\n","x_dp_dom.shape: (103, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","x_df_syn.shape: (12171, 3, 128) | np.unique(y_df_syn): [0 1 2 3]\n","Training on Df plus synthetic data...\n","\tEpoch 10/100 - Train loss: 0.0951 - Val accuracy: 0.9538 - Val loss: 0.1334 - Val F1: 0.9538 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.0372 - Val accuracy: 0.9580 - Val loss: 0.1378 - Val F1: 0.9580 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.0148 - Val accuracy: 0.9584 - Val loss: 0.1505 - Val F1: 0.9584 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.0087 - Val accuracy: 0.9584 - Val loss: 0.1635 - Val F1: 0.9584 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.0061 - Val accuracy: 0.9610 - Val loss: 0.1669 - Val F1: 0.9610 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.0035 - Val accuracy: 0.9610 - Val loss: 0.1885 - Val F1: 0.9610 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0025 - Val accuracy: 0.9610 - Val loss: 0.1808 - Val F1: 0.9610 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0027 - Val accuracy: 0.9614 - Val loss: 0.1849 - Val F1: 0.9614 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0013 - Val accuracy: 0.9627 - Val loss: 0.1902 - Val F1: 0.9627 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0014 - Val accuracy: 0.9639 - Val loss: 0.1936 - Val F1: 0.9640 - LR: 0.00e+00\n","\tBest epoch: 14 - Best val accuracy: 0.9559 - Best val loss: 0.1277 - Best val F1: 0.9559\n","\n","Source class: WAL | Domain: 38 | Accuracy: 0.1262 | Loss: 30.8976 | F1: 0.0378\n","\n","Domain: 39\n","x_syn_dom.shape: (444, 3, 128) | np.unique(y_syn_dom): [0 1 2 3]\n","x_dp_dom.shape: (165, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","x_syn_dom.shape: (388, 3, 128) | np.unique(y_syn_dom): [0 1 2 3]\n","x_dp_dom.shape: (110, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","x_df_syn.shape: (12171, 3, 128) | np.unique(y_df_syn): [0 1 2 3]\n","Training on Df plus synthetic data...\n","\tEpoch 10/100 - Train loss: 0.0908 - Val accuracy: 0.9555 - Val loss: 0.1397 - Val F1: 0.9555 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.0363 - Val accuracy: 0.9597 - Val loss: 0.1382 - Val F1: 0.9597 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.0136 - Val accuracy: 0.9635 - Val loss: 0.1456 - Val F1: 0.9636 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.0084 - Val accuracy: 0.9618 - Val loss: 0.1616 - Val F1: 0.9619 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.0045 - Val accuracy: 0.9601 - Val loss: 0.1703 - Val F1: 0.9602 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.0029 - Val accuracy: 0.9656 - Val loss: 0.1658 - Val F1: 0.9657 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0021 - Val accuracy: 0.9669 - Val loss: 0.1695 - Val F1: 0.9669 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0035 - Val accuracy: 0.9652 - Val loss: 0.1691 - Val F1: 0.9652 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0015 - Val accuracy: 0.9669 - Val loss: 0.1820 - Val F1: 0.9669 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0012 - Val accuracy: 0.9644 - Val loss: 0.1883 - Val F1: 0.9644 - LR: 0.00e+00\n","\tBest epoch: 15 - Best val accuracy: 0.9584 - Best val loss: 0.1299 - Best val F1: 0.9585\n","\n","Source class: WAL | Domain: 39 | Accuracy: 0.1000 | Loss: 40.6168 | F1: 0.0255\n","\n","Domain: 40\n","x_syn_dom.shape: (444, 3, 128) | np.unique(y_syn_dom): [0 1 2 3]\n","x_dp_dom.shape: (155, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","x_syn_dom.shape: (388, 3, 128) | np.unique(y_syn_dom): [0 1 2 3]\n","x_dp_dom.shape: (100, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","x_df_syn.shape: (12171, 3, 128) | np.unique(y_df_syn): [0 1 2 3]\n","Training on Df plus synthetic data...\n","\tEpoch 10/100 - Train loss: 0.0984 - Val accuracy: 0.9521 - Val loss: 0.1404 - Val F1: 0.9522 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.0469 - Val accuracy: 0.9550 - Val loss: 0.1399 - Val F1: 0.9551 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.0226 - Val accuracy: 0.9584 - Val loss: 0.1439 - Val F1: 0.9584 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.0116 - Val accuracy: 0.9550 - Val loss: 0.1578 - Val F1: 0.9550 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.0075 - Val accuracy: 0.9533 - Val loss: 0.1681 - Val F1: 0.9533 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.0060 - Val accuracy: 0.9593 - Val loss: 0.1657 - Val F1: 0.9593 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0034 - Val accuracy: 0.9584 - Val loss: 0.1732 - Val F1: 0.9585 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0024 - Val accuracy: 0.9610 - Val loss: 0.1780 - Val F1: 0.9610 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0021 - Val accuracy: 0.9576 - Val loss: 0.1766 - Val F1: 0.9576 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0015 - Val accuracy: 0.9605 - Val loss: 0.1809 - Val F1: 0.9606 - LR: 0.00e+00\n","\tBest epoch: 23 - Best val accuracy: 0.9571 - Best val loss: 0.1282 - Best val F1: 0.9572\n","\n","Source class: WAL | Domain: 40 | Accuracy: 0.2400 | Loss: 19.2223 | F1: 0.1084\n","\n","Domain: 41\n","x_syn_dom.shape: (444, 3, 128) | np.unique(y_syn_dom): [0 1 2 3]\n","x_dp_dom.shape: (156, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","x_syn_dom.shape: (388, 3, 128) | np.unique(y_syn_dom): [0 1 2 3]\n","x_dp_dom.shape: (101, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","x_df_syn.shape: (12171, 3, 128) | np.unique(y_df_syn): [0 1 2 3]\n","Training on Df plus synthetic data...\n","\tEpoch 10/100 - Train loss: 0.0994 - Val accuracy: 0.9436 - Val loss: 0.1610 - Val F1: 0.9436 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.0433 - Val accuracy: 0.9499 - Val loss: 0.1447 - Val F1: 0.9499 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.0182 - Val accuracy: 0.9542 - Val loss: 0.1492 - Val F1: 0.9542 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.0094 - Val accuracy: 0.9546 - Val loss: 0.1634 - Val F1: 0.9546 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.0063 - Val accuracy: 0.9555 - Val loss: 0.1648 - Val F1: 0.9554 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.0031 - Val accuracy: 0.9559 - Val loss: 0.1770 - Val F1: 0.9559 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0041 - Val accuracy: 0.9546 - Val loss: 0.1916 - Val F1: 0.9546 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0019 - Val accuracy: 0.9576 - Val loss: 0.1874 - Val F1: 0.9575 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0021 - Val accuracy: 0.9563 - Val loss: 0.1971 - Val F1: 0.9563 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0012 - Val accuracy: 0.9593 - Val loss: 0.1869 - Val F1: 0.9593 - LR: 0.00e+00\n","\tBest epoch: 23 - Best val accuracy: 0.9546 - Best val loss: 0.1305 - Best val F1: 0.9546\n","\n","Source class: WAL | Domain: 41 | Accuracy: 0.3960 | Loss: 4.0666 | F1: 0.4589\n","\n","Domain: 42\n","x_syn_dom.shape: (448, 3, 128) | np.unique(y_syn_dom): [0 1 2 3]\n","x_dp_dom.shape: (158, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","x_syn_dom.shape: (392, 3, 128) | np.unique(y_syn_dom): [0 1 2 3]\n","x_dp_dom.shape: (102, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","x_df_syn.shape: (12175, 3, 128) | np.unique(y_df_syn): [0 1 2 3]\n","Training on Df plus synthetic data...\n","\tEpoch 10/100 - Train loss: 0.1111 - Val accuracy: 0.9499 - Val loss: 0.1527 - Val F1: 0.9499 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.0504 - Val accuracy: 0.9499 - Val loss: 0.1457 - Val F1: 0.9498 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.0224 - Val accuracy: 0.9538 - Val loss: 0.1506 - Val F1: 0.9538 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.0111 - Val accuracy: 0.9546 - Val loss: 0.1618 - Val F1: 0.9546 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.0060 - Val accuracy: 0.9559 - Val loss: 0.1815 - Val F1: 0.9559 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.0037 - Val accuracy: 0.9550 - Val loss: 0.1838 - Val F1: 0.9551 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0048 - Val accuracy: 0.9550 - Val loss: 0.1989 - Val F1: 0.9551 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0031 - Val accuracy: 0.9550 - Val loss: 0.1948 - Val F1: 0.9550 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0024 - Val accuracy: 0.9538 - Val loss: 0.2015 - Val F1: 0.9538 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0014 - Val accuracy: 0.9542 - Val loss: 0.2015 - Val F1: 0.9542 - LR: 0.00e+00\n","\tBest epoch: 22 - Best val accuracy: 0.9546 - Best val loss: 0.1351 - Best val F1: 0.9547\n","\n","Source class: WAL | Domain: 42 | Accuracy: 0.2745 | Loss: 24.1341 | F1: 0.2200\n","\n","Domain: 43\n","x_syn_dom.shape: (444, 3, 128) | np.unique(y_syn_dom): [0 1 2 3]\n","x_dp_dom.shape: (153, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","x_syn_dom.shape: (388, 3, 128) | np.unique(y_syn_dom): [0 1 2 3]\n","x_dp_dom.shape: (98, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","x_df_syn.shape: (12171, 3, 128) | np.unique(y_df_syn): [0 1 2 3]\n","Training on Df plus synthetic data...\n","\tEpoch 10/100 - Train loss: 0.1019 - Val accuracy: 0.9521 - Val loss: 0.1386 - Val F1: 0.9520 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.0435 - Val accuracy: 0.9584 - Val loss: 0.1264 - Val F1: 0.9584 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.0210 - Val accuracy: 0.9588 - Val loss: 0.1351 - Val F1: 0.9589 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.0117 - Val accuracy: 0.9593 - Val loss: 0.1494 - Val F1: 0.9592 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.0082 - Val accuracy: 0.9593 - Val loss: 0.1592 - Val F1: 0.9592 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.0070 - Val accuracy: 0.9605 - Val loss: 0.1589 - Val F1: 0.9606 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0036 - Val accuracy: 0.9593 - Val loss: 0.1759 - Val F1: 0.9592 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0027 - Val accuracy: 0.9593 - Val loss: 0.1740 - Val F1: 0.9592 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0015 - Val accuracy: 0.9614 - Val loss: 0.1729 - Val F1: 0.9613 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0018 - Val accuracy: 0.9635 - Val loss: 0.1736 - Val F1: 0.9635 - LR: 0.00e+00\n","\tBest epoch: 17 - Best val accuracy: 0.9559 - Best val loss: 0.1225 - Best val F1: 0.9559\n","\n","Source class: WAL | Domain: 43 | Accuracy: 0.1327 | Loss: 37.2796 | F1: 0.1113\n","\n","Domain: 44\n","x_syn_dom.shape: (444, 3, 128) | np.unique(y_syn_dom): [0 1 2 3]\n","x_dp_dom.shape: (153, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","x_syn_dom.shape: (388, 3, 128) | np.unique(y_syn_dom): [0 1 2 3]\n","x_dp_dom.shape: (98, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","x_df_syn.shape: (12171, 3, 128) | np.unique(y_df_syn): [0 1 2 3]\n","Training on Df plus synthetic data...\n","\tEpoch 10/100 - Train loss: 0.0988 - Val accuracy: 0.9525 - Val loss: 0.1339 - Val F1: 0.9526 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.0408 - Val accuracy: 0.9580 - Val loss: 0.1359 - Val F1: 0.9581 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.0179 - Val accuracy: 0.9555 - Val loss: 0.1560 - Val F1: 0.9555 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.0097 - Val accuracy: 0.9601 - Val loss: 0.1539 - Val F1: 0.9602 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.0073 - Val accuracy: 0.9593 - Val loss: 0.1625 - Val F1: 0.9593 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.0045 - Val accuracy: 0.9588 - Val loss: 0.1854 - Val F1: 0.9589 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0035 - Val accuracy: 0.9614 - Val loss: 0.1697 - Val F1: 0.9614 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0030 - Val accuracy: 0.9631 - Val loss: 0.1725 - Val F1: 0.9631 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0019 - Val accuracy: 0.9614 - Val loss: 0.1916 - Val F1: 0.9614 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0013 - Val accuracy: 0.9614 - Val loss: 0.1855 - Val F1: 0.9614 - LR: 0.00e+00\n","\tBest epoch: 15 - Best val accuracy: 0.9588 - Best val loss: 0.1249 - Best val F1: 0.9589\n","\n","Source class: WAL | Domain: 44 | Accuracy: 0.2245 | Loss: 15.4312 | F1: 0.2115\n","\n","Domain: 45\n","x_syn_dom.shape: (444, 3, 128) | np.unique(y_syn_dom): [0 1 2 3]\n","x_dp_dom.shape: (163, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","x_syn_dom.shape: (388, 3, 128) | np.unique(y_syn_dom): [0 1 2 3]\n","x_dp_dom.shape: (108, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","x_df_syn.shape: (12171, 3, 128) | np.unique(y_df_syn): [0 1 2 3]\n","Training on Df plus synthetic data...\n","\tEpoch 10/100 - Train loss: 0.0997 - Val accuracy: 0.9504 - Val loss: 0.1465 - Val F1: 0.9504 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.0397 - Val accuracy: 0.9567 - Val loss: 0.1412 - Val F1: 0.9568 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.0157 - Val accuracy: 0.9576 - Val loss: 0.1632 - Val F1: 0.9576 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.0097 - Val accuracy: 0.9601 - Val loss: 0.1702 - Val F1: 0.9602 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.0063 - Val accuracy: 0.9584 - Val loss: 0.1829 - Val F1: 0.9585 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.0041 - Val accuracy: 0.9601 - Val loss: 0.1847 - Val F1: 0.9602 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0035 - Val accuracy: 0.9605 - Val loss: 0.2008 - Val F1: 0.9606 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0018 - Val accuracy: 0.9580 - Val loss: 0.2087 - Val F1: 0.9580 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0013 - Val accuracy: 0.9597 - Val loss: 0.1956 - Val F1: 0.9597 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0014 - Val accuracy: 0.9588 - Val loss: 0.2138 - Val F1: 0.9589 - LR: 0.00e+00\n","\tBest epoch: 13 - Best val accuracy: 0.9542 - Best val loss: 0.1352 - Best val F1: 0.9542\n","\n","Source class: WAL | Domain: 45 | Accuracy: 0.1759 | Loss: 7.6865 | F1: 0.1332\n","\n","Domain: 46\n","x_syn_dom.shape: (448, 3, 128) | np.unique(y_syn_dom): [0 1 2 3]\n","x_dp_dom.shape: (160, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","x_syn_dom.shape: (392, 3, 128) | np.unique(y_syn_dom): [0 1 2 3]\n","x_dp_dom.shape: (104, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","x_df_syn.shape: (12175, 3, 128) | np.unique(y_df_syn): [0 1 2 3]\n","Training on Df plus synthetic data...\n","\tEpoch 10/100 - Train loss: 0.0923 - Val accuracy: 0.9521 - Val loss: 0.1393 - Val F1: 0.9519 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.0383 - Val accuracy: 0.9546 - Val loss: 0.1260 - Val F1: 0.9547 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.0161 - Val accuracy: 0.9580 - Val loss: 0.1258 - Val F1: 0.9580 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.0081 - Val accuracy: 0.9601 - Val loss: 0.1421 - Val F1: 0.9602 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.0056 - Val accuracy: 0.9639 - Val loss: 0.1339 - Val F1: 0.9639 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.0045 - Val accuracy: 0.9618 - Val loss: 0.1468 - Val F1: 0.9618 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0028 - Val accuracy: 0.9601 - Val loss: 0.1574 - Val F1: 0.9602 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0029 - Val accuracy: 0.9618 - Val loss: 0.1545 - Val F1: 0.9618 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0015 - Val accuracy: 0.9618 - Val loss: 0.1513 - Val F1: 0.9618 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0011 - Val accuracy: 0.9610 - Val loss: 0.1577 - Val F1: 0.9610 - LR: 0.00e+00\n","\tBest epoch: 18 - Best val accuracy: 0.9597 - Best val loss: 0.1142 - Best val F1: 0.9597\n","\n","Source class: WAL | Domain: 46 | Accuracy: 0.3173 | Loss: 32.2580 | F1: 0.1811\n","\n","Domain: 47\n","x_syn_dom.shape: (444, 3, 128) | np.unique(y_syn_dom): [0 1 2 3]\n","x_dp_dom.shape: (155, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","x_syn_dom.shape: (388, 3, 128) | np.unique(y_syn_dom): [0 1 2 3]\n","x_dp_dom.shape: (100, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","x_df_syn.shape: (12171, 3, 128) | np.unique(y_df_syn): [0 1 2 3]\n","Training on Df plus synthetic data...\n","\tEpoch 10/100 - Train loss: 0.1026 - Val accuracy: 0.9478 - Val loss: 0.1478 - Val F1: 0.9478 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.0402 - Val accuracy: 0.9529 - Val loss: 0.1482 - Val F1: 0.9529 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.0215 - Val accuracy: 0.9512 - Val loss: 0.1673 - Val F1: 0.9512 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.0086 - Val accuracy: 0.9529 - Val loss: 0.1808 - Val F1: 0.9529 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.0058 - Val accuracy: 0.9542 - Val loss: 0.2062 - Val F1: 0.9542 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.0036 - Val accuracy: 0.9555 - Val loss: 0.1907 - Val F1: 0.9555 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0031 - Val accuracy: 0.9576 - Val loss: 0.1930 - Val F1: 0.9576 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0020 - Val accuracy: 0.9559 - Val loss: 0.2108 - Val F1: 0.9559 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0015 - Val accuracy: 0.9550 - Val loss: 0.2196 - Val F1: 0.9551 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0020 - Val accuracy: 0.9567 - Val loss: 0.2042 - Val F1: 0.9567 - LR: 0.00e+00\n","\tBest epoch: 21 - Best val accuracy: 0.9533 - Best val loss: 0.1400 - Best val F1: 0.9534\n","\n","Source class: WAL | Domain: 47 | Accuracy: 0.1900 | Loss: 14.0788 | F1: 0.1594\n","\n","Domain: 48\n","x_syn_dom.shape: (444, 3, 128) | np.unique(y_syn_dom): [0 1 2 3]\n","x_dp_dom.shape: (159, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","x_syn_dom.shape: (388, 3, 128) | np.unique(y_syn_dom): [0 1 2 3]\n","x_dp_dom.shape: (104, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","x_df_syn.shape: (12171, 3, 128) | np.unique(y_df_syn): [0 1 2 3]\n","Training on Df plus synthetic data...\n","\tEpoch 10/100 - Train loss: 0.1079 - Val accuracy: 0.9491 - Val loss: 0.1441 - Val F1: 0.9490 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.0489 - Val accuracy: 0.9610 - Val loss: 0.1329 - Val F1: 0.9609 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.0239 - Val accuracy: 0.9580 - Val loss: 0.1390 - Val F1: 0.9580 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.0150 - Val accuracy: 0.9555 - Val loss: 0.1654 - Val F1: 0.9555 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.0078 - Val accuracy: 0.9525 - Val loss: 0.1712 - Val F1: 0.9525 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.0051 - Val accuracy: 0.9563 - Val loss: 0.1757 - Val F1: 0.9563 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0034 - Val accuracy: 0.9563 - Val loss: 0.1824 - Val F1: 0.9563 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0026 - Val accuracy: 0.9555 - Val loss: 0.1846 - Val F1: 0.9554 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0021 - Val accuracy: 0.9563 - Val loss: 0.1880 - Val F1: 0.9563 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0016 - Val accuracy: 0.9588 - Val loss: 0.1918 - Val F1: 0.9588 - LR: 0.00e+00\n","\tBest epoch: 17 - Best val accuracy: 0.9550 - Best val loss: 0.1277 - Best val F1: 0.9550\n","\n","Source class: WAL | Domain: 48 | Accuracy: 0.2981 | Loss: 8.5517 | F1: 0.1630\n","\n","Domain: 49\n","x_syn_dom.shape: (444, 3, 128) | np.unique(y_syn_dom): [0 1 2 3]\n","x_dp_dom.shape: (164, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","x_syn_dom.shape: (388, 3, 128) | np.unique(y_syn_dom): [0 1 2 3]\n","x_dp_dom.shape: (109, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","x_df_syn.shape: (12171, 3, 128) | np.unique(y_df_syn): [0 1 2 3]\n","Training on Df plus synthetic data...\n","\tEpoch 10/100 - Train loss: 0.1115 - Val accuracy: 0.9436 - Val loss: 0.1557 - Val F1: 0.9436 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.0448 - Val accuracy: 0.9516 - Val loss: 0.1521 - Val F1: 0.9516 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.0217 - Val accuracy: 0.9512 - Val loss: 0.1690 - Val F1: 0.9512 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.0109 - Val accuracy: 0.9550 - Val loss: 0.1743 - Val F1: 0.9550 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.0071 - Val accuracy: 0.9546 - Val loss: 0.1994 - Val F1: 0.9546 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.0063 - Val accuracy: 0.9538 - Val loss: 0.2014 - Val F1: 0.9538 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0031 - Val accuracy: 0.9546 - Val loss: 0.1900 - Val F1: 0.9546 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0025 - Val accuracy: 0.9571 - Val loss: 0.1977 - Val F1: 0.9571 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0021 - Val accuracy: 0.9563 - Val loss: 0.2008 - Val F1: 0.9563 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0016 - Val accuracy: 0.9546 - Val loss: 0.2157 - Val F1: 0.9546 - LR: 0.00e+00\n","\tBest epoch: 17 - Best val accuracy: 0.9508 - Best val loss: 0.1436 - Best val F1: 0.9508\n","\n","Source class: WAL | Domain: 49 | Accuracy: 0.1376 | Loss: 21.9853 | F1: 0.0601\n","\n","Domain: 50\n","x_syn_dom.shape: (444, 3, 128) | np.unique(y_syn_dom): [0 1 2 3]\n","x_dp_dom.shape: (153, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","x_syn_dom.shape: (388, 3, 128) | np.unique(y_syn_dom): [0 1 2 3]\n","x_dp_dom.shape: (98, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","x_df_syn.shape: (12171, 3, 128) | np.unique(y_df_syn): [0 1 2 3]\n","Training on Df plus synthetic data...\n","\tEpoch 10/100 - Train loss: 0.1058 - Val accuracy: 0.9504 - Val loss: 0.1490 - Val F1: 0.9505 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.0442 - Val accuracy: 0.9550 - Val loss: 0.1322 - Val F1: 0.9551 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.0205 - Val accuracy: 0.9593 - Val loss: 0.1353 - Val F1: 0.9593 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.0130 - Val accuracy: 0.9618 - Val loss: 0.1479 - Val F1: 0.9618 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.0080 - Val accuracy: 0.9610 - Val loss: 0.1512 - Val F1: 0.9609 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.0049 - Val accuracy: 0.9622 - Val loss: 0.1677 - Val F1: 0.9622 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0028 - Val accuracy: 0.9614 - Val loss: 0.1767 - Val F1: 0.9614 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0018 - Val accuracy: 0.9618 - Val loss: 0.1698 - Val F1: 0.9618 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0020 - Val accuracy: 0.9618 - Val loss: 0.1741 - Val F1: 0.9618 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0015 - Val accuracy: 0.9627 - Val loss: 0.1786 - Val F1: 0.9626 - LR: 0.00e+00\n","\tBest epoch: 27 - Best val accuracy: 0.9580 - Best val loss: 0.1301 - Best val F1: 0.9580\n","\n","Source class: WAL | Domain: 50 | Accuracy: 0.3265 | Loss: 32.9202 | F1: 0.2820\n","\n","Domain: 51\n","x_syn_dom.shape: (444, 3, 128) | np.unique(y_syn_dom): [0 1 2 3]\n","x_dp_dom.shape: (157, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","x_syn_dom.shape: (388, 3, 128) | np.unique(y_syn_dom): [0 1 2 3]\n","x_dp_dom.shape: (102, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","x_df_syn.shape: (12171, 3, 128) | np.unique(y_df_syn): [0 1 2 3]\n","Training on Df plus synthetic data...\n","\tEpoch 10/100 - Train loss: 0.1070 - Val accuracy: 0.9470 - Val loss: 0.1535 - Val F1: 0.9471 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.0433 - Val accuracy: 0.9555 - Val loss: 0.1515 - Val F1: 0.9555 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.0193 - Val accuracy: 0.9571 - Val loss: 0.1561 - Val F1: 0.9573 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.0093 - Val accuracy: 0.9559 - Val loss: 0.1767 - Val F1: 0.9559 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.0083 - Val accuracy: 0.9580 - Val loss: 0.1817 - Val F1: 0.9581 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.0032 - Val accuracy: 0.9567 - Val loss: 0.2007 - Val F1: 0.9568 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0037 - Val accuracy: 0.9571 - Val loss: 0.1916 - Val F1: 0.9572 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0016 - Val accuracy: 0.9605 - Val loss: 0.1951 - Val F1: 0.9606 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0022 - Val accuracy: 0.9601 - Val loss: 0.2119 - Val F1: 0.9602 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0016 - Val accuracy: 0.9580 - Val loss: 0.2084 - Val F1: 0.9581 - LR: 0.00e+00\n","\tBest epoch: 21 - Best val accuracy: 0.9555 - Best val loss: 0.1387 - Best val F1: 0.9555\n","\n","Source class: WAL | Domain: 51 | Accuracy: 0.4510 | Loss: 5.0211 | F1: 0.4717\n","\n","Domain: 52\n","x_syn_dom.shape: (444, 3, 128) | np.unique(y_syn_dom): [0 1 2 3]\n","x_dp_dom.shape: (153, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","x_syn_dom.shape: (388, 3, 128) | np.unique(y_syn_dom): [0 1 2 3]\n","x_dp_dom.shape: (98, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","x_df_syn.shape: (12171, 3, 128) | np.unique(y_df_syn): [0 1 2 3]\n","Training on Df plus synthetic data...\n","\tEpoch 10/100 - Train loss: 0.1002 - Val accuracy: 0.9508 - Val loss: 0.1327 - Val F1: 0.9509 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.0519 - Val accuracy: 0.9529 - Val loss: 0.1349 - Val F1: 0.9530 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.0225 - Val accuracy: 0.9529 - Val loss: 0.1441 - Val F1: 0.9530 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.0109 - Val accuracy: 0.9597 - Val loss: 0.1503 - Val F1: 0.9597 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.0059 - Val accuracy: 0.9559 - Val loss: 0.1671 - Val F1: 0.9559 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.0044 - Val accuracy: 0.9571 - Val loss: 0.1643 - Val F1: 0.9571 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0027 - Val accuracy: 0.9584 - Val loss: 0.1786 - Val F1: 0.9584 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0022 - Val accuracy: 0.9593 - Val loss: 0.1716 - Val F1: 0.9593 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0031 - Val accuracy: 0.9580 - Val loss: 0.1897 - Val F1: 0.9580 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0015 - Val accuracy: 0.9567 - Val loss: 0.1862 - Val F1: 0.9568 - LR: 0.00e+00\n","\tBest epoch: 19 - Best val accuracy: 0.9546 - Best val loss: 0.1248 - Best val F1: 0.9546\n","\n","Source class: WAL | Domain: 52 | Accuracy: 0.0408 | Loss: 28.2925 | F1: 0.0147\n","\n","Domain: 53\n","x_syn_dom.shape: (444, 3, 128) | np.unique(y_syn_dom): [0 1 2 3]\n","x_dp_dom.shape: (159, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","x_syn_dom.shape: (388, 3, 128) | np.unique(y_syn_dom): [0 1 2 3]\n","x_dp_dom.shape: (104, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","x_df_syn.shape: (12171, 3, 128) | np.unique(y_df_syn): [0 1 2 3]\n","Training on Df plus synthetic data...\n","\tEpoch 10/100 - Train loss: 0.0994 - Val accuracy: 0.9470 - Val loss: 0.1494 - Val F1: 0.9470 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.0422 - Val accuracy: 0.9525 - Val loss: 0.1402 - Val F1: 0.9525 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.0189 - Val accuracy: 0.9567 - Val loss: 0.1559 - Val F1: 0.9567 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.0101 - Val accuracy: 0.9567 - Val loss: 0.1648 - Val F1: 0.9567 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.0059 - Val accuracy: 0.9576 - Val loss: 0.1781 - Val F1: 0.9576 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.0052 - Val accuracy: 0.9597 - Val loss: 0.1715 - Val F1: 0.9597 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0036 - Val accuracy: 0.9610 - Val loss: 0.1769 - Val F1: 0.9610 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0038 - Val accuracy: 0.9571 - Val loss: 0.1911 - Val F1: 0.9571 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0020 - Val accuracy: 0.9597 - Val loss: 0.1845 - Val F1: 0.9597 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0017 - Val accuracy: 0.9614 - Val loss: 0.1890 - Val F1: 0.9614 - LR: 0.00e+00\n","\tBest epoch: 17 - Best val accuracy: 0.9491 - Best val loss: 0.1361 - Best val F1: 0.9492\n","\n","Source class: WAL | Domain: 53 | Accuracy: 0.2596 | Loss: 12.4527 | F1: 0.2016\n","\n","Domain: 54\n","x_syn_dom.shape: (444, 3, 128) | np.unique(y_syn_dom): [0 1 2 3]\n","x_dp_dom.shape: (153, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","x_syn_dom.shape: (388, 3, 128) | np.unique(y_syn_dom): [0 1 2 3]\n","x_dp_dom.shape: (98, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","x_df_syn.shape: (12171, 3, 128) | np.unique(y_df_syn): [0 1 2 3]\n","Training on Df plus synthetic data...\n","\tEpoch 10/100 - Train loss: 0.1028 - Val accuracy: 0.9427 - Val loss: 0.1701 - Val F1: 0.9428 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.0402 - Val accuracy: 0.9495 - Val loss: 0.1461 - Val F1: 0.9495 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.0201 - Val accuracy: 0.9550 - Val loss: 0.1509 - Val F1: 0.9551 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.0104 - Val accuracy: 0.9546 - Val loss: 0.1724 - Val F1: 0.9546 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.0083 - Val accuracy: 0.9525 - Val loss: 0.1869 - Val F1: 0.9525 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.0048 - Val accuracy: 0.9576 - Val loss: 0.1815 - Val F1: 0.9576 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0047 - Val accuracy: 0.9555 - Val loss: 0.2064 - Val F1: 0.9555 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0027 - Val accuracy: 0.9538 - Val loss: 0.2068 - Val F1: 0.9538 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0021 - Val accuracy: 0.9555 - Val loss: 0.2084 - Val F1: 0.9554 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0015 - Val accuracy: 0.9571 - Val loss: 0.2088 - Val F1: 0.9572 - LR: 0.00e+00\n","\tBest epoch: 16 - Best val accuracy: 0.9470 - Best val loss: 0.1379 - Best val F1: 0.9471\n","\n","Source class: WAL | Domain: 54 | Accuracy: 0.3265 | Loss: 24.5869 | F1: 0.2825\n","\n","Domain: 55\n","x_syn_dom.shape: (444, 3, 128) | np.unique(y_syn_dom): [0 1 2 3]\n","x_dp_dom.shape: (160, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","x_syn_dom.shape: (388, 3, 128) | np.unique(y_syn_dom): [0 1 2 3]\n","x_dp_dom.shape: (105, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","x_df_syn.shape: (12171, 3, 128) | np.unique(y_df_syn): [0 1 2 3]\n","Training on Df plus synthetic data...\n","\tEpoch 10/100 - Train loss: 0.0925 - Val accuracy: 0.9465 - Val loss: 0.1520 - Val F1: 0.9465 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.0337 - Val accuracy: 0.9504 - Val loss: 0.1696 - Val F1: 0.9504 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.0184 - Val accuracy: 0.9525 - Val loss: 0.1863 - Val F1: 0.9526 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.0072 - Val accuracy: 0.9546 - Val loss: 0.1854 - Val F1: 0.9546 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.0066 - Val accuracy: 0.9571 - Val loss: 0.1943 - Val F1: 0.9572 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.0032 - Val accuracy: 0.9538 - Val loss: 0.2195 - Val F1: 0.9538 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0040 - Val accuracy: 0.9588 - Val loss: 0.2089 - Val F1: 0.9588 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0025 - Val accuracy: 0.9555 - Val loss: 0.2083 - Val F1: 0.9554 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0019 - Val accuracy: 0.9559 - Val loss: 0.2305 - Val F1: 0.9559 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0010 - Val accuracy: 0.9584 - Val loss: 0.2288 - Val F1: 0.9584 - LR: 0.00e+00\n","\tBest epoch: 13 - Best val accuracy: 0.9521 - Best val loss: 0.1441 - Best val F1: 0.9521\n","\n","Source class: WAL | Domain: 55 | Accuracy: 0.4381 | Loss: 33.8433 | F1: 0.3016\n","\n","Domain: 56\n","x_syn_dom.shape: (444, 3, 128) | np.unique(y_syn_dom): [0 1 2 3]\n","x_dp_dom.shape: (153, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","x_syn_dom.shape: (388, 3, 128) | np.unique(y_syn_dom): [0 1 2 3]\n","x_dp_dom.shape: (98, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","x_df_syn.shape: (12171, 3, 128) | np.unique(y_df_syn): [0 1 2 3]\n","Training on Df plus synthetic data...\n","\tEpoch 10/100 - Train loss: 0.0991 - Val accuracy: 0.9385 - Val loss: 0.2072 - Val F1: 0.9387 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.0427 - Val accuracy: 0.9521 - Val loss: 0.1411 - Val F1: 0.9521 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.0200 - Val accuracy: 0.9580 - Val loss: 0.1411 - Val F1: 0.9580 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.0087 - Val accuracy: 0.9550 - Val loss: 0.1751 - Val F1: 0.9551 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.0051 - Val accuracy: 0.9559 - Val loss: 0.1788 - Val F1: 0.9559 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.0040 - Val accuracy: 0.9550 - Val loss: 0.1858 - Val F1: 0.9550 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0031 - Val accuracy: 0.9580 - Val loss: 0.1862 - Val F1: 0.9580 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0024 - Val accuracy: 0.9584 - Val loss: 0.1982 - Val F1: 0.9585 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0018 - Val accuracy: 0.9580 - Val loss: 0.2037 - Val F1: 0.9580 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0014 - Val accuracy: 0.9576 - Val loss: 0.2066 - Val F1: 0.9576 - LR: 0.00e+00\n","\tBest epoch: 21 - Best val accuracy: 0.9550 - Best val loss: 0.1312 - Best val F1: 0.9550\n","\n","Source class: WAL | Domain: 56 | Accuracy: 0.2857 | Loss: 22.4347 | F1: 0.1270\n","\n","Domain: 57\n","x_syn_dom.shape: (444, 3, 128) | np.unique(y_syn_dom): [0 1 2 3]\n","x_dp_dom.shape: (153, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","x_syn_dom.shape: (388, 3, 128) | np.unique(y_syn_dom): [0 1 2 3]\n","x_dp_dom.shape: (98, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","x_df_syn.shape: (12171, 3, 128) | np.unique(y_df_syn): [0 1 2 3]\n","Training on Df plus synthetic data...\n","\tEpoch 10/100 - Train loss: 0.0999 - Val accuracy: 0.9538 - Val loss: 0.1527 - Val F1: 0.9538 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.0368 - Val accuracy: 0.9550 - Val loss: 0.1251 - Val F1: 0.9551 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.0199 - Val accuracy: 0.9563 - Val loss: 0.1392 - Val F1: 0.9563 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.0106 - Val accuracy: 0.9559 - Val loss: 0.1671 - Val F1: 0.9559 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.0066 - Val accuracy: 0.9576 - Val loss: 0.1685 - Val F1: 0.9576 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.0043 - Val accuracy: 0.9580 - Val loss: 0.1775 - Val F1: 0.9580 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0023 - Val accuracy: 0.9593 - Val loss: 0.1885 - Val F1: 0.9593 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0017 - Val accuracy: 0.9601 - Val loss: 0.2033 - Val F1: 0.9602 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0013 - Val accuracy: 0.9597 - Val loss: 0.1872 - Val F1: 0.9597 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0015 - Val accuracy: 0.9584 - Val loss: 0.1861 - Val F1: 0.9584 - LR: 0.00e+00\n","\tBest epoch: 20 - Best val accuracy: 0.9550 - Best val loss: 0.1251 - Best val F1: 0.9551\n","\n","Source class: WAL | Domain: 57 | Accuracy: 0.2857 | Loss: 13.0079 | F1: 0.1368\n","\n","Domain: 58\n","x_syn_dom.shape: (444, 3, 128) | np.unique(y_syn_dom): [0 1 2 3]\n","x_dp_dom.shape: (149, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","x_syn_dom.shape: (388, 3, 128) | np.unique(y_syn_dom): [0 1 2 3]\n","x_dp_dom.shape: (94, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","x_df_syn.shape: (12171, 3, 128) | np.unique(y_df_syn): [0 1 2 3]\n","Training on Df plus synthetic data...\n","\tEpoch 10/100 - Train loss: 0.1052 - Val accuracy: 0.9499 - Val loss: 0.1442 - Val F1: 0.9500 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.0498 - Val accuracy: 0.9542 - Val loss: 0.1309 - Val F1: 0.9542 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.0206 - Val accuracy: 0.9567 - Val loss: 0.1533 - Val F1: 0.9568 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.0110 - Val accuracy: 0.9576 - Val loss: 0.1709 - Val F1: 0.9576 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.0060 - Val accuracy: 0.9576 - Val loss: 0.1748 - Val F1: 0.9576 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.0043 - Val accuracy: 0.9597 - Val loss: 0.1792 - Val F1: 0.9598 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0042 - Val accuracy: 0.9597 - Val loss: 0.1786 - Val F1: 0.9597 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0028 - Val accuracy: 0.9584 - Val loss: 0.1914 - Val F1: 0.9585 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0024 - Val accuracy: 0.9597 - Val loss: 0.1860 - Val F1: 0.9597 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0015 - Val accuracy: 0.9588 - Val loss: 0.2032 - Val F1: 0.9589 - LR: 0.00e+00\n","\tBest epoch: 19 - Best val accuracy: 0.9588 - Best val loss: 0.1246 - Best val F1: 0.9589\n","\n","Source class: WAL | Domain: 58 | Accuracy: 0.3723 | Loss: 5.5627 | F1: 0.2883\n","\n","Domain: 59\n","x_syn_dom.shape: (444, 3, 128) | np.unique(y_syn_dom): [0 1 2 3]\n","x_dp_dom.shape: (154, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","x_syn_dom.shape: (388, 3, 128) | np.unique(y_syn_dom): [0 1 2 3]\n","x_dp_dom.shape: (99, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","x_df_syn.shape: (12171, 3, 128) | np.unique(y_df_syn): [0 1 2 3]\n","Training on Df plus synthetic data...\n","\tEpoch 10/100 - Train loss: 0.1034 - Val accuracy: 0.9512 - Val loss: 0.1345 - Val F1: 0.9512 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.0469 - Val accuracy: 0.9470 - Val loss: 0.1388 - Val F1: 0.9470 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.0231 - Val accuracy: 0.9546 - Val loss: 0.1390 - Val F1: 0.9546 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.0117 - Val accuracy: 0.9516 - Val loss: 0.1810 - Val F1: 0.9516 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.0072 - Val accuracy: 0.9563 - Val loss: 0.1856 - Val F1: 0.9563 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.0047 - Val accuracy: 0.9538 - Val loss: 0.1745 - Val F1: 0.9538 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0036 - Val accuracy: 0.9555 - Val loss: 0.1820 - Val F1: 0.9555 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0029 - Val accuracy: 0.9584 - Val loss: 0.1762 - Val F1: 0.9584 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0025 - Val accuracy: 0.9563 - Val loss: 0.1796 - Val F1: 0.9563 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0013 - Val accuracy: 0.9559 - Val loss: 0.1913 - Val F1: 0.9559 - LR: 0.00e+00\n","\tBest epoch: 19 - Best val accuracy: 0.9571 - Best val loss: 0.1276 - Best val F1: 0.9572\n","\n","Source class: WAL | Domain: 59 | Accuracy: 0.3333 | Loss: 16.8316 | F1: 0.1997\n","\n","Domain: 60\n","x_syn_dom.shape: (444, 3, 128) | np.unique(y_syn_dom): [0 1 2 3]\n","x_dp_dom.shape: (158, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","x_syn_dom.shape: (388, 3, 128) | np.unique(y_syn_dom): [0 1 2 3]\n","x_dp_dom.shape: (103, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","x_df_syn.shape: (12171, 3, 128) | np.unique(y_df_syn): [0 1 2 3]\n","Training on Df plus synthetic data...\n","\tEpoch 10/100 - Train loss: 0.0931 - Val accuracy: 0.9529 - Val loss: 0.1357 - Val F1: 0.9529 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.0390 - Val accuracy: 0.9593 - Val loss: 0.1324 - Val F1: 0.9593 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.0178 - Val accuracy: 0.9614 - Val loss: 0.1350 - Val F1: 0.9613 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.0082 - Val accuracy: 0.9597 - Val loss: 0.1461 - Val F1: 0.9597 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.0045 - Val accuracy: 0.9648 - Val loss: 0.1392 - Val F1: 0.9648 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.0048 - Val accuracy: 0.9622 - Val loss: 0.1476 - Val F1: 0.9622 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0037 - Val accuracy: 0.9605 - Val loss: 0.1538 - Val F1: 0.9605 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0019 - Val accuracy: 0.9597 - Val loss: 0.1677 - Val F1: 0.9596 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0012 - Val accuracy: 0.9618 - Val loss: 0.1674 - Val F1: 0.9618 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0011 - Val accuracy: 0.9614 - Val loss: 0.1646 - Val F1: 0.9613 - LR: 0.00e+00\n","\tBest epoch: 21 - Best val accuracy: 0.9610 - Best val loss: 0.1190 - Best val F1: 0.9610\n","\n","Source class: WAL | Domain: 60 | Accuracy: 0.3204 | Loss: 12.4069 | F1: 0.1768\n","\n","Domain: 61\n","x_syn_dom.shape: (444, 3, 128) | np.unique(y_syn_dom): [0 1 2 3]\n","x_dp_dom.shape: (158, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","x_syn_dom.shape: (388, 3, 128) | np.unique(y_syn_dom): [0 1 2 3]\n","x_dp_dom.shape: (103, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","x_df_syn.shape: (12171, 3, 128) | np.unique(y_df_syn): [0 1 2 3]\n","Training on Df plus synthetic data...\n","\tEpoch 10/100 - Train loss: 0.0974 - Val accuracy: 0.9465 - Val loss: 0.1521 - Val F1: 0.9466 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.0408 - Val accuracy: 0.9538 - Val loss: 0.1466 - Val F1: 0.9538 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.0177 - Val accuracy: 0.9580 - Val loss: 0.1457 - Val F1: 0.9580 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.0087 - Val accuracy: 0.9614 - Val loss: 0.1601 - Val F1: 0.9615 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.0043 - Val accuracy: 0.9597 - Val loss: 0.1698 - Val F1: 0.9598 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.0043 - Val accuracy: 0.9601 - Val loss: 0.1694 - Val F1: 0.9602 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0040 - Val accuracy: 0.9576 - Val loss: 0.1939 - Val F1: 0.9577 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0028 - Val accuracy: 0.9593 - Val loss: 0.1918 - Val F1: 0.9593 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0016 - Val accuracy: 0.9605 - Val loss: 0.1903 - Val F1: 0.9606 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0011 - Val accuracy: 0.9605 - Val loss: 0.1878 - Val F1: 0.9606 - LR: 0.00e+00\n","\tBest epoch: 17 - Best val accuracy: 0.9521 - Best val loss: 0.1337 - Best val F1: 0.9521\n","\n","Source class: WAL | Domain: 61 | Accuracy: 0.2816 | Loss: 22.8817 | F1: 0.1341\n","\n","Domain: 62\n","x_syn_dom.shape: (444, 3, 128) | np.unique(y_syn_dom): [0 1 2 3]\n","x_dp_dom.shape: (158, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","x_syn_dom.shape: (388, 3, 128) | np.unique(y_syn_dom): [0 1 2 3]\n","x_dp_dom.shape: (103, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","x_df_syn.shape: (12171, 3, 128) | np.unique(y_df_syn): [0 1 2 3]\n","Training on Df plus synthetic data...\n","\tEpoch 10/100 - Train loss: 0.0994 - Val accuracy: 0.9538 - Val loss: 0.1417 - Val F1: 0.9538 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.0380 - Val accuracy: 0.9580 - Val loss: 0.1283 - Val F1: 0.9580 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.0161 - Val accuracy: 0.9605 - Val loss: 0.1310 - Val F1: 0.9606 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.0083 - Val accuracy: 0.9584 - Val loss: 0.1373 - Val F1: 0.9585 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.0058 - Val accuracy: 0.9618 - Val loss: 0.1378 - Val F1: 0.9618 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.0040 - Val accuracy: 0.9593 - Val loss: 0.1610 - Val F1: 0.9593 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0025 - Val accuracy: 0.9627 - Val loss: 0.1639 - Val F1: 0.9627 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0027 - Val accuracy: 0.9610 - Val loss: 0.1822 - Val F1: 0.9610 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0016 - Val accuracy: 0.9601 - Val loss: 0.1734 - Val F1: 0.9601 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0023 - Val accuracy: 0.9618 - Val loss: 0.1652 - Val F1: 0.9618 - LR: 0.00e+00\n","\tBest epoch: 23 - Best val accuracy: 0.9597 - Best val loss: 0.1247 - Best val F1: 0.9597\n","\n","Source class: WAL | Domain: 62 | Accuracy: 0.1165 | Loss: 26.2745 | F1: 0.0243\n","\n","Domain: 63\n","x_syn_dom.shape: (444, 3, 128) | np.unique(y_syn_dom): [0 1 2 3]\n","x_dp_dom.shape: (153, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","x_syn_dom.shape: (388, 3, 128) | np.unique(y_syn_dom): [0 1 2 3]\n","x_dp_dom.shape: (98, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","x_df_syn.shape: (12171, 3, 128) | np.unique(y_df_syn): [0 1 2 3]\n","Training on Df plus synthetic data...\n","\tEpoch 10/100 - Train loss: 0.1015 - Val accuracy: 0.9525 - Val loss: 0.1355 - Val F1: 0.9525 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.0353 - Val accuracy: 0.9563 - Val loss: 0.1381 - Val F1: 0.9563 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.0145 - Val accuracy: 0.9559 - Val loss: 0.1469 - Val F1: 0.9559 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.0098 - Val accuracy: 0.9588 - Val loss: 0.1554 - Val F1: 0.9588 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.0048 - Val accuracy: 0.9610 - Val loss: 0.1754 - Val F1: 0.9609 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.0038 - Val accuracy: 0.9605 - Val loss: 0.1723 - Val F1: 0.9606 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0054 - Val accuracy: 0.9614 - Val loss: 0.2051 - Val F1: 0.9614 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0022 - Val accuracy: 0.9622 - Val loss: 0.1766 - Val F1: 0.9622 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0016 - Val accuracy: 0.9614 - Val loss: 0.1971 - Val F1: 0.9614 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0015 - Val accuracy: 0.9614 - Val loss: 0.1981 - Val F1: 0.9614 - LR: 0.00e+00\n","\tBest epoch: 14 - Best val accuracy: 0.9567 - Best val loss: 0.1246 - Best val F1: 0.9567\n","\n","Source class: WAL | Domain: 63 | Accuracy: 0.2959 | Loss: 25.1041 | F1: 0.1459\n","\n","Domain: 64\n","x_syn_dom.shape: (448, 3, 128) | np.unique(y_syn_dom): [0 1 2 3]\n","x_dp_dom.shape: (154, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","x_syn_dom.shape: (392, 3, 128) | np.unique(y_syn_dom): [0 1 2 3]\n","x_dp_dom.shape: (98, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","x_df_syn.shape: (12175, 3, 128) | np.unique(y_df_syn): [0 1 2 3]\n","Training on Df plus synthetic data...\n","\tEpoch 10/100 - Train loss: 0.1026 - Val accuracy: 0.9512 - Val loss: 0.1410 - Val F1: 0.9512 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.0400 - Val accuracy: 0.9542 - Val loss: 0.1408 - Val F1: 0.9542 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.0184 - Val accuracy: 0.9555 - Val loss: 0.1453 - Val F1: 0.9555 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.0105 - Val accuracy: 0.9559 - Val loss: 0.1618 - Val F1: 0.9558 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.0050 - Val accuracy: 0.9563 - Val loss: 0.1860 - Val F1: 0.9562 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.0050 - Val accuracy: 0.9576 - Val loss: 0.1898 - Val F1: 0.9576 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0023 - Val accuracy: 0.9559 - Val loss: 0.2022 - Val F1: 0.9559 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0022 - Val accuracy: 0.9605 - Val loss: 0.1857 - Val F1: 0.9606 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0017 - Val accuracy: 0.9588 - Val loss: 0.1994 - Val F1: 0.9589 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0018 - Val accuracy: 0.9584 - Val loss: 0.1907 - Val F1: 0.9584 - LR: 0.00e+00\n","\tBest epoch: 16 - Best val accuracy: 0.9555 - Best val loss: 0.1272 - Best val F1: 0.9555\n","\n","Source class: WAL | Domain: 64 | Accuracy: 0.3163 | Loss: 7.4101 | F1: 0.1729\n","\n","Domain: 65\n","x_syn_dom.shape: (444, 3, 128) | np.unique(y_syn_dom): [0 1 2 3]\n","x_dp_dom.shape: (161, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","x_syn_dom.shape: (388, 3, 128) | np.unique(y_syn_dom): [0 1 2 3]\n","x_dp_dom.shape: (106, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","x_df_syn.shape: (12171, 3, 128) | np.unique(y_df_syn): [0 1 2 3]\n","Training on Df plus synthetic data...\n","\tEpoch 10/100 - Train loss: 0.0957 - Val accuracy: 0.9516 - Val loss: 0.1425 - Val F1: 0.9516 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.0403 - Val accuracy: 0.9588 - Val loss: 0.1305 - Val F1: 0.9588 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.0180 - Val accuracy: 0.9605 - Val loss: 0.1468 - Val F1: 0.9606 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.0091 - Val accuracy: 0.9627 - Val loss: 0.1524 - Val F1: 0.9627 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.0053 - Val accuracy: 0.9614 - Val loss: 0.1757 - Val F1: 0.9614 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.0034 - Val accuracy: 0.9627 - Val loss: 0.1744 - Val F1: 0.9627 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0026 - Val accuracy: 0.9614 - Val loss: 0.1860 - Val F1: 0.9614 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0021 - Val accuracy: 0.9627 - Val loss: 0.1889 - Val F1: 0.9627 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0013 - Val accuracy: 0.9627 - Val loss: 0.1874 - Val F1: 0.9627 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0015 - Val accuracy: 0.9648 - Val loss: 0.1874 - Val F1: 0.9648 - LR: 0.00e+00\n","\tBest epoch: 17 - Best val accuracy: 0.9567 - Best val loss: 0.1194 - Best val F1: 0.9567\n","\n","Source class: WAL | Domain: 65 | Accuracy: 0.1415 | Loss: 23.6758 | F1: 0.0625\n","\n","Domain: 66\n","x_syn_dom.shape: (444, 3, 128) | np.unique(y_syn_dom): [0 1 2 3]\n","x_dp_dom.shape: (153, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","x_syn_dom.shape: (388, 3, 128) | np.unique(y_syn_dom): [0 1 2 3]\n","x_dp_dom.shape: (98, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","x_df_syn.shape: (12171, 3, 128) | np.unique(y_df_syn): [0 1 2 3]\n","Training on Df plus synthetic data...\n","\tEpoch 10/100 - Train loss: 0.1041 - Val accuracy: 0.9550 - Val loss: 0.1372 - Val F1: 0.9550 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.0407 - Val accuracy: 0.9550 - Val loss: 0.1514 - Val F1: 0.9551 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.0185 - Val accuracy: 0.9567 - Val loss: 0.1426 - Val F1: 0.9567 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.0128 - Val accuracy: 0.9576 - Val loss: 0.1621 - Val F1: 0.9576 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.0067 - Val accuracy: 0.9597 - Val loss: 0.1760 - Val F1: 0.9597 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.0046 - Val accuracy: 0.9588 - Val loss: 0.1825 - Val F1: 0.9589 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0034 - Val accuracy: 0.9580 - Val loss: 0.1972 - Val F1: 0.9580 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0022 - Val accuracy: 0.9563 - Val loss: 0.2021 - Val F1: 0.9564 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0018 - Val accuracy: 0.9559 - Val loss: 0.2036 - Val F1: 0.9559 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0013 - Val accuracy: 0.9584 - Val loss: 0.2133 - Val F1: 0.9585 - LR: 0.00e+00\n","\tBest epoch: 11 - Best val accuracy: 0.9571 - Best val loss: 0.1311 - Best val F1: 0.9571\n","\n","Source class: WAL | Domain: 66 | Accuracy: 0.2245 | Loss: 22.1604 | F1: 0.2073\n","\n","Domain: 67\n","x_syn_dom.shape: (444, 3, 128) | np.unique(y_syn_dom): [0 1 2 3]\n","x_dp_dom.shape: (153, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","x_syn_dom.shape: (388, 3, 128) | np.unique(y_syn_dom): [0 1 2 3]\n","x_dp_dom.shape: (98, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","x_df_syn.shape: (12171, 3, 128) | np.unique(y_df_syn): [0 1 2 3]\n","Training on Df plus synthetic data...\n","\tEpoch 10/100 - Train loss: 0.1030 - Val accuracy: 0.9516 - Val loss: 0.1444 - Val F1: 0.9517 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.0388 - Val accuracy: 0.9584 - Val loss: 0.1314 - Val F1: 0.9585 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.0179 - Val accuracy: 0.9580 - Val loss: 0.1517 - Val F1: 0.9581 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.0122 - Val accuracy: 0.9571 - Val loss: 0.1585 - Val F1: 0.9572 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.0067 - Val accuracy: 0.9584 - Val loss: 0.1564 - Val F1: 0.9585 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.0042 - Val accuracy: 0.9571 - Val loss: 0.1553 - Val F1: 0.9572 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0041 - Val accuracy: 0.9584 - Val loss: 0.1813 - Val F1: 0.9584 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0018 - Val accuracy: 0.9601 - Val loss: 0.1842 - Val F1: 0.9602 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0013 - Val accuracy: 0.9593 - Val loss: 0.1825 - Val F1: 0.9593 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0019 - Val accuracy: 0.9576 - Val loss: 0.2034 - Val F1: 0.9576 - LR: 0.00e+00\n","\tBest epoch: 21 - Best val accuracy: 0.9563 - Best val loss: 0.1280 - Best val F1: 0.9564\n","\n","Source class: WAL | Domain: 67 | Accuracy: 0.2857 | Loss: 40.3774 | F1: 0.1270\n","\n","Domain: 68\n","x_syn_dom.shape: (444, 3, 128) | np.unique(y_syn_dom): [0 1 2 3]\n","x_dp_dom.shape: (154, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","x_syn_dom.shape: (388, 3, 128) | np.unique(y_syn_dom): [0 1 2 3]\n","x_dp_dom.shape: (99, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","x_df_syn.shape: (12171, 3, 128) | np.unique(y_df_syn): [0 1 2 3]\n","Training on Df plus synthetic data...\n","\tEpoch 10/100 - Train loss: 0.0962 - Val accuracy: 0.9482 - Val loss: 0.1454 - Val F1: 0.9484 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.0414 - Val accuracy: 0.9559 - Val loss: 0.1244 - Val F1: 0.9559 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.0187 - Val accuracy: 0.9571 - Val loss: 0.1397 - Val F1: 0.9572 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.0129 - Val accuracy: 0.9597 - Val loss: 0.1494 - Val F1: 0.9598 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.0072 - Val accuracy: 0.9593 - Val loss: 0.1547 - Val F1: 0.9593 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.0043 - Val accuracy: 0.9576 - Val loss: 0.1633 - Val F1: 0.9576 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0030 - Val accuracy: 0.9555 - Val loss: 0.1785 - Val F1: 0.9555 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0021 - Val accuracy: 0.9588 - Val loss: 0.1815 - Val F1: 0.9589 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0015 - Val accuracy: 0.9597 - Val loss: 0.1787 - Val F1: 0.9597 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0013 - Val accuracy: 0.9580 - Val loss: 0.1780 - Val F1: 0.9580 - LR: 0.00e+00\n","\tBest epoch: 20 - Best val accuracy: 0.9559 - Best val loss: 0.1244 - Best val F1: 0.9559\n","\n","Source class: WAL | Domain: 68 | Accuracy: 0.1717 | Loss: 17.1547 | F1: 0.1518\n","\n","Domain: 69\n","x_syn_dom.shape: (444, 3, 128) | np.unique(y_syn_dom): [0 1 2 3]\n","x_dp_dom.shape: (153, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","x_syn_dom.shape: (388, 3, 128) | np.unique(y_syn_dom): [0 1 2 3]\n","x_dp_dom.shape: (98, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","x_df_syn.shape: (12171, 3, 128) | np.unique(y_df_syn): [0 1 2 3]\n","Training on Df plus synthetic data...\n","\tEpoch 10/100 - Train loss: 0.1009 - Val accuracy: 0.9495 - Val loss: 0.1470 - Val F1: 0.9496 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.0401 - Val accuracy: 0.9601 - Val loss: 0.1291 - Val F1: 0.9602 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.0185 - Val accuracy: 0.9593 - Val loss: 0.1470 - Val F1: 0.9592 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.0093 - Val accuracy: 0.9618 - Val loss: 0.1519 - Val F1: 0.9619 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.0049 - Val accuracy: 0.9639 - Val loss: 0.1541 - Val F1: 0.9640 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.0045 - Val accuracy: 0.9605 - Val loss: 0.1741 - Val F1: 0.9606 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0031 - Val accuracy: 0.9635 - Val loss: 0.1738 - Val F1: 0.9635 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0040 - Val accuracy: 0.9635 - Val loss: 0.1866 - Val F1: 0.9635 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0018 - Val accuracy: 0.9644 - Val loss: 0.1819 - Val F1: 0.9644 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0016 - Val accuracy: 0.9644 - Val loss: 0.1801 - Val F1: 0.9644 - LR: 0.00e+00\n","\tBest epoch: 16 - Best val accuracy: 0.9584 - Best val loss: 0.1251 - Best val F1: 0.9584\n","\n","Source class: WAL | Domain: 69 | Accuracy: 0.2653 | Loss: 22.3632 | F1: 0.2081\n","\n","Domain: 70\n","x_syn_dom.shape: (444, 3, 128) | np.unique(y_syn_dom): [0 1 2 3]\n","x_dp_dom.shape: (153, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","x_syn_dom.shape: (388, 3, 128) | np.unique(y_syn_dom): [0 1 2 3]\n","x_dp_dom.shape: (98, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","x_df_syn.shape: (12171, 3, 128) | np.unique(y_df_syn): [0 1 2 3]\n","Training on Df plus synthetic data...\n","\tEpoch 10/100 - Train loss: 0.0962 - Val accuracy: 0.9482 - Val loss: 0.1465 - Val F1: 0.9483 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.0407 - Val accuracy: 0.9521 - Val loss: 0.1401 - Val F1: 0.9521 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.0213 - Val accuracy: 0.9533 - Val loss: 0.1500 - Val F1: 0.9534 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.0099 - Val accuracy: 0.9567 - Val loss: 0.1686 - Val F1: 0.9568 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.0064 - Val accuracy: 0.9588 - Val loss: 0.1785 - Val F1: 0.9589 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.0037 - Val accuracy: 0.9597 - Val loss: 0.1935 - Val F1: 0.9598 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0032 - Val accuracy: 0.9588 - Val loss: 0.1925 - Val F1: 0.9589 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0026 - Val accuracy: 0.9563 - Val loss: 0.2192 - Val F1: 0.9564 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0021 - Val accuracy: 0.9563 - Val loss: 0.2090 - Val F1: 0.9564 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0014 - Val accuracy: 0.9580 - Val loss: 0.2190 - Val F1: 0.9581 - LR: 0.00e+00\n","\tBest epoch: 13 - Best val accuracy: 0.9512 - Best val loss: 0.1360 - Best val F1: 0.9513\n","\n","Source class: WAL | Domain: 70 | Accuracy: 0.0918 | Loss: 11.8708 | F1: 0.0485\n","\n","Domain: 71\n","x_syn_dom.shape: (444, 3, 128) | np.unique(y_syn_dom): [0 1 2 3]\n","x_dp_dom.shape: (155, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","x_syn_dom.shape: (388, 3, 128) | np.unique(y_syn_dom): [0 1 2 3]\n","x_dp_dom.shape: (100, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","x_df_syn.shape: (12171, 3, 128) | np.unique(y_df_syn): [0 1 2 3]\n","Training on Df plus synthetic data...\n","\tEpoch 10/100 - Train loss: 0.0990 - Val accuracy: 0.9550 - Val loss: 0.1356 - Val F1: 0.9549 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.0381 - Val accuracy: 0.9563 - Val loss: 0.1388 - Val F1: 0.9563 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.0168 - Val accuracy: 0.9597 - Val loss: 0.1391 - Val F1: 0.9596 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.0088 - Val accuracy: 0.9597 - Val loss: 0.1488 - Val F1: 0.9597 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.0057 - Val accuracy: 0.9550 - Val loss: 0.1881 - Val F1: 0.9550 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.0031 - Val accuracy: 0.9601 - Val loss: 0.1728 - Val F1: 0.9602 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0021 - Val accuracy: 0.9605 - Val loss: 0.1856 - Val F1: 0.9606 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0023 - Val accuracy: 0.9618 - Val loss: 0.1884 - Val F1: 0.9618 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0014 - Val accuracy: 0.9605 - Val loss: 0.1838 - Val F1: 0.9606 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0018 - Val accuracy: 0.9622 - Val loss: 0.1893 - Val F1: 0.9623 - LR: 0.00e+00\n","\tBest epoch: 21 - Best val accuracy: 0.9571 - Best val loss: 0.1274 - Best val F1: 0.9572\n","\n","Source class: WAL | Domain: 71 | Accuracy: 0.0900 | Loss: 36.3836 | F1: 0.0149\n","\n","Domain: 72\n","x_syn_dom.shape: (444, 3, 128) | np.unique(y_syn_dom): [0 1 2 3]\n","x_dp_dom.shape: (153, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","x_syn_dom.shape: (388, 3, 128) | np.unique(y_syn_dom): [0 1 2 3]\n","x_dp_dom.shape: (98, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","x_df_syn.shape: (12171, 3, 128) | np.unique(y_df_syn): [0 1 2 3]\n","Training on Df plus synthetic data...\n","\tEpoch 10/100 - Train loss: 0.0910 - Val accuracy: 0.9512 - Val loss: 0.1333 - Val F1: 0.9513 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.0360 - Val accuracy: 0.9593 - Val loss: 0.1259 - Val F1: 0.9593 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.0170 - Val accuracy: 0.9584 - Val loss: 0.1428 - Val F1: 0.9584 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.0089 - Val accuracy: 0.9605 - Val loss: 0.1580 - Val F1: 0.9606 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.0072 - Val accuracy: 0.9601 - Val loss: 0.1601 - Val F1: 0.9602 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.0031 - Val accuracy: 0.9588 - Val loss: 0.1796 - Val F1: 0.9589 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0031 - Val accuracy: 0.9648 - Val loss: 0.1642 - Val F1: 0.9648 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0030 - Val accuracy: 0.9618 - Val loss: 0.1735 - Val F1: 0.9619 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0015 - Val accuracy: 0.9610 - Val loss: 0.1850 - Val F1: 0.9610 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0016 - Val accuracy: 0.9614 - Val loss: 0.1819 - Val F1: 0.9614 - LR: 0.00e+00\n","\tBest epoch: 16 - Best val accuracy: 0.9584 - Best val loss: 0.1198 - Best val F1: 0.9585\n","\n","Source class: WAL | Domain: 72 | Accuracy: 0.3571 | Loss: 24.5830 | F1: 0.2987\n","\n","Domain: 73\n","x_syn_dom.shape: (444, 3, 128) | np.unique(y_syn_dom): [0 1 2 3]\n","x_dp_dom.shape: (152, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","x_syn_dom.shape: (388, 3, 128) | np.unique(y_syn_dom): [0 1 2 3]\n","x_dp_dom.shape: (97, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","x_df_syn.shape: (12171, 3, 128) | np.unique(y_df_syn): [0 1 2 3]\n","Training on Df plus synthetic data...\n","\tEpoch 10/100 - Train loss: 0.0998 - Val accuracy: 0.9508 - Val loss: 0.1430 - Val F1: 0.9508 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.0394 - Val accuracy: 0.9597 - Val loss: 0.1228 - Val F1: 0.9598 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.0187 - Val accuracy: 0.9601 - Val loss: 0.1287 - Val F1: 0.9601 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.0101 - Val accuracy: 0.9635 - Val loss: 0.1357 - Val F1: 0.9636 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.0059 - Val accuracy: 0.9656 - Val loss: 0.1341 - Val F1: 0.9657 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.0030 - Val accuracy: 0.9644 - Val loss: 0.1573 - Val F1: 0.9644 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0024 - Val accuracy: 0.9622 - Val loss: 0.1553 - Val F1: 0.9623 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0019 - Val accuracy: 0.9644 - Val loss: 0.1690 - Val F1: 0.9644 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0018 - Val accuracy: 0.9648 - Val loss: 0.1639 - Val F1: 0.9649 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0013 - Val accuracy: 0.9665 - Val loss: 0.1650 - Val F1: 0.9665 - LR: 0.00e+00\n","\tBest epoch: 18 - Best val accuracy: 0.9546 - Best val loss: 0.1162 - Best val F1: 0.9546\n","\n","Source class: WAL | Domain: 73 | Accuracy: 0.0722 | Loss: 23.0166 | F1: 0.0097\n","\n","Domain: 74\n","x_syn_dom.shape: (444, 3, 128) | np.unique(y_syn_dom): [0 1 2 3]\n","x_dp_dom.shape: (146, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","x_syn_dom.shape: (388, 3, 128) | np.unique(y_syn_dom): [0 1 2 3]\n","x_dp_dom.shape: (91, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","x_df_syn.shape: (12171, 3, 128) | np.unique(y_df_syn): [0 1 2 3]\n","Training on Df plus synthetic data...\n","\tEpoch 10/100 - Train loss: 0.0929 - Val accuracy: 0.9504 - Val loss: 0.1421 - Val F1: 0.9504 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.0346 - Val accuracy: 0.9538 - Val loss: 0.1362 - Val F1: 0.9537 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.0132 - Val accuracy: 0.9571 - Val loss: 0.1534 - Val F1: 0.9571 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.0071 - Val accuracy: 0.9571 - Val loss: 0.1621 - Val F1: 0.9572 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.0059 - Val accuracy: 0.9529 - Val loss: 0.2483 - Val F1: 0.9528 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.0034 - Val accuracy: 0.9555 - Val loss: 0.1939 - Val F1: 0.9554 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0028 - Val accuracy: 0.9584 - Val loss: 0.1962 - Val F1: 0.9584 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0023 - Val accuracy: 0.9601 - Val loss: 0.1884 - Val F1: 0.9601 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0026 - Val accuracy: 0.9588 - Val loss: 0.1974 - Val F1: 0.9588 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0014 - Val accuracy: 0.9576 - Val loss: 0.1905 - Val F1: 0.9575 - LR: 0.00e+00\n","\tBest epoch: 15 - Best val accuracy: 0.9546 - Best val loss: 0.1328 - Best val F1: 0.9546\n","\n","Source class: WAL | Domain: 74 | Accuracy: 0.3077 | Loss: 5.3323 | F1: 0.3033\n","\n","Domain: 75\n","x_syn_dom.shape: (444, 3, 128) | np.unique(y_syn_dom): [0 1 2 3]\n","x_dp_dom.shape: (153, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","x_syn_dom.shape: (388, 3, 128) | np.unique(y_syn_dom): [0 1 2 3]\n","x_dp_dom.shape: (98, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","x_df_syn.shape: (12171, 3, 128) | np.unique(y_df_syn): [0 1 2 3]\n","Training on Df plus synthetic data...\n","\tEpoch 10/100 - Train loss: 0.0973 - Val accuracy: 0.9521 - Val loss: 0.1451 - Val F1: 0.9522 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.0429 - Val accuracy: 0.9525 - Val loss: 0.1541 - Val F1: 0.9525 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.0143 - Val accuracy: 0.9580 - Val loss: 0.1388 - Val F1: 0.9580 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.0087 - Val accuracy: 0.9563 - Val loss: 0.1755 - Val F1: 0.9563 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.0057 - Val accuracy: 0.9597 - Val loss: 0.1569 - Val F1: 0.9597 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.0055 - Val accuracy: 0.9588 - Val loss: 0.1819 - Val F1: 0.9589 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0032 - Val accuracy: 0.9588 - Val loss: 0.1812 - Val F1: 0.9589 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0015 - Val accuracy: 0.9588 - Val loss: 0.1883 - Val F1: 0.9589 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0016 - Val accuracy: 0.9588 - Val loss: 0.1987 - Val F1: 0.9589 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0015 - Val accuracy: 0.9576 - Val loss: 0.1965 - Val F1: 0.9576 - LR: 0.00e+00\n","\tBest epoch: 19 - Best val accuracy: 0.9550 - Best val loss: 0.1297 - Best val F1: 0.9550\n","\n","Source class: WAL | Domain: 75 | Accuracy: 0.0714 | Loss: 48.2559 | F1: 0.0095\n","\n","Mean accuracy: 0.2448 +- 0.1175\n","Mean F1: 0.1672 +- 0.1237\n","\n"]}],"source":["def compute_TSTR_Df_plus_Syn(dataset):\n","    accs = []\n","    f1s = []\n","\n","    for src_class in config[dataset]['class_names']:\n","        if src_class != 'WAL':\n","            continue\n","\n","        print(f\"Source class: {src_class}\\n\")\n","\n","        # Load Df data\n","        x_df, y_df, k_df = get_data(dataset, 'df', src_class)\n","        print(f'x_df.shape: {x_df.shape} | np.unique(y_df): {np.unique(y_df)}\\n')\n","\n","        for domain in range(config[dataset]['num_df_domains'], config[dataset]['num_df_domains'] + config[dataset]['num_dp_domains']):\n","            print(f\"Domain: {domain}\")\n","\n","            # Load synthetic data\n","            x_syn_dom, y_syn_dom, k_syn_dom = get_syn_data(dataset, syn_name, src_class, domain)\n","            print(f'x_syn_dom.shape: {x_syn_dom.shape} | np.unique(y_syn_dom): {np.unique(y_syn_dom)}')\n","\n","            # Load Dp data\n","            x_dp_dom, y_dp_dom, k_dp_dom = get_data(dataset, 'dp', src_class, domain)\n","            print(f'x_dp_dom.shape: {x_dp_dom.shape} | np.unique(y_dp_dom): {np.unique(y_dp_dom)}\\n')\n","\n","            y0_indices_syn = np.where(y_syn_dom == 0)[0]\n","            y0_indices_dp = np.where(y_dp_dom == 0)[0]\n","            assert np.array_equal(y0_indices_syn, y0_indices_dp), \"Labels do not match\"\n","            assert np.array_equal(y_syn_dom[y0_indices_syn], y_dp_dom[y0_indices_dp]), \"Labels do not match\"\n","\n","            y0_indices_train, y0_indices_test = train_test_split(y0_indices_syn, test_size=0.5, shuffle=True, random_state=seed)\n","\n","            x_syn_dom_y0, y_syn_dom_y0 = x_syn_dom[y0_indices_train], y_syn_dom[y0_indices_train]\n","            x_dp_dom_y0, y_dp_dom_y0 = x_dp_dom[y0_indices_test], y_dp_dom[y0_indices_test]\n","\n","            x_syn_dom = np.concatenate([x_syn_dom_y0, x_syn_dom[y_syn_dom != 0]])\n","            y_syn_dom = np.concatenate([y_syn_dom_y0, y_syn_dom[y_syn_dom != 0]])\n","            x_dp_dom = np.concatenate([x_dp_dom_y0, x_dp_dom[y_dp_dom != 0]])\n","            y_dp_dom = np.concatenate([y_dp_dom_y0, y_dp_dom[y_dp_dom != 0]])\n","\n","            print(f'x_syn_dom.shape: {x_syn_dom.shape} | np.unique(y_syn_dom): {np.unique(y_syn_dom)}')\n","            print(f'x_dp_dom.shape: {x_dp_dom.shape} | np.unique(y_dp_dom): {np.unique(y_dp_dom)}\\n')\n","\n","            # Join Df and synthetic data\n","            x_df_syn = np.concatenate([x_df, x_syn_dom], axis=0)\n","            y_df_syn = np.concatenate([y_df, y_syn_dom], axis=0)\n","            k_df_syn = np.concatenate([k_df, k_syn_dom], axis=0)\n","            print(f'x_df_syn.shape: {x_df_syn.shape} | np.unique(y_df_syn): {np.unique(y_df_syn)}')\n","\n","            # Train on Df plus synthetic data and test on Dp data\n","            print('Training on Df plus synthetic data...')\n","            acc, loss, f1 = train_and_test(x_df, y_df, x_dp_dom, y_dp_dom, dataset, num_epochs=num_epochs)\n","            save_scores(src_class, domain, acc, loss, f1, 'Df_plus_Syn', dataset)\n","            accs.append(acc)\n","            f1s.append(f1)\n","            print(f'Source class: {src_class} | Domain: {domain} | Accuracy: {acc:.4f} | Loss: {loss:.4f} | F1: {f1:.4f}\\n')\n","\n","    print(f\"Mean accuracy: {np.mean(accs):.4f} +- {np.std(accs):.4f}\")\n","    print(f\"Mean F1: {np.mean(f1s):.4f} +- {np.std(f1s):.4f}\\n\")\n","\n","\n","\n","\n","compute_TSTR_Df_plus_Syn('realworld_mobiact')"]},{"cell_type":"markdown","metadata":{"id":"fLSuTddOmD5c"},"source":["# TSTRFS"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"wZqvTTwNCPto"},"outputs":[],"source":["def compute_TSTRFS_Dpfs(dataset):\n","    accs = []\n","\n","    for src_class in config[dataset]['class_names']:\n","        if src_class != 'WAL':\n","            continue\n","\n","        print(f\"Source class: {src_class}\\n\")\n","\n","        for domain in range(config[dataset]['num_df_domains'], config[dataset]['num_df_domains'] + config[dataset]['num_dp_domains']):\n","            print(f\"Domain: {domain}\")\n","\n","            # Load Dpfs data\n","            x_dpfs_dom, y_dpfs_dom, k_dpfs_dom = get_data(dataset, 'dpfs', src_class, domain)\n","            print(f'x_dpfs_dom.shape: {x_dpfs_dom.shape} | np.unique(y_dpfs_dom): {np.unique(y_dpfs_dom)}')\n","\n","            # Load Dp data\n","            x_dp_dom, y_dp_dom, k_dp_dom = get_data(dataset, 'dp', src_class, domain)\n","            print(f'x_dp_dom.shape: {x_dp_dom.shape} | np.unique(y_dp_dom): {np.unique(y_dp_dom)}\\n')\n","\n","            # Train on Dpfs data and test on Dp data\n","            print('Training on Dpfs data...')\n","            acc, loss = train_and_test(x_dpfs_dom, y_dpfs_dom, x_dp_dom, y_dp_dom, dataset, num_epochs=num_epochs)\n","            save_scores(src_class, domain, acc, loss, 'FS_Dpfs', dataset)\n","            accs.append(acc)\n","            print(f'Source class: {src_class} | Domain: {domain} | Accuracy: {acc:.4f} | Loss: {loss:.4f}\\n')\n","\n","    print(f\"Mean accuracy: {np.mean(accs):.4f}\\n\")\n","\n","\n","\n","compute_TSTRFS_Dpfs('realworld_mobiact')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"YOqZB6ARCPtp"},"outputs":[],"source":["def compute_TSTRFS_Df_Dpfs(dataset):\n","    accs = []\n","\n","    for src_class in config[dataset]['class_names']:\n","        if src_class != 'WAL':\n","            continue\n","\n","        print(f\"Source class: {src_class}\\n\")\n","\n","        # Load Df data\n","        x_df, y_df, k_df = get_data(dataset, 'df', src_class)\n","        print(f'x_df.shape: {x_df.shape} | np.unique(y_df): {np.unique(y_df)}\\n')\n","\n","        # Train on Df data\n","        print('Training on Df data...')\n","        df_model = train_only(x_df, y_df, dataset, num_epochs=num_epochs)\n","\n","        for domain in range(config[dataset]['num_df_domains'], config[dataset]['num_df_domains'] + config[dataset]['num_dp_domains']):\n","            print(f\"Domain: {domain}\")\n","\n","            # Load Dpfs data\n","            x_dpfs_dom, y_dpfs_dom, k_dpfs_dom = get_data(dataset, 'dpfs', src_class, domain)\n","            print(f'x_dpfs_dom.shape: {x_dpfs_dom.shape} | np.unique(y_dpfs_dom): {np.unique(y_dpfs_dom)}')\n","\n","            # Load Dp data\n","            x_dp_dom, y_dp_dom, k_dp_dom = get_data(dataset, 'dp', src_class, domain)\n","            print(f'x_dp_dom.shape: {x_dp_dom.shape} | np.unique(y_dp_dom): {np.unique(y_dp_dom)}\\n')\n","\n","            # Fine-tune Df model on Dpfs data and test on Dp data\n","            print('Fine-tuning on Dpfs data...')\n","            df_dpfs_model = fine_tune(copy.deepcopy(df_model), x_dpfs_dom, y_dpfs_dom, num_epochs=num_epochs)\n","            acc, loss = evaluate_model(df_dpfs_model, get_dataloader(x_dp_dom, y_dp_dom))\n","            save_scores(src_class, domain, acc, loss, 'FS_Df_Dpfs', dataset)\n","            accs.append(acc)\n","            print(f'Source class: {src_class} | Domain: {domain} | Accuracy: {acc:.4f} | Loss: {loss:.4f}\\n')\n","\n","    print(f\"Mean accuracy: {np.mean(accs):.4f}\\n\")\n","\n","\n","\n","compute_TSTRFS_Df_Dpfs('realworld_mobiact')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"oA89psVZg5yb"},"outputs":[],"source":["def compute_TSTRFS_Syn(dataset):\n","    accs = []\n","\n","    for src_class in config[dataset]['class_names']:\n","        if src_class != 'WAL':\n","            continue\n","\n","        print(f\"Source class: {src_class}\\n\")\n","\n","        for domain in range(config[dataset]['num_df_domains'], config[dataset]['num_df_domains'] + config[dataset]['num_dp_domains']):\n","            print(f\"Domain: {domain}\")\n","\n","            # Load synthetic data\n","            x_syn_dom, y_syn_dom, k_syn_dom = get_syn_data(dataset, syn_name, src_class, domain)\n","            print(f'x_syn_dom.shape: {x_syn_dom.shape} | np.unique(y_syn_dom): {np.unique(y_syn_dom)}')\n","\n","            # Load Dp data\n","            x_dp_dom, y_dp_dom, k_dp_dom = get_data(dataset, 'dp', src_class, domain)\n","            print(f'x_dp_dom.shape: {x_dp_dom.shape} | np.unique(y_dp_dom): {np.unique(y_dp_dom)}\\n')\n","\n","            # Train on synthetic data and evaluate on Dp data\n","            print('Training on synthetic data...')\n","            acc, loss = train_and_test(x_syn_dom, y_syn_dom, x_dp_dom, y_dp_dom, dataset, num_epochs=num_epochs)\n","            save_scores(src_class, domain, acc, loss, 'FS_Syn', dataset)\n","            accs.append(acc)\n","            print(f'Source class: {src_class} | Domain: {domain} | Accuracy: {acc:.4f} | Loss: {loss:.4f}\\n')\n","\n","    print(f\"Mean accuracy: {np.mean(accs):.4f}\\n\")\n","\n","\n","\n","\n","compute_TSTRFS_Syn('realworld_mobiact')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"38LHCQjRCPtp"},"outputs":[],"source":["def compute_TSTRFS_Df_Syn(dataset):\n","    accs = []\n","\n","    for src_class in config[dataset]['class_names']:\n","        if src_class != 'WAL':\n","            continue\n","\n","        print(f\"Source class: {src_class}\\n\")\n","\n","        # Load Df data\n","        x_df, y_df, k_df = get_data(dataset, 'df', src_class)\n","        print(f'x_df.shape: {x_df.shape} | np.unique(y_df): {np.unique(y_df)}\\n')\n","\n","        # Train on Df data\n","        print('Training on Df data...')\n","        df_model = train_only(x_df, y_df, dataset, num_epochs=num_epochs)\n","\n","        for domain in range(config[dataset]['num_df_domains'], config[dataset]['num_df_domains'] + config[dataset]['num_dp_domains']):\n","            print(f\"Domain: {domain}\")\n","\n","            # Load synthetic data\n","            x_syn_dom, y_syn_dom, k_syn_dom = get_syn_data(dataset, syn_name, src_class, domain)\n","            print(f'x_syn_dom.shape: {x_syn_dom.shape} | np.unique(y_syn_dom): {np.unique(y_syn_dom)}')\n","\n","            # Load Dp data\n","            x_dp_dom, y_dp_dom, k_dp_dom = get_data(dataset, 'dp', src_class, domain)\n","            print(f'x_dp_dom.shape: {x_dp_dom.shape} | np.unique(y_dp_dom): {np.unique(y_dp_dom)}\\n')\n","\n","            # Fine-tune Df model on synthetic data and evaluate on Dp data\n","            print('Fine-tuning on synthetic data...')\n","            df_syn_model = fine_tune(copy.deepcopy(df_model), x_syn_dom, y_syn_dom, num_epochs=num_epochs)\n","            acc, loss = evaluate_model(df_syn_model, get_dataloader(x_dp_dom, y_dp_dom))\n","            save_scores(src_class, domain, acc, loss, 'FS_Df_Syn', dataset)\n","            accs.append(acc)\n","            print(f'Source class: {src_class} | Domain: {domain} | Accuracy: {acc:.4f} | Loss: {loss:.4f}\\n')\n","\n","    print(f\"Mean accuracy: {np.mean(accs):.4f}\\n\")\n","\n","\n","\n","\n","compute_TSTRFS_Df_Syn('realworld_mobiact')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ueNEmwhVCPtp"},"outputs":[],"source":["def compute_TSTRFS_Syn_Dpfs(dataset):\n","    accs = []\n","\n","    for src_class in config[dataset]['class_names']:\n","        if src_class != 'WAL':\n","            continue\n","\n","        print(f\"Source class: {src_class}\\n\")\n","\n","        for domain in range(config[dataset]['num_df_domains'], config[dataset]['num_df_domains'] + config[dataset]['num_dp_domains']):\n","            print(f\"Domain: {domain}\")\n","\n","            # Load synthetic data\n","            x_syn_dom, y_syn_dom, k_syn_dom = get_syn_data(dataset, syn_name, src_class, domain)\n","            print(f'x_syn_dom.shape: {x_syn_dom.shape} | np.unique(y_syn_dom): {np.unique(y_syn_dom)}')\n","\n","            # Load Dpfs data\n","            x_dpfs_dom, y_dpfs_dom, k_dpfs_dom = get_data(dataset, 'dpfs', src_class, domain)\n","            print(f'x_dpfs_dom.shape: {x_dpfs_dom.shape} | np.unique(y_dpfs_dom): {np.unique(y_dpfs_dom)}')\n","\n","            # Load Dp data\n","            x_dp_dom, y_dp_dom, k_dp_dom = get_data(dataset, 'dp', src_class, domain)\n","            print(f'x_dp_dom.shape: {x_dp_dom.shape} | np.unique(y_dp_dom): {np.unique(y_dp_dom)}\\n')\n","\n","            # Train on synthetic data\n","            print('Training on synthetic data...')\n","            syn_model = train_only(x_syn_dom, y_syn_dom, dataset, num_epochs=num_epochs)\n","\n","            # Fine-tune synthetic model on Dpfs data and evaluate on Dp data\n","            print('Fine-tuning on Dpfs data...')\n","            syn_dpfs_model = fine_tune(copy.deepcopy(syn_model), x_dpfs_dom, y_dpfs_dom, num_epochs=num_epochs)\n","            acc, loss = evaluate_model(syn_dpfs_model, get_dataloader(x_dp_dom, y_dp_dom))\n","            save_scores(src_class, domain, acc, loss, 'FS_Syn_Dpfs', dataset)\n","            accs.append(acc)\n","            print(f'Source class: {src_class} | Domain: {domain} | Accuracy: {acc:.4f} | Loss: {loss:.4f}\\n')\n","\n","    print(f\"Mean accuracy: {np.mean(accs):.4f}\\n\")\n","\n","\n","\n","\n","compute_TSTRFS_Syn_Dpfs('realworld_mobiact')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"7z0xuuhhCPtp"},"outputs":[],"source":["def compute_TSTRFS_Df_Syn_Dpfs(dataset):\n","    accs = []\n","\n","    for src_class in config[dataset]['class_names']:\n","        if src_class != 'WAL':\n","            continue\n","\n","        print(f\"Source class: {src_class}\\n\")\n","\n","        # Load Df data\n","        x_df, y_df, k_df = get_data(dataset, 'df', src_class)\n","        print(f'x_df.shape: {x_df.shape} | np.unique(y_df): {np.unique(y_df)}\\n')\n","\n","        # Train on Df data\n","        print('Training on Df data...')\n","        df_model = train_only(x_df, y_df, dataset, num_epochs=num_epochs)\n","\n","        for domain in range(config[dataset]['num_df_domains'], config[dataset]['num_df_domains'] + config[dataset]['num_dp_domains']):\n","            print(f\"Domain: {domain}\")\n","\n","            # Load synthetic data\n","            x_syn_dom, y_syn_dom, k_syn_dom = get_syn_data(dataset, syn_name, src_class, domain)\n","            print(f'x_syn_dom.shape: {x_syn_dom.shape} | np.unique(y_syn_dom): {np.unique(y_syn_dom)}')\n","\n","            # Load Dpfs data\n","            x_dpfs_dom, y_dpfs_dom, k_dpfs_dom = get_data(dataset, 'dpfs', src_class, domain)\n","            print(f'x_dpfs_dom.shape: {x_dpfs_dom.shape} | np.unique(y_dpfs_dom): {np.unique(y_dpfs_dom)}')\n","\n","            # Load Dp data\n","            x_dp_dom, y_dp_dom, k_dp_dom = get_data(dataset, 'dp', src_class, domain)\n","            print(f'x_dp_dom.shape: {x_dp_dom.shape} | np.unique(y_dp_dom): {np.unique(y_dp_dom)}\\n')\n","\n","            # Fine-tune Df model on synthetic data\n","            print('Fine-tuning on synthetic data...')\n","            df_syn_model = fine_tune(copy.deepcopy(df_model), x_syn_dom, y_syn_dom, num_epochs=num_epochs)\n","\n","            # Fine-tune Df-syn model on Dpfs data and evaluate on Dp data\n","            print('Fine-tuning on Dpfs data...')\n","            df_syn_dpfs_model = fine_tune(copy.deepcopy(df_syn_model), x_dpfs_dom, y_dpfs_dom, num_epochs=num_epochs)\n","            acc, loss = evaluate_model(df_syn_dpfs_model, get_dataloader(x_dp_dom, y_dp_dom))\n","            save_scores(src_class, domain, acc, loss, 'FS_Df_Syn_Dpfs', dataset)\n","            accs.append(acc)\n","            print(f'Source class: {src_class} | Domain: {domain} | Accuracy: {acc:.4f} | Loss: {loss:.4f}\\n')\n","\n","    print(f\"Mean accuracy: {np.mean(accs):.4f}\\n\")\n","\n","\n","\n","\n","compute_TSTRFS_Df_Syn_Dpfs('realworld_mobiact')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"zpB3ecNGmD5f"},"outputs":[],"source":["def compute_TSTRFS_Df_plus_Dpfs(dataset):\n","    accs = []\n","\n","    for src_class in config[dataset]['class_names']:\n","        if src_class != 'WAL':\n","            continue\n","\n","        print(f\"Source class: {src_class}\\n\")\n","\n","        # Load Df data\n","        x_df, y_df, k_df = get_data(dataset, 'df', src_class)\n","        print(f'x_df.shape: {x_df.shape} | np.unique(y_df): {np.unique(y_df)}\\n')\n","\n","        for domain in range(config[dataset]['num_df_domains'], config[dataset]['num_df_domains'] + config[dataset]['num_dp_domains']):\n","            print(f\"Domain: {domain}\")\n","\n","            # Load Dpfs data\n","            x_dpfs_dom, y_dpfs_dom, k_dpfs_dom = get_data(dataset, 'dpfs', src_class, domain)\n","            print(f'x_dpfs_dom.shape: {x_dpfs_dom.shape} | np.unique(y_dpfs_dom): {np.unique(y_dpfs_dom)}')\n","\n","            # Join Df and Dpfs data\n","            x_df_dpfs = np.concatenate([x_df, x_dpfs_dom], axis=0)\n","            y_df_dpfs = np.concatenate([y_df, y_dpfs_dom], axis=0)\n","            k_df_dpfs = np.concatenate([k_df, k_dpfs_dom], axis=0)\n","            print(f'x_df_dpfs.shape: {x_df_dpfs.shape} | np.unique(y_df_dpfs): {np.unique(y_df_dpfs)}')\n","\n","            # Load Dp data\n","            x_dp_dom, y_dp_dom, k_dp_dom = get_data(dataset, 'dp', src_class, domain)\n","            print(f'x_dp_dom.shape: {x_dp_dom.shape} | np.unique(y_dp_dom): {np.unique(y_dp_dom)}\\n')\n","\n","            # Train on Df plus Dpfs data and test on Dp data\n","            print('Training on Df plus Dpfs data...')\n","            acc, loss = train_and_test(x_df_dpfs, y_df_dpfs, x_dp_dom, y_dp_dom, dataset, num_epochs=num_epochs)\n","            save_scores(src_class, domain, acc, loss, 'FS_Df_plus_Dpfs', dataset)\n","            accs.append(acc)\n","            print(f'Source class: {src_class} | Domain: {domain} | Accuracy: {acc:.4f} | Loss: {loss:.4f}\\n')\n","\n","    print(f\"Mean accuracy: {np.mean(accs):.4f}\\n\")\n","\n","\n","\n","compute_TSTRFS_Df_plus_Dpfs('realworld_mobiact')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"RYl0a9ZJmD5f"},"outputs":[],"source":["def compute_TSTRFS_Df_plus_Syn(dataset):\n","    accs = []\n","\n","    for src_class in config[dataset]['class_names']:\n","        if src_class != 'WAL':\n","            continue\n","\n","        print(f\"Source class: {src_class}\\n\")\n","\n","        # Load Df data\n","        x_df, y_df, k_df = get_data(dataset, 'df', src_class)\n","        print(f'x_df.shape: {x_df.shape} | np.unique(y_df): {np.unique(y_df)}\\n')\n","\n","        for domain in range(config[dataset]['num_df_domains'], config[dataset]['num_df_domains'] + config[dataset]['num_dp_domains']):\n","            print(f\"Domain: {domain}\")\n","\n","            # Load synthetic data\n","            x_syn_dom, y_syn_dom, k_syn_dom = get_syn_data(dataset, syn_name, src_class, domain)\n","            print(f'x_syn_dom.shape: {x_syn_dom.shape} | np.unique(y_syn_dom): {np.unique(y_syn_dom)}')\n","\n","            # Join Df and synthetic data\n","            x_df_syn = np.concatenate([x_df, x_syn_dom], axis=0)\n","            y_df_syn = np.concatenate([y_df, y_syn_dom], axis=0)\n","            k_df_syn = np.concatenate([k_df, k_syn_dom], axis=0)\n","            print(f'x_df_syn.shape: {x_df_syn.shape} | np.unique(y_df_syn): {np.unique(y_df_syn)}')\n","\n","            # Load Dp data\n","            x_dp_dom, y_dp_dom, k_dp_dom = get_data(dataset, 'dp', src_class, domain)\n","            print(f'x_dp_dom.shape: {x_dp_dom.shape} | np.unique(y_dp_dom): {np.unique(y_dp_dom)}\\n')\n","\n","            # Train on Df plus synthetic data and test on Dp data\n","            print('Training on Df plus synthetic data...')\n","            acc, loss = train_and_test(x_df, y_df, x_dp_dom, y_dp_dom, dataset, num_epochs=num_epochs)\n","            save_scores(src_class, domain, acc, loss, 'FS_Df_plus_Syn', dataset)\n","            accs.append(acc)\n","            print(f'Source class: {src_class} | Domain: {domain} | Accuracy: {acc:.4f} | Loss: {loss:.4f}\\n')\n","\n","    print(f\"Mean accuracy: {np.mean(accs):.4f}\\n\")\n","\n","\n","\n","\n","compute_TSTRFS_Df_plus_Syn('realworld_mobiact')"]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[],"toc_visible":true},"kernelspec":{"display_name":"stargan-v2","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.13"}},"nbformat":4,"nbformat_minor":0}