{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":19487,"status":"ok","timestamp":1731666758981,"user":{"displayName":"Pietro ST","userId":"01777116294553213330"},"user_tz":-60},"id":"I0_1KsKpCPtk","outputId":"922dfbc1-14c8-49b9-ef4e-99d44dbfffe1"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n","/content/drive/MyDrive/ST/stargan\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')\n","\n","%cd drive/MyDrive/ST/stargan"]},{"cell_type":"markdown","metadata":{"id":"lLVVBGiQmD5W"},"source":["# Configuration"]},{"cell_type":"code","execution_count":2,"metadata":{"executionInfo":{"elapsed":5423,"status":"ok","timestamp":1731666764402,"user":{"displayName":"Pietro ST","userId":"01777116294553213330"},"user_tz":-60},"id":"yh05UGFkCPtm"},"outputs":[],"source":["import pickle\n","import numpy as np\n","from sklearn.model_selection import train_test_split, StratifiedKFold\n","import torch\n","import torch.nn as nn\n","from torch.utils.data import DataLoader, TensorDataset\n","from torch.optim.lr_scheduler import LambdaLR\n","import torch.optim as optim\n","import os\n","import csv\n","import random\n","import copy\n","\n","seed = 2710\n","torch.manual_seed(seed)\n","torch.cuda.manual_seed(seed)\n","np.random.seed(seed)\n","random.seed(seed)"]},{"cell_type":"code","execution_count":3,"metadata":{"executionInfo":{"elapsed":3,"status":"ok","timestamp":1731666764402,"user":{"displayName":"Pietro ST","userId":"01777116294553213330"},"user_tz":-60},"id":"UJN2bKbaCPtm"},"outputs":[],"source":["config = {\n","    'realworld': {\n","        'dataset_name': 'realworld',\n","        'num_df_domains': 10,\n","        'num_dp_domains': 5,\n","        'num_classes': 4,\n","        'class_names': ['WAL', 'RUN', 'CLD', 'CLU'],\n","        'num_timesteps': 128,\n","        'num_channels': 3,\n","        'num_classes': 4,\n","    },\n","    'cwru': {\n","        'dataset_name': 'cwru_256_3ch_5cl',\n","        'num_df_domains': 4,\n","        'num_dp_domains': 4,\n","        'num_classes': 5,\n","        'class_names': ['IR', 'Ball', 'OR_centred', 'OR_orthogonal', 'OR_opposite'],\n","        'num_timesteps': 256,\n","        'num_channels': 3,\n","        'num_classes': 5,\n","    },\n","    'realworld_mobiact': {\n","        'dataset_name': 'realworld_mobiact',\n","        'num_df_domains': 15,\n","        'num_dp_domains': 61,\n","        'num_classes': 4,\n","        'class_names': ['WAL', 'RUN', 'CLD', 'CLU'],\n","        'num_timesteps': 128,\n","        'num_channels': 3,\n","        'num_classes': 4,\n","    }\n","}\n","\n","syn_name = 'rwma08'"]},{"cell_type":"code","execution_count":12,"metadata":{"executionInfo":{"elapsed":3,"status":"ok","timestamp":1731668759244,"user":{"displayName":"Pietro ST","userId":"01777116294553213330"},"user_tz":-60},"id":"XwSwaF-LCPtn"},"outputs":[],"source":["def get_data(dataset, domains_set, src_class, domain=None):\n","    # Load configurations\n","    dataset_name = config[dataset]['dataset_name']\n","    class_idx = config[dataset]['class_names'].index(src_class)\n","    num_df_domains = config[dataset]['num_df_domains']\n","\n","    try:\n","        with open(f'data/{dataset_name}.pkl', 'rb') as f:\n","            x, y, k = pickle.load(f)\n","        with open(f'data/{dataset_name}_fs.pkl', 'rb') as f:\n","            fs = pickle.load(f)\n","    except FileNotFoundError:\n","        raise FileNotFoundError(f\"Dataset files for {dataset} not found.\")\n","\n","\n","    if domains_set == 'df':\n","        mask = (y != class_idx) & (k < num_df_domains) & (fs == 0)\n","    elif domains_set == 'dp':\n","        mask = (y != class_idx) & (k >= num_df_domains) & (fs == 0)\n","    elif domains_set == 'dpfs':\n","        mask = (y != class_idx) & (k >= num_df_domains) & (fs == 1)\n","    else:\n","        raise ValueError(f\"Invalid domains set: {domains_set}\")\n","\n","    # Apply initial mask\n","    x, y, k = x[mask], y[mask], k[mask]\n","\n","    # Additional domain filtering if specified\n","    if domain is not None:\n","        domain_mask = (k == domain)\n","        x, y, k = x[domain_mask], y[domain_mask], k[domain_mask]\n","\n","    assert len(x) > 0, f\"No data found\"\n","    assert len(x) == len(y) == len(k), f\"Data length mismatch\"\n","\n","    return x, y, k\n","\n","\n","\n","def get_syn_data(dataset, syn_name, src_class, domain=None, fs=False):\n","    # Load configurations\n","    class_names = config[dataset]['class_names']\n","\n","    try:\n","        with open(f'data/{dataset}_{syn_name}.pkl', 'rb') as f:\n","            x, y, k = pickle.load(f)\n","    except FileNotFoundError:\n","        raise FileNotFoundError(f\"Dataset files for {dataset} not found.\")\n","\n","    with open(f'data/{dataset}_fs_{syn_name}.pkl', 'rb') as f:\n","        fs = pickle.load(f)\n","\n","    x, y, k = x[fs == 0], y[fs == 0], k[fs == 0]\n","\n","    if domain is not None:\n","        domain_mask = (k == domain)\n","        x, y, k = x[domain_mask], y[domain_mask], k[domain_mask]\n","\n","    assert len(x) > 0, f\"No data found\"\n","    assert len(x) == len(y) == len(k), f\"Data length mismatch\"\n","\n","    return x, y, k\n","\n","\n","\n","class TSTRClassifier(nn.Module):\n","    def __init__(self, num_timesteps=128, num_channels=3, num_classes=5):\n","        super(TSTRClassifier, self).__init__()\n","\n","        self.conv1 = nn.Conv1d(num_channels, 16, kernel_size=5, stride=1, padding=2)\n","        self.bn1 = nn.BatchNorm1d(16)\n","        self.conv2 = nn.Conv1d(16, 32, kernel_size=5, stride=1, padding=2)\n","        self.bn2 = nn.BatchNorm1d(32)\n","        self.conv3 = nn.Conv1d(32, 64, kernel_size=5, stride=1, padding=2)\n","        self.bn3 = nn.BatchNorm1d(64)\n","        self.conv4 = nn.Conv1d(64, 128, kernel_size=5, stride=1, padding=2)\n","        self.bn4 = nn.BatchNorm1d(128)\n","        self.pool = nn.MaxPool1d(kernel_size=2, stride=2)\n","        self.relu = nn.ReLU()\n","        self.dropout = nn.Dropout(p=0.25)\n","\n","        self.fc_shared = nn.Linear(num_timesteps * 8, 100)\n","\n","        self.fc_class = nn.Linear(100, num_classes)\n","\n","    def forward(self, x):\n","        x = self.pool(self.relu(self.bn1(self.conv1(x))))\n","        x = self.pool(self.relu(self.bn2(self.conv2(x))))\n","        x = self.pool(self.relu(self.bn3(self.conv3(x))))\n","        x = self.pool(self.relu(self.bn4(self.conv4(x))))\n","        x = x.view(x.size(0), -1)  # Flatten\n","        x = self.dropout(x)\n","        x = self.relu(self.fc_shared(x))\n","\n","        # Final output for class prediction\n","        class_outputs = self.fc_class(x)\n","        return class_outputs\n","\n","\n","\n","def remap_labels(y):\n","    label_map = {clss: i for i, clss in enumerate(np.unique(y))}\n","    return np.array([label_map[clss] for clss in y])\n","\n","\n","\n","def get_dataloader(x, y, shuffle=False):\n","    x = torch.tensor(x, dtype=torch.float32)\n","    y = remap_labels(y)\n","    y = torch.tensor(y, dtype=torch.long)\n","\n","    # Determine dataset size and batch size\n","    dataset_size = len(x)\n","    if dataset_size <= 100:\n","        batch_size = dataset_size\n","    elif dataset_size <= 1000:\n","        batch_size = 16\n","    elif dataset_size <= 5000:\n","        batch_size = 32\n","    else:\n","        batch_size = 64\n","\n","    dataset = TensorDataset(x, y)\n","    loader = DataLoader(dataset, batch_size=batch_size, shuffle=shuffle)\n","\n","    return loader\n","\n","\n","def random_rotation_matrix():\n","    \"\"\"Generate a random rotation matrix from a predefined set of quaternions.\"\"\"\n","    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","    # Define quaternions for 90° and 180° rotations around x, y, and z axes\n","    quaternions = [\n","        [1, 0, 0, 0],  # 0° rotation (identity)\n","        [0.7071, 0.7071, 0, 0],  # 90° rotation around x-axis\n","        [0.7071, 0, 0.7071, 0],  # 90° rotation around y-axis\n","        [0.7071, 0, 0, 0.7071],  # 90° rotation around z-axis\n","        [0.7071, -0.7071, 0, 0],  # -90° rotation around x-axis\n","        [0.7071, 0, -0.7071, 0],  # -90° rotation around y-axis\n","        [0.7071, 0, 0, -0.7071],  # -90° rotation around z-axis\n","        [0, 1, 0, 0],  # 180° rotation around x-axis\n","        [0, 0, 1, 0],  # 180° rotation around y-axis\n","        [0, 0, 0, 1],  # 180° rotation around z-axis\n","    ]\n","\n","    # Randomly select one quaternion\n","    q = random.choice(quaternions)\n","\n","    # Convert quaternion to rotation matrix\n","    q = torch.tensor(q, device=device, dtype=torch.float32)\n","    q = q / torch.norm(q)  # Normalize quaternion\n","    q0, q1, q2, q3 = q\n","\n","    R = torch.tensor([\n","        [1 - 2*q2**2 - 2*q3**2, 2*q1*q2 - 2*q3*q0, 2*q1*q3 + 2*q2*q0],\n","        [2*q1*q2 + 2*q3*q0, 1 - 2*q1**2 - 2*q3**2, 2*q2*q3 - 2*q1*q0],\n","        [2*q1*q3 - 2*q2*q0, 2*q2*q3 + 2*q1*q0, 1 - 2*q1**2 - 2*q2**2]\n","    ], device=device, dtype=torch.float32)\n","\n","    return R, q\n","\n","\n","def augment_batch(x_real):\n","    \"\"\"Apply random rotation to the batch of real time series.\"\"\"\n","    min_val, max_val = -19.61, 19.61\n","    x_real = x_real * (max_val - min_val) + min_val  # De-normalize\n","    R, q = random_rotation_matrix()\n","    x_real = torch.matmul(R, x_real)  # Apply rotation\n","    x_real = (x_real - min_val) / (max_val - min_val)  # Re-normalize\n","    return x_real, q\n","\n","\n","\n","def evaluate_model(model, test_loader):\n","    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","    model.to(device)\n","    model.eval()\n","\n","    loss_fn = nn.CrossEntropyLoss()\n","\n","    total_loss = 0\n","    correct_predictions = 0\n","    total_predictions = 0\n","\n","    with torch.no_grad():\n","        for x_batch, y_batch in test_loader:\n","            x_batch, y_batch = x_batch.to(device), y_batch.to(device)\n","            outputs = model(x_batch)\n","            loss = loss_fn(outputs, y_batch)\n","            total_loss += loss.item()\n","\n","            _, predicted_labels = torch.max(outputs, 1)\n","            correct_predictions += (predicted_labels == y_batch).sum().item()\n","            total_predictions += len(y_batch)\n","\n","    total_loss /= len(test_loader)\n","    accuracy = correct_predictions / total_predictions\n","\n","    return accuracy, total_loss\n","\n","\n","\n","def train_model(model, train_loader, val_loader, optimizer, num_epochs=100, augment=False):\n","    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","    model.to(device)\n","\n","    loss_fn = nn.CrossEntropyLoss()\n","\n","    loss_train = []\n","    loss_val = []\n","    accuracy_val = []\n","    best_model_state = None\n","    best_loss = np.inf\n","    best_accuracy = 0\n","\n","    # Set up linear learning rate decay\n","    lambda_lr = lambda epoch: 1 - epoch / num_epochs\n","    scheduler = LambdaLR(optimizer, lr_lambda=lambda_lr)\n","\n","    for epoch in range(num_epochs):\n","        model.train()\n","        total_loss = 0\n","        for x_batch, y_batch in train_loader:\n","            x_batch, y_batch = x_batch.to(device), y_batch.to(device)\n","            if augment:\n","                x_batch, _ = augment_batch(x_batch)\n","            optimizer.zero_grad()\n","            outputs = model(x_batch)\n","            loss = loss_fn(outputs, y_batch)\n","            loss.backward()\n","            optimizer.step()\n","            total_loss += loss.item()\n","        total_loss /= len(train_loader)\n","        loss_train.append(total_loss)\n","\n","        # Update learning rate\n","        scheduler.step()\n","\n","        val_accuracy, val_loss = evaluate_model(model, val_loader)\n","        if val_loss < best_loss:\n","            best_epoch = epoch\n","            best_accuracy = val_accuracy\n","            best_loss = val_loss\n","            best_model_state = model.state_dict().copy()\n","\n","        loss_val.append(val_loss)\n","        accuracy_val.append(val_accuracy)\n","\n","        current_lr = scheduler.get_last_lr()[0]\n","        if (epoch+1) % 10 == 0:\n","            print(f\"\\tEpoch {epoch + 1}/{num_epochs} - Train loss: {total_loss:.4f} - Val accuracy: {val_accuracy:.4f} - Val loss: {val_loss:.4f} - LR: {current_lr:.2e}\")\n","\n","    print(f\"\\tBest epoch: {best_epoch + 1} - Best val accuracy: {best_accuracy:.4f} - Best val loss: {best_loss:.4f}\\n\")\n","\n","    # Load best model state\n","    model.load_state_dict(best_model_state)\n","\n","    return model\n","\n","\n","\n","def train_and_test(x_train, y_train, x_test, y_test, dataset, num_epochs=100):\n","    assert np.array_equal(np.unique(y_train), np.unique(y_test)), \"Training and test labels do not match\"\n","\n","    x_tr, x_val, y_tr, y_val = train_test_split(x_train, y_train, test_size=0.2, stratify=y_train, shuffle=True, random_state=seed)\n","\n","    train_loader = get_dataloader(x_tr, y_tr, shuffle=True)\n","    val_loader = get_dataloader(x_val, y_val)\n","    test_loader = get_dataloader(x_test, y_test)\n","\n","    model = TSTRClassifier(num_timesteps=config[dataset]['num_timesteps'],\n","                           num_channels=config[dataset]['num_channels'],\n","                           num_classes=config[dataset]['num_classes']-1)\n","    initial_lr = 0.0001\n","    optimizer = optim.Adam(model.parameters(), lr=initial_lr)\n","\n","    trained_model = train_model(model, train_loader, val_loader, optimizer, num_epochs)\n","\n","    test_accuracy, test_loss = evaluate_model(trained_model, test_loader)\n","\n","    return test_accuracy, test_loss\n","\n","\n","\n","def train_only(x_train, y_train, dataset, num_epochs=100, augment=False):\n","\n","    x_tr, x_val, y_tr, y_val = train_test_split(x_train, y_train, test_size=0.2, stratify=y_train, shuffle=True, random_state=seed)\n","\n","    train_loader = get_dataloader(x_tr, y_tr, shuffle=True)\n","    val_loader = get_dataloader(x_val, y_val)\n","\n","    model = TSTRClassifier(num_timesteps=config[dataset]['num_timesteps'],\n","                           num_channels=config[dataset]['num_channels'],\n","                           num_classes=config[dataset]['num_classes']-1)\n","    initial_lr = 0.0001\n","    optimizer = optim.Adam(model.parameters(), lr=initial_lr)\n","\n","    trained_model = train_model(model, train_loader, val_loader, optimizer, num_epochs, augment=augment)\n","\n","    return trained_model\n","\n","\n","\n","def train_classifier_cv(x_train, y_train, dataset, num_epochs=100):\n","    skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=seed)\n","\n","    accs = []\n","    losses = []\n","\n","    for train_index, test_index in skf.split(x_train, y_train):\n","        x_train_fold, x_test_fold = x_train[train_index], x_train[test_index]\n","        y_train_fold, y_test_fold = y_train[train_index], y_train[test_index]\n","\n","        acc, loss = train_and_test(x_train_fold, y_train_fold, x_test_fold, y_test_fold, dataset, num_epochs)\n","        accs.append(acc)\n","        losses.append(loss)\n","\n","    return np.mean(accs), np.mean(losses)\n","\n","\n","\n","def fine_tune(model, x_train, y_train, num_epochs=100):\n","    # Freeze feature extraction layers\n","    for name, param in model.named_parameters():\n","        if 'conv' in name or 'bn' in name:\n","            param.requires_grad = False\n","\n","    x_tr, x_val, y_tr, y_val = train_test_split(x_train, y_train, test_size=0.2, stratify=y_train, shuffle=True, random_state=seed)\n","\n","    train_loader = get_dataloader(x_tr, y_tr, shuffle=True)\n","    val_loader = get_dataloader(x_val, y_val)\n","\n","    initial_lr = 0.00001\n","    optimizer = optim.Adam(filter(lambda p: p.requires_grad, model.parameters()), lr=initial_lr)\n","\n","    trained_model = train_model(model, train_loader, val_loader, optimizer, num_epochs)\n","\n","    return trained_model\n","\n","\n","\n","def save_scores(source, domain, accuracy, loss, name, dataset):\n","    results_dir = 'results'\n","    # Ensure the directory exists\n","    os.makedirs(results_dir, exist_ok=True)\n","    # Path to the CSV file\n","    file_path = os.path.join(results_dir, f'{dataset}_{name}.csv')\n","    # Check if the file exists\n","    file_exists = os.path.exists(file_path)\n","\n","    # Open the file in append mode if it exists, or write mode if it doesn't\n","    with open(file_path, mode='a' if file_exists else 'w', newline='') as file:\n","        writer = csv.writer(file)\n","        # If the file does not exist, write the header\n","        if not file_exists:\n","            writer.writerow(['source', 'domain', 'accuracy', 'loss'])\n","        # Write the data rows\n","        writer.writerow([source, domain, accuracy, loss])"]},{"cell_type":"markdown","metadata":{"id":"PRAlLTPumD5Z"},"source":["# TSTR"]},{"cell_type":"code","execution_count":10,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":207857,"status":"ok","timestamp":1731668758958,"user":{"displayName":"Pietro ST","userId":"01777116294553213330"},"user_tz":-60},"id":"XrDIDrL9CPtn","outputId":"4d351447-22c1-4a59-cea2-9f058c4a1cb2"},"outputs":[{"output_type":"stream","name":"stdout","text":["Source class: WAL\n","\n","Domain: 15\n","x_dp_dom.shape: (50, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Training and evaluating on Dp data via cross-validation...\n","\tEpoch 10/100 - Train loss: 0.5386 - Val accuracy: 0.2500 - Val loss: 1.1027 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.2788 - Val accuracy: 0.2500 - Val loss: 1.1502 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.1391 - Val accuracy: 0.2500 - Val loss: 1.2180 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.0829 - Val accuracy: 0.5000 - Val loss: 1.0278 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.0488 - Val accuracy: 0.7500 - Val loss: 0.4158 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.0384 - Val accuracy: 1.0000 - Val loss: 0.1012 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0292 - Val accuracy: 1.0000 - Val loss: 0.0481 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0262 - Val accuracy: 1.0000 - Val loss: 0.0359 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0239 - Val accuracy: 1.0000 - Val loss: 0.0317 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0253 - Val accuracy: 1.0000 - Val loss: 0.0303 - LR: 0.00e+00\n","\tBest epoch: 100 - Best val accuracy: 1.0000 - Best val loss: 0.0303\n","\n","\tEpoch 10/100 - Train loss: 0.4651 - Val accuracy: 0.5000 - Val loss: 1.0977 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.2028 - Val accuracy: 0.5000 - Val loss: 1.1770 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.1003 - Val accuracy: 0.5000 - Val loss: 1.2061 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.0527 - Val accuracy: 0.5000 - Val loss: 0.9317 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.0381 - Val accuracy: 0.8750 - Val loss: 0.3435 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.0299 - Val accuracy: 1.0000 - Val loss: 0.0909 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0231 - Val accuracy: 1.0000 - Val loss: 0.0437 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0211 - Val accuracy: 1.0000 - Val loss: 0.0326 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0209 - Val accuracy: 1.0000 - Val loss: 0.0289 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0189 - Val accuracy: 1.0000 - Val loss: 0.0277 - LR: 0.00e+00\n","\tBest epoch: 100 - Best val accuracy: 1.0000 - Best val loss: 0.0277\n","\n","\tEpoch 10/100 - Train loss: 0.5575 - Val accuracy: 0.5000 - Val loss: 1.0803 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.2820 - Val accuracy: 0.2500 - Val loss: 1.1074 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.1385 - Val accuracy: 0.2500 - Val loss: 1.1855 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.0803 - Val accuracy: 0.5000 - Val loss: 1.0694 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.0547 - Val accuracy: 0.7500 - Val loss: 0.4546 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.0431 - Val accuracy: 1.0000 - Val loss: 0.1076 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0344 - Val accuracy: 1.0000 - Val loss: 0.0523 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0307 - Val accuracy: 1.0000 - Val loss: 0.0400 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0294 - Val accuracy: 1.0000 - Val loss: 0.0357 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0293 - Val accuracy: 1.0000 - Val loss: 0.0343 - LR: 0.00e+00\n","\tBest epoch: 100 - Best val accuracy: 1.0000 - Best val loss: 0.0343\n","\n","\tEpoch 10/100 - Train loss: 0.5987 - Val accuracy: 0.1250 - Val loss: 1.1020 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.3375 - Val accuracy: 0.1250 - Val loss: 1.1637 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.1713 - Val accuracy: 0.3750 - Val loss: 1.2183 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.0965 - Val accuracy: 0.3750 - Val loss: 1.0486 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.0627 - Val accuracy: 0.7500 - Val loss: 0.5195 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.0482 - Val accuracy: 1.0000 - Val loss: 0.1970 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0372 - Val accuracy: 1.0000 - Val loss: 0.1035 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0326 - Val accuracy: 1.0000 - Val loss: 0.0751 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0307 - Val accuracy: 1.0000 - Val loss: 0.0651 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0315 - Val accuracy: 1.0000 - Val loss: 0.0615 - LR: 0.00e+00\n","\tBest epoch: 100 - Best val accuracy: 1.0000 - Best val loss: 0.0615\n","\n","\tEpoch 10/100 - Train loss: 0.5694 - Val accuracy: 0.6250 - Val loss: 1.0619 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.2841 - Val accuracy: 0.1250 - Val loss: 1.1150 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.1498 - Val accuracy: 0.1250 - Val loss: 1.1940 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.0895 - Val accuracy: 0.3750 - Val loss: 0.9207 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.0610 - Val accuracy: 1.0000 - Val loss: 0.3688 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.0395 - Val accuracy: 1.0000 - Val loss: 0.1232 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0357 - Val accuracy: 1.0000 - Val loss: 0.0634 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0306 - Val accuracy: 1.0000 - Val loss: 0.0466 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0281 - Val accuracy: 1.0000 - Val loss: 0.0407 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0273 - Val accuracy: 1.0000 - Val loss: 0.0389 - LR: 0.00e+00\n","\tBest epoch: 100 - Best val accuracy: 1.0000 - Best val loss: 0.0389\n","\n","Source class: WAL | Domain: 15 | Accuracy: 1.0000 | Loss: 0.0427\n","\n","Domain: 16\n","x_dp_dom.shape: (54, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Training and evaluating on Dp data via cross-validation...\n","\tEpoch 10/100 - Train loss: 0.7694 - Val accuracy: 0.2222 - Val loss: 1.0893 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.4893 - Val accuracy: 0.2222 - Val loss: 1.1625 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.3381 - Val accuracy: 0.2222 - Val loss: 1.3131 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.2458 - Val accuracy: 0.3333 - Val loss: 1.2387 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.1844 - Val accuracy: 0.6667 - Val loss: 0.7181 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.1467 - Val accuracy: 0.7778 - Val loss: 0.4601 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.1257 - Val accuracy: 0.7778 - Val loss: 0.4104 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.1072 - Val accuracy: 0.7778 - Val loss: 0.4034 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0949 - Val accuracy: 0.7778 - Val loss: 0.4029 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0921 - Val accuracy: 0.7778 - Val loss: 0.4031 - LR: 0.00e+00\n","\tBest epoch: 91 - Best val accuracy: 0.7778 - Best val loss: 0.4029\n","\n","\tEpoch 10/100 - Train loss: 0.7001 - Val accuracy: 0.2222 - Val loss: 1.1286 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.4301 - Val accuracy: 0.2222 - Val loss: 1.2610 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.3156 - Val accuracy: 0.2222 - Val loss: 1.5210 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.2334 - Val accuracy: 0.2222 - Val loss: 1.6387 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.1948 - Val accuracy: 0.3333 - Val loss: 1.1098 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.1560 - Val accuracy: 0.5556 - Val loss: 0.5911 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.1335 - Val accuracy: 0.7778 - Val loss: 0.4126 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.1209 - Val accuracy: 0.7778 - Val loss: 0.3576 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.1018 - Val accuracy: 0.7778 - Val loss: 0.3376 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.1071 - Val accuracy: 0.8889 - Val loss: 0.3285 - LR: 0.00e+00\n","\tBest epoch: 100 - Best val accuracy: 0.8889 - Best val loss: 0.3285\n","\n","\tEpoch 10/100 - Train loss: 0.6801 - Val accuracy: 0.2222 - Val loss: 1.1113 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.4518 - Val accuracy: 0.2222 - Val loss: 1.2043 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.3095 - Val accuracy: 0.2222 - Val loss: 1.3918 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.2418 - Val accuracy: 0.2222 - Val loss: 1.3415 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.1798 - Val accuracy: 0.6667 - Val loss: 0.7434 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.1498 - Val accuracy: 1.0000 - Val loss: 0.3611 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.1189 - Val accuracy: 1.0000 - Val loss: 0.2526 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.1070 - Val accuracy: 1.0000 - Val loss: 0.2181 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0951 - Val accuracy: 1.0000 - Val loss: 0.2040 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0962 - Val accuracy: 1.0000 - Val loss: 0.1988 - LR: 0.00e+00\n","\tBest epoch: 100 - Best val accuracy: 1.0000 - Best val loss: 0.1988\n","\n","\tEpoch 10/100 - Train loss: 0.6664 - Val accuracy: 0.2222 - Val loss: 1.1080 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.4452 - Val accuracy: 0.2222 - Val loss: 1.2256 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.3167 - Val accuracy: 0.2222 - Val loss: 1.4161 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.2470 - Val accuracy: 0.2222 - Val loss: 1.3923 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.1975 - Val accuracy: 1.0000 - Val loss: 0.6662 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.1643 - Val accuracy: 1.0000 - Val loss: 0.2769 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.1484 - Val accuracy: 1.0000 - Val loss: 0.1894 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.1276 - Val accuracy: 1.0000 - Val loss: 0.1629 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.1102 - Val accuracy: 1.0000 - Val loss: 0.1520 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.1226 - Val accuracy: 1.0000 - Val loss: 0.1478 - LR: 0.00e+00\n","\tBest epoch: 100 - Best val accuracy: 1.0000 - Best val loss: 0.1478\n","\n","\tEpoch 10/100 - Train loss: 0.6787 - Val accuracy: 0.5556 - Val loss: 1.0809 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.4352 - Val accuracy: 0.2222 - Val loss: 1.2024 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.3154 - Val accuracy: 0.2222 - Val loss: 1.4447 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.2470 - Val accuracy: 0.2222 - Val loss: 1.5229 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.1892 - Val accuracy: 0.4444 - Val loss: 0.9478 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.1518 - Val accuracy: 0.7778 - Val loss: 0.4647 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.1267 - Val accuracy: 0.7778 - Val loss: 0.3430 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.1229 - Val accuracy: 0.7778 - Val loss: 0.3141 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.1127 - Val accuracy: 0.7778 - Val loss: 0.3039 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.1076 - Val accuracy: 0.7778 - Val loss: 0.3006 - LR: 0.00e+00\n","\tBest epoch: 100 - Best val accuracy: 0.7778 - Best val loss: 0.3006\n","\n","Source class: WAL | Domain: 16 | Accuracy: 0.8673 | Loss: 0.3420\n","\n","Domain: 17\n","x_dp_dom.shape: (53, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Training and evaluating on Dp data via cross-validation...\n","\tEpoch 10/100 - Train loss: 0.5939 - Val accuracy: 0.2222 - Val loss: 1.1255 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.3873 - Val accuracy: 0.2222 - Val loss: 1.1676 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.2674 - Val accuracy: 0.2222 - Val loss: 1.2503 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.1953 - Val accuracy: 0.2222 - Val loss: 1.0474 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.1418 - Val accuracy: 0.8889 - Val loss: 0.4381 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.1045 - Val accuracy: 1.0000 - Val loss: 0.1693 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0988 - Val accuracy: 1.0000 - Val loss: 0.0969 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0707 - Val accuracy: 1.0000 - Val loss: 0.0748 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0697 - Val accuracy: 1.0000 - Val loss: 0.0665 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0684 - Val accuracy: 1.0000 - Val loss: 0.0639 - LR: 0.00e+00\n","\tBest epoch: 100 - Best val accuracy: 1.0000 - Best val loss: 0.0639\n","\n","\tEpoch 10/100 - Train loss: 0.5757 - Val accuracy: 0.2222 - Val loss: 1.0907 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.3645 - Val accuracy: 0.2222 - Val loss: 1.1803 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.2542 - Val accuracy: 0.2222 - Val loss: 1.2954 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.1811 - Val accuracy: 0.5556 - Val loss: 1.0874 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.1369 - Val accuracy: 0.8889 - Val loss: 0.5467 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.1064 - Val accuracy: 1.0000 - Val loss: 0.2667 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0902 - Val accuracy: 1.0000 - Val loss: 0.1862 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0716 - Val accuracy: 1.0000 - Val loss: 0.1607 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0660 - Val accuracy: 1.0000 - Val loss: 0.1498 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0742 - Val accuracy: 1.0000 - Val loss: 0.1458 - LR: 0.00e+00\n","\tBest epoch: 100 - Best val accuracy: 1.0000 - Best val loss: 0.1458\n","\n","\tEpoch 10/100 - Train loss: 0.5984 - Val accuracy: 0.2222 - Val loss: 1.1084 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.3707 - Val accuracy: 0.4444 - Val loss: 1.1790 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.2487 - Val accuracy: 0.4444 - Val loss: 1.2703 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.1640 - Val accuracy: 0.4444 - Val loss: 1.0933 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.1284 - Val accuracy: 0.7778 - Val loss: 0.5866 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.0862 - Val accuracy: 1.0000 - Val loss: 0.2719 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0685 - Val accuracy: 1.0000 - Val loss: 0.1749 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0650 - Val accuracy: 1.0000 - Val loss: 0.1458 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0547 - Val accuracy: 1.0000 - Val loss: 0.1354 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0564 - Val accuracy: 1.0000 - Val loss: 0.1320 - LR: 0.00e+00\n","\tBest epoch: 100 - Best val accuracy: 1.0000 - Best val loss: 0.1320\n","\n","\tEpoch 10/100 - Train loss: 0.5604 - Val accuracy: 0.2222 - Val loss: 1.1100 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.3847 - Val accuracy: 0.2222 - Val loss: 1.1904 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.2923 - Val accuracy: 0.2222 - Val loss: 1.2773 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.2345 - Val accuracy: 0.2222 - Val loss: 1.1410 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.1805 - Val accuracy: 0.6667 - Val loss: 0.6275 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.1389 - Val accuracy: 1.0000 - Val loss: 0.2949 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.1155 - Val accuracy: 1.0000 - Val loss: 0.1892 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.1046 - Val accuracy: 1.0000 - Val loss: 0.1538 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0961 - Val accuracy: 1.0000 - Val loss: 0.1395 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0886 - Val accuracy: 1.0000 - Val loss: 0.1344 - LR: 0.00e+00\n","\tBest epoch: 100 - Best val accuracy: 1.0000 - Best val loss: 0.1344\n","\n","\tEpoch 10/100 - Train loss: 0.5850 - Val accuracy: 0.2222 - Val loss: 1.1511 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.3331 - Val accuracy: 0.2222 - Val loss: 1.2547 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.2206 - Val accuracy: 0.2222 - Val loss: 1.4132 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.1494 - Val accuracy: 0.2222 - Val loss: 1.4087 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.1092 - Val accuracy: 0.7778 - Val loss: 0.9065 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.0776 - Val accuracy: 0.8889 - Val loss: 0.4180 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0591 - Val accuracy: 1.0000 - Val loss: 0.2224 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0540 - Val accuracy: 1.0000 - Val loss: 0.1638 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0453 - Val accuracy: 1.0000 - Val loss: 0.1448 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0434 - Val accuracy: 1.0000 - Val loss: 0.1385 - LR: 0.00e+00\n","\tBest epoch: 100 - Best val accuracy: 1.0000 - Best val loss: 0.1385\n","\n","Source class: WAL | Domain: 17 | Accuracy: 0.9418 | Loss: 0.1650\n","\n","Domain: 18\n","x_dp_dom.shape: (54, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Training and evaluating on Dp data via cross-validation...\n","\tEpoch 10/100 - Train loss: 0.6421 - Val accuracy: 0.5556 - Val loss: 1.0950 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.4381 - Val accuracy: 0.2222 - Val loss: 1.1871 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.3049 - Val accuracy: 0.2222 - Val loss: 1.2977 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.2373 - Val accuracy: 0.4444 - Val loss: 1.2016 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.1763 - Val accuracy: 0.8889 - Val loss: 0.7897 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.1504 - Val accuracy: 0.8889 - Val loss: 0.4722 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.1241 - Val accuracy: 0.8889 - Val loss: 0.3448 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.1112 - Val accuracy: 1.0000 - Val loss: 0.2913 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.1022 - Val accuracy: 1.0000 - Val loss: 0.2669 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.1066 - Val accuracy: 1.0000 - Val loss: 0.2561 - LR: 0.00e+00\n","\tBest epoch: 100 - Best val accuracy: 1.0000 - Best val loss: 0.2561\n","\n","\tEpoch 10/100 - Train loss: 0.6468 - Val accuracy: 0.2222 - Val loss: 1.1176 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.4069 - Val accuracy: 0.2222 - Val loss: 1.2576 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.2733 - Val accuracy: 0.2222 - Val loss: 1.4628 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.2195 - Val accuracy: 0.2222 - Val loss: 1.3096 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.1640 - Val accuracy: 0.7778 - Val loss: 0.7239 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.1300 - Val accuracy: 0.7778 - Val loss: 0.4680 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.1085 - Val accuracy: 0.7778 - Val loss: 0.3930 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0895 - Val accuracy: 0.7778 - Val loss: 0.3618 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0842 - Val accuracy: 0.7778 - Val loss: 0.3478 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0836 - Val accuracy: 0.7778 - Val loss: 0.3421 - LR: 0.00e+00\n","\tBest epoch: 100 - Best val accuracy: 0.7778 - Best val loss: 0.3421\n","\n","\tEpoch 10/100 - Train loss: 0.6539 - Val accuracy: 0.2222 - Val loss: 1.1069 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.4206 - Val accuracy: 0.2222 - Val loss: 1.2525 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.2925 - Val accuracy: 0.2222 - Val loss: 1.4472 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.2076 - Val accuracy: 0.2222 - Val loss: 1.2975 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.1731 - Val accuracy: 0.7778 - Val loss: 0.6131 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.1345 - Val accuracy: 1.0000 - Val loss: 0.3356 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.1138 - Val accuracy: 0.8889 - Val loss: 0.2785 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0983 - Val accuracy: 0.8889 - Val loss: 0.2577 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0795 - Val accuracy: 0.8889 - Val loss: 0.2469 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0875 - Val accuracy: 0.8889 - Val loss: 0.2431 - LR: 0.00e+00\n","\tBest epoch: 100 - Best val accuracy: 0.8889 - Best val loss: 0.2431\n","\n","\tEpoch 10/100 - Train loss: 0.6657 - Val accuracy: 0.2222 - Val loss: 1.1156 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.3966 - Val accuracy: 0.2222 - Val loss: 1.2392 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.3048 - Val accuracy: 0.2222 - Val loss: 1.4126 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.2413 - Val accuracy: 0.2222 - Val loss: 1.1932 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.1863 - Val accuracy: 0.8889 - Val loss: 0.5467 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.1619 - Val accuracy: 0.8889 - Val loss: 0.3200 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.1503 - Val accuracy: 0.8889 - Val loss: 0.2669 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.1242 - Val accuracy: 0.8889 - Val loss: 0.2479 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.1233 - Val accuracy: 0.8889 - Val loss: 0.2395 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.1225 - Val accuracy: 0.8889 - Val loss: 0.2366 - LR: 0.00e+00\n","\tBest epoch: 100 - Best val accuracy: 0.8889 - Best val loss: 0.2366\n","\n","\tEpoch 10/100 - Train loss: 0.5876 - Val accuracy: 0.2222 - Val loss: 1.1324 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.3881 - Val accuracy: 0.2222 - Val loss: 1.2927 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.2830 - Val accuracy: 0.2222 - Val loss: 1.4889 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.2031 - Val accuracy: 0.3333 - Val loss: 1.3685 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.1643 - Val accuracy: 0.7778 - Val loss: 0.7426 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.1386 - Val accuracy: 0.8889 - Val loss: 0.3444 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.1093 - Val accuracy: 0.8889 - Val loss: 0.2390 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0999 - Val accuracy: 0.8889 - Val loss: 0.2036 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.1020 - Val accuracy: 0.8889 - Val loss: 0.1897 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0996 - Val accuracy: 0.8889 - Val loss: 0.1846 - LR: 0.00e+00\n","\tBest epoch: 100 - Best val accuracy: 0.8889 - Best val loss: 0.1846\n","\n","Source class: WAL | Domain: 18 | Accuracy: 0.9455 | Loss: 0.2331\n","\n","Domain: 19\n","x_dp_dom.shape: (54, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Training and evaluating on Dp data via cross-validation...\n","\tEpoch 10/100 - Train loss: 0.6459 - Val accuracy: 0.2222 - Val loss: 1.0949 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.3983 - Val accuracy: 0.2222 - Val loss: 1.2073 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.2639 - Val accuracy: 0.2222 - Val loss: 1.4116 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.1815 - Val accuracy: 0.2222 - Val loss: 1.4499 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.1375 - Val accuracy: 0.2222 - Val loss: 1.0235 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.1011 - Val accuracy: 1.0000 - Val loss: 0.3981 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0779 - Val accuracy: 1.0000 - Val loss: 0.1653 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0698 - Val accuracy: 1.0000 - Val loss: 0.1079 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0663 - Val accuracy: 1.0000 - Val loss: 0.0909 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0606 - Val accuracy: 1.0000 - Val loss: 0.0854 - LR: 0.00e+00\n","\tBest epoch: 100 - Best val accuracy: 1.0000 - Best val loss: 0.0854\n","\n","\tEpoch 10/100 - Train loss: 0.5731 - Val accuracy: 0.2222 - Val loss: 1.0955 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.3597 - Val accuracy: 0.2222 - Val loss: 1.1901 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.2307 - Val accuracy: 0.2222 - Val loss: 1.3196 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.1735 - Val accuracy: 0.2222 - Val loss: 1.3139 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.1240 - Val accuracy: 0.7778 - Val loss: 0.7543 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.0992 - Val accuracy: 1.0000 - Val loss: 0.2646 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0807 - Val accuracy: 1.0000 - Val loss: 0.1459 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0607 - Val accuracy: 1.0000 - Val loss: 0.1151 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0513 - Val accuracy: 1.0000 - Val loss: 0.1033 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0561 - Val accuracy: 1.0000 - Val loss: 0.0993 - LR: 0.00e+00\n","\tBest epoch: 100 - Best val accuracy: 1.0000 - Best val loss: 0.0993\n","\n","\tEpoch 10/100 - Train loss: 0.5476 - Val accuracy: 0.2222 - Val loss: 1.1014 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.3513 - Val accuracy: 0.2222 - Val loss: 1.2591 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.2536 - Val accuracy: 0.2222 - Val loss: 1.4820 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.1938 - Val accuracy: 0.2222 - Val loss: 1.5673 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.1485 - Val accuracy: 0.3333 - Val loss: 1.0837 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.1164 - Val accuracy: 1.0000 - Val loss: 0.3896 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0877 - Val accuracy: 1.0000 - Val loss: 0.1871 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0844 - Val accuracy: 1.0000 - Val loss: 0.1351 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0763 - Val accuracy: 1.0000 - Val loss: 0.1176 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0730 - Val accuracy: 1.0000 - Val loss: 0.1115 - LR: 0.00e+00\n","\tBest epoch: 100 - Best val accuracy: 1.0000 - Best val loss: 0.1115\n","\n","\tEpoch 10/100 - Train loss: 0.6145 - Val accuracy: 0.2222 - Val loss: 1.0969 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.3900 - Val accuracy: 0.2222 - Val loss: 1.2076 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.2813 - Val accuracy: 0.2222 - Val loss: 1.3961 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.2031 - Val accuracy: 0.2222 - Val loss: 1.3341 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.1581 - Val accuracy: 0.7778 - Val loss: 0.6936 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.1371 - Val accuracy: 1.0000 - Val loss: 0.2544 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.1071 - Val accuracy: 1.0000 - Val loss: 0.1549 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0866 - Val accuracy: 1.0000 - Val loss: 0.1276 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0871 - Val accuracy: 1.0000 - Val loss: 0.1174 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0854 - Val accuracy: 1.0000 - Val loss: 0.1144 - LR: 0.00e+00\n","\tBest epoch: 100 - Best val accuracy: 1.0000 - Best val loss: 0.1144\n","\n","\tEpoch 10/100 - Train loss: 0.6216 - Val accuracy: 0.5556 - Val loss: 1.0700 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.4084 - Val accuracy: 0.2222 - Val loss: 1.1179 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.2784 - Val accuracy: 0.2222 - Val loss: 1.2205 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.2121 - Val accuracy: 0.2222 - Val loss: 1.1728 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.1485 - Val accuracy: 0.7778 - Val loss: 0.6797 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.1242 - Val accuracy: 1.0000 - Val loss: 0.2596 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0981 - Val accuracy: 1.0000 - Val loss: 0.1421 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0805 - Val accuracy: 1.0000 - Val loss: 0.1099 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0756 - Val accuracy: 1.0000 - Val loss: 0.0987 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0692 - Val accuracy: 1.0000 - Val loss: 0.0948 - LR: 0.00e+00\n","\tBest epoch: 100 - Best val accuracy: 1.0000 - Best val loss: 0.0948\n","\n","Source class: WAL | Domain: 19 | Accuracy: 1.0000 | Loss: 0.1208\n","\n","Domain: 20\n","x_dp_dom.shape: (51, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Training and evaluating on Dp data via cross-validation...\n","\tEpoch 10/100 - Train loss: 0.6273 - Val accuracy: 0.2500 - Val loss: 1.0920 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.3794 - Val accuracy: 0.2500 - Val loss: 1.1292 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.2243 - Val accuracy: 0.2500 - Val loss: 1.1884 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.1659 - Val accuracy: 0.3750 - Val loss: 1.0742 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.1161 - Val accuracy: 0.5000 - Val loss: 0.7418 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.0918 - Val accuracy: 0.7500 - Val loss: 0.5112 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0751 - Val accuracy: 0.7500 - Val loss: 0.4145 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0651 - Val accuracy: 0.7500 - Val loss: 0.3777 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0563 - Val accuracy: 0.7500 - Val loss: 0.3633 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0607 - Val accuracy: 0.7500 - Val loss: 0.3581 - LR: 0.00e+00\n","\tBest epoch: 100 - Best val accuracy: 0.7500 - Best val loss: 0.3581\n","\n","\tEpoch 10/100 - Train loss: 0.6155 - Val accuracy: 0.5556 - Val loss: 1.0835 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.3781 - Val accuracy: 0.2222 - Val loss: 1.1251 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.2547 - Val accuracy: 0.2222 - Val loss: 1.1583 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.1968 - Val accuracy: 0.4444 - Val loss: 0.9038 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.1537 - Val accuracy: 0.7778 - Val loss: 0.4550 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.1270 - Val accuracy: 0.8889 - Val loss: 0.2768 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.1054 - Val accuracy: 1.0000 - Val loss: 0.2230 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0953 - Val accuracy: 1.0000 - Val loss: 0.2021 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0802 - Val accuracy: 1.0000 - Val loss: 0.1928 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0873 - Val accuracy: 1.0000 - Val loss: 0.1899 - LR: 0.00e+00\n","\tBest epoch: 100 - Best val accuracy: 1.0000 - Best val loss: 0.1899\n","\n","\tEpoch 10/100 - Train loss: 0.7148 - Val accuracy: 0.7778 - Val loss: 1.0891 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.4651 - Val accuracy: 0.2222 - Val loss: 1.1514 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.3217 - Val accuracy: 0.2222 - Val loss: 1.2499 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.2503 - Val accuracy: 0.4444 - Val loss: 1.0756 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.2036 - Val accuracy: 0.6667 - Val loss: 0.6796 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.1668 - Val accuracy: 0.7778 - Val loss: 0.4860 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.1326 - Val accuracy: 0.7778 - Val loss: 0.4219 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.1247 - Val accuracy: 0.7778 - Val loss: 0.3995 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.1128 - Val accuracy: 0.7778 - Val loss: 0.3906 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.1126 - Val accuracy: 0.7778 - Val loss: 0.3886 - LR: 0.00e+00\n","\tBest epoch: 99 - Best val accuracy: 0.7778 - Best val loss: 0.3886\n","\n","\tEpoch 10/100 - Train loss: 0.5998 - Val accuracy: 0.6667 - Val loss: 1.0877 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.3498 - Val accuracy: 0.2222 - Val loss: 1.1241 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.2206 - Val accuracy: 0.1111 - Val loss: 1.1743 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.1494 - Val accuracy: 0.3333 - Val loss: 1.0995 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.0962 - Val accuracy: 0.5556 - Val loss: 0.7960 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.0715 - Val accuracy: 0.5556 - Val loss: 0.6292 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0579 - Val accuracy: 0.6667 - Val loss: 0.5936 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0523 - Val accuracy: 0.6667 - Val loss: 0.5883 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0450 - Val accuracy: 0.6667 - Val loss: 0.5894 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0422 - Val accuracy: 0.6667 - Val loss: 0.5902 - LR: 0.00e+00\n","\tBest epoch: 80 - Best val accuracy: 0.6667 - Best val loss: 0.5883\n","\n","\tEpoch 10/100 - Train loss: 0.6741 - Val accuracy: 0.1111 - Val loss: 1.1221 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.4165 - Val accuracy: 0.2222 - Val loss: 1.1954 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.2648 - Val accuracy: 0.2222 - Val loss: 1.2562 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.1853 - Val accuracy: 0.2222 - Val loss: 0.9413 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.1487 - Val accuracy: 0.7778 - Val loss: 0.5237 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.1222 - Val accuracy: 0.7778 - Val loss: 0.3831 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0950 - Val accuracy: 0.7778 - Val loss: 0.3478 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0816 - Val accuracy: 0.8889 - Val loss: 0.3352 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0713 - Val accuracy: 0.8889 - Val loss: 0.3279 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0761 - Val accuracy: 0.8889 - Val loss: 0.3255 - LR: 0.00e+00\n","\tBest epoch: 100 - Best val accuracy: 0.8889 - Best val loss: 0.3255\n","\n","Source class: WAL | Domain: 20 | Accuracy: 0.9400 | Loss: 0.2417\n","\n","Domain: 21\n","x_dp_dom.shape: (47, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Training and evaluating on Dp data via cross-validation...\n","\tEpoch 10/100 - Train loss: 0.6371 - Val accuracy: 0.2500 - Val loss: 1.0886 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.3894 - Val accuracy: 0.2500 - Val loss: 1.1969 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.2759 - Val accuracy: 0.2500 - Val loss: 1.4167 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.2176 - Val accuracy: 0.2500 - Val loss: 1.4063 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.1791 - Val accuracy: 0.7500 - Val loss: 0.7841 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.1379 - Val accuracy: 0.8750 - Val loss: 0.3465 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.1304 - Val accuracy: 0.8750 - Val loss: 0.2548 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.1092 - Val accuracy: 0.8750 - Val loss: 0.2313 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.1095 - Val accuracy: 0.8750 - Val loss: 0.2226 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.1015 - Val accuracy: 0.8750 - Val loss: 0.2191 - LR: 0.00e+00\n","\tBest epoch: 100 - Best val accuracy: 0.8750 - Best val loss: 0.2191\n","\n","\tEpoch 10/100 - Train loss: 0.7065 - Val accuracy: 0.2500 - Val loss: 1.0980 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.4260 - Val accuracy: 0.2500 - Val loss: 1.2323 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.2643 - Val accuracy: 0.2500 - Val loss: 1.4369 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.2018 - Val accuracy: 0.2500 - Val loss: 1.2511 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.1403 - Val accuracy: 0.7500 - Val loss: 0.6116 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.1091 - Val accuracy: 0.8750 - Val loss: 0.3122 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0861 - Val accuracy: 0.8750 - Val loss: 0.2393 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0771 - Val accuracy: 0.8750 - Val loss: 0.2157 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0750 - Val accuracy: 0.8750 - Val loss: 0.2058 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0608 - Val accuracy: 0.8750 - Val loss: 0.2025 - LR: 0.00e+00\n","\tBest epoch: 100 - Best val accuracy: 0.8750 - Best val loss: 0.2025\n","\n","\tEpoch 10/100 - Train loss: 0.5871 - Val accuracy: 0.2500 - Val loss: 1.0957 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.3604 - Val accuracy: 0.2500 - Val loss: 1.2100 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.2508 - Val accuracy: 0.2500 - Val loss: 1.4397 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.1788 - Val accuracy: 0.2500 - Val loss: 1.5179 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.1348 - Val accuracy: 0.5000 - Val loss: 0.8837 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.1081 - Val accuracy: 0.8750 - Val loss: 0.3379 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0907 - Val accuracy: 0.8750 - Val loss: 0.2090 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0795 - Val accuracy: 0.8750 - Val loss: 0.1718 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0711 - Val accuracy: 0.8750 - Val loss: 0.1561 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0694 - Val accuracy: 1.0000 - Val loss: 0.1502 - LR: 0.00e+00\n","\tBest epoch: 100 - Best val accuracy: 1.0000 - Best val loss: 0.1502\n","\n","\tEpoch 10/100 - Train loss: 0.5955 - Val accuracy: 0.2500 - Val loss: 1.1122 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.3445 - Val accuracy: 0.2500 - Val loss: 1.2207 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.2347 - Val accuracy: 0.2500 - Val loss: 1.4292 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.1722 - Val accuracy: 0.2500 - Val loss: 1.3873 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.1275 - Val accuracy: 0.6250 - Val loss: 0.6963 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.1042 - Val accuracy: 0.8750 - Val loss: 0.3236 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0852 - Val accuracy: 0.8750 - Val loss: 0.2545 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0822 - Val accuracy: 0.8750 - Val loss: 0.2368 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0688 - Val accuracy: 0.8750 - Val loss: 0.2298 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0687 - Val accuracy: 0.8750 - Val loss: 0.2273 - LR: 0.00e+00\n","\tBest epoch: 100 - Best val accuracy: 0.8750 - Best val loss: 0.2273\n","\n","\tEpoch 10/100 - Train loss: 0.6092 - Val accuracy: 0.2500 - Val loss: 1.0914 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.4022 - Val accuracy: 0.2500 - Val loss: 1.1696 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.2822 - Val accuracy: 0.2500 - Val loss: 1.3546 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.2047 - Val accuracy: 0.2500 - Val loss: 1.3625 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.1628 - Val accuracy: 0.7500 - Val loss: 0.7381 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.1486 - Val accuracy: 0.8750 - Val loss: 0.4033 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.1133 - Val accuracy: 0.8750 - Val loss: 0.3490 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0939 - Val accuracy: 0.8750 - Val loss: 0.3438 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0956 - Val accuracy: 0.8750 - Val loss: 0.3446 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0960 - Val accuracy: 0.8750 - Val loss: 0.3455 - LR: 0.00e+00\n","\tBest epoch: 81 - Best val accuracy: 0.8750 - Best val loss: 0.3438\n","\n","Source class: WAL | Domain: 21 | Accuracy: 0.9356 | Loss: 0.2263\n","\n","Domain: 22\n","x_dp_dom.shape: (54, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Training and evaluating on Dp data via cross-validation...\n","\tEpoch 10/100 - Train loss: 0.6401 - Val accuracy: 0.2222 - Val loss: 1.1150 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.4050 - Val accuracy: 0.2222 - Val loss: 1.2374 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.2855 - Val accuracy: 0.2222 - Val loss: 1.4649 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.2034 - Val accuracy: 0.2222 - Val loss: 1.6654 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.1440 - Val accuracy: 0.2222 - Val loss: 1.1903 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.1084 - Val accuracy: 0.8889 - Val loss: 0.4606 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0917 - Val accuracy: 0.8889 - Val loss: 0.2824 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0822 - Val accuracy: 0.8889 - Val loss: 0.2467 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0785 - Val accuracy: 1.0000 - Val loss: 0.2361 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0653 - Val accuracy: 1.0000 - Val loss: 0.2330 - LR: 0.00e+00\n","\tBest epoch: 100 - Best val accuracy: 1.0000 - Best val loss: 0.2330\n","\n","\tEpoch 10/100 - Train loss: 0.5738 - Val accuracy: 0.2222 - Val loss: 1.1487 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.3817 - Val accuracy: 0.2222 - Val loss: 1.3685 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.2505 - Val accuracy: 0.2222 - Val loss: 1.6721 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.2090 - Val accuracy: 0.2222 - Val loss: 1.7437 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.1708 - Val accuracy: 0.2222 - Val loss: 1.0106 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.1306 - Val accuracy: 0.8889 - Val loss: 0.3386 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.1096 - Val accuracy: 1.0000 - Val loss: 0.1983 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.1025 - Val accuracy: 1.0000 - Val loss: 0.1632 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0920 - Val accuracy: 1.0000 - Val loss: 0.1515 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0926 - Val accuracy: 1.0000 - Val loss: 0.1476 - LR: 0.00e+00\n","\tBest epoch: 100 - Best val accuracy: 1.0000 - Best val loss: 0.1476\n","\n","\tEpoch 10/100 - Train loss: 0.6674 - Val accuracy: 0.2222 - Val loss: 1.1076 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.4393 - Val accuracy: 0.3333 - Val loss: 1.2517 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.3012 - Val accuracy: 0.2222 - Val loss: 1.4919 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.2260 - Val accuracy: 0.2222 - Val loss: 1.5411 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.1783 - Val accuracy: 0.5556 - Val loss: 0.9267 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.1568 - Val accuracy: 1.0000 - Val loss: 0.4279 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.1277 - Val accuracy: 1.0000 - Val loss: 0.3232 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.1006 - Val accuracy: 1.0000 - Val loss: 0.2982 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0934 - Val accuracy: 1.0000 - Val loss: 0.2897 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.1029 - Val accuracy: 1.0000 - Val loss: 0.2872 - LR: 0.00e+00\n","\tBest epoch: 100 - Best val accuracy: 1.0000 - Best val loss: 0.2872\n","\n","\tEpoch 10/100 - Train loss: 0.7213 - Val accuracy: 0.2222 - Val loss: 1.1273 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.4768 - Val accuracy: 0.2222 - Val loss: 1.1886 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.3307 - Val accuracy: 0.2222 - Val loss: 1.3152 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.2370 - Val accuracy: 0.2222 - Val loss: 1.3369 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.1769 - Val accuracy: 0.6667 - Val loss: 0.8572 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.1291 - Val accuracy: 0.7778 - Val loss: 0.4725 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.1047 - Val accuracy: 0.7778 - Val loss: 0.3827 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0911 - Val accuracy: 0.7778 - Val loss: 0.3679 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0853 - Val accuracy: 0.7778 - Val loss: 0.3653 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0864 - Val accuracy: 0.7778 - Val loss: 0.3652 - LR: 0.00e+00\n","\tBest epoch: 98 - Best val accuracy: 0.7778 - Best val loss: 0.3652\n","\n","\tEpoch 10/100 - Train loss: 0.5714 - Val accuracy: 0.2222 - Val loss: 1.1275 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.3569 - Val accuracy: 0.2222 - Val loss: 1.3232 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.2592 - Val accuracy: 0.2222 - Val loss: 1.6351 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.1949 - Val accuracy: 0.2222 - Val loss: 1.7914 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.1386 - Val accuracy: 0.3333 - Val loss: 1.2977 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.1180 - Val accuracy: 1.0000 - Val loss: 0.4808 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0926 - Val accuracy: 1.0000 - Val loss: 0.2606 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0909 - Val accuracy: 1.0000 - Val loss: 0.2153 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0775 - Val accuracy: 1.0000 - Val loss: 0.2000 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0804 - Val accuracy: 1.0000 - Val loss: 0.1947 - LR: 0.00e+00\n","\tBest epoch: 100 - Best val accuracy: 1.0000 - Best val loss: 0.1947\n","\n","Source class: WAL | Domain: 22 | Accuracy: 0.9073 | Loss: 0.2674\n","\n","Domain: 23\n","x_dp_dom.shape: (52, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Training and evaluating on Dp data via cross-validation...\n","\tEpoch 10/100 - Train loss: 0.5950 - Val accuracy: 0.2222 - Val loss: 1.0991 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.3759 - Val accuracy: 0.2222 - Val loss: 1.2265 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.2549 - Val accuracy: 0.2222 - Val loss: 1.4354 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.2031 - Val accuracy: 0.2222 - Val loss: 1.3389 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.1580 - Val accuracy: 0.5556 - Val loss: 0.7598 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.1165 - Val accuracy: 0.8889 - Val loss: 0.4353 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.1077 - Val accuracy: 0.8889 - Val loss: 0.3354 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0993 - Val accuracy: 0.8889 - Val loss: 0.3034 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0920 - Val accuracy: 0.8889 - Val loss: 0.2919 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0910 - Val accuracy: 0.8889 - Val loss: 0.2877 - LR: 0.00e+00\n","\tBest epoch: 100 - Best val accuracy: 0.8889 - Best val loss: 0.2877\n","\n","\tEpoch 10/100 - Train loss: 0.6533 - Val accuracy: 0.5556 - Val loss: 1.0858 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.4201 - Val accuracy: 0.2222 - Val loss: 1.1809 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.2968 - Val accuracy: 0.2222 - Val loss: 1.3379 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.2392 - Val accuracy: 0.2222 - Val loss: 1.1976 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.1922 - Val accuracy: 0.7778 - Val loss: 0.5779 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.1490 - Val accuracy: 0.8889 - Val loss: 0.3393 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.1262 - Val accuracy: 0.8889 - Val loss: 0.2914 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.1193 - Val accuracy: 0.8889 - Val loss: 0.2771 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.1102 - Val accuracy: 0.8889 - Val loss: 0.2703 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.1007 - Val accuracy: 0.8889 - Val loss: 0.2676 - LR: 0.00e+00\n","\tBest epoch: 100 - Best val accuracy: 0.8889 - Best val loss: 0.2676\n","\n","\tEpoch 10/100 - Train loss: 0.6328 - Val accuracy: 0.3333 - Val loss: 1.1282 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.4200 - Val accuracy: 0.2222 - Val loss: 1.2096 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.2948 - Val accuracy: 0.2222 - Val loss: 1.3373 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.2311 - Val accuracy: 0.2222 - Val loss: 1.2125 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.1722 - Val accuracy: 0.7778 - Val loss: 0.5849 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.1297 - Val accuracy: 0.8889 - Val loss: 0.3219 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.1216 - Val accuracy: 1.0000 - Val loss: 0.2643 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.1037 - Val accuracy: 1.0000 - Val loss: 0.2458 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0991 - Val accuracy: 1.0000 - Val loss: 0.2378 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0918 - Val accuracy: 1.0000 - Val loss: 0.2349 - LR: 0.00e+00\n","\tBest epoch: 100 - Best val accuracy: 1.0000 - Best val loss: 0.2349\n","\n","\tEpoch 10/100 - Train loss: 0.5957 - Val accuracy: 0.2222 - Val loss: 1.1110 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.3946 - Val accuracy: 0.2222 - Val loss: 1.2488 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.2966 - Val accuracy: 0.2222 - Val loss: 1.4451 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.2218 - Val accuracy: 0.2222 - Val loss: 1.2498 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.1758 - Val accuracy: 0.7778 - Val loss: 0.5903 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.1404 - Val accuracy: 0.8889 - Val loss: 0.3175 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.1196 - Val accuracy: 0.8889 - Val loss: 0.2486 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.1088 - Val accuracy: 0.8889 - Val loss: 0.2250 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.1074 - Val accuracy: 0.8889 - Val loss: 0.2152 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.1033 - Val accuracy: 0.8889 - Val loss: 0.2111 - LR: 0.00e+00\n","\tBest epoch: 100 - Best val accuracy: 0.8889 - Best val loss: 0.2111\n","\n","\tEpoch 10/100 - Train loss: 0.5780 - Val accuracy: 0.2222 - Val loss: 1.1086 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.3592 - Val accuracy: 0.2222 - Val loss: 1.3088 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.2470 - Val accuracy: 0.2222 - Val loss: 1.5933 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.2011 - Val accuracy: 0.2222 - Val loss: 1.4171 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.1595 - Val accuracy: 0.6667 - Val loss: 0.7094 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.1217 - Val accuracy: 0.7778 - Val loss: 0.4007 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0987 - Val accuracy: 0.7778 - Val loss: 0.3284 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0959 - Val accuracy: 0.7778 - Val loss: 0.3045 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0870 - Val accuracy: 0.7778 - Val loss: 0.2933 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0881 - Val accuracy: 0.7778 - Val loss: 0.2886 - LR: 0.00e+00\n","\tBest epoch: 100 - Best val accuracy: 0.7778 - Best val loss: 0.2886\n","\n","Source class: WAL | Domain: 23 | Accuracy: 0.8455 | Loss: 0.3089\n","\n","Domain: 24\n","x_dp_dom.shape: (51, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Training and evaluating on Dp data via cross-validation...\n","\tEpoch 10/100 - Train loss: 0.5657 - Val accuracy: 0.5000 - Val loss: 1.0905 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.3841 - Val accuracy: 0.2500 - Val loss: 1.1174 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.2966 - Val accuracy: 0.2500 - Val loss: 1.1357 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.2546 - Val accuracy: 0.6250 - Val loss: 0.8971 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.2075 - Val accuracy: 0.6250 - Val loss: 0.5639 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.1651 - Val accuracy: 1.0000 - Val loss: 0.3735 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.1462 - Val accuracy: 1.0000 - Val loss: 0.2758 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.1248 - Val accuracy: 1.0000 - Val loss: 0.2304 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.1189 - Val accuracy: 1.0000 - Val loss: 0.2103 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.1178 - Val accuracy: 1.0000 - Val loss: 0.2033 - LR: 0.00e+00\n","\tBest epoch: 100 - Best val accuracy: 1.0000 - Best val loss: 0.2033\n","\n","\tEpoch 10/100 - Train loss: 0.6475 - Val accuracy: 0.2222 - Val loss: 1.0876 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.4545 - Val accuracy: 0.2222 - Val loss: 1.1310 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.3524 - Val accuracy: 0.3333 - Val loss: 1.1588 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.2971 - Val accuracy: 0.8889 - Val loss: 0.8968 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.2359 - Val accuracy: 0.8889 - Val loss: 0.6129 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.1894 - Val accuracy: 0.8889 - Val loss: 0.4975 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.1694 - Val accuracy: 0.8889 - Val loss: 0.4356 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.1632 - Val accuracy: 0.8889 - Val loss: 0.4023 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.1497 - Val accuracy: 0.8889 - Val loss: 0.3851 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.1449 - Val accuracy: 0.8889 - Val loss: 0.3782 - LR: 0.00e+00\n","\tBest epoch: 100 - Best val accuracy: 0.8889 - Best val loss: 0.3782\n","\n","\tEpoch 10/100 - Train loss: 0.6002 - Val accuracy: 0.2222 - Val loss: 1.1179 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.4095 - Val accuracy: 0.2222 - Val loss: 1.2441 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.3205 - Val accuracy: 0.2222 - Val loss: 1.3575 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.2781 - Val accuracy: 0.3333 - Val loss: 1.1333 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.2367 - Val accuracy: 0.8889 - Val loss: 0.7324 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.2005 - Val accuracy: 0.8889 - Val loss: 0.5573 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.1697 - Val accuracy: 0.8889 - Val loss: 0.4722 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.1475 - Val accuracy: 0.8889 - Val loss: 0.4280 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.1387 - Val accuracy: 0.8889 - Val loss: 0.4060 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.1328 - Val accuracy: 0.8889 - Val loss: 0.3956 - LR: 0.00e+00\n","\tBest epoch: 100 - Best val accuracy: 0.8889 - Best val loss: 0.3956\n","\n","\tEpoch 10/100 - Train loss: 0.5237 - Val accuracy: 0.2222 - Val loss: 1.1002 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.3722 - Val accuracy: 0.2222 - Val loss: 1.1773 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.2891 - Val accuracy: 0.2222 - Val loss: 1.1759 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.2336 - Val accuracy: 0.8889 - Val loss: 0.7906 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.1903 - Val accuracy: 1.0000 - Val loss: 0.3762 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.1516 - Val accuracy: 1.0000 - Val loss: 0.2635 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.1302 - Val accuracy: 1.0000 - Val loss: 0.2297 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.1232 - Val accuracy: 1.0000 - Val loss: 0.2123 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.1088 - Val accuracy: 1.0000 - Val loss: 0.2028 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.1022 - Val accuracy: 1.0000 - Val loss: 0.1995 - LR: 0.00e+00\n","\tBest epoch: 100 - Best val accuracy: 1.0000 - Best val loss: 0.1995\n","\n","\tEpoch 10/100 - Train loss: 0.6110 - Val accuracy: 0.2222 - Val loss: 1.1212 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.4538 - Val accuracy: 0.2222 - Val loss: 1.2009 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.3782 - Val accuracy: 0.2222 - Val loss: 1.2612 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.3425 - Val accuracy: 0.4444 - Val loss: 0.9460 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.3082 - Val accuracy: 0.8889 - Val loss: 0.4605 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.2829 - Val accuracy: 1.0000 - Val loss: 0.3267 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.2696 - Val accuracy: 1.0000 - Val loss: 0.2865 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.2457 - Val accuracy: 1.0000 - Val loss: 0.2662 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.2350 - Val accuracy: 1.0000 - Val loss: 0.2544 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.2214 - Val accuracy: 1.0000 - Val loss: 0.2498 - LR: 0.00e+00\n","\tBest epoch: 100 - Best val accuracy: 1.0000 - Best val loss: 0.2498\n","\n","Source class: WAL | Domain: 24 | Accuracy: 0.9618 | Loss: 0.2591\n","\n","Domain: 25\n","x_dp_dom.shape: (54, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Training and evaluating on Dp data via cross-validation...\n","\tEpoch 10/100 - Train loss: 0.6083 - Val accuracy: 0.2222 - Val loss: 1.0998 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.4080 - Val accuracy: 0.2222 - Val loss: 1.1779 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.3142 - Val accuracy: 0.2222 - Val loss: 1.2716 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.2644 - Val accuracy: 0.2222 - Val loss: 1.0463 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.2215 - Val accuracy: 0.8889 - Val loss: 0.5389 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.1630 - Val accuracy: 1.0000 - Val loss: 0.3162 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.1529 - Val accuracy: 1.0000 - Val loss: 0.2416 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.1270 - Val accuracy: 1.0000 - Val loss: 0.2099 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.1207 - Val accuracy: 1.0000 - Val loss: 0.1938 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.1094 - Val accuracy: 1.0000 - Val loss: 0.1875 - LR: 0.00e+00\n","\tBest epoch: 100 - Best val accuracy: 1.0000 - Best val loss: 0.1875\n","\n","\tEpoch 10/100 - Train loss: 0.5955 - Val accuracy: 0.2222 - Val loss: 1.1249 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.4037 - Val accuracy: 0.2222 - Val loss: 1.2344 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.3043 - Val accuracy: 0.2222 - Val loss: 1.3768 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.2287 - Val accuracy: 0.2222 - Val loss: 1.1830 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.1842 - Val accuracy: 0.8889 - Val loss: 0.4902 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.1303 - Val accuracy: 0.8889 - Val loss: 0.2297 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.1048 - Val accuracy: 1.0000 - Val loss: 0.1637 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0974 - Val accuracy: 1.0000 - Val loss: 0.1395 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0800 - Val accuracy: 1.0000 - Val loss: 0.1292 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0855 - Val accuracy: 1.0000 - Val loss: 0.1262 - LR: 0.00e+00\n","\tBest epoch: 100 - Best val accuracy: 1.0000 - Best val loss: 0.1262\n","\n","\tEpoch 10/100 - Train loss: 0.6217 - Val accuracy: 0.2222 - Val loss: 1.1203 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.4363 - Val accuracy: 0.2222 - Val loss: 1.2602 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.3482 - Val accuracy: 0.2222 - Val loss: 1.3770 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.2933 - Val accuracy: 0.5556 - Val loss: 0.8897 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.2573 - Val accuracy: 0.8889 - Val loss: 0.3922 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.2203 - Val accuracy: 1.0000 - Val loss: 0.2801 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.2132 - Val accuracy: 1.0000 - Val loss: 0.2452 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.1901 - Val accuracy: 1.0000 - Val loss: 0.2258 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.1740 - Val accuracy: 1.0000 - Val loss: 0.2146 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.1675 - Val accuracy: 1.0000 - Val loss: 0.2099 - LR: 0.00e+00\n","\tBest epoch: 100 - Best val accuracy: 1.0000 - Best val loss: 0.2099\n","\n","\tEpoch 10/100 - Train loss: 0.6093 - Val accuracy: 0.5556 - Val loss: 1.0863 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.4442 - Val accuracy: 0.2222 - Val loss: 1.1758 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.3710 - Val accuracy: 0.2222 - Val loss: 1.2998 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.3323 - Val accuracy: 0.2222 - Val loss: 1.0278 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.2971 - Val accuracy: 0.7778 - Val loss: 0.4678 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.2753 - Val accuracy: 0.8889 - Val loss: 0.3259 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.2435 - Val accuracy: 0.8889 - Val loss: 0.2938 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.2363 - Val accuracy: 0.8889 - Val loss: 0.2797 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.2178 - Val accuracy: 0.8889 - Val loss: 0.2721 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.2179 - Val accuracy: 0.8889 - Val loss: 0.2690 - LR: 0.00e+00\n","\tBest epoch: 100 - Best val accuracy: 0.8889 - Best val loss: 0.2690\n","\n","\tEpoch 10/100 - Train loss: 0.5480 - Val accuracy: 0.2222 - Val loss: 1.1237 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.3952 - Val accuracy: 0.2222 - Val loss: 1.2667 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.3472 - Val accuracy: 0.2222 - Val loss: 1.4423 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.3149 - Val accuracy: 0.2222 - Val loss: 1.2479 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.2742 - Val accuracy: 0.8889 - Val loss: 0.5748 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.2436 - Val accuracy: 0.7778 - Val loss: 0.3610 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.2129 - Val accuracy: 0.7778 - Val loss: 0.3291 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.1874 - Val accuracy: 0.7778 - Val loss: 0.3209 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.1798 - Val accuracy: 0.7778 - Val loss: 0.3163 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.1738 - Val accuracy: 0.7778 - Val loss: 0.3135 - LR: 0.00e+00\n","\tBest epoch: 100 - Best val accuracy: 0.7778 - Best val loss: 0.3135\n","\n","Source class: WAL | Domain: 25 | Accuracy: 0.8891 | Loss: 0.3193\n","\n","Domain: 26\n","x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Training and evaluating on Dp data via cross-validation...\n","\tEpoch 10/100 - Train loss: 0.7380 - Val accuracy: 0.1429 - Val loss: 1.1285 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.4528 - Val accuracy: 0.1429 - Val loss: 1.1416 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.2932 - Val accuracy: 0.1429 - Val loss: 1.2567 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.1879 - Val accuracy: 0.1429 - Val loss: 1.2578 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.1389 - Val accuracy: 0.7143 - Val loss: 0.8080 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.1015 - Val accuracy: 0.7143 - Val loss: 0.4413 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0793 - Val accuracy: 0.8571 - Val loss: 0.3181 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0780 - Val accuracy: 0.8571 - Val loss: 0.2819 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0671 - Val accuracy: 0.8571 - Val loss: 0.2707 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0643 - Val accuracy: 0.8571 - Val loss: 0.2672 - LR: 0.00e+00\n","\tBest epoch: 100 - Best val accuracy: 0.8571 - Best val loss: 0.2672\n","\n","\tEpoch 10/100 - Train loss: 0.6497 - Val accuracy: 0.7143 - Val loss: 1.0357 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.4249 - Val accuracy: 0.7143 - Val loss: 1.0200 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.2594 - Val accuracy: 0.2857 - Val loss: 1.0741 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.1777 - Val accuracy: 0.2857 - Val loss: 1.0924 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.1174 - Val accuracy: 0.7143 - Val loss: 0.8823 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.0954 - Val accuracy: 0.8571 - Val loss: 0.5917 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0711 - Val accuracy: 0.8571 - Val loss: 0.4460 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0664 - Val accuracy: 0.8571 - Val loss: 0.4005 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0566 - Val accuracy: 0.8571 - Val loss: 0.3856 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0527 - Val accuracy: 0.8571 - Val loss: 0.3813 - LR: 0.00e+00\n","\tBest epoch: 100 - Best val accuracy: 0.8571 - Best val loss: 0.3813\n","\n","\tEpoch 10/100 - Train loss: 0.6008 - Val accuracy: 0.1429 - Val loss: 1.0888 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.3899 - Val accuracy: 0.1429 - Val loss: 1.1595 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.2613 - Val accuracy: 0.1429 - Val loss: 1.3335 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.1963 - Val accuracy: 0.1429 - Val loss: 1.3607 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.1343 - Val accuracy: 0.5714 - Val loss: 0.8152 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.1137 - Val accuracy: 0.8571 - Val loss: 0.3935 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0885 - Val accuracy: 0.8571 - Val loss: 0.2947 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0741 - Val accuracy: 0.8571 - Val loss: 0.2716 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0753 - Val accuracy: 0.8571 - Val loss: 0.2643 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0675 - Val accuracy: 0.8571 - Val loss: 0.2619 - LR: 0.00e+00\n","\tBest epoch: 100 - Best val accuracy: 0.8571 - Best val loss: 0.2619\n","\n","\tEpoch 10/100 - Train loss: 0.5591 - Val accuracy: 0.7143 - Val loss: 1.0612 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.3500 - Val accuracy: 0.1429 - Val loss: 1.1250 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.2395 - Val accuracy: 0.1429 - Val loss: 1.2979 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.1573 - Val accuracy: 0.1429 - Val loss: 1.3400 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.1053 - Val accuracy: 0.7143 - Val loss: 0.8072 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.0867 - Val accuracy: 0.8571 - Val loss: 0.3299 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0761 - Val accuracy: 0.8571 - Val loss: 0.2228 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0584 - Val accuracy: 1.0000 - Val loss: 0.1982 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0608 - Val accuracy: 1.0000 - Val loss: 0.1902 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0566 - Val accuracy: 1.0000 - Val loss: 0.1873 - LR: 0.00e+00\n","\tBest epoch: 100 - Best val accuracy: 1.0000 - Best val loss: 0.1873\n","\n","\tEpoch 10/100 - Train loss: 0.6101 - Val accuracy: 0.7143 - Val loss: 1.0320 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.3924 - Val accuracy: 0.1429 - Val loss: 1.0776 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.2739 - Val accuracy: 0.1429 - Val loss: 1.2460 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.1896 - Val accuracy: 0.2857 - Val loss: 1.2175 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.1341 - Val accuracy: 0.5714 - Val loss: 0.7776 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.0990 - Val accuracy: 0.8571 - Val loss: 0.3675 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0908 - Val accuracy: 1.0000 - Val loss: 0.2125 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0726 - Val accuracy: 1.0000 - Val loss: 0.1683 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0660 - Val accuracy: 1.0000 - Val loss: 0.1532 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0590 - Val accuracy: 1.0000 - Val loss: 0.1481 - LR: 0.00e+00\n","\tBest epoch: 100 - Best val accuracy: 1.0000 - Best val loss: 0.1481\n","\n","Source class: WAL | Domain: 26 | Accuracy: 0.9778 | Loss: 0.2435\n","\n","Domain: 27\n","x_dp_dom.shape: (54, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Training and evaluating on Dp data via cross-validation...\n","\tEpoch 10/100 - Train loss: 0.6245 - Val accuracy: 0.2222 - Val loss: 1.1206 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.3927 - Val accuracy: 0.2222 - Val loss: 1.2860 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.2912 - Val accuracy: 0.2222 - Val loss: 1.4669 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.2388 - Val accuracy: 0.2222 - Val loss: 1.3515 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.1872 - Val accuracy: 0.6667 - Val loss: 0.7224 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.1611 - Val accuracy: 0.8889 - Val loss: 0.3416 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.1195 - Val accuracy: 0.8889 - Val loss: 0.2358 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.1072 - Val accuracy: 0.8889 - Val loss: 0.1978 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.1019 - Val accuracy: 0.8889 - Val loss: 0.1818 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.1069 - Val accuracy: 0.8889 - Val loss: 0.1755 - LR: 0.00e+00\n","\tBest epoch: 100 - Best val accuracy: 0.8889 - Best val loss: 0.1755\n","\n","\tEpoch 10/100 - Train loss: 0.7627 - Val accuracy: 0.2222 - Val loss: 1.1170 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.5148 - Val accuracy: 0.2222 - Val loss: 1.1882 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.3748 - Val accuracy: 0.2222 - Val loss: 1.2776 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.3211 - Val accuracy: 0.2222 - Val loss: 1.2358 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.2457 - Val accuracy: 0.6667 - Val loss: 0.7799 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.2089 - Val accuracy: 0.8889 - Val loss: 0.4278 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.1886 - Val accuracy: 1.0000 - Val loss: 0.3193 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.1756 - Val accuracy: 1.0000 - Val loss: 0.2842 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.1543 - Val accuracy: 1.0000 - Val loss: 0.2689 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.1486 - Val accuracy: 1.0000 - Val loss: 0.2628 - LR: 0.00e+00\n","\tBest epoch: 100 - Best val accuracy: 1.0000 - Best val loss: 0.2628\n","\n","\tEpoch 10/100 - Train loss: 0.6719 - Val accuracy: 0.2222 - Val loss: 1.1142 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.4434 - Val accuracy: 0.2222 - Val loss: 1.1395 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.3210 - Val accuracy: 0.4444 - Val loss: 1.1700 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.2477 - Val accuracy: 0.6667 - Val loss: 0.9802 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.1966 - Val accuracy: 1.0000 - Val loss: 0.5728 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.1664 - Val accuracy: 1.0000 - Val loss: 0.3373 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.1365 - Val accuracy: 1.0000 - Val loss: 0.2499 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.1242 - Val accuracy: 1.0000 - Val loss: 0.2115 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.1160 - Val accuracy: 1.0000 - Val loss: 0.1947 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.1174 - Val accuracy: 1.0000 - Val loss: 0.1882 - LR: 0.00e+00\n","\tBest epoch: 100 - Best val accuracy: 1.0000 - Best val loss: 0.1882\n","\n","\tEpoch 10/100 - Train loss: 0.6040 - Val accuracy: 0.2222 - Val loss: 1.1244 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.4051 - Val accuracy: 0.2222 - Val loss: 1.2421 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.3033 - Val accuracy: 0.2222 - Val loss: 1.4293 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.2439 - Val accuracy: 0.2222 - Val loss: 1.3899 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.2040 - Val accuracy: 0.4444 - Val loss: 0.7703 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.1554 - Val accuracy: 0.8889 - Val loss: 0.3983 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.1424 - Val accuracy: 0.8889 - Val loss: 0.3009 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.1244 - Val accuracy: 0.8889 - Val loss: 0.2722 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.1090 - Val accuracy: 0.8889 - Val loss: 0.2616 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.1137 - Val accuracy: 0.8889 - Val loss: 0.2579 - LR: 0.00e+00\n","\tBest epoch: 100 - Best val accuracy: 0.8889 - Best val loss: 0.2579\n","\n","\tEpoch 10/100 - Train loss: 0.5508 - Val accuracy: 0.6667 - Val loss: 1.0881 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.3931 - Val accuracy: 0.2222 - Val loss: 1.1816 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.3140 - Val accuracy: 0.2222 - Val loss: 1.2630 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.2317 - Val accuracy: 0.4444 - Val loss: 0.9810 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.1792 - Val accuracy: 0.8889 - Val loss: 0.4935 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.1385 - Val accuracy: 1.0000 - Val loss: 0.2824 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.1157 - Val accuracy: 1.0000 - Val loss: 0.2162 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0992 - Val accuracy: 1.0000 - Val loss: 0.1916 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0951 - Val accuracy: 1.0000 - Val loss: 0.1803 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0889 - Val accuracy: 1.0000 - Val loss: 0.1753 - LR: 0.00e+00\n","\tBest epoch: 100 - Best val accuracy: 1.0000 - Best val loss: 0.1753\n","\n","Source class: WAL | Domain: 27 | Accuracy: 0.9273 | Loss: 0.2610\n","\n","Domain: 28\n","x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Training and evaluating on Dp data via cross-validation...\n","\tEpoch 10/100 - Train loss: 0.6072 - Val accuracy: 0.1429 - Val loss: 1.1327 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.3645 - Val accuracy: 0.1429 - Val loss: 1.2652 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.2670 - Val accuracy: 0.1429 - Val loss: 1.4884 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.2186 - Val accuracy: 0.1429 - Val loss: 1.3750 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.1810 - Val accuracy: 0.8571 - Val loss: 0.6043 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.1592 - Val accuracy: 0.8571 - Val loss: 0.2906 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.1387 - Val accuracy: 0.7143 - Val loss: 0.2463 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.1377 - Val accuracy: 0.8571 - Val loss: 0.2392 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.1236 - Val accuracy: 0.8571 - Val loss: 0.2369 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.1164 - Val accuracy: 0.8571 - Val loss: 0.2362 - LR: 0.00e+00\n","\tBest epoch: 100 - Best val accuracy: 0.8571 - Best val loss: 0.2362\n","\n","\tEpoch 10/100 - Train loss: 0.5415 - Val accuracy: 0.1429 - Val loss: 1.1005 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.3501 - Val accuracy: 0.1429 - Val loss: 1.1870 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.2456 - Val accuracy: 0.1429 - Val loss: 1.3054 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.2023 - Val accuracy: 0.1429 - Val loss: 1.1874 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.1660 - Val accuracy: 0.8571 - Val loss: 0.6653 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.1290 - Val accuracy: 0.8571 - Val loss: 0.3555 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.1143 - Val accuracy: 0.8571 - Val loss: 0.2828 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.1067 - Val accuracy: 0.7143 - Val loss: 0.2656 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0876 - Val accuracy: 0.7143 - Val loss: 0.2598 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0942 - Val accuracy: 0.7143 - Val loss: 0.2572 - LR: 0.00e+00\n","\tBest epoch: 100 - Best val accuracy: 0.7143 - Best val loss: 0.2572\n","\n","\tEpoch 10/100 - Train loss: 0.6004 - Val accuracy: 0.1429 - Val loss: 1.0961 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.3890 - Val accuracy: 0.1429 - Val loss: 1.2069 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.2865 - Val accuracy: 0.1429 - Val loss: 1.4081 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.2291 - Val accuracy: 0.1429 - Val loss: 1.3344 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.1756 - Val accuracy: 0.8571 - Val loss: 0.6731 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.1517 - Val accuracy: 0.8571 - Val loss: 0.3279 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.1306 - Val accuracy: 0.8571 - Val loss: 0.2629 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.1151 - Val accuracy: 0.8571 - Val loss: 0.2502 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.1002 - Val accuracy: 0.8571 - Val loss: 0.2467 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.1065 - Val accuracy: 0.8571 - Val loss: 0.2455 - LR: 0.00e+00\n","\tBest epoch: 100 - Best val accuracy: 0.8571 - Best val loss: 0.2455\n","\n","\tEpoch 10/100 - Train loss: 0.5621 - Val accuracy: 0.1429 - Val loss: 1.0953 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.3588 - Val accuracy: 0.1429 - Val loss: 1.1954 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.2804 - Val accuracy: 0.1429 - Val loss: 1.4013 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.2346 - Val accuracy: 0.1429 - Val loss: 1.3843 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.2074 - Val accuracy: 0.7143 - Val loss: 0.7233 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.1629 - Val accuracy: 0.8571 - Val loss: 0.3230 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.1630 - Val accuracy: 0.8571 - Val loss: 0.2628 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.1487 - Val accuracy: 0.8571 - Val loss: 0.2528 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.1382 - Val accuracy: 0.8571 - Val loss: 0.2502 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.1320 - Val accuracy: 0.8571 - Val loss: 0.2496 - LR: 0.00e+00\n","\tBest epoch: 100 - Best val accuracy: 0.8571 - Best val loss: 0.2496\n","\n","\tEpoch 10/100 - Train loss: 0.6184 - Val accuracy: 0.1429 - Val loss: 1.1124 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.3813 - Val accuracy: 0.1429 - Val loss: 1.1294 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.2725 - Val accuracy: 0.1429 - Val loss: 1.2247 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.1922 - Val accuracy: 0.4286 - Val loss: 1.0269 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.1555 - Val accuracy: 0.8571 - Val loss: 0.5311 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.1303 - Val accuracy: 0.8571 - Val loss: 0.3185 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0973 - Val accuracy: 0.8571 - Val loss: 0.2702 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.1000 - Val accuracy: 0.8571 - Val loss: 0.2544 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0824 - Val accuracy: 0.8571 - Val loss: 0.2485 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0857 - Val accuracy: 0.8571 - Val loss: 0.2459 - LR: 0.00e+00\n","\tBest epoch: 100 - Best val accuracy: 0.8571 - Best val loss: 0.2459\n","\n","Source class: WAL | Domain: 28 | Accuracy: 0.7861 | Loss: 0.2872\n","\n","Domain: 29\n","x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Training and evaluating on Dp data via cross-validation...\n","\tEpoch 10/100 - Train loss: 0.6124 - Val accuracy: 0.1429 - Val loss: 1.1069 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.3631 - Val accuracy: 0.1429 - Val loss: 1.1142 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.2093 - Val accuracy: 0.1429 - Val loss: 1.1960 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.1331 - Val accuracy: 0.1429 - Val loss: 1.2104 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.0917 - Val accuracy: 1.0000 - Val loss: 0.8515 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.0643 - Val accuracy: 1.0000 - Val loss: 0.3915 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0499 - Val accuracy: 1.0000 - Val loss: 0.2403 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0485 - Val accuracy: 1.0000 - Val loss: 0.2014 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0429 - Val accuracy: 1.0000 - Val loss: 0.1896 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0396 - Val accuracy: 1.0000 - Val loss: 0.1862 - LR: 0.00e+00\n","\tBest epoch: 100 - Best val accuracy: 1.0000 - Best val loss: 0.1862\n","\n","\tEpoch 10/100 - Train loss: 0.5541 - Val accuracy: 0.1429 - Val loss: 1.0954 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.3609 - Val accuracy: 0.1429 - Val loss: 1.2470 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.2348 - Val accuracy: 0.1429 - Val loss: 1.5382 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.1626 - Val accuracy: 0.1429 - Val loss: 1.3685 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.1325 - Val accuracy: 0.8571 - Val loss: 0.5027 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.1147 - Val accuracy: 1.0000 - Val loss: 0.1926 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0782 - Val accuracy: 1.0000 - Val loss: 0.1344 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0776 - Val accuracy: 1.0000 - Val loss: 0.1158 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0690 - Val accuracy: 1.0000 - Val loss: 0.1084 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0691 - Val accuracy: 1.0000 - Val loss: 0.1056 - LR: 0.00e+00\n","\tBest epoch: 100 - Best val accuracy: 1.0000 - Best val loss: 0.1056\n","\n","\tEpoch 10/100 - Train loss: 0.6839 - Val accuracy: 0.7143 - Val loss: 1.0654 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.4269 - Val accuracy: 0.1429 - Val loss: 1.1029 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.2563 - Val accuracy: 0.1429 - Val loss: 1.2495 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.1849 - Val accuracy: 0.1429 - Val loss: 1.3174 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.1378 - Val accuracy: 0.8571 - Val loss: 0.8207 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.0991 - Val accuracy: 0.8571 - Val loss: 0.3184 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0799 - Val accuracy: 1.0000 - Val loss: 0.1905 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0702 - Val accuracy: 1.0000 - Val loss: 0.1571 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0676 - Val accuracy: 1.0000 - Val loss: 0.1470 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0614 - Val accuracy: 1.0000 - Val loss: 0.1436 - LR: 0.00e+00\n","\tBest epoch: 100 - Best val accuracy: 1.0000 - Best val loss: 0.1436\n","\n","\tEpoch 10/100 - Train loss: 0.5830 - Val accuracy: 0.7143 - Val loss: 1.0857 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.3494 - Val accuracy: 0.1429 - Val loss: 1.1329 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.2176 - Val accuracy: 0.1429 - Val loss: 1.2830 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.1406 - Val accuracy: 0.1429 - Val loss: 1.3683 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.1052 - Val accuracy: 0.5714 - Val loss: 0.9325 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.0820 - Val accuracy: 0.8571 - Val loss: 0.3742 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0692 - Val accuracy: 0.8571 - Val loss: 0.2247 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0566 - Val accuracy: 0.8571 - Val loss: 0.1857 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0561 - Val accuracy: 1.0000 - Val loss: 0.1727 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0509 - Val accuracy: 1.0000 - Val loss: 0.1685 - LR: 0.00e+00\n","\tBest epoch: 100 - Best val accuracy: 1.0000 - Best val loss: 0.1685\n","\n","\tEpoch 10/100 - Train loss: 0.5592 - Val accuracy: 0.7143 - Val loss: 1.0316 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.3634 - Val accuracy: 0.7143 - Val loss: 1.0067 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.2116 - Val accuracy: 0.7143 - Val loss: 1.0377 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.1291 - Val accuracy: 0.8571 - Val loss: 0.9388 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.0868 - Val accuracy: 1.0000 - Val loss: 0.5898 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.0670 - Val accuracy: 1.0000 - Val loss: 0.3224 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0587 - Val accuracy: 1.0000 - Val loss: 0.2198 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0544 - Val accuracy: 1.0000 - Val loss: 0.1859 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0464 - Val accuracy: 1.0000 - Val loss: 0.1729 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0474 - Val accuracy: 1.0000 - Val loss: 0.1683 - LR: 0.00e+00\n","\tBest epoch: 100 - Best val accuracy: 1.0000 - Best val loss: 0.1683\n","\n","Source class: WAL | Domain: 29 | Accuracy: 0.9528 | Loss: 0.2174\n","\n","Domain: 30\n","x_dp_dom.shape: (50, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Training and evaluating on Dp data via cross-validation...\n","\tEpoch 10/100 - Train loss: 0.6779 - Val accuracy: 0.5000 - Val loss: 1.0823 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.4807 - Val accuracy: 0.2500 - Val loss: 1.1076 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.3478 - Val accuracy: 0.2500 - Val loss: 1.1485 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.2394 - Val accuracy: 0.2500 - Val loss: 1.1339 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.1911 - Val accuracy: 0.5000 - Val loss: 0.8715 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.1517 - Val accuracy: 0.7500 - Val loss: 0.6220 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.1301 - Val accuracy: 0.7500 - Val loss: 0.5472 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.1227 - Val accuracy: 0.7500 - Val loss: 0.5304 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.1107 - Val accuracy: 0.7500 - Val loss: 0.5265 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.1131 - Val accuracy: 0.7500 - Val loss: 0.5273 - LR: 0.00e+00\n","\tBest epoch: 92 - Best val accuracy: 0.7500 - Best val loss: 0.5264\n","\n","\tEpoch 10/100 - Train loss: 0.5639 - Val accuracy: 0.2500 - Val loss: 1.1076 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.3638 - Val accuracy: 0.2500 - Val loss: 1.2107 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.2666 - Val accuracy: 0.2500 - Val loss: 1.4430 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.2066 - Val accuracy: 0.2500 - Val loss: 1.6146 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.1548 - Val accuracy: 0.2500 - Val loss: 1.2038 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.1362 - Val accuracy: 0.7500 - Val loss: 0.6683 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.1232 - Val accuracy: 0.8750 - Val loss: 0.4875 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.1021 - Val accuracy: 0.8750 - Val loss: 0.4393 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0945 - Val accuracy: 0.8750 - Val loss: 0.4228 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0823 - Val accuracy: 0.8750 - Val loss: 0.4172 - LR: 0.00e+00\n","\tBest epoch: 100 - Best val accuracy: 0.8750 - Best val loss: 0.4172\n","\n","\tEpoch 10/100 - Train loss: 0.7162 - Val accuracy: 0.2500 - Val loss: 1.0998 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.5005 - Val accuracy: 0.2500 - Val loss: 1.0890 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.3892 - Val accuracy: 0.2500 - Val loss: 1.0807 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.2984 - Val accuracy: 0.6250 - Val loss: 0.9325 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.2554 - Val accuracy: 0.7500 - Val loss: 0.6886 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.1920 - Val accuracy: 0.7500 - Val loss: 0.5672 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.1737 - Val accuracy: 0.7500 - Val loss: 0.5327 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.1512 - Val accuracy: 0.7500 - Val loss: 0.5198 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.1444 - Val accuracy: 0.7500 - Val loss: 0.5145 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.1271 - Val accuracy: 0.7500 - Val loss: 0.5125 - LR: 0.00e+00\n","\tBest epoch: 100 - Best val accuracy: 0.7500 - Best val loss: 0.5125\n","\n","\tEpoch 10/100 - Train loss: 0.5949 - Val accuracy: 0.8750 - Val loss: 1.0693 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.3596 - Val accuracy: 0.2500 - Val loss: 1.1800 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.2501 - Val accuracy: 0.2500 - Val loss: 1.4467 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.1793 - Val accuracy: 0.0000 - Val loss: 1.6472 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.1377 - Val accuracy: 0.1250 - Val loss: 1.3451 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.1153 - Val accuracy: 0.6250 - Val loss: 1.0326 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0839 - Val accuracy: 0.7500 - Val loss: 1.0341 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0804 - Val accuracy: 0.7500 - Val loss: 1.0661 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0698 - Val accuracy: 0.7500 - Val loss: 1.0848 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0731 - Val accuracy: 0.7500 - Val loss: 1.0945 - LR: 0.00e+00\n","\tBest epoch: 64 - Best val accuracy: 0.6250 - Best val loss: 1.0196\n","\n","\tEpoch 10/100 - Train loss: 0.6376 - Val accuracy: 0.6250 - Val loss: 1.0709 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.4283 - Val accuracy: 0.1250 - Val loss: 1.1466 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.3011 - Val accuracy: 0.1250 - Val loss: 1.3072 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.2289 - Val accuracy: 0.1250 - Val loss: 1.4614 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.1975 - Val accuracy: 0.2500 - Val loss: 1.2009 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.1574 - Val accuracy: 0.6250 - Val loss: 0.7270 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.1370 - Val accuracy: 0.7500 - Val loss: 0.5994 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.1231 - Val accuracy: 0.7500 - Val loss: 0.5866 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.1102 - Val accuracy: 0.7500 - Val loss: 0.5912 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.1155 - Val accuracy: 0.7500 - Val loss: 0.5944 - LR: 0.00e+00\n","\tBest epoch: 79 - Best val accuracy: 0.7500 - Best val loss: 0.5866\n","\n","Source class: WAL | Domain: 30 | Accuracy: 0.8400 | Loss: 0.3582\n","\n","Domain: 31\n","x_dp_dom.shape: (43, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Training and evaluating on Dp data via cross-validation...\n","\tEpoch 10/100 - Train loss: 0.5716 - Val accuracy: 0.7143 - Val loss: 1.0637 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.3443 - Val accuracy: 0.1429 - Val loss: 1.1458 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.2455 - Val accuracy: 0.1429 - Val loss: 1.3334 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.1899 - Val accuracy: 0.2857 - Val loss: 1.2348 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.1490 - Val accuracy: 1.0000 - Val loss: 0.5464 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.1256 - Val accuracy: 1.0000 - Val loss: 0.2088 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.1008 - Val accuracy: 1.0000 - Val loss: 0.1388 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0910 - Val accuracy: 1.0000 - Val loss: 0.1193 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0750 - Val accuracy: 1.0000 - Val loss: 0.1109 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0780 - Val accuracy: 1.0000 - Val loss: 0.1079 - LR: 0.00e+00\n","\tBest epoch: 100 - Best val accuracy: 1.0000 - Best val loss: 0.1079\n","\n","\tEpoch 10/100 - Train loss: 0.5461 - Val accuracy: 0.8571 - Val loss: 1.0630 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.3453 - Val accuracy: 0.8571 - Val loss: 1.0305 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.2413 - Val accuracy: 0.2857 - Val loss: 1.0190 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.1794 - Val accuracy: 0.8571 - Val loss: 0.7949 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.1438 - Val accuracy: 1.0000 - Val loss: 0.3873 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.1151 - Val accuracy: 1.0000 - Val loss: 0.1805 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0979 - Val accuracy: 1.0000 - Val loss: 0.1196 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0879 - Val accuracy: 1.0000 - Val loss: 0.0983 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0725 - Val accuracy: 1.0000 - Val loss: 0.0890 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0764 - Val accuracy: 1.0000 - Val loss: 0.0854 - LR: 0.00e+00\n","\tBest epoch: 100 - Best val accuracy: 1.0000 - Best val loss: 0.0854\n","\n","\tEpoch 10/100 - Train loss: 0.5289 - Val accuracy: 0.5714 - Val loss: 1.0780 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.3163 - Val accuracy: 0.1429 - Val loss: 1.1524 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.2194 - Val accuracy: 0.1429 - Val loss: 1.3058 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.1450 - Val accuracy: 0.1429 - Val loss: 1.2866 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.1103 - Val accuracy: 0.7143 - Val loss: 0.7548 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.0967 - Val accuracy: 1.0000 - Val loss: 0.3128 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0723 - Val accuracy: 1.0000 - Val loss: 0.1837 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0683 - Val accuracy: 1.0000 - Val loss: 0.1525 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0568 - Val accuracy: 1.0000 - Val loss: 0.1421 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0591 - Val accuracy: 1.0000 - Val loss: 0.1387 - LR: 0.00e+00\n","\tBest epoch: 100 - Best val accuracy: 1.0000 - Best val loss: 0.1387\n","\n","\tEpoch 10/100 - Train loss: 0.5997 - Val accuracy: 0.7143 - Val loss: 1.0604 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.3861 - Val accuracy: 0.8571 - Val loss: 1.0597 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.2417 - Val accuracy: 0.2857 - Val loss: 1.1105 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.1550 - Val accuracy: 0.2857 - Val loss: 1.0988 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.1223 - Val accuracy: 0.4286 - Val loss: 0.8601 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.0836 - Val accuracy: 0.8571 - Val loss: 0.4689 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0751 - Val accuracy: 1.0000 - Val loss: 0.2690 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0712 - Val accuracy: 1.0000 - Val loss: 0.1976 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0593 - Val accuracy: 1.0000 - Val loss: 0.1732 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0606 - Val accuracy: 1.0000 - Val loss: 0.1658 - LR: 0.00e+00\n","\tBest epoch: 100 - Best val accuracy: 1.0000 - Best val loss: 0.1658\n","\n","\tEpoch 10/100 - Train loss: 0.5970 - Val accuracy: 0.7143 - Val loss: 1.0231 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.3899 - Val accuracy: 0.7143 - Val loss: 0.9933 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.2584 - Val accuracy: 0.5714 - Val loss: 1.0318 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.1896 - Val accuracy: 0.7143 - Val loss: 0.8748 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.1418 - Val accuracy: 0.8571 - Val loss: 0.5930 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.1042 - Val accuracy: 0.8571 - Val loss: 0.4356 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0943 - Val accuracy: 0.8571 - Val loss: 0.3761 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0762 - Val accuracy: 0.8571 - Val loss: 0.3548 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0704 - Val accuracy: 0.8571 - Val loss: 0.3470 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0654 - Val accuracy: 0.8571 - Val loss: 0.3438 - LR: 0.00e+00\n","\tBest epoch: 100 - Best val accuracy: 0.8571 - Best val loss: 0.3438\n","\n","Source class: WAL | Domain: 31 | Accuracy: 0.9278 | Loss: 0.3019\n","\n","Domain: 32\n","x_dp_dom.shape: (52, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Training and evaluating on Dp data via cross-validation...\n","\tEpoch 10/100 - Train loss: 0.6467 - Val accuracy: 0.2222 - Val loss: 1.1076 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.3891 - Val accuracy: 0.2222 - Val loss: 1.1717 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.2627 - Val accuracy: 0.3333 - Val loss: 1.2780 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.1846 - Val accuracy: 0.3333 - Val loss: 1.1650 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.1228 - Val accuracy: 0.7778 - Val loss: 0.6357 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.0943 - Val accuracy: 1.0000 - Val loss: 0.3117 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0775 - Val accuracy: 1.0000 - Val loss: 0.2166 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0652 - Val accuracy: 1.0000 - Val loss: 0.1844 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0633 - Val accuracy: 1.0000 - Val loss: 0.1713 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0586 - Val accuracy: 1.0000 - Val loss: 0.1665 - LR: 0.00e+00\n","\tBest epoch: 100 - Best val accuracy: 1.0000 - Best val loss: 0.1665\n","\n","\tEpoch 10/100 - Train loss: 0.6792 - Val accuracy: 0.2222 - Val loss: 1.1235 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.4007 - Val accuracy: 0.2222 - Val loss: 1.2315 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.2498 - Val accuracy: 0.3333 - Val loss: 1.4344 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.1867 - Val accuracy: 0.4444 - Val loss: 1.3150 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.1341 - Val accuracy: 1.0000 - Val loss: 0.6045 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.1026 - Val accuracy: 1.0000 - Val loss: 0.2891 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0818 - Val accuracy: 1.0000 - Val loss: 0.2131 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0704 - Val accuracy: 1.0000 - Val loss: 0.1861 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0646 - Val accuracy: 1.0000 - Val loss: 0.1744 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0619 - Val accuracy: 1.0000 - Val loss: 0.1704 - LR: 0.00e+00\n","\tBest epoch: 100 - Best val accuracy: 1.0000 - Best val loss: 0.1704\n","\n","\tEpoch 10/100 - Train loss: 0.5333 - Val accuracy: 0.2222 - Val loss: 1.1146 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.3121 - Val accuracy: 0.2222 - Val loss: 1.2360 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.2023 - Val accuracy: 0.2222 - Val loss: 1.3615 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.1313 - Val accuracy: 0.3333 - Val loss: 1.2836 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.0874 - Val accuracy: 0.8889 - Val loss: 0.7545 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.0698 - Val accuracy: 0.8889 - Val loss: 0.3710 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0534 - Val accuracy: 0.8889 - Val loss: 0.2714 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0426 - Val accuracy: 0.8889 - Val loss: 0.2493 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0406 - Val accuracy: 0.8889 - Val loss: 0.2427 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0406 - Val accuracy: 0.8889 - Val loss: 0.2402 - LR: 0.00e+00\n","\tBest epoch: 100 - Best val accuracy: 0.8889 - Best val loss: 0.2402\n","\n","\tEpoch 10/100 - Train loss: 0.5469 - Val accuracy: 0.2222 - Val loss: 1.1416 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.3211 - Val accuracy: 0.2222 - Val loss: 1.2454 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.2305 - Val accuracy: 0.2222 - Val loss: 1.3742 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.1576 - Val accuracy: 0.3333 - Val loss: 1.2987 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.1167 - Val accuracy: 0.7778 - Val loss: 0.7112 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.0804 - Val accuracy: 0.8889 - Val loss: 0.3558 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0710 - Val accuracy: 0.8889 - Val loss: 0.2391 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0641 - Val accuracy: 0.8889 - Val loss: 0.1980 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0505 - Val accuracy: 1.0000 - Val loss: 0.1807 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0495 - Val accuracy: 1.0000 - Val loss: 0.1738 - LR: 0.00e+00\n","\tBest epoch: 100 - Best val accuracy: 1.0000 - Best val loss: 0.1738\n","\n","\tEpoch 10/100 - Train loss: 0.5627 - Val accuracy: 0.2222 - Val loss: 1.1275 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.3476 - Val accuracy: 0.2222 - Val loss: 1.2466 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.2282 - Val accuracy: 0.2222 - Val loss: 1.4560 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.1614 - Val accuracy: 0.2222 - Val loss: 1.4647 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.1113 - Val accuracy: 0.7778 - Val loss: 0.8132 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.0866 - Val accuracy: 0.8889 - Val loss: 0.3452 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0730 - Val accuracy: 0.8889 - Val loss: 0.2498 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0595 - Val accuracy: 0.8889 - Val loss: 0.2294 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0518 - Val accuracy: 0.8889 - Val loss: 0.2229 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0521 - Val accuracy: 0.8889 - Val loss: 0.2207 - LR: 0.00e+00\n","\tBest epoch: 100 - Best val accuracy: 0.8889 - Best val loss: 0.2207\n","\n","Source class: WAL | Domain: 32 | Accuracy: 0.9618 | Loss: 0.1461\n","\n","Domain: 33\n","x_dp_dom.shape: (44, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Training and evaluating on Dp data via cross-validation...\n","\tEpoch 10/100 - Train loss: 0.6858 - Val accuracy: 0.5714 - Val loss: 1.0643 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.4415 - Val accuracy: 0.8571 - Val loss: 1.0784 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.2910 - Val accuracy: 0.2857 - Val loss: 1.1428 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.2248 - Val accuracy: 0.5714 - Val loss: 0.9823 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.1637 - Val accuracy: 0.8571 - Val loss: 0.5348 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.1307 - Val accuracy: 0.8571 - Val loss: 0.3466 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.1221 - Val accuracy: 0.8571 - Val loss: 0.2963 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0927 - Val accuracy: 0.8571 - Val loss: 0.2807 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0853 - Val accuracy: 0.8571 - Val loss: 0.2738 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0862 - Val accuracy: 0.8571 - Val loss: 0.2713 - LR: 0.00e+00\n","\tBest epoch: 100 - Best val accuracy: 0.8571 - Best val loss: 0.2713\n","\n","\tEpoch 10/100 - Train loss: 0.6418 - Val accuracy: 0.1429 - Val loss: 1.1113 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.4097 - Val accuracy: 0.2857 - Val loss: 1.1661 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.3089 - Val accuracy: 0.2857 - Val loss: 1.2564 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.2358 - Val accuracy: 0.5714 - Val loss: 1.0606 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.1827 - Val accuracy: 0.8571 - Val loss: 0.5588 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.1523 - Val accuracy: 0.8571 - Val loss: 0.3608 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.1199 - Val accuracy: 1.0000 - Val loss: 0.3187 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.1073 - Val accuracy: 1.0000 - Val loss: 0.3052 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.1058 - Val accuracy: 1.0000 - Val loss: 0.2984 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0924 - Val accuracy: 1.0000 - Val loss: 0.2966 - LR: 0.00e+00\n","\tBest epoch: 99 - Best val accuracy: 1.0000 - Best val loss: 0.2966\n","\n","\tEpoch 10/100 - Train loss: 0.5716 - Val accuracy: 0.5714 - Val loss: 1.0868 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.3476 - Val accuracy: 0.2857 - Val loss: 1.1331 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.2437 - Val accuracy: 0.2857 - Val loss: 1.2012 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.1826 - Val accuracy: 0.5714 - Val loss: 0.9753 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.1269 - Val accuracy: 0.8571 - Val loss: 0.5123 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.1151 - Val accuracy: 1.0000 - Val loss: 0.3331 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0935 - Val accuracy: 1.0000 - Val loss: 0.2805 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0736 - Val accuracy: 1.0000 - Val loss: 0.2620 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0688 - Val accuracy: 1.0000 - Val loss: 0.2546 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0736 - Val accuracy: 1.0000 - Val loss: 0.2517 - LR: 0.00e+00\n","\tBest epoch: 100 - Best val accuracy: 1.0000 - Best val loss: 0.2517\n","\n","\tEpoch 10/100 - Train loss: 0.5735 - Val accuracy: 0.1429 - Val loss: 1.0672 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.3707 - Val accuracy: 0.1429 - Val loss: 1.2462 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.2426 - Val accuracy: 0.1429 - Val loss: 1.5274 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.1931 - Val accuracy: 0.1429 - Val loss: 1.3710 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.1515 - Val accuracy: 0.8571 - Val loss: 0.5894 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.1188 - Val accuracy: 0.8571 - Val loss: 0.2995 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.1087 - Val accuracy: 0.8571 - Val loss: 0.2561 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0823 - Val accuracy: 0.8571 - Val loss: 0.2458 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0868 - Val accuracy: 0.8571 - Val loss: 0.2418 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0828 - Val accuracy: 0.8571 - Val loss: 0.2401 - LR: 0.00e+00\n","\tBest epoch: 100 - Best val accuracy: 0.8571 - Best val loss: 0.2401\n","\n","\tEpoch 10/100 - Train loss: 0.6168 - Val accuracy: 0.6250 - Val loss: 1.0309 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.3987 - Val accuracy: 0.2500 - Val loss: 1.0551 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.2670 - Val accuracy: 0.2500 - Val loss: 1.2110 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.2026 - Val accuracy: 0.2500 - Val loss: 1.1636 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.1595 - Val accuracy: 0.8750 - Val loss: 0.5531 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.1312 - Val accuracy: 0.8750 - Val loss: 0.3046 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.1022 - Val accuracy: 0.8750 - Val loss: 0.2572 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0886 - Val accuracy: 0.8750 - Val loss: 0.2435 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0786 - Val accuracy: 0.8750 - Val loss: 0.2387 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0777 - Val accuracy: 0.8750 - Val loss: 0.2372 - LR: 0.00e+00\n","\tBest epoch: 100 - Best val accuracy: 0.8750 - Best val loss: 0.2372\n","\n","Source class: WAL | Domain: 33 | Accuracy: 0.9056 | Loss: 0.2551\n","\n","Domain: 34\n","x_dp_dom.shape: (49, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Training and evaluating on Dp data via cross-validation...\n","\tEpoch 10/100 - Train loss: 0.6450 - Val accuracy: 0.1250 - Val loss: 1.1103 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.4229 - Val accuracy: 0.2500 - Val loss: 1.1798 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.3011 - Val accuracy: 0.2500 - Val loss: 1.3621 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.2092 - Val accuracy: 0.2500 - Val loss: 1.2840 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.1694 - Val accuracy: 0.7500 - Val loss: 0.7715 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.1271 - Val accuracy: 0.8750 - Val loss: 0.4572 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.1168 - Val accuracy: 0.8750 - Val loss: 0.3674 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.1047 - Val accuracy: 0.8750 - Val loss: 0.3416 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.1048 - Val accuracy: 0.8750 - Val loss: 0.3321 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0831 - Val accuracy: 0.8750 - Val loss: 0.3290 - LR: 0.00e+00\n","\tBest epoch: 100 - Best val accuracy: 0.8750 - Best val loss: 0.3290\n","\n","\tEpoch 10/100 - Train loss: 0.6263 - Val accuracy: 0.1250 - Val loss: 1.1058 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.4078 - Val accuracy: 0.2500 - Val loss: 1.1969 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.2596 - Val accuracy: 0.2500 - Val loss: 1.3452 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.1679 - Val accuracy: 0.3750 - Val loss: 1.1743 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.1338 - Val accuracy: 0.7500 - Val loss: 0.7315 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.1075 - Val accuracy: 0.7500 - Val loss: 0.5984 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0837 - Val accuracy: 0.7500 - Val loss: 0.6222 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0666 - Val accuracy: 0.7500 - Val loss: 0.6499 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0670 - Val accuracy: 0.7500 - Val loss: 0.6641 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0626 - Val accuracy: 0.7500 - Val loss: 0.6707 - LR: 0.00e+00\n","\tBest epoch: 61 - Best val accuracy: 0.7500 - Best val loss: 0.5983\n","\n","\tEpoch 10/100 - Train loss: 0.6914 - Val accuracy: 0.6250 - Val loss: 1.0502 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.4654 - Val accuracy: 0.2500 - Val loss: 1.0843 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.3164 - Val accuracy: 0.2500 - Val loss: 1.1422 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.2024 - Val accuracy: 0.5000 - Val loss: 0.9112 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.1432 - Val accuracy: 0.8750 - Val loss: 0.4783 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.1058 - Val accuracy: 0.8750 - Val loss: 0.2863 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0909 - Val accuracy: 1.0000 - Val loss: 0.2333 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0841 - Val accuracy: 1.0000 - Val loss: 0.2140 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0710 - Val accuracy: 1.0000 - Val loss: 0.2057 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0732 - Val accuracy: 1.0000 - Val loss: 0.2025 - LR: 0.00e+00\n","\tBest epoch: 100 - Best val accuracy: 1.0000 - Best val loss: 0.2025\n","\n","\tEpoch 10/100 - Train loss: 0.5766 - Val accuracy: 0.6250 - Val loss: 1.0924 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.3835 - Val accuracy: 0.2500 - Val loss: 1.2129 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.2936 - Val accuracy: 0.2500 - Val loss: 1.4320 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.2029 - Val accuracy: 0.3750 - Val loss: 1.4816 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.1553 - Val accuracy: 0.5000 - Val loss: 0.9694 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.1329 - Val accuracy: 0.8750 - Val loss: 0.4051 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0966 - Val accuracy: 1.0000 - Val loss: 0.2394 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0908 - Val accuracy: 1.0000 - Val loss: 0.1944 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0781 - Val accuracy: 1.0000 - Val loss: 0.1795 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0803 - Val accuracy: 1.0000 - Val loss: 0.1748 - LR: 0.00e+00\n","\tBest epoch: 100 - Best val accuracy: 1.0000 - Best val loss: 0.1748\n","\n","\tEpoch 10/100 - Train loss: 0.6272 - Val accuracy: 0.2500 - Val loss: 1.0839 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.4472 - Val accuracy: 0.2500 - Val loss: 1.1615 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.2839 - Val accuracy: 0.2500 - Val loss: 1.3370 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.2129 - Val accuracy: 0.3750 - Val loss: 1.2112 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.1641 - Val accuracy: 0.7500 - Val loss: 0.7313 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.1240 - Val accuracy: 0.7500 - Val loss: 0.4660 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.1219 - Val accuracy: 0.8750 - Val loss: 0.3724 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.1109 - Val accuracy: 0.8750 - Val loss: 0.3412 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0971 - Val accuracy: 0.8750 - Val loss: 0.3293 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0855 - Val accuracy: 0.8750 - Val loss: 0.3257 - LR: 0.00e+00\n","\tBest epoch: 100 - Best val accuracy: 0.8750 - Best val loss: 0.3257\n","\n","Source class: WAL | Domain: 34 | Accuracy: 0.8556 | Loss: 0.3490\n","\n","Domain: 35\n","x_dp_dom.shape: (48, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Training and evaluating on Dp data via cross-validation...\n","\tEpoch 10/100 - Train loss: 0.6834 - Val accuracy: 0.2500 - Val loss: 1.1046 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.4457 - Val accuracy: 0.2500 - Val loss: 1.1699 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.3168 - Val accuracy: 0.2500 - Val loss: 1.2512 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.2358 - Val accuracy: 0.2500 - Val loss: 1.0461 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.1793 - Val accuracy: 0.8750 - Val loss: 0.5560 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.1591 - Val accuracy: 0.8750 - Val loss: 0.3003 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.1172 - Val accuracy: 0.8750 - Val loss: 0.2278 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.1168 - Val accuracy: 1.0000 - Val loss: 0.1990 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.1088 - Val accuracy: 1.0000 - Val loss: 0.1870 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.1011 - Val accuracy: 1.0000 - Val loss: 0.1822 - LR: 0.00e+00\n","\tBest epoch: 100 - Best val accuracy: 1.0000 - Best val loss: 0.1822\n","\n","\tEpoch 10/100 - Train loss: 0.6385 - Val accuracy: 0.2500 - Val loss: 1.1099 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.4033 - Val accuracy: 0.2500 - Val loss: 1.2446 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.3195 - Val accuracy: 0.2500 - Val loss: 1.4849 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.2627 - Val accuracy: 0.2500 - Val loss: 1.5683 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.2257 - Val accuracy: 0.2500 - Val loss: 1.1099 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.2068 - Val accuracy: 0.8750 - Val loss: 0.4458 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.1797 - Val accuracy: 0.8750 - Val loss: 0.2637 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.1659 - Val accuracy: 0.8750 - Val loss: 0.2321 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.1539 - Val accuracy: 0.8750 - Val loss: 0.2230 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.1618 - Val accuracy: 0.8750 - Val loss: 0.2201 - LR: 0.00e+00\n","\tBest epoch: 100 - Best val accuracy: 0.8750 - Best val loss: 0.2201\n","\n","\tEpoch 10/100 - Train loss: 0.6635 - Val accuracy: 0.1250 - Val loss: 1.1082 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.4556 - Val accuracy: 0.2500 - Val loss: 1.1890 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.3472 - Val accuracy: 0.2500 - Val loss: 1.3776 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.2946 - Val accuracy: 0.2500 - Val loss: 1.4412 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.2513 - Val accuracy: 0.3750 - Val loss: 1.0453 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.2236 - Val accuracy: 0.8750 - Val loss: 0.5091 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.2046 - Val accuracy: 0.8750 - Val loss: 0.3331 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.1776 - Val accuracy: 0.8750 - Val loss: 0.2870 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.1814 - Val accuracy: 0.8750 - Val loss: 0.2728 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.1774 - Val accuracy: 0.8750 - Val loss: 0.2677 - LR: 0.00e+00\n","\tBest epoch: 100 - Best val accuracy: 0.8750 - Best val loss: 0.2677\n","\n","\tEpoch 10/100 - Train loss: 0.5257 - Val accuracy: 0.2500 - Val loss: 1.1059 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.3428 - Val accuracy: 0.2500 - Val loss: 1.1474 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.2544 - Val accuracy: 0.2500 - Val loss: 1.2654 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.1992 - Val accuracy: 0.2500 - Val loss: 1.1932 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.1581 - Val accuracy: 0.7500 - Val loss: 0.6860 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.1286 - Val accuracy: 0.8750 - Val loss: 0.3485 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.1133 - Val accuracy: 0.8750 - Val loss: 0.2589 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.1068 - Val accuracy: 0.8750 - Val loss: 0.2306 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0873 - Val accuracy: 1.0000 - Val loss: 0.2196 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.1009 - Val accuracy: 1.0000 - Val loss: 0.2157 - LR: 0.00e+00\n","\tBest epoch: 100 - Best val accuracy: 1.0000 - Best val loss: 0.2157\n","\n","\tEpoch 10/100 - Train loss: 0.6112 - Val accuracy: 0.2500 - Val loss: 1.0864 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.3969 - Val accuracy: 0.2500 - Val loss: 1.1779 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.2762 - Val accuracy: 0.2500 - Val loss: 1.3858 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.2222 - Val accuracy: 0.2500 - Val loss: 1.4240 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.1915 - Val accuracy: 0.3750 - Val loss: 0.9276 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.1620 - Val accuracy: 0.8750 - Val loss: 0.4013 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.1425 - Val accuracy: 0.8750 - Val loss: 0.3025 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.1328 - Val accuracy: 0.8750 - Val loss: 0.2914 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.1204 - Val accuracy: 0.8750 - Val loss: 0.2903 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.1195 - Val accuracy: 0.8750 - Val loss: 0.2904 - LR: 0.00e+00\n","\tBest epoch: 94 - Best val accuracy: 0.8750 - Best val loss: 0.2902\n","\n","Source class: WAL | Domain: 35 | Accuracy: 0.8511 | Loss: 0.3039\n","\n","Domain: 36\n","x_dp_dom.shape: (43, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Training and evaluating on Dp data via cross-validation...\n","\tEpoch 10/100 - Train loss: 0.5732 - Val accuracy: 0.7143 - Val loss: 1.0439 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.3447 - Val accuracy: 0.1429 - Val loss: 1.2201 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.2495 - Val accuracy: 0.1429 - Val loss: 1.5331 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.1995 - Val accuracy: 0.1429 - Val loss: 1.6357 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.1620 - Val accuracy: 0.4286 - Val loss: 1.0181 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.1315 - Val accuracy: 1.0000 - Val loss: 0.3620 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.1145 - Val accuracy: 0.8571 - Val loss: 0.2315 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.1042 - Val accuracy: 0.8571 - Val loss: 0.2079 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0995 - Val accuracy: 0.8571 - Val loss: 0.2008 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0848 - Val accuracy: 0.8571 - Val loss: 0.1985 - LR: 0.00e+00\n","\tBest epoch: 100 - Best val accuracy: 0.8571 - Best val loss: 0.1985\n","\n","\tEpoch 10/100 - Train loss: 0.7212 - Val accuracy: 0.7143 - Val loss: 1.0580 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.5208 - Val accuracy: 0.7143 - Val loss: 1.0429 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.3468 - Val accuracy: 0.4286 - Val loss: 1.0793 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.2385 - Val accuracy: 0.4286 - Val loss: 0.9931 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.1835 - Val accuracy: 1.0000 - Val loss: 0.6437 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.1499 - Val accuracy: 1.0000 - Val loss: 0.3322 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.1087 - Val accuracy: 1.0000 - Val loss: 0.2166 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.1036 - Val accuracy: 1.0000 - Val loss: 0.1802 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.1009 - Val accuracy: 1.0000 - Val loss: 0.1667 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0924 - Val accuracy: 1.0000 - Val loss: 0.1622 - LR: 0.00e+00\n","\tBest epoch: 100 - Best val accuracy: 1.0000 - Best val loss: 0.1622\n","\n","\tEpoch 10/100 - Train loss: 0.6114 - Val accuracy: 0.7143 - Val loss: 1.0704 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.3862 - Val accuracy: 0.1429 - Val loss: 1.1231 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.2593 - Val accuracy: 0.2857 - Val loss: 1.2406 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.1731 - Val accuracy: 0.2857 - Val loss: 1.2517 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.1364 - Val accuracy: 0.5714 - Val loss: 0.8422 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.1100 - Val accuracy: 1.0000 - Val loss: 0.3299 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0844 - Val accuracy: 1.0000 - Val loss: 0.1672 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0799 - Val accuracy: 1.0000 - Val loss: 0.1244 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0725 - Val accuracy: 1.0000 - Val loss: 0.1107 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0636 - Val accuracy: 1.0000 - Val loss: 0.1056 - LR: 0.00e+00\n","\tBest epoch: 100 - Best val accuracy: 1.0000 - Best val loss: 0.1056\n","\n","\tEpoch 10/100 - Train loss: 0.5539 - Val accuracy: 0.7143 - Val loss: 1.0521 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.3057 - Val accuracy: 0.1429 - Val loss: 1.1565 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.1980 - Val accuracy: 0.0000 - Val loss: 1.3378 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.1319 - Val accuracy: 0.1429 - Val loss: 1.3618 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.0974 - Val accuracy: 0.2857 - Val loss: 0.9734 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.0761 - Val accuracy: 0.7143 - Val loss: 0.4429 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0603 - Val accuracy: 0.8571 - Val loss: 0.3163 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0564 - Val accuracy: 0.8571 - Val loss: 0.2950 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0521 - Val accuracy: 0.8571 - Val loss: 0.2897 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0469 - Val accuracy: 0.8571 - Val loss: 0.2884 - LR: 0.00e+00\n","\tBest epoch: 100 - Best val accuracy: 0.8571 - Best val loss: 0.2884\n","\n","\tEpoch 10/100 - Train loss: 0.6686 - Val accuracy: 0.7143 - Val loss: 1.0258 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.4488 - Val accuracy: 0.7143 - Val loss: 1.0415 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.3303 - Val accuracy: 0.1429 - Val loss: 1.1249 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.2476 - Val accuracy: 0.4286 - Val loss: 1.0389 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.1925 - Val accuracy: 0.8571 - Val loss: 0.6482 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.1560 - Val accuracy: 1.0000 - Val loss: 0.3728 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.1257 - Val accuracy: 1.0000 - Val loss: 0.2811 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.1139 - Val accuracy: 1.0000 - Val loss: 0.2495 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.1032 - Val accuracy: 1.0000 - Val loss: 0.2373 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0956 - Val accuracy: 1.0000 - Val loss: 0.2329 - LR: 0.00e+00\n","\tBest epoch: 100 - Best val accuracy: 1.0000 - Best val loss: 0.2329\n","\n","Source class: WAL | Domain: 36 | Accuracy: 0.8833 | Loss: 0.2705\n","\n","Domain: 37\n","x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Training and evaluating on Dp data via cross-validation...\n","\tEpoch 10/100 - Train loss: 0.5673 - Val accuracy: 0.7143 - Val loss: 1.0368 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.3715 - Val accuracy: 0.2857 - Val loss: 1.0894 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.2814 - Val accuracy: 0.1429 - Val loss: 1.2088 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.2145 - Val accuracy: 0.1429 - Val loss: 1.1661 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.1486 - Val accuracy: 0.7143 - Val loss: 0.6450 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.1188 - Val accuracy: 0.8571 - Val loss: 0.3537 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.1040 - Val accuracy: 0.8571 - Val loss: 0.2846 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0915 - Val accuracy: 0.8571 - Val loss: 0.2665 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0800 - Val accuracy: 0.8571 - Val loss: 0.2597 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0777 - Val accuracy: 0.8571 - Val loss: 0.2574 - LR: 0.00e+00\n","\tBest epoch: 100 - Best val accuracy: 0.8571 - Best val loss: 0.2574\n","\n","\tEpoch 10/100 - Train loss: 0.5650 - Val accuracy: 0.7143 - Val loss: 1.0732 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.3399 - Val accuracy: 0.1429 - Val loss: 1.1878 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.2676 - Val accuracy: 0.1429 - Val loss: 1.4004 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.1992 - Val accuracy: 0.1429 - Val loss: 1.3755 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.1645 - Val accuracy: 0.7143 - Val loss: 0.8468 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.1419 - Val accuracy: 0.7143 - Val loss: 0.5005 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.1220 - Val accuracy: 0.8571 - Val loss: 0.4102 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.1089 - Val accuracy: 0.8571 - Val loss: 0.3922 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.1019 - Val accuracy: 0.8571 - Val loss: 0.3892 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.1008 - Val accuracy: 0.8571 - Val loss: 0.3888 - LR: 0.00e+00\n","\tBest epoch: 100 - Best val accuracy: 0.8571 - Best val loss: 0.3888\n","\n","\tEpoch 10/100 - Train loss: 0.6316 - Val accuracy: 0.1429 - Val loss: 1.1359 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.3818 - Val accuracy: 0.1429 - Val loss: 1.2311 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.2903 - Val accuracy: 0.1429 - Val loss: 1.4045 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.2164 - Val accuracy: 0.1429 - Val loss: 1.2346 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.1678 - Val accuracy: 0.8571 - Val loss: 0.5764 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.1439 - Val accuracy: 0.8571 - Val loss: 0.3116 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.1174 - Val accuracy: 0.8571 - Val loss: 0.2682 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.1078 - Val accuracy: 0.8571 - Val loss: 0.2598 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0903 - Val accuracy: 0.8571 - Val loss: 0.2581 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0964 - Val accuracy: 0.8571 - Val loss: 0.2581 - LR: 0.00e+00\n","\tBest epoch: 93 - Best val accuracy: 0.8571 - Best val loss: 0.2580\n","\n","\tEpoch 10/100 - Train loss: 0.6526 - Val accuracy: 0.7143 - Val loss: 1.0714 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.4134 - Val accuracy: 0.1429 - Val loss: 1.1306 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.3004 - Val accuracy: 0.1429 - Val loss: 1.3095 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.2188 - Val accuracy: 0.1429 - Val loss: 1.3206 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.1767 - Val accuracy: 0.7143 - Val loss: 0.7722 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.1490 - Val accuracy: 0.8571 - Val loss: 0.3648 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.1408 - Val accuracy: 0.8571 - Val loss: 0.2512 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.1204 - Val accuracy: 0.8571 - Val loss: 0.2156 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.1074 - Val accuracy: 1.0000 - Val loss: 0.2014 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.1023 - Val accuracy: 1.0000 - Val loss: 0.1962 - LR: 0.00e+00\n","\tBest epoch: 100 - Best val accuracy: 1.0000 - Best val loss: 0.1962\n","\n","\tEpoch 10/100 - Train loss: 0.5629 - Val accuracy: 0.7143 - Val loss: 1.0504 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.3476 - Val accuracy: 0.1429 - Val loss: 1.1665 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.2370 - Val accuracy: 0.1429 - Val loss: 1.4511 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.1718 - Val accuracy: 0.1429 - Val loss: 1.5248 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.1302 - Val accuracy: 0.7143 - Val loss: 0.8726 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.1086 - Val accuracy: 0.8571 - Val loss: 0.4477 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0858 - Val accuracy: 0.8571 - Val loss: 0.3465 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0843 - Val accuracy: 0.8571 - Val loss: 0.3156 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0677 - Val accuracy: 0.8571 - Val loss: 0.3057 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0620 - Val accuracy: 0.8571 - Val loss: 0.3027 - LR: 0.00e+00\n","\tBest epoch: 100 - Best val accuracy: 0.8571 - Best val loss: 0.3027\n","\n","Source class: WAL | Domain: 37 | Accuracy: 0.8306 | Loss: 0.3128\n","\n","Domain: 38\n","x_dp_dom.shape: (47, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Training and evaluating on Dp data via cross-validation...\n","\tEpoch 10/100 - Train loss: 0.5536 - Val accuracy: 0.6250 - Val loss: 1.0943 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.3345 - Val accuracy: 0.2500 - Val loss: 1.2067 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.2126 - Val accuracy: 0.2500 - Val loss: 1.4028 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.1583 - Val accuracy: 0.1250 - Val loss: 1.5378 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.1087 - Val accuracy: 0.6250 - Val loss: 1.1575 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.0945 - Val accuracy: 0.7500 - Val loss: 0.9961 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0805 - Val accuracy: 0.7500 - Val loss: 1.0710 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0597 - Val accuracy: 0.7500 - Val loss: 1.1233 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0610 - Val accuracy: 0.7500 - Val loss: 1.1488 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0519 - Val accuracy: 0.7500 - Val loss: 1.1586 - LR: 0.00e+00\n","\tBest epoch: 58 - Best val accuracy: 0.7500 - Best val loss: 0.9909\n","\n","\tEpoch 10/100 - Train loss: 0.6724 - Val accuracy: 0.6250 - Val loss: 1.0766 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.4598 - Val accuracy: 0.2500 - Val loss: 1.1600 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.3078 - Val accuracy: 0.2500 - Val loss: 1.3774 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.2252 - Val accuracy: 0.2500 - Val loss: 1.3961 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.1673 - Val accuracy: 0.7500 - Val loss: 0.8850 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.1295 - Val accuracy: 0.8750 - Val loss: 0.4651 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.1081 - Val accuracy: 0.8750 - Val loss: 0.3690 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0957 - Val accuracy: 0.7500 - Val loss: 0.3546 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0833 - Val accuracy: 0.7500 - Val loss: 0.3490 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0809 - Val accuracy: 0.7500 - Val loss: 0.3484 - LR: 0.00e+00\n","\tBest epoch: 100 - Best val accuracy: 0.7500 - Best val loss: 0.3484\n","\n","\tEpoch 10/100 - Train loss: 0.6743 - Val accuracy: 0.2500 - Val loss: 1.1061 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.4357 - Val accuracy: 0.1250 - Val loss: 1.1200 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.2995 - Val accuracy: 0.3750 - Val loss: 1.1337 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.2193 - Val accuracy: 0.5000 - Val loss: 0.9336 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.1708 - Val accuracy: 0.8750 - Val loss: 0.5367 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.1347 - Val accuracy: 0.8750 - Val loss: 0.3524 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.1067 - Val accuracy: 0.8750 - Val loss: 0.3043 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0891 - Val accuracy: 0.8750 - Val loss: 0.2928 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0863 - Val accuracy: 0.8750 - Val loss: 0.2890 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0790 - Val accuracy: 0.8750 - Val loss: 0.2877 - LR: 0.00e+00\n","\tBest epoch: 100 - Best val accuracy: 0.8750 - Best val loss: 0.2877\n","\n","\tEpoch 10/100 - Train loss: 0.6058 - Val accuracy: 0.6250 - Val loss: 1.0667 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.3941 - Val accuracy: 0.2500 - Val loss: 1.0911 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.2988 - Val accuracy: 0.2500 - Val loss: 1.1164 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.2344 - Val accuracy: 0.5000 - Val loss: 0.9098 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.1850 - Val accuracy: 0.8750 - Val loss: 0.5081 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.1573 - Val accuracy: 0.8750 - Val loss: 0.3178 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.1355 - Val accuracy: 0.8750 - Val loss: 0.2656 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.1138 - Val accuracy: 0.8750 - Val loss: 0.2477 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.1150 - Val accuracy: 0.8750 - Val loss: 0.2405 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.1017 - Val accuracy: 0.8750 - Val loss: 0.2380 - LR: 0.00e+00\n","\tBest epoch: 100 - Best val accuracy: 0.8750 - Best val loss: 0.2380\n","\n","\tEpoch 10/100 - Train loss: 0.6659 - Val accuracy: 0.6250 - Val loss: 1.0838 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.4462 - Val accuracy: 0.2500 - Val loss: 1.1237 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.3255 - Val accuracy: 0.2500 - Val loss: 1.2505 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.2425 - Val accuracy: 0.2500 - Val loss: 1.2418 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.1807 - Val accuracy: 0.7500 - Val loss: 0.7705 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.1441 - Val accuracy: 0.8750 - Val loss: 0.3677 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.1139 - Val accuracy: 0.8750 - Val loss: 0.2644 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.1125 - Val accuracy: 0.8750 - Val loss: 0.2364 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.1032 - Val accuracy: 0.8750 - Val loss: 0.2260 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0937 - Val accuracy: 0.8750 - Val loss: 0.2222 - LR: 0.00e+00\n","\tBest epoch: 100 - Best val accuracy: 0.8750 - Best val loss: 0.2222\n","\n","Source class: WAL | Domain: 38 | Accuracy: 0.7911 | Loss: 0.7522\n","\n","Domain: 39\n","x_dp_dom.shape: (54, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Training and evaluating on Dp data via cross-validation...\n","\tEpoch 10/100 - Train loss: 0.5122 - Val accuracy: 0.2222 - Val loss: 1.1033 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.2797 - Val accuracy: 0.2222 - Val loss: 1.2039 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.1367 - Val accuracy: 0.4444 - Val loss: 1.3800 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.0714 - Val accuracy: 0.4444 - Val loss: 1.4373 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.0465 - Val accuracy: 0.4444 - Val loss: 0.9687 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.0353 - Val accuracy: 0.8889 - Val loss: 0.4031 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0298 - Val accuracy: 0.8889 - Val loss: 0.2244 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0234 - Val accuracy: 0.8889 - Val loss: 0.1688 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0225 - Val accuracy: 0.8889 - Val loss: 0.1493 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0227 - Val accuracy: 0.8889 - Val loss: 0.1424 - LR: 0.00e+00\n","\tBest epoch: 100 - Best val accuracy: 0.8889 - Best val loss: 0.1424\n","\n","\tEpoch 10/100 - Train loss: 0.5476 - Val accuracy: 0.2222 - Val loss: 1.0980 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.2802 - Val accuracy: 0.2222 - Val loss: 1.1610 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.1559 - Val accuracy: 0.3333 - Val loss: 1.2137 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.0851 - Val accuracy: 0.4444 - Val loss: 1.0194 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.0578 - Val accuracy: 0.8889 - Val loss: 0.4262 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.0392 - Val accuracy: 1.0000 - Val loss: 0.1090 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0335 - Val accuracy: 1.0000 - Val loss: 0.0516 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0288 - Val accuracy: 1.0000 - Val loss: 0.0383 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0283 - Val accuracy: 1.0000 - Val loss: 0.0337 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0273 - Val accuracy: 1.0000 - Val loss: 0.0321 - LR: 0.00e+00\n","\tBest epoch: 100 - Best val accuracy: 1.0000 - Best val loss: 0.0321\n","\n","\tEpoch 10/100 - Train loss: 0.5628 - Val accuracy: 0.2222 - Val loss: 1.0815 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.3315 - Val accuracy: 0.4444 - Val loss: 1.0910 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.1859 - Val accuracy: 0.4444 - Val loss: 1.0863 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.1253 - Val accuracy: 0.4444 - Val loss: 0.9341 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.0907 - Val accuracy: 0.8889 - Val loss: 0.4478 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.0645 - Val accuracy: 1.0000 - Val loss: 0.1409 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0548 - Val accuracy: 1.0000 - Val loss: 0.0661 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0462 - Val accuracy: 1.0000 - Val loss: 0.0463 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0419 - Val accuracy: 1.0000 - Val loss: 0.0395 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0421 - Val accuracy: 1.0000 - Val loss: 0.0371 - LR: 0.00e+00\n","\tBest epoch: 100 - Best val accuracy: 1.0000 - Best val loss: 0.0371\n","\n","\tEpoch 10/100 - Train loss: 0.5954 - Val accuracy: 0.5556 - Val loss: 1.0626 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.3410 - Val accuracy: 0.2222 - Val loss: 1.0341 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.2009 - Val accuracy: 0.4444 - Val loss: 1.0003 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.1212 - Val accuracy: 0.4444 - Val loss: 0.9128 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.0810 - Val accuracy: 0.6667 - Val loss: 0.5312 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.0606 - Val accuracy: 1.0000 - Val loss: 0.1757 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0490 - Val accuracy: 1.0000 - Val loss: 0.0828 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0439 - Val accuracy: 1.0000 - Val loss: 0.0588 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0369 - Val accuracy: 1.0000 - Val loss: 0.0507 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0374 - Val accuracy: 1.0000 - Val loss: 0.0480 - LR: 0.00e+00\n","\tBest epoch: 100 - Best val accuracy: 1.0000 - Best val loss: 0.0480\n","\n","\tEpoch 10/100 - Train loss: 0.5573 - Val accuracy: 0.2222 - Val loss: 1.0863 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.2975 - Val accuracy: 0.4444 - Val loss: 1.0860 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.1575 - Val accuracy: 0.4444 - Val loss: 1.0691 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.0976 - Val accuracy: 0.5556 - Val loss: 0.9074 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.0635 - Val accuracy: 0.7778 - Val loss: 0.4189 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.0484 - Val accuracy: 0.8889 - Val loss: 0.1649 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0394 - Val accuracy: 1.0000 - Val loss: 0.1080 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0329 - Val accuracy: 1.0000 - Val loss: 0.0903 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0305 - Val accuracy: 1.0000 - Val loss: 0.0837 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0314 - Val accuracy: 1.0000 - Val loss: 0.0814 - LR: 0.00e+00\n","\tBest epoch: 100 - Best val accuracy: 1.0000 - Best val loss: 0.0814\n","\n","Source class: WAL | Domain: 39 | Accuracy: 1.0000 | Loss: 0.0603\n","\n","Domain: 40\n","x_dp_dom.shape: (44, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Training and evaluating on Dp data via cross-validation...\n","\tEpoch 10/100 - Train loss: 0.5843 - Val accuracy: 0.5714 - Val loss: 1.0781 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.3824 - Val accuracy: 0.2857 - Val loss: 1.1171 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.2592 - Val accuracy: 0.2857 - Val loss: 1.2209 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.1725 - Val accuracy: 0.4286 - Val loss: 1.2490 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.1349 - Val accuracy: 0.5714 - Val loss: 0.9166 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.1051 - Val accuracy: 0.8571 - Val loss: 0.5050 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0877 - Val accuracy: 0.8571 - Val loss: 0.3841 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0802 - Val accuracy: 0.8571 - Val loss: 0.3587 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0692 - Val accuracy: 0.8571 - Val loss: 0.3521 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0687 - Val accuracy: 0.8571 - Val loss: 0.3504 - LR: 0.00e+00\n","\tBest epoch: 100 - Best val accuracy: 0.8571 - Best val loss: 0.3504\n","\n","\tEpoch 10/100 - Train loss: 0.5884 - Val accuracy: 0.5714 - Val loss: 1.0700 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.3834 - Val accuracy: 0.5714 - Val loss: 1.0910 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.2453 - Val accuracy: 0.1429 - Val loss: 1.1940 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.1581 - Val accuracy: 0.1429 - Val loss: 1.1535 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.1091 - Val accuracy: 0.5714 - Val loss: 0.8157 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.0860 - Val accuracy: 0.7143 - Val loss: 0.5886 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0755 - Val accuracy: 0.7143 - Val loss: 0.5449 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0766 - Val accuracy: 0.7143 - Val loss: 0.5514 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0600 - Val accuracy: 0.7143 - Val loss: 0.5584 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0605 - Val accuracy: 0.7143 - Val loss: 0.5602 - LR: 0.00e+00\n","\tBest epoch: 70 - Best val accuracy: 0.7143 - Best val loss: 0.5449\n","\n","\tEpoch 10/100 - Train loss: 0.6691 - Val accuracy: 0.5714 - Val loss: 1.0766 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.3938 - Val accuracy: 0.2857 - Val loss: 1.1190 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.2473 - Val accuracy: 0.2857 - Val loss: 1.2405 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.1691 - Val accuracy: 0.4286 - Val loss: 1.0956 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.1349 - Val accuracy: 0.8571 - Val loss: 0.5643 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.0986 - Val accuracy: 0.8571 - Val loss: 0.3366 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0853 - Val accuracy: 0.8571 - Val loss: 0.2956 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0678 - Val accuracy: 0.8571 - Val loss: 0.2853 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0675 - Val accuracy: 0.8571 - Val loss: 0.2811 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0700 - Val accuracy: 0.8571 - Val loss: 0.2795 - LR: 0.00e+00\n","\tBest epoch: 100 - Best val accuracy: 0.8571 - Best val loss: 0.2795\n","\n","\tEpoch 10/100 - Train loss: 0.6460 - Val accuracy: 0.7143 - Val loss: 1.0675 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.3869 - Val accuracy: 0.1429 - Val loss: 1.1402 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.2476 - Val accuracy: 0.1429 - Val loss: 1.3101 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.1672 - Val accuracy: 0.1429 - Val loss: 1.2530 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.1160 - Val accuracy: 0.8571 - Val loss: 0.6323 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.0895 - Val accuracy: 0.8571 - Val loss: 0.3087 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0826 - Val accuracy: 0.8571 - Val loss: 0.2374 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0655 - Val accuracy: 0.8571 - Val loss: 0.2198 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0647 - Val accuracy: 0.8571 - Val loss: 0.2146 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0632 - Val accuracy: 0.8571 - Val loss: 0.2127 - LR: 0.00e+00\n","\tBest epoch: 100 - Best val accuracy: 0.8571 - Best val loss: 0.2127\n","\n","\tEpoch 10/100 - Train loss: 0.5163 - Val accuracy: 0.2500 - Val loss: 1.1156 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.3500 - Val accuracy: 0.2500 - Val loss: 1.1846 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.2484 - Val accuracy: 0.2500 - Val loss: 1.2927 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.1888 - Val accuracy: 0.2500 - Val loss: 1.2501 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.1517 - Val accuracy: 0.7500 - Val loss: 0.8037 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.1094 - Val accuracy: 1.0000 - Val loss: 0.3433 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0999 - Val accuracy: 1.0000 - Val loss: 0.2222 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0914 - Val accuracy: 1.0000 - Val loss: 0.2092 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0886 - Val accuracy: 1.0000 - Val loss: 0.2117 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0839 - Val accuracy: 0.8750 - Val loss: 0.2153 - LR: 0.00e+00\n","\tBest epoch: 80 - Best val accuracy: 1.0000 - Best val loss: 0.2092\n","\n","Source class: WAL | Domain: 40 | Accuracy: 0.8861 | Loss: 0.2814\n","\n","Domain: 41\n","x_dp_dom.shape: (45, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Training and evaluating on Dp data via cross-validation...\n","\tEpoch 10/100 - Train loss: 0.6481 - Val accuracy: 0.6250 - Val loss: 1.0574 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.3584 - Val accuracy: 0.6250 - Val loss: 0.9758 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.2299 - Val accuracy: 0.6250 - Val loss: 0.8815 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.1525 - Val accuracy: 0.6250 - Val loss: 0.7106 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.1023 - Val accuracy: 0.6250 - Val loss: 0.5829 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.0850 - Val accuracy: 0.7500 - Val loss: 0.5535 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0687 - Val accuracy: 0.7500 - Val loss: 0.5584 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0586 - Val accuracy: 0.7500 - Val loss: 0.5649 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0577 - Val accuracy: 0.7500 - Val loss: 0.5696 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0530 - Val accuracy: 0.7500 - Val loss: 0.5721 - LR: 0.00e+00\n","\tBest epoch: 62 - Best val accuracy: 0.7500 - Best val loss: 0.5528\n","\n","\tEpoch 10/100 - Train loss: 0.6220 - Val accuracy: 0.6250 - Val loss: 1.0477 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.3503 - Val accuracy: 0.6250 - Val loss: 0.9648 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.2353 - Val accuracy: 0.7500 - Val loss: 0.8306 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.1602 - Val accuracy: 0.8750 - Val loss: 0.5954 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.1192 - Val accuracy: 0.8750 - Val loss: 0.4182 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.0866 - Val accuracy: 0.8750 - Val loss: 0.3751 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0789 - Val accuracy: 0.8750 - Val loss: 0.3854 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0657 - Val accuracy: 0.8750 - Val loss: 0.3989 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0624 - Val accuracy: 0.8750 - Val loss: 0.4061 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0637 - Val accuracy: 0.8750 - Val loss: 0.4094 - LR: 0.00e+00\n","\tBest epoch: 61 - Best val accuracy: 0.8750 - Best val loss: 0.3749\n","\n","\tEpoch 10/100 - Train loss: 0.6323 - Val accuracy: 0.6250 - Val loss: 1.0144 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.3794 - Val accuracy: 0.6250 - Val loss: 0.9314 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.2499 - Val accuracy: 0.6250 - Val loss: 0.8239 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.1805 - Val accuracy: 0.7500 - Val loss: 0.6657 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.1273 - Val accuracy: 0.7500 - Val loss: 0.5081 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.0958 - Val accuracy: 0.7500 - Val loss: 0.4224 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0814 - Val accuracy: 0.7500 - Val loss: 0.3901 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0807 - Val accuracy: 0.8750 - Val loss: 0.3773 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0607 - Val accuracy: 0.8750 - Val loss: 0.3718 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0675 - Val accuracy: 0.8750 - Val loss: 0.3701 - LR: 0.00e+00\n","\tBest epoch: 100 - Best val accuracy: 0.8750 - Best val loss: 0.3701\n","\n","\tEpoch 10/100 - Train loss: 0.7054 - Val accuracy: 0.6250 - Val loss: 1.0240 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.4563 - Val accuracy: 0.6250 - Val loss: 0.9134 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.3013 - Val accuracy: 0.6250 - Val loss: 0.7893 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.1935 - Val accuracy: 0.8750 - Val loss: 0.6051 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.1526 - Val accuracy: 0.8750 - Val loss: 0.4484 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.1204 - Val accuracy: 0.8750 - Val loss: 0.3951 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0948 - Val accuracy: 0.8750 - Val loss: 0.3848 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0944 - Val accuracy: 0.8750 - Val loss: 0.3858 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0806 - Val accuracy: 0.8750 - Val loss: 0.3863 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0912 - Val accuracy: 0.8750 - Val loss: 0.3866 - LR: 0.00e+00\n","\tBest epoch: 71 - Best val accuracy: 0.8750 - Best val loss: 0.3846\n","\n","\tEpoch 10/100 - Train loss: 0.6657 - Val accuracy: 0.6250 - Val loss: 1.0492 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.3562 - Val accuracy: 0.6250 - Val loss: 0.9267 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.1851 - Val accuracy: 0.6250 - Val loss: 0.7970 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.1025 - Val accuracy: 0.7500 - Val loss: 0.7066 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.0660 - Val accuracy: 0.7500 - Val loss: 0.7502 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.0493 - Val accuracy: 0.7500 - Val loss: 0.8120 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0378 - Val accuracy: 0.7500 - Val loss: 0.8529 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0378 - Val accuracy: 0.7500 - Val loss: 0.8776 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0333 - Val accuracy: 0.7500 - Val loss: 0.8909 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0301 - Val accuracy: 0.7500 - Val loss: 0.8952 - LR: 0.00e+00\n","\tBest epoch: 41 - Best val accuracy: 0.7500 - Best val loss: 0.7058\n","\n","Source class: WAL | Domain: 41 | Accuracy: 0.8889 | Loss: 0.4037\n","\n","Domain: 42\n","x_dp_dom.shape: (46, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Training and evaluating on Dp data via cross-validation...\n","\tEpoch 10/100 - Train loss: 0.5905 - Val accuracy: 0.6250 - Val loss: 1.0674 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.3630 - Val accuracy: 0.2500 - Val loss: 1.1458 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.2368 - Val accuracy: 0.2500 - Val loss: 1.3014 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.1539 - Val accuracy: 0.2500 - Val loss: 1.2667 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.1116 - Val accuracy: 0.7500 - Val loss: 0.7821 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.0822 - Val accuracy: 0.8750 - Val loss: 0.3982 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0693 - Val accuracy: 0.8750 - Val loss: 0.2700 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0580 - Val accuracy: 0.8750 - Val loss: 0.2307 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0531 - Val accuracy: 0.8750 - Val loss: 0.2156 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0554 - Val accuracy: 0.8750 - Val loss: 0.2102 - LR: 0.00e+00\n","\tBest epoch: 100 - Best val accuracy: 0.8750 - Best val loss: 0.2102\n","\n","\tEpoch 10/100 - Train loss: 0.6001 - Val accuracy: 0.1250 - Val loss: 1.1408 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.4057 - Val accuracy: 0.2500 - Val loss: 1.2378 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.2827 - Val accuracy: 0.2500 - Val loss: 1.4059 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.1960 - Val accuracy: 0.2500 - Val loss: 1.1998 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.1488 - Val accuracy: 0.8750 - Val loss: 0.5086 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.1076 - Val accuracy: 1.0000 - Val loss: 0.2678 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.1044 - Val accuracy: 1.0000 - Val loss: 0.2227 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0980 - Val accuracy: 1.0000 - Val loss: 0.2081 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0835 - Val accuracy: 1.0000 - Val loss: 0.2013 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0808 - Val accuracy: 1.0000 - Val loss: 0.1986 - LR: 0.00e+00\n","\tBest epoch: 100 - Best val accuracy: 1.0000 - Best val loss: 0.1986\n","\n","\tEpoch 10/100 - Train loss: 0.5992 - Val accuracy: 0.2500 - Val loss: 1.1146 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.3735 - Val accuracy: 0.2500 - Val loss: 1.2115 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.2707 - Val accuracy: 0.2500 - Val loss: 1.3772 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.2164 - Val accuracy: 0.2500 - Val loss: 1.2280 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.1483 - Val accuracy: 1.0000 - Val loss: 0.6035 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.1226 - Val accuracy: 1.0000 - Val loss: 0.2588 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.1053 - Val accuracy: 1.0000 - Val loss: 0.1797 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0914 - Val accuracy: 1.0000 - Val loss: 0.1561 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0855 - Val accuracy: 1.0000 - Val loss: 0.1461 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0803 - Val accuracy: 1.0000 - Val loss: 0.1425 - LR: 0.00e+00\n","\tBest epoch: 100 - Best val accuracy: 1.0000 - Best val loss: 0.1425\n","\n","\tEpoch 10/100 - Train loss: 0.6154 - Val accuracy: 0.6250 - Val loss: 1.0684 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.3846 - Val accuracy: 0.2500 - Val loss: 1.1094 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.2359 - Val accuracy: 0.2500 - Val loss: 1.2849 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.1803 - Val accuracy: 0.2500 - Val loss: 1.2022 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.1352 - Val accuracy: 0.8750 - Val loss: 0.6269 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.0984 - Val accuracy: 0.8750 - Val loss: 0.3677 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0923 - Val accuracy: 0.8750 - Val loss: 0.3194 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0878 - Val accuracy: 0.8750 - Val loss: 0.3090 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0689 - Val accuracy: 0.8750 - Val loss: 0.3063 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0670 - Val accuracy: 0.8750 - Val loss: 0.3058 - LR: 0.00e+00\n","\tBest epoch: 100 - Best val accuracy: 0.8750 - Best val loss: 0.3058\n","\n","\tEpoch 10/100 - Train loss: 0.5949 - Val accuracy: 0.2500 - Val loss: 1.0737 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.3567 - Val accuracy: 0.2500 - Val loss: 1.1947 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.2301 - Val accuracy: 0.2500 - Val loss: 1.4149 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.1663 - Val accuracy: 0.2500 - Val loss: 1.4542 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.1305 - Val accuracy: 0.6250 - Val loss: 0.8849 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.1006 - Val accuracy: 0.8750 - Val loss: 0.3941 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0789 - Val accuracy: 0.8750 - Val loss: 0.2612 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0667 - Val accuracy: 1.0000 - Val loss: 0.2242 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0657 - Val accuracy: 1.0000 - Val loss: 0.2111 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0720 - Val accuracy: 1.0000 - Val loss: 0.2063 - LR: 0.00e+00\n","\tBest epoch: 100 - Best val accuracy: 1.0000 - Best val loss: 0.2063\n","\n","Source class: WAL | Domain: 42 | Accuracy: 0.9133 | Loss: 0.2894\n","\n","Domain: 43\n","x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Training and evaluating on Dp data via cross-validation...\n","\tEpoch 10/100 - Train loss: 0.6265 - Val accuracy: 0.7143 - Val loss: 1.0355 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.4058 - Val accuracy: 0.1429 - Val loss: 1.0892 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.2776 - Val accuracy: 0.1429 - Val loss: 1.2294 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.1989 - Val accuracy: 0.1429 - Val loss: 1.2007 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.1585 - Val accuracy: 0.7143 - Val loss: 0.7950 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.1409 - Val accuracy: 0.8571 - Val loss: 0.4905 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.1161 - Val accuracy: 0.8571 - Val loss: 0.4120 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0967 - Val accuracy: 0.8571 - Val loss: 0.3914 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0960 - Val accuracy: 0.8571 - Val loss: 0.3848 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0913 - Val accuracy: 0.8571 - Val loss: 0.3829 - LR: 0.00e+00\n","\tBest epoch: 100 - Best val accuracy: 0.8571 - Best val loss: 0.3829\n","\n","\tEpoch 10/100 - Train loss: 0.6580 - Val accuracy: 0.7143 - Val loss: 1.0334 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.4293 - Val accuracy: 0.5714 - Val loss: 1.0544 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.2763 - Val accuracy: 0.2857 - Val loss: 1.1475 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.2071 - Val accuracy: 0.4286 - Val loss: 1.0866 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.1490 - Val accuracy: 0.7143 - Val loss: 0.7101 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.1222 - Val accuracy: 0.7143 - Val loss: 0.4657 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.1018 - Val accuracy: 0.7143 - Val loss: 0.4253 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0806 - Val accuracy: 0.7143 - Val loss: 0.4278 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0850 - Val accuracy: 0.7143 - Val loss: 0.4319 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0871 - Val accuracy: 0.7143 - Val loss: 0.4340 - LR: 0.00e+00\n","\tBest epoch: 72 - Best val accuracy: 0.7143 - Best val loss: 0.4249\n","\n","\tEpoch 10/100 - Train loss: 0.6301 - Val accuracy: 0.7143 - Val loss: 1.0668 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.3742 - Val accuracy: 0.1429 - Val loss: 1.1633 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.2384 - Val accuracy: 0.1429 - Val loss: 1.3865 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.1618 - Val accuracy: 0.1429 - Val loss: 1.4318 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.1283 - Val accuracy: 0.7143 - Val loss: 0.8807 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.0972 - Val accuracy: 0.8571 - Val loss: 0.4935 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0842 - Val accuracy: 0.8571 - Val loss: 0.4307 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0722 - Val accuracy: 0.8571 - Val loss: 0.4276 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0831 - Val accuracy: 0.8571 - Val loss: 0.4304 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0700 - Val accuracy: 0.8571 - Val loss: 0.4325 - LR: 0.00e+00\n","\tBest epoch: 77 - Best val accuracy: 0.8571 - Best val loss: 0.4271\n","\n","\tEpoch 10/100 - Train loss: 0.7190 - Val accuracy: 0.1429 - Val loss: 1.0808 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.4948 - Val accuracy: 0.1429 - Val loss: 1.0694 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.3541 - Val accuracy: 0.1429 - Val loss: 1.1234 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.2745 - Val accuracy: 0.1429 - Val loss: 1.0459 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.2210 - Val accuracy: 0.8571 - Val loss: 0.6229 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.1790 - Val accuracy: 0.8571 - Val loss: 0.3267 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.1515 - Val accuracy: 0.8571 - Val loss: 0.2621 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.1365 - Val accuracy: 0.8571 - Val loss: 0.2459 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.1276 - Val accuracy: 0.8571 - Val loss: 0.2401 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.1218 - Val accuracy: 0.8571 - Val loss: 0.2382 - LR: 0.00e+00\n","\tBest epoch: 100 - Best val accuracy: 0.8571 - Best val loss: 0.2382\n","\n","\tEpoch 10/100 - Train loss: 0.6071 - Val accuracy: 0.1429 - Val loss: 1.0952 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.4065 - Val accuracy: 0.1429 - Val loss: 1.0907 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.3090 - Val accuracy: 0.2857 - Val loss: 1.0968 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.2316 - Val accuracy: 0.7143 - Val loss: 0.8315 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.1824 - Val accuracy: 1.0000 - Val loss: 0.3986 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.1498 - Val accuracy: 1.0000 - Val loss: 0.2455 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.1298 - Val accuracy: 1.0000 - Val loss: 0.2009 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.1247 - Val accuracy: 1.0000 - Val loss: 0.1843 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.1179 - Val accuracy: 1.0000 - Val loss: 0.1761 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.1131 - Val accuracy: 1.0000 - Val loss: 0.1729 - LR: 0.00e+00\n","\tBest epoch: 100 - Best val accuracy: 1.0000 - Best val loss: 0.1729\n","\n","Source class: WAL | Domain: 43 | Accuracy: 0.8306 | Loss: 0.3811\n","\n","Domain: 44\n","x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Training and evaluating on Dp data via cross-validation...\n","\tEpoch 10/100 - Train loss: 0.5363 - Val accuracy: 0.7143 - Val loss: 1.0578 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.3083 - Val accuracy: 0.1429 - Val loss: 1.1767 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.2162 - Val accuracy: 0.1429 - Val loss: 1.3616 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.1514 - Val accuracy: 0.1429 - Val loss: 1.3292 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.1127 - Val accuracy: 0.5714 - Val loss: 0.7914 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.0914 - Val accuracy: 0.8571 - Val loss: 0.3986 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0761 - Val accuracy: 0.8571 - Val loss: 0.3389 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0652 - Val accuracy: 0.8571 - Val loss: 0.3448 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0615 - Val accuracy: 0.8571 - Val loss: 0.3527 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0553 - Val accuracy: 0.8571 - Val loss: 0.3570 - LR: 0.00e+00\n","\tBest epoch: 71 - Best val accuracy: 0.8571 - Best val loss: 0.3385\n","\n","\tEpoch 10/100 - Train loss: 0.5892 - Val accuracy: 0.7143 - Val loss: 1.0258 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.3586 - Val accuracy: 0.7143 - Val loss: 1.0750 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.2431 - Val accuracy: 0.1429 - Val loss: 1.2746 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.1653 - Val accuracy: 0.1429 - Val loss: 1.3690 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.1310 - Val accuracy: 0.5714 - Val loss: 0.7792 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.0983 - Val accuracy: 0.8571 - Val loss: 0.4069 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0868 - Val accuracy: 0.8571 - Val loss: 0.3659 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0774 - Val accuracy: 0.8571 - Val loss: 0.3804 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0646 - Val accuracy: 0.8571 - Val loss: 0.3927 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0687 - Val accuracy: 0.7143 - Val loss: 0.3971 - LR: 0.00e+00\n","\tBest epoch: 69 - Best val accuracy: 0.8571 - Best val loss: 0.3657\n","\n","\tEpoch 10/100 - Train loss: 0.5236 - Val accuracy: 0.1429 - Val loss: 1.1270 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.3521 - Val accuracy: 0.1429 - Val loss: 1.2545 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.2469 - Val accuracy: 0.1429 - Val loss: 1.4465 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.2033 - Val accuracy: 0.1429 - Val loss: 1.3056 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.1526 - Val accuracy: 0.8571 - Val loss: 0.5061 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.1255 - Val accuracy: 0.8571 - Val loss: 0.2478 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.1050 - Val accuracy: 0.8571 - Val loss: 0.2482 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.1080 - Val accuracy: 0.8571 - Val loss: 0.2738 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0818 - Val accuracy: 0.8571 - Val loss: 0.2879 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0888 - Val accuracy: 0.8571 - Val loss: 0.2938 - LR: 0.00e+00\n","\tBest epoch: 64 - Best val accuracy: 0.8571 - Best val loss: 0.2387\n","\n","\tEpoch 10/100 - Train loss: 0.5392 - Val accuracy: 0.1429 - Val loss: 1.0814 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.3101 - Val accuracy: 0.1429 - Val loss: 1.1338 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.2281 - Val accuracy: 0.1429 - Val loss: 1.2830 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.1735 - Val accuracy: 0.2857 - Val loss: 1.1637 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.1248 - Val accuracy: 0.7143 - Val loss: 0.5714 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.0994 - Val accuracy: 1.0000 - Val loss: 0.2752 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0838 - Val accuracy: 1.0000 - Val loss: 0.1821 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0743 - Val accuracy: 1.0000 - Val loss: 0.1499 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0687 - Val accuracy: 1.0000 - Val loss: 0.1380 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0644 - Val accuracy: 1.0000 - Val loss: 0.1334 - LR: 0.00e+00\n","\tBest epoch: 100 - Best val accuracy: 1.0000 - Best val loss: 0.1334\n","\n","\tEpoch 10/100 - Train loss: 0.4906 - Val accuracy: 0.1429 - Val loss: 1.0988 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.3562 - Val accuracy: 0.1429 - Val loss: 1.1320 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.2807 - Val accuracy: 0.1429 - Val loss: 1.2099 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.2333 - Val accuracy: 0.4286 - Val loss: 1.0381 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.1928 - Val accuracy: 0.8571 - Val loss: 0.4787 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.1545 - Val accuracy: 0.8571 - Val loss: 0.2661 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.1336 - Val accuracy: 0.8571 - Val loss: 0.2194 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.1139 - Val accuracy: 0.8571 - Val loss: 0.2000 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0977 - Val accuracy: 0.8571 - Val loss: 0.1911 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.1086 - Val accuracy: 0.8571 - Val loss: 0.1883 - LR: 0.00e+00\n","\tBest epoch: 100 - Best val accuracy: 0.8571 - Best val loss: 0.1883\n","\n","Source class: WAL | Domain: 44 | Accuracy: 0.8778 | Loss: 0.2642\n","\n","Domain: 45\n","x_dp_dom.shape: (52, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Training and evaluating on Dp data via cross-validation...\n","\tEpoch 10/100 - Train loss: 0.5042 - Val accuracy: 0.2222 - Val loss: 1.1316 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.3556 - Val accuracy: 0.2222 - Val loss: 1.2627 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.2800 - Val accuracy: 0.2222 - Val loss: 1.4635 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.2168 - Val accuracy: 0.2222 - Val loss: 1.5125 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.1633 - Val accuracy: 0.5556 - Val loss: 0.8043 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.1443 - Val accuracy: 0.8889 - Val loss: 0.3354 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.1067 - Val accuracy: 0.8889 - Val loss: 0.2414 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0970 - Val accuracy: 0.8889 - Val loss: 0.2092 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0900 - Val accuracy: 1.0000 - Val loss: 0.1941 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0854 - Val accuracy: 1.0000 - Val loss: 0.1885 - LR: 0.00e+00\n","\tBest epoch: 100 - Best val accuracy: 1.0000 - Best val loss: 0.1885\n","\n","\tEpoch 10/100 - Train loss: 0.5788 - Val accuracy: 0.2222 - Val loss: 1.1191 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.3544 - Val accuracy: 0.2222 - Val loss: 1.2000 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.2431 - Val accuracy: 0.2222 - Val loss: 1.3471 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.1736 - Val accuracy: 0.2222 - Val loss: 1.2875 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.1204 - Val accuracy: 0.7778 - Val loss: 0.7462 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.0950 - Val accuracy: 0.8889 - Val loss: 0.3614 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0891 - Val accuracy: 0.8889 - Val loss: 0.2561 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0657 - Val accuracy: 1.0000 - Val loss: 0.2212 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0668 - Val accuracy: 1.0000 - Val loss: 0.2084 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0589 - Val accuracy: 1.0000 - Val loss: 0.2044 - LR: 0.00e+00\n","\tBest epoch: 100 - Best val accuracy: 1.0000 - Best val loss: 0.2044\n","\n","\tEpoch 10/100 - Train loss: 0.6516 - Val accuracy: 0.2222 - Val loss: 1.1100 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.4616 - Val accuracy: 0.2222 - Val loss: 1.1546 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.3265 - Val accuracy: 0.2222 - Val loss: 1.2644 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.2437 - Val accuracy: 0.2222 - Val loss: 1.3130 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.1700 - Val accuracy: 0.5556 - Val loss: 0.8928 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.1280 - Val accuracy: 0.8889 - Val loss: 0.4123 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.1051 - Val accuracy: 0.8889 - Val loss: 0.2661 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0906 - Val accuracy: 0.8889 - Val loss: 0.2257 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0827 - Val accuracy: 0.8889 - Val loss: 0.2132 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0745 - Val accuracy: 0.8889 - Val loss: 0.2092 - LR: 0.00e+00\n","\tBest epoch: 100 - Best val accuracy: 0.8889 - Best val loss: 0.2092\n","\n","\tEpoch 10/100 - Train loss: 0.6214 - Val accuracy: 0.2222 - Val loss: 1.1128 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.4089 - Val accuracy: 0.2222 - Val loss: 1.1738 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.2893 - Val accuracy: 0.2222 - Val loss: 1.3025 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.2102 - Val accuracy: 0.2222 - Val loss: 1.2691 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.1649 - Val accuracy: 0.6667 - Val loss: 0.7668 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.1224 - Val accuracy: 0.7778 - Val loss: 0.3903 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.1051 - Val accuracy: 0.7778 - Val loss: 0.2842 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0897 - Val accuracy: 0.8889 - Val loss: 0.2463 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0853 - Val accuracy: 1.0000 - Val loss: 0.2282 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0801 - Val accuracy: 1.0000 - Val loss: 0.2210 - LR: 0.00e+00\n","\tBest epoch: 100 - Best val accuracy: 1.0000 - Best val loss: 0.2210\n","\n","\tEpoch 10/100 - Train loss: 0.6314 - Val accuracy: 0.2222 - Val loss: 1.1073 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.4119 - Val accuracy: 0.2222 - Val loss: 1.1997 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.3108 - Val accuracy: 0.2222 - Val loss: 1.3714 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.2232 - Val accuracy: 0.2222 - Val loss: 1.4235 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.1689 - Val accuracy: 0.4444 - Val loss: 0.9620 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.1397 - Val accuracy: 0.7778 - Val loss: 0.4401 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.1186 - Val accuracy: 0.7778 - Val loss: 0.2937 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.1004 - Val accuracy: 0.8889 - Val loss: 0.2584 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0938 - Val accuracy: 0.8889 - Val loss: 0.2430 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0864 - Val accuracy: 1.0000 - Val loss: 0.2368 - LR: 0.00e+00\n","\tBest epoch: 100 - Best val accuracy: 1.0000 - Best val loss: 0.2368\n","\n","Source class: WAL | Domain: 45 | Accuracy: 0.9055 | Loss: 0.2484\n","\n","Domain: 46\n","x_dp_dom.shape: (48, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Training and evaluating on Dp data via cross-validation...\n","\tEpoch 10/100 - Train loss: 0.5356 - Val accuracy: 0.2500 - Val loss: 1.1272 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.3221 - Val accuracy: 0.2500 - Val loss: 1.2786 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.2140 - Val accuracy: 0.2500 - Val loss: 1.4649 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.1446 - Val accuracy: 0.3750 - Val loss: 1.3742 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.1008 - Val accuracy: 0.8750 - Val loss: 0.6762 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.0776 - Val accuracy: 1.0000 - Val loss: 0.2633 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0635 - Val accuracy: 1.0000 - Val loss: 0.1492 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0608 - Val accuracy: 1.0000 - Val loss: 0.1120 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0529 - Val accuracy: 1.0000 - Val loss: 0.0980 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0504 - Val accuracy: 1.0000 - Val loss: 0.0930 - LR: 0.00e+00\n","\tBest epoch: 100 - Best val accuracy: 1.0000 - Best val loss: 0.0930\n","\n","\tEpoch 10/100 - Train loss: 0.6693 - Val accuracy: 0.6250 - Val loss: 1.0796 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.4449 - Val accuracy: 0.2500 - Val loss: 1.1463 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.3389 - Val accuracy: 0.2500 - Val loss: 1.2773 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.2860 - Val accuracy: 0.2500 - Val loss: 1.1831 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.2308 - Val accuracy: 0.8750 - Val loss: 0.6313 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.1972 - Val accuracy: 1.0000 - Val loss: 0.3088 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.1717 - Val accuracy: 1.0000 - Val loss: 0.2227 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.1610 - Val accuracy: 1.0000 - Val loss: 0.1928 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.1498 - Val accuracy: 1.0000 - Val loss: 0.1794 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.1344 - Val accuracy: 1.0000 - Val loss: 0.1742 - LR: 0.00e+00\n","\tBest epoch: 100 - Best val accuracy: 1.0000 - Best val loss: 0.1742\n","\n","\tEpoch 10/100 - Train loss: 0.5056 - Val accuracy: 0.2500 - Val loss: 1.1083 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.3516 - Val accuracy: 0.2500 - Val loss: 1.2744 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.2976 - Val accuracy: 0.2500 - Val loss: 1.4782 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.2270 - Val accuracy: 0.2500 - Val loss: 1.4334 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.1930 - Val accuracy: 0.8750 - Val loss: 0.7206 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.1559 - Val accuracy: 0.8750 - Val loss: 0.2758 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.1467 - Val accuracy: 1.0000 - Val loss: 0.1847 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.1240 - Val accuracy: 1.0000 - Val loss: 0.1560 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.1113 - Val accuracy: 1.0000 - Val loss: 0.1435 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.1163 - Val accuracy: 1.0000 - Val loss: 0.1389 - LR: 0.00e+00\n","\tBest epoch: 100 - Best val accuracy: 1.0000 - Best val loss: 0.1389\n","\n","\tEpoch 10/100 - Train loss: 0.5389 - Val accuracy: 0.2500 - Val loss: 1.0883 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.3159 - Val accuracy: 0.2500 - Val loss: 1.2231 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.2301 - Val accuracy: 0.2500 - Val loss: 1.4241 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.1728 - Val accuracy: 0.2500 - Val loss: 1.1967 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.1325 - Val accuracy: 0.8750 - Val loss: 0.4861 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.1053 - Val accuracy: 1.0000 - Val loss: 0.2196 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0853 - Val accuracy: 1.0000 - Val loss: 0.1621 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0671 - Val accuracy: 1.0000 - Val loss: 0.1419 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0601 - Val accuracy: 1.0000 - Val loss: 0.1327 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0701 - Val accuracy: 1.0000 - Val loss: 0.1294 - LR: 0.00e+00\n","\tBest epoch: 100 - Best val accuracy: 1.0000 - Best val loss: 0.1294\n","\n","\tEpoch 10/100 - Train loss: 0.4933 - Val accuracy: 0.2500 - Val loss: 1.0930 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.3003 - Val accuracy: 0.2500 - Val loss: 1.3476 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.2056 - Val accuracy: 0.2500 - Val loss: 1.6626 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.1640 - Val accuracy: 0.2500 - Val loss: 1.6828 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.1306 - Val accuracy: 0.3750 - Val loss: 1.0136 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.1037 - Val accuracy: 0.8750 - Val loss: 0.4317 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0870 - Val accuracy: 1.0000 - Val loss: 0.2558 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0730 - Val accuracy: 1.0000 - Val loss: 0.2022 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0682 - Val accuracy: 1.0000 - Val loss: 0.1820 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0634 - Val accuracy: 1.0000 - Val loss: 0.1742 - LR: 0.00e+00\n","\tBest epoch: 100 - Best val accuracy: 1.0000 - Best val loss: 0.1742\n","\n","Source class: WAL | Domain: 46 | Accuracy: 0.9133 | Loss: 0.2518\n","\n","Domain: 47\n","x_dp_dom.shape: (44, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Training and evaluating on Dp data via cross-validation...\n","\tEpoch 10/100 - Train loss: 0.5967 - Val accuracy: 0.5714 - Val loss: 1.0904 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.3714 - Val accuracy: 0.2857 - Val loss: 1.1290 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.2372 - Val accuracy: 0.2857 - Val loss: 1.2334 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.1708 - Val accuracy: 0.2857 - Val loss: 1.2139 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.1382 - Val accuracy: 0.7143 - Val loss: 0.8029 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.1098 - Val accuracy: 0.8571 - Val loss: 0.4505 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0870 - Val accuracy: 0.8571 - Val loss: 0.3530 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0742 - Val accuracy: 0.8571 - Val loss: 0.3312 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0727 - Val accuracy: 0.8571 - Val loss: 0.3241 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0668 - Val accuracy: 0.8571 - Val loss: 0.3215 - LR: 0.00e+00\n","\tBest epoch: 100 - Best val accuracy: 0.8571 - Best val loss: 0.3215\n","\n","\tEpoch 10/100 - Train loss: 0.6437 - Val accuracy: 0.5714 - Val loss: 1.0741 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.4085 - Val accuracy: 0.2857 - Val loss: 1.0911 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.2877 - Val accuracy: 0.2857 - Val loss: 1.2071 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.2033 - Val accuracy: 0.2857 - Val loss: 1.1769 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.1564 - Val accuracy: 0.7143 - Val loss: 0.6991 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.1294 - Val accuracy: 0.8571 - Val loss: 0.4233 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.1070 - Val accuracy: 0.8571 - Val loss: 0.3408 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0977 - Val accuracy: 0.8571 - Val loss: 0.3140 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0839 - Val accuracy: 0.8571 - Val loss: 0.3030 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0842 - Val accuracy: 0.8571 - Val loss: 0.2986 - LR: 0.00e+00\n","\tBest epoch: 100 - Best val accuracy: 0.8571 - Best val loss: 0.2986\n","\n","\tEpoch 10/100 - Train loss: 0.6149 - Val accuracy: 0.5714 - Val loss: 1.0660 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.4049 - Val accuracy: 0.1429 - Val loss: 1.0990 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.2804 - Val accuracy: 0.1429 - Val loss: 1.1851 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.2003 - Val accuracy: 0.1429 - Val loss: 1.0762 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.1569 - Val accuracy: 0.7143 - Val loss: 0.6300 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.1137 - Val accuracy: 0.7143 - Val loss: 0.4394 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.1095 - Val accuracy: 0.7143 - Val loss: 0.4167 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0944 - Val accuracy: 0.7143 - Val loss: 0.4204 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0892 - Val accuracy: 0.7143 - Val loss: 0.4247 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0870 - Val accuracy: 0.7143 - Val loss: 0.4269 - LR: 0.00e+00\n","\tBest epoch: 71 - Best val accuracy: 0.7143 - Best val loss: 0.4166\n","\n","\tEpoch 10/100 - Train loss: 0.5732 - Val accuracy: 0.7143 - Val loss: 1.0890 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.3753 - Val accuracy: 0.1429 - Val loss: 1.1506 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.2661 - Val accuracy: 0.1429 - Val loss: 1.3097 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.2225 - Val accuracy: 0.1429 - Val loss: 1.1216 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.1769 - Val accuracy: 0.8571 - Val loss: 0.5063 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.1437 - Val accuracy: 0.8571 - Val loss: 0.2696 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.1293 - Val accuracy: 0.8571 - Val loss: 0.2213 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.1105 - Val accuracy: 0.8571 - Val loss: 0.2048 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.1063 - Val accuracy: 0.8571 - Val loss: 0.1976 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.1012 - Val accuracy: 0.8571 - Val loss: 0.1948 - LR: 0.00e+00\n","\tBest epoch: 100 - Best val accuracy: 0.8571 - Best val loss: 0.1948\n","\n","\tEpoch 10/100 - Train loss: 0.5024 - Val accuracy: 0.6250 - Val loss: 1.0803 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.3520 - Val accuracy: 0.2500 - Val loss: 1.1558 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.2720 - Val accuracy: 0.2500 - Val loss: 1.2716 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.2028 - Val accuracy: 0.2500 - Val loss: 1.2869 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.1577 - Val accuracy: 0.8750 - Val loss: 0.7078 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.1285 - Val accuracy: 1.0000 - Val loss: 0.3162 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0999 - Val accuracy: 0.8750 - Val loss: 0.2757 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.1018 - Val accuracy: 0.8750 - Val loss: 0.2790 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0831 - Val accuracy: 0.8750 - Val loss: 0.2822 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0846 - Val accuracy: 0.8750 - Val loss: 0.2851 - LR: 0.00e+00\n","\tBest epoch: 70 - Best val accuracy: 0.8750 - Best val loss: 0.2757\n","\n","Source class: WAL | Domain: 47 | Accuracy: 0.8833 | Loss: 0.2995\n","\n","Domain: 48\n","x_dp_dom.shape: (48, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Training and evaluating on Dp data via cross-validation...\n","\tEpoch 10/100 - Train loss: 0.7345 - Val accuracy: 0.2500 - Val loss: 1.1459 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.4136 - Val accuracy: 0.2500 - Val loss: 1.3045 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.2772 - Val accuracy: 0.2500 - Val loss: 1.5281 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.1860 - Val accuracy: 0.2500 - Val loss: 1.1701 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.1358 - Val accuracy: 0.7500 - Val loss: 0.5278 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.1201 - Val accuracy: 0.8750 - Val loss: 0.3188 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0930 - Val accuracy: 0.8750 - Val loss: 0.2612 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0921 - Val accuracy: 0.8750 - Val loss: 0.2398 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0765 - Val accuracy: 0.8750 - Val loss: 0.2300 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0807 - Val accuracy: 0.8750 - Val loss: 0.2261 - LR: 0.00e+00\n","\tBest epoch: 100 - Best val accuracy: 0.8750 - Best val loss: 0.2261\n","\n","\tEpoch 10/100 - Train loss: 0.5604 - Val accuracy: 0.6250 - Val loss: 1.0860 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.3418 - Val accuracy: 0.2500 - Val loss: 1.2444 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.2320 - Val accuracy: 0.2500 - Val loss: 1.4574 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.1675 - Val accuracy: 0.2500 - Val loss: 1.1744 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.1362 - Val accuracy: 1.0000 - Val loss: 0.5194 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.0954 - Val accuracy: 1.0000 - Val loss: 0.2982 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0960 - Val accuracy: 1.0000 - Val loss: 0.2474 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0786 - Val accuracy: 1.0000 - Val loss: 0.2294 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0659 - Val accuracy: 1.0000 - Val loss: 0.2211 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0681 - Val accuracy: 1.0000 - Val loss: 0.2176 - LR: 0.00e+00\n","\tBest epoch: 100 - Best val accuracy: 1.0000 - Best val loss: 0.2176\n","\n","\tEpoch 10/100 - Train loss: 0.6516 - Val accuracy: 0.2500 - Val loss: 1.1073 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.4370 - Val accuracy: 0.2500 - Val loss: 1.2262 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.2812 - Val accuracy: 0.2500 - Val loss: 1.4221 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.2075 - Val accuracy: 0.2500 - Val loss: 1.1787 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.1620 - Val accuracy: 0.8750 - Val loss: 0.5266 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.1434 - Val accuracy: 0.8750 - Val loss: 0.2940 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.1174 - Val accuracy: 0.8750 - Val loss: 0.2492 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.1067 - Val accuracy: 0.8750 - Val loss: 0.2345 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0918 - Val accuracy: 0.8750 - Val loss: 0.2276 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0895 - Val accuracy: 0.8750 - Val loss: 0.2248 - LR: 0.00e+00\n","\tBest epoch: 100 - Best val accuracy: 0.8750 - Best val loss: 0.2248\n","\n","\tEpoch 10/100 - Train loss: 0.5387 - Val accuracy: 0.2500 - Val loss: 1.1306 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.3732 - Val accuracy: 0.2500 - Val loss: 1.2649 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.2940 - Val accuracy: 0.2500 - Val loss: 1.4429 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.2405 - Val accuracy: 0.2500 - Val loss: 1.1893 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.2039 - Val accuracy: 0.8750 - Val loss: 0.5184 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.1593 - Val accuracy: 0.8750 - Val loss: 0.3043 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.1337 - Val accuracy: 0.8750 - Val loss: 0.2692 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.1312 - Val accuracy: 0.8750 - Val loss: 0.2624 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.1109 - Val accuracy: 0.8750 - Val loss: 0.2608 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.1162 - Val accuracy: 0.8750 - Val loss: 0.2601 - LR: 0.00e+00\n","\tBest epoch: 100 - Best val accuracy: 0.8750 - Best val loss: 0.2601\n","\n","\tEpoch 10/100 - Train loss: 0.5609 - Val accuracy: 0.2500 - Val loss: 1.0910 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.3475 - Val accuracy: 0.2500 - Val loss: 1.1832 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.2592 - Val accuracy: 0.2500 - Val loss: 1.3240 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.2065 - Val accuracy: 0.3750 - Val loss: 1.0257 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.1652 - Val accuracy: 0.7500 - Val loss: 0.4834 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.1325 - Val accuracy: 0.8750 - Val loss: 0.2738 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.1054 - Val accuracy: 0.8750 - Val loss: 0.2088 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.1004 - Val accuracy: 1.0000 - Val loss: 0.1844 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0819 - Val accuracy: 1.0000 - Val loss: 0.1735 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0716 - Val accuracy: 1.0000 - Val loss: 0.1688 - LR: 0.00e+00\n","\tBest epoch: 100 - Best val accuracy: 1.0000 - Best val loss: 0.1688\n","\n","Source class: WAL | Domain: 48 | Accuracy: 0.8733 | Loss: 0.2515\n","\n","Domain: 49\n","x_dp_dom.shape: (53, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Training and evaluating on Dp data via cross-validation...\n","\tEpoch 10/100 - Train loss: 0.7284 - Val accuracy: 0.5556 - Val loss: 1.0824 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.4543 - Val accuracy: 0.2222 - Val loss: 1.1850 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.2862 - Val accuracy: 0.2222 - Val loss: 1.4094 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.2026 - Val accuracy: 0.3333 - Val loss: 1.4867 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.1498 - Val accuracy: 0.6667 - Val loss: 0.9324 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.1147 - Val accuracy: 1.0000 - Val loss: 0.4538 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0909 - Val accuracy: 1.0000 - Val loss: 0.3036 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0880 - Val accuracy: 1.0000 - Val loss: 0.2559 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0821 - Val accuracy: 1.0000 - Val loss: 0.2383 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0794 - Val accuracy: 1.0000 - Val loss: 0.2316 - LR: 0.00e+00\n","\tBest epoch: 100 - Best val accuracy: 1.0000 - Best val loss: 0.2316\n","\n","\tEpoch 10/100 - Train loss: 0.6647 - Val accuracy: 0.2222 - Val loss: 1.1056 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.3780 - Val accuracy: 0.4444 - Val loss: 1.1804 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.2545 - Val accuracy: 0.4444 - Val loss: 1.3244 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.1799 - Val accuracy: 0.3333 - Val loss: 1.1770 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.1290 - Val accuracy: 0.6667 - Val loss: 0.6491 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.1135 - Val accuracy: 0.8889 - Val loss: 0.3344 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0852 - Val accuracy: 0.8889 - Val loss: 0.2407 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0874 - Val accuracy: 0.8889 - Val loss: 0.2102 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0705 - Val accuracy: 0.8889 - Val loss: 0.1982 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0627 - Val accuracy: 0.8889 - Val loss: 0.1940 - LR: 0.00e+00\n","\tBest epoch: 100 - Best val accuracy: 0.8889 - Best val loss: 0.1940\n","\n","\tEpoch 10/100 - Train loss: 0.6482 - Val accuracy: 0.5556 - Val loss: 1.0785 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.4089 - Val accuracy: 0.2222 - Val loss: 1.1462 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.2914 - Val accuracy: 0.2222 - Val loss: 1.2723 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.2030 - Val accuracy: 0.3333 - Val loss: 1.2428 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.1479 - Val accuracy: 0.5556 - Val loss: 0.7301 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.1287 - Val accuracy: 0.8889 - Val loss: 0.3448 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.1070 - Val accuracy: 0.7778 - Val loss: 0.2613 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0894 - Val accuracy: 0.7778 - Val loss: 0.2454 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0827 - Val accuracy: 0.7778 - Val loss: 0.2403 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0767 - Val accuracy: 0.7778 - Val loss: 0.2382 - LR: 0.00e+00\n","\tBest epoch: 100 - Best val accuracy: 0.7778 - Best val loss: 0.2382\n","\n","\tEpoch 10/100 - Train loss: 0.6202 - Val accuracy: 0.2222 - Val loss: 1.1004 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.3813 - Val accuracy: 0.2222 - Val loss: 1.2005 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.2426 - Val accuracy: 0.2222 - Val loss: 1.3564 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.1621 - Val accuracy: 0.2222 - Val loss: 1.4641 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.1121 - Val accuracy: 0.4444 - Val loss: 1.0097 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.0814 - Val accuracy: 1.0000 - Val loss: 0.3440 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0673 - Val accuracy: 1.0000 - Val loss: 0.1767 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0643 - Val accuracy: 1.0000 - Val loss: 0.1425 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0560 - Val accuracy: 1.0000 - Val loss: 0.1312 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0496 - Val accuracy: 1.0000 - Val loss: 0.1271 - LR: 0.00e+00\n","\tBest epoch: 100 - Best val accuracy: 1.0000 - Best val loss: 0.1271\n","\n","\tEpoch 10/100 - Train loss: 0.6257 - Val accuracy: 0.2222 - Val loss: 1.1012 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.3748 - Val accuracy: 0.2222 - Val loss: 1.1475 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.2281 - Val accuracy: 0.2222 - Val loss: 1.2481 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.1550 - Val accuracy: 0.2222 - Val loss: 1.2067 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.1120 - Val accuracy: 0.6667 - Val loss: 0.7118 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.0849 - Val accuracy: 1.0000 - Val loss: 0.2816 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0713 - Val accuracy: 1.0000 - Val loss: 0.1596 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0591 - Val accuracy: 1.0000 - Val loss: 0.1282 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0532 - Val accuracy: 1.0000 - Val loss: 0.1179 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0503 - Val accuracy: 1.0000 - Val loss: 0.1143 - LR: 0.00e+00\n","\tBest epoch: 100 - Best val accuracy: 1.0000 - Best val loss: 0.1143\n","\n","Source class: WAL | Domain: 49 | Accuracy: 0.9455 | Loss: 0.1966\n","\n","Domain: 50\n","x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Training and evaluating on Dp data via cross-validation...\n","\tEpoch 10/100 - Train loss: 0.5697 - Val accuracy: 0.7143 - Val loss: 1.0493 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.3590 - Val accuracy: 0.1429 - Val loss: 1.1378 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.2364 - Val accuracy: 0.1429 - Val loss: 1.2819 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.1819 - Val accuracy: 0.2857 - Val loss: 1.0745 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.1315 - Val accuracy: 0.8571 - Val loss: 0.5146 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.1010 - Val accuracy: 0.8571 - Val loss: 0.2704 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0816 - Val accuracy: 0.8571 - Val loss: 0.2067 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0723 - Val accuracy: 0.8571 - Val loss: 0.1842 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0645 - Val accuracy: 0.8571 - Val loss: 0.1742 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0611 - Val accuracy: 0.8571 - Val loss: 0.1703 - LR: 0.00e+00\n","\tBest epoch: 100 - Best val accuracy: 0.8571 - Best val loss: 0.1703\n","\n","\tEpoch 10/100 - Train loss: 0.5548 - Val accuracy: 0.7143 - Val loss: 1.0788 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.3536 - Val accuracy: 0.1429 - Val loss: 1.1575 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.2252 - Val accuracy: 0.1429 - Val loss: 1.2382 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.1644 - Val accuracy: 0.5714 - Val loss: 0.8090 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.1083 - Val accuracy: 1.0000 - Val loss: 0.2997 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.0848 - Val accuracy: 1.0000 - Val loss: 0.1461 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0697 - Val accuracy: 1.0000 - Val loss: 0.1045 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0654 - Val accuracy: 1.0000 - Val loss: 0.0885 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0559 - Val accuracy: 1.0000 - Val loss: 0.0812 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0564 - Val accuracy: 1.0000 - Val loss: 0.0786 - LR: 0.00e+00\n","\tBest epoch: 100 - Best val accuracy: 1.0000 - Best val loss: 0.0786\n","\n","\tEpoch 10/100 - Train loss: 0.6321 - Val accuracy: 0.7143 - Val loss: 1.0908 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.4184 - Val accuracy: 0.1429 - Val loss: 1.1091 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.2841 - Val accuracy: 0.1429 - Val loss: 1.1861 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.1960 - Val accuracy: 0.2857 - Val loss: 1.0035 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.1435 - Val accuracy: 0.8571 - Val loss: 0.4932 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.1178 - Val accuracy: 1.0000 - Val loss: 0.2481 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.1018 - Val accuracy: 1.0000 - Val loss: 0.1777 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0786 - Val accuracy: 1.0000 - Val loss: 0.1512 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0736 - Val accuracy: 1.0000 - Val loss: 0.1398 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0692 - Val accuracy: 1.0000 - Val loss: 0.1358 - LR: 0.00e+00\n","\tBest epoch: 100 - Best val accuracy: 1.0000 - Best val loss: 0.1358\n","\n","\tEpoch 10/100 - Train loss: 0.6621 - Val accuracy: 0.7143 - Val loss: 1.0291 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.4283 - Val accuracy: 0.7143 - Val loss: 1.0388 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.2593 - Val accuracy: 0.1429 - Val loss: 1.0913 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.1755 - Val accuracy: 0.7143 - Val loss: 0.8615 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.1165 - Val accuracy: 0.8571 - Val loss: 0.4512 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.0937 - Val accuracy: 1.0000 - Val loss: 0.2703 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0773 - Val accuracy: 1.0000 - Val loss: 0.2038 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0663 - Val accuracy: 1.0000 - Val loss: 0.1784 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0576 - Val accuracy: 1.0000 - Val loss: 0.1682 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0557 - Val accuracy: 1.0000 - Val loss: 0.1646 - LR: 0.00e+00\n","\tBest epoch: 100 - Best val accuracy: 1.0000 - Best val loss: 0.1646\n","\n","\tEpoch 10/100 - Train loss: 0.6159 - Val accuracy: 0.1429 - Val loss: 1.1123 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.4030 - Val accuracy: 0.1429 - Val loss: 1.1482 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.2754 - Val accuracy: 0.1429 - Val loss: 1.2660 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.1928 - Val accuracy: 0.4286 - Val loss: 1.0046 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.1539 - Val accuracy: 0.8571 - Val loss: 0.5296 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.1214 - Val accuracy: 1.0000 - Val loss: 0.3164 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.1052 - Val accuracy: 1.0000 - Val loss: 0.2561 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0995 - Val accuracy: 1.0000 - Val loss: 0.2372 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0868 - Val accuracy: 1.0000 - Val loss: 0.2294 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0838 - Val accuracy: 1.0000 - Val loss: 0.2270 - LR: 0.00e+00\n","\tBest epoch: 100 - Best val accuracy: 1.0000 - Best val loss: 0.2270\n","\n","Source class: WAL | Domain: 50 | Accuracy: 0.9028 | Loss: 0.2621\n","\n","Domain: 51\n","x_dp_dom.shape: (46, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Training and evaluating on Dp data via cross-validation...\n","\tEpoch 10/100 - Train loss: 0.7309 - Val accuracy: 0.1250 - Val loss: 1.1554 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.4734 - Val accuracy: 0.1250 - Val loss: 1.2360 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.3565 - Val accuracy: 0.1250 - Val loss: 1.3652 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.3026 - Val accuracy: 0.1250 - Val loss: 1.2159 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.2380 - Val accuracy: 0.5000 - Val loss: 0.8083 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.2233 - Val accuracy: 0.7500 - Val loss: 0.5647 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.1962 - Val accuracy: 0.7500 - Val loss: 0.4640 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.1899 - Val accuracy: 0.7500 - Val loss: 0.4225 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.1738 - Val accuracy: 0.7500 - Val loss: 0.4039 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.1708 - Val accuracy: 0.7500 - Val loss: 0.3962 - LR: 0.00e+00\n","\tBest epoch: 100 - Best val accuracy: 0.7500 - Best val loss: 0.3962\n","\n","\tEpoch 10/100 - Train loss: 0.5972 - Val accuracy: 0.2500 - Val loss: 1.1182 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.3991 - Val accuracy: 0.2500 - Val loss: 1.2460 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.2882 - Val accuracy: 0.2500 - Val loss: 1.4113 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.2206 - Val accuracy: 0.2500 - Val loss: 1.0831 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.1929 - Val accuracy: 0.8750 - Val loss: 0.4701 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.1596 - Val accuracy: 0.8750 - Val loss: 0.3032 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.1346 - Val accuracy: 0.8750 - Val loss: 0.2729 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.1264 - Val accuracy: 0.8750 - Val loss: 0.2629 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.1225 - Val accuracy: 0.8750 - Val loss: 0.2583 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.1230 - Val accuracy: 0.8750 - Val loss: 0.2567 - LR: 0.00e+00\n","\tBest epoch: 100 - Best val accuracy: 0.8750 - Best val loss: 0.2567\n","\n","\tEpoch 10/100 - Train loss: 0.6035 - Val accuracy: 0.1250 - Val loss: 1.1056 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.3981 - Val accuracy: 0.1250 - Val loss: 1.2410 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.2824 - Val accuracy: 0.1250 - Val loss: 1.4160 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.2095 - Val accuracy: 0.5000 - Val loss: 1.0482 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.1736 - Val accuracy: 0.7500 - Val loss: 0.5211 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.1577 - Val accuracy: 0.7500 - Val loss: 0.3859 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.1340 - Val accuracy: 0.7500 - Val loss: 0.3576 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.1163 - Val accuracy: 0.7500 - Val loss: 0.3489 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.1109 - Val accuracy: 0.7500 - Val loss: 0.3453 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.1004 - Val accuracy: 0.7500 - Val loss: 0.3439 - LR: 0.00e+00\n","\tBest epoch: 100 - Best val accuracy: 0.7500 - Best val loss: 0.3439\n","\n","\tEpoch 10/100 - Train loss: 0.6156 - Val accuracy: 0.6250 - Val loss: 1.0691 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.3911 - Val accuracy: 0.1250 - Val loss: 1.1285 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.2930 - Val accuracy: 0.1250 - Val loss: 1.1819 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.2257 - Val accuracy: 0.6250 - Val loss: 0.8676 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.1821 - Val accuracy: 0.7500 - Val loss: 0.5324 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.1514 - Val accuracy: 0.7500 - Val loss: 0.4230 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.1286 - Val accuracy: 0.6250 - Val loss: 0.3882 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.1096 - Val accuracy: 0.6250 - Val loss: 0.3755 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.1040 - Val accuracy: 0.6250 - Val loss: 0.3703 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.1003 - Val accuracy: 0.6250 - Val loss: 0.3681 - LR: 0.00e+00\n","\tBest epoch: 100 - Best val accuracy: 0.6250 - Best val loss: 0.3681\n","\n","\tEpoch 10/100 - Train loss: 0.6211 - Val accuracy: 0.6250 - Val loss: 1.0889 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.3811 - Val accuracy: 0.1250 - Val loss: 1.2010 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.2836 - Val accuracy: 0.1250 - Val loss: 1.3172 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.2083 - Val accuracy: 0.5000 - Val loss: 1.0278 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.1672 - Val accuracy: 0.7500 - Val loss: 0.5346 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.1355 - Val accuracy: 0.7500 - Val loss: 0.3828 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.1228 - Val accuracy: 0.7500 - Val loss: 0.3492 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.1050 - Val accuracy: 0.7500 - Val loss: 0.3395 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0995 - Val accuracy: 0.7500 - Val loss: 0.3372 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0919 - Val accuracy: 0.7500 - Val loss: 0.3367 - LR: 0.00e+00\n","\tBest epoch: 100 - Best val accuracy: 0.7500 - Best val loss: 0.3367\n","\n","Source class: WAL | Domain: 51 | Accuracy: 0.8467 | Loss: 0.3339\n","\n","Domain: 52\n","x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Training and evaluating on Dp data via cross-validation...\n","\tEpoch 10/100 - Train loss: 0.6429 - Val accuracy: 0.1429 - Val loss: 1.1060 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.4180 - Val accuracy: 0.1429 - Val loss: 1.1857 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.2799 - Val accuracy: 0.2857 - Val loss: 1.3724 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.2088 - Val accuracy: 0.2857 - Val loss: 1.4172 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.1726 - Val accuracy: 0.5714 - Val loss: 0.9083 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.1462 - Val accuracy: 0.8571 - Val loss: 0.4115 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.1133 - Val accuracy: 0.8571 - Val loss: 0.2873 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.1106 - Val accuracy: 0.8571 - Val loss: 0.2612 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0985 - Val accuracy: 0.8571 - Val loss: 0.2528 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0960 - Val accuracy: 0.8571 - Val loss: 0.2495 - LR: 0.00e+00\n","\tBest epoch: 100 - Best val accuracy: 0.8571 - Best val loss: 0.2495\n","\n","\tEpoch 10/100 - Train loss: 0.5863 - Val accuracy: 0.7143 - Val loss: 1.0580 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.3720 - Val accuracy: 0.1429 - Val loss: 1.0901 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.2586 - Val accuracy: 0.1429 - Val loss: 1.2136 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.1962 - Val accuracy: 0.1429 - Val loss: 1.1481 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.1386 - Val accuracy: 1.0000 - Val loss: 0.6141 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.1004 - Val accuracy: 1.0000 - Val loss: 0.2633 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0895 - Val accuracy: 1.0000 - Val loss: 0.1868 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0733 - Val accuracy: 1.0000 - Val loss: 0.1659 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0699 - Val accuracy: 1.0000 - Val loss: 0.1587 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0672 - Val accuracy: 1.0000 - Val loss: 0.1559 - LR: 0.00e+00\n","\tBest epoch: 100 - Best val accuracy: 1.0000 - Best val loss: 0.1559\n","\n","\tEpoch 10/100 - Train loss: 0.6372 - Val accuracy: 0.1429 - Val loss: 1.0880 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.3938 - Val accuracy: 0.1429 - Val loss: 1.1667 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.2640 - Val accuracy: 0.1429 - Val loss: 1.3280 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.1867 - Val accuracy: 0.1429 - Val loss: 1.2599 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.1330 - Val accuracy: 0.8571 - Val loss: 0.6437 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.1059 - Val accuracy: 0.8571 - Val loss: 0.3361 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0839 - Val accuracy: 0.7143 - Val loss: 0.2813 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0760 - Val accuracy: 0.8571 - Val loss: 0.2676 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0738 - Val accuracy: 0.8571 - Val loss: 0.2621 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0604 - Val accuracy: 0.8571 - Val loss: 0.2604 - LR: 0.00e+00\n","\tBest epoch: 100 - Best val accuracy: 0.8571 - Best val loss: 0.2604\n","\n","\tEpoch 10/100 - Train loss: 0.4825 - Val accuracy: 0.7143 - Val loss: 0.9928 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.3201 - Val accuracy: 0.7143 - Val loss: 1.0184 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.2438 - Val accuracy: 0.0000 - Val loss: 1.1739 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.1991 - Val accuracy: 0.0000 - Val loss: 1.1787 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.1658 - Val accuracy: 0.7143 - Val loss: 0.6822 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.1283 - Val accuracy: 0.7143 - Val loss: 0.3304 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.1273 - Val accuracy: 0.8571 - Val loss: 0.2720 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.1080 - Val accuracy: 0.8571 - Val loss: 0.2639 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.1079 - Val accuracy: 0.8571 - Val loss: 0.2613 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.1041 - Val accuracy: 0.8571 - Val loss: 0.2603 - LR: 0.00e+00\n","\tBest epoch: 100 - Best val accuracy: 0.8571 - Best val loss: 0.2603\n","\n","\tEpoch 10/100 - Train loss: 0.5211 - Val accuracy: 0.7143 - Val loss: 1.0756 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.3344 - Val accuracy: 0.1429 - Val loss: 1.1837 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.2298 - Val accuracy: 0.1429 - Val loss: 1.4947 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.1846 - Val accuracy: 0.1429 - Val loss: 1.6080 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.1446 - Val accuracy: 0.4286 - Val loss: 1.0074 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.1197 - Val accuracy: 0.8571 - Val loss: 0.4956 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0960 - Val accuracy: 0.8571 - Val loss: 0.3791 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0859 - Val accuracy: 0.8571 - Val loss: 0.3608 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0783 - Val accuracy: 0.8571 - Val loss: 0.3564 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0865 - Val accuracy: 0.8571 - Val loss: 0.3545 - LR: 0.00e+00\n","\tBest epoch: 100 - Best val accuracy: 0.8571 - Best val loss: 0.3545\n","\n","Source class: WAL | Domain: 52 | Accuracy: 0.8083 | Loss: 0.3288\n","\n","Domain: 53\n","x_dp_dom.shape: (48, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Training and evaluating on Dp data via cross-validation...\n","\tEpoch 10/100 - Train loss: 0.5789 - Val accuracy: 0.2500 - Val loss: 1.1179 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.3785 - Val accuracy: 0.2500 - Val loss: 1.2557 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.2758 - Val accuracy: 0.2500 - Val loss: 1.5112 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.2402 - Val accuracy: 0.2500 - Val loss: 1.3662 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.1858 - Val accuracy: 0.8750 - Val loss: 0.5930 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.1584 - Val accuracy: 0.8750 - Val loss: 0.2494 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.1263 - Val accuracy: 1.0000 - Val loss: 0.1775 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.1044 - Val accuracy: 1.0000 - Val loss: 0.1551 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.1054 - Val accuracy: 1.0000 - Val loss: 0.1451 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.1050 - Val accuracy: 1.0000 - Val loss: 0.1415 - LR: 0.00e+00\n","\tBest epoch: 100 - Best val accuracy: 1.0000 - Best val loss: 0.1415\n","\n","\tEpoch 10/100 - Train loss: 0.6326 - Val accuracy: 0.2500 - Val loss: 1.0982 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.4081 - Val accuracy: 0.2500 - Val loss: 1.2127 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.3172 - Val accuracy: 0.2500 - Val loss: 1.3441 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.2639 - Val accuracy: 0.5000 - Val loss: 1.0896 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.2135 - Val accuracy: 0.7500 - Val loss: 0.5664 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.2023 - Val accuracy: 0.8750 - Val loss: 0.3456 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.1519 - Val accuracy: 1.0000 - Val loss: 0.2699 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.1416 - Val accuracy: 1.0000 - Val loss: 0.2390 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.1275 - Val accuracy: 1.0000 - Val loss: 0.2233 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.1435 - Val accuracy: 1.0000 - Val loss: 0.2172 - LR: 0.00e+00\n","\tBest epoch: 100 - Best val accuracy: 1.0000 - Best val loss: 0.2172\n","\n","\tEpoch 10/100 - Train loss: 0.6424 - Val accuracy: 0.6250 - Val loss: 1.0739 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.4151 - Val accuracy: 0.1250 - Val loss: 1.1575 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.2993 - Val accuracy: 0.2500 - Val loss: 1.2833 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.2502 - Val accuracy: 0.6250 - Val loss: 1.0210 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.1779 - Val accuracy: 0.8750 - Val loss: 0.5399 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.1564 - Val accuracy: 1.0000 - Val loss: 0.3500 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.1375 - Val accuracy: 1.0000 - Val loss: 0.2866 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.1288 - Val accuracy: 1.0000 - Val loss: 0.2608 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.1118 - Val accuracy: 1.0000 - Val loss: 0.2490 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.1095 - Val accuracy: 1.0000 - Val loss: 0.2433 - LR: 0.00e+00\n","\tBest epoch: 100 - Best val accuracy: 1.0000 - Best val loss: 0.2433\n","\n","\tEpoch 10/100 - Train loss: 0.5093 - Val accuracy: 0.6250 - Val loss: 1.0740 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.3301 - Val accuracy: 0.2500 - Val loss: 1.1976 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.2229 - Val accuracy: 0.2500 - Val loss: 1.3872 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.1584 - Val accuracy: 0.2500 - Val loss: 1.2994 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.1121 - Val accuracy: 0.7500 - Val loss: 0.6117 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.0854 - Val accuracy: 0.8750 - Val loss: 0.2765 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0715 - Val accuracy: 0.8750 - Val loss: 0.2136 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0494 - Val accuracy: 0.8750 - Val loss: 0.1971 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0502 - Val accuracy: 0.8750 - Val loss: 0.1904 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0470 - Val accuracy: 0.8750 - Val loss: 0.1881 - LR: 0.00e+00\n","\tBest epoch: 100 - Best val accuracy: 0.8750 - Best val loss: 0.1881\n","\n","\tEpoch 10/100 - Train loss: 0.5563 - Val accuracy: 0.2500 - Val loss: 1.1040 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.3533 - Val accuracy: 0.2500 - Val loss: 1.2169 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.2476 - Val accuracy: 0.2500 - Val loss: 1.3825 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.1880 - Val accuracy: 0.2500 - Val loss: 1.0706 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.1543 - Val accuracy: 0.8750 - Val loss: 0.4437 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.1244 - Val accuracy: 0.8750 - Val loss: 0.2270 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.1040 - Val accuracy: 1.0000 - Val loss: 0.1757 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0869 - Val accuracy: 1.0000 - Val loss: 0.1559 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0821 - Val accuracy: 1.0000 - Val loss: 0.1470 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0754 - Val accuracy: 1.0000 - Val loss: 0.1442 - LR: 0.00e+00\n","\tBest epoch: 100 - Best val accuracy: 1.0000 - Best val loss: 0.1442\n","\n","Source class: WAL | Domain: 53 | Accuracy: 0.8556 | Loss: 0.2703\n","\n","Domain: 54\n","x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Training and evaluating on Dp data via cross-validation...\n","\tEpoch 10/100 - Train loss: 0.5561 - Val accuracy: 0.7143 - Val loss: 1.0782 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.3372 - Val accuracy: 0.1429 - Val loss: 1.1730 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.2306 - Val accuracy: 0.1429 - Val loss: 1.4540 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.1742 - Val accuracy: 0.1429 - Val loss: 1.4424 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.1295 - Val accuracy: 0.8571 - Val loss: 0.6717 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.1070 - Val accuracy: 1.0000 - Val loss: 0.2240 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.1065 - Val accuracy: 1.0000 - Val loss: 0.1373 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0903 - Val accuracy: 1.0000 - Val loss: 0.1154 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0757 - Val accuracy: 1.0000 - Val loss: 0.1068 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0762 - Val accuracy: 1.0000 - Val loss: 0.1038 - LR: 0.00e+00\n","\tBest epoch: 100 - Best val accuracy: 1.0000 - Best val loss: 0.1038\n","\n","\tEpoch 10/100 - Train loss: 0.6084 - Val accuracy: 0.7143 - Val loss: 1.0183 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.4067 - Val accuracy: 0.1429 - Val loss: 1.0566 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.2943 - Val accuracy: 0.1429 - Val loss: 1.1848 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.2374 - Val accuracy: 0.1429 - Val loss: 1.0824 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.1904 - Val accuracy: 0.8571 - Val loss: 0.5947 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.1575 - Val accuracy: 0.8571 - Val loss: 0.2875 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.1546 - Val accuracy: 0.8571 - Val loss: 0.2134 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.1246 - Val accuracy: 0.8571 - Val loss: 0.1916 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.1103 - Val accuracy: 0.8571 - Val loss: 0.1835 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.1216 - Val accuracy: 0.8571 - Val loss: 0.1811 - LR: 0.00e+00\n","\tBest epoch: 100 - Best val accuracy: 0.8571 - Best val loss: 0.1811\n","\n","\tEpoch 10/100 - Train loss: 0.5140 - Val accuracy: 0.7143 - Val loss: 1.0706 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.3437 - Val accuracy: 0.1429 - Val loss: 1.1976 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.2638 - Val accuracy: 0.1429 - Val loss: 1.4474 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.2109 - Val accuracy: 0.1429 - Val loss: 1.4382 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.1898 - Val accuracy: 0.7143 - Val loss: 0.8071 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.1577 - Val accuracy: 1.0000 - Val loss: 0.3883 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.1551 - Val accuracy: 1.0000 - Val loss: 0.2683 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.1343 - Val accuracy: 1.0000 - Val loss: 0.2256 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.1209 - Val accuracy: 1.0000 - Val loss: 0.2080 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.1345 - Val accuracy: 1.0000 - Val loss: 0.2013 - LR: 0.00e+00\n","\tBest epoch: 100 - Best val accuracy: 1.0000 - Best val loss: 0.2013\n","\n","\tEpoch 10/100 - Train loss: 0.5202 - Val accuracy: 0.7143 - Val loss: 1.0115 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.3620 - Val accuracy: 0.7143 - Val loss: 1.0326 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.2627 - Val accuracy: 0.1429 - Val loss: 1.1014 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.2138 - Val accuracy: 0.7143 - Val loss: 1.0056 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.1680 - Val accuracy: 1.0000 - Val loss: 0.6145 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.1260 - Val accuracy: 1.0000 - Val loss: 0.3151 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.1136 - Val accuracy: 1.0000 - Val loss: 0.2160 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0980 - Val accuracy: 1.0000 - Val loss: 0.1823 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0865 - Val accuracy: 1.0000 - Val loss: 0.1685 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0876 - Val accuracy: 1.0000 - Val loss: 0.1635 - LR: 0.00e+00\n","\tBest epoch: 100 - Best val accuracy: 1.0000 - Best val loss: 0.1635\n","\n","\tEpoch 10/100 - Train loss: 0.5471 - Val accuracy: 0.7143 - Val loss: 1.0430 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.3483 - Val accuracy: 0.5714 - Val loss: 1.0865 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.2449 - Val accuracy: 0.1429 - Val loss: 1.2502 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.1805 - Val accuracy: 0.4286 - Val loss: 1.0926 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.1430 - Val accuracy: 0.8571 - Val loss: 0.5677 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.1220 - Val accuracy: 1.0000 - Val loss: 0.3122 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0954 - Val accuracy: 1.0000 - Val loss: 0.2372 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0888 - Val accuracy: 1.0000 - Val loss: 0.2118 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0894 - Val accuracy: 1.0000 - Val loss: 0.2018 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0900 - Val accuracy: 1.0000 - Val loss: 0.1981 - LR: 0.00e+00\n","\tBest epoch: 100 - Best val accuracy: 1.0000 - Best val loss: 0.1981\n","\n","Source class: WAL | Domain: 54 | Accuracy: 0.9278 | Loss: 0.2431\n","\n","Domain: 55\n","x_dp_dom.shape: (49, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Training and evaluating on Dp data via cross-validation...\n","\tEpoch 10/100 - Train loss: 0.6100 - Val accuracy: 0.6250 - Val loss: 1.0917 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.3696 - Val accuracy: 0.2500 - Val loss: 1.1689 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.2635 - Val accuracy: 0.2500 - Val loss: 1.2900 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.2057 - Val accuracy: 0.2500 - Val loss: 1.1949 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.1452 - Val accuracy: 0.8750 - Val loss: 0.5720 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.1190 - Val accuracy: 1.0000 - Val loss: 0.2273 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0984 - Val accuracy: 1.0000 - Val loss: 0.1489 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0790 - Val accuracy: 1.0000 - Val loss: 0.1234 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0800 - Val accuracy: 1.0000 - Val loss: 0.1124 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0730 - Val accuracy: 1.0000 - Val loss: 0.1085 - LR: 0.00e+00\n","\tBest epoch: 100 - Best val accuracy: 1.0000 - Best val loss: 0.1085\n","\n","\tEpoch 10/100 - Train loss: 0.5884 - Val accuracy: 0.2500 - Val loss: 1.1546 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.3689 - Val accuracy: 0.2500 - Val loss: 1.3036 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.2760 - Val accuracy: 0.2500 - Val loss: 1.5138 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.2033 - Val accuracy: 0.1250 - Val loss: 1.1686 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.1704 - Val accuracy: 0.8750 - Val loss: 0.4612 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.1289 - Val accuracy: 0.8750 - Val loss: 0.2701 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0949 - Val accuracy: 0.8750 - Val loss: 0.2330 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0905 - Val accuracy: 0.8750 - Val loss: 0.2225 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0877 - Val accuracy: 0.8750 - Val loss: 0.2190 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0851 - Val accuracy: 0.8750 - Val loss: 0.2176 - LR: 0.00e+00\n","\tBest epoch: 100 - Best val accuracy: 0.8750 - Best val loss: 0.2176\n","\n","\tEpoch 10/100 - Train loss: 0.6025 - Val accuracy: 0.2500 - Val loss: 1.0982 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.3584 - Val accuracy: 0.2500 - Val loss: 1.2003 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.2707 - Val accuracy: 0.2500 - Val loss: 1.3316 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.2220 - Val accuracy: 0.3750 - Val loss: 1.0571 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.1620 - Val accuracy: 0.8750 - Val loss: 0.4986 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.1338 - Val accuracy: 0.8750 - Val loss: 0.3007 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.1097 - Val accuracy: 0.8750 - Val loss: 0.2491 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0921 - Val accuracy: 0.8750 - Val loss: 0.2281 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0915 - Val accuracy: 0.8750 - Val loss: 0.2176 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0988 - Val accuracy: 0.8750 - Val loss: 0.2138 - LR: 0.00e+00\n","\tBest epoch: 100 - Best val accuracy: 0.8750 - Best val loss: 0.2138\n","\n","\tEpoch 10/100 - Train loss: 0.5764 - Val accuracy: 0.2500 - Val loss: 1.1022 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.3559 - Val accuracy: 0.2500 - Val loss: 1.1580 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.2664 - Val accuracy: 0.2500 - Val loss: 1.2276 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.2027 - Val accuracy: 0.5000 - Val loss: 1.0402 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.1502 - Val accuracy: 1.0000 - Val loss: 0.4834 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.1196 - Val accuracy: 1.0000 - Val loss: 0.2096 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0983 - Val accuracy: 1.0000 - Val loss: 0.1401 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0875 - Val accuracy: 1.0000 - Val loss: 0.1175 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0813 - Val accuracy: 1.0000 - Val loss: 0.1079 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0704 - Val accuracy: 1.0000 - Val loss: 0.1045 - LR: 0.00e+00\n","\tBest epoch: 100 - Best val accuracy: 1.0000 - Best val loss: 0.1045\n","\n","\tEpoch 10/100 - Train loss: 0.6030 - Val accuracy: 0.3750 - Val loss: 1.0937 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.3407 - Val accuracy: 0.2500 - Val loss: 1.1016 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.2311 - Val accuracy: 0.2500 - Val loss: 1.0783 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.1581 - Val accuracy: 0.8750 - Val loss: 0.7465 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.1159 - Val accuracy: 0.8750 - Val loss: 0.3428 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.0855 - Val accuracy: 0.8750 - Val loss: 0.2192 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0750 - Val accuracy: 0.8750 - Val loss: 0.1895 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0625 - Val accuracy: 0.8750 - Val loss: 0.1811 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0570 - Val accuracy: 0.8750 - Val loss: 0.1782 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0587 - Val accuracy: 0.8750 - Val loss: 0.1786 - LR: 0.00e+00\n","\tBest epoch: 93 - Best val accuracy: 0.8750 - Best val loss: 0.1781\n","\n","Source class: WAL | Domain: 55 | Accuracy: 0.9378 | Loss: 0.1823\n","\n","Domain: 56\n","x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Training and evaluating on Dp data via cross-validation...\n","\tEpoch 10/100 - Train loss: 0.4854 - Val accuracy: 0.1429 - Val loss: 1.1310 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.2965 - Val accuracy: 0.1429 - Val loss: 1.2771 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.2061 - Val accuracy: 0.1429 - Val loss: 1.5433 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.1562 - Val accuracy: 0.1429 - Val loss: 1.4446 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.1237 - Val accuracy: 0.7143 - Val loss: 0.7756 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.0940 - Val accuracy: 0.7143 - Val loss: 0.4364 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0819 - Val accuracy: 0.8571 - Val loss: 0.3436 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0676 - Val accuracy: 0.8571 - Val loss: 0.3164 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0601 - Val accuracy: 0.8571 - Val loss: 0.3068 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0556 - Val accuracy: 0.8571 - Val loss: 0.3030 - LR: 0.00e+00\n","\tBest epoch: 100 - Best val accuracy: 0.8571 - Best val loss: 0.3030\n","\n","\tEpoch 10/100 - Train loss: 0.4757 - Val accuracy: 0.7143 - Val loss: 1.0356 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.3029 - Val accuracy: 0.1429 - Val loss: 1.1540 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.2163 - Val accuracy: 0.1429 - Val loss: 1.3308 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.1663 - Val accuracy: 0.1429 - Val loss: 1.1062 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.1282 - Val accuracy: 0.8571 - Val loss: 0.4540 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.1010 - Val accuracy: 0.8571 - Val loss: 0.2495 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0806 - Val accuracy: 0.8571 - Val loss: 0.2045 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0720 - Val accuracy: 0.8571 - Val loss: 0.1892 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0666 - Val accuracy: 0.8571 - Val loss: 0.1828 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0651 - Val accuracy: 0.8571 - Val loss: 0.1806 - LR: 0.00e+00\n","\tBest epoch: 100 - Best val accuracy: 0.8571 - Best val loss: 0.1806\n","\n","\tEpoch 10/100 - Train loss: 0.5764 - Val accuracy: 0.7143 - Val loss: 1.0671 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.3696 - Val accuracy: 0.1429 - Val loss: 1.2118 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.2573 - Val accuracy: 0.1429 - Val loss: 1.4429 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.1862 - Val accuracy: 0.1429 - Val loss: 1.2644 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.1424 - Val accuracy: 0.8571 - Val loss: 0.5832 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.1069 - Val accuracy: 1.0000 - Val loss: 0.2776 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0893 - Val accuracy: 1.0000 - Val loss: 0.2070 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0863 - Val accuracy: 1.0000 - Val loss: 0.1854 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0743 - Val accuracy: 1.0000 - Val loss: 0.1766 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0723 - Val accuracy: 1.0000 - Val loss: 0.1734 - LR: 0.00e+00\n","\tBest epoch: 100 - Best val accuracy: 1.0000 - Best val loss: 0.1734\n","\n","\tEpoch 10/100 - Train loss: 0.5214 - Val accuracy: 0.1429 - Val loss: 1.0979 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.3219 - Val accuracy: 0.1429 - Val loss: 1.2033 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.2286 - Val accuracy: 0.1429 - Val loss: 1.3053 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.1726 - Val accuracy: 0.2857 - Val loss: 0.9604 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.1335 - Val accuracy: 0.8571 - Val loss: 0.3569 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.1024 - Val accuracy: 1.0000 - Val loss: 0.1729 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0908 - Val accuracy: 1.0000 - Val loss: 0.1212 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0733 - Val accuracy: 1.0000 - Val loss: 0.1006 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0694 - Val accuracy: 1.0000 - Val loss: 0.0914 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0671 - Val accuracy: 1.0000 - Val loss: 0.0880 - LR: 0.00e+00\n","\tBest epoch: 100 - Best val accuracy: 1.0000 - Best val loss: 0.0880\n","\n","\tEpoch 10/100 - Train loss: 0.4610 - Val accuracy: 0.1429 - Val loss: 1.1008 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.3072 - Val accuracy: 0.1429 - Val loss: 1.2948 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.2133 - Val accuracy: 0.1429 - Val loss: 1.5620 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.1738 - Val accuracy: 0.1429 - Val loss: 1.4473 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.1413 - Val accuracy: 0.8571 - Val loss: 0.4768 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.1088 - Val accuracy: 0.8571 - Val loss: 0.2450 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0985 - Val accuracy: 0.8571 - Val loss: 0.2134 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0798 - Val accuracy: 0.8571 - Val loss: 0.2043 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0741 - Val accuracy: 0.8571 - Val loss: 0.2005 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0625 - Val accuracy: 0.8571 - Val loss: 0.1993 - LR: 0.00e+00\n","\tBest epoch: 100 - Best val accuracy: 0.8571 - Best val loss: 0.1993\n","\n","Source class: WAL | Domain: 56 | Accuracy: 0.9750 | Loss: 0.1990\n","\n","Domain: 57\n","x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Training and evaluating on Dp data via cross-validation...\n","\tEpoch 10/100 - Train loss: 0.5933 - Val accuracy: 0.7143 - Val loss: 1.0607 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.3559 - Val accuracy: 0.1429 - Val loss: 1.0948 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.2254 - Val accuracy: 0.1429 - Val loss: 1.1902 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.1611 - Val accuracy: 0.5714 - Val loss: 0.9314 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.1123 - Val accuracy: 0.8571 - Val loss: 0.4679 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.0827 - Val accuracy: 0.8571 - Val loss: 0.2704 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0876 - Val accuracy: 0.8571 - Val loss: 0.2144 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0638 - Val accuracy: 0.8571 - Val loss: 0.1951 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0568 - Val accuracy: 0.8571 - Val loss: 0.1872 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0545 - Val accuracy: 0.8571 - Val loss: 0.1845 - LR: 0.00e+00\n","\tBest epoch: 100 - Best val accuracy: 0.8571 - Best val loss: 0.1845\n","\n","\tEpoch 10/100 - Train loss: 0.6542 - Val accuracy: 0.7143 - Val loss: 1.0262 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.4112 - Val accuracy: 0.7143 - Val loss: 0.9956 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.2480 - Val accuracy: 0.1429 - Val loss: 1.0684 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.1649 - Val accuracy: 0.7143 - Val loss: 0.8906 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.1078 - Val accuracy: 0.8571 - Val loss: 0.4715 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.0830 - Val accuracy: 0.8571 - Val loss: 0.2731 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0700 - Val accuracy: 0.8571 - Val loss: 0.2172 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0613 - Val accuracy: 0.8571 - Val loss: 0.1990 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0526 - Val accuracy: 0.8571 - Val loss: 0.1922 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0498 - Val accuracy: 0.8571 - Val loss: 0.1906 - LR: 0.00e+00\n","\tBest epoch: 99 - Best val accuracy: 0.8571 - Best val loss: 0.1906\n","\n","\tEpoch 10/100 - Train loss: 0.5470 - Val accuracy: 0.7143 - Val loss: 1.0598 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.3239 - Val accuracy: 0.1429 - Val loss: 1.1888 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.2004 - Val accuracy: 0.1429 - Val loss: 1.4874 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.1278 - Val accuracy: 0.1429 - Val loss: 1.4576 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.0938 - Val accuracy: 0.8571 - Val loss: 0.6320 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.0693 - Val accuracy: 0.8571 - Val loss: 0.2731 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0603 - Val accuracy: 0.8571 - Val loss: 0.2218 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0506 - Val accuracy: 1.0000 - Val loss: 0.2136 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0457 - Val accuracy: 1.0000 - Val loss: 0.2112 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0462 - Val accuracy: 1.0000 - Val loss: 0.2104 - LR: 0.00e+00\n","\tBest epoch: 100 - Best val accuracy: 1.0000 - Best val loss: 0.2104\n","\n","\tEpoch 10/100 - Train loss: 0.5472 - Val accuracy: 0.1429 - Val loss: 1.1008 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.3280 - Val accuracy: 0.1429 - Val loss: 1.1956 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.2115 - Val accuracy: 0.1429 - Val loss: 1.3511 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.1587 - Val accuracy: 0.1429 - Val loss: 1.1025 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.1280 - Val accuracy: 0.8571 - Val loss: 0.3804 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.0949 - Val accuracy: 1.0000 - Val loss: 0.1899 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0879 - Val accuracy: 1.0000 - Val loss: 0.1578 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0729 - Val accuracy: 1.0000 - Val loss: 0.1462 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0690 - Val accuracy: 1.0000 - Val loss: 0.1408 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0682 - Val accuracy: 1.0000 - Val loss: 0.1389 - LR: 0.00e+00\n","\tBest epoch: 100 - Best val accuracy: 1.0000 - Best val loss: 0.1389\n","\n","\tEpoch 10/100 - Train loss: 0.5872 - Val accuracy: 0.1429 - Val loss: 1.0940 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.3883 - Val accuracy: 0.1429 - Val loss: 1.1349 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.2527 - Val accuracy: 0.1429 - Val loss: 1.2964 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.1681 - Val accuracy: 0.1429 - Val loss: 1.2621 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.1221 - Val accuracy: 0.8571 - Val loss: 0.6699 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.0961 - Val accuracy: 0.8571 - Val loss: 0.3257 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0817 - Val accuracy: 0.8571 - Val loss: 0.2574 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0758 - Val accuracy: 0.8571 - Val loss: 0.2440 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0678 - Val accuracy: 0.8571 - Val loss: 0.2408 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0649 - Val accuracy: 0.8571 - Val loss: 0.2399 - LR: 0.00e+00\n","\tBest epoch: 100 - Best val accuracy: 0.8571 - Best val loss: 0.2399\n","\n","Source class: WAL | Domain: 57 | Accuracy: 0.9250 | Loss: 0.2342\n","\n","Domain: 58\n","x_dp_dom.shape: (38, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Training and evaluating on Dp data via cross-validation...\n","\tEpoch 10/100 - Train loss: 0.4703 - Val accuracy: 0.6667 - Val loss: 1.0523 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.2743 - Val accuracy: 0.6667 - Val loss: 0.9660 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.1929 - Val accuracy: 0.6667 - Val loss: 0.8410 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.1421 - Val accuracy: 0.8333 - Val loss: 0.6326 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.1142 - Val accuracy: 0.8333 - Val loss: 0.4688 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.0922 - Val accuracy: 0.8333 - Val loss: 0.4025 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0839 - Val accuracy: 0.8333 - Val loss: 0.3859 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0783 - Val accuracy: 0.8333 - Val loss: 0.3870 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0664 - Val accuracy: 0.8333 - Val loss: 0.3899 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0645 - Val accuracy: 0.8333 - Val loss: 0.3914 - LR: 0.00e+00\n","\tBest epoch: 73 - Best val accuracy: 0.8333 - Best val loss: 0.3853\n","\n","\tEpoch 10/100 - Train loss: 0.3885 - Val accuracy: 0.6667 - Val loss: 0.9985 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.2215 - Val accuracy: 0.6667 - Val loss: 0.9735 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.1549 - Val accuracy: 1.0000 - Val loss: 0.8526 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.1102 - Val accuracy: 1.0000 - Val loss: 0.4971 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.0810 - Val accuracy: 0.8333 - Val loss: 0.3181 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.0695 - Val accuracy: 0.8333 - Val loss: 0.2837 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0539 - Val accuracy: 0.8333 - Val loss: 0.2806 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0434 - Val accuracy: 0.8333 - Val loss: 0.2823 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0414 - Val accuracy: 0.8333 - Val loss: 0.2839 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0384 - Val accuracy: 0.8333 - Val loss: 0.2848 - LR: 0.00e+00\n","\tBest epoch: 69 - Best val accuracy: 0.8333 - Best val loss: 0.2806\n","\n","\tEpoch 10/100 - Train loss: 0.5253 - Val accuracy: 0.6667 - Val loss: 1.0393 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.3554 - Val accuracy: 0.6667 - Val loss: 0.9902 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.2294 - Val accuracy: 0.6667 - Val loss: 0.9143 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.1674 - Val accuracy: 1.0000 - Val loss: 0.6326 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.1278 - Val accuracy: 1.0000 - Val loss: 0.3744 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.1134 - Val accuracy: 0.8333 - Val loss: 0.2887 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0824 - Val accuracy: 0.8333 - Val loss: 0.2623 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0690 - Val accuracy: 0.8333 - Val loss: 0.2523 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0713 - Val accuracy: 0.8333 - Val loss: 0.2485 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0687 - Val accuracy: 0.8333 - Val loss: 0.2472 - LR: 0.00e+00\n","\tBest epoch: 100 - Best val accuracy: 0.8333 - Best val loss: 0.2472\n","\n","\tEpoch 10/100 - Train loss: 0.5269 - Val accuracy: 0.7143 - Val loss: 1.0289 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.3347 - Val accuracy: 0.7143 - Val loss: 1.0425 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.2380 - Val accuracy: 0.1429 - Val loss: 1.1101 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.1900 - Val accuracy: 0.5714 - Val loss: 0.9865 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.1413 - Val accuracy: 0.8571 - Val loss: 0.5942 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.1081 - Val accuracy: 0.8571 - Val loss: 0.3889 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0958 - Val accuracy: 0.8571 - Val loss: 0.3535 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0833 - Val accuracy: 0.8571 - Val loss: 0.3581 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0749 - Val accuracy: 0.8571 - Val loss: 0.3650 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0725 - Val accuracy: 0.8571 - Val loss: 0.3699 - LR: 0.00e+00\n","\tBest epoch: 72 - Best val accuracy: 0.8571 - Best val loss: 0.3531\n","\n","\tEpoch 10/100 - Train loss: 0.4591 - Val accuracy: 0.7143 - Val loss: 1.0105 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.2629 - Val accuracy: 0.7143 - Val loss: 0.9540 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.1752 - Val accuracy: 0.7143 - Val loss: 0.9291 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.1314 - Val accuracy: 0.8571 - Val loss: 0.7074 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.0984 - Val accuracy: 0.8571 - Val loss: 0.4249 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.0871 - Val accuracy: 0.8571 - Val loss: 0.2957 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0684 - Val accuracy: 0.8571 - Val loss: 0.2646 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0626 - Val accuracy: 0.8571 - Val loss: 0.2566 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0598 - Val accuracy: 0.8571 - Val loss: 0.2534 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0554 - Val accuracy: 0.8571 - Val loss: 0.2526 - LR: 0.00e+00\n","\tBest epoch: 100 - Best val accuracy: 0.8571 - Best val loss: 0.2526\n","\n","Source class: WAL | Domain: 58 | Accuracy: 0.8714 | Loss: 0.2802\n","\n","Domain: 59\n","x_dp_dom.shape: (43, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Training and evaluating on Dp data via cross-validation...\n","\tEpoch 10/100 - Train loss: 0.5818 - Val accuracy: 0.1429 - Val loss: 1.1371 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.3346 - Val accuracy: 0.1429 - Val loss: 1.3057 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.2382 - Val accuracy: 0.1429 - Val loss: 1.5755 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.1677 - Val accuracy: 0.4286 - Val loss: 1.2446 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.1261 - Val accuracy: 1.0000 - Val loss: 0.4310 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.1054 - Val accuracy: 1.0000 - Val loss: 0.1969 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0879 - Val accuracy: 1.0000 - Val loss: 0.1563 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0763 - Val accuracy: 1.0000 - Val loss: 0.1459 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0702 - Val accuracy: 1.0000 - Val loss: 0.1417 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0651 - Val accuracy: 1.0000 - Val loss: 0.1405 - LR: 0.00e+00\n","\tBest epoch: 100 - Best val accuracy: 1.0000 - Best val loss: 0.1405\n","\n","\tEpoch 10/100 - Train loss: 0.6142 - Val accuracy: 0.7143 - Val loss: 1.0759 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.4002 - Val accuracy: 0.1429 - Val loss: 1.1628 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.2787 - Val accuracy: 0.1429 - Val loss: 1.3052 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.2236 - Val accuracy: 0.2857 - Val loss: 1.0828 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.1891 - Val accuracy: 0.8571 - Val loss: 0.4895 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.1470 - Val accuracy: 1.0000 - Val loss: 0.2607 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.1251 - Val accuracy: 1.0000 - Val loss: 0.2091 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.1047 - Val accuracy: 1.0000 - Val loss: 0.1920 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0994 - Val accuracy: 1.0000 - Val loss: 0.1843 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.1124 - Val accuracy: 1.0000 - Val loss: 0.1814 - LR: 0.00e+00\n","\tBest epoch: 100 - Best val accuracy: 1.0000 - Best val loss: 0.1814\n","\n","\tEpoch 10/100 - Train loss: 0.5100 - Val accuracy: 0.1429 - Val loss: 1.1220 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.3082 - Val accuracy: 0.1429 - Val loss: 1.2897 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.2235 - Val accuracy: 0.1429 - Val loss: 1.5430 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.1488 - Val accuracy: 0.2857 - Val loss: 1.4820 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.0992 - Val accuracy: 0.7143 - Val loss: 0.7536 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.0941 - Val accuracy: 1.0000 - Val loss: 0.2933 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0692 - Val accuracy: 1.0000 - Val loss: 0.1675 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0606 - Val accuracy: 1.0000 - Val loss: 0.1303 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0556 - Val accuracy: 1.0000 - Val loss: 0.1163 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0531 - Val accuracy: 1.0000 - Val loss: 0.1111 - LR: 0.00e+00\n","\tBest epoch: 100 - Best val accuracy: 1.0000 - Best val loss: 0.1111\n","\n","\tEpoch 10/100 - Train loss: 0.5376 - Val accuracy: 0.1429 - Val loss: 1.1174 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.3528 - Val accuracy: 0.1429 - Val loss: 1.2052 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.2655 - Val accuracy: 0.1429 - Val loss: 1.3176 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.2060 - Val accuracy: 0.2857 - Val loss: 1.1480 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.1625 - Val accuracy: 1.0000 - Val loss: 0.5501 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.1361 - Val accuracy: 1.0000 - Val loss: 0.2838 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.1163 - Val accuracy: 1.0000 - Val loss: 0.2129 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0945 - Val accuracy: 1.0000 - Val loss: 0.1865 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0959 - Val accuracy: 1.0000 - Val loss: 0.1737 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0856 - Val accuracy: 1.0000 - Val loss: 0.1684 - LR: 0.00e+00\n","\tBest epoch: 100 - Best val accuracy: 1.0000 - Best val loss: 0.1684\n","\n","\tEpoch 10/100 - Train loss: 0.5572 - Val accuracy: 0.1429 - Val loss: 1.0936 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.3602 - Val accuracy: 0.1429 - Val loss: 1.1997 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.2680 - Val accuracy: 0.1429 - Val loss: 1.3701 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.1999 - Val accuracy: 0.2857 - Val loss: 1.2160 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.1615 - Val accuracy: 0.8571 - Val loss: 0.6547 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.1398 - Val accuracy: 1.0000 - Val loss: 0.3352 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.1149 - Val accuracy: 1.0000 - Val loss: 0.2279 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0970 - Val accuracy: 1.0000 - Val loss: 0.1895 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0904 - Val accuracy: 1.0000 - Val loss: 0.1738 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0870 - Val accuracy: 1.0000 - Val loss: 0.1675 - LR: 0.00e+00\n","\tBest epoch: 100 - Best val accuracy: 1.0000 - Best val loss: 0.1675\n","\n","Source class: WAL | Domain: 59 | Accuracy: 0.9778 | Loss: 0.1670\n","\n","Domain: 60\n","x_dp_dom.shape: (47, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Training and evaluating on Dp data via cross-validation...\n","\tEpoch 10/100 - Train loss: 0.6650 - Val accuracy: 0.6250 - Val loss: 1.0814 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.4684 - Val accuracy: 0.3750 - Val loss: 1.0999 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.3429 - Val accuracy: 0.2500 - Val loss: 1.1738 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.2779 - Val accuracy: 0.3750 - Val loss: 1.1415 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.2271 - Val accuracy: 0.8750 - Val loss: 0.7312 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.1926 - Val accuracy: 0.8750 - Val loss: 0.4588 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.1792 - Val accuracy: 0.8750 - Val loss: 0.3847 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.1585 - Val accuracy: 0.8750 - Val loss: 0.3649 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.1394 - Val accuracy: 0.8750 - Val loss: 0.3593 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.1400 - Val accuracy: 0.8750 - Val loss: 0.3575 - LR: 0.00e+00\n","\tBest epoch: 100 - Best val accuracy: 0.8750 - Best val loss: 0.3575\n","\n","\tEpoch 10/100 - Train loss: 0.5909 - Val accuracy: 0.2500 - Val loss: 1.0956 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.4321 - Val accuracy: 0.2500 - Val loss: 1.1415 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.3230 - Val accuracy: 0.3750 - Val loss: 1.2300 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.2476 - Val accuracy: 0.3750 - Val loss: 1.1366 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.1990 - Val accuracy: 0.8750 - Val loss: 0.6591 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.1696 - Val accuracy: 0.8750 - Val loss: 0.3511 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.1478 - Val accuracy: 0.8750 - Val loss: 0.2686 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.1196 - Val accuracy: 0.8750 - Val loss: 0.2451 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.1104 - Val accuracy: 0.8750 - Val loss: 0.2365 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.1056 - Val accuracy: 0.8750 - Val loss: 0.2334 - LR: 0.00e+00\n","\tBest epoch: 100 - Best val accuracy: 0.8750 - Best val loss: 0.2334\n","\n","\tEpoch 10/100 - Train loss: 0.6609 - Val accuracy: 0.1250 - Val loss: 1.1294 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.4764 - Val accuracy: 0.1250 - Val loss: 1.1410 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.3445 - Val accuracy: 0.2500 - Val loss: 1.1645 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.2534 - Val accuracy: 0.2500 - Val loss: 1.0721 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.1868 - Val accuracy: 0.7500 - Val loss: 0.7473 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.1584 - Val accuracy: 0.8750 - Val loss: 0.4644 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.1413 - Val accuracy: 0.8750 - Val loss: 0.3580 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.1171 - Val accuracy: 0.8750 - Val loss: 0.3290 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0929 - Val accuracy: 0.8750 - Val loss: 0.3190 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.1007 - Val accuracy: 0.8750 - Val loss: 0.3166 - LR: 0.00e+00\n","\tBest epoch: 100 - Best val accuracy: 0.8750 - Best val loss: 0.3166\n","\n","\tEpoch 10/100 - Train loss: 0.6522 - Val accuracy: 0.2500 - Val loss: 1.1273 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.4130 - Val accuracy: 0.2500 - Val loss: 1.2100 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.3000 - Val accuracy: 0.2500 - Val loss: 1.3371 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.2414 - Val accuracy: 0.3750 - Val loss: 1.0851 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.1933 - Val accuracy: 0.8750 - Val loss: 0.5077 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.1723 - Val accuracy: 0.8750 - Val loss: 0.3383 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.1488 - Val accuracy: 0.8750 - Val loss: 0.3271 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.1280 - Val accuracy: 0.8750 - Val loss: 0.3308 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.1267 - Val accuracy: 0.8750 - Val loss: 0.3343 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.1225 - Val accuracy: 0.8750 - Val loss: 0.3369 - LR: 0.00e+00\n","\tBest epoch: 69 - Best val accuracy: 0.8750 - Best val loss: 0.3270\n","\n","\tEpoch 10/100 - Train loss: 0.6380 - Val accuracy: 0.2500 - Val loss: 1.0976 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.4073 - Val accuracy: 0.2500 - Val loss: 1.2569 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.3038 - Val accuracy: 0.2500 - Val loss: 1.5285 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.2357 - Val accuracy: 0.2500 - Val loss: 1.4315 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.2135 - Val accuracy: 0.6250 - Val loss: 0.7555 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.1843 - Val accuracy: 0.8750 - Val loss: 0.3858 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.1604 - Val accuracy: 0.8750 - Val loss: 0.3046 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.1495 - Val accuracy: 0.8750 - Val loss: 0.2861 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.1352 - Val accuracy: 0.8750 - Val loss: 0.2806 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.1411 - Val accuracy: 0.8750 - Val loss: 0.2785 - LR: 0.00e+00\n","\tBest epoch: 100 - Best val accuracy: 0.8750 - Best val loss: 0.2785\n","\n","Source class: WAL | Domain: 60 | Accuracy: 0.8489 | Loss: 0.3172\n","\n","Domain: 61\n","x_dp_dom.shape: (47, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Training and evaluating on Dp data via cross-validation...\n","\tEpoch 10/100 - Train loss: 0.6255 - Val accuracy: 0.2500 - Val loss: 1.1039 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.3500 - Val accuracy: 0.2500 - Val loss: 1.2110 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.2491 - Val accuracy: 0.2500 - Val loss: 1.4389 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.1687 - Val accuracy: 0.2500 - Val loss: 1.5755 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.1225 - Val accuracy: 0.3750 - Val loss: 1.4282 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.0914 - Val accuracy: 0.8750 - Val loss: 1.1519 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0777 - Val accuracy: 0.8750 - Val loss: 1.1844 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0633 - Val accuracy: 0.8750 - Val loss: 1.2349 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0578 - Val accuracy: 0.8750 - Val loss: 1.2552 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0612 - Val accuracy: 0.8750 - Val loss: 1.2634 - LR: 0.00e+00\n","\tBest epoch: 9 - Best val accuracy: 0.2500 - Best val loss: 1.1029\n","\n","\tEpoch 10/100 - Train loss: 0.6420 - Val accuracy: 0.2500 - Val loss: 1.1126 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.3836 - Val accuracy: 0.2500 - Val loss: 1.1717 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.2547 - Val accuracy: 0.2500 - Val loss: 1.3518 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.1696 - Val accuracy: 0.2500 - Val loss: 1.3999 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.1333 - Val accuracy: 0.5000 - Val loss: 0.9730 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.0927 - Val accuracy: 0.7500 - Val loss: 0.7065 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0803 - Val accuracy: 0.8750 - Val loss: 0.7126 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0726 - Val accuracy: 0.8750 - Val loss: 0.7556 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0721 - Val accuracy: 0.8750 - Val loss: 0.7812 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0629 - Val accuracy: 0.8750 - Val loss: 0.7926 - LR: 0.00e+00\n","\tBest epoch: 64 - Best val accuracy: 0.8750 - Best val loss: 0.6914\n","\n","\tEpoch 10/100 - Train loss: 0.6621 - Val accuracy: 0.6250 - Val loss: 1.0672 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.4636 - Val accuracy: 0.2500 - Val loss: 1.1047 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.3183 - Val accuracy: 0.2500 - Val loss: 1.2522 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.2156 - Val accuracy: 0.2500 - Val loss: 1.4466 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.1645 - Val accuracy: 0.3750 - Val loss: 1.4142 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.1182 - Val accuracy: 0.6250 - Val loss: 1.1994 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0991 - Val accuracy: 0.7500 - Val loss: 1.1507 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0743 - Val accuracy: 0.7500 - Val loss: 1.1645 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0743 - Val accuracy: 0.8750 - Val loss: 1.1808 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0748 - Val accuracy: 0.8750 - Val loss: 1.1881 - LR: 0.00e+00\n","\tBest epoch: 10 - Best val accuracy: 0.6250 - Best val loss: 1.0672\n","\n","\tEpoch 10/100 - Train loss: 0.6773 - Val accuracy: 0.2500 - Val loss: 1.0878 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.4277 - Val accuracy: 0.2500 - Val loss: 1.1755 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.2806 - Val accuracy: 0.2500 - Val loss: 1.4603 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.2028 - Val accuracy: 0.2500 - Val loss: 1.6043 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.1468 - Val accuracy: 0.2500 - Val loss: 0.9889 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.1229 - Val accuracy: 0.8750 - Val loss: 0.3856 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.1026 - Val accuracy: 0.8750 - Val loss: 0.2275 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0892 - Val accuracy: 0.8750 - Val loss: 0.1849 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0730 - Val accuracy: 1.0000 - Val loss: 0.1690 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0723 - Val accuracy: 1.0000 - Val loss: 0.1638 - LR: 0.00e+00\n","\tBest epoch: 100 - Best val accuracy: 1.0000 - Best val loss: 0.1638\n","\n","\tEpoch 10/100 - Train loss: 0.6121 - Val accuracy: 0.6250 - Val loss: 1.0349 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.4060 - Val accuracy: 0.2500 - Val loss: 1.0565 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.2602 - Val accuracy: 0.2500 - Val loss: 1.2102 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.2010 - Val accuracy: 0.2500 - Val loss: 1.3004 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.1439 - Val accuracy: 0.3750 - Val loss: 0.9637 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.1107 - Val accuracy: 0.8750 - Val loss: 0.4362 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0866 - Val accuracy: 0.8750 - Val loss: 0.2589 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0782 - Val accuracy: 0.8750 - Val loss: 0.2164 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0724 - Val accuracy: 0.8750 - Val loss: 0.2017 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0670 - Val accuracy: 0.8750 - Val loss: 0.1966 - LR: 0.00e+00\n","\tBest epoch: 100 - Best val accuracy: 0.8750 - Best val loss: 0.1966\n","\n","Source class: WAL | Domain: 61 | Accuracy: 0.9133 | Loss: 0.4745\n","\n","Domain: 62\n","x_dp_dom.shape: (47, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Training and evaluating on Dp data via cross-validation...\n","\tEpoch 10/100 - Train loss: 0.5736 - Val accuracy: 0.2500 - Val loss: 1.0930 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.3724 - Val accuracy: 0.2500 - Val loss: 1.1840 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.2672 - Val accuracy: 0.2500 - Val loss: 1.3820 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.2059 - Val accuracy: 0.2500 - Val loss: 1.5162 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.1534 - Val accuracy: 0.3750 - Val loss: 1.0278 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.1185 - Val accuracy: 0.8750 - Val loss: 0.3780 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0993 - Val accuracy: 0.8750 - Val loss: 0.2351 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0927 - Val accuracy: 0.8750 - Val loss: 0.2040 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0850 - Val accuracy: 0.8750 - Val loss: 0.1940 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0810 - Val accuracy: 0.8750 - Val loss: 0.1906 - LR: 0.00e+00\n","\tBest epoch: 100 - Best val accuracy: 0.8750 - Best val loss: 0.1906\n","\n","\tEpoch 10/100 - Train loss: 0.5934 - Val accuracy: 0.2500 - Val loss: 1.1188 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.3579 - Val accuracy: 0.2500 - Val loss: 1.2037 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.2429 - Val accuracy: 0.2500 - Val loss: 1.3788 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.1771 - Val accuracy: 0.2500 - Val loss: 1.3914 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.1302 - Val accuracy: 0.6250 - Val loss: 0.8915 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.0962 - Val accuracy: 0.8750 - Val loss: 0.3862 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0884 - Val accuracy: 0.8750 - Val loss: 0.2511 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0705 - Val accuracy: 0.8750 - Val loss: 0.2269 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0663 - Val accuracy: 0.8750 - Val loss: 0.2223 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0656 - Val accuracy: 0.8750 - Val loss: 0.2217 - LR: 0.00e+00\n","\tBest epoch: 100 - Best val accuracy: 0.8750 - Best val loss: 0.2217\n","\n","\tEpoch 10/100 - Train loss: 0.6011 - Val accuracy: 0.1250 - Val loss: 1.1609 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.3536 - Val accuracy: 0.2500 - Val loss: 1.3087 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.2286 - Val accuracy: 0.3750 - Val loss: 1.5319 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.1710 - Val accuracy: 0.3750 - Val loss: 1.5345 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.1289 - Val accuracy: 0.5000 - Val loss: 0.9092 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.1032 - Val accuracy: 1.0000 - Val loss: 0.2808 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0819 - Val accuracy: 1.0000 - Val loss: 0.1340 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0696 - Val accuracy: 1.0000 - Val loss: 0.1016 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0618 - Val accuracy: 1.0000 - Val loss: 0.0916 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0610 - Val accuracy: 1.0000 - Val loss: 0.0885 - LR: 0.00e+00\n","\tBest epoch: 100 - Best val accuracy: 1.0000 - Best val loss: 0.0885\n","\n","\tEpoch 10/100 - Train loss: 0.5459 - Val accuracy: 0.2500 - Val loss: 1.1036 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.3272 - Val accuracy: 0.2500 - Val loss: 1.1812 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.2109 - Val accuracy: 0.2500 - Val loss: 1.3526 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.1449 - Val accuracy: 0.1250 - Val loss: 1.3935 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.1005 - Val accuracy: 0.6250 - Val loss: 0.9535 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.0770 - Val accuracy: 1.0000 - Val loss: 0.4008 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0638 - Val accuracy: 1.0000 - Val loss: 0.2243 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0606 - Val accuracy: 1.0000 - Val loss: 0.1810 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0495 - Val accuracy: 1.0000 - Val loss: 0.1670 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0444 - Val accuracy: 1.0000 - Val loss: 0.1624 - LR: 0.00e+00\n","\tBest epoch: 100 - Best val accuracy: 1.0000 - Best val loss: 0.1624\n","\n","\tEpoch 10/100 - Train loss: 0.5613 - Val accuracy: 0.6250 - Val loss: 1.0614 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.3774 - Val accuracy: 0.2500 - Val loss: 1.1209 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.2954 - Val accuracy: 0.2500 - Val loss: 1.2163 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.2314 - Val accuracy: 0.2500 - Val loss: 1.1951 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.1958 - Val accuracy: 0.8750 - Val loss: 0.7292 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.1691 - Val accuracy: 0.8750 - Val loss: 0.3471 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.1398 - Val accuracy: 0.8750 - Val loss: 0.2679 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.1184 - Val accuracy: 0.8750 - Val loss: 0.2453 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.1114 - Val accuracy: 0.8750 - Val loss: 0.2366 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.1080 - Val accuracy: 0.8750 - Val loss: 0.2333 - LR: 0.00e+00\n","\tBest epoch: 100 - Best val accuracy: 0.8750 - Best val loss: 0.2333\n","\n","Source class: WAL | Domain: 62 | Accuracy: 0.9578 | Loss: 0.1970\n","\n","Domain: 63\n","x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Training and evaluating on Dp data via cross-validation...\n","\tEpoch 10/100 - Train loss: 0.5629 - Val accuracy: 0.7143 - Val loss: 1.0675 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.3758 - Val accuracy: 0.1429 - Val loss: 1.1136 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.2420 - Val accuracy: 0.1429 - Val loss: 1.2608 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.1671 - Val accuracy: 0.1429 - Val loss: 1.2381 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.1179 - Val accuracy: 0.5714 - Val loss: 0.8519 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.0886 - Val accuracy: 0.8571 - Val loss: 0.6020 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0728 - Val accuracy: 0.8571 - Val loss: 0.5349 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0652 - Val accuracy: 0.8571 - Val loss: 0.5166 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0625 - Val accuracy: 0.8571 - Val loss: 0.5108 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0606 - Val accuracy: 0.8571 - Val loss: 0.5091 - LR: 0.00e+00\n","\tBest epoch: 100 - Best val accuracy: 0.8571 - Best val loss: 0.5091\n","\n","\tEpoch 10/100 - Train loss: 0.7021 - Val accuracy: 0.7143 - Val loss: 1.0360 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.5066 - Val accuracy: 0.7143 - Val loss: 1.0477 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.3473 - Val accuracy: 0.1429 - Val loss: 1.1233 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.2456 - Val accuracy: 0.7143 - Val loss: 0.9767 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.1883 - Val accuracy: 0.8571 - Val loss: 0.5928 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.1443 - Val accuracy: 0.8571 - Val loss: 0.3817 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.1100 - Val accuracy: 0.7143 - Val loss: 0.3416 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.1042 - Val accuracy: 0.7143 - Val loss: 0.3403 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0937 - Val accuracy: 0.7143 - Val loss: 0.3421 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0906 - Val accuracy: 0.7143 - Val loss: 0.3441 - LR: 0.00e+00\n","\tBest epoch: 75 - Best val accuracy: 0.7143 - Best val loss: 0.3392\n","\n","\tEpoch 10/100 - Train loss: 0.6473 - Val accuracy: 0.7143 - Val loss: 1.0892 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.4367 - Val accuracy: 0.1429 - Val loss: 1.1224 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.3251 - Val accuracy: 0.1429 - Val loss: 1.2282 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.2286 - Val accuracy: 0.1429 - Val loss: 1.1976 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.1629 - Val accuracy: 0.7143 - Val loss: 0.7964 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.1438 - Val accuracy: 0.8571 - Val loss: 0.4362 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.1020 - Val accuracy: 0.8571 - Val loss: 0.3140 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0903 - Val accuracy: 0.8571 - Val loss: 0.2803 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0818 - Val accuracy: 0.8571 - Val loss: 0.2683 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0779 - Val accuracy: 0.8571 - Val loss: 0.2647 - LR: 0.00e+00\n","\tBest epoch: 100 - Best val accuracy: 0.8571 - Best val loss: 0.2647\n","\n","\tEpoch 10/100 - Train loss: 0.5335 - Val accuracy: 0.7143 - Val loss: 1.0593 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.3517 - Val accuracy: 0.1429 - Val loss: 1.1158 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.2510 - Val accuracy: 0.1429 - Val loss: 1.3419 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.1840 - Val accuracy: 0.1429 - Val loss: 1.3430 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.1455 - Val accuracy: 0.8571 - Val loss: 0.6989 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.1100 - Val accuracy: 1.0000 - Val loss: 0.2812 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0925 - Val accuracy: 1.0000 - Val loss: 0.1923 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0832 - Val accuracy: 0.8571 - Val loss: 0.1796 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0761 - Val accuracy: 0.8571 - Val loss: 0.1779 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0737 - Val accuracy: 0.8571 - Val loss: 0.1783 - LR: 0.00e+00\n","\tBest epoch: 92 - Best val accuracy: 0.8571 - Best val loss: 0.1778\n","\n","\tEpoch 10/100 - Train loss: 0.6771 - Val accuracy: 0.7143 - Val loss: 1.0634 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.4561 - Val accuracy: 0.7143 - Val loss: 1.0227 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.3049 - Val accuracy: 0.1429 - Val loss: 1.0757 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.2085 - Val accuracy: 0.4286 - Val loss: 1.0186 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.1708 - Val accuracy: 0.7143 - Val loss: 0.7256 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.1314 - Val accuracy: 0.7143 - Val loss: 0.5522 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.1051 - Val accuracy: 0.7143 - Val loss: 0.5146 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0946 - Val accuracy: 0.7143 - Val loss: 0.5089 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0844 - Val accuracy: 0.7143 - Val loss: 0.5086 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0810 - Val accuracy: 0.7143 - Val loss: 0.5082 - LR: 0.00e+00\n","\tBest epoch: 100 - Best val accuracy: 0.7143 - Best val loss: 0.5082\n","\n","Source class: WAL | Domain: 63 | Accuracy: 0.8333 | Loss: 0.4569\n","\n","Domain: 64\n","x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Training and evaluating on Dp data via cross-validation...\n","\tEpoch 10/100 - Train loss: 0.4835 - Val accuracy: 0.7143 - Val loss: 1.0359 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.2937 - Val accuracy: 0.1429 - Val loss: 1.1509 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.1910 - Val accuracy: 0.1429 - Val loss: 1.3254 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.1538 - Val accuracy: 0.2857 - Val loss: 1.1600 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.1115 - Val accuracy: 1.0000 - Val loss: 0.4730 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.0852 - Val accuracy: 1.0000 - Val loss: 0.1582 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0680 - Val accuracy: 1.0000 - Val loss: 0.0864 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0599 - Val accuracy: 1.0000 - Val loss: 0.0646 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0543 - Val accuracy: 1.0000 - Val loss: 0.0565 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0585 - Val accuracy: 1.0000 - Val loss: 0.0538 - LR: 0.00e+00\n","\tBest epoch: 100 - Best val accuracy: 1.0000 - Best val loss: 0.0538\n","\n","\tEpoch 10/100 - Train loss: 0.5587 - Val accuracy: 0.7143 - Val loss: 1.0856 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.3256 - Val accuracy: 0.1429 - Val loss: 1.1739 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.2379 - Val accuracy: 0.1429 - Val loss: 1.3731 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.1856 - Val accuracy: 0.2857 - Val loss: 1.3019 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.1392 - Val accuracy: 1.0000 - Val loss: 0.5551 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.1281 - Val accuracy: 1.0000 - Val loss: 0.1922 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0980 - Val accuracy: 1.0000 - Val loss: 0.1235 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0850 - Val accuracy: 1.0000 - Val loss: 0.1005 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0773 - Val accuracy: 1.0000 - Val loss: 0.0910 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0839 - Val accuracy: 1.0000 - Val loss: 0.0874 - LR: 0.00e+00\n","\tBest epoch: 100 - Best val accuracy: 1.0000 - Best val loss: 0.0874\n","\n","\tEpoch 10/100 - Train loss: 0.5705 - Val accuracy: 0.7143 - Val loss: 1.0375 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.3619 - Val accuracy: 0.1429 - Val loss: 1.1156 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.2289 - Val accuracy: 0.1429 - Val loss: 1.2824 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.1656 - Val accuracy: 0.2857 - Val loss: 1.2203 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.1233 - Val accuracy: 1.0000 - Val loss: 0.5415 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.1048 - Val accuracy: 1.0000 - Val loss: 0.1800 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0762 - Val accuracy: 1.0000 - Val loss: 0.1074 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0702 - Val accuracy: 1.0000 - Val loss: 0.0870 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0583 - Val accuracy: 1.0000 - Val loss: 0.0792 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0623 - Val accuracy: 1.0000 - Val loss: 0.0764 - LR: 0.00e+00\n","\tBest epoch: 100 - Best val accuracy: 1.0000 - Best val loss: 0.0764\n","\n","\tEpoch 10/100 - Train loss: 0.5004 - Val accuracy: 0.7143 - Val loss: 1.0358 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.3103 - Val accuracy: 0.1429 - Val loss: 1.0891 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.2043 - Val accuracy: 0.1429 - Val loss: 1.2194 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.1473 - Val accuracy: 0.2857 - Val loss: 0.9622 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.1163 - Val accuracy: 0.8571 - Val loss: 0.3691 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.0802 - Val accuracy: 1.0000 - Val loss: 0.1912 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0683 - Val accuracy: 1.0000 - Val loss: 0.1554 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0636 - Val accuracy: 1.0000 - Val loss: 0.1421 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0543 - Val accuracy: 1.0000 - Val loss: 0.1349 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0522 - Val accuracy: 1.0000 - Val loss: 0.1320 - LR: 0.00e+00\n","\tBest epoch: 100 - Best val accuracy: 1.0000 - Best val loss: 0.1320\n","\n","\tEpoch 10/100 - Train loss: 0.5679 - Val accuracy: 0.7143 - Val loss: 1.0515 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.3469 - Val accuracy: 0.1429 - Val loss: 1.0716 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.2296 - Val accuracy: 0.1429 - Val loss: 1.1804 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.1667 - Val accuracy: 0.2857 - Val loss: 1.0397 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.1276 - Val accuracy: 1.0000 - Val loss: 0.4621 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.0979 - Val accuracy: 1.0000 - Val loss: 0.1866 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0776 - Val accuracy: 1.0000 - Val loss: 0.1230 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0685 - Val accuracy: 1.0000 - Val loss: 0.1019 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0582 - Val accuracy: 1.0000 - Val loss: 0.0925 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0615 - Val accuracy: 1.0000 - Val loss: 0.0894 - LR: 0.00e+00\n","\tBest epoch: 100 - Best val accuracy: 1.0000 - Best val loss: 0.0894\n","\n","Source class: WAL | Domain: 64 | Accuracy: 0.9528 | Loss: 0.1645\n","\n","Domain: 65\n","x_dp_dom.shape: (50, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Training and evaluating on Dp data via cross-validation...\n","\tEpoch 10/100 - Train loss: 0.5019 - Val accuracy: 0.5000 - Val loss: 1.0785 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.2815 - Val accuracy: 0.2500 - Val loss: 1.1002 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.1790 - Val accuracy: 0.5000 - Val loss: 1.1088 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.1279 - Val accuracy: 0.5000 - Val loss: 0.9925 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.0804 - Val accuracy: 0.7500 - Val loss: 0.5238 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.0619 - Val accuracy: 1.0000 - Val loss: 0.1808 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0512 - Val accuracy: 1.0000 - Val loss: 0.1097 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0444 - Val accuracy: 1.0000 - Val loss: 0.0920 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0395 - Val accuracy: 1.0000 - Val loss: 0.0852 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0395 - Val accuracy: 1.0000 - Val loss: 0.0827 - LR: 0.00e+00\n","\tBest epoch: 100 - Best val accuracy: 1.0000 - Best val loss: 0.0827\n","\n","\tEpoch 10/100 - Train loss: 0.5394 - Val accuracy: 0.5000 - Val loss: 1.0771 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.3389 - Val accuracy: 0.2500 - Val loss: 1.0684 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.2365 - Val accuracy: 0.5000 - Val loss: 0.9634 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.1601 - Val accuracy: 1.0000 - Val loss: 0.6669 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.1177 - Val accuracy: 1.0000 - Val loss: 0.3752 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.0904 - Val accuracy: 1.0000 - Val loss: 0.2302 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0686 - Val accuracy: 1.0000 - Val loss: 0.1699 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0624 - Val accuracy: 1.0000 - Val loss: 0.1414 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0574 - Val accuracy: 1.0000 - Val loss: 0.1286 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0544 - Val accuracy: 1.0000 - Val loss: 0.1244 - LR: 0.00e+00\n","\tBest epoch: 100 - Best val accuracy: 1.0000 - Best val loss: 0.1244\n","\n","\tEpoch 10/100 - Train loss: 0.6142 - Val accuracy: 0.5000 - Val loss: 1.0892 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.3844 - Val accuracy: 0.7500 - Val loss: 1.0674 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.2543 - Val accuracy: 0.2500 - Val loss: 1.0492 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.1794 - Val accuracy: 0.5000 - Val loss: 0.8896 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.1210 - Val accuracy: 0.7500 - Val loss: 0.5455 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.0987 - Val accuracy: 0.8750 - Val loss: 0.3303 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0754 - Val accuracy: 0.8750 - Val loss: 0.2580 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0684 - Val accuracy: 0.8750 - Val loss: 0.2327 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0617 - Val accuracy: 0.8750 - Val loss: 0.2208 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0548 - Val accuracy: 0.8750 - Val loss: 0.2177 - LR: 0.00e+00\n","\tBest epoch: 100 - Best val accuracy: 0.8750 - Best val loss: 0.2177\n","\n","\tEpoch 10/100 - Train loss: 0.5410 - Val accuracy: 0.2500 - Val loss: 1.0910 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.3443 - Val accuracy: 0.2500 - Val loss: 1.0850 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.2409 - Val accuracy: 0.8750 - Val loss: 0.9269 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.1700 - Val accuracy: 0.8750 - Val loss: 0.5568 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.1205 - Val accuracy: 1.0000 - Val loss: 0.2683 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.0930 - Val accuracy: 1.0000 - Val loss: 0.1265 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0692 - Val accuracy: 1.0000 - Val loss: 0.0747 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0640 - Val accuracy: 1.0000 - Val loss: 0.0562 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0529 - Val accuracy: 1.0000 - Val loss: 0.0490 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0530 - Val accuracy: 1.0000 - Val loss: 0.0466 - LR: 0.00e+00\n","\tBest epoch: 100 - Best val accuracy: 1.0000 - Best val loss: 0.0466\n","\n","\tEpoch 10/100 - Train loss: 0.5579 - Val accuracy: 0.2500 - Val loss: 1.0819 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.3461 - Val accuracy: 0.2500 - Val loss: 1.0764 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.2442 - Val accuracy: 0.2500 - Val loss: 1.1026 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.1694 - Val accuracy: 0.3750 - Val loss: 0.9728 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.1313 - Val accuracy: 1.0000 - Val loss: 0.5181 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.0965 - Val accuracy: 1.0000 - Val loss: 0.2259 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0812 - Val accuracy: 1.0000 - Val loss: 0.1519 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0622 - Val accuracy: 1.0000 - Val loss: 0.1284 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0606 - Val accuracy: 1.0000 - Val loss: 0.1194 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0588 - Val accuracy: 1.0000 - Val loss: 0.1161 - LR: 0.00e+00\n","\tBest epoch: 100 - Best val accuracy: 1.0000 - Best val loss: 0.1161\n","\n","Source class: WAL | Domain: 65 | Accuracy: 0.9800 | Loss: 0.1440\n","\n","Domain: 66\n","x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Training and evaluating on Dp data via cross-validation...\n","\tEpoch 10/100 - Train loss: 0.6000 - Val accuracy: 0.1429 - Val loss: 1.0806 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.3370 - Val accuracy: 0.1429 - Val loss: 1.1383 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.2035 - Val accuracy: 0.1429 - Val loss: 1.2689 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.1414 - Val accuracy: 0.2857 - Val loss: 1.1992 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.1006 - Val accuracy: 0.7143 - Val loss: 0.7163 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.0703 - Val accuracy: 0.8571 - Val loss: 0.3607 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0584 - Val accuracy: 0.8571 - Val loss: 0.2645 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0549 - Val accuracy: 0.8571 - Val loss: 0.2409 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0452 - Val accuracy: 0.8571 - Val loss: 0.2331 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0481 - Val accuracy: 0.8571 - Val loss: 0.2305 - LR: 0.00e+00\n","\tBest epoch: 100 - Best val accuracy: 0.8571 - Best val loss: 0.2305\n","\n","\tEpoch 10/100 - Train loss: 0.6665 - Val accuracy: 0.1429 - Val loss: 1.0927 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.4042 - Val accuracy: 0.1429 - Val loss: 1.1171 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.2541 - Val accuracy: 0.1429 - Val loss: 1.2763 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.1552 - Val accuracy: 0.1429 - Val loss: 1.2591 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.1056 - Val accuracy: 0.7143 - Val loss: 0.7331 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.0819 - Val accuracy: 0.8571 - Val loss: 0.3306 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0694 - Val accuracy: 1.0000 - Val loss: 0.2025 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0598 - Val accuracy: 1.0000 - Val loss: 0.1618 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0559 - Val accuracy: 1.0000 - Val loss: 0.1471 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0471 - Val accuracy: 1.0000 - Val loss: 0.1421 - LR: 0.00e+00\n","\tBest epoch: 100 - Best val accuracy: 1.0000 - Best val loss: 0.1421\n","\n","\tEpoch 10/100 - Train loss: 0.6404 - Val accuracy: 0.7143 - Val loss: 1.0663 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.4140 - Val accuracy: 0.1429 - Val loss: 1.1287 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.2781 - Val accuracy: 0.1429 - Val loss: 1.3133 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.2027 - Val accuracy: 0.2857 - Val loss: 1.2714 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.1523 - Val accuracy: 0.8571 - Val loss: 0.7204 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.1102 - Val accuracy: 1.0000 - Val loss: 0.3450 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0919 - Val accuracy: 1.0000 - Val loss: 0.2299 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0863 - Val accuracy: 1.0000 - Val loss: 0.1925 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0722 - Val accuracy: 1.0000 - Val loss: 0.1787 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0694 - Val accuracy: 1.0000 - Val loss: 0.1737 - LR: 0.00e+00\n","\tBest epoch: 100 - Best val accuracy: 1.0000 - Best val loss: 0.1737\n","\n","\tEpoch 10/100 - Train loss: 0.6078 - Val accuracy: 0.7143 - Val loss: 1.0521 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.3718 - Val accuracy: 0.1429 - Val loss: 1.1089 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.2504 - Val accuracy: 0.1429 - Val loss: 1.2996 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.1847 - Val accuracy: 0.1429 - Val loss: 1.3823 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.1349 - Val accuracy: 0.5714 - Val loss: 0.9545 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.1053 - Val accuracy: 1.0000 - Val loss: 0.4394 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0843 - Val accuracy: 1.0000 - Val loss: 0.2622 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0752 - Val accuracy: 1.0000 - Val loss: 0.2175 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0682 - Val accuracy: 1.0000 - Val loss: 0.2043 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0605 - Val accuracy: 1.0000 - Val loss: 0.2002 - LR: 0.00e+00\n","\tBest epoch: 100 - Best val accuracy: 1.0000 - Best val loss: 0.2002\n","\n","\tEpoch 10/100 - Train loss: 0.5331 - Val accuracy: 0.1429 - Val loss: 1.1193 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.3267 - Val accuracy: 0.1429 - Val loss: 1.2467 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.2286 - Val accuracy: 0.1429 - Val loss: 1.4761 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.1736 - Val accuracy: 0.1429 - Val loss: 1.6107 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.1315 - Val accuracy: 0.2857 - Val loss: 1.1935 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.1064 - Val accuracy: 1.0000 - Val loss: 0.4865 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0792 - Val accuracy: 1.0000 - Val loss: 0.2512 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0674 - Val accuracy: 1.0000 - Val loss: 0.1982 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0711 - Val accuracy: 1.0000 - Val loss: 0.1829 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0669 - Val accuracy: 1.0000 - Val loss: 0.1778 - LR: 0.00e+00\n","\tBest epoch: 100 - Best val accuracy: 1.0000 - Best val loss: 0.1778\n","\n","Source class: WAL | Domain: 66 | Accuracy: 0.9083 | Loss: 0.2301\n","\n","Domain: 67\n","x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Training and evaluating on Dp data via cross-validation...\n","\tEpoch 10/100 - Train loss: 0.5688 - Val accuracy: 0.7143 - Val loss: 1.0752 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.3108 - Val accuracy: 0.1429 - Val loss: 1.0760 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.1808 - Val accuracy: 0.1429 - Val loss: 1.0327 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.1139 - Val accuracy: 0.8571 - Val loss: 0.6300 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.0757 - Val accuracy: 1.0000 - Val loss: 0.2666 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.0547 - Val accuracy: 1.0000 - Val loss: 0.1804 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0453 - Val accuracy: 0.8571 - Val loss: 0.1729 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0391 - Val accuracy: 0.8571 - Val loss: 0.1725 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0357 - Val accuracy: 0.8571 - Val loss: 0.1698 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0355 - Val accuracy: 0.8571 - Val loss: 0.1678 - LR: 0.00e+00\n","\tBest epoch: 100 - Best val accuracy: 0.8571 - Best val loss: 0.1678\n","\n","\tEpoch 10/100 - Train loss: 0.6778 - Val accuracy: 0.7143 - Val loss: 1.0817 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.4222 - Val accuracy: 0.8571 - Val loss: 1.0724 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.2854 - Val accuracy: 0.2857 - Val loss: 1.1170 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.2204 - Val accuracy: 0.7143 - Val loss: 0.8980 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.1665 - Val accuracy: 1.0000 - Val loss: 0.4850 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.1325 - Val accuracy: 1.0000 - Val loss: 0.2705 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.1132 - Val accuracy: 1.0000 - Val loss: 0.2019 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0900 - Val accuracy: 1.0000 - Val loss: 0.1778 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0919 - Val accuracy: 1.0000 - Val loss: 0.1677 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0821 - Val accuracy: 1.0000 - Val loss: 0.1639 - LR: 0.00e+00\n","\tBest epoch: 100 - Best val accuracy: 1.0000 - Best val loss: 0.1639\n","\n","\tEpoch 10/100 - Train loss: 0.6461 - Val accuracy: 0.1429 - Val loss: 1.1398 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.3889 - Val accuracy: 0.1429 - Val loss: 1.1704 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.2445 - Val accuracy: 0.2857 - Val loss: 1.2097 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.1740 - Val accuracy: 0.5714 - Val loss: 1.0160 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.1303 - Val accuracy: 1.0000 - Val loss: 0.5146 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.1064 - Val accuracy: 1.0000 - Val loss: 0.2353 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0764 - Val accuracy: 1.0000 - Val loss: 0.1772 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0676 - Val accuracy: 0.8571 - Val loss: 0.1696 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0640 - Val accuracy: 0.8571 - Val loss: 0.1681 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0599 - Val accuracy: 0.8571 - Val loss: 0.1687 - LR: 0.00e+00\n","\tBest epoch: 92 - Best val accuracy: 0.8571 - Best val loss: 0.1680\n","\n","\tEpoch 10/100 - Train loss: 0.4586 - Val accuracy: 0.7143 - Val loss: 1.0307 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.2972 - Val accuracy: 0.1429 - Val loss: 1.0884 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.2354 - Val accuracy: 0.1429 - Val loss: 1.2464 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.1707 - Val accuracy: 0.2857 - Val loss: 1.0614 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.1477 - Val accuracy: 0.8571 - Val loss: 0.5091 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.1102 - Val accuracy: 0.8571 - Val loss: 0.2570 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0869 - Val accuracy: 1.0000 - Val loss: 0.1867 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0794 - Val accuracy: 1.0000 - Val loss: 0.1627 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0678 - Val accuracy: 1.0000 - Val loss: 0.1531 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0739 - Val accuracy: 1.0000 - Val loss: 0.1498 - LR: 0.00e+00\n","\tBest epoch: 100 - Best val accuracy: 1.0000 - Best val loss: 0.1498\n","\n","\tEpoch 10/100 - Train loss: 0.5227 - Val accuracy: 0.7143 - Val loss: 1.0510 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.3272 - Val accuracy: 0.8571 - Val loss: 1.0462 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.2328 - Val accuracy: 0.4286 - Val loss: 1.0299 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.1835 - Val accuracy: 0.8571 - Val loss: 0.7792 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.1394 - Val accuracy: 0.8571 - Val loss: 0.4127 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.1151 - Val accuracy: 0.8571 - Val loss: 0.2467 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0989 - Val accuracy: 0.8571 - Val loss: 0.1897 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0807 - Val accuracy: 1.0000 - Val loss: 0.1680 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0755 - Val accuracy: 1.0000 - Val loss: 0.1585 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0713 - Val accuracy: 1.0000 - Val loss: 0.1546 - LR: 0.00e+00\n","\tBest epoch: 100 - Best val accuracy: 1.0000 - Best val loss: 0.1546\n","\n","Source class: WAL | Domain: 67 | Accuracy: 0.9056 | Loss: 0.2096\n","\n","Domain: 68\n","x_dp_dom.shape: (43, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Training and evaluating on Dp data via cross-validation...\n","\tEpoch 10/100 - Train loss: 0.6404 - Val accuracy: 0.1429 - Val loss: 1.1075 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.3939 - Val accuracy: 0.1429 - Val loss: 1.1596 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.2695 - Val accuracy: 0.1429 - Val loss: 1.2931 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.2084 - Val accuracy: 0.2857 - Val loss: 1.1436 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.1557 - Val accuracy: 0.8571 - Val loss: 0.5850 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.1196 - Val accuracy: 1.0000 - Val loss: 0.3152 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.1010 - Val accuracy: 1.0000 - Val loss: 0.2381 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0841 - Val accuracy: 1.0000 - Val loss: 0.2104 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0829 - Val accuracy: 1.0000 - Val loss: 0.1986 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0802 - Val accuracy: 1.0000 - Val loss: 0.1942 - LR: 0.00e+00\n","\tBest epoch: 100 - Best val accuracy: 1.0000 - Best val loss: 0.1942\n","\n","\tEpoch 10/100 - Train loss: 0.5411 - Val accuracy: 0.1429 - Val loss: 1.1380 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.3444 - Val accuracy: 0.1429 - Val loss: 1.3238 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.2495 - Val accuracy: 0.1429 - Val loss: 1.6193 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.1874 - Val accuracy: 0.1429 - Val loss: 1.7242 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.1473 - Val accuracy: 0.4286 - Val loss: 1.0604 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.1036 - Val accuracy: 0.8571 - Val loss: 0.4529 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0990 - Val accuracy: 0.8571 - Val loss: 0.3002 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0824 - Val accuracy: 0.8571 - Val loss: 0.2617 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0732 - Val accuracy: 0.8571 - Val loss: 0.2493 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0805 - Val accuracy: 0.8571 - Val loss: 0.2446 - LR: 0.00e+00\n","\tBest epoch: 100 - Best val accuracy: 0.8571 - Best val loss: 0.2446\n","\n","\tEpoch 10/100 - Train loss: 0.5865 - Val accuracy: 0.7143 - Val loss: 1.0318 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.3727 - Val accuracy: 0.1429 - Val loss: 1.1541 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.2657 - Val accuracy: 0.1429 - Val loss: 1.4176 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.2138 - Val accuracy: 0.1429 - Val loss: 1.4599 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.1578 - Val accuracy: 0.4286 - Val loss: 0.8838 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.1407 - Val accuracy: 1.0000 - Val loss: 0.3922 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.1267 - Val accuracy: 1.0000 - Val loss: 0.2354 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.1024 - Val accuracy: 1.0000 - Val loss: 0.1870 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0972 - Val accuracy: 1.0000 - Val loss: 0.1687 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0985 - Val accuracy: 1.0000 - Val loss: 0.1618 - LR: 0.00e+00\n","\tBest epoch: 100 - Best val accuracy: 1.0000 - Best val loss: 0.1618\n","\n","\tEpoch 10/100 - Train loss: 0.5379 - Val accuracy: 0.1429 - Val loss: 1.0925 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.3433 - Val accuracy: 0.1429 - Val loss: 1.1823 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.2759 - Val accuracy: 0.1429 - Val loss: 1.3767 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.2142 - Val accuracy: 0.1429 - Val loss: 1.3232 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.1890 - Val accuracy: 0.8571 - Val loss: 0.6395 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.1592 - Val accuracy: 0.8571 - Val loss: 0.2831 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.1333 - Val accuracy: 0.8571 - Val loss: 0.2054 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.1091 - Val accuracy: 0.8571 - Val loss: 0.1835 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.1006 - Val accuracy: 0.8571 - Val loss: 0.1742 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0958 - Val accuracy: 0.8571 - Val loss: 0.1698 - LR: 0.00e+00\n","\tBest epoch: 100 - Best val accuracy: 0.8571 - Best val loss: 0.1698\n","\n","\tEpoch 10/100 - Train loss: 0.6183 - Val accuracy: 0.1429 - Val loss: 1.1110 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.3541 - Val accuracy: 0.1429 - Val loss: 1.2749 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.2419 - Val accuracy: 0.1429 - Val loss: 1.5467 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.1760 - Val accuracy: 0.1429 - Val loss: 1.6200 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.1451 - Val accuracy: 0.4286 - Val loss: 1.0214 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.1342 - Val accuracy: 0.7143 - Val loss: 0.4531 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0965 - Val accuracy: 1.0000 - Val loss: 0.2779 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0932 - Val accuracy: 1.0000 - Val loss: 0.2230 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0894 - Val accuracy: 1.0000 - Val loss: 0.2037 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0857 - Val accuracy: 1.0000 - Val loss: 0.1967 - LR: 0.00e+00\n","\tBest epoch: 100 - Best val accuracy: 1.0000 - Best val loss: 0.1967\n","\n","Source class: WAL | Domain: 68 | Accuracy: 0.8556 | Loss: 0.2723\n","\n","Domain: 69\n","x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Training and evaluating on Dp data via cross-validation...\n","\tEpoch 10/100 - Train loss: 0.6109 - Val accuracy: 0.1429 - Val loss: 1.1121 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.3464 - Val accuracy: 0.8571 - Val loss: 1.0038 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.2327 - Val accuracy: 0.8571 - Val loss: 0.7607 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.1639 - Val accuracy: 1.0000 - Val loss: 0.4462 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.1305 - Val accuracy: 1.0000 - Val loss: 0.2537 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.0994 - Val accuracy: 1.0000 - Val loss: 0.1815 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0854 - Val accuracy: 1.0000 - Val loss: 0.1541 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0757 - Val accuracy: 1.0000 - Val loss: 0.1415 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0600 - Val accuracy: 1.0000 - Val loss: 0.1340 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0643 - Val accuracy: 1.0000 - Val loss: 0.1307 - LR: 0.00e+00\n","\tBest epoch: 100 - Best val accuracy: 1.0000 - Best val loss: 0.1307\n","\n","\tEpoch 10/100 - Train loss: 0.4452 - Val accuracy: 0.7143 - Val loss: 1.0249 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.2949 - Val accuracy: 0.1429 - Val loss: 1.0638 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.2196 - Val accuracy: 0.8571 - Val loss: 0.9671 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.1566 - Val accuracy: 1.0000 - Val loss: 0.5292 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.1164 - Val accuracy: 1.0000 - Val loss: 0.2604 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.0847 - Val accuracy: 1.0000 - Val loss: 0.1807 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0730 - Val accuracy: 0.8571 - Val loss: 0.1560 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0584 - Val accuracy: 0.8571 - Val loss: 0.1476 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0578 - Val accuracy: 0.8571 - Val loss: 0.1438 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0552 - Val accuracy: 0.8571 - Val loss: 0.1414 - LR: 0.00e+00\n","\tBest epoch: 100 - Best val accuracy: 0.8571 - Best val loss: 0.1414\n","\n","\tEpoch 10/100 - Train loss: 0.5661 - Val accuracy: 0.1429 - Val loss: 1.1058 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.3425 - Val accuracy: 0.1429 - Val loss: 1.1063 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.2362 - Val accuracy: 0.1429 - Val loss: 0.9991 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.1741 - Val accuracy: 0.8571 - Val loss: 0.6652 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.1430 - Val accuracy: 1.0000 - Val loss: 0.3486 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.1018 - Val accuracy: 1.0000 - Val loss: 0.2285 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0887 - Val accuracy: 1.0000 - Val loss: 0.1984 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0776 - Val accuracy: 1.0000 - Val loss: 0.1878 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0724 - Val accuracy: 1.0000 - Val loss: 0.1833 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0712 - Val accuracy: 0.8571 - Val loss: 0.1815 - LR: 0.00e+00\n","\tBest epoch: 100 - Best val accuracy: 0.8571 - Best val loss: 0.1815\n","\n","\tEpoch 10/100 - Train loss: 0.5271 - Val accuracy: 0.7143 - Val loss: 1.0206 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.3175 - Val accuracy: 0.7143 - Val loss: 0.8679 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.1894 - Val accuracy: 0.7143 - Val loss: 0.6587 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.1348 - Val accuracy: 0.8571 - Val loss: 0.4529 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.1006 - Val accuracy: 1.0000 - Val loss: 0.3175 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.0744 - Val accuracy: 0.8571 - Val loss: 0.2556 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0600 - Val accuracy: 0.8571 - Val loss: 0.2322 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0538 - Val accuracy: 0.8571 - Val loss: 0.2221 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0528 - Val accuracy: 0.8571 - Val loss: 0.2178 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0508 - Val accuracy: 0.8571 - Val loss: 0.2163 - LR: 0.00e+00\n","\tBest epoch: 100 - Best val accuracy: 0.8571 - Best val loss: 0.2163\n","\n","\tEpoch 10/100 - Train loss: 0.4894 - Val accuracy: 0.7143 - Val loss: 1.0416 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.2943 - Val accuracy: 0.7143 - Val loss: 0.8344 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.2141 - Val accuracy: 0.8571 - Val loss: 0.5384 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.1683 - Val accuracy: 0.8571 - Val loss: 0.3540 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.1342 - Val accuracy: 0.8571 - Val loss: 0.2822 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.1183 - Val accuracy: 0.8571 - Val loss: 0.2599 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.1059 - Val accuracy: 0.8571 - Val loss: 0.2542 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0932 - Val accuracy: 0.8571 - Val loss: 0.2545 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0906 - Val accuracy: 0.8571 - Val loss: 0.2549 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0870 - Val accuracy: 0.8571 - Val loss: 0.2547 - LR: 0.00e+00\n","\tBest epoch: 72 - Best val accuracy: 0.8571 - Best val loss: 0.2541\n","\n","Source class: WAL | Domain: 69 | Accuracy: 0.9083 | Loss: 0.1944\n","\n","Domain: 70\n","x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Training and evaluating on Dp data via cross-validation...\n","\tEpoch 10/100 - Train loss: 0.5550 - Val accuracy: 0.7143 - Val loss: 1.0199 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.3167 - Val accuracy: 0.8571 - Val loss: 1.0212 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.2244 - Val accuracy: 0.4286 - Val loss: 1.0394 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.1800 - Val accuracy: 0.5714 - Val loss: 0.8425 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.1463 - Val accuracy: 1.0000 - Val loss: 0.4542 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.1209 - Val accuracy: 1.0000 - Val loss: 0.2394 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.1027 - Val accuracy: 1.0000 - Val loss: 0.1662 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0922 - Val accuracy: 1.0000 - Val loss: 0.1406 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0917 - Val accuracy: 1.0000 - Val loss: 0.1300 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0930 - Val accuracy: 1.0000 - Val loss: 0.1251 - LR: 0.00e+00\n","\tBest epoch: 100 - Best val accuracy: 1.0000 - Best val loss: 0.1251\n","\n","\tEpoch 10/100 - Train loss: 0.5822 - Val accuracy: 0.1429 - Val loss: 1.1005 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.3729 - Val accuracy: 0.1429 - Val loss: 1.1040 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.2475 - Val accuracy: 0.1429 - Val loss: 1.2045 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.1968 - Val accuracy: 0.1429 - Val loss: 1.1784 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.1537 - Val accuracy: 0.7143 - Val loss: 0.7209 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.1151 - Val accuracy: 0.8571 - Val loss: 0.4449 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0938 - Val accuracy: 0.8571 - Val loss: 0.3760 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0824 - Val accuracy: 0.8571 - Val loss: 0.3588 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0791 - Val accuracy: 0.8571 - Val loss: 0.3535 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0823 - Val accuracy: 0.8571 - Val loss: 0.3516 - LR: 0.00e+00\n","\tBest epoch: 100 - Best val accuracy: 0.8571 - Best val loss: 0.3516\n","\n","\tEpoch 10/100 - Train loss: 0.6453 - Val accuracy: 0.7143 - Val loss: 1.0446 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.4215 - Val accuracy: 0.7143 - Val loss: 1.0064 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.3194 - Val accuracy: 0.8571 - Val loss: 0.9959 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.2564 - Val accuracy: 0.8571 - Val loss: 0.7927 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.2125 - Val accuracy: 0.8571 - Val loss: 0.4378 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.1749 - Val accuracy: 0.8571 - Val loss: 0.2757 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.1581 - Val accuracy: 1.0000 - Val loss: 0.2282 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.1409 - Val accuracy: 1.0000 - Val loss: 0.2126 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.1324 - Val accuracy: 1.0000 - Val loss: 0.2054 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.1240 - Val accuracy: 1.0000 - Val loss: 0.2025 - LR: 0.00e+00\n","\tBest epoch: 100 - Best val accuracy: 1.0000 - Best val loss: 0.2025\n","\n","\tEpoch 10/100 - Train loss: 0.5916 - Val accuracy: 0.7143 - Val loss: 1.0223 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.3926 - Val accuracy: 0.7143 - Val loss: 0.9799 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.2568 - Val accuracy: 0.8571 - Val loss: 0.9597 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.2029 - Val accuracy: 0.8571 - Val loss: 0.7951 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.1723 - Val accuracy: 1.0000 - Val loss: 0.4345 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.1371 - Val accuracy: 1.0000 - Val loss: 0.2661 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.1152 - Val accuracy: 1.0000 - Val loss: 0.2228 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.1021 - Val accuracy: 1.0000 - Val loss: 0.2073 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.1036 - Val accuracy: 1.0000 - Val loss: 0.2007 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0991 - Val accuracy: 1.0000 - Val loss: 0.1983 - LR: 0.00e+00\n","\tBest epoch: 100 - Best val accuracy: 1.0000 - Best val loss: 0.1983\n","\n","\tEpoch 10/100 - Train loss: 0.6186 - Val accuracy: 0.7143 - Val loss: 1.0630 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.3883 - Val accuracy: 0.7143 - Val loss: 1.0135 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.2692 - Val accuracy: 0.8571 - Val loss: 0.9157 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.2111 - Val accuracy: 0.8571 - Val loss: 0.6162 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.1791 - Val accuracy: 1.0000 - Val loss: 0.3416 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.1442 - Val accuracy: 1.0000 - Val loss: 0.2515 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.1320 - Val accuracy: 1.0000 - Val loss: 0.2239 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.1129 - Val accuracy: 1.0000 - Val loss: 0.2123 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.1095 - Val accuracy: 1.0000 - Val loss: 0.2069 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.1081 - Val accuracy: 1.0000 - Val loss: 0.2048 - LR: 0.00e+00\n","\tBest epoch: 100 - Best val accuracy: 1.0000 - Best val loss: 0.2048\n","\n","Source class: WAL | Domain: 70 | Accuracy: 0.8861 | Loss: 0.2973\n","\n","Domain: 71\n","x_dp_dom.shape: (44, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Training and evaluating on Dp data via cross-validation...\n","\tEpoch 10/100 - Train loss: 0.7493 - Val accuracy: 0.5714 - Val loss: 1.0823 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.4760 - Val accuracy: 0.4286 - Val loss: 1.0766 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.3094 - Val accuracy: 0.4286 - Val loss: 1.1011 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.2102 - Val accuracy: 0.4286 - Val loss: 0.9873 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.1514 - Val accuracy: 1.0000 - Val loss: 0.5539 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.1101 - Val accuracy: 1.0000 - Val loss: 0.2693 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0887 - Val accuracy: 1.0000 - Val loss: 0.1955 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0785 - Val accuracy: 1.0000 - Val loss: 0.1747 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0681 - Val accuracy: 1.0000 - Val loss: 0.1657 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0735 - Val accuracy: 1.0000 - Val loss: 0.1623 - LR: 0.00e+00\n","\tBest epoch: 100 - Best val accuracy: 1.0000 - Best val loss: 0.1623\n","\n","\tEpoch 10/100 - Train loss: 0.6222 - Val accuracy: 0.4286 - Val loss: 1.0582 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.3663 - Val accuracy: 0.2857 - Val loss: 1.1151 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.2433 - Val accuracy: 0.2857 - Val loss: 1.2029 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.1532 - Val accuracy: 0.2857 - Val loss: 1.0276 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.1042 - Val accuracy: 1.0000 - Val loss: 0.4663 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.0809 - Val accuracy: 1.0000 - Val loss: 0.1936 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0622 - Val accuracy: 1.0000 - Val loss: 0.1495 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0541 - Val accuracy: 1.0000 - Val loss: 0.1410 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0514 - Val accuracy: 1.0000 - Val loss: 0.1382 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0567 - Val accuracy: 1.0000 - Val loss: 0.1378 - LR: 0.00e+00\n","\tBest epoch: 96 - Best val accuracy: 1.0000 - Best val loss: 0.1376\n","\n","\tEpoch 10/100 - Train loss: 0.5918 - Val accuracy: 0.2857 - Val loss: 1.1061 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.3911 - Val accuracy: 0.2857 - Val loss: 1.1447 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.2671 - Val accuracy: 0.2857 - Val loss: 1.2775 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.1949 - Val accuracy: 0.4286 - Val loss: 1.3062 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.1539 - Val accuracy: 0.5714 - Val loss: 0.8683 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.1287 - Val accuracy: 1.0000 - Val loss: 0.4099 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.1075 - Val accuracy: 0.8571 - Val loss: 0.2918 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0927 - Val accuracy: 0.8571 - Val loss: 0.2708 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0935 - Val accuracy: 0.8571 - Val loss: 0.2649 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0890 - Val accuracy: 0.8571 - Val loss: 0.2630 - LR: 0.00e+00\n","\tBest epoch: 100 - Best val accuracy: 0.8571 - Best val loss: 0.2630\n","\n","\tEpoch 10/100 - Train loss: 0.5714 - Val accuracy: 0.7143 - Val loss: 1.0383 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.3067 - Val accuracy: 0.1429 - Val loss: 1.1162 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.1716 - Val accuracy: 0.1429 - Val loss: 1.2774 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.1014 - Val accuracy: 0.1429 - Val loss: 1.2043 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.0760 - Val accuracy: 0.8571 - Val loss: 0.6531 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.0615 - Val accuracy: 1.0000 - Val loss: 0.2365 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0445 - Val accuracy: 1.0000 - Val loss: 0.1491 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0434 - Val accuracy: 1.0000 - Val loss: 0.1366 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0371 - Val accuracy: 0.8571 - Val loss: 0.1339 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0355 - Val accuracy: 0.8571 - Val loss: 0.1332 - LR: 0.00e+00\n","\tBest epoch: 99 - Best val accuracy: 0.8571 - Best val loss: 0.1332\n","\n","\tEpoch 10/100 - Train loss: 0.5831 - Val accuracy: 0.6250 - Val loss: 1.0440 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.3501 - Val accuracy: 0.8750 - Val loss: 1.0439 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.2227 - Val accuracy: 0.2500 - Val loss: 1.0531 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.1414 - Val accuracy: 0.7500 - Val loss: 0.9036 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.1062 - Val accuracy: 0.8750 - Val loss: 0.5366 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.0752 - Val accuracy: 0.8750 - Val loss: 0.3541 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0638 - Val accuracy: 0.8750 - Val loss: 0.3076 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0523 - Val accuracy: 0.8750 - Val loss: 0.2912 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0526 - Val accuracy: 0.8750 - Val loss: 0.2826 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0468 - Val accuracy: 0.8750 - Val loss: 0.2793 - LR: 0.00e+00\n","\tBest epoch: 100 - Best val accuracy: 0.8750 - Best val loss: 0.2793\n","\n","Source class: WAL | Domain: 71 | Accuracy: 0.9056 | Loss: 0.2613\n","\n","Domain: 72\n","x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Training and evaluating on Dp data via cross-validation...\n","\tEpoch 10/100 - Train loss: 0.5710 - Val accuracy: 0.7143 - Val loss: 1.0661 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.3428 - Val accuracy: 0.1429 - Val loss: 1.1435 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.2319 - Val accuracy: 0.1429 - Val loss: 1.3703 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.1599 - Val accuracy: 0.1429 - Val loss: 1.4372 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.1254 - Val accuracy: 0.7143 - Val loss: 0.8395 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.0914 - Val accuracy: 1.0000 - Val loss: 0.3470 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0705 - Val accuracy: 1.0000 - Val loss: 0.1995 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0620 - Val accuracy: 1.0000 - Val loss: 0.1568 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0563 - Val accuracy: 1.0000 - Val loss: 0.1415 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0530 - Val accuracy: 1.0000 - Val loss: 0.1361 - LR: 0.00e+00\n","\tBest epoch: 100 - Best val accuracy: 1.0000 - Best val loss: 0.1361\n","\n","\tEpoch 10/100 - Train loss: 0.5986 - Val accuracy: 0.1429 - Val loss: 1.0863 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.3850 - Val accuracy: 0.1429 - Val loss: 1.1652 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.2474 - Val accuracy: 0.1429 - Val loss: 1.3862 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.1958 - Val accuracy: 0.1429 - Val loss: 1.3937 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.1434 - Val accuracy: 1.0000 - Val loss: 0.7545 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.1119 - Val accuracy: 1.0000 - Val loss: 0.2875 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0840 - Val accuracy: 1.0000 - Val loss: 0.1775 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0891 - Val accuracy: 1.0000 - Val loss: 0.1479 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0784 - Val accuracy: 1.0000 - Val loss: 0.1370 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0739 - Val accuracy: 1.0000 - Val loss: 0.1330 - LR: 0.00e+00\n","\tBest epoch: 100 - Best val accuracy: 1.0000 - Best val loss: 0.1330\n","\n","\tEpoch 10/100 - Train loss: 0.5488 - Val accuracy: 0.2857 - Val loss: 1.0801 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.3332 - Val accuracy: 0.1429 - Val loss: 1.1846 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.2411 - Val accuracy: 0.1429 - Val loss: 1.4040 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.1587 - Val accuracy: 0.1429 - Val loss: 1.4407 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.1080 - Val accuracy: 0.7143 - Val loss: 0.7835 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.0821 - Val accuracy: 1.0000 - Val loss: 0.2402 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0717 - Val accuracy: 1.0000 - Val loss: 0.1219 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0612 - Val accuracy: 1.0000 - Val loss: 0.0918 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0538 - Val accuracy: 1.0000 - Val loss: 0.0812 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0635 - Val accuracy: 1.0000 - Val loss: 0.0779 - LR: 0.00e+00\n","\tBest epoch: 100 - Best val accuracy: 1.0000 - Best val loss: 0.0779\n","\n","\tEpoch 10/100 - Train loss: 0.5603 - Val accuracy: 0.7143 - Val loss: 1.0600 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.3314 - Val accuracy: 0.1429 - Val loss: 1.1621 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.2378 - Val accuracy: 0.1429 - Val loss: 1.3922 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.1884 - Val accuracy: 0.1429 - Val loss: 1.3533 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.1454 - Val accuracy: 0.8571 - Val loss: 0.6269 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.1117 - Val accuracy: 0.8571 - Val loss: 0.2940 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0991 - Val accuracy: 1.0000 - Val loss: 0.2234 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0821 - Val accuracy: 1.0000 - Val loss: 0.2041 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0873 - Val accuracy: 1.0000 - Val loss: 0.1968 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0821 - Val accuracy: 1.0000 - Val loss: 0.1943 - LR: 0.00e+00\n","\tBest epoch: 100 - Best val accuracy: 1.0000 - Best val loss: 0.1943\n","\n","\tEpoch 10/100 - Train loss: 0.4418 - Val accuracy: 0.1429 - Val loss: 1.0943 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.2929 - Val accuracy: 0.1429 - Val loss: 1.2110 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.2137 - Val accuracy: 0.0000 - Val loss: 1.3417 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.1687 - Val accuracy: 0.1429 - Val loss: 1.3451 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.1226 - Val accuracy: 0.8571 - Val loss: 0.6735 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.1010 - Val accuracy: 0.8571 - Val loss: 0.3222 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0799 - Val accuracy: 0.8571 - Val loss: 0.2779 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0681 - Val accuracy: 0.8571 - Val loss: 0.2675 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0647 - Val accuracy: 0.8571 - Val loss: 0.2626 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0637 - Val accuracy: 0.8571 - Val loss: 0.2609 - LR: 0.00e+00\n","\tBest epoch: 100 - Best val accuracy: 0.8571 - Best val loss: 0.2609\n","\n","Source class: WAL | Domain: 72 | Accuracy: 0.8556 | Loss: 0.2360\n","\n","Domain: 73\n","x_dp_dom.shape: (41, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Training and evaluating on Dp data via cross-validation...\n","\tEpoch 10/100 - Train loss: 0.6479 - Val accuracy: 0.7143 - Val loss: 1.0526 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.3838 - Val accuracy: 0.1429 - Val loss: 1.1145 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.2642 - Val accuracy: 0.1429 - Val loss: 1.3273 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.1754 - Val accuracy: 0.2857 - Val loss: 1.2796 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.1341 - Val accuracy: 0.8571 - Val loss: 0.6803 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.0996 - Val accuracy: 0.8571 - Val loss: 0.3373 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0822 - Val accuracy: 0.8571 - Val loss: 0.2549 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0742 - Val accuracy: 0.8571 - Val loss: 0.2349 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0629 - Val accuracy: 0.8571 - Val loss: 0.2289 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0645 - Val accuracy: 0.8571 - Val loss: 0.2269 - LR: 0.00e+00\n","\tBest epoch: 100 - Best val accuracy: 0.8571 - Best val loss: 0.2269\n","\n","\tEpoch 10/100 - Train loss: 0.5623 - Val accuracy: 0.7143 - Val loss: 1.0810 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.3384 - Val accuracy: 0.1429 - Val loss: 1.1758 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.2145 - Val accuracy: 0.1429 - Val loss: 1.3763 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.1560 - Val accuracy: 0.1429 - Val loss: 1.4359 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.1208 - Val accuracy: 0.4286 - Val loss: 0.9161 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.0842 - Val accuracy: 0.8571 - Val loss: 0.4334 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0705 - Val accuracy: 1.0000 - Val loss: 0.2808 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0675 - Val accuracy: 1.0000 - Val loss: 0.2353 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0545 - Val accuracy: 1.0000 - Val loss: 0.2187 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0665 - Val accuracy: 1.0000 - Val loss: 0.2131 - LR: 0.00e+00\n","\tBest epoch: 100 - Best val accuracy: 1.0000 - Best val loss: 0.2131\n","\n","\tEpoch 10/100 - Train loss: 0.5471 - Val accuracy: 0.7143 - Val loss: 1.0421 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.3683 - Val accuracy: 0.1429 - Val loss: 1.0911 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.2573 - Val accuracy: 0.2857 - Val loss: 1.2390 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.1854 - Val accuracy: 0.2857 - Val loss: 1.3186 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.1376 - Val accuracy: 1.0000 - Val loss: 0.9041 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.0918 - Val accuracy: 1.0000 - Val loss: 0.3858 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0783 - Val accuracy: 1.0000 - Val loss: 0.2241 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0735 - Val accuracy: 1.0000 - Val loss: 0.1817 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0708 - Val accuracy: 1.0000 - Val loss: 0.1668 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0661 - Val accuracy: 1.0000 - Val loss: 0.1618 - LR: 0.00e+00\n","\tBest epoch: 100 - Best val accuracy: 1.0000 - Best val loss: 0.1618\n","\n","\tEpoch 10/100 - Train loss: 0.5895 - Val accuracy: 0.1429 - Val loss: 1.0676 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.3731 - Val accuracy: 0.1429 - Val loss: 1.1327 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.2553 - Val accuracy: 0.1429 - Val loss: 1.3433 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.1974 - Val accuracy: 0.1429 - Val loss: 1.3540 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.1476 - Val accuracy: 0.7143 - Val loss: 0.8154 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.1212 - Val accuracy: 1.0000 - Val loss: 0.3444 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.1138 - Val accuracy: 1.0000 - Val loss: 0.2321 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0903 - Val accuracy: 1.0000 - Val loss: 0.2070 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0817 - Val accuracy: 1.0000 - Val loss: 0.1973 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0815 - Val accuracy: 1.0000 - Val loss: 0.1938 - LR: 0.00e+00\n","\tBest epoch: 100 - Best val accuracy: 1.0000 - Best val loss: 0.1938\n","\n","\tEpoch 10/100 - Train loss: 0.5145 - Val accuracy: 0.7143 - Val loss: 1.0172 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.3418 - Val accuracy: 0.1429 - Val loss: 1.1157 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.2437 - Val accuracy: 0.1429 - Val loss: 1.3705 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.1764 - Val accuracy: 0.1429 - Val loss: 1.4000 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.1276 - Val accuracy: 0.5714 - Val loss: 0.7924 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.0979 - Val accuracy: 0.8571 - Val loss: 0.3558 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0895 - Val accuracy: 0.8571 - Val loss: 0.2561 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0830 - Val accuracy: 0.8571 - Val loss: 0.2298 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0723 - Val accuracy: 0.8571 - Val loss: 0.2202 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0670 - Val accuracy: 0.8571 - Val loss: 0.2169 - LR: 0.00e+00\n","\tBest epoch: 100 - Best val accuracy: 0.8571 - Best val loss: 0.2169\n","\n","Source class: WAL | Domain: 73 | Accuracy: 0.8806 | Loss: 0.3277\n","\n","Domain: 74\n","Domain: 75\n","x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Training and evaluating on Dp data via cross-validation...\n","\tEpoch 10/100 - Train loss: 0.5077 - Val accuracy: 0.7143 - Val loss: 1.0780 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.2757 - Val accuracy: 0.1429 - Val loss: 1.1911 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.1888 - Val accuracy: 0.1429 - Val loss: 1.3926 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.1520 - Val accuracy: 0.2857 - Val loss: 1.1548 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.1200 - Val accuracy: 0.8571 - Val loss: 0.5461 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.0905 - Val accuracy: 0.8571 - Val loss: 0.3124 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0703 - Val accuracy: 0.8571 - Val loss: 0.2289 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0620 - Val accuracy: 1.0000 - Val loss: 0.1936 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0596 - Val accuracy: 1.0000 - Val loss: 0.1791 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0609 - Val accuracy: 1.0000 - Val loss: 0.1732 - LR: 0.00e+00\n","\tBest epoch: 100 - Best val accuracy: 1.0000 - Best val loss: 0.1732\n","\n","\tEpoch 10/100 - Train loss: 0.5734 - Val accuracy: 0.7143 - Val loss: 1.0538 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.3270 - Val accuracy: 0.1429 - Val loss: 1.1358 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.2133 - Val accuracy: 0.1429 - Val loss: 1.3542 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.1493 - Val accuracy: 0.1429 - Val loss: 1.3982 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.1089 - Val accuracy: 0.5714 - Val loss: 0.8814 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.0845 - Val accuracy: 0.8571 - Val loss: 0.4038 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0669 - Val accuracy: 1.0000 - Val loss: 0.2655 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0540 - Val accuracy: 1.0000 - Val loss: 0.2318 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0524 - Val accuracy: 1.0000 - Val loss: 0.2205 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0521 - Val accuracy: 1.0000 - Val loss: 0.2167 - LR: 0.00e+00\n","\tBest epoch: 100 - Best val accuracy: 1.0000 - Best val loss: 0.2167\n","\n","\tEpoch 10/100 - Train loss: 0.5471 - Val accuracy: 0.1429 - Val loss: 1.1181 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.3165 - Val accuracy: 0.1429 - Val loss: 1.2673 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.2271 - Val accuracy: 0.1429 - Val loss: 1.5045 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.1621 - Val accuracy: 0.1429 - Val loss: 1.4130 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.1289 - Val accuracy: 0.8571 - Val loss: 0.5890 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.0962 - Val accuracy: 1.0000 - Val loss: 0.1909 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0810 - Val accuracy: 1.0000 - Val loss: 0.1043 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0665 - Val accuracy: 1.0000 - Val loss: 0.0801 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0638 - Val accuracy: 1.0000 - Val loss: 0.0710 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0646 - Val accuracy: 1.0000 - Val loss: 0.0675 - LR: 0.00e+00\n","\tBest epoch: 100 - Best val accuracy: 1.0000 - Best val loss: 0.0675\n","\n","\tEpoch 10/100 - Train loss: 0.5928 - Val accuracy: 0.1429 - Val loss: 1.0898 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.3421 - Val accuracy: 0.1429 - Val loss: 1.2287 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.2238 - Val accuracy: 0.1429 - Val loss: 1.5034 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.1734 - Val accuracy: 0.2857 - Val loss: 1.4128 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.1379 - Val accuracy: 1.0000 - Val loss: 0.6284 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.1048 - Val accuracy: 1.0000 - Val loss: 0.2126 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0887 - Val accuracy: 1.0000 - Val loss: 0.1337 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0811 - Val accuracy: 1.0000 - Val loss: 0.1149 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0732 - Val accuracy: 1.0000 - Val loss: 0.1090 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0685 - Val accuracy: 1.0000 - Val loss: 0.1073 - LR: 0.00e+00\n","\tBest epoch: 100 - Best val accuracy: 1.0000 - Best val loss: 0.1073\n","\n","\tEpoch 10/100 - Train loss: 0.5419 - Val accuracy: 0.7143 - Val loss: 1.0757 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.3474 - Val accuracy: 0.2857 - Val loss: 1.1439 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.2596 - Val accuracy: 0.1429 - Val loss: 1.2727 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.1981 - Val accuracy: 0.2857 - Val loss: 1.1346 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.1562 - Val accuracy: 1.0000 - Val loss: 0.5718 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.1332 - Val accuracy: 1.0000 - Val loss: 0.2746 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.1068 - Val accuracy: 1.0000 - Val loss: 0.1934 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.1007 - Val accuracy: 1.0000 - Val loss: 0.1673 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0934 - Val accuracy: 1.0000 - Val loss: 0.1561 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0802 - Val accuracy: 1.0000 - Val loss: 0.1519 - LR: 0.00e+00\n","\tBest epoch: 100 - Best val accuracy: 1.0000 - Best val loss: 0.1519\n","\n","Source class: WAL | Domain: 75 | Accuracy: 0.9778 | Loss: 0.1809\n","\n","Mean accuracy: 0.9040\n","\n"]}],"source":["def compute_TSTR_Dp(dataset):\n","    accs = []\n","\n","    for src_class in config[dataset]['class_names']:\n","        if src_class != 'WAL':\n","            continue\n","\n","        print(f\"Source class: {src_class}\\n\")\n","\n","        for domain in range(config[dataset]['num_df_domains'], config[dataset]['num_df_domains'] + config[dataset]['num_dp_domains']):\n","            print(f\"Domain: {domain}\")\n","\n","            if domain == 74:\n","              continue\n","\n","            # Load Dp data\n","            x_dp_dom, y_dp_dom, k_dp_dom = get_data(dataset, 'dp', src_class, domain)\n","            print(f'x_dp_dom.shape: {x_dp_dom.shape} | np.unique(y_dp_dom): {np.unique(y_dp_dom)}\\n')\n","\n","            # Train and evaluate via cross-validation on Dp data\n","            print('Training and evaluating on Dp data via cross-validation...')\n","            acc, loss = train_classifier_cv(x_dp_dom, y_dp_dom, dataset, num_epochs=100)\n","            save_scores(src_class, domain, acc, loss, 'Dp', dataset)\n","            accs.append(acc)\n","            print(f'Source class: {src_class} | Domain: {domain} | Accuracy: {acc:.4f} | Loss: {loss:.4f}\\n')\n","\n","    print(f\"Mean accuracy: {np.mean(accs):.4f}\\n\")\n","\n","\n","\n","compute_TSTR_Dp('realworld_mobiact')"]},{"cell_type":"code","execution_count":11,"metadata":{"executionInfo":{"elapsed":4,"status":"ok","timestamp":1731668758959,"user":{"displayName":"Pietro ST","userId":"01777116294553213330"},"user_tz":-60},"id":"M7S9IU2VVAmx"},"outputs":[],"source":["def compute_TSTR_Dpc(dataset):\n","\n","    raise NotImplementedError\n","\n","\n","\n","# compute_TSTR_Dpc('realworld_mobiact')"]},{"cell_type":"code","execution_count":9,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":597595,"status":"ok","timestamp":1731668551104,"user":{"displayName":"Pietro ST","userId":"01777116294553213330"},"user_tz":-60},"id":"zhTuwDtYCPto","outputId":"440e578a-961e-45ac-9f4f-f77896309ed6"},"outputs":[{"output_type":"stream","name":"stdout","text":["Source class: WAL\n","\n","x_df.shape: (7958, 3, 128) | np.unique(y_df): [1 2 3]\n","\n","Training on Df data...\n","\tEpoch 10/100 - Train loss: 0.0289 - Val accuracy: 0.9799 - Val loss: 0.0521 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.0092 - Val accuracy: 0.9824 - Val loss: 0.0467 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.0043 - Val accuracy: 0.9837 - Val loss: 0.0461 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.0013 - Val accuracy: 0.9868 - Val loss: 0.0493 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.0008 - Val accuracy: 0.9856 - Val loss: 0.0501 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.0003 - Val accuracy: 0.9868 - Val loss: 0.0558 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0003 - Val accuracy: 0.9887 - Val loss: 0.0534 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0002 - Val accuracy: 0.9887 - Val loss: 0.0555 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0002 - Val accuracy: 0.9868 - Val loss: 0.0570 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0002 - Val accuracy: 0.9862 - Val loss: 0.0583 - LR: 0.00e+00\n","\tBest epoch: 16 - Best val accuracy: 0.9849 - Best val loss: 0.0417\n","\n","Domain: 15\n","x_dp_dom.shape: (50, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 15 | Accuracy: 0.0000 | Loss: 36.2745\n","\n","Domain: 16\n","x_dp_dom.shape: (54, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 16 | Accuracy: 0.5185 | Loss: 8.3406\n","\n","Domain: 17\n","x_dp_dom.shape: (53, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 17 | Accuracy: 0.5283 | Loss: 8.3456\n","\n","Domain: 18\n","x_dp_dom.shape: (54, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 18 | Accuracy: 0.5185 | Loss: 11.9086\n","\n","Domain: 19\n","x_dp_dom.shape: (54, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 19 | Accuracy: 0.5185 | Loss: 9.3490\n","\n","Domain: 20\n","x_dp_dom.shape: (51, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 20 | Accuracy: 0.4902 | Loss: 6.0997\n","\n","Domain: 21\n","x_dp_dom.shape: (47, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 21 | Accuracy: 0.5957 | Loss: 7.9007\n","\n","Domain: 22\n","x_dp_dom.shape: (54, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 22 | Accuracy: 0.5185 | Loss: 11.5582\n","\n","Domain: 23\n","x_dp_dom.shape: (52, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 23 | Accuracy: 0.5385 | Loss: 14.4665\n","\n","Domain: 24\n","x_dp_dom.shape: (51, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 24 | Accuracy: 0.3922 | Loss: 8.5855\n","\n","Domain: 25\n","x_dp_dom.shape: (54, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 25 | Accuracy: 0.5185 | Loss: 9.0970\n","\n","Domain: 26\n","x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 26 | Accuracy: 0.6190 | Loss: 6.7964\n","\n","Domain: 27\n","x_dp_dom.shape: (54, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 27 | Accuracy: 0.5185 | Loss: 12.8469\n","\n","Domain: 28\n","x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 28 | Accuracy: 0.6667 | Loss: 5.6837\n","\n","Domain: 29\n","x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 29 | Accuracy: 0.6667 | Loss: 8.2665\n","\n","Domain: 30\n","x_dp_dom.shape: (50, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 30 | Accuracy: 0.6000 | Loss: 11.3613\n","\n","Domain: 31\n","x_dp_dom.shape: (43, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 31 | Accuracy: 0.7907 | Loss: 5.2276\n","\n","Domain: 32\n","x_dp_dom.shape: (52, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 32 | Accuracy: 0.5385 | Loss: 7.5486\n","\n","Domain: 33\n","x_dp_dom.shape: (44, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 33 | Accuracy: 0.6364 | Loss: 5.6934\n","\n","Domain: 34\n","x_dp_dom.shape: (49, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 34 | Accuracy: 0.4490 | Loss: 12.4033\n","\n","Domain: 35\n","x_dp_dom.shape: (48, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 35 | Accuracy: 0.5833 | Loss: 5.2452\n","\n","Domain: 36\n","x_dp_dom.shape: (43, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 36 | Accuracy: 0.6744 | Loss: 4.3076\n","\n","Domain: 37\n","x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 37 | Accuracy: 0.6190 | Loss: 5.7526\n","\n","Domain: 38\n","x_dp_dom.shape: (47, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 38 | Accuracy: 0.6596 | Loss: 7.4764\n","\n","Domain: 39\n","x_dp_dom.shape: (54, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 39 | Accuracy: 0.4074 | Loss: 18.8214\n","\n","Domain: 40\n","x_dp_dom.shape: (44, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 40 | Accuracy: 0.6364 | Loss: 6.9998\n","\n","Domain: 41\n","x_dp_dom.shape: (45, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 41 | Accuracy: 0.6444 | Loss: 7.0080\n","\n","Domain: 42\n","x_dp_dom.shape: (46, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 42 | Accuracy: 0.6739 | Loss: 7.8495\n","\n","Domain: 43\n","x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 43 | Accuracy: 0.5000 | Loss: 16.7808\n","\n","Domain: 44\n","x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 44 | Accuracy: 0.6667 | Loss: 7.3702\n","\n","Domain: 45\n","x_dp_dom.shape: (52, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 45 | Accuracy: 0.5385 | Loss: 5.4224\n","\n","Domain: 46\n","x_dp_dom.shape: (48, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 46 | Accuracy: 0.5833 | Loss: 8.9038\n","\n","Domain: 47\n","x_dp_dom.shape: (44, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 47 | Accuracy: 0.6364 | Loss: 7.3267\n","\n","Domain: 48\n","x_dp_dom.shape: (48, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 48 | Accuracy: 0.5833 | Loss: 10.4481\n","\n","Domain: 49\n","x_dp_dom.shape: (53, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 49 | Accuracy: 0.5283 | Loss: 4.9746\n","\n","Domain: 50\n","x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 50 | Accuracy: 0.6667 | Loss: 7.2904\n","\n","Domain: 51\n","x_dp_dom.shape: (46, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 51 | Accuracy: 0.6087 | Loss: 8.9026\n","\n","Domain: 52\n","x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 52 | Accuracy: 0.6667 | Loss: 4.5675\n","\n","Domain: 53\n","x_dp_dom.shape: (48, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 53 | Accuracy: 0.5833 | Loss: 7.2707\n","\n","Domain: 54\n","x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 54 | Accuracy: 0.4286 | Loss: 5.8194\n","\n","Domain: 55\n","x_dp_dom.shape: (49, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 55 | Accuracy: 0.5714 | Loss: 5.7286\n","\n","Domain: 56\n","x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 56 | Accuracy: 0.6667 | Loss: 5.6810\n","\n","Domain: 57\n","x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 57 | Accuracy: 0.6667 | Loss: 7.4346\n","\n","Domain: 58\n","x_dp_dom.shape: (38, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 58 | Accuracy: 0.4474 | Loss: 10.2353\n","\n","Domain: 59\n","x_dp_dom.shape: (43, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 59 | Accuracy: 0.6512 | Loss: 7.1872\n","\n","Domain: 60\n","x_dp_dom.shape: (47, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 60 | Accuracy: 0.4255 | Loss: 24.9650\n","\n","Domain: 61\n","x_dp_dom.shape: (47, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 61 | Accuracy: 0.5957 | Loss: 7.8038\n","\n","Domain: 62\n","x_dp_dom.shape: (47, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 62 | Accuracy: 0.5957 | Loss: 6.0170\n","\n","Domain: 63\n","x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 63 | Accuracy: 0.6905 | Loss: 6.6814\n","\n","Domain: 64\n","x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 64 | Accuracy: 0.6667 | Loss: 4.8912\n","\n","Domain: 65\n","x_dp_dom.shape: (50, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 65 | Accuracy: 0.0000 | Loss: 30.4786\n","\n","Domain: 66\n","x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 66 | Accuracy: 0.1190 | Loss: 38.7808\n","\n","Domain: 67\n","x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 67 | Accuracy: 0.5476 | Loss: 5.2084\n","\n","Domain: 68\n","x_dp_dom.shape: (43, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 68 | Accuracy: 0.6512 | Loss: 7.4014\n","\n","Domain: 69\n","x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 69 | Accuracy: 0.0000 | Loss: 31.1303\n","\n","Domain: 70\n","x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 70 | Accuracy: 0.7619 | Loss: 5.9515\n","\n","Domain: 71\n","x_dp_dom.shape: (44, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 71 | Accuracy: 0.6364 | Loss: 10.1660\n","\n","Domain: 72\n","x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 72 | Accuracy: 0.6667 | Loss: 6.8651\n","\n","Domain: 73\n","x_dp_dom.shape: (41, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 73 | Accuracy: 0.1707 | Loss: 36.9193\n","\n","Domain: 74\n","x_dp_dom.shape: (35, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 74 | Accuracy: 0.8000 | Loss: 7.5791\n","\n","Domain: 75\n","x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 75 | Accuracy: 0.6667 | Loss: 4.6992\n","\n","Source class: WAL\n","\n","x_df.shape: (7958, 3, 128) | np.unique(y_df): [1 2 3]\n","\n","Training on Df data...\n","\tEpoch 10/100 - Train loss: 0.0319 - Val accuracy: 0.9799 - Val loss: 0.0556 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.0126 - Val accuracy: 0.9780 - Val loss: 0.0601 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.0035 - Val accuracy: 0.9830 - Val loss: 0.0542 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.0017 - Val accuracy: 0.9818 - Val loss: 0.0603 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.0008 - Val accuracy: 0.9812 - Val loss: 0.0621 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.0011 - Val accuracy: 0.9843 - Val loss: 0.0573 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0006 - Val accuracy: 0.9824 - Val loss: 0.0758 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0002 - Val accuracy: 0.9824 - Val loss: 0.0684 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0002 - Val accuracy: 0.9818 - Val loss: 0.0658 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0002 - Val accuracy: 0.9830 - Val loss: 0.0659 - LR: 0.00e+00\n","\tBest epoch: 33 - Best val accuracy: 0.9843 - Best val loss: 0.0466\n","\n","Domain: 15\n","x_dp_dom.shape: (50, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 15 | Accuracy: 0.3800 | Loss: 4.6369\n","\n","Domain: 16\n","x_dp_dom.shape: (54, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 16 | Accuracy: 0.2407 | Loss: 9.4148\n","\n","Domain: 17\n","x_dp_dom.shape: (53, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 17 | Accuracy: 0.2264 | Loss: 12.0102\n","\n","Domain: 18\n","x_dp_dom.shape: (54, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 18 | Accuracy: 0.2407 | Loss: 8.4932\n","\n","Domain: 19\n","x_dp_dom.shape: (54, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 19 | Accuracy: 0.2407 | Loss: 10.4425\n","\n","Domain: 20\n","x_dp_dom.shape: (51, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 20 | Accuracy: 0.1961 | Loss: 10.8843\n","\n","Domain: 21\n","x_dp_dom.shape: (47, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 21 | Accuracy: 0.1489 | Loss: 11.1688\n","\n","Domain: 22\n","x_dp_dom.shape: (54, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 22 | Accuracy: 0.4074 | Loss: 10.0328\n","\n","Domain: 23\n","x_dp_dom.shape: (52, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 23 | Accuracy: 0.4423 | Loss: 5.8467\n","\n","Domain: 24\n","x_dp_dom.shape: (51, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 24 | Accuracy: 0.6471 | Loss: 4.5364\n","\n","Domain: 25\n","x_dp_dom.shape: (54, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 25 | Accuracy: 0.2407 | Loss: 9.1587\n","\n","Domain: 26\n","x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 26 | Accuracy: 0.1667 | Loss: 13.8086\n","\n","Domain: 27\n","x_dp_dom.shape: (54, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 27 | Accuracy: 0.2407 | Loss: 11.6840\n","\n","Domain: 28\n","x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 28 | Accuracy: 0.1667 | Loss: 13.2974\n","\n","Domain: 29\n","x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 29 | Accuracy: 0.1667 | Loss: 10.0439\n","\n","Domain: 30\n","x_dp_dom.shape: (50, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 30 | Accuracy: 0.1600 | Loss: 12.4250\n","\n","Domain: 31\n","x_dp_dom.shape: (43, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 31 | Accuracy: 0.2791 | Loss: 11.4379\n","\n","Domain: 32\n","x_dp_dom.shape: (52, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 32 | Accuracy: 0.2115 | Loss: 10.7532\n","\n","Domain: 33\n","x_dp_dom.shape: (44, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 33 | Accuracy: 0.1591 | Loss: 14.0146\n","\n","Domain: 34\n","x_dp_dom.shape: (49, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 34 | Accuracy: 0.4286 | Loss: 7.0956\n","\n","Domain: 35\n","x_dp_dom.shape: (48, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 35 | Accuracy: 0.1458 | Loss: 11.6768\n","\n","Domain: 36\n","x_dp_dom.shape: (43, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 36 | Accuracy: 0.1628 | Loss: 11.3643\n","\n","Domain: 37\n","x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 37 | Accuracy: 0.1429 | Loss: 10.8441\n","\n","Domain: 38\n","x_dp_dom.shape: (47, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 38 | Accuracy: 0.4468 | Loss: 5.0541\n","\n","Domain: 39\n","x_dp_dom.shape: (54, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 39 | Accuracy: 0.7222 | Loss: 1.4419\n","\n","Domain: 40\n","x_dp_dom.shape: (44, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 40 | Accuracy: 0.1591 | Loss: 12.4378\n","\n","Domain: 41\n","x_dp_dom.shape: (45, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 41 | Accuracy: 0.0444 | Loss: 11.6809\n","\n","Domain: 42\n","x_dp_dom.shape: (46, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 42 | Accuracy: 0.1957 | Loss: 12.0217\n","\n","Domain: 43\n","x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 43 | Accuracy: 0.1905 | Loss: 10.6289\n","\n","Domain: 44\n","x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 44 | Accuracy: 0.1667 | Loss: 11.8682\n","\n","Domain: 45\n","x_dp_dom.shape: (52, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 45 | Accuracy: 0.2115 | Loss: 11.2575\n","\n","Domain: 46\n","x_dp_dom.shape: (48, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 46 | Accuracy: 0.1458 | Loss: 7.7171\n","\n","Domain: 47\n","x_dp_dom.shape: (44, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 47 | Accuracy: 0.1591 | Loss: 10.7477\n","\n","Domain: 48\n","x_dp_dom.shape: (48, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 48 | Accuracy: 0.1875 | Loss: 8.1826\n","\n","Domain: 49\n","x_dp_dom.shape: (53, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 49 | Accuracy: 0.2264 | Loss: 10.6545\n","\n","Domain: 50\n","x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 50 | Accuracy: 0.1667 | Loss: 13.3165\n","\n","Domain: 51\n","x_dp_dom.shape: (46, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 51 | Accuracy: 0.2391 | Loss: 8.1693\n","\n","Domain: 52\n","x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 52 | Accuracy: 0.1667 | Loss: 9.4634\n","\n","Domain: 53\n","x_dp_dom.shape: (48, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 53 | Accuracy: 0.5417 | Loss: 6.2768\n","\n","Domain: 54\n","x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 54 | Accuracy: 0.2143 | Loss: 13.1269\n","\n","Domain: 55\n","x_dp_dom.shape: (49, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 55 | Accuracy: 0.1633 | Loss: 14.0160\n","\n","Domain: 56\n","x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 56 | Accuracy: 0.5238 | Loss: 6.3204\n","\n","Domain: 57\n","x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 57 | Accuracy: 0.1667 | Loss: 16.5042\n","\n","Domain: 58\n","x_dp_dom.shape: (38, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 58 | Accuracy: 0.1316 | Loss: 8.3263\n","\n","Domain: 59\n","x_dp_dom.shape: (43, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 59 | Accuracy: 0.1628 | Loss: 11.8995\n","\n","Domain: 60\n","x_dp_dom.shape: (47, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 60 | Accuracy: 0.4043 | Loss: 5.0283\n","\n","Domain: 61\n","x_dp_dom.shape: (47, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 61 | Accuracy: 0.1489 | Loss: 14.6783\n","\n","Domain: 62\n","x_dp_dom.shape: (47, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 62 | Accuracy: 0.1489 | Loss: 14.8983\n","\n","Domain: 63\n","x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 63 | Accuracy: 0.1905 | Loss: 13.0149\n","\n","Domain: 64\n","x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 64 | Accuracy: 0.1667 | Loss: 10.6018\n","\n","Domain: 65\n","x_dp_dom.shape: (50, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 65 | Accuracy: 0.2000 | Loss: 6.9388\n","\n","Domain: 66\n","x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 66 | Accuracy: 0.3571 | Loss: 3.0146\n","\n","Domain: 67\n","x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 67 | Accuracy: 0.1667 | Loss: 11.1280\n","\n","Domain: 68\n","x_dp_dom.shape: (43, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 68 | Accuracy: 0.1628 | Loss: 11.6431\n","\n","Domain: 69\n","x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 69 | Accuracy: 0.2619 | Loss: 6.0908\n","\n","Domain: 70\n","x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 70 | Accuracy: 0.4762 | Loss: 3.9819\n","\n","Domain: 71\n","x_dp_dom.shape: (44, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 71 | Accuracy: 0.1818 | Loss: 7.7560\n","\n","Domain: 72\n","x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 72 | Accuracy: 0.1667 | Loss: 11.1846\n","\n","Domain: 73\n","x_dp_dom.shape: (41, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 73 | Accuracy: 0.9024 | Loss: 0.2929\n","\n","Domain: 74\n","x_dp_dom.shape: (35, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 74 | Accuracy: 0.0286 | Loss: 13.3549\n","\n","Domain: 75\n","x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 75 | Accuracy: 0.1667 | Loss: 14.4595\n","\n","Source class: WAL\n","\n","x_df.shape: (7958, 3, 128) | np.unique(y_df): [1 2 3]\n","\n","Training on Df data...\n","\tEpoch 10/100 - Train loss: 0.0323 - Val accuracy: 0.9793 - Val loss: 0.0520 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.0099 - Val accuracy: 0.9830 - Val loss: 0.0494 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.0023 - Val accuracy: 0.9837 - Val loss: 0.0432 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.0011 - Val accuracy: 0.9837 - Val loss: 0.0416 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.0015 - Val accuracy: 0.9856 - Val loss: 0.0519 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.0004 - Val accuracy: 0.9843 - Val loss: 0.0509 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0008 - Val accuracy: 0.9843 - Val loss: 0.0603 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0004 - Val accuracy: 0.9862 - Val loss: 0.0491 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0008 - Val accuracy: 0.9843 - Val loss: 0.0508 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0001 - Val accuracy: 0.9856 - Val loss: 0.0488 - LR: 0.00e+00\n","\tBest epoch: 26 - Best val accuracy: 0.9830 - Best val loss: 0.0365\n","\n","Domain: 15\n","x_dp_dom.shape: (50, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 15 | Accuracy: 0.5400 | Loss: 2.8381\n","\n","Domain: 16\n","x_dp_dom.shape: (54, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 16 | Accuracy: 0.7593 | Loss: 2.5320\n","\n","Domain: 17\n","x_dp_dom.shape: (53, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 17 | Accuracy: 0.3396 | Loss: 5.8371\n","\n","Domain: 18\n","x_dp_dom.shape: (54, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 18 | Accuracy: 0.6481 | Loss: 1.1458\n","\n","Domain: 19\n","x_dp_dom.shape: (54, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 19 | Accuracy: 0.7037 | Loss: 2.2822\n","\n","Domain: 20\n","x_dp_dom.shape: (51, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 20 | Accuracy: 0.5882 | Loss: 3.2428\n","\n","Domain: 21\n","x_dp_dom.shape: (47, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 21 | Accuracy: 0.6383 | Loss: 1.0366\n","\n","Domain: 22\n","x_dp_dom.shape: (54, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 22 | Accuracy: 0.7593 | Loss: 0.9800\n","\n","Domain: 23\n","x_dp_dom.shape: (52, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 23 | Accuracy: 0.6154 | Loss: 2.4499\n","\n","Domain: 24\n","x_dp_dom.shape: (51, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 24 | Accuracy: 0.7255 | Loss: 4.2321\n","\n","Domain: 25\n","x_dp_dom.shape: (54, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 25 | Accuracy: 0.7037 | Loss: 2.0174\n","\n","Domain: 26\n","x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 26 | Accuracy: 0.6667 | Loss: 1.4114\n","\n","Domain: 27\n","x_dp_dom.shape: (54, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 27 | Accuracy: 0.3704 | Loss: 4.8367\n","\n","Domain: 28\n","x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 28 | Accuracy: 0.7381 | Loss: 2.2095\n","\n","Domain: 29\n","x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 29 | Accuracy: 0.7857 | Loss: 0.5993\n","\n","Domain: 30\n","x_dp_dom.shape: (50, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 30 | Accuracy: 0.6000 | Loss: 3.8883\n","\n","Domain: 31\n","x_dp_dom.shape: (43, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 31 | Accuracy: 0.8140 | Loss: 0.6320\n","\n","Domain: 32\n","x_dp_dom.shape: (52, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 32 | Accuracy: 0.5192 | Loss: 5.1918\n","\n","Domain: 33\n","x_dp_dom.shape: (44, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 33 | Accuracy: 0.8182 | Loss: 1.7224\n","\n","Domain: 34\n","x_dp_dom.shape: (49, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 34 | Accuracy: 0.7959 | Loss: 1.6973\n","\n","Domain: 35\n","x_dp_dom.shape: (48, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 35 | Accuracy: 0.6875 | Loss: 2.1972\n","\n","Domain: 36\n","x_dp_dom.shape: (43, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 36 | Accuracy: 0.8140 | Loss: 1.6828\n","\n","Domain: 37\n","x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 37 | Accuracy: 0.7857 | Loss: 2.4164\n","\n","Domain: 38\n","x_dp_dom.shape: (47, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 38 | Accuracy: 0.7872 | Loss: 1.4368\n","\n","Domain: 39\n","x_dp_dom.shape: (54, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 39 | Accuracy: 0.4074 | Loss: 5.8815\n","\n","Domain: 40\n","x_dp_dom.shape: (44, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 40 | Accuracy: 0.2955 | Loss: 8.7249\n","\n","Domain: 41\n","x_dp_dom.shape: (45, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 41 | Accuracy: 0.6222 | Loss: 3.3528\n","\n","Domain: 42\n","x_dp_dom.shape: (46, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 42 | Accuracy: 0.6087 | Loss: 3.0142\n","\n","Domain: 43\n","x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 43 | Accuracy: 0.7857 | Loss: 1.8691\n","\n","Domain: 44\n","x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 44 | Accuracy: 0.8571 | Loss: 0.9524\n","\n","Domain: 45\n","x_dp_dom.shape: (52, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 45 | Accuracy: 0.7308 | Loss: 1.6760\n","\n","Domain: 46\n","x_dp_dom.shape: (48, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 46 | Accuracy: 0.7708 | Loss: 0.4827\n","\n","Domain: 47\n","x_dp_dom.shape: (44, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 47 | Accuracy: 0.8409 | Loss: 0.5582\n","\n","Domain: 48\n","x_dp_dom.shape: (48, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 48 | Accuracy: 0.6250 | Loss: 1.4304\n","\n","Domain: 49\n","x_dp_dom.shape: (53, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 49 | Accuracy: 0.5472 | Loss: 4.3613\n","\n","Domain: 50\n","x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 50 | Accuracy: 0.8333 | Loss: 0.4388\n","\n","Domain: 51\n","x_dp_dom.shape: (46, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 51 | Accuracy: 0.8478 | Loss: 1.4844\n","\n","Domain: 52\n","x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 52 | Accuracy: 0.7857 | Loss: 1.7387\n","\n","Domain: 53\n","x_dp_dom.shape: (48, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 53 | Accuracy: 0.8333 | Loss: 1.5714\n","\n","Domain: 54\n","x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 54 | Accuracy: 0.3095 | Loss: 6.3525\n","\n","Domain: 55\n","x_dp_dom.shape: (49, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 55 | Accuracy: 0.8367 | Loss: 1.5161\n","\n","Domain: 56\n","x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 56 | Accuracy: 0.9048 | Loss: 0.2948\n","\n","Domain: 57\n","x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 57 | Accuracy: 0.9286 | Loss: 0.2061\n","\n","Domain: 58\n","x_dp_dom.shape: (38, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 58 | Accuracy: 0.7368 | Loss: 2.9074\n","\n","Domain: 59\n","x_dp_dom.shape: (43, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 59 | Accuracy: 0.6977 | Loss: 1.6299\n","\n","Domain: 60\n","x_dp_dom.shape: (47, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 60 | Accuracy: 0.6383 | Loss: 4.7268\n","\n","Domain: 61\n","x_dp_dom.shape: (47, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 61 | Accuracy: 0.6809 | Loss: 3.1326\n","\n","Domain: 62\n","x_dp_dom.shape: (47, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 62 | Accuracy: 0.8085 | Loss: 1.7483\n","\n","Domain: 63\n","x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 63 | Accuracy: 0.8810 | Loss: 0.5714\n","\n","Domain: 64\n","x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 64 | Accuracy: 0.9524 | Loss: 0.1603\n","\n","Domain: 65\n","x_dp_dom.shape: (50, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 65 | Accuracy: 0.6400 | Loss: 4.1437\n","\n","Domain: 66\n","x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 66 | Accuracy: 0.5238 | Loss: 1.9649\n","\n","Domain: 67\n","x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 67 | Accuracy: 0.5714 | Loss: 4.0467\n","\n","Domain: 68\n","x_dp_dom.shape: (43, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 68 | Accuracy: 0.8372 | Loss: 1.0659\n","\n","Domain: 69\n","x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 69 | Accuracy: 0.7619 | Loss: 0.8844\n","\n","Domain: 70\n","x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 70 | Accuracy: 0.7857 | Loss: 3.2024\n","\n","Domain: 71\n","x_dp_dom.shape: (44, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 71 | Accuracy: 0.7045 | Loss: 2.3209\n","\n","Domain: 72\n","x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 72 | Accuracy: 0.7857 | Loss: 1.3861\n","\n","Domain: 73\n","x_dp_dom.shape: (41, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 73 | Accuracy: 0.5122 | Loss: 3.0348\n","\n","Domain: 74\n","x_dp_dom.shape: (35, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 74 | Accuracy: 0.8000 | Loss: 1.6714\n","\n","Domain: 75\n","x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 75 | Accuracy: 0.8333 | Loss: 1.3612\n","\n","Source class: WAL\n","\n","x_df.shape: (7958, 3, 128) | np.unique(y_df): [1 2 3]\n","\n","Training on Df data...\n","\tEpoch 10/100 - Train loss: 0.0275 - Val accuracy: 0.9793 - Val loss: 0.0493 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.0068 - Val accuracy: 0.9849 - Val loss: 0.0366 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.0029 - Val accuracy: 0.9849 - Val loss: 0.0413 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.0013 - Val accuracy: 0.9868 - Val loss: 0.0412 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.0014 - Val accuracy: 0.9862 - Val loss: 0.0419 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.0004 - Val accuracy: 0.9856 - Val loss: 0.0455 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0004 - Val accuracy: 0.9856 - Val loss: 0.0439 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0002 - Val accuracy: 0.9874 - Val loss: 0.0453 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0003 - Val accuracy: 0.9856 - Val loss: 0.0503 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0002 - Val accuracy: 0.9868 - Val loss: 0.0472 - LR: 0.00e+00\n","\tBest epoch: 25 - Best val accuracy: 0.9849 - Best val loss: 0.0343\n","\n","Domain: 15\n","x_dp_dom.shape: (50, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 15 | Accuracy: 0.5600 | Loss: 11.5980\n","\n","Domain: 16\n","x_dp_dom.shape: (54, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 16 | Accuracy: 0.2407 | Loss: 23.3074\n","\n","Domain: 17\n","x_dp_dom.shape: (53, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 17 | Accuracy: 0.2264 | Loss: 19.0595\n","\n","Domain: 18\n","x_dp_dom.shape: (54, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 18 | Accuracy: 0.2407 | Loss: 19.2173\n","\n","Domain: 19\n","x_dp_dom.shape: (54, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 19 | Accuracy: 0.2407 | Loss: 22.7333\n","\n","Domain: 20\n","x_dp_dom.shape: (51, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 20 | Accuracy: 0.1961 | Loss: 16.7128\n","\n","Domain: 21\n","x_dp_dom.shape: (47, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 21 | Accuracy: 0.1489 | Loss: 25.9877\n","\n","Domain: 22\n","x_dp_dom.shape: (54, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 22 | Accuracy: 0.2407 | Loss: 21.2445\n","\n","Domain: 23\n","x_dp_dom.shape: (52, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 23 | Accuracy: 0.2115 | Loss: 16.1518\n","\n","Domain: 24\n","x_dp_dom.shape: (51, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 24 | Accuracy: 0.3529 | Loss: 10.7026\n","\n","Domain: 25\n","x_dp_dom.shape: (54, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 25 | Accuracy: 0.2407 | Loss: 21.9610\n","\n","Domain: 26\n","x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 26 | Accuracy: 0.1667 | Loss: 29.2470\n","\n","Domain: 27\n","x_dp_dom.shape: (54, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 27 | Accuracy: 0.2407 | Loss: 15.5985\n","\n","Domain: 28\n","x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 28 | Accuracy: 0.1667 | Loss: 28.4887\n","\n","Domain: 29\n","x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 29 | Accuracy: 0.1667 | Loss: 23.4391\n","\n","Domain: 30\n","x_dp_dom.shape: (50, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 30 | Accuracy: 0.1600 | Loss: 24.3610\n","\n","Domain: 31\n","x_dp_dom.shape: (43, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 31 | Accuracy: 0.2791 | Loss: 26.1397\n","\n","Domain: 32\n","x_dp_dom.shape: (52, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 32 | Accuracy: 0.2115 | Loss: 24.2874\n","\n","Domain: 33\n","x_dp_dom.shape: (44, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 33 | Accuracy: 0.1591 | Loss: 28.6917\n","\n","Domain: 34\n","x_dp_dom.shape: (49, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 34 | Accuracy: 0.3878 | Loss: 15.6190\n","\n","Domain: 35\n","x_dp_dom.shape: (48, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 35 | Accuracy: 0.1458 | Loss: 18.2759\n","\n","Domain: 36\n","x_dp_dom.shape: (43, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 36 | Accuracy: 0.1628 | Loss: 25.6563\n","\n","Domain: 37\n","x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 37 | Accuracy: 0.1429 | Loss: 21.0218\n","\n","Domain: 38\n","x_dp_dom.shape: (47, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 38 | Accuracy: 0.1702 | Loss: 19.6102\n","\n","Domain: 39\n","x_dp_dom.shape: (54, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 39 | Accuracy: 0.7963 | Loss: 6.0569\n","\n","Domain: 40\n","x_dp_dom.shape: (44, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 40 | Accuracy: 0.1591 | Loss: 21.7719\n","\n","Domain: 41\n","x_dp_dom.shape: (45, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 41 | Accuracy: 0.0444 | Loss: 24.0501\n","\n","Domain: 42\n","x_dp_dom.shape: (46, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 42 | Accuracy: 0.1304 | Loss: 28.0858\n","\n","Domain: 43\n","x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 43 | Accuracy: 0.3095 | Loss: 26.0126\n","\n","Domain: 44\n","x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 44 | Accuracy: 0.1667 | Loss: 31.1626\n","\n","Domain: 45\n","x_dp_dom.shape: (52, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 45 | Accuracy: 0.2115 | Loss: 23.7407\n","\n","Domain: 46\n","x_dp_dom.shape: (48, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 46 | Accuracy: 0.1458 | Loss: 23.8427\n","\n","Domain: 47\n","x_dp_dom.shape: (44, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 47 | Accuracy: 0.1591 | Loss: 29.4436\n","\n","Domain: 48\n","x_dp_dom.shape: (48, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 48 | Accuracy: 0.1667 | Loss: 20.4471\n","\n","Domain: 49\n","x_dp_dom.shape: (53, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 49 | Accuracy: 0.2264 | Loss: 16.8984\n","\n","Domain: 50\n","x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 50 | Accuracy: 0.1667 | Loss: 28.7364\n","\n","Domain: 51\n","x_dp_dom.shape: (46, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 51 | Accuracy: 0.1522 | Loss: 24.8668\n","\n","Domain: 52\n","x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 52 | Accuracy: 0.1667 | Loss: 24.3303\n","\n","Domain: 53\n","x_dp_dom.shape: (48, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 53 | Accuracy: 0.2083 | Loss: 14.8911\n","\n","Domain: 54\n","x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 54 | Accuracy: 0.2143 | Loss: 21.8645\n","\n","Domain: 55\n","x_dp_dom.shape: (49, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 55 | Accuracy: 0.1633 | Loss: 24.3908\n","\n","Domain: 56\n","x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 56 | Accuracy: 0.1667 | Loss: 20.8791\n","\n","Domain: 57\n","x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 57 | Accuracy: 0.1667 | Loss: 29.9467\n","\n","Domain: 58\n","x_dp_dom.shape: (38, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 58 | Accuracy: 0.1316 | Loss: 25.5961\n","\n","Domain: 59\n","x_dp_dom.shape: (43, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 59 | Accuracy: 0.1628 | Loss: 18.9311\n","\n","Domain: 60\n","x_dp_dom.shape: (47, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 60 | Accuracy: 0.5745 | Loss: 11.4435\n","\n","Domain: 61\n","x_dp_dom.shape: (47, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 61 | Accuracy: 0.1277 | Loss: 25.1074\n","\n","Domain: 62\n","x_dp_dom.shape: (47, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 62 | Accuracy: 0.1489 | Loss: 23.5777\n","\n","Domain: 63\n","x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 63 | Accuracy: 0.1905 | Loss: 31.8937\n","\n","Domain: 64\n","x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 64 | Accuracy: 0.1667 | Loss: 25.5730\n","\n","Domain: 65\n","x_dp_dom.shape: (50, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 65 | Accuracy: 0.7000 | Loss: 6.2092\n","\n","Domain: 66\n","x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 66 | Accuracy: 0.7857 | Loss: 6.9175\n","\n","Domain: 67\n","x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 67 | Accuracy: 0.1667 | Loss: 17.2678\n","\n","Domain: 68\n","x_dp_dom.shape: (43, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 68 | Accuracy: 0.1628 | Loss: 26.0927\n","\n","Domain: 69\n","x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 69 | Accuracy: 0.8333 | Loss: 4.8606\n","\n","Domain: 70\n","x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 70 | Accuracy: 0.1190 | Loss: 17.3367\n","\n","Domain: 71\n","x_dp_dom.shape: (44, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 71 | Accuracy: 0.1591 | Loss: 23.8064\n","\n","Domain: 72\n","x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 72 | Accuracy: 0.1667 | Loss: 24.4756\n","\n","Domain: 73\n","x_dp_dom.shape: (41, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 73 | Accuracy: 0.6829 | Loss: 5.0222\n","\n","Domain: 74\n","x_dp_dom.shape: (35, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 74 | Accuracy: 0.0000 | Loss: 35.9835\n","\n","Domain: 75\n","x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 75 | Accuracy: 0.1667 | Loss: 29.1431\n","\n","Source class: WAL\n","\n","x_df.shape: (7958, 3, 128) | np.unique(y_df): [1 2 3]\n","\n","Training on Df data...\n","\tEpoch 10/100 - Train loss: 0.0382 - Val accuracy: 0.9786 - Val loss: 0.0593 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.0101 - Val accuracy: 0.9824 - Val loss: 0.0454 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.0057 - Val accuracy: 0.9862 - Val loss: 0.0433 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.0019 - Val accuracy: 0.9874 - Val loss: 0.0499 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.0012 - Val accuracy: 0.9862 - Val loss: 0.0479 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.0011 - Val accuracy: 0.9856 - Val loss: 0.0479 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0004 - Val accuracy: 0.9868 - Val loss: 0.0537 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0006 - Val accuracy: 0.9856 - Val loss: 0.0578 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0002 - Val accuracy: 0.9874 - Val loss: 0.0511 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0003 - Val accuracy: 0.9862 - Val loss: 0.0516 - LR: 0.00e+00\n","\tBest epoch: 31 - Best val accuracy: 0.9868 - Best val loss: 0.0395\n","\n","Domain: 15\n","x_dp_dom.shape: (50, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 15 | Accuracy: 0.1000 | Loss: 10.1019\n","\n","Domain: 16\n","x_dp_dom.shape: (54, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 16 | Accuracy: 0.6111 | Loss: 1.6802\n","\n","Domain: 17\n","x_dp_dom.shape: (53, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 17 | Accuracy: 0.4340 | Loss: 1.0613\n","\n","Domain: 18\n","x_dp_dom.shape: (54, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 18 | Accuracy: 0.5000 | Loss: 2.8499\n","\n","Domain: 19\n","x_dp_dom.shape: (54, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 19 | Accuracy: 0.5556 | Loss: 0.9293\n","\n","Domain: 20\n","x_dp_dom.shape: (51, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 20 | Accuracy: 0.6667 | Loss: 1.3442\n","\n","Domain: 21\n","x_dp_dom.shape: (47, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 21 | Accuracy: 0.4681 | Loss: 2.7644\n","\n","Domain: 22\n","x_dp_dom.shape: (54, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 22 | Accuracy: 0.4630 | Loss: 3.5072\n","\n","Domain: 23\n","x_dp_dom.shape: (52, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 23 | Accuracy: 0.6346 | Loss: 2.0324\n","\n","Domain: 24\n","x_dp_dom.shape: (51, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 24 | Accuracy: 0.7647 | Loss: 0.5988\n","\n","Domain: 25\n","x_dp_dom.shape: (54, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 25 | Accuracy: 0.5370 | Loss: 1.5135\n","\n","Domain: 26\n","x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 26 | Accuracy: 0.7619 | Loss: 2.1780\n","\n","Domain: 27\n","x_dp_dom.shape: (54, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 27 | Accuracy: 0.7593 | Loss: 2.0207\n","\n","Domain: 28\n","x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 28 | Accuracy: 0.8333 | Loss: 1.4759\n","\n","Domain: 29\n","x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 29 | Accuracy: 0.4048 | Loss: 2.4675\n","\n","Domain: 30\n","x_dp_dom.shape: (50, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 30 | Accuracy: 0.6400 | Loss: 4.9346\n","\n","Domain: 31\n","x_dp_dom.shape: (43, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 31 | Accuracy: 0.7907 | Loss: 1.6294\n","\n","Domain: 32\n","x_dp_dom.shape: (52, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 32 | Accuracy: 0.5962 | Loss: 4.2123\n","\n","Domain: 33\n","x_dp_dom.shape: (44, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 33 | Accuracy: 0.7500 | Loss: 1.1909\n","\n","Domain: 34\n","x_dp_dom.shape: (49, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 34 | Accuracy: 0.6531 | Loss: 1.5484\n","\n","Domain: 35\n","x_dp_dom.shape: (48, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 35 | Accuracy: 0.2917 | Loss: 3.6230\n","\n","Domain: 36\n","x_dp_dom.shape: (43, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 36 | Accuracy: 0.6744 | Loss: 1.3383\n","\n","Domain: 37\n","x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 37 | Accuracy: 0.8095 | Loss: 0.5305\n","\n","Domain: 38\n","x_dp_dom.shape: (47, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 38 | Accuracy: 0.7447 | Loss: 2.1625\n","\n","Domain: 39\n","x_dp_dom.shape: (54, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 39 | Accuracy: 0.4074 | Loss: 7.3314\n","\n","Domain: 40\n","x_dp_dom.shape: (44, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 40 | Accuracy: 0.7500 | Loss: 1.8993\n","\n","Domain: 41\n","x_dp_dom.shape: (45, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 41 | Accuracy: 0.6667 | Loss: 5.8361\n","\n","Domain: 42\n","x_dp_dom.shape: (46, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 42 | Accuracy: 0.8261 | Loss: 1.9529\n","\n","Domain: 43\n","x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 43 | Accuracy: 0.4524 | Loss: 6.5367\n","\n","Domain: 44\n","x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 44 | Accuracy: 0.6667 | Loss: 0.9105\n","\n","Domain: 45\n","x_dp_dom.shape: (52, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 45 | Accuracy: 0.4615 | Loss: 2.7326\n","\n","Domain: 46\n","x_dp_dom.shape: (48, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 46 | Accuracy: 0.6042 | Loss: 1.4524\n","\n","Domain: 47\n","x_dp_dom.shape: (44, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 47 | Accuracy: 0.6591 | Loss: 2.0176\n","\n","Domain: 48\n","x_dp_dom.shape: (48, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 48 | Accuracy: 0.6042 | Loss: 2.6249\n","\n","Domain: 49\n","x_dp_dom.shape: (53, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 49 | Accuracy: 0.7170 | Loss: 0.8129\n","\n","Domain: 50\n","x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 50 | Accuracy: 0.6429 | Loss: 2.0949\n","\n","Domain: 51\n","x_dp_dom.shape: (46, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 51 | Accuracy: 0.6522 | Loss: 2.8910\n","\n","Domain: 52\n","x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 52 | Accuracy: 0.5952 | Loss: 1.8676\n","\n","Domain: 53\n","x_dp_dom.shape: (48, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 53 | Accuracy: 0.7292 | Loss: 1.1503\n","\n","Domain: 54\n","x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 54 | Accuracy: 0.8095 | Loss: 1.9387\n","\n","Domain: 55\n","x_dp_dom.shape: (49, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 55 | Accuracy: 0.6531 | Loss: 1.1580\n","\n","Domain: 56\n","x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 56 | Accuracy: 0.7381 | Loss: 1.4347\n","\n","Domain: 57\n","x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 57 | Accuracy: 0.7381 | Loss: 1.8083\n","\n","Domain: 58\n","x_dp_dom.shape: (38, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 58 | Accuracy: 0.8421 | Loss: 1.9708\n","\n","Domain: 59\n","x_dp_dom.shape: (43, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 59 | Accuracy: 0.5349 | Loss: 2.4942\n","\n","Domain: 60\n","x_dp_dom.shape: (47, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 60 | Accuracy: 0.4468 | Loss: 11.5707\n","\n","Domain: 61\n","x_dp_dom.shape: (47, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 61 | Accuracy: 0.7447 | Loss: 1.3164\n","\n","Domain: 62\n","x_dp_dom.shape: (47, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 62 | Accuracy: 0.1702 | Loss: 3.2629\n","\n","Domain: 63\n","x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 63 | Accuracy: 0.6429 | Loss: 2.4036\n","\n","Domain: 64\n","x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 64 | Accuracy: 0.6190 | Loss: 1.5382\n","\n","Domain: 65\n","x_dp_dom.shape: (50, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 65 | Accuracy: 0.3200 | Loss: 7.4568\n","\n","Domain: 66\n","x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 66 | Accuracy: 0.1190 | Loss: 14.1971\n","\n","Domain: 67\n","x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 67 | Accuracy: 0.7381 | Loss: 2.6032\n","\n","Domain: 68\n","x_dp_dom.shape: (43, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 68 | Accuracy: 0.4884 | Loss: 2.3284\n","\n","Domain: 69\n","x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 69 | Accuracy: 0.1190 | Loss: 4.9541\n","\n","Domain: 70\n","x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 70 | Accuracy: 0.7857 | Loss: 2.3308\n","\n","Domain: 71\n","x_dp_dom.shape: (44, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 71 | Accuracy: 0.7500 | Loss: 1.0113\n","\n","Domain: 72\n","x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 72 | Accuracy: 0.5714 | Loss: 1.7441\n","\n","Domain: 73\n","x_dp_dom.shape: (41, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 73 | Accuracy: 0.5366 | Loss: 7.3227\n","\n","Domain: 74\n","x_dp_dom.shape: (35, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 74 | Accuracy: 0.8286 | Loss: 2.2638\n","\n","Domain: 75\n","x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 75 | Accuracy: 0.5952 | Loss: 1.9180\n","\n","Source class: WAL\n","\n","x_df.shape: (7958, 3, 128) | np.unique(y_df): [1 2 3]\n","\n","Training on Df data...\n","\tEpoch 10/100 - Train loss: 0.0271 - Val accuracy: 0.9812 - Val loss: 0.0490 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.0081 - Val accuracy: 0.9830 - Val loss: 0.0473 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.0028 - Val accuracy: 0.9830 - Val loss: 0.0554 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.0012 - Val accuracy: 0.9830 - Val loss: 0.0498 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.0012 - Val accuracy: 0.9843 - Val loss: 0.0526 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.0007 - Val accuracy: 0.9856 - Val loss: 0.0537 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0004 - Val accuracy: 0.9837 - Val loss: 0.0627 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0007 - Val accuracy: 0.9849 - Val loss: 0.0585 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0002 - Val accuracy: 0.9856 - Val loss: 0.0565 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0002 - Val accuracy: 0.9830 - Val loss: 0.0611 - LR: 0.00e+00\n","\tBest epoch: 17 - Best val accuracy: 0.9837 - Best val loss: 0.0428\n","\n","Domain: 15\n","x_dp_dom.shape: (50, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 15 | Accuracy: 0.2800 | Loss: 11.9601\n","\n","Domain: 16\n","x_dp_dom.shape: (54, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 16 | Accuracy: 0.7222 | Loss: 7.5487\n","\n","Domain: 17\n","x_dp_dom.shape: (53, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 17 | Accuracy: 0.6226 | Loss: 8.1913\n","\n","Domain: 18\n","x_dp_dom.shape: (54, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 18 | Accuracy: 0.4630 | Loss: 9.1736\n","\n","Domain: 19\n","x_dp_dom.shape: (54, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 19 | Accuracy: 0.6111 | Loss: 8.3762\n","\n","Domain: 20\n","x_dp_dom.shape: (51, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 20 | Accuracy: 0.5686 | Loss: 5.9954\n","\n","Domain: 21\n","x_dp_dom.shape: (47, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 21 | Accuracy: 0.6809 | Loss: 5.3152\n","\n","Domain: 22\n","x_dp_dom.shape: (54, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 22 | Accuracy: 0.6852 | Loss: 7.8332\n","\n","Domain: 23\n","x_dp_dom.shape: (52, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 23 | Accuracy: 0.7692 | Loss: 6.6169\n","\n","Domain: 24\n","x_dp_dom.shape: (51, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 24 | Accuracy: 0.6078 | Loss: 8.2144\n","\n","Domain: 25\n","x_dp_dom.shape: (54, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 25 | Accuracy: 0.7222 | Loss: 8.0724\n","\n","Domain: 26\n","x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 26 | Accuracy: 0.6905 | Loss: 4.7588\n","\n","Domain: 27\n","x_dp_dom.shape: (54, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 27 | Accuracy: 0.7593 | Loss: 7.6560\n","\n","Domain: 28\n","x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 28 | Accuracy: 0.8333 | Loss: 4.9790\n","\n","Domain: 29\n","x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 29 | Accuracy: 0.5238 | Loss: 6.1933\n","\n","Domain: 30\n","x_dp_dom.shape: (50, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 30 | Accuracy: 0.7400 | Loss: 6.5804\n","\n","Domain: 31\n","x_dp_dom.shape: (43, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 31 | Accuracy: 0.6279 | Loss: 5.5089\n","\n","Domain: 32\n","x_dp_dom.shape: (52, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 32 | Accuracy: 0.7885 | Loss: 5.6578\n","\n","Domain: 33\n","x_dp_dom.shape: (44, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 33 | Accuracy: 0.8182 | Loss: 4.0954\n","\n","Domain: 34\n","x_dp_dom.shape: (49, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 34 | Accuracy: 0.6531 | Loss: 5.8283\n","\n","Domain: 35\n","x_dp_dom.shape: (48, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 35 | Accuracy: 0.7292 | Loss: 5.0679\n","\n","Domain: 36\n","x_dp_dom.shape: (43, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 36 | Accuracy: 0.7674 | Loss: 5.0094\n","\n","Domain: 37\n","x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 37 | Accuracy: 0.6667 | Loss: 4.4314\n","\n","Domain: 38\n","x_dp_dom.shape: (47, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 38 | Accuracy: 0.8085 | Loss: 4.3412\n","\n","Domain: 39\n","x_dp_dom.shape: (54, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 39 | Accuracy: 0.3889 | Loss: 13.5592\n","\n","Domain: 40\n","x_dp_dom.shape: (44, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 40 | Accuracy: 0.7500 | Loss: 4.3116\n","\n","Domain: 41\n","x_dp_dom.shape: (45, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 41 | Accuracy: 0.2667 | Loss: 8.9050\n","\n","Domain: 42\n","x_dp_dom.shape: (46, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 42 | Accuracy: 0.7826 | Loss: 4.5119\n","\n","Domain: 43\n","x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 43 | Accuracy: 0.6190 | Loss: 5.9140\n","\n","Domain: 44\n","x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 44 | Accuracy: 0.8095 | Loss: 5.2330\n","\n","Domain: 45\n","x_dp_dom.shape: (52, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 45 | Accuracy: 0.6923 | Loss: 6.7046\n","\n","Domain: 46\n","x_dp_dom.shape: (48, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 46 | Accuracy: 0.6875 | Loss: 5.2659\n","\n","Domain: 47\n","x_dp_dom.shape: (44, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 47 | Accuracy: 0.7500 | Loss: 4.8082\n","\n","Domain: 48\n","x_dp_dom.shape: (48, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 48 | Accuracy: 0.8333 | Loss: 4.9871\n","\n","Domain: 49\n","x_dp_dom.shape: (53, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 49 | Accuracy: 0.4151 | Loss: 7.5602\n","\n","Domain: 50\n","x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 50 | Accuracy: 0.7619 | Loss: 4.4452\n","\n","Domain: 51\n","x_dp_dom.shape: (46, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 51 | Accuracy: 0.8043 | Loss: 4.4447\n","\n","Domain: 52\n","x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 52 | Accuracy: 0.8095 | Loss: 4.9180\n","\n","Domain: 53\n","x_dp_dom.shape: (48, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 53 | Accuracy: 0.7917 | Loss: 4.9265\n","\n","Domain: 54\n","x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 54 | Accuracy: 0.5714 | Loss: 4.6252\n","\n","Domain: 55\n","x_dp_dom.shape: (49, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 55 | Accuracy: 0.7755 | Loss: 5.1311\n","\n","Domain: 56\n","x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 56 | Accuracy: 0.8333 | Loss: 4.1203\n","\n","Domain: 57\n","x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 57 | Accuracy: 0.8333 | Loss: 4.3366\n","\n","Domain: 58\n","x_dp_dom.shape: (38, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 58 | Accuracy: 0.8421 | Loss: 3.6205\n","\n","Domain: 59\n","x_dp_dom.shape: (43, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 59 | Accuracy: 0.8372 | Loss: 4.7748\n","\n","Domain: 60\n","x_dp_dom.shape: (47, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 60 | Accuracy: 0.4255 | Loss: 9.9471\n","\n","Domain: 61\n","x_dp_dom.shape: (47, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 61 | Accuracy: 0.4468 | Loss: 4.3201\n","\n","Domain: 62\n","x_dp_dom.shape: (47, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 62 | Accuracy: 0.6809 | Loss: 4.7692\n","\n","Domain: 63\n","x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 63 | Accuracy: 0.7619 | Loss: 5.1631\n","\n","Domain: 64\n","x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 64 | Accuracy: 0.8333 | Loss: 5.2685\n","\n","Domain: 65\n","x_dp_dom.shape: (50, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 65 | Accuracy: 0.2600 | Loss: 13.8424\n","\n","Domain: 66\n","x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 66 | Accuracy: 0.1667 | Loss: 17.6675\n","\n","Domain: 67\n","x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 67 | Accuracy: 0.6667 | Loss: 4.4092\n","\n","Domain: 68\n","x_dp_dom.shape: (43, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 68 | Accuracy: 0.6744 | Loss: 5.2839\n","\n","Domain: 69\n","x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 69 | Accuracy: 0.1667 | Loss: 11.6588\n","\n","Domain: 70\n","x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 70 | Accuracy: 0.4048 | Loss: 5.9251\n","\n","Domain: 71\n","x_dp_dom.shape: (44, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 71 | Accuracy: 0.7273 | Loss: 4.9559\n","\n","Domain: 72\n","x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 72 | Accuracy: 0.6429 | Loss: 5.4461\n","\n","Domain: 73\n","x_dp_dom.shape: (41, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 73 | Accuracy: 0.1707 | Loss: 15.6451\n","\n","Domain: 74\n","x_dp_dom.shape: (35, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 74 | Accuracy: 0.8286 | Loss: 1.8465\n","\n","Domain: 75\n","x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 75 | Accuracy: 0.7857 | Loss: 4.9801\n","\n","Source class: WAL\n","\n","x_df.shape: (7958, 3, 128) | np.unique(y_df): [1 2 3]\n","\n","Training on Df data...\n","\tEpoch 10/100 - Train loss: 0.0267 - Val accuracy: 0.9818 - Val loss: 0.0532 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.0087 - Val accuracy: 0.9843 - Val loss: 0.0478 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.0037 - Val accuracy: 0.9868 - Val loss: 0.0424 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.0045 - Val accuracy: 0.9849 - Val loss: 0.0484 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.0009 - Val accuracy: 0.9868 - Val loss: 0.0527 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.0005 - Val accuracy: 0.9849 - Val loss: 0.0454 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0003 - Val accuracy: 0.9868 - Val loss: 0.0467 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0002 - Val accuracy: 0.9868 - Val loss: 0.0545 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0001 - Val accuracy: 0.9874 - Val loss: 0.0520 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0002 - Val accuracy: 0.9862 - Val loss: 0.0512 - LR: 0.00e+00\n","\tBest epoch: 21 - Best val accuracy: 0.9849 - Best val loss: 0.0381\n","\n","Domain: 15\n","x_dp_dom.shape: (50, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 15 | Accuracy: 0.1400 | Loss: 19.0885\n","\n","Domain: 16\n","x_dp_dom.shape: (54, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 16 | Accuracy: 0.6481 | Loss: 3.4423\n","\n","Domain: 17\n","x_dp_dom.shape: (53, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 17 | Accuracy: 0.7736 | Loss: 3.3661\n","\n","Domain: 18\n","x_dp_dom.shape: (54, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 18 | Accuracy: 0.6667 | Loss: 3.5435\n","\n","Domain: 19\n","x_dp_dom.shape: (54, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 19 | Accuracy: 0.7593 | Loss: 3.3003\n","\n","Domain: 20\n","x_dp_dom.shape: (51, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 20 | Accuracy: 0.6471 | Loss: 2.8571\n","\n","Domain: 21\n","x_dp_dom.shape: (47, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 21 | Accuracy: 0.7234 | Loss: 2.2820\n","\n","Domain: 22\n","x_dp_dom.shape: (54, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 22 | Accuracy: 0.6296 | Loss: 4.0072\n","\n","Domain: 23\n","x_dp_dom.shape: (52, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 23 | Accuracy: 0.6731 | Loss: 3.5554\n","\n","Domain: 24\n","x_dp_dom.shape: (51, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 24 | Accuracy: 0.7059 | Loss: 3.2281\n","\n","Domain: 25\n","x_dp_dom.shape: (54, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 25 | Accuracy: 0.7593 | Loss: 4.0026\n","\n","Domain: 26\n","x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 26 | Accuracy: 0.5952 | Loss: 2.9858\n","\n","Domain: 27\n","x_dp_dom.shape: (54, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 27 | Accuracy: 0.7593 | Loss: 3.9985\n","\n","Domain: 28\n","x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 28 | Accuracy: 0.6667 | Loss: 2.3353\n","\n","Domain: 29\n","x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 29 | Accuracy: 0.6905 | Loss: 2.9127\n","\n","Domain: 30\n","x_dp_dom.shape: (50, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 30 | Accuracy: 0.7600 | Loss: 5.5955\n","\n","Domain: 31\n","x_dp_dom.shape: (43, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 31 | Accuracy: 0.8372 | Loss: 2.6208\n","\n","Domain: 32\n","x_dp_dom.shape: (52, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 32 | Accuracy: 0.7885 | Loss: 3.0347\n","\n","Domain: 33\n","x_dp_dom.shape: (44, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 33 | Accuracy: 0.6818 | Loss: 2.5324\n","\n","Domain: 34\n","x_dp_dom.shape: (49, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 34 | Accuracy: 0.4490 | Loss: 6.3524\n","\n","Domain: 35\n","x_dp_dom.shape: (48, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 35 | Accuracy: 0.8542 | Loss: 1.4606\n","\n","Domain: 36\n","x_dp_dom.shape: (43, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 36 | Accuracy: 0.7674 | Loss: 1.8560\n","\n","Domain: 37\n","x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 37 | Accuracy: 0.6905 | Loss: 2.1437\n","\n","Domain: 38\n","x_dp_dom.shape: (47, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 38 | Accuracy: 0.7021 | Loss: 3.5299\n","\n","Domain: 39\n","x_dp_dom.shape: (54, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 39 | Accuracy: 0.4074 | Loss: 13.5340\n","\n","Domain: 40\n","x_dp_dom.shape: (44, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 40 | Accuracy: 0.7273 | Loss: 2.8044\n","\n","Domain: 41\n","x_dp_dom.shape: (45, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 41 | Accuracy: 0.7111 | Loss: 5.4458\n","\n","Domain: 42\n","x_dp_dom.shape: (46, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 42 | Accuracy: 0.8478 | Loss: 2.7174\n","\n","Domain: 43\n","x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 43 | Accuracy: 0.5000 | Loss: 9.6034\n","\n","Domain: 44\n","x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 44 | Accuracy: 0.8333 | Loss: 1.8948\n","\n","Domain: 45\n","x_dp_dom.shape: (52, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 45 | Accuracy: 0.7692 | Loss: 2.0635\n","\n","Domain: 46\n","x_dp_dom.shape: (48, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 46 | Accuracy: 0.8542 | Loss: 1.8193\n","\n","Domain: 47\n","x_dp_dom.shape: (44, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 47 | Accuracy: 0.6818 | Loss: 3.4239\n","\n","Domain: 48\n","x_dp_dom.shape: (48, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 48 | Accuracy: 0.6250 | Loss: 4.7371\n","\n","Domain: 49\n","x_dp_dom.shape: (53, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 49 | Accuracy: 0.6792 | Loss: 2.1147\n","\n","Domain: 50\n","x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 50 | Accuracy: 0.6667 | Loss: 5.2016\n","\n","Domain: 51\n","x_dp_dom.shape: (46, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 51 | Accuracy: 0.6304 | Loss: 5.0294\n","\n","Domain: 52\n","x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 52 | Accuracy: 0.7619 | Loss: 1.9328\n","\n","Domain: 53\n","x_dp_dom.shape: (48, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 53 | Accuracy: 0.6250 | Loss: 3.0922\n","\n","Domain: 54\n","x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 54 | Accuracy: 0.7857 | Loss: 2.1073\n","\n","Domain: 55\n","x_dp_dom.shape: (49, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 55 | Accuracy: 0.7755 | Loss: 1.8704\n","\n","Domain: 56\n","x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 56 | Accuracy: 0.6667 | Loss: 4.2197\n","\n","Domain: 57\n","x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 57 | Accuracy: 0.6667 | Loss: 4.7337\n","\n","Domain: 58\n","x_dp_dom.shape: (38, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 58 | Accuracy: 0.7368 | Loss: 4.8592\n","\n","Domain: 59\n","x_dp_dom.shape: (43, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 59 | Accuracy: 0.6512 | Loss: 4.9884\n","\n","Domain: 60\n","x_dp_dom.shape: (47, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 60 | Accuracy: 0.4255 | Loss: 16.9708\n","\n","Domain: 61\n","x_dp_dom.shape: (47, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 61 | Accuracy: 0.7660 | Loss: 2.3673\n","\n","Domain: 62\n","x_dp_dom.shape: (47, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 62 | Accuracy: 0.8085 | Loss: 1.6159\n","\n","Domain: 63\n","x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 63 | Accuracy: 0.6905 | Loss: 4.8089\n","\n","Domain: 64\n","x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 64 | Accuracy: 0.7619 | Loss: 2.1919\n","\n","Domain: 65\n","x_dp_dom.shape: (50, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 65 | Accuracy: 0.2600 | Loss: 16.9893\n","\n","Domain: 66\n","x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 66 | Accuracy: 0.1190 | Loss: 23.8500\n","\n","Domain: 67\n","x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 67 | Accuracy: 0.7857 | Loss: 2.7008\n","\n","Domain: 68\n","x_dp_dom.shape: (43, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 68 | Accuracy: 0.6744 | Loss: 4.3398\n","\n","Domain: 69\n","x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 69 | Accuracy: 0.0000 | Loss: 13.9264\n","\n","Domain: 70\n","x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 70 | Accuracy: 0.7619 | Loss: 4.0847\n","\n","Domain: 71\n","x_dp_dom.shape: (44, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 71 | Accuracy: 0.7955 | Loss: 2.2994\n","\n","Domain: 72\n","x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 72 | Accuracy: 0.6667 | Loss: 3.6044\n","\n","Domain: 73\n","x_dp_dom.shape: (41, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 73 | Accuracy: 0.1707 | Loss: 19.3707\n","\n","Domain: 74\n","x_dp_dom.shape: (35, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 74 | Accuracy: 0.8000 | Loss: 5.4824\n","\n","Domain: 75\n","x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 75 | Accuracy: 0.6905 | Loss: 2.6261\n","\n","Source class: WAL\n","\n","x_df.shape: (7958, 3, 128) | np.unique(y_df): [1 2 3]\n","\n","Training on Df data...\n","\tEpoch 10/100 - Train loss: 0.0338 - Val accuracy: 0.9793 - Val loss: 0.0564 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.0087 - Val accuracy: 0.9805 - Val loss: 0.0495 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.0024 - Val accuracy: 0.9837 - Val loss: 0.0466 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.0013 - Val accuracy: 0.9862 - Val loss: 0.0503 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.0007 - Val accuracy: 0.9843 - Val loss: 0.0555 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.0004 - Val accuracy: 0.9830 - Val loss: 0.0643 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0009 - Val accuracy: 0.9837 - Val loss: 0.0690 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0003 - Val accuracy: 0.9856 - Val loss: 0.0567 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0005 - Val accuracy: 0.9862 - Val loss: 0.0556 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0002 - Val accuracy: 0.9856 - Val loss: 0.0587 - LR: 0.00e+00\n","\tBest epoch: 25 - Best val accuracy: 0.9837 - Best val loss: 0.0456\n","\n","Domain: 15\n","x_dp_dom.shape: (50, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 15 | Accuracy: 0.2400 | Loss: 16.6461\n","\n","Domain: 16\n","x_dp_dom.shape: (54, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 16 | Accuracy: 0.2407 | Loss: 14.6059\n","\n","Domain: 17\n","x_dp_dom.shape: (53, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 17 | Accuracy: 0.2453 | Loss: 17.8949\n","\n","Domain: 18\n","x_dp_dom.shape: (54, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 18 | Accuracy: 0.2963 | Loss: 10.7734\n","\n","Domain: 19\n","x_dp_dom.shape: (54, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 19 | Accuracy: 0.2407 | Loss: 22.3666\n","\n","Domain: 20\n","x_dp_dom.shape: (51, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 20 | Accuracy: 0.5490 | Loss: 8.2677\n","\n","Domain: 21\n","x_dp_dom.shape: (47, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 21 | Accuracy: 0.2553 | Loss: 10.9989\n","\n","Domain: 22\n","x_dp_dom.shape: (54, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 22 | Accuracy: 0.2593 | Loss: 13.6259\n","\n","Domain: 23\n","x_dp_dom.shape: (52, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 23 | Accuracy: 0.3846 | Loss: 9.5556\n","\n","Domain: 24\n","x_dp_dom.shape: (51, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 24 | Accuracy: 0.5882 | Loss: 9.2062\n","\n","Domain: 25\n","x_dp_dom.shape: (54, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 25 | Accuracy: 0.3889 | Loss: 9.6749\n","\n","Domain: 26\n","x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 26 | Accuracy: 0.2619 | Loss: 12.7316\n","\n","Domain: 27\n","x_dp_dom.shape: (54, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 27 | Accuracy: 0.2407 | Loss: 16.5176\n","\n","Domain: 28\n","x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 28 | Accuracy: 0.2381 | Loss: 11.8625\n","\n","Domain: 29\n","x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 29 | Accuracy: 0.1667 | Loss: 21.6193\n","\n","Domain: 30\n","x_dp_dom.shape: (50, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 30 | Accuracy: 0.2200 | Loss: 15.2480\n","\n","Domain: 31\n","x_dp_dom.shape: (43, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 31 | Accuracy: 0.2791 | Loss: 11.2880\n","\n","Domain: 32\n","x_dp_dom.shape: (52, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 32 | Accuracy: 0.2885 | Loss: 10.6776\n","\n","Domain: 33\n","x_dp_dom.shape: (44, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 33 | Accuracy: 0.5909 | Loss: 5.8005\n","\n","Domain: 34\n","x_dp_dom.shape: (49, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 34 | Accuracy: 0.4286 | Loss: 7.3692\n","\n","Domain: 35\n","x_dp_dom.shape: (48, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 35 | Accuracy: 0.2708 | Loss: 16.9470\n","\n","Domain: 36\n","x_dp_dom.shape: (43, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 36 | Accuracy: 0.1860 | Loss: 15.5159\n","\n","Domain: 37\n","x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 37 | Accuracy: 0.5238 | Loss: 7.4000\n","\n","Domain: 38\n","x_dp_dom.shape: (47, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 38 | Accuracy: 0.2553 | Loss: 11.6486\n","\n","Domain: 39\n","x_dp_dom.shape: (54, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 39 | Accuracy: 0.2407 | Loss: 16.5006\n","\n","Domain: 40\n","x_dp_dom.shape: (44, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 40 | Accuracy: 0.2045 | Loss: 13.0283\n","\n","Domain: 41\n","x_dp_dom.shape: (45, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 41 | Accuracy: 0.1556 | Loss: 13.9498\n","\n","Domain: 42\n","x_dp_dom.shape: (46, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 42 | Accuracy: 0.2391 | Loss: 14.3639\n","\n","Domain: 43\n","x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 43 | Accuracy: 0.3333 | Loss: 11.6250\n","\n","Domain: 44\n","x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 44 | Accuracy: 0.1905 | Loss: 15.1780\n","\n","Domain: 45\n","x_dp_dom.shape: (52, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 45 | Accuracy: 0.2885 | Loss: 9.9867\n","\n","Domain: 46\n","x_dp_dom.shape: (48, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 46 | Accuracy: 0.3542 | Loss: 9.1395\n","\n","Domain: 47\n","x_dp_dom.shape: (44, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 47 | Accuracy: 0.3409 | Loss: 8.3016\n","\n","Domain: 48\n","x_dp_dom.shape: (48, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 48 | Accuracy: 0.5833 | Loss: 5.4090\n","\n","Domain: 49\n","x_dp_dom.shape: (53, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 49 | Accuracy: 0.2453 | Loss: 16.8673\n","\n","Domain: 50\n","x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 50 | Accuracy: 0.6190 | Loss: 5.6115\n","\n","Domain: 51\n","x_dp_dom.shape: (46, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 51 | Accuracy: 0.5000 | Loss: 6.0511\n","\n","Domain: 52\n","x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 52 | Accuracy: 0.1667 | Loss: 14.9320\n","\n","Domain: 53\n","x_dp_dom.shape: (48, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 53 | Accuracy: 0.6458 | Loss: 6.8545\n","\n","Domain: 54\n","x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 54 | Accuracy: 0.2381 | Loss: 6.1128\n","\n","Domain: 55\n","x_dp_dom.shape: (49, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 55 | Accuracy: 0.5102 | Loss: 6.8413\n","\n","Domain: 56\n","x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 56 | Accuracy: 0.8333 | Loss: 4.4744\n","\n","Domain: 57\n","x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 57 | Accuracy: 0.7143 | Loss: 4.1296\n","\n","Domain: 58\n","x_dp_dom.shape: (38, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 58 | Accuracy: 0.3158 | Loss: 5.8637\n","\n","Domain: 59\n","x_dp_dom.shape: (43, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 59 | Accuracy: 0.8140 | Loss: 4.8773\n","\n","Domain: 60\n","x_dp_dom.shape: (47, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 60 | Accuracy: 0.2340 | Loss: 16.9586\n","\n","Domain: 61\n","x_dp_dom.shape: (47, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 61 | Accuracy: 0.2553 | Loss: 11.5997\n","\n","Domain: 62\n","x_dp_dom.shape: (47, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 62 | Accuracy: 0.2553 | Loss: 13.7892\n","\n","Domain: 63\n","x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 63 | Accuracy: 0.2381 | Loss: 9.6867\n","\n","Domain: 64\n","x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 64 | Accuracy: 0.3810 | Loss: 6.6849\n","\n","Domain: 65\n","x_dp_dom.shape: (50, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 65 | Accuracy: 0.2600 | Loss: 14.2844\n","\n","Domain: 66\n","x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 66 | Accuracy: 0.1667 | Loss: 16.1518\n","\n","Domain: 67\n","x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 67 | Accuracy: 0.5714 | Loss: 5.1610\n","\n","Domain: 68\n","x_dp_dom.shape: (43, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 68 | Accuracy: 0.2791 | Loss: 8.9731\n","\n","Domain: 69\n","x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 69 | Accuracy: 0.1667 | Loss: 13.3395\n","\n","Domain: 70\n","x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 70 | Accuracy: 0.1905 | Loss: 10.4174\n","\n","Domain: 71\n","x_dp_dom.shape: (44, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 71 | Accuracy: 0.2727 | Loss: 11.1508\n","\n","Domain: 72\n","x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 72 | Accuracy: 0.2857 | Loss: 8.4414\n","\n","Domain: 73\n","x_dp_dom.shape: (41, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 73 | Accuracy: 0.1707 | Loss: 11.7246\n","\n","Domain: 74\n","x_dp_dom.shape: (35, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 74 | Accuracy: 0.3143 | Loss: 6.1800\n","\n","Domain: 75\n","x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 75 | Accuracy: 0.5714 | Loss: 6.6824\n","\n","Source class: WAL\n","\n","x_df.shape: (7958, 3, 128) | np.unique(y_df): [1 2 3]\n","\n","Training on Df data...\n","\tEpoch 10/100 - Train loss: 0.0381 - Val accuracy: 0.9780 - Val loss: 0.0516 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.0103 - Val accuracy: 0.9824 - Val loss: 0.0412 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.0037 - Val accuracy: 0.9856 - Val loss: 0.0441 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.0019 - Val accuracy: 0.9868 - Val loss: 0.0464 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.0013 - Val accuracy: 0.9868 - Val loss: 0.0449 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.0005 - Val accuracy: 0.9862 - Val loss: 0.0475 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0004 - Val accuracy: 0.9874 - Val loss: 0.0448 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0002 - Val accuracy: 0.9893 - Val loss: 0.0498 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0003 - Val accuracy: 0.9874 - Val loss: 0.0533 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0002 - Val accuracy: 0.9868 - Val loss: 0.0514 - LR: 0.00e+00\n","\tBest epoch: 36 - Best val accuracy: 0.9881 - Best val loss: 0.0397\n","\n","Domain: 15\n","x_dp_dom.shape: (50, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 15 | Accuracy: 0.2400 | Loss: 11.2410\n","\n","Domain: 16\n","x_dp_dom.shape: (54, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 16 | Accuracy: 0.7593 | Loss: 4.2524\n","\n","Domain: 17\n","x_dp_dom.shape: (53, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 17 | Accuracy: 0.2642 | Loss: 8.7980\n","\n","Domain: 18\n","x_dp_dom.shape: (54, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 18 | Accuracy: 0.7037 | Loss: 4.4508\n","\n","Domain: 19\n","x_dp_dom.shape: (54, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 19 | Accuracy: 0.6852 | Loss: 4.2943\n","\n","Domain: 20\n","x_dp_dom.shape: (51, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 20 | Accuracy: 0.4902 | Loss: 4.4757\n","\n","Domain: 21\n","x_dp_dom.shape: (47, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 21 | Accuracy: 0.7234 | Loss: 2.7677\n","\n","Domain: 22\n","x_dp_dom.shape: (54, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 22 | Accuracy: 0.7407 | Loss: 4.1597\n","\n","Domain: 23\n","x_dp_dom.shape: (52, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 23 | Accuracy: 0.7692 | Loss: 4.0382\n","\n","Domain: 24\n","x_dp_dom.shape: (51, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 24 | Accuracy: 0.3922 | Loss: 8.6992\n","\n","Domain: 25\n","x_dp_dom.shape: (54, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 25 | Accuracy: 0.7593 | Loss: 4.7264\n","\n","Domain: 26\n","x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 26 | Accuracy: 0.5238 | Loss: 3.9552\n","\n","Domain: 27\n","x_dp_dom.shape: (54, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 27 | Accuracy: 0.6481 | Loss: 6.1797\n","\n","Domain: 28\n","x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 28 | Accuracy: 0.8333 | Loss: 2.8255\n","\n","Domain: 29\n","x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 29 | Accuracy: 0.7143 | Loss: 3.1326\n","\n","Domain: 30\n","x_dp_dom.shape: (50, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 30 | Accuracy: 0.6400 | Loss: 4.6334\n","\n","Domain: 31\n","x_dp_dom.shape: (43, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 31 | Accuracy: 0.7907 | Loss: 2.5378\n","\n","Domain: 32\n","x_dp_dom.shape: (52, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 32 | Accuracy: 0.6731 | Loss: 7.6631\n","\n","Domain: 33\n","x_dp_dom.shape: (44, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 33 | Accuracy: 0.8182 | Loss: 2.1366\n","\n","Domain: 34\n","x_dp_dom.shape: (49, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 34 | Accuracy: 0.5306 | Loss: 5.1142\n","\n","Domain: 35\n","x_dp_dom.shape: (48, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 35 | Accuracy: 0.7500 | Loss: 2.4580\n","\n","Domain: 36\n","x_dp_dom.shape: (43, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 36 | Accuracy: 0.7907 | Loss: 2.6309\n","\n","Domain: 37\n","x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 37 | Accuracy: 0.6190 | Loss: 4.7928\n","\n","Domain: 38\n","x_dp_dom.shape: (47, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 38 | Accuracy: 0.8085 | Loss: 2.7586\n","\n","Domain: 39\n","x_dp_dom.shape: (54, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 39 | Accuracy: 0.3704 | Loss: 14.7050\n","\n","Domain: 40\n","x_dp_dom.shape: (44, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 40 | Accuracy: 0.5455 | Loss: 5.2692\n","\n","Domain: 41\n","x_dp_dom.shape: (45, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 41 | Accuracy: 0.5778 | Loss: 5.9996\n","\n","Domain: 42\n","x_dp_dom.shape: (46, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 42 | Accuracy: 0.7174 | Loss: 4.1893\n","\n","Domain: 43\n","x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 43 | Accuracy: 0.5952 | Loss: 6.0158\n","\n","Domain: 44\n","x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 44 | Accuracy: 0.8333 | Loss: 2.9251\n","\n","Domain: 45\n","x_dp_dom.shape: (52, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 45 | Accuracy: 0.5769 | Loss: 3.5787\n","\n","Domain: 46\n","x_dp_dom.shape: (48, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 46 | Accuracy: 0.8333 | Loss: 2.3874\n","\n","Domain: 47\n","x_dp_dom.shape: (44, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 47 | Accuracy: 0.7500 | Loss: 2.9460\n","\n","Domain: 48\n","x_dp_dom.shape: (48, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 48 | Accuracy: 0.6458 | Loss: 5.0958\n","\n","Domain: 49\n","x_dp_dom.shape: (53, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 49 | Accuracy: 0.7358 | Loss: 4.9093\n","\n","Domain: 50\n","x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 50 | Accuracy: 0.6190 | Loss: 2.9184\n","\n","Domain: 51\n","x_dp_dom.shape: (46, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 51 | Accuracy: 0.5652 | Loss: 3.6683\n","\n","Domain: 52\n","x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 52 | Accuracy: 0.6429 | Loss: 3.1280\n","\n","Domain: 53\n","x_dp_dom.shape: (48, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 53 | Accuracy: 0.8333 | Loss: 2.6294\n","\n","Domain: 54\n","x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 54 | Accuracy: 0.1667 | Loss: 9.7155\n","\n","Domain: 55\n","x_dp_dom.shape: (49, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 55 | Accuracy: 0.5918 | Loss: 3.5501\n","\n","Domain: 56\n","x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 56 | Accuracy: 0.7619 | Loss: 2.4134\n","\n","Domain: 57\n","x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 57 | Accuracy: 0.6429 | Loss: 3.2421\n","\n","Domain: 58\n","x_dp_dom.shape: (38, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 58 | Accuracy: 0.1579 | Loss: 7.9104\n","\n","Domain: 59\n","x_dp_dom.shape: (43, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 59 | Accuracy: 0.7209 | Loss: 3.2890\n","\n","Domain: 60\n","x_dp_dom.shape: (47, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 60 | Accuracy: 0.4255 | Loss: 9.0672\n","\n","Domain: 61\n","x_dp_dom.shape: (47, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 61 | Accuracy: 0.8723 | Loss: 2.4804\n","\n","Domain: 62\n","x_dp_dom.shape: (47, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 62 | Accuracy: 0.7872 | Loss: 2.9242\n","\n","Domain: 63\n","x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 63 | Accuracy: 0.7143 | Loss: 3.2453\n","\n","Domain: 64\n","x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 64 | Accuracy: 0.8095 | Loss: 2.6016\n","\n","Domain: 65\n","x_dp_dom.shape: (50, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 65 | Accuracy: 0.2600 | Loss: 13.4139\n","\n","Domain: 66\n","x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 66 | Accuracy: 0.1667 | Loss: 16.2310\n","\n","Domain: 67\n","x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 67 | Accuracy: 0.4524 | Loss: 5.8817\n","\n","Domain: 68\n","x_dp_dom.shape: (43, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 68 | Accuracy: 0.7907 | Loss: 2.6758\n","\n","Domain: 69\n","x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 69 | Accuracy: 0.1190 | Loss: 12.5724\n","\n","Domain: 70\n","x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 70 | Accuracy: 0.8333 | Loss: 3.2937\n","\n","Domain: 71\n","x_dp_dom.shape: (44, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 71 | Accuracy: 0.8182 | Loss: 2.2505\n","\n","Domain: 72\n","x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 72 | Accuracy: 0.6667 | Loss: 3.2470\n","\n","Domain: 73\n","x_dp_dom.shape: (41, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 73 | Accuracy: 0.1463 | Loss: 13.7649\n","\n","Domain: 74\n","x_dp_dom.shape: (35, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 74 | Accuracy: 0.7714 | Loss: 1.7799\n","\n","Domain: 75\n","x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 75 | Accuracy: 0.5714 | Loss: 2.7528\n","\n","Source class: WAL\n","\n","x_df.shape: (7958, 3, 128) | np.unique(y_df): [1 2 3]\n","\n","Training on Df data...\n","\tEpoch 10/100 - Train loss: 0.0340 - Val accuracy: 0.9793 - Val loss: 0.0553 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.0085 - Val accuracy: 0.9818 - Val loss: 0.0540 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.0030 - Val accuracy: 0.9843 - Val loss: 0.0516 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.0017 - Val accuracy: 0.9849 - Val loss: 0.0554 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.0048 - Val accuracy: 0.9862 - Val loss: 0.0587 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.0006 - Val accuracy: 0.9849 - Val loss: 0.0646 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0004 - Val accuracy: 0.9849 - Val loss: 0.0620 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0003 - Val accuracy: 0.9868 - Val loss: 0.0601 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0002 - Val accuracy: 0.9843 - Val loss: 0.0681 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0001 - Val accuracy: 0.9856 - Val loss: 0.0656 - LR: 0.00e+00\n","\tBest epoch: 16 - Best val accuracy: 0.9837 - Best val loss: 0.0456\n","\n","Domain: 15\n","x_dp_dom.shape: (50, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 15 | Accuracy: 0.2200 | Loss: 6.0862\n","\n","Domain: 16\n","x_dp_dom.shape: (54, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 16 | Accuracy: 0.8148 | Loss: 1.4715\n","\n","Domain: 17\n","x_dp_dom.shape: (53, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 17 | Accuracy: 0.4340 | Loss: 4.0541\n","\n","Domain: 18\n","x_dp_dom.shape: (54, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 18 | Accuracy: 0.7778 | Loss: 1.3665\n","\n","Domain: 19\n","x_dp_dom.shape: (54, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 19 | Accuracy: 0.4815 | Loss: 1.6109\n","\n","Domain: 20\n","x_dp_dom.shape: (51, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 20 | Accuracy: 0.8039 | Loss: 1.5279\n","\n","Domain: 21\n","x_dp_dom.shape: (47, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 21 | Accuracy: 0.7872 | Loss: 0.8120\n","\n","Domain: 22\n","x_dp_dom.shape: (54, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 22 | Accuracy: 0.6111 | Loss: 1.8667\n","\n","Domain: 23\n","x_dp_dom.shape: (52, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 23 | Accuracy: 0.4423 | Loss: 3.8297\n","\n","Domain: 24\n","x_dp_dom.shape: (51, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 24 | Accuracy: 0.6471 | Loss: 5.9392\n","\n","Domain: 25\n","x_dp_dom.shape: (54, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 25 | Accuracy: 0.4444 | Loss: 2.8942\n","\n","Domain: 26\n","x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 26 | Accuracy: 0.4286 | Loss: 2.6633\n","\n","Domain: 27\n","x_dp_dom.shape: (54, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 27 | Accuracy: 0.6296 | Loss: 3.1600\n","\n","Domain: 28\n","x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 28 | Accuracy: 0.3810 | Loss: 2.9302\n","\n","Domain: 29\n","x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 29 | Accuracy: 0.4286 | Loss: 2.3054\n","\n","Domain: 30\n","x_dp_dom.shape: (50, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 30 | Accuracy: 0.5400 | Loss: 3.6250\n","\n","Domain: 31\n","x_dp_dom.shape: (43, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 31 | Accuracy: 0.4186 | Loss: 2.0906\n","\n","Domain: 32\n","x_dp_dom.shape: (52, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 32 | Accuracy: 0.4423 | Loss: 6.8566\n","\n","Domain: 33\n","x_dp_dom.shape: (44, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 33 | Accuracy: 0.8409 | Loss: 0.6963\n","\n","Domain: 34\n","x_dp_dom.shape: (49, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 34 | Accuracy: 0.5918 | Loss: 3.4109\n","\n","Domain: 35\n","x_dp_dom.shape: (48, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 35 | Accuracy: 0.2917 | Loss: 3.4494\n","\n","Domain: 36\n","x_dp_dom.shape: (43, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 36 | Accuracy: 0.2791 | Loss: 3.1190\n","\n","Domain: 37\n","x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 37 | Accuracy: 0.6667 | Loss: 2.8065\n","\n","Domain: 38\n","x_dp_dom.shape: (47, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 38 | Accuracy: 0.3191 | Loss: 3.7067\n","\n","Domain: 39\n","x_dp_dom.shape: (54, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 39 | Accuracy: 0.4630 | Loss: 6.1783\n","\n","Domain: 40\n","x_dp_dom.shape: (44, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 40 | Accuracy: 0.7500 | Loss: 4.0033\n","\n","Domain: 41\n","x_dp_dom.shape: (45, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 41 | Accuracy: 0.3333 | Loss: 4.4240\n","\n","Domain: 42\n","x_dp_dom.shape: (46, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 42 | Accuracy: 0.3913 | Loss: 4.8058\n","\n","Domain: 43\n","x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 43 | Accuracy: 0.3571 | Loss: 3.3001\n","\n","Domain: 44\n","x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 44 | Accuracy: 0.1905 | Loss: 3.8805\n","\n","Domain: 45\n","x_dp_dom.shape: (52, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 45 | Accuracy: 0.5769 | Loss: 2.4299\n","\n","Domain: 46\n","x_dp_dom.shape: (48, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 46 | Accuracy: 0.2708 | Loss: 4.8028\n","\n","Domain: 47\n","x_dp_dom.shape: (44, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 47 | Accuracy: 0.5227 | Loss: 1.4635\n","\n","Domain: 48\n","x_dp_dom.shape: (48, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 48 | Accuracy: 0.6250 | Loss: 2.6815\n","\n","Domain: 49\n","x_dp_dom.shape: (53, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 49 | Accuracy: 0.4717 | Loss: 5.0571\n","\n","Domain: 50\n","x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 50 | Accuracy: 0.7381 | Loss: 0.6836\n","\n","Domain: 51\n","x_dp_dom.shape: (46, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 51 | Accuracy: 0.4130 | Loss: 3.8732\n","\n","Domain: 52\n","x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 52 | Accuracy: 0.7619 | Loss: 1.3556\n","\n","Domain: 53\n","x_dp_dom.shape: (48, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 53 | Accuracy: 0.7500 | Loss: 1.3690\n","\n","Domain: 54\n","x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 54 | Accuracy: 0.5238 | Loss: 5.5630\n","\n","Domain: 55\n","x_dp_dom.shape: (49, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 55 | Accuracy: 0.6735 | Loss: 0.9087\n","\n","Domain: 56\n","x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 56 | Accuracy: 0.6190 | Loss: 1.4625\n","\n","Domain: 57\n","x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 57 | Accuracy: 0.4524 | Loss: 1.8997\n","\n","Domain: 58\n","x_dp_dom.shape: (38, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 58 | Accuracy: 0.6579 | Loss: 2.3382\n","\n","Domain: 59\n","x_dp_dom.shape: (43, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 59 | Accuracy: 0.8837 | Loss: 0.5535\n","\n","Domain: 60\n","x_dp_dom.shape: (47, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 60 | Accuracy: 0.4468 | Loss: 4.4204\n","\n","Domain: 61\n","x_dp_dom.shape: (47, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 61 | Accuracy: 0.3830 | Loss: 5.2445\n","\n","Domain: 62\n","x_dp_dom.shape: (47, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 62 | Accuracy: 0.4894 | Loss: 2.7423\n","\n","Domain: 63\n","x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 63 | Accuracy: 0.3333 | Loss: 2.6433\n","\n","Domain: 64\n","x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 64 | Accuracy: 0.9524 | Loss: 0.0921\n","\n","Domain: 65\n","x_dp_dom.shape: (50, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 65 | Accuracy: 0.2600 | Loss: 9.1835\n","\n","Domain: 66\n","x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 66 | Accuracy: 0.1667 | Loss: 8.8442\n","\n","Domain: 67\n","x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 67 | Accuracy: 0.8333 | Loss: 2.9406\n","\n","Domain: 68\n","x_dp_dom.shape: (43, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 68 | Accuracy: 0.8605 | Loss: 0.2909\n","\n","Domain: 69\n","x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 69 | Accuracy: 0.4524 | Loss: 2.1078\n","\n","Domain: 70\n","x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 70 | Accuracy: 0.7619 | Loss: 3.8737\n","\n","Domain: 71\n","x_dp_dom.shape: (44, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 71 | Accuracy: 0.3864 | Loss: 3.2179\n","\n","Domain: 72\n","x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 72 | Accuracy: 0.9048 | Loss: 0.1728\n","\n","Domain: 73\n","x_dp_dom.shape: (41, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 73 | Accuracy: 0.2195 | Loss: 3.0814\n","\n","Domain: 74\n","x_dp_dom.shape: (35, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 74 | Accuracy: 0.2571 | Loss: 3.5668\n","\n","Domain: 75\n","x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 75 | Accuracy: 0.3571 | Loss: 2.8666\n","\n","Mean accuracy: 0.5141\n","\n"]}],"source":["n_runs = 10\n","\n","def compute_TSTR_Df(dataset):\n","    accs = []\n","\n","    for i in range(n_runs):\n","\n","        for src_class in config[dataset]['class_names']:\n","            if src_class != 'WAL':\n","                continue\n","\n","            print(f\"Source class: {src_class}\\n\")\n","\n","            # Load Df data\n","            x_df, y_df, k_df = get_data(dataset, 'df', src_class)\n","            print(f'x_df.shape: {x_df.shape} | np.unique(y_df): {np.unique(y_df)}\\n')\n","\n","            # Train on Df data\n","            print('Training on Df data...')\n","            df_model = train_only(x_df, y_df, dataset, num_epochs=100)\n","\n","            for domain in range(config[dataset]['num_df_domains'], config[dataset]['num_df_domains'] + config[dataset]['num_dp_domains']):\n","                print(f\"Domain: {domain}\")\n","\n","                # Load Dp data\n","                x_dp_dom, y_dp_dom, k_dp_dom = get_data(dataset, 'dp', src_class, domain)\n","                print(f'x_dp_dom.shape: {x_dp_dom.shape} | np.unique(y_dp_dom): {np.unique(y_dp_dom)}\\n')\n","\n","                # Evaluate on Dp data\n","                acc, loss = evaluate_model(df_model, get_dataloader(x_dp_dom, y_dp_dom))\n","                save_scores(src_class, domain, acc, loss, 'Df', dataset)\n","                accs.append(acc)\n","                print(f'Source class: {src_class} | Domain: {domain} | Accuracy: {acc:.4f} | Loss: {loss:.4f}\\n')\n","\n","    print(f\"Mean accuracy: {np.mean(accs):.4f}\\n\")\n","\n","\n","\n","\n","compute_TSTR_Df('realworld_mobiact')"]},{"cell_type":"code","source":["n_runs = 10\n","\n","def compute_TSTR_Df_aug(dataset):\n","    accs = []\n","\n","    for i in range(n_runs):\n","\n","        for src_class in config[dataset]['class_names']:\n","            if src_class != 'WAL':\n","                continue\n","\n","            print(f\"Source class: {src_class}\\n\")\n","\n","            # Load Df data\n","            x_df, y_df, k_df = get_data(dataset, 'df', src_class)\n","            print(f'x_df.shape: {x_df.shape} | np.unique(y_df): {np.unique(y_df)}\\n')\n","\n","            # Train on Df data\n","            print('Training on Df data...')\n","            df_model = train_only(x_df, y_df, dataset, num_epochs=100, augment=True)\n","\n","            for domain in range(config[dataset]['num_df_domains'], config[dataset]['num_df_domains'] + config[dataset]['num_dp_domains']):\n","                print(f\"Domain: {domain}\")\n","\n","                # Load Dp data\n","                x_dp_dom, y_dp_dom, k_dp_dom = get_data(dataset, 'dp', src_class, domain)\n","                print(f'x_dp_dom.shape: {x_dp_dom.shape} | np.unique(y_dp_dom): {np.unique(y_dp_dom)}\\n')\n","\n","                # Evaluate on Dp data\n","                acc, loss = evaluate_model(df_model, get_dataloader(x_dp_dom, y_dp_dom))\n","                save_scores(src_class, domain, acc, loss, 'Df_aug', dataset)\n","                accs.append(acc)\n","                print(f'Source class: {src_class} | Domain: {domain} | Accuracy: {acc:.4f} | Loss: {loss:.4f}\\n')\n","\n","    print(f\"Mean accuracy: {np.mean(accs):.4f}\\n\")\n","\n","\n","\n","\n","compute_TSTR_Df_aug('realworld_mobiact')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6X3sBMvtdTCl","executionInfo":{"status":"ok","timestamp":1731669440158,"user_tz":-60,"elapsed":680917,"user":{"displayName":"Pietro ST","userId":"01777116294553213330"}},"outputId":"55da2f2e-0ae5-4e70-a2ff-d2051d760902"},"execution_count":13,"outputs":[{"output_type":"stream","name":"stdout","text":["Source class: WAL\n","\n","x_df.shape: (7958, 3, 128) | np.unique(y_df): [1 2 3]\n","\n","Training on Df data...\n","\tEpoch 10/100 - Train loss: 0.1558 - Val accuracy: 0.8335 - Val loss: 0.4321 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.1135 - Val accuracy: 0.7236 - Val loss: 1.6891 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.0890 - Val accuracy: 0.7399 - Val loss: 1.3941 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.0740 - Val accuracy: 0.7236 - Val loss: 2.6083 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.0622 - Val accuracy: 0.7205 - Val loss: 3.3469 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.0597 - Val accuracy: 0.7418 - Val loss: 1.8632 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0501 - Val accuracy: 0.8511 - Val loss: 0.7131 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0453 - Val accuracy: 0.7224 - Val loss: 3.8798 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0448 - Val accuracy: 0.7418 - Val loss: 1.8982 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0454 - Val accuracy: 0.7531 - Val loss: 1.6252 - LR: 0.00e+00\n","\tBest epoch: 8 - Best val accuracy: 0.8964 - Best val loss: 0.2650\n","\n","Domain: 15\n","x_dp_dom.shape: (50, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 15 | Accuracy: 0.5800 | Loss: 1.9435\n","\n","Domain: 16\n","x_dp_dom.shape: (54, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 16 | Accuracy: 0.7593 | Loss: 1.5931\n","\n","Domain: 17\n","x_dp_dom.shape: (53, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 17 | Accuracy: 0.7358 | Loss: 2.2098\n","\n","Domain: 18\n","x_dp_dom.shape: (54, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 18 | Accuracy: 0.7593 | Loss: 2.8378\n","\n","Domain: 19\n","x_dp_dom.shape: (54, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 19 | Accuracy: 0.7593 | Loss: 2.2474\n","\n","Domain: 20\n","x_dp_dom.shape: (51, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 20 | Accuracy: 0.8039 | Loss: 1.1746\n","\n","Domain: 21\n","x_dp_dom.shape: (47, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 21 | Accuracy: 0.8511 | Loss: 1.0662\n","\n","Domain: 22\n","x_dp_dom.shape: (54, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 22 | Accuracy: 0.7593 | Loss: 1.4298\n","\n","Domain: 23\n","x_dp_dom.shape: (52, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 23 | Accuracy: 0.7885 | Loss: 1.9739\n","\n","Domain: 24\n","x_dp_dom.shape: (51, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 24 | Accuracy: 0.7255 | Loss: 1.9861\n","\n","Domain: 25\n","x_dp_dom.shape: (54, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 25 | Accuracy: 0.7593 | Loss: 2.2760\n","\n","Domain: 26\n","x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 26 | Accuracy: 0.8333 | Loss: 0.4541\n","\n","Domain: 27\n","x_dp_dom.shape: (54, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 27 | Accuracy: 0.7593 | Loss: 2.6070\n","\n","Domain: 28\n","x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 28 | Accuracy: 0.8333 | Loss: 1.2828\n","\n","Domain: 29\n","x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 29 | Accuracy: 0.8333 | Loss: 1.4756\n","\n","Domain: 30\n","x_dp_dom.shape: (50, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 30 | Accuracy: 0.7800 | Loss: 1.3730\n","\n","Domain: 31\n","x_dp_dom.shape: (43, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 31 | Accuracy: 0.8372 | Loss: 1.1582\n","\n","Domain: 32\n","x_dp_dom.shape: (52, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 32 | Accuracy: 0.7885 | Loss: 1.3830\n","\n","Domain: 33\n","x_dp_dom.shape: (44, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 33 | Accuracy: 0.8636 | Loss: 0.7399\n","\n","Domain: 34\n","x_dp_dom.shape: (49, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 34 | Accuracy: 0.8367 | Loss: 0.6722\n","\n","Domain: 35\n","x_dp_dom.shape: (48, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 35 | Accuracy: 0.8542 | Loss: 1.0004\n","\n","Domain: 36\n","x_dp_dom.shape: (43, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 36 | Accuracy: 0.8372 | Loss: 1.2683\n","\n","Domain: 37\n","x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 37 | Accuracy: 0.8333 | Loss: 0.8356\n","\n","Domain: 38\n","x_dp_dom.shape: (47, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 38 | Accuracy: 0.8085 | Loss: 1.4819\n","\n","Domain: 39\n","x_dp_dom.shape: (54, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 39 | Accuracy: 0.5926 | Loss: 2.5822\n","\n","Domain: 40\n","x_dp_dom.shape: (44, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 40 | Accuracy: 0.8182 | Loss: 0.7916\n","\n","Domain: 41\n","x_dp_dom.shape: (45, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 41 | Accuracy: 0.7778 | Loss: 2.8780\n","\n","Domain: 42\n","x_dp_dom.shape: (46, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 42 | Accuracy: 0.8478 | Loss: 0.8502\n","\n","Domain: 43\n","x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 43 | Accuracy: 0.8333 | Loss: 0.7522\n","\n","Domain: 44\n","x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 44 | Accuracy: 0.8333 | Loss: 1.1573\n","\n","Domain: 45\n","x_dp_dom.shape: (52, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 45 | Accuracy: 0.7885 | Loss: 1.4218\n","\n","Domain: 46\n","x_dp_dom.shape: (48, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 46 | Accuracy: 0.8542 | Loss: 1.2953\n","\n","Domain: 47\n","x_dp_dom.shape: (44, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 47 | Accuracy: 0.8409 | Loss: 1.0332\n","\n","Domain: 48\n","x_dp_dom.shape: (48, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 48 | Accuracy: 0.8333 | Loss: 1.1542\n","\n","Domain: 49\n","x_dp_dom.shape: (53, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 49 | Accuracy: 0.7736 | Loss: 1.6364\n","\n","Domain: 50\n","x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 50 | Accuracy: 0.8333 | Loss: 0.7921\n","\n","Domain: 51\n","x_dp_dom.shape: (46, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 51 | Accuracy: 0.7609 | Loss: 0.8258\n","\n","Domain: 52\n","x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 52 | Accuracy: 0.8333 | Loss: 1.2437\n","\n","Domain: 53\n","x_dp_dom.shape: (48, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 53 | Accuracy: 0.8333 | Loss: 0.9239\n","\n","Domain: 54\n","x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 54 | Accuracy: 0.8333 | Loss: 0.7823\n","\n","Domain: 55\n","x_dp_dom.shape: (49, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 55 | Accuracy: 0.8367 | Loss: 1.2145\n","\n","Domain: 56\n","x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 56 | Accuracy: 0.8333 | Loss: 0.8974\n","\n","Domain: 57\n","x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 57 | Accuracy: 0.8095 | Loss: 0.7316\n","\n","Domain: 58\n","x_dp_dom.shape: (38, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 58 | Accuracy: 0.7368 | Loss: 1.6148\n","\n","Domain: 59\n","x_dp_dom.shape: (43, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 59 | Accuracy: 0.8372 | Loss: 0.8241\n","\n","Domain: 60\n","x_dp_dom.shape: (47, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 60 | Accuracy: 0.4255 | Loss: 2.9187\n","\n","Domain: 61\n","x_dp_dom.shape: (47, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 61 | Accuracy: 0.8298 | Loss: 0.6113\n","\n","Domain: 62\n","x_dp_dom.shape: (47, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 62 | Accuracy: 0.8511 | Loss: 1.1669\n","\n","Domain: 63\n","x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 63 | Accuracy: 0.8333 | Loss: 0.9123\n","\n","Domain: 64\n","x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 64 | Accuracy: 0.8333 | Loss: 0.8437\n","\n","Domain: 65\n","x_dp_dom.shape: (50, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 65 | Accuracy: 0.5800 | Loss: 1.5419\n","\n","Domain: 66\n","x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 66 | Accuracy: 0.2381 | Loss: 5.2704\n","\n","Domain: 67\n","x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 67 | Accuracy: 0.8571 | Loss: 0.9618\n","\n","Domain: 68\n","x_dp_dom.shape: (43, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 68 | Accuracy: 0.8372 | Loss: 1.0877\n","\n","Domain: 69\n","x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 69 | Accuracy: 0.7857 | Loss: 1.4729\n","\n","Domain: 70\n","x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 70 | Accuracy: 0.8333 | Loss: 1.0201\n","\n","Domain: 71\n","x_dp_dom.shape: (44, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 71 | Accuracy: 0.8409 | Loss: 0.9632\n","\n","Domain: 72\n","x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 72 | Accuracy: 0.8333 | Loss: 1.2077\n","\n","Domain: 73\n","x_dp_dom.shape: (41, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 73 | Accuracy: 0.7317 | Loss: 0.9671\n","\n","Domain: 74\n","x_dp_dom.shape: (35, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 74 | Accuracy: 0.8000 | Loss: 2.3870\n","\n","Domain: 75\n","x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 75 | Accuracy: 0.8333 | Loss: 1.0521\n","\n","Source class: WAL\n","\n","x_df.shape: (7958, 3, 128) | np.unique(y_df): [1 2 3]\n","\n","Training on Df data...\n","\tEpoch 10/100 - Train loss: 0.1532 - Val accuracy: 0.8863 - Val loss: 0.3060 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.1026 - Val accuracy: 0.8549 - Val loss: 0.4190 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.0790 - Val accuracy: 0.8367 - Val loss: 0.5966 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.0698 - Val accuracy: 0.7443 - Val loss: 1.5040 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.0614 - Val accuracy: 0.8235 - Val loss: 0.6506 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.0604 - Val accuracy: 0.7469 - Val loss: 1.4256 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0498 - Val accuracy: 0.7211 - Val loss: 2.5894 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0467 - Val accuracy: 0.7462 - Val loss: 1.6024 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0454 - Val accuracy: 0.8662 - Val loss: 0.4822 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0467 - Val accuracy: 0.7242 - Val loss: 2.7192 - LR: 0.00e+00\n","\tBest epoch: 27 - Best val accuracy: 0.9454 - Best val loss: 0.1419\n","\n","Domain: 15\n","x_dp_dom.shape: (50, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 15 | Accuracy: 0.7800 | Loss: 0.7602\n","\n","Domain: 16\n","x_dp_dom.shape: (54, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 16 | Accuracy: 0.6852 | Loss: 5.4429\n","\n","Domain: 17\n","x_dp_dom.shape: (53, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 17 | Accuracy: 0.2453 | Loss: 10.4016\n","\n","Domain: 18\n","x_dp_dom.shape: (54, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 18 | Accuracy: 0.3704 | Loss: 5.9914\n","\n","Domain: 19\n","x_dp_dom.shape: (54, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 19 | Accuracy: 0.4259 | Loss: 6.8216\n","\n","Domain: 20\n","x_dp_dom.shape: (51, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 20 | Accuracy: 0.3333 | Loss: 8.3857\n","\n","Domain: 21\n","x_dp_dom.shape: (47, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 21 | Accuracy: 0.3404 | Loss: 6.3194\n","\n","Domain: 22\n","x_dp_dom.shape: (54, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 22 | Accuracy: 0.7222 | Loss: 4.1452\n","\n","Domain: 23\n","x_dp_dom.shape: (52, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 23 | Accuracy: 0.7692 | Loss: 2.9629\n","\n","Domain: 24\n","x_dp_dom.shape: (51, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 24 | Accuracy: 0.6667 | Loss: 6.5508\n","\n","Domain: 25\n","x_dp_dom.shape: (54, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 25 | Accuracy: 0.7037 | Loss: 5.5208\n","\n","Domain: 26\n","x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 26 | Accuracy: 0.1905 | Loss: 7.8124\n","\n","Domain: 27\n","x_dp_dom.shape: (54, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 27 | Accuracy: 0.5556 | Loss: 4.7212\n","\n","Domain: 28\n","x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 28 | Accuracy: 0.5476 | Loss: 4.7243\n","\n","Domain: 29\n","x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 29 | Accuracy: 0.3571 | Loss: 4.6605\n","\n","Domain: 30\n","x_dp_dom.shape: (50, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 30 | Accuracy: 0.4200 | Loss: 7.0892\n","\n","Domain: 31\n","x_dp_dom.shape: (43, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 31 | Accuracy: 0.3023 | Loss: 5.5054\n","\n","Domain: 32\n","x_dp_dom.shape: (52, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 32 | Accuracy: 0.5385 | Loss: 6.1769\n","\n","Domain: 33\n","x_dp_dom.shape: (44, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 33 | Accuracy: 0.5682 | Loss: 4.8613\n","\n","Domain: 34\n","x_dp_dom.shape: (49, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 34 | Accuracy: 0.8163 | Loss: 3.7422\n","\n","Domain: 35\n","x_dp_dom.shape: (48, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 35 | Accuracy: 0.3333 | Loss: 5.9871\n","\n","Domain: 36\n","x_dp_dom.shape: (43, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 36 | Accuracy: 0.2326 | Loss: 7.7025\n","\n","Domain: 37\n","x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 37 | Accuracy: 0.3810 | Loss: 6.3391\n","\n","Domain: 38\n","x_dp_dom.shape: (47, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 38 | Accuracy: 0.8298 | Loss: 2.2525\n","\n","Domain: 39\n","x_dp_dom.shape: (54, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 39 | Accuracy: 0.4630 | Loss: 5.9319\n","\n","Domain: 40\n","x_dp_dom.shape: (44, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 40 | Accuracy: 0.4091 | Loss: 5.3437\n","\n","Domain: 41\n","x_dp_dom.shape: (45, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 41 | Accuracy: 0.2889 | Loss: 5.8169\n","\n","Domain: 42\n","x_dp_dom.shape: (46, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 42 | Accuracy: 0.2391 | Loss: 6.7241\n","\n","Domain: 43\n","x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 43 | Accuracy: 0.7619 | Loss: 1.7061\n","\n","Domain: 44\n","x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 44 | Accuracy: 0.7381 | Loss: 3.9651\n","\n","Domain: 45\n","x_dp_dom.shape: (52, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 45 | Accuracy: 0.2500 | Loss: 9.8720\n","\n","Domain: 46\n","x_dp_dom.shape: (48, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 46 | Accuracy: 0.8125 | Loss: 3.0733\n","\n","Domain: 47\n","x_dp_dom.shape: (44, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 47 | Accuracy: 0.7273 | Loss: 3.6405\n","\n","Domain: 48\n","x_dp_dom.shape: (48, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 48 | Accuracy: 0.8333 | Loss: 2.7896\n","\n","Domain: 49\n","x_dp_dom.shape: (53, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 49 | Accuracy: 0.2453 | Loss: 9.6333\n","\n","Domain: 50\n","x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 50 | Accuracy: 0.7619 | Loss: 2.9996\n","\n","Domain: 51\n","x_dp_dom.shape: (46, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 51 | Accuracy: 0.8261 | Loss: 3.3064\n","\n","Domain: 52\n","x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 52 | Accuracy: 0.4524 | Loss: 5.3031\n","\n","Domain: 53\n","x_dp_dom.shape: (48, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 53 | Accuracy: 0.7708 | Loss: 4.0570\n","\n","Domain: 54\n","x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 54 | Accuracy: 0.1667 | Loss: 8.4972\n","\n","Domain: 55\n","x_dp_dom.shape: (49, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 55 | Accuracy: 0.2653 | Loss: 7.9272\n","\n","Domain: 56\n","x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 56 | Accuracy: 0.7857 | Loss: 3.5957\n","\n","Domain: 57\n","x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 57 | Accuracy: 0.1667 | Loss: 7.4890\n","\n","Domain: 58\n","x_dp_dom.shape: (38, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 58 | Accuracy: 0.8421 | Loss: 1.7123\n","\n","Domain: 59\n","x_dp_dom.shape: (43, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 59 | Accuracy: 0.8140 | Loss: 3.6490\n","\n","Domain: 60\n","x_dp_dom.shape: (47, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 60 | Accuracy: 0.6596 | Loss: 2.8844\n","\n","Domain: 61\n","x_dp_dom.shape: (47, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 61 | Accuracy: 0.2553 | Loss: 9.9056\n","\n","Domain: 62\n","x_dp_dom.shape: (47, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 62 | Accuracy: 0.2553 | Loss: 7.7022\n","\n","Domain: 63\n","x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 63 | Accuracy: 0.5952 | Loss: 4.1381\n","\n","Domain: 64\n","x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 64 | Accuracy: 0.6667 | Loss: 3.9851\n","\n","Domain: 65\n","x_dp_dom.shape: (50, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 65 | Accuracy: 0.8200 | Loss: 3.6845\n","\n","Domain: 66\n","x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 66 | Accuracy: 0.7619 | Loss: 0.5340\n","\n","Domain: 67\n","x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 67 | Accuracy: 0.6190 | Loss: 3.2545\n","\n","Domain: 68\n","x_dp_dom.shape: (43, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 68 | Accuracy: 0.3023 | Loss: 6.0301\n","\n","Domain: 69\n","x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 69 | Accuracy: 0.8333 | Loss: 3.6525\n","\n","Domain: 70\n","x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 70 | Accuracy: 0.8095 | Loss: 3.2619\n","\n","Domain: 71\n","x_dp_dom.shape: (44, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 71 | Accuracy: 0.7727 | Loss: 2.9366\n","\n","Domain: 72\n","x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 72 | Accuracy: 0.8333 | Loss: 3.8631\n","\n","Domain: 73\n","x_dp_dom.shape: (41, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 73 | Accuracy: 0.8537 | Loss: 0.7478\n","\n","Domain: 74\n","x_dp_dom.shape: (35, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 74 | Accuracy: 0.7714 | Loss: 1.0298\n","\n","Domain: 75\n","x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 75 | Accuracy: 0.3333 | Loss: 6.2075\n","\n","Source class: WAL\n","\n","x_df.shape: (7958, 3, 128) | np.unique(y_df): [1 2 3]\n","\n","Training on Df data...\n","\tEpoch 10/100 - Train loss: 0.1394 - Val accuracy: 0.7575 - Val loss: 0.7867 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.1093 - Val accuracy: 0.7889 - Val loss: 0.8305 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.0833 - Val accuracy: 0.7330 - Val loss: 1.6799 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.0680 - Val accuracy: 0.7356 - Val loss: 1.6191 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.0613 - Val accuracy: 0.8266 - Val loss: 0.6585 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.0613 - Val accuracy: 0.7418 - Val loss: 1.5785 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0504 - Val accuracy: 0.7883 - Val loss: 1.1724 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0521 - Val accuracy: 0.9196 - Val loss: 0.2439 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0470 - Val accuracy: 0.7305 - Val loss: 2.2016 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0487 - Val accuracy: 0.7349 - Val loss: 1.8798 - LR: 0.00e+00\n","\tBest epoch: 93 - Best val accuracy: 0.9422 - Best val loss: 0.1516\n","\n","Domain: 15\n","x_dp_dom.shape: (50, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 15 | Accuracy: 0.7800 | Loss: 0.9164\n","\n","Domain: 16\n","x_dp_dom.shape: (54, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 16 | Accuracy: 0.7037 | Loss: 3.0895\n","\n","Domain: 17\n","x_dp_dom.shape: (53, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 17 | Accuracy: 0.5660 | Loss: 4.2924\n","\n","Domain: 18\n","x_dp_dom.shape: (54, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 18 | Accuracy: 0.2778 | Loss: 5.1259\n","\n","Domain: 19\n","x_dp_dom.shape: (54, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 19 | Accuracy: 0.6667 | Loss: 3.3224\n","\n","Domain: 20\n","x_dp_dom.shape: (51, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 20 | Accuracy: 0.6863 | Loss: 2.7607\n","\n","Domain: 21\n","x_dp_dom.shape: (47, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 21 | Accuracy: 0.4681 | Loss: 2.9995\n","\n","Domain: 22\n","x_dp_dom.shape: (54, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 22 | Accuracy: 0.5741 | Loss: 2.6844\n","\n","Domain: 23\n","x_dp_dom.shape: (52, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 23 | Accuracy: 0.7500 | Loss: 2.3935\n","\n","Domain: 24\n","x_dp_dom.shape: (51, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 24 | Accuracy: 0.6863 | Loss: 3.5596\n","\n","Domain: 25\n","x_dp_dom.shape: (54, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 25 | Accuracy: 0.6852 | Loss: 3.5794\n","\n","Domain: 26\n","x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 26 | Accuracy: 0.5952 | Loss: 1.4622\n","\n","Domain: 27\n","x_dp_dom.shape: (54, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 27 | Accuracy: 0.7222 | Loss: 3.5197\n","\n","Domain: 28\n","x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 28 | Accuracy: 0.8095 | Loss: 2.0672\n","\n","Domain: 29\n","x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 29 | Accuracy: 0.5952 | Loss: 2.0678\n","\n","Domain: 30\n","x_dp_dom.shape: (50, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 30 | Accuracy: 0.6800 | Loss: 2.5150\n","\n","Domain: 31\n","x_dp_dom.shape: (43, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 31 | Accuracy: 0.7442 | Loss: 1.6681\n","\n","Domain: 32\n","x_dp_dom.shape: (52, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 32 | Accuracy: 0.5385 | Loss: 3.1176\n","\n","Domain: 33\n","x_dp_dom.shape: (44, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 33 | Accuracy: 0.7727 | Loss: 1.8662\n","\n","Domain: 34\n","x_dp_dom.shape: (49, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 34 | Accuracy: 0.7143 | Loss: 1.5199\n","\n","Domain: 35\n","x_dp_dom.shape: (48, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 35 | Accuracy: 0.3542 | Loss: 3.1930\n","\n","Domain: 36\n","x_dp_dom.shape: (43, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 36 | Accuracy: 0.4884 | Loss: 2.6019\n","\n","Domain: 37\n","x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 37 | Accuracy: 0.6905 | Loss: 2.1603\n","\n","Domain: 38\n","x_dp_dom.shape: (47, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 38 | Accuracy: 0.8511 | Loss: 1.2896\n","\n","Domain: 39\n","x_dp_dom.shape: (54, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 39 | Accuracy: 0.7593 | Loss: 2.9132\n","\n","Domain: 40\n","x_dp_dom.shape: (44, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 40 | Accuracy: 0.7727 | Loss: 1.7262\n","\n","Domain: 41\n","x_dp_dom.shape: (45, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 41 | Accuracy: 0.3778 | Loss: 2.6441\n","\n","Domain: 42\n","x_dp_dom.shape: (46, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 42 | Accuracy: 0.2609 | Loss: 4.0735\n","\n","Domain: 43\n","x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 43 | Accuracy: 0.8095 | Loss: 1.0989\n","\n","Domain: 44\n","x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 44 | Accuracy: 0.5476 | Loss: 2.7238\n","\n","Domain: 45\n","x_dp_dom.shape: (52, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 45 | Accuracy: 0.6538 | Loss: 2.6655\n","\n","Domain: 46\n","x_dp_dom.shape: (48, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 46 | Accuracy: 0.6042 | Loss: 2.6143\n","\n","Domain: 47\n","x_dp_dom.shape: (44, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 47 | Accuracy: 0.7727 | Loss: 1.8086\n","\n","Domain: 48\n","x_dp_dom.shape: (48, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 48 | Accuracy: 0.6458 | Loss: 1.8888\n","\n","Domain: 49\n","x_dp_dom.shape: (53, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 49 | Accuracy: 0.2642 | Loss: 4.5831\n","\n","Domain: 50\n","x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 50 | Accuracy: 0.8095 | Loss: 0.4460\n","\n","Domain: 51\n","x_dp_dom.shape: (46, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 51 | Accuracy: 0.7826 | Loss: 1.5750\n","\n","Domain: 52\n","x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 52 | Accuracy: 0.8095 | Loss: 1.9892\n","\n","Domain: 53\n","x_dp_dom.shape: (48, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 53 | Accuracy: 0.7917 | Loss: 1.7454\n","\n","Domain: 54\n","x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 54 | Accuracy: 0.4762 | Loss: 2.5508\n","\n","Domain: 55\n","x_dp_dom.shape: (49, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 55 | Accuracy: 0.7551 | Loss: 2.2100\n","\n","Domain: 56\n","x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 56 | Accuracy: 0.5714 | Loss: 1.3846\n","\n","Domain: 57\n","x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 57 | Accuracy: 0.8571 | Loss: 0.4107\n","\n","Domain: 58\n","x_dp_dom.shape: (38, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 58 | Accuracy: 0.8158 | Loss: 1.3372\n","\n","Domain: 59\n","x_dp_dom.shape: (43, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 59 | Accuracy: 0.2326 | Loss: 3.5383\n","\n","Domain: 60\n","x_dp_dom.shape: (47, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 60 | Accuracy: 0.8085 | Loss: 2.1885\n","\n","Domain: 61\n","x_dp_dom.shape: (47, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 61 | Accuracy: 0.4043 | Loss: 4.4588\n","\n","Domain: 62\n","x_dp_dom.shape: (47, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 62 | Accuracy: 0.3830 | Loss: 2.7314\n","\n","Domain: 63\n","x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 63 | Accuracy: 0.8095 | Loss: 0.9818\n","\n","Domain: 64\n","x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 64 | Accuracy: 0.5476 | Loss: 2.3980\n","\n","Domain: 65\n","x_dp_dom.shape: (50, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 65 | Accuracy: 0.8200 | Loss: 1.9953\n","\n","Domain: 66\n","x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 66 | Accuracy: 0.8333 | Loss: 0.7327\n","\n","Domain: 67\n","x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 67 | Accuracy: 0.8333 | Loss: 1.2029\n","\n","Domain: 68\n","x_dp_dom.shape: (43, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 68 | Accuracy: 0.2791 | Loss: 3.4885\n","\n","Domain: 69\n","x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 69 | Accuracy: 0.8333 | Loss: 1.7677\n","\n","Domain: 70\n","x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 70 | Accuracy: 0.8095 | Loss: 1.8924\n","\n","Domain: 71\n","x_dp_dom.shape: (44, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 71 | Accuracy: 0.7955 | Loss: 0.9882\n","\n","Domain: 72\n","x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 72 | Accuracy: 0.5476 | Loss: 2.6784\n","\n","Domain: 73\n","x_dp_dom.shape: (41, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 73 | Accuracy: 0.7805 | Loss: 1.2859\n","\n","Domain: 74\n","x_dp_dom.shape: (35, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 74 | Accuracy: 0.8000 | Loss: 1.2362\n","\n","Domain: 75\n","x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 75 | Accuracy: 0.7381 | Loss: 2.2053\n","\n","Source class: WAL\n","\n","x_df.shape: (7958, 3, 128) | np.unique(y_df): [1 2 3]\n","\n","Training on Df data...\n","\tEpoch 10/100 - Train loss: 0.1516 - Val accuracy: 0.8725 - Val loss: 0.3518 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.0997 - Val accuracy: 0.8706 - Val loss: 0.4387 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.0856 - Val accuracy: 0.8116 - Val loss: 0.7383 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.0697 - Val accuracy: 0.7984 - Val loss: 1.0813 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.0679 - Val accuracy: 0.7707 - Val loss: 1.2815 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.0593 - Val accuracy: 0.7531 - Val loss: 1.5708 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0568 - Val accuracy: 0.8065 - Val loss: 1.0425 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0508 - Val accuracy: 0.7952 - Val loss: 1.1842 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0446 - Val accuracy: 0.8053 - Val loss: 1.1050 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0478 - Val accuracy: 0.7657 - Val loss: 1.4884 - LR: 0.00e+00\n","\tBest epoch: 8 - Best val accuracy: 0.9070 - Best val loss: 0.2372\n","\n","Domain: 15\n","x_dp_dom.shape: (50, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 15 | Accuracy: 0.7000 | Loss: 2.2298\n","\n","Domain: 16\n","x_dp_dom.shape: (54, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 16 | Accuracy: 0.7593 | Loss: 3.4794\n","\n","Domain: 17\n","x_dp_dom.shape: (53, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 17 | Accuracy: 0.6226 | Loss: 4.1187\n","\n","Domain: 18\n","x_dp_dom.shape: (54, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 18 | Accuracy: 0.6667 | Loss: 3.7351\n","\n","Domain: 19\n","x_dp_dom.shape: (54, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 19 | Accuracy: 0.7407 | Loss: 3.9205\n","\n","Domain: 20\n","x_dp_dom.shape: (51, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 20 | Accuracy: 0.8039 | Loss: 2.6102\n","\n","Domain: 21\n","x_dp_dom.shape: (47, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 21 | Accuracy: 0.8511 | Loss: 1.8604\n","\n","Domain: 22\n","x_dp_dom.shape: (54, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 22 | Accuracy: 0.7593 | Loss: 2.9044\n","\n","Domain: 23\n","x_dp_dom.shape: (52, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 23 | Accuracy: 0.7500 | Loss: 3.1503\n","\n","Domain: 24\n","x_dp_dom.shape: (51, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 24 | Accuracy: 0.7255 | Loss: 4.5652\n","\n","Domain: 25\n","x_dp_dom.shape: (54, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 25 | Accuracy: 0.7222 | Loss: 3.7391\n","\n","Domain: 26\n","x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 26 | Accuracy: 0.8095 | Loss: 1.0070\n","\n","Domain: 27\n","x_dp_dom.shape: (54, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 27 | Accuracy: 0.7407 | Loss: 4.1826\n","\n","Domain: 28\n","x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 28 | Accuracy: 0.8095 | Loss: 2.5542\n","\n","Domain: 29\n","x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 29 | Accuracy: 0.7381 | Loss: 2.4072\n","\n","Domain: 30\n","x_dp_dom.shape: (50, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 30 | Accuracy: 0.6400 | Loss: 3.3690\n","\n","Domain: 31\n","x_dp_dom.shape: (43, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 31 | Accuracy: 0.8372 | Loss: 1.4839\n","\n","Domain: 32\n","x_dp_dom.shape: (52, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 32 | Accuracy: 0.7500 | Loss: 3.2785\n","\n","Domain: 33\n","x_dp_dom.shape: (44, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 33 | Accuracy: 0.8409 | Loss: 1.7946\n","\n","Domain: 34\n","x_dp_dom.shape: (49, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 34 | Accuracy: 0.7347 | Loss: 1.4020\n","\n","Domain: 35\n","x_dp_dom.shape: (48, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 35 | Accuracy: 0.8333 | Loss: 1.9486\n","\n","Domain: 36\n","x_dp_dom.shape: (43, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 36 | Accuracy: 0.8140 | Loss: 2.3665\n","\n","Domain: 37\n","x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 37 | Accuracy: 0.8333 | Loss: 1.7462\n","\n","Domain: 38\n","x_dp_dom.shape: (47, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 38 | Accuracy: 0.8085 | Loss: 1.9532\n","\n","Domain: 39\n","x_dp_dom.shape: (54, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 39 | Accuracy: 0.5926 | Loss: 4.5886\n","\n","Domain: 40\n","x_dp_dom.shape: (44, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 40 | Accuracy: 0.7955 | Loss: 1.8404\n","\n","Domain: 41\n","x_dp_dom.shape: (45, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 41 | Accuracy: 0.4222 | Loss: 5.3869\n","\n","Domain: 42\n","x_dp_dom.shape: (46, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 42 | Accuracy: 0.3913 | Loss: 5.1897\n","\n","Domain: 43\n","x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 43 | Accuracy: 0.7857 | Loss: 1.9701\n","\n","Domain: 44\n","x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 44 | Accuracy: 0.8095 | Loss: 2.3448\n","\n","Domain: 45\n","x_dp_dom.shape: (52, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 45 | Accuracy: 0.7885 | Loss: 2.7598\n","\n","Domain: 46\n","x_dp_dom.shape: (48, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 46 | Accuracy: 0.8125 | Loss: 1.9680\n","\n","Domain: 47\n","x_dp_dom.shape: (44, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 47 | Accuracy: 0.8409 | Loss: 1.6110\n","\n","Domain: 48\n","x_dp_dom.shape: (48, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 48 | Accuracy: 0.8333 | Loss: 1.6023\n","\n","Domain: 49\n","x_dp_dom.shape: (53, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 49 | Accuracy: 0.7736 | Loss: 3.0007\n","\n","Domain: 50\n","x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 50 | Accuracy: 0.8333 | Loss: 0.6851\n","\n","Domain: 51\n","x_dp_dom.shape: (46, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 51 | Accuracy: 0.8261 | Loss: 1.8079\n","\n","Domain: 52\n","x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 52 | Accuracy: 0.8095 | Loss: 2.2703\n","\n","Domain: 53\n","x_dp_dom.shape: (48, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 53 | Accuracy: 0.8333 | Loss: 2.0048\n","\n","Domain: 54\n","x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 54 | Accuracy: 0.8333 | Loss: 2.2685\n","\n","Domain: 55\n","x_dp_dom.shape: (49, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 55 | Accuracy: 0.8367 | Loss: 2.2734\n","\n","Domain: 56\n","x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 56 | Accuracy: 0.8333 | Loss: 1.1281\n","\n","Domain: 57\n","x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 57 | Accuracy: 0.8333 | Loss: 0.6488\n","\n","Domain: 58\n","x_dp_dom.shape: (38, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 58 | Accuracy: 0.8684 | Loss: 1.0322\n","\n","Domain: 59\n","x_dp_dom.shape: (43, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 59 | Accuracy: 0.8372 | Loss: 1.9985\n","\n","Domain: 60\n","x_dp_dom.shape: (47, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 60 | Accuracy: 0.3404 | Loss: 5.3744\n","\n","Domain: 61\n","x_dp_dom.shape: (47, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 61 | Accuracy: 0.5957 | Loss: 2.3287\n","\n","Domain: 62\n","x_dp_dom.shape: (47, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 62 | Accuracy: 0.8511 | Loss: 2.0532\n","\n","Domain: 63\n","x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 63 | Accuracy: 0.8095 | Loss: 1.2366\n","\n","Domain: 64\n","x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 64 | Accuracy: 0.8571 | Loss: 1.3103\n","\n","Domain: 65\n","x_dp_dom.shape: (50, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 65 | Accuracy: 0.8200 | Loss: 2.2236\n","\n","Domain: 66\n","x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 66 | Accuracy: 0.5238 | Loss: 3.2481\n","\n","Domain: 67\n","x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 67 | Accuracy: 0.8333 | Loss: 1.6280\n","\n","Domain: 68\n","x_dp_dom.shape: (43, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 68 | Accuracy: 0.8372 | Loss: 2.1434\n","\n","Domain: 69\n","x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 69 | Accuracy: 0.4286 | Loss: 3.1118\n","\n","Domain: 70\n","x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 70 | Accuracy: 0.8095 | Loss: 2.1551\n","\n","Domain: 71\n","x_dp_dom.shape: (44, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 71 | Accuracy: 0.8636 | Loss: 1.3051\n","\n","Domain: 72\n","x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 72 | Accuracy: 0.8333 | Loss: 2.3086\n","\n","Domain: 73\n","x_dp_dom.shape: (41, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 73 | Accuracy: 0.2439 | Loss: 3.0180\n","\n","Domain: 74\n","x_dp_dom.shape: (35, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 74 | Accuracy: 0.8857 | Loss: 0.8011\n","\n","Domain: 75\n","x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 75 | Accuracy: 0.8333 | Loss: 2.3225\n","\n","Source class: WAL\n","\n","x_df.shape: (7958, 3, 128) | np.unique(y_df): [1 2 3]\n","\n","Training on Df data...\n","\tEpoch 10/100 - Train loss: 0.1629 - Val accuracy: 0.8863 - Val loss: 0.2916 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.1053 - Val accuracy: 0.8329 - Val loss: 0.6388 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.0880 - Val accuracy: 0.8078 - Val loss: 0.8800 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.0681 - Val accuracy: 0.8342 - Val loss: 0.7086 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.0643 - Val accuracy: 0.8430 - Val loss: 0.7043 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.0557 - Val accuracy: 0.8662 - Val loss: 0.5468 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0514 - Val accuracy: 0.7764 - Val loss: 1.2231 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0470 - Val accuracy: 0.7261 - Val loss: 2.1598 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0454 - Val accuracy: 0.7670 - Val loss: 1.4033 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0433 - Val accuracy: 0.7412 - Val loss: 1.7672 - LR: 0.00e+00\n","\tBest epoch: 9 - Best val accuracy: 0.8995 - Best val loss: 0.2711\n","\n","Domain: 15\n","x_dp_dom.shape: (50, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 15 | Accuracy: 0.8000 | Loss: 2.2427\n","\n","Domain: 16\n","x_dp_dom.shape: (54, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 16 | Accuracy: 0.7037 | Loss: 3.6076\n","\n","Domain: 17\n","x_dp_dom.shape: (53, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 17 | Accuracy: 0.5660 | Loss: 4.4874\n","\n","Domain: 18\n","x_dp_dom.shape: (54, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 18 | Accuracy: 0.5000 | Loss: 3.8211\n","\n","Domain: 19\n","x_dp_dom.shape: (54, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 19 | Accuracy: 0.7222 | Loss: 3.4925\n","\n","Domain: 20\n","x_dp_dom.shape: (51, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 20 | Accuracy: 0.7647 | Loss: 2.9429\n","\n","Domain: 21\n","x_dp_dom.shape: (47, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 21 | Accuracy: 0.7234 | Loss: 2.1988\n","\n","Domain: 22\n","x_dp_dom.shape: (54, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 22 | Accuracy: 0.7037 | Loss: 3.0850\n","\n","Domain: 23\n","x_dp_dom.shape: (52, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 23 | Accuracy: 0.7115 | Loss: 3.0142\n","\n","Domain: 24\n","x_dp_dom.shape: (51, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 24 | Accuracy: 0.7059 | Loss: 3.8463\n","\n","Domain: 25\n","x_dp_dom.shape: (54, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 25 | Accuracy: 0.7037 | Loss: 3.7060\n","\n","Domain: 26\n","x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 26 | Accuracy: 0.5952 | Loss: 2.9631\n","\n","Domain: 27\n","x_dp_dom.shape: (54, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 27 | Accuracy: 0.6111 | Loss: 3.7897\n","\n","Domain: 28\n","x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 28 | Accuracy: 0.8095 | Loss: 2.4284\n","\n","Domain: 29\n","x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 29 | Accuracy: 0.7619 | Loss: 1.7385\n","\n","Domain: 30\n","x_dp_dom.shape: (50, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 30 | Accuracy: 0.4400 | Loss: 4.4684\n","\n","Domain: 31\n","x_dp_dom.shape: (43, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 31 | Accuracy: 0.7907 | Loss: 2.0972\n","\n","Domain: 32\n","x_dp_dom.shape: (52, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 32 | Accuracy: 0.3654 | Loss: 4.2620\n","\n","Domain: 33\n","x_dp_dom.shape: (44, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 33 | Accuracy: 0.7955 | Loss: 2.4441\n","\n","Domain: 34\n","x_dp_dom.shape: (49, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 34 | Accuracy: 0.7755 | Loss: 2.1164\n","\n","Domain: 35\n","x_dp_dom.shape: (48, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 35 | Accuracy: 0.7917 | Loss: 2.4543\n","\n","Domain: 36\n","x_dp_dom.shape: (43, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 36 | Accuracy: 0.6977 | Loss: 2.6793\n","\n","Domain: 37\n","x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 37 | Accuracy: 0.7857 | Loss: 2.1016\n","\n","Domain: 38\n","x_dp_dom.shape: (47, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 38 | Accuracy: 0.8298 | Loss: 1.5370\n","\n","Domain: 39\n","x_dp_dom.shape: (54, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 39 | Accuracy: 0.6667 | Loss: 3.3911\n","\n","Domain: 40\n","x_dp_dom.shape: (44, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 40 | Accuracy: 0.8182 | Loss: 1.6257\n","\n","Domain: 41\n","x_dp_dom.shape: (45, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 41 | Accuracy: 0.4444 | Loss: 4.8504\n","\n","Domain: 42\n","x_dp_dom.shape: (46, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 42 | Accuracy: 0.2391 | Loss: 8.6612\n","\n","Domain: 43\n","x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 43 | Accuracy: 0.8095 | Loss: 1.9515\n","\n","Domain: 44\n","x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 44 | Accuracy: 0.8095 | Loss: 2.1718\n","\n","Domain: 45\n","x_dp_dom.shape: (52, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 45 | Accuracy: 0.7692 | Loss: 3.0623\n","\n","Domain: 46\n","x_dp_dom.shape: (48, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 46 | Accuracy: 0.8125 | Loss: 2.0198\n","\n","Domain: 47\n","x_dp_dom.shape: (44, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 47 | Accuracy: 0.7955 | Loss: 2.2198\n","\n","Domain: 48\n","x_dp_dom.shape: (48, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 48 | Accuracy: 0.8333 | Loss: 1.7447\n","\n","Domain: 49\n","x_dp_dom.shape: (53, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 49 | Accuracy: 0.7736 | Loss: 3.3165\n","\n","Domain: 50\n","x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 50 | Accuracy: 0.7857 | Loss: 1.3670\n","\n","Domain: 51\n","x_dp_dom.shape: (46, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 51 | Accuracy: 0.8043 | Loss: 2.2448\n","\n","Domain: 52\n","x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 52 | Accuracy: 0.8095 | Loss: 2.4719\n","\n","Domain: 53\n","x_dp_dom.shape: (48, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 53 | Accuracy: 0.8125 | Loss: 2.4238\n","\n","Domain: 54\n","x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 54 | Accuracy: 0.8333 | Loss: 1.6857\n","\n","Domain: 55\n","x_dp_dom.shape: (49, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 55 | Accuracy: 0.8367 | Loss: 2.3648\n","\n","Domain: 56\n","x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 56 | Accuracy: 0.8333 | Loss: 2.0158\n","\n","Domain: 57\n","x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 57 | Accuracy: 0.8095 | Loss: 1.0480\n","\n","Domain: 58\n","x_dp_dom.shape: (38, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 58 | Accuracy: 0.8684 | Loss: 1.2842\n","\n","Domain: 59\n","x_dp_dom.shape: (43, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 59 | Accuracy: 0.8372 | Loss: 2.3981\n","\n","Domain: 60\n","x_dp_dom.shape: (47, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 60 | Accuracy: 0.4255 | Loss: 3.9256\n","\n","Domain: 61\n","x_dp_dom.shape: (47, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 61 | Accuracy: 0.2979 | Loss: 5.0847\n","\n","Domain: 62\n","x_dp_dom.shape: (47, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 62 | Accuracy: 0.8298 | Loss: 2.2070\n","\n","Domain: 63\n","x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 63 | Accuracy: 0.7619 | Loss: 1.9848\n","\n","Domain: 64\n","x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 64 | Accuracy: 0.7619 | Loss: 2.6311\n","\n","Domain: 65\n","x_dp_dom.shape: (50, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 65 | Accuracy: 0.7800 | Loss: 2.3167\n","\n","Domain: 66\n","x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 66 | Accuracy: 0.8333 | Loss: 2.6265\n","\n","Domain: 67\n","x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 67 | Accuracy: 0.8333 | Loss: 1.5207\n","\n","Domain: 68\n","x_dp_dom.shape: (43, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 68 | Accuracy: 0.7907 | Loss: 2.2638\n","\n","Domain: 69\n","x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 69 | Accuracy: 0.8333 | Loss: 2.3393\n","\n","Domain: 70\n","x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 70 | Accuracy: 0.7857 | Loss: 2.1725\n","\n","Domain: 71\n","x_dp_dom.shape: (44, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 71 | Accuracy: 0.8409 | Loss: 1.5158\n","\n","Domain: 72\n","x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 72 | Accuracy: 0.8333 | Loss: 2.2860\n","\n","Domain: 73\n","x_dp_dom.shape: (41, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 73 | Accuracy: 0.8537 | Loss: 1.1223\n","\n","Domain: 74\n","x_dp_dom.shape: (35, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 74 | Accuracy: 0.8286 | Loss: 0.6982\n","\n","Domain: 75\n","x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 75 | Accuracy: 0.7857 | Loss: 2.6421\n","\n","Source class: WAL\n","\n","x_df.shape: (7958, 3, 128) | np.unique(y_df): [1 2 3]\n","\n","Training on Df data...\n","\tEpoch 10/100 - Train loss: 0.1581 - Val accuracy: 0.7249 - Val loss: 1.2222 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.1127 - Val accuracy: 0.7399 - Val loss: 1.1186 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.0917 - Val accuracy: 0.8235 - Val loss: 0.6623 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.0692 - Val accuracy: 0.7676 - Val loss: 0.9030 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.0691 - Val accuracy: 0.7242 - Val loss: 2.0342 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.0561 - Val accuracy: 0.7506 - Val loss: 1.3348 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0532 - Val accuracy: 0.7286 - Val loss: 2.0291 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0507 - Val accuracy: 0.7224 - Val loss: 2.2348 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0482 - Val accuracy: 0.7249 - Val loss: 2.1809 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0492 - Val accuracy: 0.7161 - Val loss: 3.2010 - LR: 0.00e+00\n","\tBest epoch: 3 - Best val accuracy: 0.9077 - Best val loss: 0.2688\n","\n","Domain: 15\n","x_dp_dom.shape: (50, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 15 | Accuracy: 0.8000 | Loss: 1.3551\n","\n","Domain: 16\n","x_dp_dom.shape: (54, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 16 | Accuracy: 0.7593 | Loss: 1.6235\n","\n","Domain: 17\n","x_dp_dom.shape: (53, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 17 | Accuracy: 0.7358 | Loss: 2.0144\n","\n","Domain: 18\n","x_dp_dom.shape: (54, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 18 | Accuracy: 0.7593 | Loss: 1.2838\n","\n","Domain: 19\n","x_dp_dom.shape: (54, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 19 | Accuracy: 0.7593 | Loss: 1.7080\n","\n","Domain: 20\n","x_dp_dom.shape: (51, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 20 | Accuracy: 0.8039 | Loss: 1.5607\n","\n","Domain: 21\n","x_dp_dom.shape: (47, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 21 | Accuracy: 0.8298 | Loss: 0.7218\n","\n","Domain: 22\n","x_dp_dom.shape: (54, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 22 | Accuracy: 0.7593 | Loss: 0.6762\n","\n","Domain: 23\n","x_dp_dom.shape: (52, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 23 | Accuracy: 0.7885 | Loss: 0.6672\n","\n","Domain: 24\n","x_dp_dom.shape: (51, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 24 | Accuracy: 0.7255 | Loss: 2.7563\n","\n","Domain: 25\n","x_dp_dom.shape: (54, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 25 | Accuracy: 0.7593 | Loss: 1.9230\n","\n","Domain: 26\n","x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 26 | Accuracy: 0.8333 | Loss: 0.9394\n","\n","Domain: 27\n","x_dp_dom.shape: (54, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 27 | Accuracy: 0.7593 | Loss: 1.4793\n","\n","Domain: 28\n","x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 28 | Accuracy: 0.8333 | Loss: 1.4071\n","\n","Domain: 29\n","x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 29 | Accuracy: 0.8333 | Loss: 0.5678\n","\n","Domain: 30\n","x_dp_dom.shape: (50, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 30 | Accuracy: 0.7600 | Loss: 1.4250\n","\n","Domain: 31\n","x_dp_dom.shape: (43, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 31 | Accuracy: 0.8372 | Loss: 0.5897\n","\n","Domain: 32\n","x_dp_dom.shape: (52, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 32 | Accuracy: 0.7692 | Loss: 2.5714\n","\n","Domain: 33\n","x_dp_dom.shape: (44, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 33 | Accuracy: 0.8409 | Loss: 1.3874\n","\n","Domain: 34\n","x_dp_dom.shape: (49, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 34 | Accuracy: 0.8163 | Loss: 1.4615\n","\n","Domain: 35\n","x_dp_dom.shape: (48, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 35 | Accuracy: 0.8542 | Loss: 1.0040\n","\n","Domain: 36\n","x_dp_dom.shape: (43, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 36 | Accuracy: 0.8372 | Loss: 1.0713\n","\n","Domain: 37\n","x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 37 | Accuracy: 0.8571 | Loss: 1.5169\n","\n","Domain: 38\n","x_dp_dom.shape: (47, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 38 | Accuracy: 0.8085 | Loss: 0.5966\n","\n","Domain: 39\n","x_dp_dom.shape: (54, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 39 | Accuracy: 0.7593 | Loss: 2.2585\n","\n","Domain: 40\n","x_dp_dom.shape: (44, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 40 | Accuracy: 0.8182 | Loss: 1.4250\n","\n","Domain: 41\n","x_dp_dom.shape: (45, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 41 | Accuracy: 0.8222 | Loss: 1.3591\n","\n","Domain: 42\n","x_dp_dom.shape: (46, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 42 | Accuracy: 0.8043 | Loss: 0.7244\n","\n","Domain: 43\n","x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 43 | Accuracy: 0.8333 | Loss: 1.1933\n","\n","Domain: 44\n","x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 44 | Accuracy: 0.8333 | Loss: 0.6709\n","\n","Domain: 45\n","x_dp_dom.shape: (52, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 45 | Accuracy: 0.7885 | Loss: 1.4911\n","\n","Domain: 46\n","x_dp_dom.shape: (48, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 46 | Accuracy: 0.8542 | Loss: 0.6880\n","\n","Domain: 47\n","x_dp_dom.shape: (44, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 47 | Accuracy: 0.8409 | Loss: 0.6220\n","\n","Domain: 48\n","x_dp_dom.shape: (48, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 48 | Accuracy: 0.8125 | Loss: 0.6070\n","\n","Domain: 49\n","x_dp_dom.shape: (53, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 49 | Accuracy: 0.7736 | Loss: 2.6125\n","\n","Domain: 50\n","x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 50 | Accuracy: 0.8333 | Loss: 0.8274\n","\n","Domain: 51\n","x_dp_dom.shape: (46, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 51 | Accuracy: 0.7826 | Loss: 1.3569\n","\n","Domain: 52\n","x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 52 | Accuracy: 0.8333 | Loss: 1.1373\n","\n","Domain: 53\n","x_dp_dom.shape: (48, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 53 | Accuracy: 0.8333 | Loss: 0.9943\n","\n","Domain: 54\n","x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 54 | Accuracy: 0.8333 | Loss: 1.7810\n","\n","Domain: 55\n","x_dp_dom.shape: (49, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 55 | Accuracy: 0.8367 | Loss: 1.1394\n","\n","Domain: 56\n","x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 56 | Accuracy: 0.8333 | Loss: 1.0499\n","\n","Domain: 57\n","x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 57 | Accuracy: 0.8095 | Loss: 0.8535\n","\n","Domain: 58\n","x_dp_dom.shape: (38, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 58 | Accuracy: 0.7632 | Loss: 0.7672\n","\n","Domain: 59\n","x_dp_dom.shape: (43, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 59 | Accuracy: 0.8372 | Loss: 0.6547\n","\n","Domain: 60\n","x_dp_dom.shape: (47, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 60 | Accuracy: 0.8298 | Loss: 1.4505\n","\n","Domain: 61\n","x_dp_dom.shape: (47, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 61 | Accuracy: 0.7872 | Loss: 1.2390\n","\n","Domain: 62\n","x_dp_dom.shape: (47, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 62 | Accuracy: 0.8511 | Loss: 1.0013\n","\n","Domain: 63\n","x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 63 | Accuracy: 0.8333 | Loss: 0.7587\n","\n","Domain: 64\n","x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 64 | Accuracy: 0.8333 | Loss: 0.6119\n","\n","Domain: 65\n","x_dp_dom.shape: (50, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 65 | Accuracy: 0.8200 | Loss: 1.8363\n","\n","Domain: 66\n","x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 66 | Accuracy: 0.8333 | Loss: 0.9623\n","\n","Domain: 67\n","x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 67 | Accuracy: 0.8810 | Loss: 0.6907\n","\n","Domain: 68\n","x_dp_dom.shape: (43, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 68 | Accuracy: 0.8372 | Loss: 0.7715\n","\n","Domain: 69\n","x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 69 | Accuracy: 0.8333 | Loss: 0.7427\n","\n","Domain: 70\n","x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 70 | Accuracy: 0.8333 | Loss: 1.1342\n","\n","Domain: 71\n","x_dp_dom.shape: (44, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 71 | Accuracy: 0.8636 | Loss: 0.6209\n","\n","Domain: 72\n","x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 72 | Accuracy: 0.8333 | Loss: 0.9871\n","\n","Domain: 73\n","x_dp_dom.shape: (41, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 73 | Accuracy: 0.8537 | Loss: 1.3275\n","\n","Domain: 74\n","x_dp_dom.shape: (35, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 74 | Accuracy: 0.8000 | Loss: 1.6252\n","\n","Domain: 75\n","x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 75 | Accuracy: 0.8333 | Loss: 1.1860\n","\n","Source class: WAL\n","\n","x_df.shape: (7958, 3, 128) | np.unique(y_df): [1 2 3]\n","\n","Training on Df data...\n","\tEpoch 10/100 - Train loss: 0.1506 - Val accuracy: 0.8084 - Val loss: 0.7122 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.1048 - Val accuracy: 0.8153 - Val loss: 0.8248 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.0894 - Val accuracy: 0.7575 - Val loss: 1.5317 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.0746 - Val accuracy: 0.7814 - Val loss: 1.2141 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.0709 - Val accuracy: 0.7557 - Val loss: 1.6262 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.0603 - Val accuracy: 0.7255 - Val loss: 2.3432 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0594 - Val accuracy: 0.7996 - Val loss: 1.0244 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0520 - Val accuracy: 0.7657 - Val loss: 1.6013 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0486 - Val accuracy: 0.7607 - Val loss: 1.6325 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0487 - Val accuracy: 0.7048 - Val loss: 3.0563 - LR: 0.00e+00\n","\tBest epoch: 25 - Best val accuracy: 0.9196 - Best val loss: 0.2386\n","\n","Domain: 15\n","x_dp_dom.shape: (50, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 15 | Accuracy: 0.4000 | Loss: 3.8384\n","\n","Domain: 16\n","x_dp_dom.shape: (54, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 16 | Accuracy: 0.7593 | Loss: 1.7827\n","\n","Domain: 17\n","x_dp_dom.shape: (53, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 17 | Accuracy: 0.7736 | Loss: 1.1567\n","\n","Domain: 18\n","x_dp_dom.shape: (54, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 18 | Accuracy: 0.7963 | Loss: 0.8548\n","\n","Domain: 19\n","x_dp_dom.shape: (54, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 19 | Accuracy: 0.7593 | Loss: 0.9399\n","\n","Domain: 20\n","x_dp_dom.shape: (51, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 20 | Accuracy: 0.8039 | Loss: 1.5014\n","\n","Domain: 21\n","x_dp_dom.shape: (47, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 21 | Accuracy: 0.8511 | Loss: 0.5295\n","\n","Domain: 22\n","x_dp_dom.shape: (54, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 22 | Accuracy: 0.7593 | Loss: 0.7657\n","\n","Domain: 23\n","x_dp_dom.shape: (52, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 23 | Accuracy: 0.7308 | Loss: 1.1393\n","\n","Domain: 24\n","x_dp_dom.shape: (51, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 24 | Accuracy: 0.7451 | Loss: 1.7877\n","\n","Domain: 25\n","x_dp_dom.shape: (54, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 25 | Accuracy: 0.7593 | Loss: 1.3364\n","\n","Domain: 26\n","x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 26 | Accuracy: 0.7381 | Loss: 1.7804\n","\n","Domain: 27\n","x_dp_dom.shape: (54, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 27 | Accuracy: 0.7593 | Loss: 1.8148\n","\n","Domain: 28\n","x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 28 | Accuracy: 0.8333 | Loss: 1.2676\n","\n","Domain: 29\n","x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 29 | Accuracy: 0.8095 | Loss: 0.5005\n","\n","Domain: 30\n","x_dp_dom.shape: (50, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 30 | Accuracy: 0.7200 | Loss: 1.9805\n","\n","Domain: 31\n","x_dp_dom.shape: (43, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 31 | Accuracy: 0.8372 | Loss: 0.7469\n","\n","Domain: 32\n","x_dp_dom.shape: (52, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 32 | Accuracy: 0.7885 | Loss: 1.1824\n","\n","Domain: 33\n","x_dp_dom.shape: (44, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 33 | Accuracy: 0.8409 | Loss: 1.2082\n","\n","Domain: 34\n","x_dp_dom.shape: (49, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 34 | Accuracy: 0.6122 | Loss: 1.7198\n","\n","Domain: 35\n","x_dp_dom.shape: (48, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 35 | Accuracy: 0.8542 | Loss: 1.1077\n","\n","Domain: 36\n","x_dp_dom.shape: (43, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 36 | Accuracy: 0.8372 | Loss: 1.0664\n","\n","Domain: 37\n","x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 37 | Accuracy: 0.8333 | Loss: 1.1402\n","\n","Domain: 38\n","x_dp_dom.shape: (47, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 38 | Accuracy: 0.8298 | Loss: 0.8529\n","\n","Domain: 39\n","x_dp_dom.shape: (54, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 39 | Accuracy: 0.4074 | Loss: 4.9274\n","\n","Domain: 40\n","x_dp_dom.shape: (44, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 40 | Accuracy: 0.7273 | Loss: 1.0095\n","\n","Domain: 41\n","x_dp_dom.shape: (45, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 41 | Accuracy: 0.8222 | Loss: 1.0765\n","\n","Domain: 42\n","x_dp_dom.shape: (46, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 42 | Accuracy: 0.8478 | Loss: 1.1206\n","\n","Domain: 43\n","x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 43 | Accuracy: 0.6429 | Loss: 2.4535\n","\n","Domain: 44\n","x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 44 | Accuracy: 0.8333 | Loss: 0.8744\n","\n","Domain: 45\n","x_dp_dom.shape: (52, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 45 | Accuracy: 0.7885 | Loss: 1.5930\n","\n","Domain: 46\n","x_dp_dom.shape: (48, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 46 | Accuracy: 0.8542 | Loss: 0.4601\n","\n","Domain: 47\n","x_dp_dom.shape: (44, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 47 | Accuracy: 0.8409 | Loss: 1.2452\n","\n","Domain: 48\n","x_dp_dom.shape: (48, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 48 | Accuracy: 0.8125 | Loss: 0.7672\n","\n","Domain: 49\n","x_dp_dom.shape: (53, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 49 | Accuracy: 0.7736 | Loss: 1.9057\n","\n","Domain: 50\n","x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 50 | Accuracy: 0.7619 | Loss: 1.8674\n","\n","Domain: 51\n","x_dp_dom.shape: (46, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 51 | Accuracy: 0.7174 | Loss: 1.7972\n","\n","Domain: 52\n","x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 52 | Accuracy: 0.8333 | Loss: 1.2164\n","\n","Domain: 53\n","x_dp_dom.shape: (48, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 53 | Accuracy: 0.8125 | Loss: 1.3035\n","\n","Domain: 54\n","x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 54 | Accuracy: 0.8333 | Loss: 1.0645\n","\n","Domain: 55\n","x_dp_dom.shape: (49, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 55 | Accuracy: 0.8367 | Loss: 1.2461\n","\n","Domain: 56\n","x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 56 | Accuracy: 0.8095 | Loss: 1.8323\n","\n","Domain: 57\n","x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 57 | Accuracy: 0.7857 | Loss: 1.5944\n","\n","Domain: 58\n","x_dp_dom.shape: (38, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 58 | Accuracy: 0.7368 | Loss: 1.6354\n","\n","Domain: 59\n","x_dp_dom.shape: (43, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 59 | Accuracy: 0.8140 | Loss: 1.4048\n","\n","Domain: 60\n","x_dp_dom.shape: (47, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 60 | Accuracy: 0.4255 | Loss: 6.1049\n","\n","Domain: 61\n","x_dp_dom.shape: (47, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 61 | Accuracy: 0.7234 | Loss: 1.5123\n","\n","Domain: 62\n","x_dp_dom.shape: (47, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 62 | Accuracy: 0.8511 | Loss: 0.9748\n","\n","Domain: 63\n","x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 63 | Accuracy: 0.7381 | Loss: 1.6590\n","\n","Domain: 64\n","x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 64 | Accuracy: 0.8333 | Loss: 0.7511\n","\n","Domain: 65\n","x_dp_dom.shape: (50, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 65 | Accuracy: 0.3000 | Loss: 3.2167\n","\n","Domain: 66\n","x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 66 | Accuracy: 0.2143 | Loss: 4.4472\n","\n","Domain: 67\n","x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 67 | Accuracy: 0.8333 | Loss: 0.9434\n","\n","Domain: 68\n","x_dp_dom.shape: (43, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 68 | Accuracy: 0.8372 | Loss: 1.2604\n","\n","Domain: 69\n","x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 69 | Accuracy: 0.2857 | Loss: 2.8355\n","\n","Domain: 70\n","x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 70 | Accuracy: 0.7857 | Loss: 1.3584\n","\n","Domain: 71\n","x_dp_dom.shape: (44, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 71 | Accuracy: 0.8409 | Loss: 0.8000\n","\n","Domain: 72\n","x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 72 | Accuracy: 0.8333 | Loss: 1.1452\n","\n","Domain: 73\n","x_dp_dom.shape: (41, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 73 | Accuracy: 0.5122 | Loss: 2.5303\n","\n","Domain: 74\n","x_dp_dom.shape: (35, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 74 | Accuracy: 0.8000 | Loss: 2.6817\n","\n","Domain: 75\n","x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 75 | Accuracy: 0.8333 | Loss: 1.3956\n","\n","Source class: WAL\n","\n","x_df.shape: (7958, 3, 128) | np.unique(y_df): [1 2 3]\n","\n","Training on Df data...\n","\tEpoch 10/100 - Train loss: 0.1508 - Val accuracy: 0.7374 - Val loss: 1.1189 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.1020 - Val accuracy: 0.7268 - Val loss: 1.5151 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.0834 - Val accuracy: 0.7293 - Val loss: 1.8787 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.0692 - Val accuracy: 0.7783 - Val loss: 1.1138 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.0575 - Val accuracy: 0.7443 - Val loss: 1.9091 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.0534 - Val accuracy: 0.7481 - Val loss: 1.8872 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0455 - Val accuracy: 0.7330 - Val loss: 2.2401 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0456 - Val accuracy: 0.7557 - Val loss: 1.8984 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0464 - Val accuracy: 0.7406 - Val loss: 2.1438 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0403 - Val accuracy: 0.7594 - Val loss: 1.9117 - LR: 0.00e+00\n","\tBest epoch: 3 - Best val accuracy: 0.9008 - Best val loss: 0.2558\n","\n","Domain: 15\n","x_dp_dom.shape: (50, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 15 | Accuracy: 0.8000 | Loss: 3.0709\n","\n","Domain: 16\n","x_dp_dom.shape: (54, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 16 | Accuracy: 0.7593 | Loss: 3.9022\n","\n","Domain: 17\n","x_dp_dom.shape: (53, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 17 | Accuracy: 0.6038 | Loss: 4.3988\n","\n","Domain: 18\n","x_dp_dom.shape: (54, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 18 | Accuracy: 0.3519 | Loss: 4.8584\n","\n","Domain: 19\n","x_dp_dom.shape: (54, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 19 | Accuracy: 0.6296 | Loss: 3.8857\n","\n","Domain: 20\n","x_dp_dom.shape: (51, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 20 | Accuracy: 0.7647 | Loss: 3.4394\n","\n","Domain: 21\n","x_dp_dom.shape: (47, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 21 | Accuracy: 0.7447 | Loss: 2.5266\n","\n","Domain: 22\n","x_dp_dom.shape: (54, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 22 | Accuracy: 0.7222 | Loss: 3.1051\n","\n","Domain: 23\n","x_dp_dom.shape: (52, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 23 | Accuracy: 0.7885 | Loss: 2.6847\n","\n","Domain: 24\n","x_dp_dom.shape: (51, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 24 | Accuracy: 0.7255 | Loss: 4.2858\n","\n","Domain: 25\n","x_dp_dom.shape: (54, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 25 | Accuracy: 0.6667 | Loss: 3.7729\n","\n","Domain: 26\n","x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 26 | Accuracy: 0.7619 | Loss: 2.6243\n","\n","Domain: 27\n","x_dp_dom.shape: (54, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 27 | Accuracy: 0.7593 | Loss: 3.4590\n","\n","Domain: 28\n","x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 28 | Accuracy: 0.8333 | Loss: 2.7920\n","\n","Domain: 29\n","x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 29 | Accuracy: 0.1667 | Loss: 4.7376\n","\n","Domain: 30\n","x_dp_dom.shape: (50, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 30 | Accuracy: 0.5000 | Loss: 3.8393\n","\n","Domain: 31\n","x_dp_dom.shape: (43, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 31 | Accuracy: 0.8140 | Loss: 2.3532\n","\n","Domain: 32\n","x_dp_dom.shape: (52, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 32 | Accuracy: 0.6154 | Loss: 3.5243\n","\n","Domain: 33\n","x_dp_dom.shape: (44, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 33 | Accuracy: 0.8182 | Loss: 2.7163\n","\n","Domain: 34\n","x_dp_dom.shape: (49, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 34 | Accuracy: 0.8163 | Loss: 2.7114\n","\n","Domain: 35\n","x_dp_dom.shape: (48, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 35 | Accuracy: 0.7917 | Loss: 2.9608\n","\n","Domain: 36\n","x_dp_dom.shape: (43, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 36 | Accuracy: 0.6744 | Loss: 3.4459\n","\n","Domain: 37\n","x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 37 | Accuracy: 0.8333 | Loss: 2.4197\n","\n","Domain: 38\n","x_dp_dom.shape: (47, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 38 | Accuracy: 0.8298 | Loss: 2.0478\n","\n","Domain: 39\n","x_dp_dom.shape: (54, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 39 | Accuracy: 0.7037 | Loss: 3.6659\n","\n","Domain: 40\n","x_dp_dom.shape: (44, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 40 | Accuracy: 0.7727 | Loss: 2.1619\n","\n","Domain: 41\n","x_dp_dom.shape: (45, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 41 | Accuracy: 0.5111 | Loss: 4.8303\n","\n","Domain: 42\n","x_dp_dom.shape: (46, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 42 | Accuracy: 0.5435 | Loss: 3.3471\n","\n","Domain: 43\n","x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 43 | Accuracy: 0.8095 | Loss: 2.2920\n","\n","Domain: 44\n","x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 44 | Accuracy: 0.6190 | Loss: 2.8996\n","\n","Domain: 45\n","x_dp_dom.shape: (52, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 45 | Accuracy: 0.7885 | Loss: 3.5860\n","\n","Domain: 46\n","x_dp_dom.shape: (48, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 46 | Accuracy: 0.2708 | Loss: 4.3783\n","\n","Domain: 47\n","x_dp_dom.shape: (44, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 47 | Accuracy: 0.7955 | Loss: 2.1979\n","\n","Domain: 48\n","x_dp_dom.shape: (48, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 48 | Accuracy: 0.8333 | Loss: 2.1408\n","\n","Domain: 49\n","x_dp_dom.shape: (53, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 49 | Accuracy: 0.7358 | Loss: 3.8433\n","\n","Domain: 50\n","x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 50 | Accuracy: 0.8333 | Loss: 1.0207\n","\n","Domain: 51\n","x_dp_dom.shape: (46, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 51 | Accuracy: 0.8043 | Loss: 2.3906\n","\n","Domain: 52\n","x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 52 | Accuracy: 0.8095 | Loss: 2.8676\n","\n","Domain: 53\n","x_dp_dom.shape: (48, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 53 | Accuracy: 0.8125 | Loss: 2.7551\n","\n","Domain: 54\n","x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 54 | Accuracy: 0.8333 | Loss: 2.3411\n","\n","Domain: 55\n","x_dp_dom.shape: (49, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 55 | Accuracy: 0.8163 | Loss: 2.8483\n","\n","Domain: 56\n","x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 56 | Accuracy: 0.8333 | Loss: 2.1398\n","\n","Domain: 57\n","x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 57 | Accuracy: 0.8333 | Loss: 1.6941\n","\n","Domain: 58\n","x_dp_dom.shape: (38, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 58 | Accuracy: 0.8684 | Loss: 0.8861\n","\n","Domain: 59\n","x_dp_dom.shape: (43, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 59 | Accuracy: 0.8140 | Loss: 2.3376\n","\n","Domain: 60\n","x_dp_dom.shape: (47, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 60 | Accuracy: 0.8085 | Loss: 2.1471\n","\n","Domain: 61\n","x_dp_dom.shape: (47, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 61 | Accuracy: 0.4255 | Loss: 5.3905\n","\n","Domain: 62\n","x_dp_dom.shape: (47, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 62 | Accuracy: 0.7234 | Loss: 2.7696\n","\n","Domain: 63\n","x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 63 | Accuracy: 0.7857 | Loss: 2.3936\n","\n","Domain: 64\n","x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 64 | Accuracy: 0.8333 | Loss: 2.2893\n","\n","Domain: 65\n","x_dp_dom.shape: (50, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 65 | Accuracy: 0.8200 | Loss: 2.6599\n","\n","Domain: 66\n","x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 66 | Accuracy: 0.8095 | Loss: 1.8338\n","\n","Domain: 67\n","x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 67 | Accuracy: 0.8333 | Loss: 1.8525\n","\n","Domain: 68\n","x_dp_dom.shape: (43, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 68 | Accuracy: 0.8372 | Loss: 2.5379\n","\n","Domain: 69\n","x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 69 | Accuracy: 0.8333 | Loss: 2.5064\n","\n","Domain: 70\n","x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 70 | Accuracy: 0.8333 | Loss: 1.7887\n","\n","Domain: 71\n","x_dp_dom.shape: (44, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 71 | Accuracy: 0.8409 | Loss: 1.7807\n","\n","Domain: 72\n","x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 72 | Accuracy: 0.8333 | Loss: 2.7639\n","\n","Domain: 73\n","x_dp_dom.shape: (41, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 73 | Accuracy: 0.8293 | Loss: 1.4746\n","\n","Domain: 74\n","x_dp_dom.shape: (35, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 74 | Accuracy: 0.8857 | Loss: 0.6591\n","\n","Domain: 75\n","x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 75 | Accuracy: 0.8095 | Loss: 3.0204\n","\n","Source class: WAL\n","\n","x_df.shape: (7958, 3, 128) | np.unique(y_df): [1 2 3]\n","\n","Training on Df data...\n","\tEpoch 10/100 - Train loss: 0.1552 - Val accuracy: 0.8788 - Val loss: 0.3351 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.1153 - Val accuracy: 0.8310 - Val loss: 0.5367 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.0896 - Val accuracy: 0.8003 - Val loss: 0.8095 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.0737 - Val accuracy: 0.7525 - Val loss: 1.4611 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.0683 - Val accuracy: 0.7236 - Val loss: 2.3319 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.0643 - Val accuracy: 0.8317 - Val loss: 0.7747 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0555 - Val accuracy: 0.7902 - Val loss: 1.0388 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0538 - Val accuracy: 0.7864 - Val loss: 1.0795 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0515 - Val accuracy: 0.8078 - Val loss: 0.8993 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0457 - Val accuracy: 0.8530 - Val loss: 0.6606 - LR: 0.00e+00\n","\tBest epoch: 10 - Best val accuracy: 0.8788 - Best val loss: 0.3351\n","\n","Domain: 15\n","x_dp_dom.shape: (50, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 15 | Accuracy: 0.8200 | Loss: 0.5831\n","\n","Domain: 16\n","x_dp_dom.shape: (54, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 16 | Accuracy: 0.7593 | Loss: 3.2329\n","\n","Domain: 17\n","x_dp_dom.shape: (53, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 17 | Accuracy: 0.7547 | Loss: 3.4863\n","\n","Domain: 18\n","x_dp_dom.shape: (54, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 18 | Accuracy: 0.5185 | Loss: 3.8923\n","\n","Domain: 19\n","x_dp_dom.shape: (54, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 19 | Accuracy: 0.7593 | Loss: 3.6918\n","\n","Domain: 20\n","x_dp_dom.shape: (51, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 20 | Accuracy: 0.8039 | Loss: 2.4374\n","\n","Domain: 21\n","x_dp_dom.shape: (47, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 21 | Accuracy: 0.8298 | Loss: 1.8847\n","\n","Domain: 22\n","x_dp_dom.shape: (54, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 22 | Accuracy: 0.7593 | Loss: 2.4594\n","\n","Domain: 23\n","x_dp_dom.shape: (52, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 23 | Accuracy: 0.7885 | Loss: 2.3310\n","\n","Domain: 24\n","x_dp_dom.shape: (51, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 24 | Accuracy: 0.7255 | Loss: 3.3670\n","\n","Domain: 25\n","x_dp_dom.shape: (54, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 25 | Accuracy: 0.7407 | Loss: 3.8357\n","\n","Domain: 26\n","x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 26 | Accuracy: 0.7857 | Loss: 0.8504\n","\n","Domain: 27\n","x_dp_dom.shape: (54, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 27 | Accuracy: 0.7593 | Loss: 3.2282\n","\n","Domain: 28\n","x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 28 | Accuracy: 0.8333 | Loss: 2.1709\n","\n","Domain: 29\n","x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 29 | Accuracy: 0.8333 | Loss: 1.3770\n","\n","Domain: 30\n","x_dp_dom.shape: (50, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 30 | Accuracy: 0.6600 | Loss: 2.2545\n","\n","Domain: 31\n","x_dp_dom.shape: (43, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 31 | Accuracy: 0.8140 | Loss: 1.3609\n","\n","Domain: 32\n","x_dp_dom.shape: (52, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 32 | Accuracy: 0.7692 | Loss: 2.3816\n","\n","Domain: 33\n","x_dp_dom.shape: (44, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 33 | Accuracy: 0.8409 | Loss: 1.6213\n","\n","Domain: 34\n","x_dp_dom.shape: (49, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 34 | Accuracy: 0.8163 | Loss: 0.9479\n","\n","Domain: 35\n","x_dp_dom.shape: (48, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 35 | Accuracy: 0.8333 | Loss: 1.9982\n","\n","Domain: 36\n","x_dp_dom.shape: (43, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 36 | Accuracy: 0.8372 | Loss: 2.0267\n","\n","Domain: 37\n","x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 37 | Accuracy: 0.8095 | Loss: 1.6659\n","\n","Domain: 38\n","x_dp_dom.shape: (47, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 38 | Accuracy: 0.8298 | Loss: 1.1465\n","\n","Domain: 39\n","x_dp_dom.shape: (54, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 39 | Accuracy: 0.7407 | Loss: 2.6758\n","\n","Domain: 40\n","x_dp_dom.shape: (44, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 40 | Accuracy: 0.8409 | Loss: 1.0236\n","\n","Domain: 41\n","x_dp_dom.shape: (45, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 41 | Accuracy: 0.7333 | Loss: 2.2467\n","\n","Domain: 42\n","x_dp_dom.shape: (46, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 42 | Accuracy: 0.5870 | Loss: 1.8175\n","\n","Domain: 43\n","x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 43 | Accuracy: 0.8095 | Loss: 0.8506\n","\n","Domain: 44\n","x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 44 | Accuracy: 0.8333 | Loss: 1.9101\n","\n","Domain: 45\n","x_dp_dom.shape: (52, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 45 | Accuracy: 0.7885 | Loss: 2.5868\n","\n","Domain: 46\n","x_dp_dom.shape: (48, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 46 | Accuracy: 0.8542 | Loss: 2.0619\n","\n","Domain: 47\n","x_dp_dom.shape: (44, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 47 | Accuracy: 0.8409 | Loss: 1.5843\n","\n","Domain: 48\n","x_dp_dom.shape: (48, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 48 | Accuracy: 0.8333 | Loss: 1.2729\n","\n","Domain: 49\n","x_dp_dom.shape: (53, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 49 | Accuracy: 0.7736 | Loss: 2.9203\n","\n","Domain: 50\n","x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 50 | Accuracy: 0.8333 | Loss: 0.6980\n","\n","Domain: 51\n","x_dp_dom.shape: (46, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 51 | Accuracy: 0.7826 | Loss: 1.4589\n","\n","Domain: 52\n","x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 52 | Accuracy: 0.8333 | Loss: 2.0271\n","\n","Domain: 53\n","x_dp_dom.shape: (48, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 53 | Accuracy: 0.8333 | Loss: 1.3980\n","\n","Domain: 54\n","x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 54 | Accuracy: 0.8333 | Loss: 1.3368\n","\n","Domain: 55\n","x_dp_dom.shape: (49, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 55 | Accuracy: 0.8367 | Loss: 2.3290\n","\n","Domain: 56\n","x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 56 | Accuracy: 0.8333 | Loss: 1.2788\n","\n","Domain: 57\n","x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 57 | Accuracy: 0.8333 | Loss: 0.7118\n","\n","Domain: 58\n","x_dp_dom.shape: (38, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 58 | Accuracy: 0.8421 | Loss: 0.8053\n","\n","Domain: 59\n","x_dp_dom.shape: (43, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 59 | Accuracy: 0.7907 | Loss: 1.6231\n","\n","Domain: 60\n","x_dp_dom.shape: (47, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 60 | Accuracy: 0.7660 | Loss: 1.2706\n","\n","Domain: 61\n","x_dp_dom.shape: (47, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 61 | Accuracy: 0.4255 | Loss: 2.1764\n","\n","Domain: 62\n","x_dp_dom.shape: (47, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 62 | Accuracy: 0.8511 | Loss: 1.9938\n","\n","Domain: 63\n","x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 63 | Accuracy: 0.8571 | Loss: 0.7640\n","\n","Domain: 64\n","x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 64 | Accuracy: 0.8333 | Loss: 1.8823\n","\n","Domain: 65\n","x_dp_dom.shape: (50, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 65 | Accuracy: 0.8200 | Loss: 1.5795\n","\n","Domain: 66\n","x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 66 | Accuracy: 0.8333 | Loss: 1.3884\n","\n","Domain: 67\n","x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 67 | Accuracy: 0.8333 | Loss: 1.2867\n","\n","Domain: 68\n","x_dp_dom.shape: (43, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 68 | Accuracy: 0.8372 | Loss: 1.6151\n","\n","Domain: 69\n","x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 69 | Accuracy: 0.8333 | Loss: 1.8971\n","\n","Domain: 70\n","x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 70 | Accuracy: 0.8333 | Loss: 1.3211\n","\n","Domain: 71\n","x_dp_dom.shape: (44, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 71 | Accuracy: 0.8409 | Loss: 1.0484\n","\n","Domain: 72\n","x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 72 | Accuracy: 0.8333 | Loss: 2.0856\n","\n","Domain: 73\n","x_dp_dom.shape: (41, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 73 | Accuracy: 0.8537 | Loss: 0.5197\n","\n","Domain: 74\n","x_dp_dom.shape: (35, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 74 | Accuracy: 0.8000 | Loss: 1.6447\n","\n","Domain: 75\n","x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 75 | Accuracy: 0.8333 | Loss: 1.8999\n","\n","Source class: WAL\n","\n","x_df.shape: (7958, 3, 128) | np.unique(y_df): [1 2 3]\n","\n","Training on Df data...\n","\tEpoch 10/100 - Train loss: 0.1542 - Val accuracy: 0.7990 - Val loss: 0.7577 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.1103 - Val accuracy: 0.7996 - Val loss: 0.8891 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.0906 - Val accuracy: 0.7293 - Val loss: 1.6235 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.0698 - Val accuracy: 0.7368 - Val loss: 1.7049 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.0696 - Val accuracy: 0.7619 - Val loss: 1.2327 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.0557 - Val accuracy: 0.7657 - Val loss: 1.3821 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0560 - Val accuracy: 0.9127 - Val loss: 0.2886 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0550 - Val accuracy: 0.7186 - Val loss: 3.2868 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0524 - Val accuracy: 0.7224 - Val loss: 2.5868 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0508 - Val accuracy: 0.8128 - Val loss: 1.0384 - LR: 0.00e+00\n","\tBest epoch: 87 - Best val accuracy: 0.9196 - Best val loss: 0.2486\n","\n","Domain: 15\n","x_dp_dom.shape: (50, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 15 | Accuracy: 0.8200 | Loss: 0.4265\n","\n","Domain: 16\n","x_dp_dom.shape: (54, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 16 | Accuracy: 0.7407 | Loss: 2.2461\n","\n","Domain: 17\n","x_dp_dom.shape: (53, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 17 | Accuracy: 0.6226 | Loss: 3.4538\n","\n","Domain: 18\n","x_dp_dom.shape: (54, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 18 | Accuracy: 0.3148 | Loss: 3.4413\n","\n","Domain: 19\n","x_dp_dom.shape: (54, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 19 | Accuracy: 0.7407 | Loss: 2.4824\n","\n","Domain: 20\n","x_dp_dom.shape: (51, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 20 | Accuracy: 0.7647 | Loss: 2.0449\n","\n","Domain: 21\n","x_dp_dom.shape: (47, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 21 | Accuracy: 0.8298 | Loss: 1.1029\n","\n","Domain: 22\n","x_dp_dom.shape: (54, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 22 | Accuracy: 0.7593 | Loss: 1.1122\n","\n","Domain: 23\n","x_dp_dom.shape: (52, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 23 | Accuracy: 0.7692 | Loss: 1.5056\n","\n","Domain: 24\n","x_dp_dom.shape: (51, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 24 | Accuracy: 0.7255 | Loss: 3.7416\n","\n","Domain: 25\n","x_dp_dom.shape: (54, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 25 | Accuracy: 0.7222 | Loss: 2.8625\n","\n","Domain: 26\n","x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 26 | Accuracy: 0.7143 | Loss: 1.1319\n","\n","Domain: 27\n","x_dp_dom.shape: (54, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 27 | Accuracy: 0.7593 | Loss: 2.8412\n","\n","Domain: 28\n","x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 28 | Accuracy: 0.8333 | Loss: 1.6636\n","\n","Domain: 29\n","x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 29 | Accuracy: 0.8095 | Loss: 0.5954\n","\n","Domain: 30\n","x_dp_dom.shape: (50, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 30 | Accuracy: 0.7200 | Loss: 1.8427\n","\n","Domain: 31\n","x_dp_dom.shape: (43, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 31 | Accuracy: 0.8372 | Loss: 0.5795\n","\n","Domain: 32\n","x_dp_dom.shape: (52, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 32 | Accuracy: 0.7500 | Loss: 3.8201\n","\n","Domain: 33\n","x_dp_dom.shape: (44, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 33 | Accuracy: 0.8182 | Loss: 1.5306\n","\n","Domain: 34\n","x_dp_dom.shape: (49, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 34 | Accuracy: 0.8163 | Loss: 1.2161\n","\n","Domain: 35\n","x_dp_dom.shape: (48, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 35 | Accuracy: 0.8333 | Loss: 1.5230\n","\n","Domain: 36\n","x_dp_dom.shape: (43, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 36 | Accuracy: 0.7907 | Loss: 1.6444\n","\n","Domain: 37\n","x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 37 | Accuracy: 0.7857 | Loss: 2.1480\n","\n","Domain: 38\n","x_dp_dom.shape: (47, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 38 | Accuracy: 0.8723 | Loss: 0.7504\n","\n","Domain: 39\n","x_dp_dom.shape: (54, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 39 | Accuracy: 0.7222 | Loss: 3.4319\n","\n","Domain: 40\n","x_dp_dom.shape: (44, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 40 | Accuracy: 0.7727 | Loss: 1.9533\n","\n","Domain: 41\n","x_dp_dom.shape: (45, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 41 | Accuracy: 0.7333 | Loss: 2.0561\n","\n","Domain: 42\n","x_dp_dom.shape: (46, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 42 | Accuracy: 0.8043 | Loss: 1.5167\n","\n","Domain: 43\n","x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 43 | Accuracy: 0.7381 | Loss: 0.9082\n","\n","Domain: 44\n","x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 44 | Accuracy: 0.8571 | Loss: 1.2241\n","\n","Domain: 45\n","x_dp_dom.shape: (52, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 45 | Accuracy: 0.7885 | Loss: 1.8715\n","\n","Domain: 46\n","x_dp_dom.shape: (48, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 46 | Accuracy: 0.8333 | Loss: 1.0717\n","\n","Domain: 47\n","x_dp_dom.shape: (44, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 47 | Accuracy: 0.8409 | Loss: 0.9839\n","\n","Domain: 48\n","x_dp_dom.shape: (48, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 48 | Accuracy: 0.8333 | Loss: 0.6681\n","\n","Domain: 49\n","x_dp_dom.shape: (53, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 49 | Accuracy: 0.7170 | Loss: 3.3452\n","\n","Domain: 50\n","x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 50 | Accuracy: 0.7857 | Loss: 0.6592\n","\n","Domain: 51\n","x_dp_dom.shape: (46, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 51 | Accuracy: 0.8043 | Loss: 1.3564\n","\n","Domain: 52\n","x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 52 | Accuracy: 0.8333 | Loss: 1.3221\n","\n","Domain: 53\n","x_dp_dom.shape: (48, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 53 | Accuracy: 0.8125 | Loss: 1.3667\n","\n","Domain: 54\n","x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 54 | Accuracy: 0.7857 | Loss: 2.4857\n","\n","Domain: 55\n","x_dp_dom.shape: (49, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 55 | Accuracy: 0.8163 | Loss: 1.5044\n","\n","Domain: 56\n","x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 56 | Accuracy: 0.8571 | Loss: 0.8560\n","\n","Domain: 57\n","x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 57 | Accuracy: 1.0000 | Loss: 0.1242\n","\n","Domain: 58\n","x_dp_dom.shape: (38, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 58 | Accuracy: 0.8947 | Loss: 0.9981\n","\n","Domain: 59\n","x_dp_dom.shape: (43, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 59 | Accuracy: 0.7907 | Loss: 1.2723\n","\n","Domain: 60\n","x_dp_dom.shape: (47, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 60 | Accuracy: 0.7234 | Loss: 1.1095\n","\n","Domain: 61\n","x_dp_dom.shape: (47, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 61 | Accuracy: 0.7234 | Loss: 1.9676\n","\n","Domain: 62\n","x_dp_dom.shape: (47, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 62 | Accuracy: 0.8298 | Loss: 1.7392\n","\n","Domain: 63\n","x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 63 | Accuracy: 0.9048 | Loss: 0.6221\n","\n","Domain: 64\n","x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 64 | Accuracy: 0.7619 | Loss: 0.9687\n","\n","Domain: 65\n","x_dp_dom.shape: (50, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 65 | Accuracy: 0.8200 | Loss: 1.9171\n","\n","Domain: 66\n","x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 66 | Accuracy: 0.8333 | Loss: 0.6505\n","\n","Domain: 67\n","x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 67 | Accuracy: 0.8333 | Loss: 1.8870\n","\n","Domain: 68\n","x_dp_dom.shape: (43, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 68 | Accuracy: 0.7907 | Loss: 1.3160\n","\n","Domain: 69\n","x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 69 | Accuracy: 0.8333 | Loss: 1.0031\n","\n","Domain: 70\n","x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 70 | Accuracy: 0.8333 | Loss: 1.0656\n","\n","Domain: 71\n","x_dp_dom.shape: (44, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 71 | Accuracy: 0.8409 | Loss: 0.4189\n","\n","Domain: 72\n","x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 72 | Accuracy: 0.8333 | Loss: 1.2837\n","\n","Domain: 73\n","x_dp_dom.shape: (41, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 73 | Accuracy: 0.7561 | Loss: 0.9616\n","\n","Domain: 74\n","x_dp_dom.shape: (35, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 74 | Accuracy: 0.8571 | Loss: 0.5233\n","\n","Domain: 75\n","x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 75 | Accuracy: 0.7857 | Loss: 1.6589\n","\n","Mean accuracy: 0.7358\n","\n"]}]},{"cell_type":"code","execution_count":8,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":457848,"status":"ok","timestamp":1731667953557,"user":{"displayName":"Pietro ST","userId":"01777116294553213330"},"user_tz":-60},"id":"SmGQm1ZFCPto","outputId":"6dab5ea5-ee75-4d71-a260-4fc7a699c574"},"outputs":[{"output_type":"stream","name":"stdout","text":["Source class: WAL\n","\n","Domain: 15\n","x_syn_dom.shape: (333, 3, 128) | np.unique(y_syn_dom): [1 2 3]\n","x_dp_dom.shape: (50, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Training on synthetic data...\n","\tEpoch 10/100 - Train loss: 0.0129 - Val accuracy: 1.0000 - Val loss: 0.0074 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.0025 - Val accuracy: 1.0000 - Val loss: 0.0017 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.0016 - Val accuracy: 1.0000 - Val loss: 0.0008 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.0011 - Val accuracy: 1.0000 - Val loss: 0.0005 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.0006 - Val accuracy: 1.0000 - Val loss: 0.0004 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.0006 - Val accuracy: 1.0000 - Val loss: 0.0003 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0004 - Val accuracy: 1.0000 - Val loss: 0.0002 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0004 - Val accuracy: 1.0000 - Val loss: 0.0002 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0004 - Val accuracy: 1.0000 - Val loss: 0.0002 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0005 - Val accuracy: 1.0000 - Val loss: 0.0002 - LR: 0.00e+00\n","\tBest epoch: 95 - Best val accuracy: 1.0000 - Best val loss: 0.0002\n","\n","Source class: WAL | Domain: 15 | Accuracy: 0.7000 | Loss: 2.7138\n","\n","Domain: 16\n","x_syn_dom.shape: (333, 3, 128) | np.unique(y_syn_dom): [1 2 3]\n","x_dp_dom.shape: (54, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Training on synthetic data...\n","\tEpoch 10/100 - Train loss: 0.0095 - Val accuracy: 1.0000 - Val loss: 0.0065 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.0041 - Val accuracy: 1.0000 - Val loss: 0.0017 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.0040 - Val accuracy: 1.0000 - Val loss: 0.0010 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.0011 - Val accuracy: 1.0000 - Val loss: 0.0007 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.0009 - Val accuracy: 1.0000 - Val loss: 0.0008 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.0008 - Val accuracy: 1.0000 - Val loss: 0.0003 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0007 - Val accuracy: 1.0000 - Val loss: 0.0002 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0007 - Val accuracy: 1.0000 - Val loss: 0.0003 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0003 - Val accuracy: 1.0000 - Val loss: 0.0002 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0004 - Val accuracy: 1.0000 - Val loss: 0.0002 - LR: 0.00e+00\n","\tBest epoch: 99 - Best val accuracy: 1.0000 - Best val loss: 0.0002\n","\n","Source class: WAL | Domain: 16 | Accuracy: 0.7778 | Loss: 0.8542\n","\n","Domain: 17\n","x_syn_dom.shape: (333, 3, 128) | np.unique(y_syn_dom): [1 2 3]\n","x_dp_dom.shape: (53, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Training on synthetic data...\n","\tEpoch 10/100 - Train loss: 0.0255 - Val accuracy: 1.0000 - Val loss: 0.0078 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.0060 - Val accuracy: 1.0000 - Val loss: 0.0021 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.0017 - Val accuracy: 1.0000 - Val loss: 0.0010 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.0012 - Val accuracy: 1.0000 - Val loss: 0.0005 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.0010 - Val accuracy: 1.0000 - Val loss: 0.0004 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.0011 - Val accuracy: 1.0000 - Val loss: 0.0003 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0005 - Val accuracy: 1.0000 - Val loss: 0.0002 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0008 - Val accuracy: 1.0000 - Val loss: 0.0002 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0004 - Val accuracy: 1.0000 - Val loss: 0.0002 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0004 - Val accuracy: 1.0000 - Val loss: 0.0002 - LR: 0.00e+00\n","\tBest epoch: 93 - Best val accuracy: 1.0000 - Best val loss: 0.0002\n","\n","Source class: WAL | Domain: 17 | Accuracy: 0.9245 | Loss: 0.1925\n","\n","Domain: 18\n","x_syn_dom.shape: (336, 3, 128) | np.unique(y_syn_dom): [1 2 3]\n","x_dp_dom.shape: (54, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Training on synthetic data...\n","\tEpoch 10/100 - Train loss: 0.0288 - Val accuracy: 1.0000 - Val loss: 0.0089 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.0059 - Val accuracy: 1.0000 - Val loss: 0.0022 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.0017 - Val accuracy: 1.0000 - Val loss: 0.0011 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.0018 - Val accuracy: 1.0000 - Val loss: 0.0007 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.0008 - Val accuracy: 1.0000 - Val loss: 0.0005 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.0007 - Val accuracy: 1.0000 - Val loss: 0.0003 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0011 - Val accuracy: 1.0000 - Val loss: 0.0003 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0006 - Val accuracy: 1.0000 - Val loss: 0.0003 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0007 - Val accuracy: 1.0000 - Val loss: 0.0002 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0006 - Val accuracy: 1.0000 - Val loss: 0.0002 - LR: 0.00e+00\n","\tBest epoch: 92 - Best val accuracy: 1.0000 - Best val loss: 0.0002\n","\n","Source class: WAL | Domain: 18 | Accuracy: 0.7593 | Loss: 1.0453\n","\n","Domain: 19\n","x_syn_dom.shape: (333, 3, 128) | np.unique(y_syn_dom): [1 2 3]\n","x_dp_dom.shape: (54, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Training on synthetic data...\n","\tEpoch 10/100 - Train loss: 0.0079 - Val accuracy: 1.0000 - Val loss: 0.0056 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.0038 - Val accuracy: 1.0000 - Val loss: 0.0015 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.0016 - Val accuracy: 1.0000 - Val loss: 0.0008 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.0011 - Val accuracy: 1.0000 - Val loss: 0.0004 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.0007 - Val accuracy: 1.0000 - Val loss: 0.0004 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.0006 - Val accuracy: 1.0000 - Val loss: 0.0002 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0004 - Val accuracy: 1.0000 - Val loss: 0.0002 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0004 - Val accuracy: 1.0000 - Val loss: 0.0002 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0002 - Val accuracy: 1.0000 - Val loss: 0.0002 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0003 - Val accuracy: 1.0000 - Val loss: 0.0002 - LR: 0.00e+00\n","\tBest epoch: 98 - Best val accuracy: 1.0000 - Best val loss: 0.0002\n","\n","Source class: WAL | Domain: 19 | Accuracy: 0.8333 | Loss: 0.5041\n","\n","Domain: 20\n","x_syn_dom.shape: (333, 3, 128) | np.unique(y_syn_dom): [1 2 3]\n","x_dp_dom.shape: (51, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Training on synthetic data...\n","\tEpoch 10/100 - Train loss: 0.0252 - Val accuracy: 1.0000 - Val loss: 0.0079 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.0044 - Val accuracy: 1.0000 - Val loss: 0.0026 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.0026 - Val accuracy: 1.0000 - Val loss: 0.0011 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.0022 - Val accuracy: 1.0000 - Val loss: 0.0013 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.0022 - Val accuracy: 1.0000 - Val loss: 0.0006 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.0007 - Val accuracy: 1.0000 - Val loss: 0.0004 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0010 - Val accuracy: 1.0000 - Val loss: 0.0003 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0006 - Val accuracy: 1.0000 - Val loss: 0.0004 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0007 - Val accuracy: 1.0000 - Val loss: 0.0003 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0003 - Val accuracy: 1.0000 - Val loss: 0.0003 - LR: 0.00e+00\n","\tBest epoch: 89 - Best val accuracy: 1.0000 - Best val loss: 0.0003\n","\n","Source class: WAL | Domain: 20 | Accuracy: 0.8039 | Loss: 0.3932\n","\n","Domain: 21\n","x_syn_dom.shape: (336, 3, 128) | np.unique(y_syn_dom): [1 2 3]\n","x_dp_dom.shape: (47, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Training on synthetic data...\n","\tEpoch 10/100 - Train loss: 0.0165 - Val accuracy: 1.0000 - Val loss: 0.0056 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.0029 - Val accuracy: 1.0000 - Val loss: 0.0015 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.0019 - Val accuracy: 1.0000 - Val loss: 0.0009 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.0022 - Val accuracy: 1.0000 - Val loss: 0.0005 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.0007 - Val accuracy: 1.0000 - Val loss: 0.0003 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.0009 - Val accuracy: 1.0000 - Val loss: 0.0003 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0004 - Val accuracy: 1.0000 - Val loss: 0.0002 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0011 - Val accuracy: 1.0000 - Val loss: 0.0002 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0007 - Val accuracy: 1.0000 - Val loss: 0.0002 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0003 - Val accuracy: 1.0000 - Val loss: 0.0002 - LR: 0.00e+00\n","\tBest epoch: 89 - Best val accuracy: 1.0000 - Best val loss: 0.0002\n","\n","Source class: WAL | Domain: 21 | Accuracy: 0.8298 | Loss: 0.8136\n","\n","Domain: 22\n","x_syn_dom.shape: (333, 3, 128) | np.unique(y_syn_dom): [1 2 3]\n","x_dp_dom.shape: (54, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Training on synthetic data...\n","\tEpoch 10/100 - Train loss: 0.0153 - Val accuracy: 1.0000 - Val loss: 0.0058 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.0029 - Val accuracy: 1.0000 - Val loss: 0.0013 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.0022 - Val accuracy: 1.0000 - Val loss: 0.0006 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.0014 - Val accuracy: 1.0000 - Val loss: 0.0004 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.0008 - Val accuracy: 1.0000 - Val loss: 0.0003 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.0004 - Val accuracy: 1.0000 - Val loss: 0.0002 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0005 - Val accuracy: 1.0000 - Val loss: 0.0002 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0003 - Val accuracy: 1.0000 - Val loss: 0.0002 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0004 - Val accuracy: 1.0000 - Val loss: 0.0001 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0007 - Val accuracy: 1.0000 - Val loss: 0.0002 - LR: 0.00e+00\n","\tBest epoch: 93 - Best val accuracy: 1.0000 - Best val loss: 0.0001\n","\n","Source class: WAL | Domain: 22 | Accuracy: 0.8333 | Loss: 0.5894\n","\n","Domain: 23\n","x_syn_dom.shape: (336, 3, 128) | np.unique(y_syn_dom): [1 2 3]\n","x_dp_dom.shape: (52, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Training on synthetic data...\n","\tEpoch 10/100 - Train loss: 0.0449 - Val accuracy: 1.0000 - Val loss: 0.0429 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.0120 - Val accuracy: 1.0000 - Val loss: 0.0097 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.0036 - Val accuracy: 1.0000 - Val loss: 0.0034 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.0030 - Val accuracy: 1.0000 - Val loss: 0.0023 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.0017 - Val accuracy: 1.0000 - Val loss: 0.0018 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.0012 - Val accuracy: 1.0000 - Val loss: 0.0014 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0014 - Val accuracy: 1.0000 - Val loss: 0.0014 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0008 - Val accuracy: 1.0000 - Val loss: 0.0011 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0006 - Val accuracy: 1.0000 - Val loss: 0.0010 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0007 - Val accuracy: 1.0000 - Val loss: 0.0011 - LR: 0.00e+00\n","\tBest epoch: 97 - Best val accuracy: 1.0000 - Best val loss: 0.0010\n","\n","Source class: WAL | Domain: 23 | Accuracy: 0.8077 | Loss: 0.6223\n","\n","Domain: 24\n","x_syn_dom.shape: (333, 3, 128) | np.unique(y_syn_dom): [1 2 3]\n","x_dp_dom.shape: (51, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Training on synthetic data...\n","\tEpoch 10/100 - Train loss: 0.0105 - Val accuracy: 1.0000 - Val loss: 0.0076 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.0029 - Val accuracy: 1.0000 - Val loss: 0.0019 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.0018 - Val accuracy: 1.0000 - Val loss: 0.0010 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.0013 - Val accuracy: 1.0000 - Val loss: 0.0006 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.0007 - Val accuracy: 1.0000 - Val loss: 0.0004 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.0004 - Val accuracy: 1.0000 - Val loss: 0.0003 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0005 - Val accuracy: 1.0000 - Val loss: 0.0002 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0004 - Val accuracy: 1.0000 - Val loss: 0.0002 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0004 - Val accuracy: 1.0000 - Val loss: 0.0002 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0024 - Val accuracy: 1.0000 - Val loss: 0.0002 - LR: 0.00e+00\n","\tBest epoch: 91 - Best val accuracy: 1.0000 - Best val loss: 0.0002\n","\n","Source class: WAL | Domain: 24 | Accuracy: 0.7255 | Loss: 1.8479\n","\n","Domain: 25\n","x_syn_dom.shape: (336, 3, 128) | np.unique(y_syn_dom): [1 2 3]\n","x_dp_dom.shape: (54, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Training on synthetic data...\n","\tEpoch 10/100 - Train loss: 0.0115 - Val accuracy: 1.0000 - Val loss: 0.0058 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.0031 - Val accuracy: 1.0000 - Val loss: 0.0014 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.0029 - Val accuracy: 1.0000 - Val loss: 0.0007 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.0008 - Val accuracy: 1.0000 - Val loss: 0.0004 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.0005 - Val accuracy: 1.0000 - Val loss: 0.0003 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.0007 - Val accuracy: 1.0000 - Val loss: 0.0002 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0004 - Val accuracy: 1.0000 - Val loss: 0.0002 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0006 - Val accuracy: 1.0000 - Val loss: 0.0001 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0003 - Val accuracy: 1.0000 - Val loss: 0.0002 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0005 - Val accuracy: 1.0000 - Val loss: 0.0001 - LR: 0.00e+00\n","\tBest epoch: 100 - Best val accuracy: 1.0000 - Best val loss: 0.0001\n","\n","Source class: WAL | Domain: 25 | Accuracy: 0.7407 | Loss: 1.6997\n","\n","Domain: 26\n","x_syn_dom.shape: (333, 3, 128) | np.unique(y_syn_dom): [1 2 3]\n","x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Training on synthetic data...\n","\tEpoch 10/100 - Train loss: 0.0149 - Val accuracy: 1.0000 - Val loss: 0.0125 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.0031 - Val accuracy: 1.0000 - Val loss: 0.0040 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.0026 - Val accuracy: 1.0000 - Val loss: 0.0019 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.0014 - Val accuracy: 1.0000 - Val loss: 0.0014 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.0010 - Val accuracy: 1.0000 - Val loss: 0.0011 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.0005 - Val accuracy: 1.0000 - Val loss: 0.0008 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0007 - Val accuracy: 1.0000 - Val loss: 0.0005 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0004 - Val accuracy: 1.0000 - Val loss: 0.0007 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0004 - Val accuracy: 1.0000 - Val loss: 0.0005 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0005 - Val accuracy: 1.0000 - Val loss: 0.0004 - LR: 0.00e+00\n","\tBest epoch: 100 - Best val accuracy: 1.0000 - Best val loss: 0.0004\n","\n","Source class: WAL | Domain: 26 | Accuracy: 0.6190 | Loss: 1.2903\n","\n","Domain: 27\n","x_syn_dom.shape: (333, 3, 128) | np.unique(y_syn_dom): [1 2 3]\n","x_dp_dom.shape: (54, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Training on synthetic data...\n","\tEpoch 10/100 - Train loss: 0.0176 - Val accuracy: 1.0000 - Val loss: 0.0118 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.0064 - Val accuracy: 1.0000 - Val loss: 0.0032 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.0027 - Val accuracy: 1.0000 - Val loss: 0.0018 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.0016 - Val accuracy: 1.0000 - Val loss: 0.0011 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.0020 - Val accuracy: 1.0000 - Val loss: 0.0008 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.0019 - Val accuracy: 1.0000 - Val loss: 0.0006 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0009 - Val accuracy: 1.0000 - Val loss: 0.0005 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0008 - Val accuracy: 1.0000 - Val loss: 0.0004 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0005 - Val accuracy: 1.0000 - Val loss: 0.0004 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0007 - Val accuracy: 1.0000 - Val loss: 0.0005 - LR: 0.00e+00\n","\tBest epoch: 98 - Best val accuracy: 1.0000 - Best val loss: 0.0004\n","\n","Source class: WAL | Domain: 27 | Accuracy: 0.7593 | Loss: 0.6757\n","\n","Domain: 28\n","x_syn_dom.shape: (333, 3, 128) | np.unique(y_syn_dom): [1 2 3]\n","x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Training on synthetic data...\n","\tEpoch 10/100 - Train loss: 0.0085 - Val accuracy: 1.0000 - Val loss: 0.0046 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.0037 - Val accuracy: 1.0000 - Val loss: 0.0013 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.0015 - Val accuracy: 1.0000 - Val loss: 0.0006 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.0009 - Val accuracy: 1.0000 - Val loss: 0.0004 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.0008 - Val accuracy: 1.0000 - Val loss: 0.0003 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.0005 - Val accuracy: 1.0000 - Val loss: 0.0002 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0006 - Val accuracy: 1.0000 - Val loss: 0.0002 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0004 - Val accuracy: 1.0000 - Val loss: 0.0001 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0005 - Val accuracy: 1.0000 - Val loss: 0.0001 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0003 - Val accuracy: 1.0000 - Val loss: 0.0001 - LR: 0.00e+00\n","\tBest epoch: 98 - Best val accuracy: 1.0000 - Best val loss: 0.0001\n","\n","Source class: WAL | Domain: 28 | Accuracy: 0.8571 | Loss: 0.3693\n","\n","Domain: 29\n","x_syn_dom.shape: (333, 3, 128) | np.unique(y_syn_dom): [1 2 3]\n","x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Training on synthetic data...\n","\tEpoch 10/100 - Train loss: 0.0188 - Val accuracy: 1.0000 - Val loss: 0.0066 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.0054 - Val accuracy: 1.0000 - Val loss: 0.0014 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.0048 - Val accuracy: 1.0000 - Val loss: 0.0006 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.0010 - Val accuracy: 1.0000 - Val loss: 0.0004 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.0008 - Val accuracy: 1.0000 - Val loss: 0.0003 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.0009 - Val accuracy: 1.0000 - Val loss: 0.0002 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0011 - Val accuracy: 1.0000 - Val loss: 0.0002 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0003 - Val accuracy: 1.0000 - Val loss: 0.0001 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0003 - Val accuracy: 1.0000 - Val loss: 0.0001 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0005 - Val accuracy: 1.0000 - Val loss: 0.0001 - LR: 0.00e+00\n","\tBest epoch: 97 - Best val accuracy: 1.0000 - Best val loss: 0.0001\n","\n","Source class: WAL | Domain: 29 | Accuracy: 0.8333 | Loss: 0.7173\n","\n","Domain: 30\n","x_syn_dom.shape: (333, 3, 128) | np.unique(y_syn_dom): [1 2 3]\n","x_dp_dom.shape: (50, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Training on synthetic data...\n","\tEpoch 10/100 - Train loss: 0.0668 - Val accuracy: 1.0000 - Val loss: 0.0847 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.0233 - Val accuracy: 1.0000 - Val loss: 0.0267 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.0080 - Val accuracy: 1.0000 - Val loss: 0.0188 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.0031 - Val accuracy: 1.0000 - Val loss: 0.0192 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.0043 - Val accuracy: 1.0000 - Val loss: 0.0132 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.0024 - Val accuracy: 1.0000 - Val loss: 0.0120 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0014 - Val accuracy: 1.0000 - Val loss: 0.0098 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0012 - Val accuracy: 1.0000 - Val loss: 0.0093 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0014 - Val accuracy: 1.0000 - Val loss: 0.0092 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0015 - Val accuracy: 1.0000 - Val loss: 0.0111 - LR: 0.00e+00\n","\tBest epoch: 66 - Best val accuracy: 1.0000 - Best val loss: 0.0077\n","\n","Source class: WAL | Domain: 30 | Accuracy: 0.7600 | Loss: 2.3643\n","\n","Domain: 31\n","x_syn_dom.shape: (333, 3, 128) | np.unique(y_syn_dom): [1 2 3]\n","x_dp_dom.shape: (43, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Training on synthetic data...\n","\tEpoch 10/100 - Train loss: 0.0267 - Val accuracy: 1.0000 - Val loss: 0.0096 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.0062 - Val accuracy: 1.0000 - Val loss: 0.0023 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.0028 - Val accuracy: 1.0000 - Val loss: 0.0015 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.0119 - Val accuracy: 1.0000 - Val loss: 0.0010 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.0010 - Val accuracy: 1.0000 - Val loss: 0.0005 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.0008 - Val accuracy: 1.0000 - Val loss: 0.0004 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0009 - Val accuracy: 1.0000 - Val loss: 0.0003 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0011 - Val accuracy: 1.0000 - Val loss: 0.0003 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0013 - Val accuracy: 1.0000 - Val loss: 0.0003 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0006 - Val accuracy: 1.0000 - Val loss: 0.0002 - LR: 0.00e+00\n","\tBest epoch: 94 - Best val accuracy: 1.0000 - Best val loss: 0.0002\n","\n","Source class: WAL | Domain: 31 | Accuracy: 0.6744 | Loss: 2.1087\n","\n","Domain: 32\n","x_syn_dom.shape: (333, 3, 128) | np.unique(y_syn_dom): [1 2 3]\n","x_dp_dom.shape: (52, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Training on synthetic data...\n","\tEpoch 10/100 - Train loss: 0.0150 - Val accuracy: 1.0000 - Val loss: 0.0101 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.0031 - Val accuracy: 1.0000 - Val loss: 0.0024 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.0021 - Val accuracy: 1.0000 - Val loss: 0.0012 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.0011 - Val accuracy: 1.0000 - Val loss: 0.0009 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.0008 - Val accuracy: 1.0000 - Val loss: 0.0005 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.0005 - Val accuracy: 1.0000 - Val loss: 0.0004 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0005 - Val accuracy: 1.0000 - Val loss: 0.0004 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0004 - Val accuracy: 1.0000 - Val loss: 0.0004 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0004 - Val accuracy: 1.0000 - Val loss: 0.0003 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0005 - Val accuracy: 1.0000 - Val loss: 0.0003 - LR: 0.00e+00\n","\tBest epoch: 91 - Best val accuracy: 1.0000 - Best val loss: 0.0003\n","\n","Source class: WAL | Domain: 32 | Accuracy: 0.7692 | Loss: 1.9937\n","\n","Domain: 33\n","x_syn_dom.shape: (336, 3, 128) | np.unique(y_syn_dom): [1 2 3]\n","x_dp_dom.shape: (44, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Training on synthetic data...\n","\tEpoch 10/100 - Train loss: 0.0130 - Val accuracy: 1.0000 - Val loss: 0.0102 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.0033 - Val accuracy: 1.0000 - Val loss: 0.0027 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.0014 - Val accuracy: 1.0000 - Val loss: 0.0012 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.0010 - Val accuracy: 1.0000 - Val loss: 0.0008 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.0010 - Val accuracy: 1.0000 - Val loss: 0.0006 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.0009 - Val accuracy: 1.0000 - Val loss: 0.0005 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0005 - Val accuracy: 1.0000 - Val loss: 0.0003 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0004 - Val accuracy: 1.0000 - Val loss: 0.0003 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0006 - Val accuracy: 1.0000 - Val loss: 0.0003 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0004 - Val accuracy: 1.0000 - Val loss: 0.0003 - LR: 0.00e+00\n","\tBest epoch: 91 - Best val accuracy: 1.0000 - Best val loss: 0.0003\n","\n","Source class: WAL | Domain: 33 | Accuracy: 0.8409 | Loss: 0.3540\n","\n","Domain: 34\n","x_syn_dom.shape: (336, 3, 128) | np.unique(y_syn_dom): [1 2 3]\n","x_dp_dom.shape: (49, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Training on synthetic data...\n","\tEpoch 10/100 - Train loss: 0.0642 - Val accuracy: 1.0000 - Val loss: 0.0295 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.0123 - Val accuracy: 1.0000 - Val loss: 0.0090 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.0043 - Val accuracy: 1.0000 - Val loss: 0.0037 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.0080 - Val accuracy: 1.0000 - Val loss: 0.0029 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.0018 - Val accuracy: 1.0000 - Val loss: 0.0020 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.0018 - Val accuracy: 1.0000 - Val loss: 0.0015 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0010 - Val accuracy: 1.0000 - Val loss: 0.0019 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0006 - Val accuracy: 1.0000 - Val loss: 0.0012 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0005 - Val accuracy: 1.0000 - Val loss: 0.0011 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0007 - Val accuracy: 1.0000 - Val loss: 0.0012 - LR: 0.00e+00\n","\tBest epoch: 86 - Best val accuracy: 1.0000 - Best val loss: 0.0011\n","\n","Source class: WAL | Domain: 34 | Accuracy: 0.7755 | Loss: 0.5877\n","\n","Domain: 35\n","x_syn_dom.shape: (333, 3, 128) | np.unique(y_syn_dom): [1 2 3]\n","x_dp_dom.shape: (48, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Training on synthetic data...\n","\tEpoch 10/100 - Train loss: 0.0206 - Val accuracy: 1.0000 - Val loss: 0.0055 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.0036 - Val accuracy: 1.0000 - Val loss: 0.0014 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.0023 - Val accuracy: 1.0000 - Val loss: 0.0008 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.0012 - Val accuracy: 1.0000 - Val loss: 0.0005 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.0007 - Val accuracy: 1.0000 - Val loss: 0.0003 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.0006 - Val accuracy: 1.0000 - Val loss: 0.0002 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0016 - Val accuracy: 1.0000 - Val loss: 0.0002 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0004 - Val accuracy: 1.0000 - Val loss: 0.0002 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0003 - Val accuracy: 1.0000 - Val loss: 0.0001 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0011 - Val accuracy: 1.0000 - Val loss: 0.0001 - LR: 0.00e+00\n","\tBest epoch: 97 - Best val accuracy: 1.0000 - Best val loss: 0.0001\n","\n","Source class: WAL | Domain: 35 | Accuracy: 0.8750 | Loss: 0.3812\n","\n","Domain: 36\n","x_syn_dom.shape: (336, 3, 128) | np.unique(y_syn_dom): [1 2 3]\n","x_dp_dom.shape: (43, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Training on synthetic data...\n","\tEpoch 10/100 - Train loss: 0.0083 - Val accuracy: 1.0000 - Val loss: 0.0042 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.0026 - Val accuracy: 1.0000 - Val loss: 0.0011 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.0014 - Val accuracy: 1.0000 - Val loss: 0.0005 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.0010 - Val accuracy: 1.0000 - Val loss: 0.0003 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.0006 - Val accuracy: 1.0000 - Val loss: 0.0002 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.0004 - Val accuracy: 1.0000 - Val loss: 0.0002 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0004 - Val accuracy: 1.0000 - Val loss: 0.0001 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0004 - Val accuracy: 1.0000 - Val loss: 0.0001 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0004 - Val accuracy: 1.0000 - Val loss: 0.0001 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0002 - Val accuracy: 1.0000 - Val loss: 0.0001 - LR: 0.00e+00\n","\tBest epoch: 95 - Best val accuracy: 1.0000 - Best val loss: 0.0001\n","\n","Source class: WAL | Domain: 36 | Accuracy: 0.8372 | Loss: 0.3920\n","\n","Domain: 37\n","x_syn_dom.shape: (336, 3, 128) | np.unique(y_syn_dom): [1 2 3]\n","x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Training on synthetic data...\n","\tEpoch 10/100 - Train loss: 0.0169 - Val accuracy: 1.0000 - Val loss: 0.0077 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.0054 - Val accuracy: 1.0000 - Val loss: 0.0021 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.0016 - Val accuracy: 1.0000 - Val loss: 0.0010 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.0010 - Val accuracy: 1.0000 - Val loss: 0.0006 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.0009 - Val accuracy: 1.0000 - Val loss: 0.0004 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.0006 - Val accuracy: 1.0000 - Val loss: 0.0003 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0006 - Val accuracy: 1.0000 - Val loss: 0.0002 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0007 - Val accuracy: 1.0000 - Val loss: 0.0002 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0007 - Val accuracy: 1.0000 - Val loss: 0.0002 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0004 - Val accuracy: 1.0000 - Val loss: 0.0002 - LR: 0.00e+00\n","\tBest epoch: 99 - Best val accuracy: 1.0000 - Best val loss: 0.0002\n","\n","Source class: WAL | Domain: 37 | Accuracy: 0.8333 | Loss: 0.9743\n","\n","Domain: 38\n","x_syn_dom.shape: (333, 3, 128) | np.unique(y_syn_dom): [1 2 3]\n","x_dp_dom.shape: (47, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Training on synthetic data...\n","\tEpoch 10/100 - Train loss: 0.0296 - Val accuracy: 1.0000 - Val loss: 0.0081 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.0039 - Val accuracy: 1.0000 - Val loss: 0.0018 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.0037 - Val accuracy: 1.0000 - Val loss: 0.0008 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.0012 - Val accuracy: 1.0000 - Val loss: 0.0005 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.0013 - Val accuracy: 1.0000 - Val loss: 0.0004 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.0006 - Val accuracy: 1.0000 - Val loss: 0.0003 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0009 - Val accuracy: 1.0000 - Val loss: 0.0003 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0010 - Val accuracy: 1.0000 - Val loss: 0.0002 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0017 - Val accuracy: 1.0000 - Val loss: 0.0002 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0005 - Val accuracy: 1.0000 - Val loss: 0.0002 - LR: 0.00e+00\n","\tBest epoch: 98 - Best val accuracy: 1.0000 - Best val loss: 0.0002\n","\n","Source class: WAL | Domain: 38 | Accuracy: 0.6596 | Loss: 3.5867\n","\n","Domain: 39\n","x_syn_dom.shape: (333, 3, 128) | np.unique(y_syn_dom): [1 2 3]\n","x_dp_dom.shape: (54, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Training on synthetic data...\n","\tEpoch 10/100 - Train loss: 0.0104 - Val accuracy: 1.0000 - Val loss: 0.0050 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.0023 - Val accuracy: 1.0000 - Val loss: 0.0014 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.0020 - Val accuracy: 1.0000 - Val loss: 0.0006 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.0019 - Val accuracy: 1.0000 - Val loss: 0.0004 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.0007 - Val accuracy: 1.0000 - Val loss: 0.0002 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.0006 - Val accuracy: 1.0000 - Val loss: 0.0002 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0003 - Val accuracy: 1.0000 - Val loss: 0.0002 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0003 - Val accuracy: 1.0000 - Val loss: 0.0001 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0004 - Val accuracy: 1.0000 - Val loss: 0.0001 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0009 - Val accuracy: 1.0000 - Val loss: 0.0001 - LR: 0.00e+00\n","\tBest epoch: 89 - Best val accuracy: 1.0000 - Best val loss: 0.0001\n","\n","Source class: WAL | Domain: 39 | Accuracy: 0.5185 | Loss: 3.7066\n","\n","Domain: 40\n","x_syn_dom.shape: (333, 3, 128) | np.unique(y_syn_dom): [1 2 3]\n","x_dp_dom.shape: (44, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Training on synthetic data...\n","\tEpoch 10/100 - Train loss: 0.0174 - Val accuracy: 1.0000 - Val loss: 0.0103 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.0068 - Val accuracy: 1.0000 - Val loss: 0.0020 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.0018 - Val accuracy: 1.0000 - Val loss: 0.0009 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.0027 - Val accuracy: 1.0000 - Val loss: 0.0005 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.0008 - Val accuracy: 1.0000 - Val loss: 0.0004 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.0007 - Val accuracy: 1.0000 - Val loss: 0.0003 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0006 - Val accuracy: 1.0000 - Val loss: 0.0002 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0005 - Val accuracy: 1.0000 - Val loss: 0.0002 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0003 - Val accuracy: 1.0000 - Val loss: 0.0002 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0004 - Val accuracy: 1.0000 - Val loss: 0.0002 - LR: 0.00e+00\n","\tBest epoch: 99 - Best val accuracy: 1.0000 - Best val loss: 0.0002\n","\n","Source class: WAL | Domain: 40 | Accuracy: 0.8864 | Loss: 0.3063\n","\n","Domain: 41\n","x_syn_dom.shape: (333, 3, 128) | np.unique(y_syn_dom): [1 2 3]\n","x_dp_dom.shape: (45, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Training on synthetic data...\n","\tEpoch 10/100 - Train loss: 0.0457 - Val accuracy: 0.9701 - Val loss: 0.1641 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.0073 - Val accuracy: 0.9552 - Val loss: 0.1901 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.0048 - Val accuracy: 0.9552 - Val loss: 0.2346 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.0026 - Val accuracy: 0.9552 - Val loss: 0.2525 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.0017 - Val accuracy: 0.9552 - Val loss: 0.2583 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.0013 - Val accuracy: 0.9552 - Val loss: 0.2633 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0352 - Val accuracy: 0.9552 - Val loss: 0.2470 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0008 - Val accuracy: 0.9552 - Val loss: 0.2559 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0008 - Val accuracy: 0.9552 - Val loss: 0.2702 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0008 - Val accuracy: 0.9552 - Val loss: 0.2844 - LR: 0.00e+00\n","\tBest epoch: 6 - Best val accuracy: 0.9552 - Best val loss: 0.1497\n","\n","Source class: WAL | Domain: 41 | Accuracy: 0.7111 | Loss: 1.9897\n","\n","Domain: 42\n","x_syn_dom.shape: (336, 3, 128) | np.unique(y_syn_dom): [1 2 3]\n","x_dp_dom.shape: (46, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Training on synthetic data...\n","\tEpoch 10/100 - Train loss: 0.0206 - Val accuracy: 1.0000 - Val loss: 0.0119 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.0041 - Val accuracy: 1.0000 - Val loss: 0.0034 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.0030 - Val accuracy: 1.0000 - Val loss: 0.0013 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.0014 - Val accuracy: 1.0000 - Val loss: 0.0007 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.0016 - Val accuracy: 1.0000 - Val loss: 0.0005 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.0008 - Val accuracy: 1.0000 - Val loss: 0.0004 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0006 - Val accuracy: 1.0000 - Val loss: 0.0003 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0013 - Val accuracy: 1.0000 - Val loss: 0.0003 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0004 - Val accuracy: 1.0000 - Val loss: 0.0002 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0007 - Val accuracy: 1.0000 - Val loss: 0.0002 - LR: 0.00e+00\n","\tBest epoch: 86 - Best val accuracy: 1.0000 - Best val loss: 0.0002\n","\n","Source class: WAL | Domain: 42 | Accuracy: 0.7826 | Loss: 1.1256\n","\n","Domain: 43\n","x_syn_dom.shape: (333, 3, 128) | np.unique(y_syn_dom): [1 2 3]\n","x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Training on synthetic data...\n","\tEpoch 10/100 - Train loss: 0.0147 - Val accuracy: 1.0000 - Val loss: 0.0079 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.0057 - Val accuracy: 1.0000 - Val loss: 0.0019 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.0028 - Val accuracy: 1.0000 - Val loss: 0.0007 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.0018 - Val accuracy: 1.0000 - Val loss: 0.0004 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.0013 - Val accuracy: 1.0000 - Val loss: 0.0003 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.0007 - Val accuracy: 1.0000 - Val loss: 0.0003 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0015 - Val accuracy: 1.0000 - Val loss: 0.0002 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0004 - Val accuracy: 1.0000 - Val loss: 0.0002 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0004 - Val accuracy: 1.0000 - Val loss: 0.0002 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0004 - Val accuracy: 1.0000 - Val loss: 0.0002 - LR: 0.00e+00\n","\tBest epoch: 96 - Best val accuracy: 1.0000 - Best val loss: 0.0001\n","\n","Source class: WAL | Domain: 43 | Accuracy: 0.7857 | Loss: 2.4445\n","\n","Domain: 44\n","x_syn_dom.shape: (333, 3, 128) | np.unique(y_syn_dom): [1 2 3]\n","x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Training on synthetic data...\n","\tEpoch 10/100 - Train loss: 0.0110 - Val accuracy: 1.0000 - Val loss: 0.0044 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.0028 - Val accuracy: 1.0000 - Val loss: 0.0011 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.0011 - Val accuracy: 1.0000 - Val loss: 0.0006 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.0007 - Val accuracy: 1.0000 - Val loss: 0.0003 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.0006 - Val accuracy: 1.0000 - Val loss: 0.0003 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.0004 - Val accuracy: 1.0000 - Val loss: 0.0002 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0003 - Val accuracy: 1.0000 - Val loss: 0.0002 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0004 - Val accuracy: 1.0000 - Val loss: 0.0001 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0017 - Val accuracy: 1.0000 - Val loss: 0.0001 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0007 - Val accuracy: 1.0000 - Val loss: 0.0001 - LR: 0.00e+00\n","\tBest epoch: 99 - Best val accuracy: 1.0000 - Best val loss: 0.0001\n","\n","Source class: WAL | Domain: 44 | Accuracy: 0.9286 | Loss: 0.2148\n","\n","Domain: 45\n","x_syn_dom.shape: (333, 3, 128) | np.unique(y_syn_dom): [1 2 3]\n","x_dp_dom.shape: (52, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Training on synthetic data...\n","\tEpoch 10/100 - Train loss: 0.0140 - Val accuracy: 1.0000 - Val loss: 0.0118 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.0041 - Val accuracy: 1.0000 - Val loss: 0.0052 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.0017 - Val accuracy: 1.0000 - Val loss: 0.0020 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.0008 - Val accuracy: 1.0000 - Val loss: 0.0017 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.0008 - Val accuracy: 1.0000 - Val loss: 0.0011 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.0005 - Val accuracy: 1.0000 - Val loss: 0.0009 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0004 - Val accuracy: 1.0000 - Val loss: 0.0005 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0004 - Val accuracy: 1.0000 - Val loss: 0.0005 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0008 - Val accuracy: 1.0000 - Val loss: 0.0004 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0004 - Val accuracy: 1.0000 - Val loss: 0.0004 - LR: 0.00e+00\n","\tBest epoch: 88 - Best val accuracy: 1.0000 - Best val loss: 0.0003\n","\n","Source class: WAL | Domain: 45 | Accuracy: 0.8077 | Loss: 0.4957\n","\n","Domain: 46\n","x_syn_dom.shape: (336, 3, 128) | np.unique(y_syn_dom): [1 2 3]\n","x_dp_dom.shape: (48, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Training on synthetic data...\n","\tEpoch 10/100 - Train loss: 0.0119 - Val accuracy: 1.0000 - Val loss: 0.0058 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.0023 - Val accuracy: 1.0000 - Val loss: 0.0016 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.0012 - Val accuracy: 1.0000 - Val loss: 0.0007 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.0013 - Val accuracy: 1.0000 - Val loss: 0.0004 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.0010 - Val accuracy: 1.0000 - Val loss: 0.0003 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.0004 - Val accuracy: 1.0000 - Val loss: 0.0002 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0003 - Val accuracy: 1.0000 - Val loss: 0.0002 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0003 - Val accuracy: 1.0000 - Val loss: 0.0002 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0004 - Val accuracy: 1.0000 - Val loss: 0.0002 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0005 - Val accuracy: 1.0000 - Val loss: 0.0002 - LR: 0.00e+00\n","\tBest epoch: 89 - Best val accuracy: 1.0000 - Best val loss: 0.0001\n","\n","Source class: WAL | Domain: 46 | Accuracy: 0.7500 | Loss: 0.7938\n","\n","Domain: 47\n","x_syn_dom.shape: (333, 3, 128) | np.unique(y_syn_dom): [1 2 3]\n","x_dp_dom.shape: (44, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Training on synthetic data...\n","\tEpoch 10/100 - Train loss: 0.0117 - Val accuracy: 1.0000 - Val loss: 0.0041 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.0064 - Val accuracy: 1.0000 - Val loss: 0.0012 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.0012 - Val accuracy: 1.0000 - Val loss: 0.0006 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.0007 - Val accuracy: 1.0000 - Val loss: 0.0004 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.0006 - Val accuracy: 1.0000 - Val loss: 0.0003 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.0008 - Val accuracy: 1.0000 - Val loss: 0.0002 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0003 - Val accuracy: 1.0000 - Val loss: 0.0002 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0007 - Val accuracy: 1.0000 - Val loss: 0.0002 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0003 - Val accuracy: 1.0000 - Val loss: 0.0001 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0003 - Val accuracy: 1.0000 - Val loss: 0.0001 - LR: 0.00e+00\n","\tBest epoch: 100 - Best val accuracy: 1.0000 - Best val loss: 0.0001\n","\n","Source class: WAL | Domain: 47 | Accuracy: 0.7955 | Loss: 1.1430\n","\n","Domain: 48\n","x_syn_dom.shape: (333, 3, 128) | np.unique(y_syn_dom): [1 2 3]\n","x_dp_dom.shape: (48, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Training on synthetic data...\n","\tEpoch 10/100 - Train loss: 0.0180 - Val accuracy: 1.0000 - Val loss: 0.0155 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.0053 - Val accuracy: 1.0000 - Val loss: 0.0046 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.0023 - Val accuracy: 1.0000 - Val loss: 0.0021 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.0008 - Val accuracy: 1.0000 - Val loss: 0.0012 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.0007 - Val accuracy: 1.0000 - Val loss: 0.0008 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.0007 - Val accuracy: 1.0000 - Val loss: 0.0008 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0004 - Val accuracy: 1.0000 - Val loss: 0.0005 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0005 - Val accuracy: 1.0000 - Val loss: 0.0004 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0004 - Val accuracy: 1.0000 - Val loss: 0.0004 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0006 - Val accuracy: 1.0000 - Val loss: 0.0004 - LR: 0.00e+00\n","\tBest epoch: 92 - Best val accuracy: 1.0000 - Best val loss: 0.0003\n","\n","Source class: WAL | Domain: 48 | Accuracy: 0.7500 | Loss: 1.4754\n","\n","Domain: 49\n","x_syn_dom.shape: (333, 3, 128) | np.unique(y_syn_dom): [1 2 3]\n","x_dp_dom.shape: (53, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Training on synthetic data...\n","\tEpoch 10/100 - Train loss: 0.0130 - Val accuracy: 1.0000 - Val loss: 0.0054 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.0035 - Val accuracy: 1.0000 - Val loss: 0.0014 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.0018 - Val accuracy: 1.0000 - Val loss: 0.0006 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.0016 - Val accuracy: 1.0000 - Val loss: 0.0004 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.0007 - Val accuracy: 1.0000 - Val loss: 0.0003 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.0005 - Val accuracy: 1.0000 - Val loss: 0.0002 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0005 - Val accuracy: 1.0000 - Val loss: 0.0002 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0003 - Val accuracy: 1.0000 - Val loss: 0.0002 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0003 - Val accuracy: 1.0000 - Val loss: 0.0002 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0005 - Val accuracy: 1.0000 - Val loss: 0.0001 - LR: 0.00e+00\n","\tBest epoch: 98 - Best val accuracy: 1.0000 - Best val loss: 0.0001\n","\n","Source class: WAL | Domain: 49 | Accuracy: 0.7736 | Loss: 0.8278\n","\n","Domain: 50\n","x_syn_dom.shape: (333, 3, 128) | np.unique(y_syn_dom): [1 2 3]\n","x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Training on synthetic data...\n","\tEpoch 10/100 - Train loss: 0.0129 - Val accuracy: 1.0000 - Val loss: 0.0075 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.0045 - Val accuracy: 1.0000 - Val loss: 0.0020 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.0022 - Val accuracy: 1.0000 - Val loss: 0.0009 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.0011 - Val accuracy: 1.0000 - Val loss: 0.0005 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.0008 - Val accuracy: 1.0000 - Val loss: 0.0004 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.0006 - Val accuracy: 1.0000 - Val loss: 0.0003 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0009 - Val accuracy: 1.0000 - Val loss: 0.0002 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0004 - Val accuracy: 1.0000 - Val loss: 0.0002 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0005 - Val accuracy: 1.0000 - Val loss: 0.0002 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0005 - Val accuracy: 1.0000 - Val loss: 0.0002 - LR: 0.00e+00\n","\tBest epoch: 98 - Best val accuracy: 1.0000 - Best val loss: 0.0002\n","\n","Source class: WAL | Domain: 50 | Accuracy: 0.9286 | Loss: 0.2693\n","\n","Domain: 51\n","x_syn_dom.shape: (333, 3, 128) | np.unique(y_syn_dom): [1 2 3]\n","x_dp_dom.shape: (46, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Training on synthetic data...\n","\tEpoch 10/100 - Train loss: 0.0116 - Val accuracy: 1.0000 - Val loss: 0.0053 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.0028 - Val accuracy: 1.0000 - Val loss: 0.0014 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.0019 - Val accuracy: 1.0000 - Val loss: 0.0008 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.0016 - Val accuracy: 1.0000 - Val loss: 0.0004 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.0009 - Val accuracy: 1.0000 - Val loss: 0.0003 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.0004 - Val accuracy: 1.0000 - Val loss: 0.0002 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0004 - Val accuracy: 1.0000 - Val loss: 0.0002 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0004 - Val accuracy: 1.0000 - Val loss: 0.0002 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0003 - Val accuracy: 1.0000 - Val loss: 0.0002 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0003 - Val accuracy: 1.0000 - Val loss: 0.0002 - LR: 0.00e+00\n","\tBest epoch: 94 - Best val accuracy: 1.0000 - Best val loss: 0.0001\n","\n","Source class: WAL | Domain: 51 | Accuracy: 0.7826 | Loss: 0.6748\n","\n","Domain: 52\n","x_syn_dom.shape: (333, 3, 128) | np.unique(y_syn_dom): [1 2 3]\n","x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Training on synthetic data...\n","\tEpoch 10/100 - Train loss: 0.0129 - Val accuracy: 1.0000 - Val loss: 0.0072 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.0086 - Val accuracy: 1.0000 - Val loss: 0.0018 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.0017 - Val accuracy: 1.0000 - Val loss: 0.0007 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.0013 - Val accuracy: 1.0000 - Val loss: 0.0006 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.0008 - Val accuracy: 1.0000 - Val loss: 0.0004 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.0007 - Val accuracy: 1.0000 - Val loss: 0.0004 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0006 - Val accuracy: 1.0000 - Val loss: 0.0002 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0007 - Val accuracy: 1.0000 - Val loss: 0.0002 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0004 - Val accuracy: 1.0000 - Val loss: 0.0002 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0003 - Val accuracy: 1.0000 - Val loss: 0.0002 - LR: 0.00e+00\n","\tBest epoch: 94 - Best val accuracy: 1.0000 - Best val loss: 0.0002\n","\n","Source class: WAL | Domain: 52 | Accuracy: 0.8095 | Loss: 0.7839\n","\n","Domain: 53\n","x_syn_dom.shape: (333, 3, 128) | np.unique(y_syn_dom): [1 2 3]\n","x_dp_dom.shape: (48, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Training on synthetic data...\n","\tEpoch 10/100 - Train loss: 0.0170 - Val accuracy: 1.0000 - Val loss: 0.0051 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.0127 - Val accuracy: 1.0000 - Val loss: 0.0012 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.0020 - Val accuracy: 1.0000 - Val loss: 0.0005 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.0014 - Val accuracy: 1.0000 - Val loss: 0.0004 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.0006 - Val accuracy: 1.0000 - Val loss: 0.0003 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.0008 - Val accuracy: 1.0000 - Val loss: 0.0002 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0019 - Val accuracy: 1.0000 - Val loss: 0.0002 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0005 - Val accuracy: 1.0000 - Val loss: 0.0001 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0020 - Val accuracy: 1.0000 - Val loss: 0.0001 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0008 - Val accuracy: 1.0000 - Val loss: 0.0001 - LR: 0.00e+00\n","\tBest epoch: 94 - Best val accuracy: 1.0000 - Best val loss: 0.0001\n","\n","Source class: WAL | Domain: 53 | Accuracy: 0.5833 | Loss: 6.4162\n","\n","Domain: 54\n","x_syn_dom.shape: (333, 3, 128) | np.unique(y_syn_dom): [1 2 3]\n","x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Training on synthetic data...\n","\tEpoch 10/100 - Train loss: 0.0113 - Val accuracy: 1.0000 - Val loss: 0.0052 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.0019 - Val accuracy: 1.0000 - Val loss: 0.0014 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.0016 - Val accuracy: 1.0000 - Val loss: 0.0007 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.0008 - Val accuracy: 1.0000 - Val loss: 0.0005 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.0008 - Val accuracy: 1.0000 - Val loss: 0.0004 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.0012 - Val accuracy: 1.0000 - Val loss: 0.0003 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0007 - Val accuracy: 1.0000 - Val loss: 0.0002 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0009 - Val accuracy: 1.0000 - Val loss: 0.0002 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0007 - Val accuracy: 1.0000 - Val loss: 0.0002 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0011 - Val accuracy: 1.0000 - Val loss: 0.0002 - LR: 0.00e+00\n","\tBest epoch: 100 - Best val accuracy: 1.0000 - Best val loss: 0.0002\n","\n","Source class: WAL | Domain: 54 | Accuracy: 0.7619 | Loss: 1.1104\n","\n","Domain: 55\n","x_syn_dom.shape: (333, 3, 128) | np.unique(y_syn_dom): [1 2 3]\n","x_dp_dom.shape: (49, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Training on synthetic data...\n","\tEpoch 10/100 - Train loss: 0.0101 - Val accuracy: 1.0000 - Val loss: 0.0050 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.0020 - Val accuracy: 1.0000 - Val loss: 0.0014 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.0012 - Val accuracy: 1.0000 - Val loss: 0.0006 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.0010 - Val accuracy: 1.0000 - Val loss: 0.0004 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.0009 - Val accuracy: 1.0000 - Val loss: 0.0003 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.0010 - Val accuracy: 1.0000 - Val loss: 0.0002 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0004 - Val accuracy: 1.0000 - Val loss: 0.0002 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0005 - Val accuracy: 1.0000 - Val loss: 0.0001 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0004 - Val accuracy: 1.0000 - Val loss: 0.0001 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0003 - Val accuracy: 1.0000 - Val loss: 0.0001 - LR: 0.00e+00\n","\tBest epoch: 97 - Best val accuracy: 1.0000 - Best val loss: 0.0001\n","\n","Source class: WAL | Domain: 55 | Accuracy: 0.7347 | Loss: 0.8037\n","\n","Domain: 56\n","x_syn_dom.shape: (333, 3, 128) | np.unique(y_syn_dom): [1 2 3]\n","x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Training on synthetic data...\n","\tEpoch 10/100 - Train loss: 0.0110 - Val accuracy: 1.0000 - Val loss: 0.0076 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.0036 - Val accuracy: 1.0000 - Val loss: 0.0017 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.0019 - Val accuracy: 1.0000 - Val loss: 0.0008 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.0016 - Val accuracy: 1.0000 - Val loss: 0.0005 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.0007 - Val accuracy: 1.0000 - Val loss: 0.0003 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.0005 - Val accuracy: 1.0000 - Val loss: 0.0003 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0007 - Val accuracy: 1.0000 - Val loss: 0.0002 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0004 - Val accuracy: 1.0000 - Val loss: 0.0002 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0005 - Val accuracy: 1.0000 - Val loss: 0.0002 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0003 - Val accuracy: 1.0000 - Val loss: 0.0002 - LR: 0.00e+00\n","\tBest epoch: 93 - Best val accuracy: 1.0000 - Best val loss: 0.0002\n","\n","Source class: WAL | Domain: 56 | Accuracy: 0.9286 | Loss: 0.3213\n","\n","Domain: 57\n","x_syn_dom.shape: (333, 3, 128) | np.unique(y_syn_dom): [1 2 3]\n","x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Training on synthetic data...\n","\tEpoch 10/100 - Train loss: 0.0152 - Val accuracy: 1.0000 - Val loss: 0.0090 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.0045 - Val accuracy: 1.0000 - Val loss: 0.0020 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.0018 - Val accuracy: 1.0000 - Val loss: 0.0008 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.0011 - Val accuracy: 1.0000 - Val loss: 0.0005 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.0010 - Val accuracy: 1.0000 - Val loss: 0.0003 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.0006 - Val accuracy: 1.0000 - Val loss: 0.0003 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0005 - Val accuracy: 1.0000 - Val loss: 0.0002 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0004 - Val accuracy: 1.0000 - Val loss: 0.0002 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0007 - Val accuracy: 1.0000 - Val loss: 0.0001 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0003 - Val accuracy: 1.0000 - Val loss: 0.0001 - LR: 0.00e+00\n","\tBest epoch: 92 - Best val accuracy: 1.0000 - Best val loss: 0.0001\n","\n","Source class: WAL | Domain: 57 | Accuracy: 0.7619 | Loss: 0.5317\n","\n","Domain: 58\n","x_syn_dom.shape: (333, 3, 128) | np.unique(y_syn_dom): [1 2 3]\n","x_dp_dom.shape: (38, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Training on synthetic data...\n","\tEpoch 10/100 - Train loss: 0.0532 - Val accuracy: 1.0000 - Val loss: 0.0366 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.0094 - Val accuracy: 1.0000 - Val loss: 0.0090 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.0040 - Val accuracy: 1.0000 - Val loss: 0.0072 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.0034 - Val accuracy: 1.0000 - Val loss: 0.0033 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.0015 - Val accuracy: 1.0000 - Val loss: 0.0014 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.0009 - Val accuracy: 1.0000 - Val loss: 0.0011 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0010 - Val accuracy: 1.0000 - Val loss: 0.0013 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0017 - Val accuracy: 1.0000 - Val loss: 0.0022 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0084 - Val accuracy: 1.0000 - Val loss: 0.0006 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0024 - Val accuracy: 1.0000 - Val loss: 0.0007 - LR: 0.00e+00\n","\tBest epoch: 92 - Best val accuracy: 1.0000 - Best val loss: 0.0006\n","\n","Source class: WAL | Domain: 58 | Accuracy: 0.8421 | Loss: 0.7786\n","\n","Domain: 59\n","x_syn_dom.shape: (333, 3, 128) | np.unique(y_syn_dom): [1 2 3]\n","x_dp_dom.shape: (43, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Training on synthetic data...\n","\tEpoch 10/100 - Train loss: 0.0159 - Val accuracy: 1.0000 - Val loss: 0.0103 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.0046 - Val accuracy: 1.0000 - Val loss: 0.0035 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.0017 - Val accuracy: 1.0000 - Val loss: 0.0013 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.0011 - Val accuracy: 1.0000 - Val loss: 0.0007 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.0016 - Val accuracy: 1.0000 - Val loss: 0.0006 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.0010 - Val accuracy: 1.0000 - Val loss: 0.0003 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0007 - Val accuracy: 1.0000 - Val loss: 0.0004 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0008 - Val accuracy: 1.0000 - Val loss: 0.0002 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0005 - Val accuracy: 1.0000 - Val loss: 0.0003 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0009 - Val accuracy: 1.0000 - Val loss: 0.0003 - LR: 0.00e+00\n","\tBest epoch: 81 - Best val accuracy: 1.0000 - Best val loss: 0.0002\n","\n","Source class: WAL | Domain: 59 | Accuracy: 0.8837 | Loss: 0.2682\n","\n","Domain: 60\n","x_syn_dom.shape: (333, 3, 128) | np.unique(y_syn_dom): [1 2 3]\n","x_dp_dom.shape: (47, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Training on synthetic data...\n","\tEpoch 10/100 - Train loss: 0.0219 - Val accuracy: 0.9851 - Val loss: 0.0231 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.0068 - Val accuracy: 1.0000 - Val loss: 0.0075 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.0037 - Val accuracy: 1.0000 - Val loss: 0.0024 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.0021 - Val accuracy: 1.0000 - Val loss: 0.0013 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.0078 - Val accuracy: 1.0000 - Val loss: 0.0093 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.0010 - Val accuracy: 1.0000 - Val loss: 0.0009 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0006 - Val accuracy: 1.0000 - Val loss: 0.0007 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0006 - Val accuracy: 1.0000 - Val loss: 0.0008 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0009 - Val accuracy: 1.0000 - Val loss: 0.0008 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0022 - Val accuracy: 1.0000 - Val loss: 0.0015 - LR: 0.00e+00\n","\tBest epoch: 93 - Best val accuracy: 1.0000 - Best val loss: 0.0005\n","\n","Source class: WAL | Domain: 60 | Accuracy: 0.8511 | Loss: 0.8528\n","\n","Domain: 61\n","x_syn_dom.shape: (333, 3, 128) | np.unique(y_syn_dom): [1 2 3]\n","x_dp_dom.shape: (47, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Training on synthetic data...\n","\tEpoch 10/100 - Train loss: 0.0122 - Val accuracy: 1.0000 - Val loss: 0.0052 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.0032 - Val accuracy: 1.0000 - Val loss: 0.0013 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.0026 - Val accuracy: 1.0000 - Val loss: 0.0007 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.0008 - Val accuracy: 1.0000 - Val loss: 0.0004 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.0010 - Val accuracy: 1.0000 - Val loss: 0.0003 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.0023 - Val accuracy: 1.0000 - Val loss: 0.0002 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0004 - Val accuracy: 1.0000 - Val loss: 0.0002 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0005 - Val accuracy: 1.0000 - Val loss: 0.0001 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0005 - Val accuracy: 1.0000 - Val loss: 0.0001 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0005 - Val accuracy: 1.0000 - Val loss: 0.0001 - LR: 0.00e+00\n","\tBest epoch: 96 - Best val accuracy: 1.0000 - Best val loss: 0.0001\n","\n","Source class: WAL | Domain: 61 | Accuracy: 0.7872 | Loss: 1.5736\n","\n","Domain: 62\n","x_syn_dom.shape: (333, 3, 128) | np.unique(y_syn_dom): [1 2 3]\n","x_dp_dom.shape: (47, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Training on synthetic data...\n","\tEpoch 10/100 - Train loss: 0.0108 - Val accuracy: 1.0000 - Val loss: 0.0045 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.0068 - Val accuracy: 1.0000 - Val loss: 0.0011 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.0017 - Val accuracy: 1.0000 - Val loss: 0.0005 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.0010 - Val accuracy: 1.0000 - Val loss: 0.0003 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.0020 - Val accuracy: 1.0000 - Val loss: 0.0002 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.0008 - Val accuracy: 1.0000 - Val loss: 0.0002 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0003 - Val accuracy: 1.0000 - Val loss: 0.0001 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0005 - Val accuracy: 1.0000 - Val loss: 0.0001 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0004 - Val accuracy: 1.0000 - Val loss: 0.0001 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0005 - Val accuracy: 1.0000 - Val loss: 0.0001 - LR: 0.00e+00\n","\tBest epoch: 100 - Best val accuracy: 1.0000 - Best val loss: 0.0001\n","\n","Source class: WAL | Domain: 62 | Accuracy: 0.8723 | Loss: 0.3540\n","\n","Domain: 63\n","x_syn_dom.shape: (333, 3, 128) | np.unique(y_syn_dom): [1 2 3]\n","x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Training on synthetic data...\n","\tEpoch 10/100 - Train loss: 0.0150 - Val accuracy: 1.0000 - Val loss: 0.0090 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.0042 - Val accuracy: 1.0000 - Val loss: 0.0022 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.0024 - Val accuracy: 1.0000 - Val loss: 0.0011 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.0012 - Val accuracy: 1.0000 - Val loss: 0.0006 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.0015 - Val accuracy: 1.0000 - Val loss: 0.0005 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.0009 - Val accuracy: 1.0000 - Val loss: 0.0004 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0005 - Val accuracy: 1.0000 - Val loss: 0.0004 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0007 - Val accuracy: 1.0000 - Val loss: 0.0004 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0006 - Val accuracy: 1.0000 - Val loss: 0.0003 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0004 - Val accuracy: 1.0000 - Val loss: 0.0003 - LR: 0.00e+00\n","\tBest epoch: 96 - Best val accuracy: 1.0000 - Best val loss: 0.0003\n","\n","Source class: WAL | Domain: 63 | Accuracy: 0.7857 | Loss: 0.9122\n","\n","Domain: 64\n","x_syn_dom.shape: (336, 3, 128) | np.unique(y_syn_dom): [1 2 3]\n","x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Training on synthetic data...\n","\tEpoch 10/100 - Train loss: 0.0146 - Val accuracy: 1.0000 - Val loss: 0.0114 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.0035 - Val accuracy: 1.0000 - Val loss: 0.0037 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.0014 - Val accuracy: 1.0000 - Val loss: 0.0023 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.0016 - Val accuracy: 1.0000 - Val loss: 0.0008 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.0006 - Val accuracy: 1.0000 - Val loss: 0.0006 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.0006 - Val accuracy: 1.0000 - Val loss: 0.0006 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0003 - Val accuracy: 1.0000 - Val loss: 0.0004 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0003 - Val accuracy: 1.0000 - Val loss: 0.0004 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0005 - Val accuracy: 1.0000 - Val loss: 0.0005 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0003 - Val accuracy: 1.0000 - Val loss: 0.0005 - LR: 0.00e+00\n","\tBest epoch: 73 - Best val accuracy: 1.0000 - Best val loss: 0.0003\n","\n","Source class: WAL | Domain: 64 | Accuracy: 0.8571 | Loss: 0.5647\n","\n","Domain: 65\n","x_syn_dom.shape: (333, 3, 128) | np.unique(y_syn_dom): [1 2 3]\n","x_dp_dom.shape: (50, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Training on synthetic data...\n","\tEpoch 10/100 - Train loss: 0.0126 - Val accuracy: 1.0000 - Val loss: 0.0066 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.0032 - Val accuracy: 1.0000 - Val loss: 0.0016 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.0013 - Val accuracy: 1.0000 - Val loss: 0.0008 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.0009 - Val accuracy: 1.0000 - Val loss: 0.0004 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.0008 - Val accuracy: 1.0000 - Val loss: 0.0003 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.0005 - Val accuracy: 1.0000 - Val loss: 0.0002 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0004 - Val accuracy: 1.0000 - Val loss: 0.0002 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0003 - Val accuracy: 1.0000 - Val loss: 0.0002 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0003 - Val accuracy: 1.0000 - Val loss: 0.0001 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0006 - Val accuracy: 1.0000 - Val loss: 0.0001 - LR: 0.00e+00\n","\tBest epoch: 98 - Best val accuracy: 1.0000 - Best val loss: 0.0001\n","\n","Source class: WAL | Domain: 65 | Accuracy: 0.8800 | Loss: 0.6573\n","\n","Domain: 66\n","x_syn_dom.shape: (333, 3, 128) | np.unique(y_syn_dom): [1 2 3]\n","x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Training on synthetic data...\n","\tEpoch 10/100 - Train loss: 0.0268 - Val accuracy: 1.0000 - Val loss: 0.0219 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.0048 - Val accuracy: 1.0000 - Val loss: 0.0047 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.0020 - Val accuracy: 1.0000 - Val loss: 0.0025 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.0013 - Val accuracy: 1.0000 - Val loss: 0.0013 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.0009 - Val accuracy: 1.0000 - Val loss: 0.0009 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.0007 - Val accuracy: 1.0000 - Val loss: 0.0008 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0006 - Val accuracy: 1.0000 - Val loss: 0.0007 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0004 - Val accuracy: 1.0000 - Val loss: 0.0006 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0004 - Val accuracy: 1.0000 - Val loss: 0.0005 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0005 - Val accuracy: 1.0000 - Val loss: 0.0005 - LR: 0.00e+00\n","\tBest epoch: 89 - Best val accuracy: 1.0000 - Best val loss: 0.0004\n","\n","Source class: WAL | Domain: 66 | Accuracy: 0.7143 | Loss: 1.4920\n","\n","Domain: 67\n","x_syn_dom.shape: (333, 3, 128) | np.unique(y_syn_dom): [1 2 3]\n","x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Training on synthetic data...\n","\tEpoch 10/100 - Train loss: 0.0217 - Val accuracy: 0.9851 - Val loss: 0.0512 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.0109 - Val accuracy: 0.9851 - Val loss: 0.0608 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.0032 - Val accuracy: 0.9851 - Val loss: 0.0229 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.0016 - Val accuracy: 0.9851 - Val loss: 0.0312 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.0008 - Val accuracy: 0.9851 - Val loss: 0.0305 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.0011 - Val accuracy: 0.9851 - Val loss: 0.0220 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0006 - Val accuracy: 0.9851 - Val loss: 0.0272 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0009 - Val accuracy: 0.9851 - Val loss: 0.0184 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0006 - Val accuracy: 0.9851 - Val loss: 0.0194 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0005 - Val accuracy: 0.9851 - Val loss: 0.0140 - LR: 0.00e+00\n","\tBest epoch: 63 - Best val accuracy: 1.0000 - Best val loss: 0.0075\n","\n","Source class: WAL | Domain: 67 | Accuracy: 0.8333 | Loss: 0.9494\n","\n","Domain: 68\n","x_syn_dom.shape: (333, 3, 128) | np.unique(y_syn_dom): [1 2 3]\n","x_dp_dom.shape: (43, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Training on synthetic data...\n","\tEpoch 10/100 - Train loss: 0.0168 - Val accuracy: 1.0000 - Val loss: 0.0106 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.0032 - Val accuracy: 1.0000 - Val loss: 0.0019 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.0015 - Val accuracy: 1.0000 - Val loss: 0.0009 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.0013 - Val accuracy: 1.0000 - Val loss: 0.0006 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.0008 - Val accuracy: 1.0000 - Val loss: 0.0004 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.0005 - Val accuracy: 1.0000 - Val loss: 0.0003 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0004 - Val accuracy: 1.0000 - Val loss: 0.0002 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0005 - Val accuracy: 1.0000 - Val loss: 0.0002 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0004 - Val accuracy: 1.0000 - Val loss: 0.0002 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0003 - Val accuracy: 1.0000 - Val loss: 0.0002 - LR: 0.00e+00\n","\tBest epoch: 94 - Best val accuracy: 1.0000 - Best val loss: 0.0002\n","\n","Source class: WAL | Domain: 68 | Accuracy: 0.8837 | Loss: 0.3749\n","\n","Domain: 69\n","x_syn_dom.shape: (333, 3, 128) | np.unique(y_syn_dom): [1 2 3]\n","x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Training on synthetic data...\n","\tEpoch 10/100 - Train loss: 0.0230 - Val accuracy: 1.0000 - Val loss: 0.0131 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.0028 - Val accuracy: 1.0000 - Val loss: 0.0027 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.0014 - Val accuracy: 1.0000 - Val loss: 0.0009 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.0014 - Val accuracy: 1.0000 - Val loss: 0.0007 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.0006 - Val accuracy: 1.0000 - Val loss: 0.0005 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.0008 - Val accuracy: 1.0000 - Val loss: 0.0003 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0005 - Val accuracy: 1.0000 - Val loss: 0.0002 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0003 - Val accuracy: 1.0000 - Val loss: 0.0002 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0007 - Val accuracy: 1.0000 - Val loss: 0.0002 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0003 - Val accuracy: 1.0000 - Val loss: 0.0002 - LR: 0.00e+00\n","\tBest epoch: 97 - Best val accuracy: 1.0000 - Best val loss: 0.0002\n","\n","Source class: WAL | Domain: 69 | Accuracy: 0.7619 | Loss: 0.5950\n","\n","Domain: 70\n","x_syn_dom.shape: (333, 3, 128) | np.unique(y_syn_dom): [1 2 3]\n","x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Training on synthetic data...\n","\tEpoch 10/100 - Train loss: 0.0223 - Val accuracy: 1.0000 - Val loss: 0.0077 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.0070 - Val accuracy: 1.0000 - Val loss: 0.0017 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.0031 - Val accuracy: 1.0000 - Val loss: 0.0008 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.0014 - Val accuracy: 1.0000 - Val loss: 0.0004 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.0022 - Val accuracy: 1.0000 - Val loss: 0.0003 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.0010 - Val accuracy: 1.0000 - Val loss: 0.0002 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0008 - Val accuracy: 1.0000 - Val loss: 0.0002 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0005 - Val accuracy: 1.0000 - Val loss: 0.0002 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0010 - Val accuracy: 1.0000 - Val loss: 0.0001 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0008 - Val accuracy: 1.0000 - Val loss: 0.0001 - LR: 0.00e+00\n","\tBest epoch: 89 - Best val accuracy: 1.0000 - Best val loss: 0.0001\n","\n","Source class: WAL | Domain: 70 | Accuracy: 0.7619 | Loss: 2.0320\n","\n","Domain: 71\n","x_syn_dom.shape: (333, 3, 128) | np.unique(y_syn_dom): [1 2 3]\n","x_dp_dom.shape: (44, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Training on synthetic data...\n","\tEpoch 10/100 - Train loss: 0.0201 - Val accuracy: 1.0000 - Val loss: 0.0072 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.0046 - Val accuracy: 1.0000 - Val loss: 0.0018 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.0021 - Val accuracy: 1.0000 - Val loss: 0.0008 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.0017 - Val accuracy: 1.0000 - Val loss: 0.0005 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.0008 - Val accuracy: 1.0000 - Val loss: 0.0004 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.0006 - Val accuracy: 1.0000 - Val loss: 0.0003 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0008 - Val accuracy: 1.0000 - Val loss: 0.0002 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0012 - Val accuracy: 1.0000 - Val loss: 0.0002 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0006 - Val accuracy: 1.0000 - Val loss: 0.0002 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0003 - Val accuracy: 1.0000 - Val loss: 0.0002 - LR: 0.00e+00\n","\tBest epoch: 98 - Best val accuracy: 1.0000 - Best val loss: 0.0002\n","\n","Source class: WAL | Domain: 71 | Accuracy: 0.7045 | Loss: 2.3251\n","\n","Domain: 72\n","x_syn_dom.shape: (333, 3, 128) | np.unique(y_syn_dom): [1 2 3]\n","x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Training on synthetic data...\n","\tEpoch 10/100 - Train loss: 0.0154 - Val accuracy: 1.0000 - Val loss: 0.0069 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.0037 - Val accuracy: 1.0000 - Val loss: 0.0016 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.0018 - Val accuracy: 1.0000 - Val loss: 0.0008 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.0013 - Val accuracy: 1.0000 - Val loss: 0.0005 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.0005 - Val accuracy: 1.0000 - Val loss: 0.0003 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.0008 - Val accuracy: 1.0000 - Val loss: 0.0002 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0005 - Val accuracy: 1.0000 - Val loss: 0.0002 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0004 - Val accuracy: 1.0000 - Val loss: 0.0002 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0003 - Val accuracy: 1.0000 - Val loss: 0.0001 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0003 - Val accuracy: 1.0000 - Val loss: 0.0001 - LR: 0.00e+00\n","\tBest epoch: 97 - Best val accuracy: 1.0000 - Best val loss: 0.0001\n","\n","Source class: WAL | Domain: 72 | Accuracy: 0.8333 | Loss: 1.0249\n","\n","Domain: 73\n","x_syn_dom.shape: (333, 3, 128) | np.unique(y_syn_dom): [1 2 3]\n","x_dp_dom.shape: (41, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Training on synthetic data...\n","\tEpoch 10/100 - Train loss: 0.0280 - Val accuracy: 1.0000 - Val loss: 0.0116 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.0096 - Val accuracy: 1.0000 - Val loss: 0.0028 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.0032 - Val accuracy: 1.0000 - Val loss: 0.0012 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.0024 - Val accuracy: 1.0000 - Val loss: 0.0006 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.0014 - Val accuracy: 1.0000 - Val loss: 0.0006 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.0008 - Val accuracy: 1.0000 - Val loss: 0.0004 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0008 - Val accuracy: 1.0000 - Val loss: 0.0003 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0013 - Val accuracy: 1.0000 - Val loss: 0.0003 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0005 - Val accuracy: 1.0000 - Val loss: 0.0002 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0007 - Val accuracy: 1.0000 - Val loss: 0.0002 - LR: 0.00e+00\n","\tBest epoch: 98 - Best val accuracy: 1.0000 - Best val loss: 0.0002\n","\n","Source class: WAL | Domain: 73 | Accuracy: 0.8537 | Loss: 0.3332\n","\n","Domain: 74\n","x_syn_dom.shape: (333, 3, 128) | np.unique(y_syn_dom): [1 2 3]\n","x_dp_dom.shape: (35, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Training on synthetic data...\n","\tEpoch 10/100 - Train loss: 0.0157 - Val accuracy: 1.0000 - Val loss: 0.0060 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.0045 - Val accuracy: 1.0000 - Val loss: 0.0016 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.0043 - Val accuracy: 1.0000 - Val loss: 0.0006 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.0005 - Val accuracy: 1.0000 - Val loss: 0.0004 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.0005 - Val accuracy: 1.0000 - Val loss: 0.0002 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.0012 - Val accuracy: 1.0000 - Val loss: 0.0002 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0008 - Val accuracy: 1.0000 - Val loss: 0.0002 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0006 - Val accuracy: 1.0000 - Val loss: 0.0001 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0005 - Val accuracy: 1.0000 - Val loss: 0.0001 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0003 - Val accuracy: 1.0000 - Val loss: 0.0001 - LR: 0.00e+00\n","\tBest epoch: 94 - Best val accuracy: 1.0000 - Best val loss: 0.0001\n","\n","Source class: WAL | Domain: 74 | Accuracy: 0.8000 | Loss: 1.2066\n","\n","Domain: 75\n","x_syn_dom.shape: (333, 3, 128) | np.unique(y_syn_dom): [1 2 3]\n","x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Training on synthetic data...\n","\tEpoch 10/100 - Train loss: 0.0134 - Val accuracy: 1.0000 - Val loss: 0.0075 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.0048 - Val accuracy: 1.0000 - Val loss: 0.0021 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.0016 - Val accuracy: 1.0000 - Val loss: 0.0009 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.0024 - Val accuracy: 1.0000 - Val loss: 0.0006 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.0014 - Val accuracy: 1.0000 - Val loss: 0.0004 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.0007 - Val accuracy: 1.0000 - Val loss: 0.0002 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0009 - Val accuracy: 1.0000 - Val loss: 0.0002 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0004 - Val accuracy: 1.0000 - Val loss: 0.0002 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0005 - Val accuracy: 1.0000 - Val loss: 0.0002 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0004 - Val accuracy: 1.0000 - Val loss: 0.0002 - LR: 0.00e+00\n","\tBest epoch: 93 - Best val accuracy: 1.0000 - Best val loss: 0.0001\n","\n","Source class: WAL | Domain: 75 | Accuracy: 0.7381 | Loss: 0.9667\n","\n","Mean accuracy: 0.7911\n","\n"]}],"source":["def compute_TSTR_Syn(dataset):\n","    accs = []\n","\n","    for src_class in config[dataset]['class_names']:\n","        if src_class != 'WAL':\n","            continue\n","\n","        print(f\"Source class: {src_class}\\n\")\n","\n","        for domain in range(config[dataset]['num_df_domains'], config[dataset]['num_df_domains'] + config[dataset]['num_dp_domains']):\n","            print(f\"Domain: {domain}\")\n","\n","            # Load synthetic data\n","            x_syn_dom, y_syn_dom, k_syn_dom = get_syn_data(dataset, syn_name, src_class, domain)\n","            print(f'x_syn_dom.shape: {x_syn_dom.shape} | np.unique(y_syn_dom): {np.unique(y_syn_dom)}')\n","\n","            # Load Dp data\n","            x_dp_dom, y_dp_dom, k_dp_dom = get_data(dataset, 'dp', src_class, domain)\n","            print(f'x_dp_dom.shape: {x_dp_dom.shape} | np.unique(y_dp_dom): {np.unique(y_dp_dom)}\\n')\n","\n","            # Train on synthetic data and evaluate on Dp data\n","            print('Training on synthetic data...')\n","            acc, loss = train_and_test(x_syn_dom, y_syn_dom, x_dp_dom, y_dp_dom, dataset, num_epochs=100)\n","            save_scores(src_class, domain, acc, loss, 'Syn', dataset)\n","            accs.append(acc)\n","            print(f'Source class: {src_class} | Domain: {domain} | Accuracy: {acc:.4f} | Loss: {loss:.4f}\\n')\n","\n","    print(f\"Mean accuracy: {np.mean(accs):.4f}\\n\")\n","\n","\n","\n","\n","compute_TSTR_Syn('realworld_mobiact')"]},{"cell_type":"code","execution_count":7,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":183596,"status":"ok","timestamp":1731667495712,"user":{"displayName":"Pietro ST","userId":"01777116294553213330"},"user_tz":-60},"id":"KKvjK_PAMxLm","outputId":"a8f4a454-ad2a-4523-f444-2f99883adada"},"outputs":[{"output_type":"stream","name":"stdout","text":["Source class: WAL\n","\n","x_syn.shape: (30921, 3, 128) | np.unique(y_syn): [1 2 3]\n","x_dp.shape: (2814, 3, 128) | np.unique(y_dp): [1 2 3]\n","\n","Training on synthetic data...\n","\tEpoch 10/100 - Train loss: 0.0008 - Val accuracy: 1.0000 - Val loss: 0.0001 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.0005 - Val accuracy: 1.0000 - Val loss: 0.0000 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.0000 - Val accuracy: 1.0000 - Val loss: 0.0000 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.0000 - Val accuracy: 1.0000 - Val loss: 0.0000 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.0000 - Val accuracy: 1.0000 - Val loss: 0.0000 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.0000 - Val accuracy: 1.0000 - Val loss: 0.0002 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0000 - Val accuracy: 1.0000 - Val loss: 0.0000 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0000 - Val accuracy: 1.0000 - Val loss: 0.0000 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0000 - Val accuracy: 1.0000 - Val loss: 0.0000 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0000 - Val accuracy: 1.0000 - Val loss: 0.0000 - LR: 0.00e+00\n","\tBest epoch: 91 - Best val accuracy: 1.0000 - Best val loss: 0.0000\n","\n","Source class: WAL | Domain: All | Accuracy: 0.8209 | Loss: 1.4932\n","\n","Mean accuracy: 0.8209\n","\n"]}],"source":["def compute_TSTR_Syn_all(dataset):\n","    accs = []\n","\n","    for src_class in config[dataset]['class_names']:\n","        if src_class != 'WAL':\n","            continue\n","\n","        print(f\"Source class: {src_class}\\n\")\n","\n","        # Load synthetic data\n","        x_syn, y_syn, k_syn = get_syn_data(dataset, syn_name, src_class)\n","        print(f'x_syn.shape: {x_syn.shape} | np.unique(y_syn): {np.unique(y_syn)}')\n","\n","        # Load Dp data\n","        x_dp, y_dp, k_dp = get_data(dataset, 'dp', src_class)\n","        print(f'x_dp.shape: {x_dp.shape} | np.unique(y_dp): {np.unique(y_dp)}\\n')\n","\n","        # Train on synthetic data and evaluate on Dp data\n","        print('Training on synthetic data...')\n","        acc, loss = train_and_test(x_syn, y_syn, x_dp, y_dp, dataset, num_epochs=100)\n","        save_scores(src_class, 100, acc, loss, 'Syn_all', dataset)\n","        accs.append(acc)\n","        print(f'Source class: {src_class} | Domain: All | Accuracy: {acc:.4f} | Loss: {loss:.4f}\\n')\n","\n","    print(f\"Mean accuracy: {np.mean(accs):.4f}\\n\")\n","\n","\n","\n","\n","compute_TSTR_Syn_all('realworld_mobiact')"]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":367610,"status":"ok","timestamp":1731667132010,"user":{"displayName":"Pietro ST","userId":"01777116294553213330"},"user_tz":-60},"id":"LA71th1bCPto","outputId":"6720c3de-1024-41e9-b376-c4c8a93c4bb5"},"outputs":[{"output_type":"stream","name":"stdout","text":["Source class: WAL\n","\n","x_df.shape: (7958, 3, 128) | np.unique(y_df): [1 2 3]\n","\n","Training on Df data...\n","\tEpoch 10/100 - Train loss: 0.0377 - Val accuracy: 0.9805 - Val loss: 0.0508 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.0132 - Val accuracy: 0.9837 - Val loss: 0.0430 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.0050 - Val accuracy: 0.9862 - Val loss: 0.0393 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.0016 - Val accuracy: 0.9849 - Val loss: 0.0444 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.0014 - Val accuracy: 0.9868 - Val loss: 0.0500 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.0008 - Val accuracy: 0.9874 - Val loss: 0.0438 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0007 - Val accuracy: 0.9874 - Val loss: 0.0467 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0003 - Val accuracy: 0.9868 - Val loss: 0.0491 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0003 - Val accuracy: 0.9862 - Val loss: 0.0520 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0002 - Val accuracy: 0.9868 - Val loss: 0.0506 - LR: 0.00e+00\n","\tBest epoch: 22 - Best val accuracy: 0.9856 - Best val loss: 0.0367\n","\n","Domain: 15\n","x_syn_dom.shape: (333, 3, 128) | np.unique(y_syn_dom): [1 2 3]\n","x_dp_dom.shape: (50, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Fine-tuning on synthetic data...\n","\tEpoch 10/100 - Train loss: 0.3214 - Val accuracy: 0.8507 - Val loss: 0.4297 - LR: 9.00e-06\n","\tEpoch 20/100 - Train loss: 0.2847 - Val accuracy: 0.8657 - Val loss: 0.3451 - LR: 8.00e-06\n","\tEpoch 30/100 - Train loss: 0.2653 - Val accuracy: 0.8955 - Val loss: 0.2902 - LR: 7.00e-06\n","\tEpoch 40/100 - Train loss: 0.2385 - Val accuracy: 0.8955 - Val loss: 0.2622 - LR: 6.00e-06\n","\tEpoch 50/100 - Train loss: 0.2400 - Val accuracy: 0.9254 - Val loss: 0.2424 - LR: 5.00e-06\n","\tEpoch 60/100 - Train loss: 0.2836 - Val accuracy: 0.9254 - Val loss: 0.2105 - LR: 4.00e-06\n","\tEpoch 70/100 - Train loss: 0.1992 - Val accuracy: 0.9104 - Val loss: 0.2104 - LR: 3.00e-06\n","\tEpoch 80/100 - Train loss: 0.1944 - Val accuracy: 0.9254 - Val loss: 0.1941 - LR: 2.00e-06\n","\tEpoch 90/100 - Train loss: 0.1894 - Val accuracy: 0.9254 - Val loss: 0.1836 - LR: 1.00e-06\n","\tEpoch 100/100 - Train loss: 0.1750 - Val accuracy: 0.9403 - Val loss: 0.1875 - LR: 0.00e+00\n","\tBest epoch: 95 - Best val accuracy: 0.9403 - Best val loss: 0.1783\n","\n","Source class: WAL | Domain: 15 | Accuracy: 0.7000 | Loss: 3.4751\n","\n","Domain: 16\n","x_syn_dom.shape: (333, 3, 128) | np.unique(y_syn_dom): [1 2 3]\n","x_dp_dom.shape: (54, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Fine-tuning on synthetic data...\n","\tEpoch 10/100 - Train loss: 0.3494 - Val accuracy: 0.8806 - Val loss: 0.2531 - LR: 9.00e-06\n","\tEpoch 20/100 - Train loss: 0.2167 - Val accuracy: 0.8955 - Val loss: 0.1933 - LR: 8.00e-06\n","\tEpoch 30/100 - Train loss: 0.1982 - Val accuracy: 0.9254 - Val loss: 0.1593 - LR: 7.00e-06\n","\tEpoch 40/100 - Train loss: 0.1896 - Val accuracy: 0.9403 - Val loss: 0.1406 - LR: 6.00e-06\n","\tEpoch 50/100 - Train loss: 0.0984 - Val accuracy: 0.9403 - Val loss: 0.1349 - LR: 5.00e-06\n","\tEpoch 60/100 - Train loss: 0.0660 - Val accuracy: 0.9403 - Val loss: 0.1212 - LR: 4.00e-06\n","\tEpoch 70/100 - Train loss: 0.1559 - Val accuracy: 0.9403 - Val loss: 0.1180 - LR: 3.00e-06\n","\tEpoch 80/100 - Train loss: 0.1588 - Val accuracy: 0.9552 - Val loss: 0.0918 - LR: 2.00e-06\n","\tEpoch 90/100 - Train loss: 0.1213 - Val accuracy: 0.9552 - Val loss: 0.1035 - LR: 1.00e-06\n","\tEpoch 100/100 - Train loss: 0.1921 - Val accuracy: 0.9552 - Val loss: 0.1059 - LR: 0.00e+00\n","\tBest epoch: 98 - Best val accuracy: 0.9552 - Best val loss: 0.0826\n","\n","Source class: WAL | Domain: 16 | Accuracy: 0.7407 | Loss: 1.1803\n","\n","Domain: 17\n","x_syn_dom.shape: (333, 3, 128) | np.unique(y_syn_dom): [1 2 3]\n","x_dp_dom.shape: (53, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Fine-tuning on synthetic data...\n","\tEpoch 10/100 - Train loss: 0.0810 - Val accuracy: 0.9552 - Val loss: 0.1379 - LR: 9.00e-06\n","\tEpoch 20/100 - Train loss: 0.1013 - Val accuracy: 0.9552 - Val loss: 0.1345 - LR: 8.00e-06\n","\tEpoch 30/100 - Train loss: 0.0700 - Val accuracy: 0.9552 - Val loss: 0.1266 - LR: 7.00e-06\n","\tEpoch 40/100 - Train loss: 0.0379 - Val accuracy: 0.9552 - Val loss: 0.1115 - LR: 6.00e-06\n","\tEpoch 50/100 - Train loss: 0.0745 - Val accuracy: 0.9552 - Val loss: 0.1272 - LR: 5.00e-06\n","\tEpoch 60/100 - Train loss: 0.0483 - Val accuracy: 0.9552 - Val loss: 0.1207 - LR: 4.00e-06\n","\tEpoch 70/100 - Train loss: 0.0401 - Val accuracy: 0.9552 - Val loss: 0.1165 - LR: 3.00e-06\n","\tEpoch 80/100 - Train loss: 0.0443 - Val accuracy: 0.9552 - Val loss: 0.1199 - LR: 2.00e-06\n","\tEpoch 90/100 - Train loss: 0.0335 - Val accuracy: 0.9552 - Val loss: 0.1021 - LR: 1.00e-06\n","\tEpoch 100/100 - Train loss: 0.0318 - Val accuracy: 0.9552 - Val loss: 0.1045 - LR: 0.00e+00\n","\tBest epoch: 89 - Best val accuracy: 0.9701 - Best val loss: 0.0951\n","\n","Source class: WAL | Domain: 17 | Accuracy: 0.7736 | Loss: 2.1639\n","\n","Domain: 18\n","x_syn_dom.shape: (336, 3, 128) | np.unique(y_syn_dom): [1 2 3]\n","x_dp_dom.shape: (54, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Fine-tuning on synthetic data...\n","\tEpoch 10/100 - Train loss: 0.0452 - Val accuracy: 0.9706 - Val loss: 0.0747 - LR: 9.00e-06\n","\tEpoch 20/100 - Train loss: 0.0537 - Val accuracy: 0.9853 - Val loss: 0.0595 - LR: 8.00e-06\n","\tEpoch 30/100 - Train loss: 0.0848 - Val accuracy: 0.9853 - Val loss: 0.0516 - LR: 7.00e-06\n","\tEpoch 40/100 - Train loss: 0.1178 - Val accuracy: 0.9853 - Val loss: 0.0548 - LR: 6.00e-06\n","\tEpoch 50/100 - Train loss: 0.0323 - Val accuracy: 0.9853 - Val loss: 0.0442 - LR: 5.00e-06\n","\tEpoch 60/100 - Train loss: 0.0325 - Val accuracy: 0.9853 - Val loss: 0.0440 - LR: 4.00e-06\n","\tEpoch 70/100 - Train loss: 0.0677 - Val accuracy: 0.9853 - Val loss: 0.0406 - LR: 3.00e-06\n","\tEpoch 80/100 - Train loss: 0.0618 - Val accuracy: 0.9853 - Val loss: 0.0340 - LR: 2.00e-06\n","\tEpoch 90/100 - Train loss: 0.0426 - Val accuracy: 0.9853 - Val loss: 0.0366 - LR: 1.00e-06\n","\tEpoch 100/100 - Train loss: 0.0854 - Val accuracy: 0.9853 - Val loss: 0.0298 - LR: 0.00e+00\n","\tBest epoch: 85 - Best val accuracy: 0.9853 - Best val loss: 0.0237\n","\n","Source class: WAL | Domain: 18 | Accuracy: 0.7037 | Loss: 3.8293\n","\n","Domain: 19\n","x_syn_dom.shape: (333, 3, 128) | np.unique(y_syn_dom): [1 2 3]\n","x_dp_dom.shape: (54, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Fine-tuning on synthetic data...\n","\tEpoch 10/100 - Train loss: 0.1344 - Val accuracy: 0.9403 - Val loss: 0.2260 - LR: 9.00e-06\n","\tEpoch 20/100 - Train loss: 0.2027 - Val accuracy: 0.9403 - Val loss: 0.1936 - LR: 8.00e-06\n","\tEpoch 30/100 - Train loss: 0.2074 - Val accuracy: 0.9552 - Val loss: 0.1680 - LR: 7.00e-06\n","\tEpoch 40/100 - Train loss: 0.1481 - Val accuracy: 0.9552 - Val loss: 0.1731 - LR: 6.00e-06\n","\tEpoch 50/100 - Train loss: 0.0822 - Val accuracy: 0.9552 - Val loss: 0.1468 - LR: 5.00e-06\n","\tEpoch 60/100 - Train loss: 0.0692 - Val accuracy: 0.9552 - Val loss: 0.1314 - LR: 4.00e-06\n","\tEpoch 70/100 - Train loss: 0.1114 - Val accuracy: 0.9552 - Val loss: 0.1465 - LR: 3.00e-06\n","\tEpoch 80/100 - Train loss: 0.1070 - Val accuracy: 0.9552 - Val loss: 0.1261 - LR: 2.00e-06\n","\tEpoch 90/100 - Train loss: 0.0657 - Val accuracy: 0.9552 - Val loss: 0.1161 - LR: 1.00e-06\n","\tEpoch 100/100 - Train loss: 0.0941 - Val accuracy: 0.9552 - Val loss: 0.1043 - LR: 0.00e+00\n","\tBest epoch: 100 - Best val accuracy: 0.9552 - Best val loss: 0.1043\n","\n","Source class: WAL | Domain: 19 | Accuracy: 0.7222 | Loss: 2.4749\n","\n","Domain: 20\n","x_syn_dom.shape: (333, 3, 128) | np.unique(y_syn_dom): [1 2 3]\n","x_dp_dom.shape: (51, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Fine-tuning on synthetic data...\n","\tEpoch 10/100 - Train loss: 0.1862 - Val accuracy: 0.9403 - Val loss: 0.2432 - LR: 9.00e-06\n","\tEpoch 20/100 - Train loss: 0.2165 - Val accuracy: 0.9552 - Val loss: 0.2111 - LR: 8.00e-06\n","\tEpoch 30/100 - Train loss: 0.1786 - Val accuracy: 0.9552 - Val loss: 0.1966 - LR: 7.00e-06\n","\tEpoch 40/100 - Train loss: 0.1464 - Val accuracy: 0.9552 - Val loss: 0.1605 - LR: 6.00e-06\n","\tEpoch 50/100 - Train loss: 0.1137 - Val accuracy: 0.9552 - Val loss: 0.1669 - LR: 5.00e-06\n","\tEpoch 60/100 - Train loss: 0.1479 - Val accuracy: 0.9552 - Val loss: 0.1491 - LR: 4.00e-06\n","\tEpoch 70/100 - Train loss: 0.1383 - Val accuracy: 0.9552 - Val loss: 0.1486 - LR: 3.00e-06\n","\tEpoch 80/100 - Train loss: 0.1084 - Val accuracy: 0.9552 - Val loss: 0.1327 - LR: 2.00e-06\n","\tEpoch 90/100 - Train loss: 0.1182 - Val accuracy: 0.9552 - Val loss: 0.1358 - LR: 1.00e-06\n","\tEpoch 100/100 - Train loss: 0.1202 - Val accuracy: 0.9701 - Val loss: 0.1264 - LR: 0.00e+00\n","\tBest epoch: 79 - Best val accuracy: 0.9701 - Best val loss: 0.1241\n","\n","Source class: WAL | Domain: 20 | Accuracy: 0.9608 | Loss: 0.2099\n","\n","Domain: 21\n","x_syn_dom.shape: (336, 3, 128) | np.unique(y_syn_dom): [1 2 3]\n","x_dp_dom.shape: (47, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Fine-tuning on synthetic data...\n","\tEpoch 10/100 - Train loss: 0.2563 - Val accuracy: 0.9706 - Val loss: 0.0653 - LR: 9.00e-06\n","\tEpoch 20/100 - Train loss: 0.2450 - Val accuracy: 0.9706 - Val loss: 0.0657 - LR: 8.00e-06\n","\tEpoch 30/100 - Train loss: 0.1516 - Val accuracy: 0.9706 - Val loss: 0.0481 - LR: 7.00e-06\n","\tEpoch 40/100 - Train loss: 0.1913 - Val accuracy: 0.9706 - Val loss: 0.0441 - LR: 6.00e-06\n","\tEpoch 50/100 - Train loss: 0.1216 - Val accuracy: 0.9706 - Val loss: 0.0388 - LR: 5.00e-06\n","\tEpoch 60/100 - Train loss: 0.1191 - Val accuracy: 0.9706 - Val loss: 0.0377 - LR: 4.00e-06\n","\tEpoch 70/100 - Train loss: 0.1292 - Val accuracy: 0.9706 - Val loss: 0.0342 - LR: 3.00e-06\n","\tEpoch 80/100 - Train loss: 0.0840 - Val accuracy: 0.9706 - Val loss: 0.0377 - LR: 2.00e-06\n","\tEpoch 90/100 - Train loss: 0.1083 - Val accuracy: 0.9706 - Val loss: 0.0314 - LR: 1.00e-06\n","\tEpoch 100/100 - Train loss: 0.0810 - Val accuracy: 0.9706 - Val loss: 0.0377 - LR: 0.00e+00\n","\tBest epoch: 68 - Best val accuracy: 0.9853 - Best val loss: 0.0276\n","\n","Source class: WAL | Domain: 21 | Accuracy: 0.8723 | Loss: 1.1904\n","\n","Domain: 22\n","x_syn_dom.shape: (333, 3, 128) | np.unique(y_syn_dom): [1 2 3]\n","x_dp_dom.shape: (54, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Fine-tuning on synthetic data...\n","\tEpoch 10/100 - Train loss: 0.4030 - Val accuracy: 0.9552 - Val loss: 0.1191 - LR: 9.00e-06\n","\tEpoch 20/100 - Train loss: 0.3232 - Val accuracy: 0.9552 - Val loss: 0.0961 - LR: 8.00e-06\n","\tEpoch 30/100 - Train loss: 0.3599 - Val accuracy: 0.9701 - Val loss: 0.0800 - LR: 7.00e-06\n","\tEpoch 40/100 - Train loss: 0.1847 - Val accuracy: 0.9851 - Val loss: 0.0745 - LR: 6.00e-06\n","\tEpoch 50/100 - Train loss: 0.3455 - Val accuracy: 0.9701 - Val loss: 0.0631 - LR: 5.00e-06\n","\tEpoch 60/100 - Train loss: 0.1857 - Val accuracy: 0.9701 - Val loss: 0.0522 - LR: 4.00e-06\n","\tEpoch 70/100 - Train loss: 0.1258 - Val accuracy: 0.9851 - Val loss: 0.0554 - LR: 3.00e-06\n","\tEpoch 80/100 - Train loss: 0.1697 - Val accuracy: 0.9851 - Val loss: 0.0503 - LR: 2.00e-06\n","\tEpoch 90/100 - Train loss: 0.1376 - Val accuracy: 0.9851 - Val loss: 0.0521 - LR: 1.00e-06\n","\tEpoch 100/100 - Train loss: 0.1909 - Val accuracy: 0.9851 - Val loss: 0.0441 - LR: 0.00e+00\n","\tBest epoch: 98 - Best val accuracy: 0.9851 - Best val loss: 0.0427\n","\n","Source class: WAL | Domain: 22 | Accuracy: 0.7407 | Loss: 1.9205\n","\n","Domain: 23\n","x_syn_dom.shape: (336, 3, 128) | np.unique(y_syn_dom): [1 2 3]\n","x_dp_dom.shape: (52, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Fine-tuning on synthetic data...\n","\tEpoch 10/100 - Train loss: 2.3611 - Val accuracy: 0.6765 - Val loss: 3.0240 - LR: 9.00e-06\n","\tEpoch 20/100 - Train loss: 1.9454 - Val accuracy: 0.6324 - Val loss: 2.5016 - LR: 8.00e-06\n","\tEpoch 30/100 - Train loss: 1.7440 - Val accuracy: 0.6471 - Val loss: 2.1188 - LR: 7.00e-06\n","\tEpoch 40/100 - Train loss: 1.5022 - Val accuracy: 0.6618 - Val loss: 1.6688 - LR: 6.00e-06\n","\tEpoch 50/100 - Train loss: 1.2523 - Val accuracy: 0.6912 - Val loss: 1.3307 - LR: 5.00e-06\n","\tEpoch 60/100 - Train loss: 1.1385 - Val accuracy: 0.6912 - Val loss: 1.2439 - LR: 4.00e-06\n","\tEpoch 70/100 - Train loss: 0.9744 - Val accuracy: 0.7059 - Val loss: 1.0965 - LR: 3.00e-06\n","\tEpoch 80/100 - Train loss: 0.8434 - Val accuracy: 0.7206 - Val loss: 0.9200 - LR: 2.00e-06\n","\tEpoch 90/100 - Train loss: 0.7721 - Val accuracy: 0.7206 - Val loss: 0.8983 - LR: 1.00e-06\n","\tEpoch 100/100 - Train loss: 0.6824 - Val accuracy: 0.7206 - Val loss: 0.8572 - LR: 0.00e+00\n","\tBest epoch: 93 - Best val accuracy: 0.7500 - Best val loss: 0.8405\n","\n","Source class: WAL | Domain: 23 | Accuracy: 0.8077 | Loss: 0.5506\n","\n","Domain: 24\n","x_syn_dom.shape: (333, 3, 128) | np.unique(y_syn_dom): [1 2 3]\n","x_dp_dom.shape: (51, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Fine-tuning on synthetic data...\n","\tEpoch 10/100 - Train loss: 0.0656 - Val accuracy: 1.0000 - Val loss: 0.0111 - LR: 9.00e-06\n","\tEpoch 20/100 - Train loss: 0.1192 - Val accuracy: 1.0000 - Val loss: 0.0075 - LR: 8.00e-06\n","\tEpoch 30/100 - Train loss: 0.0309 - Val accuracy: 1.0000 - Val loss: 0.0084 - LR: 7.00e-06\n","\tEpoch 40/100 - Train loss: 0.0256 - Val accuracy: 1.0000 - Val loss: 0.0117 - LR: 6.00e-06\n","\tEpoch 50/100 - Train loss: 0.0421 - Val accuracy: 1.0000 - Val loss: 0.0083 - LR: 5.00e-06\n","\tEpoch 60/100 - Train loss: 0.0490 - Val accuracy: 1.0000 - Val loss: 0.0088 - LR: 4.00e-06\n","\tEpoch 70/100 - Train loss: 0.0556 - Val accuracy: 1.0000 - Val loss: 0.0108 - LR: 3.00e-06\n","\tEpoch 80/100 - Train loss: 0.0365 - Val accuracy: 1.0000 - Val loss: 0.0081 - LR: 2.00e-06\n","\tEpoch 90/100 - Train loss: 0.0311 - Val accuracy: 1.0000 - Val loss: 0.0098 - LR: 1.00e-06\n","\tEpoch 100/100 - Train loss: 0.0214 - Val accuracy: 1.0000 - Val loss: 0.0102 - LR: 0.00e+00\n","\tBest epoch: 58 - Best val accuracy: 1.0000 - Best val loss: 0.0057\n","\n","Source class: WAL | Domain: 24 | Accuracy: 0.8039 | Loss: 1.1488\n","\n","Domain: 25\n","x_syn_dom.shape: (336, 3, 128) | np.unique(y_syn_dom): [1 2 3]\n","x_dp_dom.shape: (54, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Fine-tuning on synthetic data...\n","\tEpoch 10/100 - Train loss: 0.3836 - Val accuracy: 0.9265 - Val loss: 0.2128 - LR: 9.00e-06\n","\tEpoch 20/100 - Train loss: 0.3164 - Val accuracy: 0.9265 - Val loss: 0.1907 - LR: 8.00e-06\n","\tEpoch 30/100 - Train loss: 0.2866 - Val accuracy: 0.9412 - Val loss: 0.1679 - LR: 7.00e-06\n","\tEpoch 40/100 - Train loss: 0.2402 - Val accuracy: 0.9265 - Val loss: 0.1421 - LR: 6.00e-06\n","\tEpoch 50/100 - Train loss: 0.1774 - Val accuracy: 0.9265 - Val loss: 0.1240 - LR: 5.00e-06\n","\tEpoch 60/100 - Train loss: 0.1902 - Val accuracy: 0.9412 - Val loss: 0.1200 - LR: 4.00e-06\n","\tEpoch 70/100 - Train loss: 0.1385 - Val accuracy: 0.9412 - Val loss: 0.1184 - LR: 3.00e-06\n","\tEpoch 80/100 - Train loss: 0.1924 - Val accuracy: 0.9412 - Val loss: 0.1054 - LR: 2.00e-06\n","\tEpoch 90/100 - Train loss: 0.1693 - Val accuracy: 0.9412 - Val loss: 0.1018 - LR: 1.00e-06\n","\tEpoch 100/100 - Train loss: 0.2244 - Val accuracy: 0.9412 - Val loss: 0.1086 - LR: 0.00e+00\n","\tBest epoch: 92 - Best val accuracy: 0.9412 - Best val loss: 0.0984\n","\n","Source class: WAL | Domain: 25 | Accuracy: 0.7407 | Loss: 2.9150\n","\n","Domain: 26\n","x_syn_dom.shape: (333, 3, 128) | np.unique(y_syn_dom): [1 2 3]\n","x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Fine-tuning on synthetic data...\n","\tEpoch 10/100 - Train loss: 0.1190 - Val accuracy: 0.9851 - Val loss: 0.0606 - LR: 9.00e-06\n","\tEpoch 20/100 - Train loss: 0.0847 - Val accuracy: 0.9851 - Val loss: 0.0567 - LR: 8.00e-06\n","\tEpoch 30/100 - Train loss: 0.0905 - Val accuracy: 0.9851 - Val loss: 0.0480 - LR: 7.00e-06\n","\tEpoch 40/100 - Train loss: 0.0671 - Val accuracy: 0.9851 - Val loss: 0.0401 - LR: 6.00e-06\n","\tEpoch 50/100 - Train loss: 0.1318 - Val accuracy: 0.9851 - Val loss: 0.0407 - LR: 5.00e-06\n","\tEpoch 60/100 - Train loss: 0.0783 - Val accuracy: 0.9851 - Val loss: 0.0389 - LR: 4.00e-06\n","\tEpoch 70/100 - Train loss: 0.1267 - Val accuracy: 0.9851 - Val loss: 0.0385 - LR: 3.00e-06\n","\tEpoch 80/100 - Train loss: 0.1068 - Val accuracy: 0.9851 - Val loss: 0.0396 - LR: 2.00e-06\n","\tEpoch 90/100 - Train loss: 0.0742 - Val accuracy: 0.9851 - Val loss: 0.0346 - LR: 1.00e-06\n","\tEpoch 100/100 - Train loss: 0.0502 - Val accuracy: 0.9851 - Val loss: 0.0421 - LR: 0.00e+00\n","\tBest epoch: 97 - Best val accuracy: 0.9851 - Best val loss: 0.0314\n","\n","Source class: WAL | Domain: 26 | Accuracy: 0.9286 | Loss: 0.1401\n","\n","Domain: 27\n","x_syn_dom.shape: (333, 3, 128) | np.unique(y_syn_dom): [1 2 3]\n","x_dp_dom.shape: (54, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Fine-tuning on synthetic data...\n","\tEpoch 10/100 - Train loss: 0.3408 - Val accuracy: 0.9552 - Val loss: 0.0804 - LR: 9.00e-06\n","\tEpoch 20/100 - Train loss: 0.3150 - Val accuracy: 0.9851 - Val loss: 0.0636 - LR: 8.00e-06\n","\tEpoch 30/100 - Train loss: 0.2878 - Val accuracy: 0.9851 - Val loss: 0.0548 - LR: 7.00e-06\n","\tEpoch 40/100 - Train loss: 0.1879 - Val accuracy: 0.9851 - Val loss: 0.0442 - LR: 6.00e-06\n","\tEpoch 50/100 - Train loss: 0.2747 - Val accuracy: 0.9851 - Val loss: 0.0427 - LR: 5.00e-06\n","\tEpoch 60/100 - Train loss: 0.2198 - Val accuracy: 0.9851 - Val loss: 0.0362 - LR: 4.00e-06\n","\tEpoch 70/100 - Train loss: 0.2666 - Val accuracy: 0.9851 - Val loss: 0.0345 - LR: 3.00e-06\n","\tEpoch 80/100 - Train loss: 0.2156 - Val accuracy: 0.9851 - Val loss: 0.0368 - LR: 2.00e-06\n","\tEpoch 90/100 - Train loss: 0.1832 - Val accuracy: 0.9851 - Val loss: 0.0337 - LR: 1.00e-06\n","\tEpoch 100/100 - Train loss: 0.2294 - Val accuracy: 0.9851 - Val loss: 0.0341 - LR: 0.00e+00\n","\tBest epoch: 96 - Best val accuracy: 0.9851 - Best val loss: 0.0289\n","\n","Source class: WAL | Domain: 27 | Accuracy: 0.7593 | Loss: 3.7537\n","\n","Domain: 28\n","x_syn_dom.shape: (333, 3, 128) | np.unique(y_syn_dom): [1 2 3]\n","x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Fine-tuning on synthetic data...\n","\tEpoch 10/100 - Train loss: 0.2528 - Val accuracy: 0.9552 - Val loss: 0.0635 - LR: 9.00e-06\n","\tEpoch 20/100 - Train loss: 0.2190 - Val accuracy: 0.9851 - Val loss: 0.0438 - LR: 8.00e-06\n","\tEpoch 30/100 - Train loss: 0.1828 - Val accuracy: 1.0000 - Val loss: 0.0273 - LR: 7.00e-06\n","\tEpoch 40/100 - Train loss: 0.1795 - Val accuracy: 1.0000 - Val loss: 0.0248 - LR: 6.00e-06\n","\tEpoch 50/100 - Train loss: 0.1322 - Val accuracy: 0.9851 - Val loss: 0.0276 - LR: 5.00e-06\n","\tEpoch 60/100 - Train loss: 0.1635 - Val accuracy: 0.9851 - Val loss: 0.0226 - LR: 4.00e-06\n","\tEpoch 70/100 - Train loss: 0.1129 - Val accuracy: 0.9851 - Val loss: 0.0230 - LR: 3.00e-06\n","\tEpoch 80/100 - Train loss: 0.1906 - Val accuracy: 0.9851 - Val loss: 0.0221 - LR: 2.00e-06\n","\tEpoch 90/100 - Train loss: 0.1047 - Val accuracy: 0.9851 - Val loss: 0.0204 - LR: 1.00e-06\n","\tEpoch 100/100 - Train loss: 0.1229 - Val accuracy: 1.0000 - Val loss: 0.0169 - LR: 0.00e+00\n","\tBest epoch: 83 - Best val accuracy: 1.0000 - Best val loss: 0.0144\n","\n","Source class: WAL | Domain: 28 | Accuracy: 0.8810 | Loss: 0.9172\n","\n","Domain: 29\n","x_syn_dom.shape: (333, 3, 128) | np.unique(y_syn_dom): [1 2 3]\n","x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Fine-tuning on synthetic data...\n","\tEpoch 10/100 - Train loss: 0.2607 - Val accuracy: 0.9403 - Val loss: 0.2308 - LR: 9.00e-06\n","\tEpoch 20/100 - Train loss: 0.1602 - Val accuracy: 0.9403 - Val loss: 0.2099 - LR: 8.00e-06\n","\tEpoch 30/100 - Train loss: 0.1798 - Val accuracy: 0.9552 - Val loss: 0.1829 - LR: 7.00e-06\n","\tEpoch 40/100 - Train loss: 0.1180 - Val accuracy: 0.9403 - Val loss: 0.1630 - LR: 6.00e-06\n","\tEpoch 50/100 - Train loss: 0.1126 - Val accuracy: 0.9552 - Val loss: 0.1435 - LR: 5.00e-06\n","\tEpoch 60/100 - Train loss: 0.1769 - Val accuracy: 0.9552 - Val loss: 0.1278 - LR: 4.00e-06\n","\tEpoch 70/100 - Train loss: 0.1042 - Val accuracy: 0.9552 - Val loss: 0.1209 - LR: 3.00e-06\n","\tEpoch 80/100 - Train loss: 0.1947 - Val accuracy: 0.9552 - Val loss: 0.1086 - LR: 2.00e-06\n","\tEpoch 90/100 - Train loss: 0.1275 - Val accuracy: 0.9552 - Val loss: 0.1147 - LR: 1.00e-06\n","\tEpoch 100/100 - Train loss: 0.1039 - Val accuracy: 0.9552 - Val loss: 0.1137 - LR: 0.00e+00\n","\tBest epoch: 99 - Best val accuracy: 0.9552 - Best val loss: 0.0944\n","\n","Source class: WAL | Domain: 29 | Accuracy: 0.5952 | Loss: 2.6715\n","\n","Domain: 30\n","x_syn_dom.shape: (333, 3, 128) | np.unique(y_syn_dom): [1 2 3]\n","x_dp_dom.shape: (50, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Fine-tuning on synthetic data...\n","\tEpoch 10/100 - Train loss: 0.2693 - Val accuracy: 0.8657 - Val loss: 0.3393 - LR: 9.00e-06\n","\tEpoch 20/100 - Train loss: 0.2310 - Val accuracy: 0.8806 - Val loss: 0.3270 - LR: 8.00e-06\n","\tEpoch 30/100 - Train loss: 0.1924 - Val accuracy: 0.8806 - Val loss: 0.3020 - LR: 7.00e-06\n","\tEpoch 40/100 - Train loss: 0.2099 - Val accuracy: 0.8806 - Val loss: 0.3005 - LR: 6.00e-06\n","\tEpoch 50/100 - Train loss: 0.2921 - Val accuracy: 0.8955 - Val loss: 0.2867 - LR: 5.00e-06\n","\tEpoch 60/100 - Train loss: 0.1712 - Val accuracy: 0.8806 - Val loss: 0.2915 - LR: 4.00e-06\n","\tEpoch 70/100 - Train loss: 0.1659 - Val accuracy: 0.8955 - Val loss: 0.2861 - LR: 3.00e-06\n","\tEpoch 80/100 - Train loss: 0.3261 - Val accuracy: 0.8955 - Val loss: 0.2728 - LR: 2.00e-06\n","\tEpoch 90/100 - Train loss: 0.2017 - Val accuracy: 0.8806 - Val loss: 0.2753 - LR: 1.00e-06\n","\tEpoch 100/100 - Train loss: 0.1895 - Val accuracy: 0.8806 - Val loss: 0.2827 - LR: 0.00e+00\n","\tBest epoch: 78 - Best val accuracy: 0.8806 - Best val loss: 0.2724\n","\n","Source class: WAL | Domain: 30 | Accuracy: 0.5200 | Loss: 4.2020\n","\n","Domain: 31\n","x_syn_dom.shape: (333, 3, 128) | np.unique(y_syn_dom): [1 2 3]\n","x_dp_dom.shape: (43, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Fine-tuning on synthetic data...\n","\tEpoch 10/100 - Train loss: 0.0617 - Val accuracy: 0.9403 - Val loss: 0.1046 - LR: 9.00e-06\n","\tEpoch 20/100 - Train loss: 0.0371 - Val accuracy: 0.9851 - Val loss: 0.0424 - LR: 8.00e-06\n","\tEpoch 30/100 - Train loss: 0.0272 - Val accuracy: 0.9851 - Val loss: 0.0263 - LR: 7.00e-06\n","\tEpoch 40/100 - Train loss: 0.0424 - Val accuracy: 1.0000 - Val loss: 0.0103 - LR: 6.00e-06\n","\tEpoch 50/100 - Train loss: 0.0858 - Val accuracy: 0.9851 - Val loss: 0.0181 - LR: 5.00e-06\n","\tEpoch 60/100 - Train loss: 0.0093 - Val accuracy: 1.0000 - Val loss: 0.0142 - LR: 4.00e-06\n","\tEpoch 70/100 - Train loss: 0.0457 - Val accuracy: 1.0000 - Val loss: 0.0076 - LR: 3.00e-06\n","\tEpoch 80/100 - Train loss: 0.0246 - Val accuracy: 1.0000 - Val loss: 0.0145 - LR: 2.00e-06\n","\tEpoch 90/100 - Train loss: 0.0178 - Val accuracy: 1.0000 - Val loss: 0.0109 - LR: 1.00e-06\n","\tEpoch 100/100 - Train loss: 0.0409 - Val accuracy: 1.0000 - Val loss: 0.0056 - LR: 0.00e+00\n","\tBest epoch: 86 - Best val accuracy: 1.0000 - Best val loss: 0.0047\n","\n","Source class: WAL | Domain: 31 | Accuracy: 0.9302 | Loss: 1.6971\n","\n","Domain: 32\n","x_syn_dom.shape: (333, 3, 128) | np.unique(y_syn_dom): [1 2 3]\n","x_dp_dom.shape: (52, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Fine-tuning on synthetic data...\n","\tEpoch 10/100 - Train loss: 0.4302 - Val accuracy: 0.9254 - Val loss: 0.1845 - LR: 9.00e-06\n","\tEpoch 20/100 - Train loss: 0.2676 - Val accuracy: 0.9254 - Val loss: 0.1433 - LR: 8.00e-06\n","\tEpoch 30/100 - Train loss: 0.3952 - Val accuracy: 0.9254 - Val loss: 0.1154 - LR: 7.00e-06\n","\tEpoch 40/100 - Train loss: 0.2123 - Val accuracy: 0.9403 - Val loss: 0.1039 - LR: 6.00e-06\n","\tEpoch 50/100 - Train loss: 0.1295 - Val accuracy: 0.9552 - Val loss: 0.0916 - LR: 5.00e-06\n","\tEpoch 60/100 - Train loss: 0.1518 - Val accuracy: 0.9552 - Val loss: 0.0798 - LR: 4.00e-06\n","\tEpoch 70/100 - Train loss: 0.2074 - Val accuracy: 0.9701 - Val loss: 0.0798 - LR: 3.00e-06\n","\tEpoch 80/100 - Train loss: 0.2341 - Val accuracy: 0.9701 - Val loss: 0.0767 - LR: 2.00e-06\n","\tEpoch 90/100 - Train loss: 0.2128 - Val accuracy: 0.9701 - Val loss: 0.0717 - LR: 1.00e-06\n","\tEpoch 100/100 - Train loss: 0.2762 - Val accuracy: 0.9701 - Val loss: 0.0716 - LR: 0.00e+00\n","\tBest epoch: 96 - Best val accuracy: 0.9701 - Best val loss: 0.0688\n","\n","Source class: WAL | Domain: 32 | Accuracy: 0.7885 | Loss: 1.8811\n","\n","Domain: 33\n","x_syn_dom.shape: (336, 3, 128) | np.unique(y_syn_dom): [1 2 3]\n","x_dp_dom.shape: (44, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Fine-tuning on synthetic data...\n","\tEpoch 10/100 - Train loss: 0.2600 - Val accuracy: 0.9412 - Val loss: 0.3661 - LR: 9.00e-06\n","\tEpoch 20/100 - Train loss: 0.1819 - Val accuracy: 0.9412 - Val loss: 0.3164 - LR: 8.00e-06\n","\tEpoch 30/100 - Train loss: 0.2145 - Val accuracy: 0.9412 - Val loss: 0.3382 - LR: 7.00e-06\n","\tEpoch 40/100 - Train loss: 0.1221 - Val accuracy: 0.9412 - Val loss: 0.3117 - LR: 6.00e-06\n","\tEpoch 50/100 - Train loss: 0.1987 - Val accuracy: 0.9412 - Val loss: 0.2809 - LR: 5.00e-06\n","\tEpoch 60/100 - Train loss: 0.1560 - Val accuracy: 0.9412 - Val loss: 0.3084 - LR: 4.00e-06\n","\tEpoch 70/100 - Train loss: 0.1302 - Val accuracy: 0.9412 - Val loss: 0.2837 - LR: 3.00e-06\n","\tEpoch 80/100 - Train loss: 0.1189 - Val accuracy: 0.9412 - Val loss: 0.2614 - LR: 2.00e-06\n","\tEpoch 90/100 - Train loss: 0.0906 - Val accuracy: 0.9412 - Val loss: 0.2823 - LR: 1.00e-06\n","\tEpoch 100/100 - Train loss: 0.1512 - Val accuracy: 0.9412 - Val loss: 0.2672 - LR: 0.00e+00\n","\tBest epoch: 78 - Best val accuracy: 0.9412 - Best val loss: 0.2396\n","\n","Source class: WAL | Domain: 33 | Accuracy: 0.8182 | Loss: 0.9233\n","\n","Domain: 34\n","x_syn_dom.shape: (336, 3, 128) | np.unique(y_syn_dom): [1 2 3]\n","x_dp_dom.shape: (49, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Fine-tuning on synthetic data...\n","\tEpoch 10/100 - Train loss: 1.1558 - Val accuracy: 0.8235 - Val loss: 0.6235 - LR: 9.00e-06\n","\tEpoch 20/100 - Train loss: 0.6900 - Val accuracy: 0.8529 - Val loss: 0.4729 - LR: 8.00e-06\n","\tEpoch 30/100 - Train loss: 0.6006 - Val accuracy: 0.8824 - Val loss: 0.4275 - LR: 7.00e-06\n","\tEpoch 40/100 - Train loss: 0.4481 - Val accuracy: 0.8824 - Val loss: 0.3741 - LR: 6.00e-06\n","\tEpoch 50/100 - Train loss: 0.4796 - Val accuracy: 0.8824 - Val loss: 0.3360 - LR: 5.00e-06\n","\tEpoch 60/100 - Train loss: 0.4580 - Val accuracy: 0.8676 - Val loss: 0.3076 - LR: 4.00e-06\n","\tEpoch 70/100 - Train loss: 0.3604 - Val accuracy: 0.8824 - Val loss: 0.2916 - LR: 3.00e-06\n","\tEpoch 80/100 - Train loss: 0.4684 - Val accuracy: 0.8676 - Val loss: 0.2798 - LR: 2.00e-06\n","\tEpoch 90/100 - Train loss: 0.3599 - Val accuracy: 0.8676 - Val loss: 0.2713 - LR: 1.00e-06\n","\tEpoch 100/100 - Train loss: 0.4550 - Val accuracy: 0.8676 - Val loss: 0.2689 - LR: 0.00e+00\n","\tBest epoch: 98 - Best val accuracy: 0.8824 - Best val loss: 0.2615\n","\n","Source class: WAL | Domain: 34 | Accuracy: 0.6122 | Loss: 8.8508\n","\n","Domain: 35\n","x_syn_dom.shape: (333, 3, 128) | np.unique(y_syn_dom): [1 2 3]\n","x_dp_dom.shape: (48, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Fine-tuning on synthetic data...\n","\tEpoch 10/100 - Train loss: 1.7359 - Val accuracy: 0.7015 - Val loss: 2.6851 - LR: 9.00e-06\n","\tEpoch 20/100 - Train loss: 1.5209 - Val accuracy: 0.7612 - Val loss: 2.3159 - LR: 8.00e-06\n","\tEpoch 30/100 - Train loss: 1.2744 - Val accuracy: 0.7910 - Val loss: 2.0335 - LR: 7.00e-06\n","\tEpoch 40/100 - Train loss: 1.0278 - Val accuracy: 0.8209 - Val loss: 1.8043 - LR: 6.00e-06\n","\tEpoch 50/100 - Train loss: 0.9910 - Val accuracy: 0.8209 - Val loss: 1.5426 - LR: 5.00e-06\n","\tEpoch 60/100 - Train loss: 0.8758 - Val accuracy: 0.8358 - Val loss: 1.3940 - LR: 4.00e-06\n","\tEpoch 70/100 - Train loss: 0.8296 - Val accuracy: 0.8358 - Val loss: 1.2599 - LR: 3.00e-06\n","\tEpoch 80/100 - Train loss: 0.8029 - Val accuracy: 0.8507 - Val loss: 1.1580 - LR: 2.00e-06\n","\tEpoch 90/100 - Train loss: 0.7085 - Val accuracy: 0.8507 - Val loss: 1.1328 - LR: 1.00e-06\n","\tEpoch 100/100 - Train loss: 0.7295 - Val accuracy: 0.8507 - Val loss: 1.1056 - LR: 0.00e+00\n","\tBest epoch: 96 - Best val accuracy: 0.8507 - Best val loss: 1.0724\n","\n","Source class: WAL | Domain: 35 | Accuracy: 0.8542 | Loss: 0.9774\n","\n","Domain: 36\n","x_syn_dom.shape: (336, 3, 128) | np.unique(y_syn_dom): [1 2 3]\n","x_dp_dom.shape: (43, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Fine-tuning on synthetic data...\n","\tEpoch 10/100 - Train loss: 0.5156 - Val accuracy: 0.8382 - Val loss: 0.5717 - LR: 9.00e-06\n","\tEpoch 20/100 - Train loss: 0.4316 - Val accuracy: 0.8824 - Val loss: 0.4541 - LR: 8.00e-06\n","\tEpoch 30/100 - Train loss: 0.4087 - Val accuracy: 0.8824 - Val loss: 0.3758 - LR: 7.00e-06\n","\tEpoch 40/100 - Train loss: 0.3077 - Val accuracy: 0.8971 - Val loss: 0.3364 - LR: 6.00e-06\n","\tEpoch 50/100 - Train loss: 0.3297 - Val accuracy: 0.8971 - Val loss: 0.2938 - LR: 5.00e-06\n","\tEpoch 60/100 - Train loss: 0.2577 - Val accuracy: 0.9118 - Val loss: 0.2684 - LR: 4.00e-06\n","\tEpoch 70/100 - Train loss: 0.3158 - Val accuracy: 0.9265 - Val loss: 0.2354 - LR: 3.00e-06\n","\tEpoch 80/100 - Train loss: 0.2831 - Val accuracy: 0.9265 - Val loss: 0.2338 - LR: 2.00e-06\n","\tEpoch 90/100 - Train loss: 0.1929 - Val accuracy: 0.9265 - Val loss: 0.2143 - LR: 1.00e-06\n","\tEpoch 100/100 - Train loss: 0.1817 - Val accuracy: 0.9265 - Val loss: 0.2308 - LR: 0.00e+00\n","\tBest epoch: 91 - Best val accuracy: 0.9265 - Best val loss: 0.1996\n","\n","Source class: WAL | Domain: 36 | Accuracy: 0.8837 | Loss: 0.4985\n","\n","Domain: 37\n","x_syn_dom.shape: (336, 3, 128) | np.unique(y_syn_dom): [1 2 3]\n","x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Fine-tuning on synthetic data...\n","\tEpoch 10/100 - Train loss: 0.1164 - Val accuracy: 0.9853 - Val loss: 0.0225 - LR: 9.00e-06\n","\tEpoch 20/100 - Train loss: 0.0421 - Val accuracy: 0.9853 - Val loss: 0.0218 - LR: 8.00e-06\n","\tEpoch 30/100 - Train loss: 0.0704 - Val accuracy: 0.9853 - Val loss: 0.0220 - LR: 7.00e-06\n","\tEpoch 40/100 - Train loss: 0.0626 - Val accuracy: 0.9853 - Val loss: 0.0349 - LR: 6.00e-06\n","\tEpoch 50/100 - Train loss: 0.0654 - Val accuracy: 0.9853 - Val loss: 0.0227 - LR: 5.00e-06\n","\tEpoch 60/100 - Train loss: 0.0246 - Val accuracy: 0.9853 - Val loss: 0.0179 - LR: 4.00e-06\n","\tEpoch 70/100 - Train loss: 0.0359 - Val accuracy: 0.9853 - Val loss: 0.0172 - LR: 3.00e-06\n","\tEpoch 80/100 - Train loss: 0.0446 - Val accuracy: 0.9853 - Val loss: 0.0253 - LR: 2.00e-06\n","\tEpoch 90/100 - Train loss: 0.0247 - Val accuracy: 0.9853 - Val loss: 0.0237 - LR: 1.00e-06\n","\tEpoch 100/100 - Train loss: 0.0361 - Val accuracy: 0.9853 - Val loss: 0.0284 - LR: 0.00e+00\n","\tBest epoch: 67 - Best val accuracy: 1.0000 - Best val loss: 0.0126\n","\n","Source class: WAL | Domain: 37 | Accuracy: 0.8333 | Loss: 0.8473\n","\n","Domain: 38\n","x_syn_dom.shape: (333, 3, 128) | np.unique(y_syn_dom): [1 2 3]\n","x_dp_dom.shape: (47, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Fine-tuning on synthetic data...\n","\tEpoch 10/100 - Train loss: 1.5989 - Val accuracy: 0.7164 - Val loss: 1.4434 - LR: 9.00e-06\n","\tEpoch 20/100 - Train loss: 1.3017 - Val accuracy: 0.7463 - Val loss: 1.1845 - LR: 8.00e-06\n","\tEpoch 30/100 - Train loss: 1.2068 - Val accuracy: 0.7612 - Val loss: 0.7335 - LR: 7.00e-06\n","\tEpoch 40/100 - Train loss: 0.9904 - Val accuracy: 0.7612 - Val loss: 0.7564 - LR: 6.00e-06\n","\tEpoch 50/100 - Train loss: 0.9779 - Val accuracy: 0.8060 - Val loss: 0.6074 - LR: 5.00e-06\n","\tEpoch 60/100 - Train loss: 0.8107 - Val accuracy: 0.8060 - Val loss: 0.5556 - LR: 4.00e-06\n","\tEpoch 70/100 - Train loss: 0.8549 - Val accuracy: 0.7761 - Val loss: 0.5944 - LR: 3.00e-06\n","\tEpoch 80/100 - Train loss: 0.8607 - Val accuracy: 0.8209 - Val loss: 0.5364 - LR: 2.00e-06\n","\tEpoch 90/100 - Train loss: 0.8050 - Val accuracy: 0.7910 - Val loss: 0.5652 - LR: 1.00e-06\n","\tEpoch 100/100 - Train loss: 0.7918 - Val accuracy: 0.8060 - Val loss: 0.5555 - LR: 0.00e+00\n","\tBest epoch: 85 - Best val accuracy: 0.8209 - Best val loss: 0.5016\n","\n","Source class: WAL | Domain: 38 | Accuracy: 0.7021 | Loss: 7.0064\n","\n","Domain: 39\n","x_syn_dom.shape: (333, 3, 128) | np.unique(y_syn_dom): [1 2 3]\n","x_dp_dom.shape: (54, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Fine-tuning on synthetic data...\n","\tEpoch 10/100 - Train loss: 0.1838 - Val accuracy: 0.9403 - Val loss: 0.1010 - LR: 9.00e-06\n","\tEpoch 20/100 - Train loss: 0.1444 - Val accuracy: 0.9701 - Val loss: 0.0786 - LR: 8.00e-06\n","\tEpoch 30/100 - Train loss: 0.1182 - Val accuracy: 0.9701 - Val loss: 0.0582 - LR: 7.00e-06\n","\tEpoch 40/100 - Train loss: 0.1057 - Val accuracy: 0.9851 - Val loss: 0.0535 - LR: 6.00e-06\n","\tEpoch 50/100 - Train loss: 0.1041 - Val accuracy: 0.9701 - Val loss: 0.0544 - LR: 5.00e-06\n","\tEpoch 60/100 - Train loss: 0.2454 - Val accuracy: 1.0000 - Val loss: 0.0555 - LR: 4.00e-06\n","\tEpoch 70/100 - Train loss: 0.0839 - Val accuracy: 0.9701 - Val loss: 0.0496 - LR: 3.00e-06\n","\tEpoch 80/100 - Train loss: 0.1295 - Val accuracy: 0.9851 - Val loss: 0.0435 - LR: 2.00e-06\n","\tEpoch 90/100 - Train loss: 0.0880 - Val accuracy: 0.9851 - Val loss: 0.0423 - LR: 1.00e-06\n","\tEpoch 100/100 - Train loss: 0.1463 - Val accuracy: 0.9851 - Val loss: 0.0471 - LR: 0.00e+00\n","\tBest epoch: 86 - Best val accuracy: 1.0000 - Best val loss: 0.0378\n","\n","Source class: WAL | Domain: 39 | Accuracy: 0.6667 | Loss: 3.4024\n","\n","Domain: 40\n","x_syn_dom.shape: (333, 3, 128) | np.unique(y_syn_dom): [1 2 3]\n","x_dp_dom.shape: (44, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Fine-tuning on synthetic data...\n","\tEpoch 10/100 - Train loss: 0.2503 - Val accuracy: 0.9701 - Val loss: 0.0693 - LR: 9.00e-06\n","\tEpoch 20/100 - Train loss: 0.1164 - Val accuracy: 0.9701 - Val loss: 0.0607 - LR: 8.00e-06\n","\tEpoch 30/100 - Train loss: 0.2887 - Val accuracy: 0.9851 - Val loss: 0.0524 - LR: 7.00e-06\n","\tEpoch 40/100 - Train loss: 0.1643 - Val accuracy: 0.9851 - Val loss: 0.0382 - LR: 6.00e-06\n","\tEpoch 50/100 - Train loss: 0.1200 - Val accuracy: 0.9851 - Val loss: 0.0438 - LR: 5.00e-06\n","\tEpoch 60/100 - Train loss: 0.0783 - Val accuracy: 0.9851 - Val loss: 0.0398 - LR: 4.00e-06\n","\tEpoch 70/100 - Train loss: 0.0940 - Val accuracy: 0.9851 - Val loss: 0.0422 - LR: 3.00e-06\n","\tEpoch 80/100 - Train loss: 0.1143 - Val accuracy: 0.9851 - Val loss: 0.0404 - LR: 2.00e-06\n","\tEpoch 90/100 - Train loss: 0.0729 - Val accuracy: 0.9851 - Val loss: 0.0435 - LR: 1.00e-06\n","\tEpoch 100/100 - Train loss: 0.0876 - Val accuracy: 0.9851 - Val loss: 0.0482 - LR: 0.00e+00\n","\tBest epoch: 68 - Best val accuracy: 0.9851 - Best val loss: 0.0313\n","\n","Source class: WAL | Domain: 40 | Accuracy: 0.7273 | Loss: 1.3734\n","\n","Domain: 41\n","x_syn_dom.shape: (333, 3, 128) | np.unique(y_syn_dom): [1 2 3]\n","x_dp_dom.shape: (45, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Fine-tuning on synthetic data...\n","\tEpoch 10/100 - Train loss: 0.1398 - Val accuracy: 0.9552 - Val loss: 0.6732 - LR: 9.00e-06\n","\tEpoch 20/100 - Train loss: 0.2584 - Val accuracy: 0.9552 - Val loss: 0.6827 - LR: 8.00e-06\n","\tEpoch 30/100 - Train loss: 0.0472 - Val accuracy: 0.9552 - Val loss: 0.6819 - LR: 7.00e-06\n","\tEpoch 40/100 - Train loss: 0.0858 - Val accuracy: 0.9552 - Val loss: 0.6576 - LR: 6.00e-06\n","\tEpoch 50/100 - Train loss: 0.1097 - Val accuracy: 0.9552 - Val loss: 0.6711 - LR: 5.00e-06\n","\tEpoch 60/100 - Train loss: 0.0721 - Val accuracy: 0.9552 - Val loss: 0.6577 - LR: 4.00e-06\n","\tEpoch 70/100 - Train loss: 0.0465 - Val accuracy: 0.9552 - Val loss: 0.6600 - LR: 3.00e-06\n","\tEpoch 80/100 - Train loss: 0.1286 - Val accuracy: 0.9552 - Val loss: 0.6601 - LR: 2.00e-06\n","\tEpoch 90/100 - Train loss: 0.1032 - Val accuracy: 0.9552 - Val loss: 0.6546 - LR: 1.00e-06\n","\tEpoch 100/100 - Train loss: 0.0667 - Val accuracy: 0.9552 - Val loss: 0.6455 - LR: 0.00e+00\n","\tBest epoch: 85 - Best val accuracy: 0.9552 - Best val loss: 0.6431\n","\n","Source class: WAL | Domain: 41 | Accuracy: 0.6667 | Loss: 6.5715\n","\n","Domain: 42\n","x_syn_dom.shape: (336, 3, 128) | np.unique(y_syn_dom): [1 2 3]\n","x_dp_dom.shape: (46, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Fine-tuning on synthetic data...\n","\tEpoch 10/100 - Train loss: 0.1672 - Val accuracy: 1.0000 - Val loss: 0.0103 - LR: 9.00e-06\n","\tEpoch 20/100 - Train loss: 0.1535 - Val accuracy: 1.0000 - Val loss: 0.0071 - LR: 8.00e-06\n","\tEpoch 30/100 - Train loss: 0.2026 - Val accuracy: 1.0000 - Val loss: 0.0065 - LR: 7.00e-06\n","\tEpoch 40/100 - Train loss: 0.1188 - Val accuracy: 1.0000 - Val loss: 0.0051 - LR: 6.00e-06\n","\tEpoch 50/100 - Train loss: 0.1857 - Val accuracy: 1.0000 - Val loss: 0.0048 - LR: 5.00e-06\n","\tEpoch 60/100 - Train loss: 0.1402 - Val accuracy: 1.0000 - Val loss: 0.0046 - LR: 4.00e-06\n","\tEpoch 70/100 - Train loss: 0.0830 - Val accuracy: 1.0000 - Val loss: 0.0044 - LR: 3.00e-06\n","\tEpoch 80/100 - Train loss: 0.1232 - Val accuracy: 1.0000 - Val loss: 0.0042 - LR: 2.00e-06\n","\tEpoch 90/100 - Train loss: 0.0549 - Val accuracy: 1.0000 - Val loss: 0.0039 - LR: 1.00e-06\n","\tEpoch 100/100 - Train loss: 0.1465 - Val accuracy: 1.0000 - Val loss: 0.0039 - LR: 0.00e+00\n","\tBest epoch: 84 - Best val accuracy: 1.0000 - Best val loss: 0.0037\n","\n","Source class: WAL | Domain: 42 | Accuracy: 0.7826 | Loss: 1.9057\n","\n","Domain: 43\n","x_syn_dom.shape: (333, 3, 128) | np.unique(y_syn_dom): [1 2 3]\n","x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Fine-tuning on synthetic data...\n","\tEpoch 10/100 - Train loss: 0.0816 - Val accuracy: 0.9701 - Val loss: 0.0562 - LR: 9.00e-06\n","\tEpoch 20/100 - Train loss: 0.0957 - Val accuracy: 0.9851 - Val loss: 0.0127 - LR: 8.00e-06\n","\tEpoch 30/100 - Train loss: 0.1216 - Val accuracy: 1.0000 - Val loss: 0.0039 - LR: 7.00e-06\n","\tEpoch 40/100 - Train loss: 0.2331 - Val accuracy: 1.0000 - Val loss: 0.0022 - LR: 6.00e-06\n","\tEpoch 50/100 - Train loss: 0.0587 - Val accuracy: 0.9851 - Val loss: 0.0127 - LR: 5.00e-06\n","\tEpoch 60/100 - Train loss: 0.0496 - Val accuracy: 1.0000 - Val loss: 0.0026 - LR: 4.00e-06\n","\tEpoch 70/100 - Train loss: 0.0532 - Val accuracy: 1.0000 - Val loss: 0.0056 - LR: 3.00e-06\n","\tEpoch 80/100 - Train loss: 0.0430 - Val accuracy: 1.0000 - Val loss: 0.0020 - LR: 2.00e-06\n","\tEpoch 90/100 - Train loss: 0.0713 - Val accuracy: 1.0000 - Val loss: 0.0032 - LR: 1.00e-06\n","\tEpoch 100/100 - Train loss: 0.0763 - Val accuracy: 1.0000 - Val loss: 0.0010 - LR: 0.00e+00\n","\tBest epoch: 100 - Best val accuracy: 1.0000 - Best val loss: 0.0010\n","\n","Source class: WAL | Domain: 43 | Accuracy: 0.7857 | Loss: 6.0037\n","\n","Domain: 44\n","x_syn_dom.shape: (333, 3, 128) | np.unique(y_syn_dom): [1 2 3]\n","x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Fine-tuning on synthetic data...\n","\tEpoch 10/100 - Train loss: 0.2439 - Val accuracy: 0.8955 - Val loss: 0.3877 - LR: 9.00e-06\n","\tEpoch 20/100 - Train loss: 0.2330 - Val accuracy: 0.9104 - Val loss: 0.3454 - LR: 8.00e-06\n","\tEpoch 30/100 - Train loss: 0.1682 - Val accuracy: 0.9104 - Val loss: 0.3159 - LR: 7.00e-06\n","\tEpoch 40/100 - Train loss: 0.1226 - Val accuracy: 0.9104 - Val loss: 0.2957 - LR: 6.00e-06\n","\tEpoch 50/100 - Train loss: 0.1022 - Val accuracy: 0.9254 - Val loss: 0.2732 - LR: 5.00e-06\n","\tEpoch 60/100 - Train loss: 0.1334 - Val accuracy: 0.9254 - Val loss: 0.2574 - LR: 4.00e-06\n","\tEpoch 70/100 - Train loss: 0.1047 - Val accuracy: 0.9254 - Val loss: 0.2559 - LR: 3.00e-06\n","\tEpoch 80/100 - Train loss: 0.1102 - Val accuracy: 0.9254 - Val loss: 0.2423 - LR: 2.00e-06\n","\tEpoch 90/100 - Train loss: 0.0633 - Val accuracy: 0.9254 - Val loss: 0.2440 - LR: 1.00e-06\n","\tEpoch 100/100 - Train loss: 0.1353 - Val accuracy: 0.9254 - Val loss: 0.2402 - LR: 0.00e+00\n","\tBest epoch: 1 - Best val accuracy: 0.9403 - Best val loss: 0.1394\n","\n","Source class: WAL | Domain: 44 | Accuracy: 0.8095 | Loss: 1.1782\n","\n","Domain: 45\n","x_syn_dom.shape: (333, 3, 128) | np.unique(y_syn_dom): [1 2 3]\n","x_dp_dom.shape: (52, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Fine-tuning on synthetic data...\n","\tEpoch 10/100 - Train loss: 0.1106 - Val accuracy: 0.9254 - Val loss: 0.1511 - LR: 9.00e-06\n","\tEpoch 20/100 - Train loss: 0.0914 - Val accuracy: 0.9552 - Val loss: 0.1391 - LR: 8.00e-06\n","\tEpoch 30/100 - Train loss: 0.1461 - Val accuracy: 0.9552 - Val loss: 0.1084 - LR: 7.00e-06\n","\tEpoch 40/100 - Train loss: 0.1051 - Val accuracy: 0.9701 - Val loss: 0.0991 - LR: 6.00e-06\n","\tEpoch 50/100 - Train loss: 0.0766 - Val accuracy: 0.9701 - Val loss: 0.0908 - LR: 5.00e-06\n","\tEpoch 60/100 - Train loss: 0.0598 - Val accuracy: 0.9851 - Val loss: 0.0897 - LR: 4.00e-06\n","\tEpoch 70/100 - Train loss: 0.0751 - Val accuracy: 0.9851 - Val loss: 0.0825 - LR: 3.00e-06\n","\tEpoch 80/100 - Train loss: 0.0944 - Val accuracy: 0.9851 - Val loss: 0.0780 - LR: 2.00e-06\n","\tEpoch 90/100 - Train loss: 0.0849 - Val accuracy: 0.9851 - Val loss: 0.0762 - LR: 1.00e-06\n","\tEpoch 100/100 - Train loss: 0.1062 - Val accuracy: 0.9851 - Val loss: 0.0746 - LR: 0.00e+00\n","\tBest epoch: 98 - Best val accuracy: 0.9701 - Best val loss: 0.0739\n","\n","Source class: WAL | Domain: 45 | Accuracy: 0.9615 | Loss: 0.1025\n","\n","Domain: 46\n","x_syn_dom.shape: (336, 3, 128) | np.unique(y_syn_dom): [1 2 3]\n","x_dp_dom.shape: (48, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Fine-tuning on synthetic data...\n","\tEpoch 10/100 - Train loss: 0.2218 - Val accuracy: 0.9118 - Val loss: 0.1713 - LR: 9.00e-06\n","\tEpoch 20/100 - Train loss: 0.3784 - Val accuracy: 0.9265 - Val loss: 0.1699 - LR: 8.00e-06\n","\tEpoch 30/100 - Train loss: 0.2077 - Val accuracy: 0.9412 - Val loss: 0.1416 - LR: 7.00e-06\n","\tEpoch 40/100 - Train loss: 0.1978 - Val accuracy: 0.9412 - Val loss: 0.1242 - LR: 6.00e-06\n","\tEpoch 50/100 - Train loss: 0.1641 - Val accuracy: 0.9559 - Val loss: 0.0935 - LR: 5.00e-06\n","\tEpoch 60/100 - Train loss: 0.2427 - Val accuracy: 0.9412 - Val loss: 0.1045 - LR: 4.00e-06\n","\tEpoch 70/100 - Train loss: 0.1639 - Val accuracy: 0.9412 - Val loss: 0.0927 - LR: 3.00e-06\n","\tEpoch 80/100 - Train loss: 0.1458 - Val accuracy: 0.9559 - Val loss: 0.0849 - LR: 2.00e-06\n","\tEpoch 90/100 - Train loss: 0.1483 - Val accuracy: 0.9559 - Val loss: 0.0872 - LR: 1.00e-06\n","\tEpoch 100/100 - Train loss: 0.1585 - Val accuracy: 0.9559 - Val loss: 0.0915 - LR: 0.00e+00\n","\tBest epoch: 83 - Best val accuracy: 0.9559 - Best val loss: 0.0602\n","\n","Source class: WAL | Domain: 46 | Accuracy: 0.8333 | Loss: 1.2188\n","\n","Domain: 47\n","x_syn_dom.shape: (333, 3, 128) | np.unique(y_syn_dom): [1 2 3]\n","x_dp_dom.shape: (44, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Fine-tuning on synthetic data...\n","\tEpoch 10/100 - Train loss: 0.4140 - Val accuracy: 0.9701 - Val loss: 0.1029 - LR: 9.00e-06\n","\tEpoch 20/100 - Train loss: 0.1761 - Val accuracy: 0.9701 - Val loss: 0.0952 - LR: 8.00e-06\n","\tEpoch 30/100 - Train loss: 0.1468 - Val accuracy: 0.9701 - Val loss: 0.0869 - LR: 7.00e-06\n","\tEpoch 40/100 - Train loss: 0.1962 - Val accuracy: 0.9701 - Val loss: 0.0835 - LR: 6.00e-06\n","\tEpoch 50/100 - Train loss: 0.2522 - Val accuracy: 0.9701 - Val loss: 0.0820 - LR: 5.00e-06\n","\tEpoch 60/100 - Train loss: 0.2042 - Val accuracy: 0.9701 - Val loss: 0.0790 - LR: 4.00e-06\n","\tEpoch 70/100 - Train loss: 0.1272 - Val accuracy: 0.9701 - Val loss: 0.0765 - LR: 3.00e-06\n","\tEpoch 80/100 - Train loss: 0.1276 - Val accuracy: 0.9701 - Val loss: 0.0740 - LR: 2.00e-06\n","\tEpoch 90/100 - Train loss: 0.1592 - Val accuracy: 0.9701 - Val loss: 0.0754 - LR: 1.00e-06\n","\tEpoch 100/100 - Train loss: 0.1063 - Val accuracy: 0.9701 - Val loss: 0.0742 - LR: 0.00e+00\n","\tBest epoch: 86 - Best val accuracy: 0.9701 - Best val loss: 0.0721\n","\n","Source class: WAL | Domain: 47 | Accuracy: 0.9091 | Loss: 0.6478\n","\n","Domain: 48\n","x_syn_dom.shape: (333, 3, 128) | np.unique(y_syn_dom): [1 2 3]\n","x_dp_dom.shape: (48, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Fine-tuning on synthetic data...\n","\tEpoch 10/100 - Train loss: 0.4116 - Val accuracy: 0.9104 - Val loss: 0.6478 - LR: 9.00e-06\n","\tEpoch 20/100 - Train loss: 0.3402 - Val accuracy: 0.9104 - Val loss: 0.5728 - LR: 8.00e-06\n","\tEpoch 30/100 - Train loss: 0.2750 - Val accuracy: 0.9104 - Val loss: 0.5573 - LR: 7.00e-06\n","\tEpoch 40/100 - Train loss: 0.2241 - Val accuracy: 0.9254 - Val loss: 0.4872 - LR: 6.00e-06\n","\tEpoch 50/100 - Train loss: 0.2545 - Val accuracy: 0.9254 - Val loss: 0.5059 - LR: 5.00e-06\n","\tEpoch 60/100 - Train loss: 0.3493 - Val accuracy: 0.9254 - Val loss: 0.4649 - LR: 4.00e-06\n","\tEpoch 70/100 - Train loss: 0.2643 - Val accuracy: 0.9254 - Val loss: 0.4611 - LR: 3.00e-06\n","\tEpoch 80/100 - Train loss: 0.2018 - Val accuracy: 0.9254 - Val loss: 0.4507 - LR: 2.00e-06\n","\tEpoch 90/100 - Train loss: 0.2217 - Val accuracy: 0.9254 - Val loss: 0.4603 - LR: 1.00e-06\n","\tEpoch 100/100 - Train loss: 0.2500 - Val accuracy: 0.9254 - Val loss: 0.4458 - LR: 0.00e+00\n","\tBest epoch: 93 - Best val accuracy: 0.9254 - Best val loss: 0.4230\n","\n","Source class: WAL | Domain: 48 | Accuracy: 0.7917 | Loss: 1.0390\n","\n","Domain: 49\n","x_syn_dom.shape: (333, 3, 128) | np.unique(y_syn_dom): [1 2 3]\n","x_dp_dom.shape: (53, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Fine-tuning on synthetic data...\n","\tEpoch 10/100 - Train loss: 0.1903 - Val accuracy: 0.9552 - Val loss: 0.0556 - LR: 9.00e-06\n","\tEpoch 20/100 - Train loss: 0.1302 - Val accuracy: 0.9851 - Val loss: 0.0436 - LR: 8.00e-06\n","\tEpoch 30/100 - Train loss: 0.1191 - Val accuracy: 0.9851 - Val loss: 0.0399 - LR: 7.00e-06\n","\tEpoch 40/100 - Train loss: 0.1119 - Val accuracy: 0.9851 - Val loss: 0.0342 - LR: 6.00e-06\n","\tEpoch 50/100 - Train loss: 0.0796 - Val accuracy: 0.9851 - Val loss: 0.0325 - LR: 5.00e-06\n","\tEpoch 60/100 - Train loss: 0.0403 - Val accuracy: 0.9851 - Val loss: 0.0310 - LR: 4.00e-06\n","\tEpoch 70/100 - Train loss: 0.0961 - Val accuracy: 0.9851 - Val loss: 0.0288 - LR: 3.00e-06\n","\tEpoch 80/100 - Train loss: 0.0860 - Val accuracy: 0.9851 - Val loss: 0.0256 - LR: 2.00e-06\n","\tEpoch 90/100 - Train loss: 0.0920 - Val accuracy: 0.9851 - Val loss: 0.0338 - LR: 1.00e-06\n","\tEpoch 100/100 - Train loss: 0.0880 - Val accuracy: 0.9851 - Val loss: 0.0284 - LR: 0.00e+00\n","\tBest epoch: 95 - Best val accuracy: 0.9851 - Best val loss: 0.0246\n","\n","Source class: WAL | Domain: 49 | Accuracy: 0.9434 | Loss: 0.1076\n","\n","Domain: 50\n","x_syn_dom.shape: (333, 3, 128) | np.unique(y_syn_dom): [1 2 3]\n","x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Fine-tuning on synthetic data...\n","\tEpoch 10/100 - Train loss: 0.4319 - Val accuracy: 0.8955 - Val loss: 0.1855 - LR: 9.00e-06\n","\tEpoch 20/100 - Train loss: 0.2647 - Val accuracy: 0.9254 - Val loss: 0.1608 - LR: 8.00e-06\n","\tEpoch 30/100 - Train loss: 0.3822 - Val accuracy: 0.9403 - Val loss: 0.1790 - LR: 7.00e-06\n","\tEpoch 40/100 - Train loss: 0.2734 - Val accuracy: 0.9552 - Val loss: 0.1069 - LR: 6.00e-06\n","\tEpoch 50/100 - Train loss: 0.2423 - Val accuracy: 0.9552 - Val loss: 0.1036 - LR: 5.00e-06\n","\tEpoch 60/100 - Train loss: 0.2417 - Val accuracy: 0.9552 - Val loss: 0.1051 - LR: 4.00e-06\n","\tEpoch 70/100 - Train loss: 0.1792 - Val accuracy: 0.9552 - Val loss: 0.0960 - LR: 3.00e-06\n","\tEpoch 80/100 - Train loss: 0.1676 - Val accuracy: 0.9701 - Val loss: 0.0725 - LR: 2.00e-06\n","\tEpoch 90/100 - Train loss: 0.1496 - Val accuracy: 0.9552 - Val loss: 0.0778 - LR: 1.00e-06\n","\tEpoch 100/100 - Train loss: 0.1938 - Val accuracy: 0.9552 - Val loss: 0.0771 - LR: 0.00e+00\n","\tBest epoch: 80 - Best val accuracy: 0.9701 - Best val loss: 0.0725\n","\n","Source class: WAL | Domain: 50 | Accuracy: 0.8810 | Loss: 0.8739\n","\n","Domain: 51\n","x_syn_dom.shape: (333, 3, 128) | np.unique(y_syn_dom): [1 2 3]\n","x_dp_dom.shape: (46, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Fine-tuning on synthetic data...\n","\tEpoch 10/100 - Train loss: 0.1931 - Val accuracy: 0.9403 - Val loss: 0.1786 - LR: 9.00e-06\n","\tEpoch 20/100 - Train loss: 0.2148 - Val accuracy: 0.9403 - Val loss: 0.1499 - LR: 8.00e-06\n","\tEpoch 30/100 - Train loss: 0.1942 - Val accuracy: 0.9403 - Val loss: 0.1426 - LR: 7.00e-06\n","\tEpoch 40/100 - Train loss: 0.1441 - Val accuracy: 0.9403 - Val loss: 0.1371 - LR: 6.00e-06\n","\tEpoch 50/100 - Train loss: 0.1893 - Val accuracy: 0.9552 - Val loss: 0.1249 - LR: 5.00e-06\n","\tEpoch 60/100 - Train loss: 0.2067 - Val accuracy: 0.9403 - Val loss: 0.1223 - LR: 4.00e-06\n","\tEpoch 70/100 - Train loss: 0.1289 - Val accuracy: 0.9552 - Val loss: 0.1156 - LR: 3.00e-06\n","\tEpoch 80/100 - Train loss: 0.1256 - Val accuracy: 0.9552 - Val loss: 0.1085 - LR: 2.00e-06\n","\tEpoch 90/100 - Train loss: 0.1062 - Val accuracy: 0.9552 - Val loss: 0.1072 - LR: 1.00e-06\n","\tEpoch 100/100 - Train loss: 0.1041 - Val accuracy: 0.9552 - Val loss: 0.1069 - LR: 0.00e+00\n","\tBest epoch: 91 - Best val accuracy: 0.9552 - Best val loss: 0.1040\n","\n","Source class: WAL | Domain: 51 | Accuracy: 0.7391 | Loss: 1.8181\n","\n","Domain: 52\n","x_syn_dom.shape: (333, 3, 128) | np.unique(y_syn_dom): [1 2 3]\n","x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Fine-tuning on synthetic data...\n","\tEpoch 10/100 - Train loss: 0.1935 - Val accuracy: 0.9701 - Val loss: 0.0715 - LR: 9.00e-06\n","\tEpoch 20/100 - Train loss: 0.2301 - Val accuracy: 0.9701 - Val loss: 0.0660 - LR: 8.00e-06\n","\tEpoch 30/100 - Train loss: 0.1297 - Val accuracy: 0.9701 - Val loss: 0.0475 - LR: 7.00e-06\n","\tEpoch 40/100 - Train loss: 0.0887 - Val accuracy: 0.9701 - Val loss: 0.0424 - LR: 6.00e-06\n","\tEpoch 50/100 - Train loss: 0.0833 - Val accuracy: 0.9701 - Val loss: 0.0402 - LR: 5.00e-06\n","\tEpoch 60/100 - Train loss: 0.0715 - Val accuracy: 0.9851 - Val loss: 0.0285 - LR: 4.00e-06\n","\tEpoch 70/100 - Train loss: 0.0790 - Val accuracy: 0.9851 - Val loss: 0.0257 - LR: 3.00e-06\n","\tEpoch 80/100 - Train loss: 0.1140 - Val accuracy: 0.9851 - Val loss: 0.0244 - LR: 2.00e-06\n","\tEpoch 90/100 - Train loss: 0.1735 - Val accuracy: 1.0000 - Val loss: 0.0223 - LR: 1.00e-06\n","\tEpoch 100/100 - Train loss: 0.1522 - Val accuracy: 0.9851 - Val loss: 0.0231 - LR: 0.00e+00\n","\tBest epoch: 97 - Best val accuracy: 1.0000 - Best val loss: 0.0208\n","\n","Source class: WAL | Domain: 52 | Accuracy: 0.9048 | Loss: 0.2937\n","\n","Domain: 53\n","x_syn_dom.shape: (333, 3, 128) | np.unique(y_syn_dom): [1 2 3]\n","x_dp_dom.shape: (48, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Fine-tuning on synthetic data...\n","\tEpoch 10/100 - Train loss: 0.5506 - Val accuracy: 0.9403 - Val loss: 0.1768 - LR: 9.00e-06\n","\tEpoch 20/100 - Train loss: 0.2843 - Val accuracy: 0.9701 - Val loss: 0.0540 - LR: 8.00e-06\n","\tEpoch 30/100 - Train loss: 0.1719 - Val accuracy: 1.0000 - Val loss: 0.0183 - LR: 7.00e-06\n","\tEpoch 40/100 - Train loss: 0.1562 - Val accuracy: 1.0000 - Val loss: 0.0047 - LR: 6.00e-06\n","\tEpoch 50/100 - Train loss: 0.0961 - Val accuracy: 1.0000 - Val loss: 0.0121 - LR: 5.00e-06\n","\tEpoch 60/100 - Train loss: 0.0826 - Val accuracy: 1.0000 - Val loss: 0.0075 - LR: 4.00e-06\n","\tEpoch 70/100 - Train loss: 0.1634 - Val accuracy: 1.0000 - Val loss: 0.0046 - LR: 3.00e-06\n","\tEpoch 80/100 - Train loss: 0.0912 - Val accuracy: 1.0000 - Val loss: 0.0047 - LR: 2.00e-06\n","\tEpoch 90/100 - Train loss: 0.1230 - Val accuracy: 1.0000 - Val loss: 0.0073 - LR: 1.00e-06\n","\tEpoch 100/100 - Train loss: 0.1464 - Val accuracy: 1.0000 - Val loss: 0.0041 - LR: 0.00e+00\n","\tBest epoch: 63 - Best val accuracy: 1.0000 - Best val loss: 0.0041\n","\n","Source class: WAL | Domain: 53 | Accuracy: 0.5833 | Loss: 11.5684\n","\n","Domain: 54\n","x_syn_dom.shape: (333, 3, 128) | np.unique(y_syn_dom): [1 2 3]\n","x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Fine-tuning on synthetic data...\n","\tEpoch 10/100 - Train loss: 0.1776 - Val accuracy: 0.9254 - Val loss: 0.1970 - LR: 9.00e-06\n","\tEpoch 20/100 - Train loss: 0.1076 - Val accuracy: 0.9254 - Val loss: 0.1605 - LR: 8.00e-06\n","\tEpoch 30/100 - Train loss: 0.2269 - Val accuracy: 0.9701 - Val loss: 0.1348 - LR: 7.00e-06\n","\tEpoch 40/100 - Train loss: 0.1200 - Val accuracy: 0.9701 - Val loss: 0.1225 - LR: 6.00e-06\n","\tEpoch 50/100 - Train loss: 0.1128 - Val accuracy: 0.9701 - Val loss: 0.1137 - LR: 5.00e-06\n","\tEpoch 60/100 - Train loss: 0.0640 - Val accuracy: 0.9701 - Val loss: 0.1093 - LR: 4.00e-06\n","\tEpoch 70/100 - Train loss: 0.0880 - Val accuracy: 0.9701 - Val loss: 0.1041 - LR: 3.00e-06\n","\tEpoch 80/100 - Train loss: 0.1051 - Val accuracy: 0.9701 - Val loss: 0.0997 - LR: 2.00e-06\n","\tEpoch 90/100 - Train loss: 0.1044 - Val accuracy: 0.9701 - Val loss: 0.0988 - LR: 1.00e-06\n","\tEpoch 100/100 - Train loss: 0.1297 - Val accuracy: 0.9701 - Val loss: 0.0996 - LR: 0.00e+00\n","\tBest epoch: 84 - Best val accuracy: 0.9701 - Best val loss: 0.0959\n","\n","Source class: WAL | Domain: 54 | Accuracy: 0.7619 | Loss: 2.6885\n","\n","Domain: 55\n","x_syn_dom.shape: (333, 3, 128) | np.unique(y_syn_dom): [1 2 3]\n","x_dp_dom.shape: (49, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Fine-tuning on synthetic data...\n","\tEpoch 10/100 - Train loss: 0.1068 - Val accuracy: 0.9851 - Val loss: 0.0188 - LR: 9.00e-06\n","\tEpoch 20/100 - Train loss: 0.1116 - Val accuracy: 1.0000 - Val loss: 0.0111 - LR: 8.00e-06\n","\tEpoch 30/100 - Train loss: 0.0943 - Val accuracy: 1.0000 - Val loss: 0.0097 - LR: 7.00e-06\n","\tEpoch 40/100 - Train loss: 0.0743 - Val accuracy: 1.0000 - Val loss: 0.0076 - LR: 6.00e-06\n","\tEpoch 50/100 - Train loss: 0.0769 - Val accuracy: 1.0000 - Val loss: 0.0059 - LR: 5.00e-06\n","\tEpoch 60/100 - Train loss: 0.0602 - Val accuracy: 1.0000 - Val loss: 0.0055 - LR: 4.00e-06\n","\tEpoch 70/100 - Train loss: 0.0641 - Val accuracy: 1.0000 - Val loss: 0.0056 - LR: 3.00e-06\n","\tEpoch 80/100 - Train loss: 0.0456 - Val accuracy: 1.0000 - Val loss: 0.0049 - LR: 2.00e-06\n","\tEpoch 90/100 - Train loss: 0.0686 - Val accuracy: 1.0000 - Val loss: 0.0046 - LR: 1.00e-06\n","\tEpoch 100/100 - Train loss: 0.0412 - Val accuracy: 1.0000 - Val loss: 0.0041 - LR: 0.00e+00\n","\tBest epoch: 91 - Best val accuracy: 1.0000 - Best val loss: 0.0039\n","\n","Source class: WAL | Domain: 55 | Accuracy: 0.9184 | Loss: 0.7081\n","\n","Domain: 56\n","x_syn_dom.shape: (333, 3, 128) | np.unique(y_syn_dom): [1 2 3]\n","x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Fine-tuning on synthetic data...\n","\tEpoch 10/100 - Train loss: 0.1148 - Val accuracy: 0.9403 - Val loss: 0.2470 - LR: 9.00e-06\n","\tEpoch 20/100 - Train loss: 0.0834 - Val accuracy: 0.9403 - Val loss: 0.2260 - LR: 8.00e-06\n","\tEpoch 30/100 - Train loss: 0.0772 - Val accuracy: 0.9403 - Val loss: 0.2174 - LR: 7.00e-06\n","\tEpoch 40/100 - Train loss: 0.1009 - Val accuracy: 0.9403 - Val loss: 0.2064 - LR: 6.00e-06\n","\tEpoch 50/100 - Train loss: 0.1100 - Val accuracy: 0.9403 - Val loss: 0.2010 - LR: 5.00e-06\n","\tEpoch 60/100 - Train loss: 0.0848 - Val accuracy: 0.9403 - Val loss: 0.1963 - LR: 4.00e-06\n","\tEpoch 70/100 - Train loss: 0.0412 - Val accuracy: 0.9403 - Val loss: 0.1873 - LR: 3.00e-06\n","\tEpoch 80/100 - Train loss: 0.1118 - Val accuracy: 0.9403 - Val loss: 0.1894 - LR: 2.00e-06\n","\tEpoch 90/100 - Train loss: 0.0586 - Val accuracy: 0.9403 - Val loss: 0.1895 - LR: 1.00e-06\n","\tEpoch 100/100 - Train loss: 0.0657 - Val accuracy: 0.9403 - Val loss: 0.1844 - LR: 0.00e+00\n","\tBest epoch: 100 - Best val accuracy: 0.9403 - Best val loss: 0.1844\n","\n","Source class: WAL | Domain: 56 | Accuracy: 0.9286 | Loss: 0.1959\n","\n","Domain: 57\n","x_syn_dom.shape: (333, 3, 128) | np.unique(y_syn_dom): [1 2 3]\n","x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Fine-tuning on synthetic data...\n","\tEpoch 10/100 - Train loss: 0.1086 - Val accuracy: 0.9851 - Val loss: 0.0865 - LR: 9.00e-06\n","\tEpoch 20/100 - Train loss: 0.0929 - Val accuracy: 0.9851 - Val loss: 0.0757 - LR: 8.00e-06\n","\tEpoch 30/100 - Train loss: 0.0815 - Val accuracy: 0.9851 - Val loss: 0.0686 - LR: 7.00e-06\n","\tEpoch 40/100 - Train loss: 0.0497 - Val accuracy: 0.9851 - Val loss: 0.0692 - LR: 6.00e-06\n","\tEpoch 50/100 - Train loss: 0.0433 - Val accuracy: 0.9851 - Val loss: 0.0646 - LR: 5.00e-06\n","\tEpoch 60/100 - Train loss: 0.0434 - Val accuracy: 0.9851 - Val loss: 0.0644 - LR: 4.00e-06\n","\tEpoch 70/100 - Train loss: 0.0839 - Val accuracy: 0.9851 - Val loss: 0.0667 - LR: 3.00e-06\n","\tEpoch 80/100 - Train loss: 0.0602 - Val accuracy: 0.9851 - Val loss: 0.0663 - LR: 2.00e-06\n","\tEpoch 90/100 - Train loss: 0.0722 - Val accuracy: 0.9851 - Val loss: 0.0624 - LR: 1.00e-06\n","\tEpoch 100/100 - Train loss: 0.0580 - Val accuracy: 0.9851 - Val loss: 0.0613 - LR: 0.00e+00\n","\tBest epoch: 71 - Best val accuracy: 0.9851 - Best val loss: 0.0588\n","\n","Source class: WAL | Domain: 57 | Accuracy: 0.8333 | Loss: 1.2421\n","\n","Domain: 58\n","x_syn_dom.shape: (333, 3, 128) | np.unique(y_syn_dom): [1 2 3]\n","x_dp_dom.shape: (38, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Fine-tuning on synthetic data...\n","\tEpoch 10/100 - Train loss: 1.2132 - Val accuracy: 0.7910 - Val loss: 1.1980 - LR: 9.00e-06\n","\tEpoch 20/100 - Train loss: 0.8408 - Val accuracy: 0.8060 - Val loss: 0.8872 - LR: 8.00e-06\n","\tEpoch 30/100 - Train loss: 0.7074 - Val accuracy: 0.8209 - Val loss: 0.7781 - LR: 7.00e-06\n","\tEpoch 40/100 - Train loss: 0.5693 - Val accuracy: 0.8806 - Val loss: 0.6513 - LR: 6.00e-06\n","\tEpoch 50/100 - Train loss: 0.5159 - Val accuracy: 0.8955 - Val loss: 0.5360 - LR: 5.00e-06\n","\tEpoch 60/100 - Train loss: 0.4990 - Val accuracy: 0.8955 - Val loss: 0.5330 - LR: 4.00e-06\n","\tEpoch 70/100 - Train loss: 0.4766 - Val accuracy: 0.8955 - Val loss: 0.4845 - LR: 3.00e-06\n","\tEpoch 80/100 - Train loss: 0.4326 - Val accuracy: 0.8955 - Val loss: 0.4567 - LR: 2.00e-06\n","\tEpoch 90/100 - Train loss: 0.5001 - Val accuracy: 0.8955 - Val loss: 0.4468 - LR: 1.00e-06\n","\tEpoch 100/100 - Train loss: 0.3874 - Val accuracy: 0.8955 - Val loss: 0.5032 - LR: 0.00e+00\n","\tBest epoch: 87 - Best val accuracy: 0.8955 - Best val loss: 0.4340\n","\n","Source class: WAL | Domain: 58 | Accuracy: 0.7368 | Loss: 4.0844\n","\n","Domain: 59\n","x_syn_dom.shape: (333, 3, 128) | np.unique(y_syn_dom): [1 2 3]\n","x_dp_dom.shape: (43, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Fine-tuning on synthetic data...\n","\tEpoch 10/100 - Train loss: 0.3594 - Val accuracy: 0.9254 - Val loss: 0.1685 - LR: 9.00e-06\n","\tEpoch 20/100 - Train loss: 0.4415 - Val accuracy: 0.9403 - Val loss: 0.1332 - LR: 8.00e-06\n","\tEpoch 30/100 - Train loss: 0.2717 - Val accuracy: 0.9552 - Val loss: 0.1126 - LR: 7.00e-06\n","\tEpoch 40/100 - Train loss: 0.2642 - Val accuracy: 0.9701 - Val loss: 0.0967 - LR: 6.00e-06\n","\tEpoch 50/100 - Train loss: 0.3143 - Val accuracy: 0.9701 - Val loss: 0.0853 - LR: 5.00e-06\n","\tEpoch 60/100 - Train loss: 0.2314 - Val accuracy: 0.9701 - Val loss: 0.0822 - LR: 4.00e-06\n","\tEpoch 70/100 - Train loss: 0.3171 - Val accuracy: 0.9701 - Val loss: 0.0731 - LR: 3.00e-06\n","\tEpoch 80/100 - Train loss: 0.1700 - Val accuracy: 0.9851 - Val loss: 0.0713 - LR: 2.00e-06\n","\tEpoch 90/100 - Train loss: 0.2748 - Val accuracy: 0.9851 - Val loss: 0.0824 - LR: 1.00e-06\n","\tEpoch 100/100 - Train loss: 0.2533 - Val accuracy: 0.9701 - Val loss: 0.0626 - LR: 0.00e+00\n","\tBest epoch: 98 - Best val accuracy: 0.9701 - Best val loss: 0.0604\n","\n","Source class: WAL | Domain: 59 | Accuracy: 0.9535 | Loss: 0.0587\n","\n","Domain: 60\n","x_syn_dom.shape: (333, 3, 128) | np.unique(y_syn_dom): [1 2 3]\n","x_dp_dom.shape: (47, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Fine-tuning on synthetic data...\n","\tEpoch 10/100 - Train loss: 0.6762 - Val accuracy: 0.9104 - Val loss: 0.6293 - LR: 9.00e-06\n","\tEpoch 20/100 - Train loss: 0.5423 - Val accuracy: 0.9104 - Val loss: 0.4512 - LR: 8.00e-06\n","\tEpoch 30/100 - Train loss: 0.7473 - Val accuracy: 0.9403 - Val loss: 0.3204 - LR: 7.00e-06\n","\tEpoch 40/100 - Train loss: 0.3798 - Val accuracy: 0.9403 - Val loss: 0.2979 - LR: 6.00e-06\n","\tEpoch 50/100 - Train loss: 0.4551 - Val accuracy: 0.9254 - Val loss: 0.3567 - LR: 5.00e-06\n","\tEpoch 60/100 - Train loss: 0.3272 - Val accuracy: 0.9403 - Val loss: 0.2843 - LR: 4.00e-06\n","\tEpoch 70/100 - Train loss: 0.3085 - Val accuracy: 0.9403 - Val loss: 0.2573 - LR: 3.00e-06\n","\tEpoch 80/100 - Train loss: 0.3264 - Val accuracy: 0.9403 - Val loss: 0.2678 - LR: 2.00e-06\n","\tEpoch 90/100 - Train loss: 0.4628 - Val accuracy: 0.9403 - Val loss: 0.2749 - LR: 1.00e-06\n","\tEpoch 100/100 - Train loss: 0.3055 - Val accuracy: 0.9403 - Val loss: 0.2375 - LR: 0.00e+00\n","\tBest epoch: 94 - Best val accuracy: 0.9552 - Best val loss: 0.1879\n","\n","Source class: WAL | Domain: 60 | Accuracy: 0.6596 | Loss: 2.2574\n","\n","Domain: 61\n","x_syn_dom.shape: (333, 3, 128) | np.unique(y_syn_dom): [1 2 3]\n","x_dp_dom.shape: (47, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Fine-tuning on synthetic data...\n","\tEpoch 10/100 - Train loss: 0.2604 - Val accuracy: 0.8955 - Val loss: 0.2098 - LR: 9.00e-06\n","\tEpoch 20/100 - Train loss: 0.2936 - Val accuracy: 0.8955 - Val loss: 0.1984 - LR: 8.00e-06\n","\tEpoch 30/100 - Train loss: 0.1834 - Val accuracy: 0.9104 - Val loss: 0.1729 - LR: 7.00e-06\n","\tEpoch 40/100 - Train loss: 0.1271 - Val accuracy: 0.9254 - Val loss: 0.1395 - LR: 6.00e-06\n","\tEpoch 50/100 - Train loss: 0.1728 - Val accuracy: 0.9403 - Val loss: 0.1444 - LR: 5.00e-06\n","\tEpoch 60/100 - Train loss: 0.1386 - Val accuracy: 0.9403 - Val loss: 0.1450 - LR: 4.00e-06\n","\tEpoch 70/100 - Train loss: 0.1710 - Val accuracy: 0.9403 - Val loss: 0.1441 - LR: 3.00e-06\n","\tEpoch 80/100 - Train loss: 0.1364 - Val accuracy: 0.9552 - Val loss: 0.1309 - LR: 2.00e-06\n","\tEpoch 90/100 - Train loss: 0.0721 - Val accuracy: 0.9552 - Val loss: 0.1188 - LR: 1.00e-06\n","\tEpoch 100/100 - Train loss: 0.1415 - Val accuracy: 0.9552 - Val loss: 0.1270 - LR: 0.00e+00\n","\tBest epoch: 89 - Best val accuracy: 0.9403 - Best val loss: 0.1113\n","\n","Source class: WAL | Domain: 61 | Accuracy: 0.8085 | Loss: 0.8107\n","\n","Domain: 62\n","x_syn_dom.shape: (333, 3, 128) | np.unique(y_syn_dom): [1 2 3]\n","x_dp_dom.shape: (47, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Fine-tuning on synthetic data...\n","\tEpoch 10/100 - Train loss: 0.4562 - Val accuracy: 0.8507 - Val loss: 0.6363 - LR: 9.00e-06\n","\tEpoch 20/100 - Train loss: 0.3016 - Val accuracy: 0.8955 - Val loss: 0.4709 - LR: 8.00e-06\n","\tEpoch 30/100 - Train loss: 0.2571 - Val accuracy: 0.8955 - Val loss: 0.3748 - LR: 7.00e-06\n","\tEpoch 40/100 - Train loss: 0.3527 - Val accuracy: 0.8955 - Val loss: 0.3584 - LR: 6.00e-06\n","\tEpoch 50/100 - Train loss: 0.1748 - Val accuracy: 0.9104 - Val loss: 0.3302 - LR: 5.00e-06\n","\tEpoch 60/100 - Train loss: 0.2115 - Val accuracy: 0.9254 - Val loss: 0.2833 - LR: 4.00e-06\n","\tEpoch 70/100 - Train loss: 0.1012 - Val accuracy: 0.9254 - Val loss: 0.2863 - LR: 3.00e-06\n","\tEpoch 80/100 - Train loss: 0.1384 - Val accuracy: 0.9104 - Val loss: 0.2988 - LR: 2.00e-06\n","\tEpoch 90/100 - Train loss: 0.1529 - Val accuracy: 0.9254 - Val loss: 0.2467 - LR: 1.00e-06\n","\tEpoch 100/100 - Train loss: 0.1035 - Val accuracy: 0.9254 - Val loss: 0.2497 - LR: 0.00e+00\n","\tBest epoch: 87 - Best val accuracy: 0.9254 - Best val loss: 0.2389\n","\n","Source class: WAL | Domain: 62 | Accuracy: 0.9574 | Loss: 0.1116\n","\n","Domain: 63\n","x_syn_dom.shape: (333, 3, 128) | np.unique(y_syn_dom): [1 2 3]\n","x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Fine-tuning on synthetic data...\n","\tEpoch 10/100 - Train loss: 0.5666 - Val accuracy: 0.8806 - Val loss: 0.5457 - LR: 9.00e-06\n","\tEpoch 20/100 - Train loss: 0.4635 - Val accuracy: 0.8955 - Val loss: 0.4845 - LR: 8.00e-06\n","\tEpoch 30/100 - Train loss: 0.4653 - Val accuracy: 0.9254 - Val loss: 0.4311 - LR: 7.00e-06\n","\tEpoch 40/100 - Train loss: 0.3418 - Val accuracy: 0.9254 - Val loss: 0.3950 - LR: 6.00e-06\n","\tEpoch 50/100 - Train loss: 0.3086 - Val accuracy: 0.9254 - Val loss: 0.3801 - LR: 5.00e-06\n","\tEpoch 60/100 - Train loss: 0.3047 - Val accuracy: 0.9254 - Val loss: 0.3479 - LR: 4.00e-06\n","\tEpoch 70/100 - Train loss: 0.2803 - Val accuracy: 0.9254 - Val loss: 0.3331 - LR: 3.00e-06\n","\tEpoch 80/100 - Train loss: 0.2897 - Val accuracy: 0.9254 - Val loss: 0.3211 - LR: 2.00e-06\n","\tEpoch 90/100 - Train loss: 0.2210 - Val accuracy: 0.9254 - Val loss: 0.3178 - LR: 1.00e-06\n","\tEpoch 100/100 - Train loss: 0.3276 - Val accuracy: 0.9254 - Val loss: 0.3105 - LR: 0.00e+00\n","\tBest epoch: 94 - Best val accuracy: 0.9254 - Best val loss: 0.3054\n","\n","Source class: WAL | Domain: 63 | Accuracy: 0.7857 | Loss: 0.7123\n","\n","Domain: 64\n","x_syn_dom.shape: (336, 3, 128) | np.unique(y_syn_dom): [1 2 3]\n","x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Fine-tuning on synthetic data...\n","\tEpoch 10/100 - Train loss: 0.2740 - Val accuracy: 0.9265 - Val loss: 0.3464 - LR: 9.00e-06\n","\tEpoch 20/100 - Train loss: 0.1778 - Val accuracy: 0.9559 - Val loss: 0.2985 - LR: 8.00e-06\n","\tEpoch 30/100 - Train loss: 0.2628 - Val accuracy: 0.9559 - Val loss: 0.2812 - LR: 7.00e-06\n","\tEpoch 40/100 - Train loss: 0.1842 - Val accuracy: 0.9559 - Val loss: 0.2519 - LR: 6.00e-06\n","\tEpoch 50/100 - Train loss: 0.2318 - Val accuracy: 0.9559 - Val loss: 0.2358 - LR: 5.00e-06\n","\tEpoch 60/100 - Train loss: 0.1541 - Val accuracy: 0.9559 - Val loss: 0.2237 - LR: 4.00e-06\n","\tEpoch 70/100 - Train loss: 0.1269 - Val accuracy: 0.9559 - Val loss: 0.2111 - LR: 3.00e-06\n","\tEpoch 80/100 - Train loss: 0.1172 - Val accuracy: 0.9559 - Val loss: 0.2059 - LR: 2.00e-06\n","\tEpoch 90/100 - Train loss: 0.1323 - Val accuracy: 0.9559 - Val loss: 0.1964 - LR: 1.00e-06\n","\tEpoch 100/100 - Train loss: 0.1227 - Val accuracy: 0.9559 - Val loss: 0.1941 - LR: 0.00e+00\n","\tBest epoch: 93 - Best val accuracy: 0.9559 - Best val loss: 0.1864\n","\n","Source class: WAL | Domain: 64 | Accuracy: 0.9048 | Loss: 1.1850\n","\n","Domain: 65\n","x_syn_dom.shape: (333, 3, 128) | np.unique(y_syn_dom): [1 2 3]\n","x_dp_dom.shape: (50, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Fine-tuning on synthetic data...\n","\tEpoch 10/100 - Train loss: 0.1307 - Val accuracy: 0.9701 - Val loss: 0.0864 - LR: 9.00e-06\n","\tEpoch 20/100 - Train loss: 0.1122 - Val accuracy: 0.9701 - Val loss: 0.0489 - LR: 8.00e-06\n","\tEpoch 30/100 - Train loss: 0.0640 - Val accuracy: 0.9701 - Val loss: 0.0359 - LR: 7.00e-06\n","\tEpoch 40/100 - Train loss: 0.1314 - Val accuracy: 0.9701 - Val loss: 0.0524 - LR: 6.00e-06\n","\tEpoch 50/100 - Train loss: 0.0821 - Val accuracy: 0.9701 - Val loss: 0.0401 - LR: 5.00e-06\n","\tEpoch 60/100 - Train loss: 0.0647 - Val accuracy: 0.9851 - Val loss: 0.0325 - LR: 4.00e-06\n","\tEpoch 70/100 - Train loss: 0.0896 - Val accuracy: 0.9701 - Val loss: 0.0394 - LR: 3.00e-06\n","\tEpoch 80/100 - Train loss: 0.0331 - Val accuracy: 0.9701 - Val loss: 0.0334 - LR: 2.00e-06\n","\tEpoch 90/100 - Train loss: 0.0563 - Val accuracy: 1.0000 - Val loss: 0.0231 - LR: 1.00e-06\n","\tEpoch 100/100 - Train loss: 0.0679 - Val accuracy: 0.9851 - Val loss: 0.0243 - LR: 0.00e+00\n","\tBest epoch: 98 - Best val accuracy: 1.0000 - Best val loss: 0.0225\n","\n","Source class: WAL | Domain: 65 | Accuracy: 0.6600 | Loss: 2.6464\n","\n","Domain: 66\n","x_syn_dom.shape: (333, 3, 128) | np.unique(y_syn_dom): [1 2 3]\n","x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Fine-tuning on synthetic data...\n","\tEpoch 10/100 - Train loss: 0.1493 - Val accuracy: 0.9254 - Val loss: 0.1883 - LR: 9.00e-06\n","\tEpoch 20/100 - Train loss: 0.1524 - Val accuracy: 0.9552 - Val loss: 0.1617 - LR: 8.00e-06\n","\tEpoch 30/100 - Train loss: 0.1238 - Val accuracy: 0.9552 - Val loss: 0.1623 - LR: 7.00e-06\n","\tEpoch 40/100 - Train loss: 0.0864 - Val accuracy: 0.9552 - Val loss: 0.1551 - LR: 6.00e-06\n","\tEpoch 50/100 - Train loss: 0.1239 - Val accuracy: 0.9552 - Val loss: 0.1431 - LR: 5.00e-06\n","\tEpoch 60/100 - Train loss: 0.0910 - Val accuracy: 0.9552 - Val loss: 0.1325 - LR: 4.00e-06\n","\tEpoch 70/100 - Train loss: 0.1619 - Val accuracy: 0.9552 - Val loss: 0.1162 - LR: 3.00e-06\n","\tEpoch 80/100 - Train loss: 0.1001 - Val accuracy: 0.9552 - Val loss: 0.1329 - LR: 2.00e-06\n","\tEpoch 90/100 - Train loss: 0.0971 - Val accuracy: 0.9701 - Val loss: 0.0904 - LR: 1.00e-06\n","\tEpoch 100/100 - Train loss: 0.1164 - Val accuracy: 0.9701 - Val loss: 0.1234 - LR: 0.00e+00\n","\tBest epoch: 90 - Best val accuracy: 0.9701 - Best val loss: 0.0904\n","\n","Source class: WAL | Domain: 66 | Accuracy: 0.1667 | Loss: 11.1819\n","\n","Domain: 67\n","x_syn_dom.shape: (333, 3, 128) | np.unique(y_syn_dom): [1 2 3]\n","x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Fine-tuning on synthetic data...\n","\tEpoch 10/100 - Train loss: 0.5721 - Val accuracy: 0.9851 - Val loss: 0.0274 - LR: 9.00e-06\n","\tEpoch 20/100 - Train loss: 0.5995 - Val accuracy: 1.0000 - Val loss: 0.0194 - LR: 8.00e-06\n","\tEpoch 30/100 - Train loss: 0.6270 - Val accuracy: 1.0000 - Val loss: 0.0192 - LR: 7.00e-06\n","\tEpoch 40/100 - Train loss: 0.3046 - Val accuracy: 1.0000 - Val loss: 0.0134 - LR: 6.00e-06\n","\tEpoch 50/100 - Train loss: 0.4231 - Val accuracy: 1.0000 - Val loss: 0.0186 - LR: 5.00e-06\n","\tEpoch 60/100 - Train loss: 0.3015 - Val accuracy: 1.0000 - Val loss: 0.0109 - LR: 4.00e-06\n","\tEpoch 70/100 - Train loss: 0.3451 - Val accuracy: 1.0000 - Val loss: 0.0122 - LR: 3.00e-06\n","\tEpoch 80/100 - Train loss: 0.2683 - Val accuracy: 1.0000 - Val loss: 0.0096 - LR: 2.00e-06\n","\tEpoch 90/100 - Train loss: 0.2887 - Val accuracy: 1.0000 - Val loss: 0.0092 - LR: 1.00e-06\n","\tEpoch 100/100 - Train loss: 0.2820 - Val accuracy: 1.0000 - Val loss: 0.0101 - LR: 0.00e+00\n","\tBest epoch: 95 - Best val accuracy: 1.0000 - Best val loss: 0.0085\n","\n","Source class: WAL | Domain: 67 | Accuracy: 0.7381 | Loss: 2.6693\n","\n","Domain: 68\n","x_syn_dom.shape: (333, 3, 128) | np.unique(y_syn_dom): [1 2 3]\n","x_dp_dom.shape: (43, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Fine-tuning on synthetic data...\n","\tEpoch 10/100 - Train loss: 0.1690 - Val accuracy: 0.8955 - Val loss: 0.4976 - LR: 9.00e-06\n","\tEpoch 20/100 - Train loss: 0.1358 - Val accuracy: 0.8955 - Val loss: 0.4029 - LR: 8.00e-06\n","\tEpoch 30/100 - Train loss: 0.1617 - Val accuracy: 0.8955 - Val loss: 0.4017 - LR: 7.00e-06\n","\tEpoch 40/100 - Train loss: 0.1555 - Val accuracy: 0.8955 - Val loss: 0.3621 - LR: 6.00e-06\n","\tEpoch 50/100 - Train loss: 0.0666 - Val accuracy: 0.9104 - Val loss: 0.3388 - LR: 5.00e-06\n","\tEpoch 60/100 - Train loss: 0.0696 - Val accuracy: 0.9104 - Val loss: 0.3396 - LR: 4.00e-06\n","\tEpoch 70/100 - Train loss: 0.0817 - Val accuracy: 0.9104 - Val loss: 0.3482 - LR: 3.00e-06\n","\tEpoch 80/100 - Train loss: 0.2325 - Val accuracy: 0.9104 - Val loss: 0.2942 - LR: 2.00e-06\n","\tEpoch 90/100 - Train loss: 0.2564 - Val accuracy: 0.9254 - Val loss: 0.2746 - LR: 1.00e-06\n","\tEpoch 100/100 - Train loss: 0.0948 - Val accuracy: 0.9104 - Val loss: 0.3268 - LR: 0.00e+00\n","\tBest epoch: 90 - Best val accuracy: 0.9254 - Best val loss: 0.2746\n","\n","Source class: WAL | Domain: 68 | Accuracy: 0.8605 | Loss: 0.6693\n","\n","Domain: 69\n","x_syn_dom.shape: (333, 3, 128) | np.unique(y_syn_dom): [1 2 3]\n","x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Fine-tuning on synthetic data...\n","\tEpoch 10/100 - Train loss: 0.2836 - Val accuracy: 0.9552 - Val loss: 0.1735 - LR: 9.00e-06\n","\tEpoch 20/100 - Train loss: 0.2105 - Val accuracy: 0.9552 - Val loss: 0.1586 - LR: 8.00e-06\n","\tEpoch 30/100 - Train loss: 0.2130 - Val accuracy: 0.9552 - Val loss: 0.1452 - LR: 7.00e-06\n","\tEpoch 40/100 - Train loss: 0.2267 - Val accuracy: 0.9552 - Val loss: 0.1374 - LR: 6.00e-06\n","\tEpoch 50/100 - Train loss: 0.2126 - Val accuracy: 0.9552 - Val loss: 0.1249 - LR: 5.00e-06\n","\tEpoch 60/100 - Train loss: 0.1790 - Val accuracy: 0.9552 - Val loss: 0.1254 - LR: 4.00e-06\n","\tEpoch 70/100 - Train loss: 0.1381 - Val accuracy: 0.9552 - Val loss: 0.1143 - LR: 3.00e-06\n","\tEpoch 80/100 - Train loss: 0.1168 - Val accuracy: 0.9552 - Val loss: 0.1109 - LR: 2.00e-06\n","\tEpoch 90/100 - Train loss: 0.1544 - Val accuracy: 0.9552 - Val loss: 0.1126 - LR: 1.00e-06\n","\tEpoch 100/100 - Train loss: 0.2609 - Val accuracy: 0.9552 - Val loss: 0.1108 - LR: 0.00e+00\n","\tBest epoch: 96 - Best val accuracy: 0.9701 - Best val loss: 0.1090\n","\n","Source class: WAL | Domain: 69 | Accuracy: 0.9048 | Loss: 0.4575\n","\n","Domain: 70\n","x_syn_dom.shape: (333, 3, 128) | np.unique(y_syn_dom): [1 2 3]\n","x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Fine-tuning on synthetic data...\n","\tEpoch 10/100 - Train loss: 0.2980 - Val accuracy: 0.9552 - Val loss: 0.1402 - LR: 9.00e-06\n","\tEpoch 20/100 - Train loss: 0.2514 - Val accuracy: 0.9552 - Val loss: 0.1070 - LR: 8.00e-06\n","\tEpoch 30/100 - Train loss: 0.2650 - Val accuracy: 0.9552 - Val loss: 0.1015 - LR: 7.00e-06\n","\tEpoch 40/100 - Train loss: 0.2724 - Val accuracy: 0.9552 - Val loss: 0.0931 - LR: 6.00e-06\n","\tEpoch 50/100 - Train loss: 0.1742 - Val accuracy: 0.9701 - Val loss: 0.0749 - LR: 5.00e-06\n","\tEpoch 60/100 - Train loss: 0.2234 - Val accuracy: 0.9701 - Val loss: 0.0761 - LR: 4.00e-06\n","\tEpoch 70/100 - Train loss: 0.1829 - Val accuracy: 0.9701 - Val loss: 0.0700 - LR: 3.00e-06\n","\tEpoch 80/100 - Train loss: 0.1252 - Val accuracy: 0.9701 - Val loss: 0.0628 - LR: 2.00e-06\n","\tEpoch 90/100 - Train loss: 0.2256 - Val accuracy: 0.9701 - Val loss: 0.0646 - LR: 1.00e-06\n","\tEpoch 100/100 - Train loss: 0.1658 - Val accuracy: 0.9701 - Val loss: 0.0637 - LR: 0.00e+00\n","\tBest epoch: 91 - Best val accuracy: 0.9701 - Best val loss: 0.0609\n","\n","Source class: WAL | Domain: 70 | Accuracy: 0.8333 | Loss: 1.1107\n","\n","Domain: 71\n","x_syn_dom.shape: (333, 3, 128) | np.unique(y_syn_dom): [1 2 3]\n","x_dp_dom.shape: (44, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Fine-tuning on synthetic data...\n","\tEpoch 10/100 - Train loss: 0.4410 - Val accuracy: 0.8806 - Val loss: 0.3805 - LR: 9.00e-06\n","\tEpoch 20/100 - Train loss: 0.3662 - Val accuracy: 0.8806 - Val loss: 0.3278 - LR: 8.00e-06\n","\tEpoch 30/100 - Train loss: 0.3107 - Val accuracy: 0.8806 - Val loss: 0.2856 - LR: 7.00e-06\n","\tEpoch 40/100 - Train loss: 0.3116 - Val accuracy: 0.9104 - Val loss: 0.2477 - LR: 6.00e-06\n","\tEpoch 50/100 - Train loss: 0.2895 - Val accuracy: 0.9254 - Val loss: 0.2292 - LR: 5.00e-06\n","\tEpoch 60/100 - Train loss: 0.3391 - Val accuracy: 0.9403 - Val loss: 0.2148 - LR: 4.00e-06\n","\tEpoch 70/100 - Train loss: 0.1929 - Val accuracy: 0.9403 - Val loss: 0.1937 - LR: 3.00e-06\n","\tEpoch 80/100 - Train loss: 0.2207 - Val accuracy: 0.9552 - Val loss: 0.1892 - LR: 2.00e-06\n","\tEpoch 90/100 - Train loss: 0.2576 - Val accuracy: 0.9552 - Val loss: 0.1839 - LR: 1.00e-06\n","\tEpoch 100/100 - Train loss: 0.1984 - Val accuracy: 0.9552 - Val loss: 0.1754 - LR: 0.00e+00\n","\tBest epoch: 98 - Best val accuracy: 0.9552 - Best val loss: 0.1716\n","\n","Source class: WAL | Domain: 71 | Accuracy: 0.8636 | Loss: 0.7360\n","\n","Domain: 72\n","x_syn_dom.shape: (333, 3, 128) | np.unique(y_syn_dom): [1 2 3]\n","x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Fine-tuning on synthetic data...\n","\tEpoch 10/100 - Train loss: 0.4136 - Val accuracy: 0.9403 - Val loss: 0.2666 - LR: 9.00e-06\n","\tEpoch 20/100 - Train loss: 0.3116 - Val accuracy: 0.9254 - Val loss: 0.2122 - LR: 8.00e-06\n","\tEpoch 30/100 - Train loss: 0.2335 - Val accuracy: 0.9254 - Val loss: 0.1695 - LR: 7.00e-06\n","\tEpoch 40/100 - Train loss: 0.2194 - Val accuracy: 0.9403 - Val loss: 0.1475 - LR: 6.00e-06\n","\tEpoch 50/100 - Train loss: 0.2018 - Val accuracy: 0.9403 - Val loss: 0.1375 - LR: 5.00e-06\n","\tEpoch 60/100 - Train loss: 0.1951 - Val accuracy: 0.9403 - Val loss: 0.1120 - LR: 4.00e-06\n","\tEpoch 70/100 - Train loss: 0.2726 - Val accuracy: 0.9403 - Val loss: 0.1142 - LR: 3.00e-06\n","\tEpoch 80/100 - Train loss: 0.1859 - Val accuracy: 0.9403 - Val loss: 0.0996 - LR: 2.00e-06\n","\tEpoch 90/100 - Train loss: 0.1590 - Val accuracy: 0.9403 - Val loss: 0.0964 - LR: 1.00e-06\n","\tEpoch 100/100 - Train loss: 0.1442 - Val accuracy: 0.9403 - Val loss: 0.1002 - LR: 0.00e+00\n","\tBest epoch: 96 - Best val accuracy: 0.9552 - Best val loss: 0.0815\n","\n","Source class: WAL | Domain: 72 | Accuracy: 0.9048 | Loss: 0.5482\n","\n","Domain: 73\n","x_syn_dom.shape: (333, 3, 128) | np.unique(y_syn_dom): [1 2 3]\n","x_dp_dom.shape: (41, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Fine-tuning on synthetic data...\n","\tEpoch 10/100 - Train loss: 0.4706 - Val accuracy: 0.9254 - Val loss: 0.2227 - LR: 9.00e-06\n","\tEpoch 20/100 - Train loss: 0.4957 - Val accuracy: 0.9254 - Val loss: 0.1800 - LR: 8.00e-06\n","\tEpoch 30/100 - Train loss: 0.3553 - Val accuracy: 0.9552 - Val loss: 0.1357 - LR: 7.00e-06\n","\tEpoch 40/100 - Train loss: 0.3550 - Val accuracy: 0.9552 - Val loss: 0.1148 - LR: 6.00e-06\n","\tEpoch 50/100 - Train loss: 0.2255 - Val accuracy: 0.9552 - Val loss: 0.0945 - LR: 5.00e-06\n","\tEpoch 60/100 - Train loss: 0.3861 - Val accuracy: 0.9403 - Val loss: 0.0840 - LR: 4.00e-06\n","\tEpoch 70/100 - Train loss: 0.3037 - Val accuracy: 0.9552 - Val loss: 0.0772 - LR: 3.00e-06\n","\tEpoch 80/100 - Train loss: 0.1353 - Val accuracy: 0.9552 - Val loss: 0.0935 - LR: 2.00e-06\n","\tEpoch 90/100 - Train loss: 0.3465 - Val accuracy: 0.9552 - Val loss: 0.0829 - LR: 1.00e-06\n","\tEpoch 100/100 - Train loss: 0.1368 - Val accuracy: 0.9552 - Val loss: 0.0841 - LR: 0.00e+00\n","\tBest epoch: 94 - Best val accuracy: 0.9552 - Best val loss: 0.0720\n","\n","Source class: WAL | Domain: 73 | Accuracy: 0.8537 | Loss: 0.6963\n","\n","Domain: 74\n","x_syn_dom.shape: (333, 3, 128) | np.unique(y_syn_dom): [1 2 3]\n","x_dp_dom.shape: (35, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Fine-tuning on synthetic data...\n","\tEpoch 10/100 - Train loss: 0.4159 - Val accuracy: 0.9254 - Val loss: 0.1925 - LR: 9.00e-06\n","\tEpoch 20/100 - Train loss: 0.3796 - Val accuracy: 0.9254 - Val loss: 0.1571 - LR: 8.00e-06\n","\tEpoch 30/100 - Train loss: 0.3822 - Val accuracy: 0.9254 - Val loss: 0.1352 - LR: 7.00e-06\n","\tEpoch 40/100 - Train loss: 0.3338 - Val accuracy: 0.9254 - Val loss: 0.1164 - LR: 6.00e-06\n","\tEpoch 50/100 - Train loss: 0.3100 - Val accuracy: 0.9254 - Val loss: 0.1116 - LR: 5.00e-06\n","\tEpoch 60/100 - Train loss: 0.2554 - Val accuracy: 0.9403 - Val loss: 0.0972 - LR: 4.00e-06\n","\tEpoch 70/100 - Train loss: 0.2561 - Val accuracy: 0.9403 - Val loss: 0.0914 - LR: 3.00e-06\n","\tEpoch 80/100 - Train loss: 0.2270 - Val accuracy: 0.9403 - Val loss: 0.0829 - LR: 2.00e-06\n","\tEpoch 90/100 - Train loss: 0.2703 - Val accuracy: 0.9403 - Val loss: 0.0832 - LR: 1.00e-06\n","\tEpoch 100/100 - Train loss: 0.2297 - Val accuracy: 0.9403 - Val loss: 0.0803 - LR: 0.00e+00\n","\tBest epoch: 99 - Best val accuracy: 0.9403 - Best val loss: 0.0786\n","\n","Source class: WAL | Domain: 74 | Accuracy: 0.8000 | Loss: 2.0843\n","\n","Domain: 75\n","x_syn_dom.shape: (333, 3, 128) | np.unique(y_syn_dom): [1 2 3]\n","x_dp_dom.shape: (42, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Fine-tuning on synthetic data...\n","\tEpoch 10/100 - Train loss: 0.0930 - Val accuracy: 0.9851 - Val loss: 0.0971 - LR: 9.00e-06\n","\tEpoch 20/100 - Train loss: 0.1304 - Val accuracy: 0.9851 - Val loss: 0.0766 - LR: 8.00e-06\n","\tEpoch 30/100 - Train loss: 0.0832 - Val accuracy: 0.9851 - Val loss: 0.0709 - LR: 7.00e-06\n","\tEpoch 40/100 - Train loss: 0.0644 - Val accuracy: 0.9851 - Val loss: 0.0651 - LR: 6.00e-06\n","\tEpoch 50/100 - Train loss: 0.0668 - Val accuracy: 0.9851 - Val loss: 0.0545 - LR: 5.00e-06\n","\tEpoch 60/100 - Train loss: 0.0532 - Val accuracy: 0.9851 - Val loss: 0.0476 - LR: 4.00e-06\n","\tEpoch 70/100 - Train loss: 0.0403 - Val accuracy: 0.9851 - Val loss: 0.0457 - LR: 3.00e-06\n","\tEpoch 80/100 - Train loss: 0.0819 - Val accuracy: 0.9851 - Val loss: 0.0412 - LR: 2.00e-06\n","\tEpoch 90/100 - Train loss: 0.0483 - Val accuracy: 0.9851 - Val loss: 0.0367 - LR: 1.00e-06\n","\tEpoch 100/100 - Train loss: 0.0648 - Val accuracy: 0.9851 - Val loss: 0.0414 - LR: 0.00e+00\n","\tBest epoch: 82 - Best val accuracy: 0.9851 - Best val loss: 0.0360\n","\n","Source class: WAL | Domain: 75 | Accuracy: 0.9524 | Loss: 0.2276\n","\n","Mean accuracy: 0.7942\n","\n"]}],"source":["def compute_TSTR_Df_Syn(dataset):\n","    accs = []\n","\n","    for src_class in config[dataset]['class_names']:\n","        if src_class != 'WAL':\n","            continue\n","\n","        print(f\"Source class: {src_class}\\n\")\n","\n","        # Load Df data\n","        x_df, y_df, k_df = get_data(dataset, 'df', src_class)\n","        print(f'x_df.shape: {x_df.shape} | np.unique(y_df): {np.unique(y_df)}\\n')\n","\n","        # Train on Df data\n","        print('Training on Df data...')\n","        df_model = train_only(x_df, y_df, dataset, num_epochs=100)\n","\n","        for domain in range(config[dataset]['num_df_domains'], config[dataset]['num_df_domains'] + config[dataset]['num_dp_domains']):\n","            print(f\"Domain: {domain}\")\n","\n","            # Load synthetic data\n","            x_syn_dom, y_syn_dom, k_syn_dom = get_syn_data(dataset, syn_name, src_class, domain)\n","            print(f'x_syn_dom.shape: {x_syn_dom.shape} | np.unique(y_syn_dom): {np.unique(y_syn_dom)}')\n","\n","            # Load Dp data\n","            x_dp_dom, y_dp_dom, k_dp_dom = get_data(dataset, 'dp', src_class, domain)\n","            print(f'x_dp_dom.shape: {x_dp_dom.shape} | np.unique(y_dp_dom): {np.unique(y_dp_dom)}\\n')\n","\n","            # Fine-tune Df model on synthetic data and evaluate on Dp data\n","            print('Fine-tuning on synthetic data...')\n","            df_syn_model = fine_tune(copy.deepcopy(df_model), x_syn_dom, y_syn_dom, num_epochs=100)\n","            acc, loss = evaluate_model(df_syn_model, get_dataloader(x_dp_dom, y_dp_dom))\n","            save_scores(src_class, domain, acc, loss, 'Df_Syn', dataset)\n","            accs.append(acc)\n","            print(f'Source class: {src_class} | Domain: {domain} | Accuracy: {acc:.4f} | Loss: {loss:.4f}\\n')\n","\n","    print(f\"Mean accuracy: {np.mean(accs):.4f}\\n\")\n","\n","\n","\n","\n","compute_TSTR_Df_Syn('realworld_mobiact')"]},{"cell_type":"code","execution_count":6,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":180114,"status":"ok","timestamp":1731667312121,"user":{"displayName":"Pietro ST","userId":"01777116294553213330"},"user_tz":-60},"id":"WrQyLH7NMxLn","outputId":"cf416e8e-9d33-4958-9dfb-603c0788709c"},"outputs":[{"output_type":"stream","name":"stdout","text":["Source class: WAL\n","\n","x_df.shape: (7958, 3, 128) | np.unique(y_df): [1 2 3]\n","\n","Training on Df data...\n","\tEpoch 10/100 - Train loss: 0.0276 - Val accuracy: 0.9812 - Val loss: 0.0455 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.0071 - Val accuracy: 0.9868 - Val loss: 0.0440 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.0044 - Val accuracy: 0.9862 - Val loss: 0.0441 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.0014 - Val accuracy: 0.9874 - Val loss: 0.0478 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.0010 - Val accuracy: 0.9862 - Val loss: 0.0498 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.0005 - Val accuracy: 0.9849 - Val loss: 0.0547 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0004 - Val accuracy: 0.9856 - Val loss: 0.0548 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0002 - Val accuracy: 0.9874 - Val loss: 0.0497 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0002 - Val accuracy: 0.9874 - Val loss: 0.0526 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0002 - Val accuracy: 0.9874 - Val loss: 0.0529 - LR: 0.00e+00\n","\tBest epoch: 15 - Best val accuracy: 0.9849 - Best val loss: 0.0415\n","\n","x_syn.shape: (30921, 3, 128) | np.unique(y_syn): [1 2 3]\n","x_dp.shape: (2814, 3, 128) | np.unique(y_dp): [1 2 3]\n","\n","Fine-tuning on synthetic data...\n","\tEpoch 10/100 - Train loss: 0.1399 - Val accuracy: 0.9720 - Val loss: 0.0949 - LR: 9.00e-06\n","\tEpoch 20/100 - Train loss: 0.0752 - Val accuracy: 0.9892 - Val loss: 0.0456 - LR: 8.00e-06\n","\tEpoch 30/100 - Train loss: 0.0547 - Val accuracy: 0.9932 - Val loss: 0.0306 - LR: 7.00e-06\n","\tEpoch 40/100 - Train loss: 0.0457 - Val accuracy: 0.9950 - Val loss: 0.0235 - LR: 6.00e-06\n","\tEpoch 50/100 - Train loss: 0.0410 - Val accuracy: 0.9951 - Val loss: 0.0210 - LR: 5.00e-06\n","\tEpoch 60/100 - Train loss: 0.0370 - Val accuracy: 0.9956 - Val loss: 0.0189 - LR: 4.00e-06\n","\tEpoch 70/100 - Train loss: 0.0337 - Val accuracy: 0.9964 - Val loss: 0.0175 - LR: 3.00e-06\n","\tEpoch 80/100 - Train loss: 0.0334 - Val accuracy: 0.9969 - Val loss: 0.0156 - LR: 2.00e-06\n","\tEpoch 90/100 - Train loss: 0.0306 - Val accuracy: 0.9968 - Val loss: 0.0151 - LR: 1.00e-06\n","\tEpoch 100/100 - Train loss: 0.0308 - Val accuracy: 0.9968 - Val loss: 0.0150 - LR: 0.00e+00\n","\tBest epoch: 99 - Best val accuracy: 0.9974 - Best val loss: 0.0148\n","\n","Source class: WAL | Domain: All | Accuracy: 0.8280 | Loss: 0.6170\n","\n","Mean accuracy: 0.8280\n","\n"]}],"source":["def compute_TSTR_Df_Syn_all(dataset):\n","    accs = []\n","\n","    for src_class in config[dataset]['class_names']:\n","        if src_class != 'WAL':\n","            continue\n","\n","        print(f\"Source class: {src_class}\\n\")\n","\n","        # Load Df data\n","        x_df, y_df, k_df = get_data(dataset, 'df', src_class)\n","        print(f'x_df.shape: {x_df.shape} | np.unique(y_df): {np.unique(y_df)}\\n')\n","\n","        # Train on Df data\n","        print('Training on Df data...')\n","        df_model = train_only(x_df, y_df, dataset, num_epochs=100)\n","\n","        # Load synthetic data\n","        x_syn, y_syn, k_syn = get_syn_data(dataset, syn_name, src_class)\n","        print(f'x_syn.shape: {x_syn.shape} | np.unique(y_syn): {np.unique(y_syn)}')\n","\n","        # Load Dp data\n","        x_dp, y_dp, k_dp = get_data(dataset, 'dp', src_class)\n","        print(f'x_dp.shape: {x_dp.shape} | np.unique(y_dp): {np.unique(y_dp)}\\n')\n","\n","        # Fine-tune Df model on synthetic data and evaluate on Dp data\n","        print('Fine-tuning on synthetic data...')\n","        df_syn_model = fine_tune(copy.deepcopy(df_model), x_syn, y_syn, num_epochs=100)\n","        acc, loss = evaluate_model(df_syn_model, get_dataloader(x_dp, y_dp))\n","        save_scores(src_class, 100, acc, loss, 'Df_Syn_all', dataset)\n","        accs.append(acc)\n","        print(f'Source class: {src_class} | Domain: All | Accuracy: {acc:.4f} | Loss: {loss:.4f}\\n')\n","\n","    print(f\"Mean accuracy: {np.mean(accs):.4f}\\n\")\n","\n","\n","\n","\n","compute_TSTR_Df_Syn_all('realworld_mobiact')"]},{"cell_type":"markdown","metadata":{"id":"fLSuTddOmD5c"},"source":["# TSTRFS"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"wZqvTTwNCPto"},"outputs":[],"source":["def compute_TSTRFS_Dpfs(dataset):\n","    accs = []\n","\n","    for src_class in config[dataset]['class_names']:\n","        if src_class != 'WAL':\n","            continue\n","\n","        print(f\"Source class: {src_class}\\n\")\n","\n","        for domain in range(config[dataset]['num_df_domains'], config[dataset]['num_df_domains'] + config[dataset]['num_dp_domains']):\n","            print(f\"Domain: {domain}\")\n","\n","            # Load Dpfs data\n","            x_dpfs_dom, y_dpfs_dom, k_dpfs_dom = get_data(dataset, 'dpfs', src_class, domain)\n","            print(f'x_dpfs_dom.shape: {x_dpfs_dom.shape} | np.unique(y_dpfs_dom): {np.unique(y_dpfs_dom)}')\n","\n","            # Load Dp data\n","            x_dp_dom, y_dp_dom, k_dp_dom = get_data(dataset, 'dp', src_class, domain)\n","            print(f'x_dp_dom.shape: {x_dp_dom.shape} | np.unique(y_dp_dom): {np.unique(y_dp_dom)}\\n')\n","\n","            # Train on Dpfs data and test on Dp data\n","            print('Training on Dpfs data...')\n","            acc, loss = train_and_test(x_dpfs_dom, y_dpfs_dom, x_dp_dom, y_dp_dom, dataset, num_epochs=100)\n","            save_scores(src_class, domain, acc, loss, 'FS_Dpfs', dataset)\n","            accs.append(acc)\n","            print(f'Source class: {src_class} | Domain: {domain} | Accuracy: {acc:.4f} | Loss: {loss:.4f}\\n')\n","\n","    print(f\"Mean accuracy: {np.mean(accs):.4f}\\n\")\n","\n","\n","\n","compute_TSTRFS_Dpfs('realworld_mobiact')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"YOqZB6ARCPtp"},"outputs":[],"source":["def compute_TSTRFS_Df_Dpfs(dataset):\n","    accs = []\n","\n","    for src_class in config[dataset]['class_names']:\n","        if src_class != 'WAL':\n","            continue\n","\n","        print(f\"Source class: {src_class}\\n\")\n","\n","        # Load Df data\n","        x_df, y_df, k_df = get_data(dataset, 'df', src_class)\n","        print(f'x_df.shape: {x_df.shape} | np.unique(y_df): {np.unique(y_df)}\\n')\n","\n","        # Train on Df data\n","        print('Training on Df data...')\n","        df_model = train_only(x_df, y_df, dataset, num_epochs=100)\n","\n","        for domain in range(config[dataset]['num_df_domains'], config[dataset]['num_df_domains'] + config[dataset]['num_dp_domains']):\n","            print(f\"Domain: {domain}\")\n","\n","            # Load Dpfs data\n","            x_dpfs_dom, y_dpfs_dom, k_dpfs_dom = get_data(dataset, 'dpfs', src_class, domain)\n","            print(f'x_dpfs_dom.shape: {x_dpfs_dom.shape} | np.unique(y_dpfs_dom): {np.unique(y_dpfs_dom)}')\n","\n","            # Load Dp data\n","            x_dp_dom, y_dp_dom, k_dp_dom = get_data(dataset, 'dp', src_class, domain)\n","            print(f'x_dp_dom.shape: {x_dp_dom.shape} | np.unique(y_dp_dom): {np.unique(y_dp_dom)}\\n')\n","\n","            # Fine-tune Df model on Dpfs data and test on Dp data\n","            print('Fine-tuning on Dpfs data...')\n","            df_dpfs_model = fine_tune(copy.deepcopy(df_model), x_dpfs_dom, y_dpfs_dom, num_epochs=100)\n","            acc, loss = evaluate_model(df_dpfs_model, get_dataloader(x_dp_dom, y_dp_dom))\n","            save_scores(src_class, domain, acc, loss, 'FS_Df_Dpfs', dataset)\n","            accs.append(acc)\n","            print(f'Source class: {src_class} | Domain: {domain} | Accuracy: {acc:.4f} | Loss: {loss:.4f}\\n')\n","\n","    print(f\"Mean accuracy: {np.mean(accs):.4f}\\n\")\n","\n","\n","\n","compute_TSTRFS_Df_Dpfs('realworld_mobiact')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"oA89psVZg5yb"},"outputs":[],"source":["def compute_TSTRFS_Syn(dataset):\n","    accs = []\n","\n","    for src_class in config[dataset]['class_names']:\n","        if src_class != 'WAL':\n","            continue\n","\n","        print(f\"Source class: {src_class}\\n\")\n","\n","        for domain in range(config[dataset]['num_df_domains'], config[dataset]['num_df_domains'] + config[dataset]['num_dp_domains']):\n","            print(f\"Domain: {domain}\")\n","\n","            # Load synthetic data\n","            x_syn_dom, y_syn_dom, k_syn_dom = get_syn_data(dataset, syn_name, src_class, domain)\n","            print(f'x_syn_dom.shape: {x_syn_dom.shape} | np.unique(y_syn_dom): {np.unique(y_syn_dom)}')\n","\n","            # Load Dp data\n","            x_dp_dom, y_dp_dom, k_dp_dom = get_data(dataset, 'dp', src_class, domain)\n","            print(f'x_dp_dom.shape: {x_dp_dom.shape} | np.unique(y_dp_dom): {np.unique(y_dp_dom)}\\n')\n","\n","            # Train on synthetic data and evaluate on Dp data\n","            print('Training on synthetic data...')\n","            acc, loss = train_and_test(x_syn_dom, y_syn_dom, x_dp_dom, y_dp_dom, dataset, num_epochs=100)\n","            save_scores(src_class, domain, acc, loss, 'FS_Syn', dataset)\n","            accs.append(acc)\n","            print(f'Source class: {src_class} | Domain: {domain} | Accuracy: {acc:.4f} | Loss: {loss:.4f}\\n')\n","\n","    print(f\"Mean accuracy: {np.mean(accs):.4f}\\n\")\n","\n","\n","\n","\n","compute_TSTRFS_Syn('realworld_mobiact')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"38LHCQjRCPtp"},"outputs":[],"source":["def compute_TSTRFS_Df_Syn(dataset):\n","    accs = []\n","\n","    for src_class in config[dataset]['class_names']:\n","        if src_class != 'WAL':\n","            continue\n","\n","        print(f\"Source class: {src_class}\\n\")\n","\n","        # Load Df data\n","        x_df, y_df, k_df = get_data(dataset, 'df', src_class)\n","        print(f'x_df.shape: {x_df.shape} | np.unique(y_df): {np.unique(y_df)}\\n')\n","\n","        # Train on Df data\n","        print('Training on Df data...')\n","        df_model = train_only(x_df, y_df, dataset, num_epochs=100)\n","\n","        for domain in range(config[dataset]['num_df_domains'], config[dataset]['num_df_domains'] + config[dataset]['num_dp_domains']):\n","            print(f\"Domain: {domain}\")\n","\n","            # Load synthetic data\n","            x_syn_dom, y_syn_dom, k_syn_dom = get_syn_data(dataset, syn_name, src_class, domain)\n","            print(f'x_syn_dom.shape: {x_syn_dom.shape} | np.unique(y_syn_dom): {np.unique(y_syn_dom)}')\n","\n","            # Load Dp data\n","            x_dp_dom, y_dp_dom, k_dp_dom = get_data(dataset, 'dp', src_class, domain)\n","            print(f'x_dp_dom.shape: {x_dp_dom.shape} | np.unique(y_dp_dom): {np.unique(y_dp_dom)}\\n')\n","\n","            # Fine-tune Df model on synthetic data and evaluate on Dp data\n","            print('Fine-tuning on synthetic data...')\n","            df_syn_model = fine_tune(copy.deepcopy(df_model), x_syn_dom, y_syn_dom, num_epochs=100)\n","            acc, loss = evaluate_model(df_syn_model, get_dataloader(x_dp_dom, y_dp_dom))\n","            save_scores(src_class, domain, acc, loss, 'FS_Df_Syn', dataset)\n","            accs.append(acc)\n","            print(f'Source class: {src_class} | Domain: {domain} | Accuracy: {acc:.4f} | Loss: {loss:.4f}\\n')\n","\n","    print(f\"Mean accuracy: {np.mean(accs):.4f}\\n\")\n","\n","\n","\n","\n","compute_TSTRFS_Df_Syn('realworld_mobiact')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ueNEmwhVCPtp"},"outputs":[],"source":["def compute_TSTRFS_Syn_Dpfs(dataset):\n","    accs = []\n","\n","    for src_class in config[dataset]['class_names']:\n","        if src_class != 'WAL':\n","            continue\n","\n","        print(f\"Source class: {src_class}\\n\")\n","\n","        for domain in range(config[dataset]['num_df_domains'], config[dataset]['num_df_domains'] + config[dataset]['num_dp_domains']):\n","            print(f\"Domain: {domain}\")\n","\n","            # Load synthetic data\n","            x_syn_dom, y_syn_dom, k_syn_dom = get_syn_data(dataset, syn_name, src_class, domain)\n","            print(f'x_syn_dom.shape: {x_syn_dom.shape} | np.unique(y_syn_dom): {np.unique(y_syn_dom)}')\n","\n","            # Load Dpfs data\n","            x_dpfs_dom, y_dpfs_dom, k_dpfs_dom = get_data(dataset, 'dpfs', src_class, domain)\n","            print(f'x_dpfs_dom.shape: {x_dpfs_dom.shape} | np.unique(y_dpfs_dom): {np.unique(y_dpfs_dom)}')\n","\n","            # Load Dp data\n","            x_dp_dom, y_dp_dom, k_dp_dom = get_data(dataset, 'dp', src_class, domain)\n","            print(f'x_dp_dom.shape: {x_dp_dom.shape} | np.unique(y_dp_dom): {np.unique(y_dp_dom)}\\n')\n","\n","            # Train on synthetic data\n","            print('Training on synthetic data...')\n","            syn_model = train_only(x_syn_dom, y_syn_dom, dataset, num_epochs=100)\n","\n","            # Fine-tune synthetic model on Dpfs data and evaluate on Dp data\n","            print('Fine-tuning on Dpfs data...')\n","            syn_dpfs_model = fine_tune(copy.deepcopy(syn_model), x_dpfs_dom, y_dpfs_dom, num_epochs=100)\n","            acc, loss = evaluate_model(syn_dpfs_model, get_dataloader(x_dp_dom, y_dp_dom))\n","            save_scores(src_class, domain, acc, loss, 'FS_Syn_Dpfs', dataset)\n","            accs.append(acc)\n","            print(f'Source class: {src_class} | Domain: {domain} | Accuracy: {acc:.4f} | Loss: {loss:.4f}\\n')\n","\n","    print(f\"Mean accuracy: {np.mean(accs):.4f}\\n\")\n","\n","\n","\n","\n","compute_TSTRFS_Syn_Dpfs('realworld_mobiact')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"7z0xuuhhCPtp"},"outputs":[],"source":["def compute_TSTRFS_Df_Syn_Dpfs(dataset):\n","    accs = []\n","\n","    for src_class in config[dataset]['class_names']:\n","        if src_class != 'WAL':\n","            continue\n","\n","        print(f\"Source class: {src_class}\\n\")\n","\n","        # Load Df data\n","        x_df, y_df, k_df = get_data(dataset, 'df', src_class)\n","        print(f'x_df.shape: {x_df.shape} | np.unique(y_df): {np.unique(y_df)}\\n')\n","\n","        # Train on Df data\n","        print('Training on Df data...')\n","        df_model = train_only(x_df, y_df, dataset, num_epochs=100)\n","\n","        for domain in range(config[dataset]['num_df_domains'], config[dataset]['num_df_domains'] + config[dataset]['num_dp_domains']):\n","            print(f\"Domain: {domain}\")\n","\n","            # Load synthetic data\n","            x_syn_dom, y_syn_dom, k_syn_dom = get_syn_data(dataset, syn_name, src_class, domain)\n","            print(f'x_syn_dom.shape: {x_syn_dom.shape} | np.unique(y_syn_dom): {np.unique(y_syn_dom)}')\n","\n","            # Load Dpfs data\n","            x_dpfs_dom, y_dpfs_dom, k_dpfs_dom = get_data(dataset, 'dpfs', src_class, domain)\n","            print(f'x_dpfs_dom.shape: {x_dpfs_dom.shape} | np.unique(y_dpfs_dom): {np.unique(y_dpfs_dom)}')\n","\n","            # Load Dp data\n","            x_dp_dom, y_dp_dom, k_dp_dom = get_data(dataset, 'dp', src_class, domain)\n","            print(f'x_dp_dom.shape: {x_dp_dom.shape} | np.unique(y_dp_dom): {np.unique(y_dp_dom)}\\n')\n","\n","            # Fine-tune Df model on synthetic data\n","            print('Fine-tuning on synthetic data...')\n","            df_syn_model = fine_tune(copy.deepcopy(df_model), x_syn_dom, y_syn_dom, num_epochs=100)\n","\n","            # Fine-tune Df-syn model on Dpfs data and evaluate on Dp data\n","            print('Fine-tuning on Dpfs data...')\n","            df_syn_dpfs_model = fine_tune(copy.deepcopy(df_syn_model), x_dpfs_dom, y_dpfs_dom, num_epochs=100)\n","            acc, loss = evaluate_model(df_syn_dpfs_model, get_dataloader(x_dp_dom, y_dp_dom))\n","            save_scores(src_class, domain, acc, loss, 'FS_Df_Syn_Dpfs', dataset)\n","            accs.append(acc)\n","            print(f'Source class: {src_class} | Domain: {domain} | Accuracy: {acc:.4f} | Loss: {loss:.4f}\\n')\n","\n","    print(f\"Mean accuracy: {np.mean(accs):.4f}\\n\")\n","\n","\n","\n","\n","compute_TSTRFS_Df_Syn_Dpfs('realworld_mobiact')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"zpB3ecNGmD5f"},"outputs":[],"source":["def compute_TSTRFS_Df_plus_Dpfs(dataset):\n","    accs = []\n","\n","    for src_class in config[dataset]['class_names']:\n","        if src_class != 'WAL':\n","            continue\n","\n","        print(f\"Source class: {src_class}\\n\")\n","\n","        # Load Df data\n","        x_df, y_df, k_df = get_data(dataset, 'df', src_class)\n","        print(f'x_df.shape: {x_df.shape} | np.unique(y_df): {np.unique(y_df)}\\n')\n","\n","        for domain in range(config[dataset]['num_df_domains'], config[dataset]['num_df_domains'] + config[dataset]['num_dp_domains']):\n","            print(f\"Domain: {domain}\")\n","\n","            # Load Dpfs data\n","            x_dpfs_dom, y_dpfs_dom, k_dpfs_dom = get_data(dataset, 'dpfs', src_class, domain)\n","            print(f'x_dpfs_dom.shape: {x_dpfs_dom.shape} | np.unique(y_dpfs_dom): {np.unique(y_dpfs_dom)}')\n","\n","            # Join Df and Dpfs data\n","            x_df_dpfs = np.concatenate([x_df, x_dpfs_dom], axis=0)\n","            y_df_dpfs = np.concatenate([y_df, y_dpfs_dom], axis=0)\n","            k_df_dpfs = np.concatenate([k_df, k_dpfs_dom], axis=0)\n","            print(f'x_df_dpfs.shape: {x_df_dpfs.shape} | np.unique(y_df_dpfs): {np.unique(y_df_dpfs)}')\n","\n","            # Load Dp data\n","            x_dp_dom, y_dp_dom, k_dp_dom = get_data(dataset, 'dp', src_class, domain)\n","            print(f'x_dp_dom.shape: {x_dp_dom.shape} | np.unique(y_dp_dom): {np.unique(y_dp_dom)}\\n')\n","\n","            # Train on Df plus Dpfs data and test on Dp data\n","            print('Training on Df plus Dpfs data...')\n","            acc, loss = train_and_test(x_df_dpfs, y_df_dpfs, x_dp_dom, y_dp_dom, dataset, num_epochs=100)\n","            save_scores(src_class, domain, acc, loss, 'FS_Df_plus_Dpfs', dataset)\n","            accs.append(acc)\n","            print(f'Source class: {src_class} | Domain: {domain} | Accuracy: {acc:.4f} | Loss: {loss:.4f}\\n')\n","\n","    print(f\"Mean accuracy: {np.mean(accs):.4f}\\n\")\n","\n","\n","\n","compute_TSTRFS_Df_plus_Dpfs('realworld_mobiact')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"RYl0a9ZJmD5f"},"outputs":[],"source":["def compute_TSTRFS_Df_plus_Syn(dataset):\n","    accs = []\n","\n","    for src_class in config[dataset]['class_names']:\n","        if src_class != 'WAL':\n","            continue\n","\n","        print(f\"Source class: {src_class}\\n\")\n","\n","        # Load Df data\n","        x_df, y_df, k_df = get_data(dataset, 'df', src_class)\n","        print(f'x_df.shape: {x_df.shape} | np.unique(y_df): {np.unique(y_df)}\\n')\n","\n","        for domain in range(config[dataset]['num_df_domains'], config[dataset]['num_df_domains'] + config[dataset]['num_dp_domains']):\n","            print(f\"Domain: {domain}\")\n","\n","            # Load synthetic data\n","            x_syn_dom, y_syn_dom, k_syn_dom = get_syn_data(dataset, syn_name, src_class, domain)\n","            print(f'x_syn_dom.shape: {x_syn_dom.shape} | np.unique(y_syn_dom): {np.unique(y_syn_dom)}')\n","\n","            # Join Df and synthetic data\n","            x_df_syn = np.concatenate([x_df, x_syn_dom], axis=0)\n","            y_df_syn = np.concatenate([y_df, y_syn_dom], axis=0)\n","            k_df_syn = np.concatenate([k_df, k_syn_dom], axis=0)\n","            print(f'x_df_syn.shape: {x_df_syn.shape} | np.unique(y_df_syn): {np.unique(y_df_syn)}')\n","\n","            # Load Dp data\n","            x_dp_dom, y_dp_dom, k_dp_dom = get_data(dataset, 'dp', src_class, domain)\n","            print(f'x_dp_dom.shape: {x_dp_dom.shape} | np.unique(y_dp_dom): {np.unique(y_dp_dom)}\\n')\n","\n","            # Train on Df plus synthetic data and test on Dp data\n","            print('Training on Df plus synthetic data...')\n","            acc, loss = train_and_test(x_df, y_df, x_dp_dom, y_dp_dom, dataset, num_epochs=100)\n","            save_scores(src_class, domain, acc, loss, 'FS_Df_plus_Syn', dataset)\n","            accs.append(acc)\n","            print(f'Source class: {src_class} | Domain: {domain} | Accuracy: {acc:.4f} | Loss: {loss:.4f}\\n')\n","\n","    print(f\"Mean accuracy: {np.mean(accs):.4f}\\n\")\n","\n","\n","\n","\n","compute_TSTRFS_Df_plus_Syn('realworld_mobiact')"]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[]},"kernelspec":{"display_name":"stargan-v2","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.13"}},"nbformat":4,"nbformat_minor":0}