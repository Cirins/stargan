{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":49913,"status":"ok","timestamp":1732700095290,"user":{"displayName":"Pietro Castelvetri","userId":"04218697278633758016"},"user_tz":-60},"id":"I0_1KsKpCPtk","outputId":"d5d4b745-321e-4168-c4e8-9d6b432ed3e2"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n","/content/drive/MyDrive/ST/stargan\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')\n","\n","%cd drive/MyDrive/ST/stargan"]},{"cell_type":"markdown","metadata":{"id":"lLVVBGiQmD5W"},"source":["# Configuration"]},{"cell_type":"code","execution_count":2,"metadata":{"executionInfo":{"elapsed":9665,"status":"ok","timestamp":1732700104951,"user":{"displayName":"Pietro Castelvetri","userId":"04218697278633758016"},"user_tz":-60},"id":"yh05UGFkCPtm"},"outputs":[],"source":["import pickle\n","import numpy as np\n","from sklearn.model_selection import train_test_split, StratifiedKFold\n","from sklearn.metrics import accuracy_score, f1_score\n","import torch\n","import torch.nn as nn\n","from torch.utils.data import DataLoader, TensorDataset\n","from torch.optim.lr_scheduler import LambdaLR\n","import torch.optim as optim\n","import os\n","import csv\n","import random\n","import copy\n","\n","seed = 2710\n","torch.manual_seed(seed)\n","torch.cuda.manual_seed(seed)\n","np.random.seed(seed)\n","random.seed(seed)"]},{"cell_type":"code","execution_count":3,"metadata":{"executionInfo":{"elapsed":5,"status":"ok","timestamp":1732700104952,"user":{"displayName":"Pietro Castelvetri","userId":"04218697278633758016"},"user_tz":-60},"id":"UJN2bKbaCPtm"},"outputs":[],"source":["config = {\n","    'realworld': {\n","        'dataset_name': 'realworld',\n","        'num_df_domains': 10,\n","        'num_dp_domains': 5,\n","        'num_classes': 4,\n","        'class_names': ['WAL', 'RUN', 'CLD', 'CLU'],\n","        'num_timesteps': 128,\n","        'num_channels': 3,\n","        'num_classes': 4,\n","    },\n","    'cwru': {\n","        'dataset_name': 'cwru_256_3ch_5cl',\n","        'num_df_domains': 4,\n","        'num_dp_domains': 4,\n","        'num_classes': 5,\n","        'class_names': ['IR', 'Ball', 'OR_centred', 'OR_orthogonal', 'OR_opposite'],\n","        'num_timesteps': 256,\n","        'num_channels': 3,\n","        'num_classes': 5,\n","    },\n","    'realworld_mobiact': {\n","        'dataset_name': 'realworld_mobiact',\n","        'num_df_domains': 15,\n","        'num_dp_domains': 61,\n","        'num_classes': 4,\n","        'class_names': ['WAL', 'RUN', 'CLD', 'CLU'],\n","        'num_timesteps': 128,\n","        'num_channels': 3,\n","        'num_classes': 4,\n","    },\n","    'mobiact_realworld': {\n","        'dataset_name': 'mobiact_realworld',\n","        'num_df_domains': 61,\n","        'num_dp_domains': 15,\n","        'num_classes': 4,\n","        'class_names': ['WAL', 'RUN', 'CLD', 'CLU'],\n","        'num_timesteps': 128,\n","        'num_channels': 3,\n","        'num_classes': 4,\n","    }\n","}\n","\n","syn_name = 'marw01_wal'\n","num_epochs = 100\n","num_runs = 10"]},{"cell_type":"code","execution_count":4,"metadata":{"executionInfo":{"elapsed":6,"status":"ok","timestamp":1732700104953,"user":{"displayName":"Pietro Castelvetri","userId":"04218697278633758016"},"user_tz":-60},"id":"XwSwaF-LCPtn"},"outputs":[],"source":["def get_data(dataset, domains_set, src_class, domain=None, rot=False):\n","    # Load configurations\n","    dataset_name = config[dataset]['dataset_name']\n","    class_idx = config[dataset]['class_names'].index(src_class)\n","    num_df_domains = config[dataset]['num_df_domains']\n","\n","    if rot:\n","        dataset_name += '_rot'\n","\n","    try:\n","        with open(f'data/{dataset_name}.pkl', 'rb') as f:\n","            x, y, k = pickle.load(f)\n","        with open(f'data/{dataset_name}_fs.pkl', 'rb') as f:\n","            fs = pickle.load(f)\n","    except FileNotFoundError:\n","        raise FileNotFoundError(f\"Dataset files for {dataset} not found.\")\n","\n","\n","    if domains_set == 'df':\n","        mask = (k < num_df_domains)\n","    elif domains_set == 'dp':\n","        mask = (k >= num_df_domains) & (fs == 0)\n","    elif domains_set == 'dpfs':\n","        mask = (k >= num_df_domains) & (fs == 1)\n","    else:\n","        raise ValueError(f\"Invalid domains set: {domains_set}\")\n","\n","    # Apply initial mask\n","    x, y, k = x[mask], y[mask], k[mask]\n","\n","    # Additional domain filtering if specified\n","    if domain is not None:\n","        domain_mask = (k == domain)\n","        x, y, k = x[domain_mask], y[domain_mask], k[domain_mask]\n","\n","    assert len(x) > 0, f\"No data found\"\n","    assert len(x) == len(y) == len(k), f\"Data length mismatch\"\n","\n","    return x, y, k\n","\n","\n","\n","def get_syn_data(dataset, syn_name, src_class, domain=None, fs=False):\n","    # Load configurations\n","    class_names = config[dataset]['class_names']\n","\n","    try:\n","        with open(f'data/{dataset}_{syn_name}.pkl', 'rb') as f:\n","            x, y, k = pickle.load(f)\n","    except FileNotFoundError:\n","        raise FileNotFoundError(f\"Dataset files for {dataset} not found.\")\n","\n","    with open(f'data/{dataset}_{syn_name}_fs.pkl', 'rb') as f:\n","        fs = pickle.load(f)\n","\n","    x, y, k = x[fs == 0], y[fs == 0], k[fs == 0]\n","\n","    if domain is not None:\n","        domain_mask = (k == domain)\n","        x, y, k = x[domain_mask], y[domain_mask], k[domain_mask]\n","\n","    assert len(x) > 0, f\"No data found\"\n","    assert len(x) == len(y) == len(k), f\"Data length mismatch\"\n","\n","    return x, y, k\n","\n","\n","\n","class TSTRClassifier(nn.Module):\n","    def __init__(self, num_timesteps=128, num_channels=3, num_classes=5):\n","        super(TSTRClassifier, self).__init__()\n","\n","        self.conv1 = nn.Conv1d(num_channels, 16, kernel_size=5, stride=1, padding=2)\n","        self.bn1 = nn.BatchNorm1d(16)\n","        self.conv2 = nn.Conv1d(16, 32, kernel_size=5, stride=1, padding=2)\n","        self.bn2 = nn.BatchNorm1d(32)\n","        self.conv3 = nn.Conv1d(32, 64, kernel_size=5, stride=1, padding=2)\n","        self.bn3 = nn.BatchNorm1d(64)\n","        self.conv4 = nn.Conv1d(64, 128, kernel_size=5, stride=1, padding=2)\n","        self.bn4 = nn.BatchNorm1d(128)\n","        self.pool = nn.MaxPool1d(kernel_size=2, stride=2)\n","        self.relu = nn.ReLU()\n","        self.dropout = nn.Dropout(p=0.25)\n","\n","        self.fc_shared = nn.Linear(num_timesteps * 8, 100)\n","\n","        self.fc_class = nn.Linear(100, num_classes)\n","\n","    def forward(self, x):\n","        x = self.pool(self.relu(self.bn1(self.conv1(x))))\n","        x = self.pool(self.relu(self.bn2(self.conv2(x))))\n","        x = self.pool(self.relu(self.bn3(self.conv3(x))))\n","        x = self.pool(self.relu(self.bn4(self.conv4(x))))\n","        x = x.view(x.size(0), -1)  # Flatten\n","        x = self.dropout(x)\n","        x = self.relu(self.fc_shared(x))\n","\n","        # Final output for class prediction\n","        class_outputs = self.fc_class(x)\n","        return class_outputs\n","\n","\n","\n","def remap_labels(y):\n","    label_map = {clss: i for i, clss in enumerate(np.unique(y))}\n","    return np.array([label_map[clss] for clss in y])\n","\n","\n","\n","def get_dataloader(x, y, shuffle=False):\n","    x = torch.tensor(x, dtype=torch.float32)\n","    y = remap_labels(y)\n","    y = torch.tensor(y, dtype=torch.long)\n","\n","    # Determine dataset size and batch size\n","    dataset_size = len(x)\n","    if dataset_size <= 100:\n","        batch_size = dataset_size\n","    elif dataset_size <= 1000:\n","        batch_size = 16\n","    elif dataset_size <= 5000:\n","        batch_size = 32\n","    else:\n","        batch_size = 64\n","\n","    dataset = TensorDataset(x, y)\n","    loader = DataLoader(dataset, batch_size=batch_size, shuffle=shuffle)\n","\n","    return loader\n","\n","\n","def random_rotation_matrix():\n","    \"\"\"Generate a random rotation matrix from a predefined set of quaternions.\"\"\"\n","    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","\n","    # Randomly generate a quaternion\n","    q = np.random.rand(4)\n","\n","    # Convert quaternion to rotation matrix\n","    q = torch.tensor(q, device=device, dtype=torch.float32)\n","    q = q / torch.norm(q)  # Normalize quaternion\n","    q0, q1, q2, q3 = q\n","\n","    R = torch.tensor([\n","        [1 - 2*q2**2 - 2*q3**2, 2*q1*q2 - 2*q3*q0, 2*q1*q3 + 2*q2*q0],\n","        [2*q1*q2 + 2*q3*q0, 1 - 2*q1**2 - 2*q3**2, 2*q2*q3 - 2*q1*q0],\n","        [2*q1*q3 - 2*q2*q0, 2*q2*q3 + 2*q1*q0, 1 - 2*q1**2 - 2*q2**2]\n","    ], device=device, dtype=torch.float32)\n","\n","    return R, q\n","\n","\n","def augment_batch(x_real):\n","    \"\"\"Apply random rotation to the batch of real time series.\"\"\"\n","    min_val, max_val = -19.61, 19.61\n","    x_real = x_real * (max_val - min_val) + min_val  # De-normalize\n","    R, q = random_rotation_matrix()\n","    x_real = torch.matmul(R, x_real)  # Apply rotation\n","    x_real = (x_real - min_val) / (max_val - min_val)  # Re-normalize\n","    return x_real, q\n","\n","\n","\n","def evaluate_model(model, test_loader):\n","    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","    model.to(device)\n","    model.eval()\n","\n","    loss_fn = nn.CrossEntropyLoss()\n","\n","    total_loss = 0\n","    all_preds = []\n","    all_labels = []\n","\n","    with torch.no_grad():\n","        for x_batch, y_batch in test_loader:\n","            x_batch, y_batch = x_batch.to(device), y_batch.to(device)\n","            outputs = model(x_batch)\n","            loss = loss_fn(outputs, y_batch)\n","            total_loss += loss.item()\n","\n","            _, predicted_labels = torch.max(outputs, 1)\n","            all_preds.extend(predicted_labels.detach().cpu().numpy())\n","            all_labels.extend(y_batch.detach().cpu().numpy())\n","\n","    all_labels = np.array(all_labels)\n","    all_preds = np.array(all_preds)\n","    accuracy = accuracy_score(all_labels, all_preds)\n","    f1 = f1_score(all_labels, all_preds, average='weighted')\n","    total_loss /= len(test_loader)\n","\n","    return accuracy, total_loss, f1\n","\n","\n","\n","def train_model(model, train_loader, val_loader, optimizer, num_epochs=100, augment=False):\n","    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","    model.to(device)\n","\n","    loss_fn = nn.CrossEntropyLoss()\n","\n","    loss_train = []\n","    loss_val = []\n","    accuracy_val = []\n","    best_model_state = None\n","    best_loss = np.inf\n","    best_accuracy = 0\n","    best_f1 = 0\n","\n","    # Set up linear learning rate decay\n","    lambda_lr = lambda epoch: 1 - epoch / num_epochs\n","    scheduler = LambdaLR(optimizer, lr_lambda=lambda_lr)\n","\n","    for epoch in range(num_epochs):\n","        model.train()\n","        total_loss = 0\n","        for x_batch, y_batch in train_loader:\n","            x_batch, y_batch = x_batch.to(device), y_batch.to(device)\n","            if augment:\n","                x_batch, _ = augment_batch(x_batch)\n","            optimizer.zero_grad()\n","            outputs = model(x_batch)\n","            loss = loss_fn(outputs, y_batch)\n","            loss.backward()\n","            optimizer.step()\n","            total_loss += loss.item()\n","        total_loss /= len(train_loader)\n","        loss_train.append(total_loss)\n","\n","        # Update learning rate\n","        scheduler.step()\n","\n","        val_accuracy, val_loss, val_f1 = evaluate_model(model, val_loader)\n","        if val_loss < best_loss:\n","            best_epoch = epoch\n","            best_accuracy = val_accuracy\n","            best_f1 = val_f1\n","            best_loss = val_loss\n","            best_model_state = model.state_dict().copy()\n","\n","        loss_val.append(val_loss)\n","        accuracy_val.append(val_accuracy)\n","\n","        current_lr = scheduler.get_last_lr()[0]\n","        if (epoch+1) % 10 == 0:\n","            print(f\"\\tEpoch {epoch + 1}/{num_epochs} - Train loss: {total_loss:.4f} - Val accuracy: {val_accuracy:.4f} - Val loss: {val_loss:.4f} - Val F1: {val_f1:.4f} - LR: {current_lr:.2e}\")\n","\n","    print(f\"\\tBest epoch: {best_epoch + 1} - Best val accuracy: {best_accuracy:.4f} - Best val loss: {best_loss:.4f} - Best val F1: {best_f1:.4f}\\n\")\n","\n","    # Load best model state\n","    model.load_state_dict(best_model_state)\n","\n","    return model\n","\n","\n","\n","def train_and_test(x_train, y_train, x_test, y_test, dataset, num_epochs=100, augment=False):\n","    assert np.array_equal(np.unique(y_train), np.unique(y_test)), \"Training and test labels do not match\"\n","\n","    x_tr, x_val, y_tr, y_val = train_test_split(x_train, y_train, test_size=0.2, stratify=y_train, shuffle=True, random_state=seed)\n","\n","    train_loader = get_dataloader(x_tr, y_tr, shuffle=True)\n","    val_loader = get_dataloader(x_val, y_val)\n","    test_loader = get_dataloader(x_test, y_test)\n","\n","    model = TSTRClassifier(num_timesteps=config[dataset]['num_timesteps'],\n","                           num_channels=config[dataset]['num_channels'],\n","                           num_classes=config[dataset]['num_classes'])\n","    initial_lr = 0.0001\n","    optimizer = optim.Adam(model.parameters(), lr=initial_lr)\n","\n","    trained_model = train_model(model, train_loader, val_loader, optimizer, num_epochs, augment)\n","\n","    test_accuracy, test_loss, test_f1 = evaluate_model(trained_model, test_loader)\n","\n","    return test_accuracy, test_loss, test_f1\n","\n","\n","\n","def train_only(x_train, y_train, dataset, num_epochs=100, augment=False):\n","\n","    x_tr, x_val, y_tr, y_val = train_test_split(x_train, y_train, test_size=0.2, stratify=y_train, shuffle=True, random_state=seed)\n","\n","    train_loader = get_dataloader(x_tr, y_tr, shuffle=True)\n","    val_loader = get_dataloader(x_val, y_val)\n","\n","    model = TSTRClassifier(num_timesteps=config[dataset]['num_timesteps'],\n","                           num_channels=config[dataset]['num_channels'],\n","                           num_classes=config[dataset]['num_classes'])\n","    initial_lr = 0.0001\n","    optimizer = optim.Adam(model.parameters(), lr=initial_lr)\n","\n","    trained_model = train_model(model, train_loader, val_loader, optimizer, num_epochs, augment=augment)\n","\n","    return trained_model\n","\n","\n","\n","def train_classifier_cv(x_train, y_train, dataset, num_epochs=100):\n","    skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=seed)\n","\n","    accs = []\n","    losses = []\n","    f1s = []\n","\n","    for train_index, test_index in skf.split(x_train, y_train):\n","        x_train_fold, x_test_fold = x_train[train_index], x_train[test_index]\n","        y_train_fold, y_test_fold = y_train[train_index], y_train[test_index]\n","\n","        acc, loss, f1 = train_and_test(x_train_fold, y_train_fold, x_test_fold, y_test_fold, dataset, num_epochs)\n","        accs.append(acc)\n","        losses.append(loss)\n","        f1s.append(f1)\n","    return np.mean(accs), np.mean(losses), np.mean(f1s)\n","\n","\n","\n","def fine_tune(model, x_train, y_train, num_epochs=100):\n","    # Freeze feature extraction layers\n","    for name, param in model.named_parameters():\n","        if 'conv' in name or 'bn' in name:\n","            param.requires_grad = False\n","\n","    x_tr, x_val, y_tr, y_val = train_test_split(x_train, y_train, test_size=0.2, stratify=y_train, shuffle=True, random_state=seed)\n","\n","    train_loader = get_dataloader(x_tr, y_tr, shuffle=True)\n","    val_loader = get_dataloader(x_val, y_val)\n","\n","    initial_lr = 0.00001\n","    optimizer = optim.Adam(filter(lambda p: p.requires_grad, model.parameters()), lr=initial_lr)\n","\n","    trained_model = train_model(model, train_loader, val_loader, optimizer, num_epochs)\n","\n","    return trained_model\n","\n","\n","\n","def save_scores(source, domain, accuracy, loss, f1, name, dataset):\n","    results_dir = 'results_wal'\n","    # Ensure the directory exists\n","    os.makedirs(results_dir, exist_ok=True)\n","    # Path to the CSV file\n","    file_path = os.path.join(results_dir, f'{dataset}_{name}.csv')\n","    # Check if the file exists\n","    file_exists = os.path.exists(file_path)\n","\n","    # Open the file in append mode if it exists, or write mode if it doesn't\n","    with open(file_path, mode='a' if file_exists else 'w', newline='') as file:\n","        writer = csv.writer(file)\n","        # If the file does not exist, write the header\n","        if not file_exists:\n","            writer.writerow(['source', 'domain', 'accuracy', 'loss', 'f1'])\n","        # Write the data rows\n","        writer.writerow([source, domain, accuracy, loss, f1])"]},{"cell_type":"markdown","metadata":{"id":"PRAlLTPumD5Z"},"source":["# TSTR"]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1312028,"status":"ok","timestamp":1732701416976,"user":{"displayName":"Pietro Castelvetri","userId":"04218697278633758016"},"user_tz":-60},"id":"XrDIDrL9CPtn","outputId":"6b6ff457-cf86-4be8-8a0b-644a90f58b8c"},"outputs":[{"output_type":"stream","name":"stdout","text":["Source class: WAL\n","\n","Domain: 61\n","x_dp_dom.shape: (855, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Training and evaluating on Dp data via cross-validation...\n","\tEpoch 10/100 - Train loss: 0.1602 - Val accuracy: 0.9562 - Val loss: 0.1262 - Val F1: 0.9565 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.0506 - Val accuracy: 0.9708 - Val loss: 0.1025 - Val F1: 0.9708 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.0250 - Val accuracy: 0.9781 - Val loss: 0.0931 - Val F1: 0.9781 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.0120 - Val accuracy: 0.9781 - Val loss: 0.1003 - Val F1: 0.9781 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.0128 - Val accuracy: 0.9781 - Val loss: 0.0913 - Val F1: 0.9781 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.0041 - Val accuracy: 0.9781 - Val loss: 0.1045 - Val F1: 0.9781 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0781 - Val accuracy: 0.9781 - Val loss: 0.1150 - Val F1: 0.9781 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0050 - Val accuracy: 0.9781 - Val loss: 0.1289 - Val F1: 0.9781 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0034 - Val accuracy: 0.9781 - Val loss: 0.1064 - Val F1: 0.9781 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0131 - Val accuracy: 0.9781 - Val loss: 0.1086 - Val F1: 0.9781 - LR: 0.00e+00\n","\tBest epoch: 38 - Best val accuracy: 0.9708 - Best val loss: 0.0836 - Best val F1: 0.9708\n","\n","\tEpoch 10/100 - Train loss: 0.1457 - Val accuracy: 0.8686 - Val loss: 0.3869 - Val F1: 0.8699 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.0456 - Val accuracy: 0.9124 - Val loss: 0.3400 - Val F1: 0.9127 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.0185 - Val accuracy: 0.9124 - Val loss: 0.3100 - Val F1: 0.9127 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.0138 - Val accuracy: 0.8978 - Val loss: 0.3770 - Val F1: 0.8974 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.0073 - Val accuracy: 0.9124 - Val loss: 0.3511 - Val F1: 0.9120 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.0550 - Val accuracy: 0.9197 - Val loss: 0.3687 - Val F1: 0.9196 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0047 - Val accuracy: 0.9124 - Val loss: 0.3457 - Val F1: 0.9127 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0049 - Val accuracy: 0.9197 - Val loss: 0.2736 - Val F1: 0.9200 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0039 - Val accuracy: 0.9051 - Val loss: 0.3612 - Val F1: 0.9051 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0039 - Val accuracy: 0.9051 - Val loss: 0.3564 - Val F1: 0.9051 - LR: 0.00e+00\n","\tBest epoch: 80 - Best val accuracy: 0.9197 - Best val loss: 0.2736 - Best val F1: 0.9200\n","\n","\tEpoch 10/100 - Train loss: 0.1223 - Val accuracy: 0.9489 - Val loss: 0.1842 - Val F1: 0.9495 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.0594 - Val accuracy: 0.9416 - Val loss: 0.1979 - Val F1: 0.9425 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.0233 - Val accuracy: 0.9489 - Val loss: 0.1759 - Val F1: 0.9495 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.0130 - Val accuracy: 0.9416 - Val loss: 0.1815 - Val F1: 0.9423 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.0073 - Val accuracy: 0.9416 - Val loss: 0.1651 - Val F1: 0.9423 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.0068 - Val accuracy: 0.9416 - Val loss: 0.1547 - Val F1: 0.9423 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0041 - Val accuracy: 0.9489 - Val loss: 0.1551 - Val F1: 0.9494 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0027 - Val accuracy: 0.9489 - Val loss: 0.1719 - Val F1: 0.9495 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0028 - Val accuracy: 0.9416 - Val loss: 0.1618 - Val F1: 0.9423 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0072 - Val accuracy: 0.9416 - Val loss: 0.1765 - Val F1: 0.9423 - LR: 0.00e+00\n","\tBest epoch: 39 - Best val accuracy: 0.9416 - Best val loss: 0.1361 - Best val F1: 0.9423\n","\n","\tEpoch 10/100 - Train loss: 0.1410 - Val accuracy: 0.9270 - Val loss: 0.2093 - Val F1: 0.9265 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.0527 - Val accuracy: 0.9416 - Val loss: 0.1681 - Val F1: 0.9412 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.0248 - Val accuracy: 0.9489 - Val loss: 0.1633 - Val F1: 0.9484 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.0110 - Val accuracy: 0.9489 - Val loss: 0.1787 - Val F1: 0.9484 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.0100 - Val accuracy: 0.9562 - Val loss: 0.1770 - Val F1: 0.9559 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.0062 - Val accuracy: 0.9562 - Val loss: 0.2066 - Val F1: 0.9559 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0318 - Val accuracy: 0.9489 - Val loss: 0.1823 - Val F1: 0.9491 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0034 - Val accuracy: 0.9562 - Val loss: 0.1823 - Val F1: 0.9559 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0020 - Val accuracy: 0.9562 - Val loss: 0.1954 - Val F1: 0.9559 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0026 - Val accuracy: 0.9489 - Val loss: 0.2113 - Val F1: 0.9491 - LR: 0.00e+00\n","\tBest epoch: 72 - Best val accuracy: 0.9489 - Best val loss: 0.1494 - Best val F1: 0.9490\n","\n","\tEpoch 10/100 - Train loss: 0.1291 - Val accuracy: 0.9270 - Val loss: 0.2252 - Val F1: 0.9277 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.0269 - Val accuracy: 0.9270 - Val loss: 0.1892 - Val F1: 0.9277 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.0208 - Val accuracy: 0.9270 - Val loss: 0.2157 - Val F1: 0.9281 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.0081 - Val accuracy: 0.9197 - Val loss: 0.2635 - Val F1: 0.9207 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.0068 - Val accuracy: 0.9270 - Val loss: 0.2158 - Val F1: 0.9272 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.0174 - Val accuracy: 0.9343 - Val loss: 0.2184 - Val F1: 0.9349 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0042 - Val accuracy: 0.9416 - Val loss: 0.2065 - Val F1: 0.9423 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0036 - Val accuracy: 0.9416 - Val loss: 0.2179 - Val F1: 0.9417 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0031 - Val accuracy: 0.9416 - Val loss: 0.2242 - Val F1: 0.9423 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0034 - Val accuracy: 0.9343 - Val loss: 0.2151 - Val F1: 0.9350 - LR: 0.00e+00\n","\tBest epoch: 28 - Best val accuracy: 0.9343 - Best val loss: 0.1767 - Best val F1: 0.9350\n","\n","Source class: WAL | Domain: 61 | Accuracy: 0.9591 | Loss: 0.1538 | F1: 0.9592\n","\n","Domain: 62\n","x_dp_dom.shape: (780, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Training and evaluating on Dp data via cross-validation...\n","\tEpoch 10/100 - Train loss: 0.1155 - Val accuracy: 0.9680 - Val loss: 0.1031 - Val F1: 0.9681 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.0249 - Val accuracy: 0.9680 - Val loss: 0.0820 - Val F1: 0.9683 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.0152 - Val accuracy: 0.9760 - Val loss: 0.0629 - Val F1: 0.9760 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.0116 - Val accuracy: 0.9600 - Val loss: 0.0607 - Val F1: 0.9603 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.0065 - Val accuracy: 0.9680 - Val loss: 0.0475 - Val F1: 0.9683 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.0057 - Val accuracy: 0.9840 - Val loss: 0.0426 - Val F1: 0.9842 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0281 - Val accuracy: 0.9840 - Val loss: 0.0411 - Val F1: 0.9842 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0130 - Val accuracy: 0.9840 - Val loss: 0.0392 - Val F1: 0.9840 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0028 - Val accuracy: 0.9920 - Val loss: 0.0391 - Val F1: 0.9920 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0033 - Val accuracy: 0.9760 - Val loss: 0.0499 - Val F1: 0.9763 - LR: 0.00e+00\n","\tBest epoch: 89 - Best val accuracy: 0.9840 - Best val loss: 0.0354 - Best val F1: 0.9840\n","\n","\tEpoch 10/100 - Train loss: 0.0983 - Val accuracy: 0.9520 - Val loss: 0.1616 - Val F1: 0.9518 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.0293 - Val accuracy: 0.9440 - Val loss: 0.0948 - Val F1: 0.9437 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.0202 - Val accuracy: 0.9520 - Val loss: 0.0863 - Val F1: 0.9517 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.0090 - Val accuracy: 0.9520 - Val loss: 0.0758 - Val F1: 0.9520 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.0070 - Val accuracy: 0.9680 - Val loss: 0.0633 - Val F1: 0.9681 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.0045 - Val accuracy: 0.9760 - Val loss: 0.0562 - Val F1: 0.9759 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0027 - Val accuracy: 0.9680 - Val loss: 0.0619 - Val F1: 0.9678 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0050 - Val accuracy: 0.9600 - Val loss: 0.0911 - Val F1: 0.9596 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0015 - Val accuracy: 0.9680 - Val loss: 0.0618 - Val F1: 0.9678 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0028 - Val accuracy: 0.9680 - Val loss: 0.0603 - Val F1: 0.9678 - LR: 0.00e+00\n","\tBest epoch: 60 - Best val accuracy: 0.9760 - Best val loss: 0.0562 - Best val F1: 0.9759\n","\n","\tEpoch 10/100 - Train loss: 0.1149 - Val accuracy: 0.9520 - Val loss: 0.1335 - Val F1: 0.9520 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.0366 - Val accuracy: 0.9600 - Val loss: 0.1201 - Val F1: 0.9598 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.0199 - Val accuracy: 0.9680 - Val loss: 0.0984 - Val F1: 0.9676 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.0133 - Val accuracy: 0.9520 - Val loss: 0.0877 - Val F1: 0.9516 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.0069 - Val accuracy: 0.9520 - Val loss: 0.0945 - Val F1: 0.9516 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.0063 - Val accuracy: 0.9520 - Val loss: 0.1000 - Val F1: 0.9516 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0284 - Val accuracy: 0.9680 - Val loss: 0.0995 - Val F1: 0.9681 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0043 - Val accuracy: 0.9520 - Val loss: 0.0969 - Val F1: 0.9516 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0016 - Val accuracy: 0.9600 - Val loss: 0.0998 - Val F1: 0.9596 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0030 - Val accuracy: 0.9520 - Val loss: 0.1060 - Val F1: 0.9516 - LR: 0.00e+00\n","\tBest epoch: 40 - Best val accuracy: 0.9520 - Best val loss: 0.0877 - Best val F1: 0.9516\n","\n","\tEpoch 10/100 - Train loss: 0.1411 - Val accuracy: 0.9360 - Val loss: 0.1546 - Val F1: 0.9360 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.0308 - Val accuracy: 0.9520 - Val loss: 0.1205 - Val F1: 0.9519 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.0152 - Val accuracy: 0.9600 - Val loss: 0.1190 - Val F1: 0.9599 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.0198 - Val accuracy: 0.9520 - Val loss: 0.1165 - Val F1: 0.9519 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.0087 - Val accuracy: 0.9600 - Val loss: 0.1161 - Val F1: 0.9600 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.0067 - Val accuracy: 0.9600 - Val loss: 0.1152 - Val F1: 0.9600 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0074 - Val accuracy: 0.9680 - Val loss: 0.1174 - Val F1: 0.9681 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0154 - Val accuracy: 0.9600 - Val loss: 0.1121 - Val F1: 0.9600 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0027 - Val accuracy: 0.9680 - Val loss: 0.1148 - Val F1: 0.9681 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0017 - Val accuracy: 0.9520 - Val loss: 0.1271 - Val F1: 0.9521 - LR: 0.00e+00\n","\tBest epoch: 39 - Best val accuracy: 0.9680 - Best val loss: 0.1089 - Best val F1: 0.9680\n","\n","\tEpoch 10/100 - Train loss: 0.1175 - Val accuracy: 0.9360 - Val loss: 0.2019 - Val F1: 0.9355 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.0554 - Val accuracy: 0.9520 - Val loss: 0.1429 - Val F1: 0.9519 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.0229 - Val accuracy: 0.9680 - Val loss: 0.1342 - Val F1: 0.9677 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.0083 - Val accuracy: 0.9520 - Val loss: 0.1404 - Val F1: 0.9521 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.0084 - Val accuracy: 0.9760 - Val loss: 0.1272 - Val F1: 0.9760 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.0051 - Val accuracy: 0.9600 - Val loss: 0.1188 - Val F1: 0.9603 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0043 - Val accuracy: 0.9600 - Val loss: 0.1172 - Val F1: 0.9603 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0030 - Val accuracy: 0.9600 - Val loss: 0.1077 - Val F1: 0.9600 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0056 - Val accuracy: 0.9680 - Val loss: 0.1173 - Val F1: 0.9681 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0046 - Val accuracy: 0.9680 - Val loss: 0.1083 - Val F1: 0.9682 - LR: 0.00e+00\n","\tBest epoch: 77 - Best val accuracy: 0.9600 - Best val loss: 0.1024 - Best val F1: 0.9600\n","\n","Source class: WAL | Domain: 62 | Accuracy: 0.9667 | Loss: 0.1102 | F1: 0.9668\n","\n","Domain: 63\n","x_dp_dom.shape: (859, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Training and evaluating on Dp data via cross-validation...\n","\tEpoch 10/100 - Train loss: 0.0887 - Val accuracy: 0.9855 - Val loss: 0.0788 - Val F1: 0.9855 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.0412 - Val accuracy: 0.9855 - Val loss: 0.0555 - Val F1: 0.9855 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.0286 - Val accuracy: 0.9855 - Val loss: 0.0413 - Val F1: 0.9855 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.0101 - Val accuracy: 0.9855 - Val loss: 0.0384 - Val F1: 0.9855 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.0108 - Val accuracy: 0.9855 - Val loss: 0.0390 - Val F1: 0.9855 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.0032 - Val accuracy: 0.9855 - Val loss: 0.0430 - Val F1: 0.9855 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0056 - Val accuracy: 0.9855 - Val loss: 0.0545 - Val F1: 0.9855 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0030 - Val accuracy: 0.9855 - Val loss: 0.0419 - Val F1: 0.9855 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0019 - Val accuracy: 0.9855 - Val loss: 0.0508 - Val F1: 0.9855 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0033 - Val accuracy: 0.9855 - Val loss: 0.0420 - Val F1: 0.9855 - LR: 0.00e+00\n","\tBest epoch: 88 - Best val accuracy: 0.9855 - Best val loss: 0.0266 - Best val F1: 0.9855\n","\n","\tEpoch 10/100 - Train loss: 0.0881 - Val accuracy: 0.9710 - Val loss: 0.0849 - Val F1: 0.9711 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.0332 - Val accuracy: 0.9710 - Val loss: 0.0729 - Val F1: 0.9711 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.0148 - Val accuracy: 0.9710 - Val loss: 0.0626 - Val F1: 0.9711 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.0160 - Val accuracy: 0.9710 - Val loss: 0.0660 - Val F1: 0.9711 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.0057 - Val accuracy: 0.9783 - Val loss: 0.0668 - Val F1: 0.9783 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.0101 - Val accuracy: 0.9783 - Val loss: 0.0622 - Val F1: 0.9783 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0027 - Val accuracy: 0.9783 - Val loss: 0.0645 - Val F1: 0.9783 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0040 - Val accuracy: 0.9783 - Val loss: 0.0651 - Val F1: 0.9782 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0033 - Val accuracy: 0.9783 - Val loss: 0.0631 - Val F1: 0.9782 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0014 - Val accuracy: 0.9710 - Val loss: 0.0658 - Val F1: 0.9711 - LR: 0.00e+00\n","\tBest epoch: 88 - Best val accuracy: 0.9783 - Best val loss: 0.0595 - Best val F1: 0.9783\n","\n","\tEpoch 10/100 - Train loss: 0.0836 - Val accuracy: 0.9710 - Val loss: 0.0976 - Val F1: 0.9711 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.0322 - Val accuracy: 0.9710 - Val loss: 0.0947 - Val F1: 0.9711 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.0236 - Val accuracy: 0.9710 - Val loss: 0.0900 - Val F1: 0.9711 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.0089 - Val accuracy: 0.9638 - Val loss: 0.1062 - Val F1: 0.9640 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.0056 - Val accuracy: 0.9783 - Val loss: 0.0908 - Val F1: 0.9783 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.0062 - Val accuracy: 0.9710 - Val loss: 0.0972 - Val F1: 0.9711 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0078 - Val accuracy: 0.9783 - Val loss: 0.0953 - Val F1: 0.9783 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0027 - Val accuracy: 0.9638 - Val loss: 0.0944 - Val F1: 0.9640 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0063 - Val accuracy: 0.9783 - Val loss: 0.0894 - Val F1: 0.9783 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0050 - Val accuracy: 0.9710 - Val loss: 0.0876 - Val F1: 0.9711 - LR: 0.00e+00\n","\tBest epoch: 97 - Best val accuracy: 0.9783 - Best val loss: 0.0867 - Best val F1: 0.9783\n","\n","\tEpoch 10/100 - Train loss: 0.1443 - Val accuracy: 0.9638 - Val loss: 0.1080 - Val F1: 0.9636 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.0331 - Val accuracy: 0.9710 - Val loss: 0.0782 - Val F1: 0.9708 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.0207 - Val accuracy: 0.9710 - Val loss: 0.0573 - Val F1: 0.9709 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.0118 - Val accuracy: 0.9783 - Val loss: 0.0543 - Val F1: 0.9781 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.0067 - Val accuracy: 0.9710 - Val loss: 0.0824 - Val F1: 0.9708 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.0087 - Val accuracy: 0.9783 - Val loss: 0.0525 - Val F1: 0.9781 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0037 - Val accuracy: 0.9783 - Val loss: 0.0609 - Val F1: 0.9781 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0036 - Val accuracy: 0.9783 - Val loss: 0.0674 - Val F1: 0.9781 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0085 - Val accuracy: 0.9783 - Val loss: 0.0685 - Val F1: 0.9781 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0024 - Val accuracy: 0.9783 - Val loss: 0.0640 - Val F1: 0.9781 - LR: 0.00e+00\n","\tBest epoch: 63 - Best val accuracy: 0.9783 - Best val loss: 0.0363 - Best val F1: 0.9782\n","\n","\tEpoch 10/100 - Train loss: 0.1042 - Val accuracy: 0.9638 - Val loss: 0.1235 - Val F1: 0.9638 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.0337 - Val accuracy: 0.9710 - Val loss: 0.0665 - Val F1: 0.9712 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.0168 - Val accuracy: 0.9855 - Val loss: 0.0422 - Val F1: 0.9856 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.0077 - Val accuracy: 0.9783 - Val loss: 0.0512 - Val F1: 0.9781 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.0076 - Val accuracy: 0.9710 - Val loss: 0.0484 - Val F1: 0.9709 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.0065 - Val accuracy: 0.9565 - Val loss: 0.0692 - Val F1: 0.9564 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0047 - Val accuracy: 0.9855 - Val loss: 0.0393 - Val F1: 0.9855 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0046 - Val accuracy: 0.9710 - Val loss: 0.0504 - Val F1: 0.9712 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0048 - Val accuracy: 0.9638 - Val loss: 0.0620 - Val F1: 0.9641 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0034 - Val accuracy: 0.9710 - Val loss: 0.0547 - Val F1: 0.9712 - LR: 0.00e+00\n","\tBest epoch: 73 - Best val accuracy: 0.9928 - Best val loss: 0.0349 - Best val F1: 0.9927\n","\n","Source class: WAL | Domain: 63 | Accuracy: 0.9674 | Loss: 0.0890 | F1: 0.9673\n","\n","Domain: 64\n","x_dp_dom.shape: (481, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Training and evaluating on Dp data via cross-validation...\n","\tEpoch 10/100 - Train loss: 0.1072 - Val accuracy: 0.9740 - Val loss: 0.0825 - Val F1: 0.9729 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.0492 - Val accuracy: 1.0000 - Val loss: 0.0204 - Val F1: 1.0000 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.0390 - Val accuracy: 1.0000 - Val loss: 0.0207 - Val F1: 1.0000 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.0208 - Val accuracy: 1.0000 - Val loss: 0.0104 - Val F1: 1.0000 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.0109 - Val accuracy: 1.0000 - Val loss: 0.0088 - Val F1: 1.0000 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.0041 - Val accuracy: 1.0000 - Val loss: 0.0107 - Val F1: 1.0000 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0043 - Val accuracy: 1.0000 - Val loss: 0.0062 - Val F1: 1.0000 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0305 - Val accuracy: 1.0000 - Val loss: 0.0047 - Val F1: 1.0000 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0039 - Val accuracy: 1.0000 - Val loss: 0.0073 - Val F1: 1.0000 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0030 - Val accuracy: 1.0000 - Val loss: 0.0092 - Val F1: 1.0000 - LR: 0.00e+00\n","\tBest epoch: 79 - Best val accuracy: 1.0000 - Best val loss: 0.0043 - Best val F1: 1.0000\n","\n","\tEpoch 10/100 - Train loss: 0.0713 - Val accuracy: 0.9870 - Val loss: 0.0637 - Val F1: 0.9869 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.0137 - Val accuracy: 0.9870 - Val loss: 0.0312 - Val F1: 0.9869 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.0106 - Val accuracy: 0.9870 - Val loss: 0.0367 - Val F1: 0.9869 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.0089 - Val accuracy: 1.0000 - Val loss: 0.0222 - Val F1: 1.0000 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.0051 - Val accuracy: 0.9870 - Val loss: 0.0250 - Val F1: 0.9870 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.0060 - Val accuracy: 0.9870 - Val loss: 0.0219 - Val F1: 0.9870 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0033 - Val accuracy: 1.0000 - Val loss: 0.0187 - Val F1: 1.0000 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0022 - Val accuracy: 0.9870 - Val loss: 0.0223 - Val F1: 0.9870 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0027 - Val accuracy: 0.9870 - Val loss: 0.0234 - Val F1: 0.9870 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0018 - Val accuracy: 1.0000 - Val loss: 0.0152 - Val F1: 1.0000 - LR: 0.00e+00\n","\tBest epoch: 78 - Best val accuracy: 1.0000 - Best val loss: 0.0145 - Best val F1: 1.0000\n","\n","\tEpoch 10/100 - Train loss: 0.0766 - Val accuracy: 1.0000 - Val loss: 0.0440 - Val F1: 1.0000 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.0232 - Val accuracy: 1.0000 - Val loss: 0.0143 - Val F1: 1.0000 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.0068 - Val accuracy: 1.0000 - Val loss: 0.0078 - Val F1: 1.0000 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.0043 - Val accuracy: 1.0000 - Val loss: 0.0052 - Val F1: 1.0000 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.0032 - Val accuracy: 1.0000 - Val loss: 0.0051 - Val F1: 1.0000 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.0029 - Val accuracy: 1.0000 - Val loss: 0.0035 - Val F1: 1.0000 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0027 - Val accuracy: 1.0000 - Val loss: 0.0035 - Val F1: 1.0000 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0030 - Val accuracy: 1.0000 - Val loss: 0.0023 - Val F1: 1.0000 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0017 - Val accuracy: 1.0000 - Val loss: 0.0022 - Val F1: 1.0000 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0136 - Val accuracy: 1.0000 - Val loss: 0.0028 - Val F1: 1.0000 - LR: 0.00e+00\n","\tBest epoch: 79 - Best val accuracy: 1.0000 - Best val loss: 0.0020 - Best val F1: 1.0000\n","\n","\tEpoch 10/100 - Train loss: 0.0518 - Val accuracy: 1.0000 - Val loss: 0.0324 - Val F1: 1.0000 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.0432 - Val accuracy: 1.0000 - Val loss: 0.0074 - Val F1: 1.0000 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.0115 - Val accuracy: 1.0000 - Val loss: 0.0050 - Val F1: 1.0000 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.0047 - Val accuracy: 1.0000 - Val loss: 0.0043 - Val F1: 1.0000 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.0102 - Val accuracy: 1.0000 - Val loss: 0.0023 - Val F1: 1.0000 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.0052 - Val accuracy: 1.0000 - Val loss: 0.0018 - Val F1: 1.0000 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0021 - Val accuracy: 1.0000 - Val loss: 0.0019 - Val F1: 1.0000 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0037 - Val accuracy: 1.0000 - Val loss: 0.0020 - Val F1: 1.0000 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0127 - Val accuracy: 1.0000 - Val loss: 0.0019 - Val F1: 1.0000 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0025 - Val accuracy: 1.0000 - Val loss: 0.0018 - Val F1: 1.0000 - LR: 0.00e+00\n","\tBest epoch: 98 - Best val accuracy: 1.0000 - Best val loss: 0.0016 - Best val F1: 1.0000\n","\n","\tEpoch 10/100 - Train loss: 0.0497 - Val accuracy: 1.0000 - Val loss: 0.0349 - Val F1: 1.0000 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.0194 - Val accuracy: 1.0000 - Val loss: 0.0072 - Val F1: 1.0000 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.0106 - Val accuracy: 1.0000 - Val loss: 0.0032 - Val F1: 1.0000 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.0064 - Val accuracy: 1.0000 - Val loss: 0.0021 - Val F1: 1.0000 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.0040 - Val accuracy: 1.0000 - Val loss: 0.0012 - Val F1: 1.0000 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.0053 - Val accuracy: 1.0000 - Val loss: 0.0019 - Val F1: 1.0000 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0016 - Val accuracy: 1.0000 - Val loss: 0.0012 - Val F1: 1.0000 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0053 - Val accuracy: 1.0000 - Val loss: 0.0008 - Val F1: 1.0000 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0010 - Val accuracy: 1.0000 - Val loss: 0.0010 - Val F1: 1.0000 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0028 - Val accuracy: 1.0000 - Val loss: 0.0010 - Val F1: 1.0000 - LR: 0.00e+00\n","\tBest epoch: 92 - Best val accuracy: 1.0000 - Best val loss: 0.0006 - Best val F1: 1.0000\n","\n","Source class: WAL | Domain: 64 | Accuracy: 0.9938 | Loss: 0.0349 | F1: 0.9938\n","\n","Domain: 65\n","x_dp_dom.shape: (840, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Training and evaluating on Dp data via cross-validation...\n","\tEpoch 10/100 - Train loss: 0.0864 - Val accuracy: 0.9704 - Val loss: 0.1416 - Val F1: 0.9704 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.0275 - Val accuracy: 0.9630 - Val loss: 0.1413 - Val F1: 0.9629 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.0086 - Val accuracy: 0.9556 - Val loss: 0.1635 - Val F1: 0.9557 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.0082 - Val accuracy: 0.9556 - Val loss: 0.1820 - Val F1: 0.9557 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.0038 - Val accuracy: 0.9630 - Val loss: 0.1763 - Val F1: 0.9629 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.0025 - Val accuracy: 0.9556 - Val loss: 0.1874 - Val F1: 0.9557 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0027 - Val accuracy: 0.9630 - Val loss: 0.1829 - Val F1: 0.9629 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0017 - Val accuracy: 0.9556 - Val loss: 0.1849 - Val F1: 0.9557 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0015 - Val accuracy: 0.9556 - Val loss: 0.1817 - Val F1: 0.9557 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0017 - Val accuracy: 0.9556 - Val loss: 0.1825 - Val F1: 0.9557 - LR: 0.00e+00\n","\tBest epoch: 15 - Best val accuracy: 0.9556 - Best val loss: 0.1317 - Best val F1: 0.9554\n","\n","\tEpoch 10/100 - Train loss: 0.0626 - Val accuracy: 0.9778 - Val loss: 0.0834 - Val F1: 0.9777 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.0275 - Val accuracy: 0.9704 - Val loss: 0.0795 - Val F1: 0.9703 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.0119 - Val accuracy: 0.9704 - Val loss: 0.0911 - Val F1: 0.9703 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.0054 - Val accuracy: 0.9704 - Val loss: 0.0915 - Val F1: 0.9703 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.0075 - Val accuracy: 0.9704 - Val loss: 0.0957 - Val F1: 0.9703 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.0068 - Val accuracy: 0.9704 - Val loss: 0.0966 - Val F1: 0.9703 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0029 - Val accuracy: 0.9704 - Val loss: 0.1060 - Val F1: 0.9703 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0020 - Val accuracy: 0.9704 - Val loss: 0.0971 - Val F1: 0.9703 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0021 - Val accuracy: 0.9704 - Val loss: 0.1089 - Val F1: 0.9703 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0022 - Val accuracy: 0.9704 - Val loss: 0.1010 - Val F1: 0.9703 - LR: 0.00e+00\n","\tBest epoch: 20 - Best val accuracy: 0.9704 - Best val loss: 0.0795 - Best val F1: 0.9703\n","\n","\tEpoch 10/100 - Train loss: 0.0901 - Val accuracy: 0.9852 - Val loss: 0.0498 - Val F1: 0.9852 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.0329 - Val accuracy: 0.9852 - Val loss: 0.0317 - Val F1: 0.9852 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.0146 - Val accuracy: 0.9926 - Val loss: 0.0274 - Val F1: 0.9926 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.0071 - Val accuracy: 0.9926 - Val loss: 0.0237 - Val F1: 0.9926 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.0062 - Val accuracy: 0.9926 - Val loss: 0.0194 - Val F1: 0.9926 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.0037 - Val accuracy: 0.9926 - Val loss: 0.0218 - Val F1: 0.9926 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0022 - Val accuracy: 0.9926 - Val loss: 0.0194 - Val F1: 0.9926 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0031 - Val accuracy: 0.9926 - Val loss: 0.0215 - Val F1: 0.9926 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0020 - Val accuracy: 0.9926 - Val loss: 0.0251 - Val F1: 0.9926 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0021 - Val accuracy: 0.9926 - Val loss: 0.0222 - Val F1: 0.9926 - LR: 0.00e+00\n","\tBest epoch: 76 - Best val accuracy: 0.9926 - Best val loss: 0.0190 - Best val F1: 0.9926\n","\n","\tEpoch 10/100 - Train loss: 0.0656 - Val accuracy: 0.9778 - Val loss: 0.0765 - Val F1: 0.9778 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.0381 - Val accuracy: 0.9778 - Val loss: 0.0746 - Val F1: 0.9778 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.0134 - Val accuracy: 0.9704 - Val loss: 0.0781 - Val F1: 0.9704 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.0054 - Val accuracy: 0.9704 - Val loss: 0.0828 - Val F1: 0.9704 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.0035 - Val accuracy: 0.9778 - Val loss: 0.0829 - Val F1: 0.9777 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.0043 - Val accuracy: 0.9704 - Val loss: 0.0824 - Val F1: 0.9704 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0017 - Val accuracy: 0.9704 - Val loss: 0.0877 - Val F1: 0.9704 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0027 - Val accuracy: 0.9704 - Val loss: 0.0881 - Val F1: 0.9704 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0030 - Val accuracy: 0.9778 - Val loss: 0.0907 - Val F1: 0.9778 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0015 - Val accuracy: 0.9704 - Val loss: 0.0891 - Val F1: 0.9704 - LR: 0.00e+00\n","\tBest epoch: 23 - Best val accuracy: 0.9704 - Best val loss: 0.0698 - Best val F1: 0.9704\n","\n","\tEpoch 10/100 - Train loss: 0.0655 - Val accuracy: 0.9926 - Val loss: 0.0307 - Val F1: 0.9926 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.0350 - Val accuracy: 0.9926 - Val loss: 0.0153 - Val F1: 0.9926 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.0390 - Val accuracy: 0.9926 - Val loss: 0.0153 - Val F1: 0.9926 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.0076 - Val accuracy: 0.9926 - Val loss: 0.0097 - Val F1: 0.9926 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.0035 - Val accuracy: 0.9926 - Val loss: 0.0094 - Val F1: 0.9926 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.0041 - Val accuracy: 0.9926 - Val loss: 0.0119 - Val F1: 0.9926 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0056 - Val accuracy: 0.9926 - Val loss: 0.0147 - Val F1: 0.9926 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0052 - Val accuracy: 0.9926 - Val loss: 0.0076 - Val F1: 0.9926 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0050 - Val accuracy: 0.9926 - Val loss: 0.0116 - Val F1: 0.9926 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0017 - Val accuracy: 0.9926 - Val loss: 0.0071 - Val F1: 0.9926 - LR: 0.00e+00\n","\tBest epoch: 82 - Best val accuracy: 1.0000 - Best val loss: 0.0053 - Best val F1: 1.0000\n","\n","Source class: WAL | Domain: 65 | Accuracy: 0.9750 | Loss: 0.0889 | F1: 0.9750\n","\n","Domain: 66\n","x_dp_dom.shape: (792, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Training and evaluating on Dp data via cross-validation...\n","\tEpoch 10/100 - Train loss: 0.1297 - Val accuracy: 0.9370 - Val loss: 0.1418 - Val F1: 0.9354 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.0476 - Val accuracy: 0.9449 - Val loss: 0.1223 - Val F1: 0.9456 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.0282 - Val accuracy: 0.9370 - Val loss: 0.1193 - Val F1: 0.9369 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.0170 - Val accuracy: 0.9528 - Val loss: 0.1150 - Val F1: 0.9521 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.0075 - Val accuracy: 0.9449 - Val loss: 0.1210 - Val F1: 0.9445 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.0138 - Val accuracy: 0.9449 - Val loss: 0.1214 - Val F1: 0.9452 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0041 - Val accuracy: 0.9449 - Val loss: 0.1223 - Val F1: 0.9452 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0037 - Val accuracy: 0.9449 - Val loss: 0.1242 - Val F1: 0.9445 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0038 - Val accuracy: 0.9370 - Val loss: 0.1288 - Val F1: 0.9370 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0053 - Val accuracy: 0.9370 - Val loss: 0.1302 - Val F1: 0.9370 - LR: 0.00e+00\n","\tBest epoch: 26 - Best val accuracy: 0.9606 - Best val loss: 0.1128 - Best val F1: 0.9603\n","\n","\tEpoch 10/100 - Train loss: 0.1218 - Val accuracy: 0.9685 - Val loss: 0.1004 - Val F1: 0.9683 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.0408 - Val accuracy: 0.9764 - Val loss: 0.0722 - Val F1: 0.9765 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.0354 - Val accuracy: 0.9764 - Val loss: 0.0753 - Val F1: 0.9763 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.0137 - Val accuracy: 0.9685 - Val loss: 0.0832 - Val F1: 0.9683 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.0060 - Val accuracy: 0.9764 - Val loss: 0.0768 - Val F1: 0.9763 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.0032 - Val accuracy: 0.9843 - Val loss: 0.0727 - Val F1: 0.9842 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0049 - Val accuracy: 0.9764 - Val loss: 0.0782 - Val F1: 0.9763 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0027 - Val accuracy: 0.9764 - Val loss: 0.0742 - Val F1: 0.9763 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0030 - Val accuracy: 0.9843 - Val loss: 0.0714 - Val F1: 0.9842 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0035 - Val accuracy: 0.9843 - Val loss: 0.0741 - Val F1: 0.9842 - LR: 0.00e+00\n","\tBest epoch: 86 - Best val accuracy: 0.9843 - Best val loss: 0.0687 - Best val F1: 0.9842\n","\n","\tEpoch 10/100 - Train loss: 0.1072 - Val accuracy: 0.9764 - Val loss: 0.1347 - Val F1: 0.9762 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.0412 - Val accuracy: 0.9843 - Val loss: 0.1139 - Val F1: 0.9842 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.0152 - Val accuracy: 0.9843 - Val loss: 0.1061 - Val F1: 0.9843 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.0147 - Val accuracy: 0.9764 - Val loss: 0.1119 - Val F1: 0.9763 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.0061 - Val accuracy: 0.9685 - Val loss: 0.1179 - Val F1: 0.9682 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.0043 - Val accuracy: 0.9685 - Val loss: 0.1185 - Val F1: 0.9683 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0020 - Val accuracy: 0.9685 - Val loss: 0.1333 - Val F1: 0.9682 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0062 - Val accuracy: 0.9685 - Val loss: 0.1275 - Val F1: 0.9682 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0025 - Val accuracy: 0.9685 - Val loss: 0.1289 - Val F1: 0.9682 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0026 - Val accuracy: 0.9685 - Val loss: 0.1322 - Val F1: 0.9682 - LR: 0.00e+00\n","\tBest epoch: 31 - Best val accuracy: 0.9843 - Best val loss: 0.1047 - Best val F1: 0.9842\n","\n","\tEpoch 10/100 - Train loss: 0.1174 - Val accuracy: 0.9685 - Val loss: 0.1250 - Val F1: 0.9685 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.0298 - Val accuracy: 0.9685 - Val loss: 0.0916 - Val F1: 0.9685 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.0167 - Val accuracy: 0.9606 - Val loss: 0.0866 - Val F1: 0.9608 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.0115 - Val accuracy: 0.9843 - Val loss: 0.0805 - Val F1: 0.9843 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.0088 - Val accuracy: 0.9843 - Val loss: 0.0798 - Val F1: 0.9842 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.0071 - Val accuracy: 0.9764 - Val loss: 0.0806 - Val F1: 0.9764 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0044 - Val accuracy: 0.9843 - Val loss: 0.0791 - Val F1: 0.9842 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0030 - Val accuracy: 0.9843 - Val loss: 0.0759 - Val F1: 0.9843 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0017 - Val accuracy: 0.9843 - Val loss: 0.0786 - Val F1: 0.9843 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0020 - Val accuracy: 0.9764 - Val loss: 0.0783 - Val F1: 0.9762 - LR: 0.00e+00\n","\tBest epoch: 68 - Best val accuracy: 0.9921 - Best val loss: 0.0744 - Best val F1: 0.9921\n","\n","\tEpoch 10/100 - Train loss: 0.0922 - Val accuracy: 0.9764 - Val loss: 0.0966 - Val F1: 0.9764 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.0281 - Val accuracy: 0.9843 - Val loss: 0.0743 - Val F1: 0.9842 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.0175 - Val accuracy: 0.9843 - Val loss: 0.0659 - Val F1: 0.9843 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.0049 - Val accuracy: 0.9843 - Val loss: 0.0636 - Val F1: 0.9843 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.0032 - Val accuracy: 0.9843 - Val loss: 0.0636 - Val F1: 0.9843 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.0055 - Val accuracy: 0.9843 - Val loss: 0.0597 - Val F1: 0.9843 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0037 - Val accuracy: 0.9843 - Val loss: 0.0692 - Val F1: 0.9842 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0023 - Val accuracy: 0.9921 - Val loss: 0.0668 - Val F1: 0.9921 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0035 - Val accuracy: 0.9843 - Val loss: 0.0577 - Val F1: 0.9843 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0021 - Val accuracy: 0.9843 - Val loss: 0.0657 - Val F1: 0.9842 - LR: 0.00e+00\n","\tBest epoch: 76 - Best val accuracy: 0.9843 - Best val loss: 0.0549 - Best val F1: 0.9843\n","\n","Source class: WAL | Domain: 66 | Accuracy: 0.9621 | Loss: 0.0974 | F1: 0.9617\n","\n","Domain: 67\n","x_dp_dom.shape: (572, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Training and evaluating on Dp data via cross-validation...\n","\tEpoch 10/100 - Train loss: 0.0634 - Val accuracy: 0.9783 - Val loss: 0.0764 - Val F1: 0.9781 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.0132 - Val accuracy: 0.9891 - Val loss: 0.0300 - Val F1: 0.9891 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.0123 - Val accuracy: 1.0000 - Val loss: 0.0134 - Val F1: 1.0000 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.0027 - Val accuracy: 1.0000 - Val loss: 0.0114 - Val F1: 1.0000 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.0016 - Val accuracy: 1.0000 - Val loss: 0.0082 - Val F1: 1.0000 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.0012 - Val accuracy: 1.0000 - Val loss: 0.0099 - Val F1: 1.0000 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0010 - Val accuracy: 1.0000 - Val loss: 0.0078 - Val F1: 1.0000 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0006 - Val accuracy: 1.0000 - Val loss: 0.0085 - Val F1: 1.0000 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0024 - Val accuracy: 1.0000 - Val loss: 0.0067 - Val F1: 1.0000 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0014 - Val accuracy: 1.0000 - Val loss: 0.0076 - Val F1: 1.0000 - LR: 0.00e+00\n","\tBest epoch: 89 - Best val accuracy: 1.0000 - Best val loss: 0.0063 - Best val F1: 1.0000\n","\n","\tEpoch 10/100 - Train loss: 0.0450 - Val accuracy: 0.9891 - Val loss: 0.0735 - Val F1: 0.9893 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.0110 - Val accuracy: 0.9891 - Val loss: 0.0698 - Val F1: 0.9893 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.0025 - Val accuracy: 0.9891 - Val loss: 0.0658 - Val F1: 0.9893 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.0016 - Val accuracy: 0.9891 - Val loss: 0.0762 - Val F1: 0.9893 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.0075 - Val accuracy: 0.9891 - Val loss: 0.0720 - Val F1: 0.9893 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.0010 - Val accuracy: 0.9891 - Val loss: 0.0722 - Val F1: 0.9893 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0011 - Val accuracy: 0.9891 - Val loss: 0.0794 - Val F1: 0.9893 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0022 - Val accuracy: 0.9891 - Val loss: 0.0812 - Val F1: 0.9893 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0007 - Val accuracy: 0.9891 - Val loss: 0.0742 - Val F1: 0.9893 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0003 - Val accuracy: 0.9891 - Val loss: 0.0742 - Val F1: 0.9893 - LR: 0.00e+00\n","\tBest epoch: 17 - Best val accuracy: 0.9891 - Best val loss: 0.0597 - Best val F1: 0.9893\n","\n","\tEpoch 10/100 - Train loss: 0.0818 - Val accuracy: 0.9783 - Val loss: 0.0800 - Val F1: 0.9783 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.0210 - Val accuracy: 0.9891 - Val loss: 0.0261 - Val F1: 0.9891 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.0059 - Val accuracy: 1.0000 - Val loss: 0.0164 - Val F1: 1.0000 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.0032 - Val accuracy: 1.0000 - Val loss: 0.0123 - Val F1: 1.0000 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.0023 - Val accuracy: 1.0000 - Val loss: 0.0093 - Val F1: 1.0000 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.0017 - Val accuracy: 1.0000 - Val loss: 0.0122 - Val F1: 1.0000 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0014 - Val accuracy: 1.0000 - Val loss: 0.0086 - Val F1: 1.0000 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0008 - Val accuracy: 1.0000 - Val loss: 0.0072 - Val F1: 1.0000 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0007 - Val accuracy: 1.0000 - Val loss: 0.0089 - Val F1: 1.0000 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0007 - Val accuracy: 1.0000 - Val loss: 0.0060 - Val F1: 1.0000 - LR: 0.00e+00\n","\tBest epoch: 83 - Best val accuracy: 1.0000 - Best val loss: 0.0050 - Best val F1: 1.0000\n","\n","\tEpoch 10/100 - Train loss: 0.0845 - Val accuracy: 0.9891 - Val loss: 0.0872 - Val F1: 0.9891 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.0168 - Val accuracy: 0.9891 - Val loss: 0.0323 - Val F1: 0.9891 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.0089 - Val accuracy: 0.9891 - Val loss: 0.0245 - Val F1: 0.9891 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.0037 - Val accuracy: 0.9891 - Val loss: 0.0175 - Val F1: 0.9891 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.0028 - Val accuracy: 0.9891 - Val loss: 0.0197 - Val F1: 0.9891 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.0021 - Val accuracy: 0.9891 - Val loss: 0.0156 - Val F1: 0.9891 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0021 - Val accuracy: 1.0000 - Val loss: 0.0112 - Val F1: 1.0000 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0010 - Val accuracy: 0.9891 - Val loss: 0.0146 - Val F1: 0.9891 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0012 - Val accuracy: 1.0000 - Val loss: 0.0120 - Val F1: 1.0000 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0012 - Val accuracy: 0.9891 - Val loss: 0.0123 - Val F1: 0.9891 - LR: 0.00e+00\n","\tBest epoch: 65 - Best val accuracy: 1.0000 - Best val loss: 0.0107 - Best val F1: 1.0000\n","\n","\tEpoch 10/100 - Train loss: 0.0432 - Val accuracy: 1.0000 - Val loss: 0.0222 - Val F1: 1.0000 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.0101 - Val accuracy: 1.0000 - Val loss: 0.0077 - Val F1: 1.0000 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.0040 - Val accuracy: 1.0000 - Val loss: 0.0044 - Val F1: 1.0000 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.0072 - Val accuracy: 1.0000 - Val loss: 0.0086 - Val F1: 1.0000 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.0022 - Val accuracy: 1.0000 - Val loss: 0.0031 - Val F1: 1.0000 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.0015 - Val accuracy: 1.0000 - Val loss: 0.0016 - Val F1: 1.0000 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0013 - Val accuracy: 1.0000 - Val loss: 0.0019 - Val F1: 1.0000 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0008 - Val accuracy: 1.0000 - Val loss: 0.0018 - Val F1: 1.0000 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0009 - Val accuracy: 1.0000 - Val loss: 0.0016 - Val F1: 1.0000 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0011 - Val accuracy: 1.0000 - Val loss: 0.0015 - Val F1: 1.0000 - LR: 0.00e+00\n","\tBest epoch: 88 - Best val accuracy: 1.0000 - Best val loss: 0.0010 - Best val F1: 1.0000\n","\n","Source class: WAL | Domain: 67 | Accuracy: 0.9930 | Loss: 0.0262 | F1: 0.9930\n","\n","Domain: 68\n","x_dp_dom.shape: (877, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Training and evaluating on Dp data via cross-validation...\n","\tEpoch 10/100 - Train loss: 0.0228 - Val accuracy: 1.0000 - Val loss: 0.0120 - Val F1: 1.0000 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.0070 - Val accuracy: 1.0000 - Val loss: 0.0063 - Val F1: 1.0000 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.0037 - Val accuracy: 1.0000 - Val loss: 0.0039 - Val F1: 1.0000 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.0019 - Val accuracy: 1.0000 - Val loss: 0.0017 - Val F1: 1.0000 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.0027 - Val accuracy: 1.0000 - Val loss: 0.0022 - Val F1: 1.0000 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.0006 - Val accuracy: 1.0000 - Val loss: 0.0019 - Val F1: 1.0000 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0012 - Val accuracy: 1.0000 - Val loss: 0.0010 - Val F1: 1.0000 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0004 - Val accuracy: 1.0000 - Val loss: 0.0012 - Val F1: 1.0000 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0007 - Val accuracy: 1.0000 - Val loss: 0.0009 - Val F1: 1.0000 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0004 - Val accuracy: 1.0000 - Val loss: 0.0007 - Val F1: 1.0000 - LR: 0.00e+00\n","\tBest epoch: 100 - Best val accuracy: 1.0000 - Best val loss: 0.0007 - Best val F1: 1.0000\n","\n","\tEpoch 10/100 - Train loss: 0.0203 - Val accuracy: 1.0000 - Val loss: 0.0058 - Val F1: 1.0000 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.0065 - Val accuracy: 1.0000 - Val loss: 0.0016 - Val F1: 1.0000 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.0040 - Val accuracy: 1.0000 - Val loss: 0.0007 - Val F1: 1.0000 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.0017 - Val accuracy: 1.0000 - Val loss: 0.0004 - Val F1: 1.0000 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.0020 - Val accuracy: 1.0000 - Val loss: 0.0003 - Val F1: 1.0000 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.0006 - Val accuracy: 1.0000 - Val loss: 0.0002 - Val F1: 1.0000 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0008 - Val accuracy: 1.0000 - Val loss: 0.0002 - Val F1: 1.0000 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0007 - Val accuracy: 1.0000 - Val loss: 0.0002 - Val F1: 1.0000 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0006 - Val accuracy: 1.0000 - Val loss: 0.0001 - Val F1: 1.0000 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0004 - Val accuracy: 1.0000 - Val loss: 0.0001 - Val F1: 1.0000 - LR: 0.00e+00\n","\tBest epoch: 100 - Best val accuracy: 1.0000 - Best val loss: 0.0001 - Best val F1: 1.0000\n","\n","\tEpoch 10/100 - Train loss: 0.0621 - Val accuracy: 1.0000 - Val loss: 0.0287 - Val F1: 1.0000 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.0394 - Val accuracy: 1.0000 - Val loss: 0.0123 - Val F1: 1.0000 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.0585 - Val accuracy: 0.9858 - Val loss: 0.0255 - Val F1: 0.9857 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.0130 - Val accuracy: 1.0000 - Val loss: 0.0106 - Val F1: 1.0000 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.0313 - Val accuracy: 1.0000 - Val loss: 0.0101 - Val F1: 1.0000 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.0113 - Val accuracy: 1.0000 - Val loss: 0.0033 - Val F1: 1.0000 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0165 - Val accuracy: 1.0000 - Val loss: 0.0054 - Val F1: 1.0000 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0124 - Val accuracy: 1.0000 - Val loss: 0.0034 - Val F1: 1.0000 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0127 - Val accuracy: 1.0000 - Val loss: 0.0032 - Val F1: 1.0000 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0057 - Val accuracy: 1.0000 - Val loss: 0.0029 - Val F1: 1.0000 - LR: 0.00e+00\n","\tBest epoch: 83 - Best val accuracy: 1.0000 - Best val loss: 0.0026 - Best val F1: 1.0000\n","\n","\tEpoch 10/100 - Train loss: 0.0450 - Val accuracy: 1.0000 - Val loss: 0.0158 - Val F1: 1.0000 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.0178 - Val accuracy: 1.0000 - Val loss: 0.0053 - Val F1: 1.0000 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.0113 - Val accuracy: 1.0000 - Val loss: 0.0108 - Val F1: 1.0000 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.0059 - Val accuracy: 1.0000 - Val loss: 0.0029 - Val F1: 1.0000 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.0078 - Val accuracy: 1.0000 - Val loss: 0.0025 - Val F1: 1.0000 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.0060 - Val accuracy: 1.0000 - Val loss: 0.0014 - Val F1: 1.0000 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0051 - Val accuracy: 1.0000 - Val loss: 0.0021 - Val F1: 1.0000 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0019 - Val accuracy: 1.0000 - Val loss: 0.0017 - Val F1: 1.0000 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0032 - Val accuracy: 1.0000 - Val loss: 0.0008 - Val F1: 1.0000 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0035 - Val accuracy: 1.0000 - Val loss: 0.0009 - Val F1: 1.0000 - LR: 0.00e+00\n","\tBest epoch: 93 - Best val accuracy: 1.0000 - Best val loss: 0.0008 - Best val F1: 1.0000\n","\n","\tEpoch 10/100 - Train loss: 0.0566 - Val accuracy: 1.0000 - Val loss: 0.0259 - Val F1: 1.0000 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.0708 - Val accuracy: 1.0000 - Val loss: 0.0082 - Val F1: 1.0000 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.0070 - Val accuracy: 1.0000 - Val loss: 0.0047 - Val F1: 1.0000 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.0664 - Val accuracy: 1.0000 - Val loss: 0.0046 - Val F1: 1.0000 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.0661 - Val accuracy: 1.0000 - Val loss: 0.0032 - Val F1: 1.0000 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.0238 - Val accuracy: 1.0000 - Val loss: 0.0030 - Val F1: 1.0000 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0061 - Val accuracy: 1.0000 - Val loss: 0.0020 - Val F1: 1.0000 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0056 - Val accuracy: 1.0000 - Val loss: 0.0016 - Val F1: 1.0000 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0064 - Val accuracy: 1.0000 - Val loss: 0.0030 - Val F1: 1.0000 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0064 - Val accuracy: 1.0000 - Val loss: 0.0016 - Val F1: 1.0000 - LR: 0.00e+00\n","\tBest epoch: 88 - Best val accuracy: 1.0000 - Best val loss: 0.0014 - Best val F1: 1.0000\n","\n","Source class: WAL | Domain: 68 | Accuracy: 0.9989 | Loss: 0.0056 | F1: 0.9989\n","\n","Domain: 69\n","x_dp_dom.shape: (799, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Training and evaluating on Dp data via cross-validation...\n","\tEpoch 10/100 - Train loss: 0.1214 - Val accuracy: 0.9453 - Val loss: 0.1593 - Val F1: 0.9454 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.0359 - Val accuracy: 0.9375 - Val loss: 0.1184 - Val F1: 0.9375 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.0153 - Val accuracy: 0.9609 - Val loss: 0.1006 - Val F1: 0.9609 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.0071 - Val accuracy: 0.9766 - Val loss: 0.1051 - Val F1: 0.9765 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.0039 - Val accuracy: 0.9609 - Val loss: 0.1104 - Val F1: 0.9609 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.0035 - Val accuracy: 0.9609 - Val loss: 0.1013 - Val F1: 0.9609 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0019 - Val accuracy: 0.9531 - Val loss: 0.1064 - Val F1: 0.9531 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0038 - Val accuracy: 0.9531 - Val loss: 0.1092 - Val F1: 0.9531 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0032 - Val accuracy: 0.9766 - Val loss: 0.1042 - Val F1: 0.9765 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0017 - Val accuracy: 0.9531 - Val loss: 0.1089 - Val F1: 0.9531 - LR: 0.00e+00\n","\tBest epoch: 73 - Best val accuracy: 0.9688 - Best val loss: 0.0905 - Best val F1: 0.9687\n","\n","\tEpoch 10/100 - Train loss: 0.1417 - Val accuracy: 0.9453 - Val loss: 0.1403 - Val F1: 0.9453 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.0395 - Val accuracy: 0.9688 - Val loss: 0.0774 - Val F1: 0.9688 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.0156 - Val accuracy: 0.9766 - Val loss: 0.0539 - Val F1: 0.9766 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.0076 - Val accuracy: 0.9766 - Val loss: 0.0461 - Val F1: 0.9766 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.0048 - Val accuracy: 0.9844 - Val loss: 0.0431 - Val F1: 0.9844 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.0051 - Val accuracy: 0.9844 - Val loss: 0.0348 - Val F1: 0.9844 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0038 - Val accuracy: 0.9844 - Val loss: 0.0372 - Val F1: 0.9844 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0022 - Val accuracy: 0.9844 - Val loss: 0.0360 - Val F1: 0.9844 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0016 - Val accuracy: 0.9844 - Val loss: 0.0393 - Val F1: 0.9844 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0017 - Val accuracy: 0.9844 - Val loss: 0.0360 - Val F1: 0.9844 - LR: 0.00e+00\n","\tBest epoch: 98 - Best val accuracy: 0.9844 - Best val loss: 0.0329 - Best val F1: 0.9844\n","\n","\tEpoch 10/100 - Train loss: 0.1269 - Val accuracy: 0.9453 - Val loss: 0.2042 - Val F1: 0.9457 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.0388 - Val accuracy: 0.9531 - Val loss: 0.1857 - Val F1: 0.9536 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.0133 - Val accuracy: 0.9609 - Val loss: 0.1861 - Val F1: 0.9608 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.0120 - Val accuracy: 0.9609 - Val loss: 0.1908 - Val F1: 0.9608 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.0047 - Val accuracy: 0.9609 - Val loss: 0.1767 - Val F1: 0.9608 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.0023 - Val accuracy: 0.9609 - Val loss: 0.1899 - Val F1: 0.9608 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0018 - Val accuracy: 0.9609 - Val loss: 0.2024 - Val F1: 0.9608 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0030 - Val accuracy: 0.9609 - Val loss: 0.1978 - Val F1: 0.9608 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0033 - Val accuracy: 0.9609 - Val loss: 0.1963 - Val F1: 0.9608 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0013 - Val accuracy: 0.9609 - Val loss: 0.1975 - Val F1: 0.9608 - LR: 0.00e+00\n","\tBest epoch: 50 - Best val accuracy: 0.9609 - Best val loss: 0.1767 - Best val F1: 0.9608\n","\n","\tEpoch 10/100 - Train loss: 0.1399 - Val accuracy: 0.9297 - Val loss: 0.2055 - Val F1: 0.9303 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.0384 - Val accuracy: 0.9531 - Val loss: 0.1481 - Val F1: 0.9534 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.0284 - Val accuracy: 0.9609 - Val loss: 0.1359 - Val F1: 0.9608 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.0079 - Val accuracy: 0.9609 - Val loss: 0.1440 - Val F1: 0.9607 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.0088 - Val accuracy: 0.9688 - Val loss: 0.1215 - Val F1: 0.9686 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.0066 - Val accuracy: 0.9688 - Val loss: 0.1299 - Val F1: 0.9686 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0037 - Val accuracy: 0.9688 - Val loss: 0.1323 - Val F1: 0.9686 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0037 - Val accuracy: 0.9688 - Val loss: 0.1334 - Val F1: 0.9686 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0031 - Val accuracy: 0.9688 - Val loss: 0.1274 - Val F1: 0.9686 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0029 - Val accuracy: 0.9688 - Val loss: 0.1259 - Val F1: 0.9686 - LR: 0.00e+00\n","\tBest epoch: 78 - Best val accuracy: 0.9688 - Best val loss: 0.1093 - Best val F1: 0.9686\n","\n","\tEpoch 10/100 - Train loss: 0.1467 - Val accuracy: 0.9453 - Val loss: 0.2136 - Val F1: 0.9456 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.0466 - Val accuracy: 0.9531 - Val loss: 0.1933 - Val F1: 0.9532 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.0225 - Val accuracy: 0.9609 - Val loss: 0.1831 - Val F1: 0.9609 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.0091 - Val accuracy: 0.9688 - Val loss: 0.1947 - Val F1: 0.9687 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.0058 - Val accuracy: 0.9688 - Val loss: 0.2149 - Val F1: 0.9687 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.0036 - Val accuracy: 0.9688 - Val loss: 0.2055 - Val F1: 0.9687 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0041 - Val accuracy: 0.9609 - Val loss: 0.2353 - Val F1: 0.9609 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0037 - Val accuracy: 0.9609 - Val loss: 0.2237 - Val F1: 0.9609 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0027 - Val accuracy: 0.9688 - Val loss: 0.2096 - Val F1: 0.9687 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0024 - Val accuracy: 0.9688 - Val loss: 0.2162 - Val F1: 0.9687 - LR: 0.00e+00\n","\tBest epoch: 32 - Best val accuracy: 0.9609 - Best val loss: 0.1781 - Best val F1: 0.9611\n","\n","Source class: WAL | Domain: 69 | Accuracy: 0.9725 | Loss: 0.0992 | F1: 0.9725\n","\n","Domain: 70\n","x_dp_dom.shape: (762, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Training and evaluating on Dp data via cross-validation...\n","\tEpoch 10/100 - Train loss: 0.1060 - Val accuracy: 0.9754 - Val loss: 0.0815 - Val F1: 0.9751 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.0293 - Val accuracy: 0.9754 - Val loss: 0.0691 - Val F1: 0.9751 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.0223 - Val accuracy: 0.9672 - Val loss: 0.0690 - Val F1: 0.9669 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.0125 - Val accuracy: 0.9754 - Val loss: 0.0856 - Val F1: 0.9751 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.0059 - Val accuracy: 0.9672 - Val loss: 0.0804 - Val F1: 0.9669 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.0029 - Val accuracy: 0.9754 - Val loss: 0.0949 - Val F1: 0.9751 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0031 - Val accuracy: 0.9754 - Val loss: 0.0933 - Val F1: 0.9751 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0047 - Val accuracy: 0.9672 - Val loss: 0.0769 - Val F1: 0.9669 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0021 - Val accuracy: 0.9672 - Val loss: 0.0845 - Val F1: 0.9669 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0034 - Val accuracy: 0.9672 - Val loss: 0.1045 - Val F1: 0.9669 - LR: 0.00e+00\n","\tBest epoch: 34 - Best val accuracy: 0.9672 - Best val loss: 0.0651 - Best val F1: 0.9669\n","\n","\tEpoch 10/100 - Train loss: 0.0771 - Val accuracy: 0.9672 - Val loss: 0.0945 - Val F1: 0.9673 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.0261 - Val accuracy: 0.9754 - Val loss: 0.0867 - Val F1: 0.9753 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.0110 - Val accuracy: 0.9754 - Val loss: 0.0896 - Val F1: 0.9753 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.0208 - Val accuracy: 0.9672 - Val loss: 0.0852 - Val F1: 0.9673 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.0040 - Val accuracy: 0.9754 - Val loss: 0.0893 - Val F1: 0.9753 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.0027 - Val accuracy: 0.9754 - Val loss: 0.0909 - Val F1: 0.9753 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0019 - Val accuracy: 0.9754 - Val loss: 0.0867 - Val F1: 0.9753 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0029 - Val accuracy: 0.9754 - Val loss: 0.0852 - Val F1: 0.9753 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0013 - Val accuracy: 0.9754 - Val loss: 0.0906 - Val F1: 0.9753 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0021 - Val accuracy: 0.9754 - Val loss: 0.0856 - Val F1: 0.9753 - LR: 0.00e+00\n","\tBest epoch: 66 - Best val accuracy: 0.9754 - Best val loss: 0.0750 - Best val F1: 0.9753\n","\n","\tEpoch 10/100 - Train loss: 0.0836 - Val accuracy: 0.9918 - Val loss: 0.0525 - Val F1: 0.9918 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.0283 - Val accuracy: 0.9754 - Val loss: 0.0468 - Val F1: 0.9750 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.0090 - Val accuracy: 0.9918 - Val loss: 0.0330 - Val F1: 0.9918 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.0058 - Val accuracy: 0.9754 - Val loss: 0.0456 - Val F1: 0.9750 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.0030 - Val accuracy: 0.9918 - Val loss: 0.0331 - Val F1: 0.9918 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.0033 - Val accuracy: 0.9754 - Val loss: 0.0292 - Val F1: 0.9750 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0029 - Val accuracy: 0.9754 - Val loss: 0.0490 - Val F1: 0.9749 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0019 - Val accuracy: 0.9754 - Val loss: 0.0517 - Val F1: 0.9749 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0014 - Val accuracy: 0.9836 - Val loss: 0.0365 - Val F1: 0.9834 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0013 - Val accuracy: 0.9918 - Val loss: 0.0375 - Val F1: 0.9918 - LR: 0.00e+00\n","\tBest epoch: 62 - Best val accuracy: 0.9918 - Best val loss: 0.0229 - Best val F1: 0.9918\n","\n","\tEpoch 10/100 - Train loss: 0.0882 - Val accuracy: 0.9344 - Val loss: 0.1372 - Val F1: 0.9342 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.0386 - Val accuracy: 0.9672 - Val loss: 0.1107 - Val F1: 0.9669 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.0145 - Val accuracy: 0.9672 - Val loss: 0.1013 - Val F1: 0.9669 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.0082 - Val accuracy: 0.9672 - Val loss: 0.1033 - Val F1: 0.9669 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.0069 - Val accuracy: 0.9672 - Val loss: 0.1119 - Val F1: 0.9669 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.0043 - Val accuracy: 0.9672 - Val loss: 0.1128 - Val F1: 0.9669 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0025 - Val accuracy: 0.9672 - Val loss: 0.1006 - Val F1: 0.9669 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0028 - Val accuracy: 0.9754 - Val loss: 0.1009 - Val F1: 0.9754 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0055 - Val accuracy: 0.9754 - Val loss: 0.0858 - Val F1: 0.9754 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0021 - Val accuracy: 0.9672 - Val loss: 0.0994 - Val F1: 0.9669 - LR: 0.00e+00\n","\tBest epoch: 67 - Best val accuracy: 0.9754 - Best val loss: 0.0799 - Best val F1: 0.9754\n","\n","\tEpoch 10/100 - Train loss: 0.1010 - Val accuracy: 0.9754 - Val loss: 0.0805 - Val F1: 0.9751 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.0229 - Val accuracy: 0.9836 - Val loss: 0.0653 - Val F1: 0.9835 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.0117 - Val accuracy: 0.9754 - Val loss: 0.0765 - Val F1: 0.9751 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.0065 - Val accuracy: 0.9836 - Val loss: 0.0687 - Val F1: 0.9835 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.0055 - Val accuracy: 0.9836 - Val loss: 0.0678 - Val F1: 0.9835 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.0042 - Val accuracy: 0.9836 - Val loss: 0.0734 - Val F1: 0.9835 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0043 - Val accuracy: 0.9836 - Val loss: 0.0674 - Val F1: 0.9835 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0023 - Val accuracy: 0.9836 - Val loss: 0.0702 - Val F1: 0.9835 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0025 - Val accuracy: 0.9836 - Val loss: 0.0760 - Val F1: 0.9835 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0020 - Val accuracy: 0.9918 - Val loss: 0.0619 - Val F1: 0.9918 - LR: 0.00e+00\n","\tBest epoch: 24 - Best val accuracy: 0.9918 - Best val loss: 0.0555 - Best val F1: 0.9918\n","\n","Source class: WAL | Domain: 70 | Accuracy: 0.9829 | Loss: 0.0811 | F1: 0.9828\n","\n","Domain: 71\n","x_dp_dom.shape: (854, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Training and evaluating on Dp data via cross-validation...\n","\tEpoch 10/100 - Train loss: 0.1272 - Val accuracy: 0.9489 - Val loss: 0.1441 - Val F1: 0.9492 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.0366 - Val accuracy: 0.9635 - Val loss: 0.1129 - Val F1: 0.9638 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.0228 - Val accuracy: 0.9635 - Val loss: 0.1158 - Val F1: 0.9638 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.0413 - Val accuracy: 0.9635 - Val loss: 0.1282 - Val F1: 0.9638 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.0083 - Val accuracy: 0.9708 - Val loss: 0.0980 - Val F1: 0.9710 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.0160 - Val accuracy: 0.9708 - Val loss: 0.0874 - Val F1: 0.9708 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0061 - Val accuracy: 0.9708 - Val loss: 0.0988 - Val F1: 0.9710 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0130 - Val accuracy: 0.9781 - Val loss: 0.0886 - Val F1: 0.9781 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0060 - Val accuracy: 0.9781 - Val loss: 0.0783 - Val F1: 0.9781 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0053 - Val accuracy: 0.9781 - Val loss: 0.0836 - Val F1: 0.9781 - LR: 0.00e+00\n","\tBest epoch: 98 - Best val accuracy: 0.9781 - Best val loss: 0.0734 - Best val F1: 0.9781\n","\n","\tEpoch 10/100 - Train loss: 0.1334 - Val accuracy: 0.9708 - Val loss: 0.1065 - Val F1: 0.9708 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.0464 - Val accuracy: 0.9854 - Val loss: 0.0747 - Val F1: 0.9855 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.0326 - Val accuracy: 0.9854 - Val loss: 0.0536 - Val F1: 0.9853 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.0128 - Val accuracy: 0.9927 - Val loss: 0.0431 - Val F1: 0.9927 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.0163 - Val accuracy: 0.9854 - Val loss: 0.0505 - Val F1: 0.9855 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.0051 - Val accuracy: 0.9854 - Val loss: 0.0470 - Val F1: 0.9854 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0057 - Val accuracy: 0.9854 - Val loss: 0.0359 - Val F1: 0.9853 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0091 - Val accuracy: 0.9854 - Val loss: 0.0446 - Val F1: 0.9853 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0045 - Val accuracy: 0.9854 - Val loss: 0.0385 - Val F1: 0.9853 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0063 - Val accuracy: 0.9854 - Val loss: 0.0366 - Val F1: 0.9854 - LR: 0.00e+00\n","\tBest epoch: 75 - Best val accuracy: 0.9854 - Best val loss: 0.0341 - Best val F1: 0.9853\n","\n","\tEpoch 10/100 - Train loss: 0.1387 - Val accuracy: 0.9781 - Val loss: 0.1221 - Val F1: 0.9781 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.0395 - Val accuracy: 0.9708 - Val loss: 0.1165 - Val F1: 0.9708 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.0174 - Val accuracy: 0.9781 - Val loss: 0.1206 - Val F1: 0.9781 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.0134 - Val accuracy: 0.9781 - Val loss: 0.1148 - Val F1: 0.9781 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.0129 - Val accuracy: 0.9635 - Val loss: 0.1478 - Val F1: 0.9633 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.0236 - Val accuracy: 0.9781 - Val loss: 0.1079 - Val F1: 0.9781 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0080 - Val accuracy: 0.9635 - Val loss: 0.1322 - Val F1: 0.9633 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0040 - Val accuracy: 0.9708 - Val loss: 0.1174 - Val F1: 0.9707 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0040 - Val accuracy: 0.9708 - Val loss: 0.1250 - Val F1: 0.9707 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0036 - Val accuracy: 0.9781 - Val loss: 0.1208 - Val F1: 0.9780 - LR: 0.00e+00\n","\tBest epoch: 60 - Best val accuracy: 0.9781 - Best val loss: 0.1079 - Best val F1: 0.9781\n","\n","\tEpoch 10/100 - Train loss: 0.1345 - Val accuracy: 0.9270 - Val loss: 0.1672 - Val F1: 0.9276 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.0433 - Val accuracy: 0.9562 - Val loss: 0.1288 - Val F1: 0.9566 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.0190 - Val accuracy: 0.9562 - Val loss: 0.1205 - Val F1: 0.9566 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.0101 - Val accuracy: 0.9635 - Val loss: 0.1068 - Val F1: 0.9638 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.0949 - Val accuracy: 0.9635 - Val loss: 0.1649 - Val F1: 0.9634 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.0114 - Val accuracy: 0.9635 - Val loss: 0.1176 - Val F1: 0.9634 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0052 - Val accuracy: 0.9635 - Val loss: 0.1167 - Val F1: 0.9638 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0053 - Val accuracy: 0.9635 - Val loss: 0.1123 - Val F1: 0.9636 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0161 - Val accuracy: 0.9635 - Val loss: 0.1096 - Val F1: 0.9638 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0043 - Val accuracy: 0.9635 - Val loss: 0.1154 - Val F1: 0.9638 - LR: 0.00e+00\n","\tBest epoch: 57 - Best val accuracy: 0.9781 - Best val loss: 0.0967 - Best val F1: 0.9781\n","\n","\tEpoch 10/100 - Train loss: 0.1483 - Val accuracy: 0.9489 - Val loss: 0.1646 - Val F1: 0.9492 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.0655 - Val accuracy: 0.9562 - Val loss: 0.1657 - Val F1: 0.9563 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.0250 - Val accuracy: 0.9781 - Val loss: 0.1467 - Val F1: 0.9781 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.0130 - Val accuracy: 0.9781 - Val loss: 0.1469 - Val F1: 0.9781 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.0099 - Val accuracy: 0.9781 - Val loss: 0.1486 - Val F1: 0.9781 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.0244 - Val accuracy: 0.9708 - Val loss: 0.1400 - Val F1: 0.9708 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0080 - Val accuracy: 0.9708 - Val loss: 0.1564 - Val F1: 0.9709 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0047 - Val accuracy: 0.9708 - Val loss: 0.1594 - Val F1: 0.9709 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0052 - Val accuracy: 0.9708 - Val loss: 0.1367 - Val F1: 0.9708 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0044 - Val accuracy: 0.9781 - Val loss: 0.1481 - Val F1: 0.9781 - LR: 0.00e+00\n","\tBest epoch: 25 - Best val accuracy: 0.9708 - Best val loss: 0.1273 - Best val F1: 0.9708\n","\n","Source class: WAL | Domain: 71 | Accuracy: 0.9579 | Loss: 0.1096 | F1: 0.9579\n","\n","Domain: 72\n","x_dp_dom.shape: (811, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Training and evaluating on Dp data via cross-validation...\n","\tEpoch 10/100 - Train loss: 0.1070 - Val accuracy: 0.9308 - Val loss: 0.1904 - Val F1: 0.9315 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.0431 - Val accuracy: 0.9462 - Val loss: 0.1753 - Val F1: 0.9467 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.0173 - Val accuracy: 0.9231 - Val loss: 0.2273 - Val F1: 0.9236 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.0145 - Val accuracy: 0.9308 - Val loss: 0.2203 - Val F1: 0.9308 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.0076 - Val accuracy: 0.9308 - Val loss: 0.2196 - Val F1: 0.9308 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.0042 - Val accuracy: 0.9231 - Val loss: 0.2729 - Val F1: 0.9236 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0040 - Val accuracy: 0.9308 - Val loss: 0.2310 - Val F1: 0.9308 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0022 - Val accuracy: 0.9462 - Val loss: 0.2073 - Val F1: 0.9465 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0034 - Val accuracy: 0.9385 - Val loss: 0.2354 - Val F1: 0.9387 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0023 - Val accuracy: 0.9385 - Val loss: 0.2291 - Val F1: 0.9387 - LR: 0.00e+00\n","\tBest epoch: 33 - Best val accuracy: 0.9462 - Best val loss: 0.1729 - Best val F1: 0.9466\n","\n","\tEpoch 10/100 - Train loss: 0.1092 - Val accuracy: 0.9538 - Val loss: 0.3443 - Val F1: 0.9538 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.0395 - Val accuracy: 0.9615 - Val loss: 0.3642 - Val F1: 0.9613 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.0184 - Val accuracy: 0.9462 - Val loss: 0.3051 - Val F1: 0.9458 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.0074 - Val accuracy: 0.9538 - Val loss: 0.4714 - Val F1: 0.9535 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.0043 - Val accuracy: 0.9462 - Val loss: 0.4223 - Val F1: 0.9458 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.0036 - Val accuracy: 0.9538 - Val loss: 0.4749 - Val F1: 0.9535 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0033 - Val accuracy: 0.9538 - Val loss: 0.4061 - Val F1: 0.9535 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0022 - Val accuracy: 0.9538 - Val loss: 0.4775 - Val F1: 0.9535 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0022 - Val accuracy: 0.9538 - Val loss: 0.5059 - Val F1: 0.9535 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0020 - Val accuracy: 0.9538 - Val loss: 0.4693 - Val F1: 0.9535 - LR: 0.00e+00\n","\tBest epoch: 30 - Best val accuracy: 0.9462 - Best val loss: 0.3051 - Best val F1: 0.9458\n","\n","\tEpoch 10/100 - Train loss: 0.1135 - Val accuracy: 0.9385 - Val loss: 0.2380 - Val F1: 0.9387 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.0378 - Val accuracy: 0.9385 - Val loss: 0.2041 - Val F1: 0.9383 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.0270 - Val accuracy: 0.9308 - Val loss: 0.2258 - Val F1: 0.9311 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.0115 - Val accuracy: 0.9308 - Val loss: 0.2226 - Val F1: 0.9310 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.0109 - Val accuracy: 0.9462 - Val loss: 0.1857 - Val F1: 0.9459 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.0051 - Val accuracy: 0.9308 - Val loss: 0.2268 - Val F1: 0.9310 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0032 - Val accuracy: 0.9385 - Val loss: 0.2409 - Val F1: 0.9387 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0061 - Val accuracy: 0.9462 - Val loss: 0.2113 - Val F1: 0.9459 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0024 - Val accuracy: 0.9308 - Val loss: 0.2253 - Val F1: 0.9310 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0037 - Val accuracy: 0.9385 - Val loss: 0.2279 - Val F1: 0.9381 - LR: 0.00e+00\n","\tBest epoch: 37 - Best val accuracy: 0.9462 - Best val loss: 0.1740 - Best val F1: 0.9462\n","\n","\tEpoch 10/100 - Train loss: 0.1654 - Val accuracy: 0.9231 - Val loss: 0.2335 - Val F1: 0.9236 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.0878 - Val accuracy: 0.9538 - Val loss: 0.1570 - Val F1: 0.9542 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.0304 - Val accuracy: 0.9385 - Val loss: 0.2320 - Val F1: 0.9391 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.0176 - Val accuracy: 0.9385 - Val loss: 0.2287 - Val F1: 0.9389 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.0107 - Val accuracy: 0.9385 - Val loss: 0.2398 - Val F1: 0.9389 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.0078 - Val accuracy: 0.9385 - Val loss: 0.2415 - Val F1: 0.9389 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0044 - Val accuracy: 0.9308 - Val loss: 0.2498 - Val F1: 0.9312 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0042 - Val accuracy: 0.9385 - Val loss: 0.2520 - Val F1: 0.9389 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0026 - Val accuracy: 0.9308 - Val loss: 0.2624 - Val F1: 0.9312 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0079 - Val accuracy: 0.9308 - Val loss: 0.3126 - Val F1: 0.9312 - LR: 0.00e+00\n","\tBest epoch: 20 - Best val accuracy: 0.9538 - Best val loss: 0.1570 - Best val F1: 0.9542\n","\n","\tEpoch 10/100 - Train loss: 0.1545 - Val accuracy: 0.9769 - Val loss: 0.3481 - Val F1: 0.9769 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.0611 - Val accuracy: 0.9769 - Val loss: 0.3629 - Val F1: 0.9769 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.0175 - Val accuracy: 0.9769 - Val loss: 0.3912 - Val F1: 0.9769 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.0074 - Val accuracy: 0.9769 - Val loss: 0.4238 - Val F1: 0.9769 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.0060 - Val accuracy: 0.9769 - Val loss: 0.3828 - Val F1: 0.9769 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.0041 - Val accuracy: 0.9769 - Val loss: 0.4134 - Val F1: 0.9769 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0029 - Val accuracy: 0.9769 - Val loss: 0.4184 - Val F1: 0.9769 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0037 - Val accuracy: 0.9769 - Val loss: 0.4482 - Val F1: 0.9769 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0018 - Val accuracy: 0.9769 - Val loss: 0.4237 - Val F1: 0.9769 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0023 - Val accuracy: 0.9769 - Val loss: 0.4337 - Val F1: 0.9769 - LR: 0.00e+00\n","\tBest epoch: 8 - Best val accuracy: 0.9769 - Best val loss: 0.3106 - Best val F1: 0.9769\n","\n","Source class: WAL | Domain: 72 | Accuracy: 0.9445 | Loss: 0.1848 | F1: 0.9449\n","\n","Domain: 73\n","x_dp_dom.shape: (815, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Training and evaluating on Dp data via cross-validation...\n","\tEpoch 10/100 - Train loss: 0.1347 - Val accuracy: 0.9313 - Val loss: 0.2042 - Val F1: 0.9321 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.0416 - Val accuracy: 0.9618 - Val loss: 0.1243 - Val F1: 0.9621 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.0180 - Val accuracy: 0.9618 - Val loss: 0.1289 - Val F1: 0.9622 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.0123 - Val accuracy: 0.9618 - Val loss: 0.0923 - Val F1: 0.9618 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.0072 - Val accuracy: 0.9695 - Val loss: 0.0898 - Val F1: 0.9695 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.0045 - Val accuracy: 0.9618 - Val loss: 0.1138 - Val F1: 0.9621 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0049 - Val accuracy: 0.9618 - Val loss: 0.1104 - Val F1: 0.9618 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0062 - Val accuracy: 0.9695 - Val loss: 0.0999 - Val F1: 0.9698 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0026 - Val accuracy: 0.9695 - Val loss: 0.0943 - Val F1: 0.9695 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0029 - Val accuracy: 0.9771 - Val loss: 0.0947 - Val F1: 0.9771 - LR: 0.00e+00\n","\tBest epoch: 79 - Best val accuracy: 0.9618 - Best val loss: 0.0853 - Best val F1: 0.9618\n","\n","\tEpoch 10/100 - Train loss: 0.1341 - Val accuracy: 0.9160 - Val loss: 0.2520 - Val F1: 0.9165 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.0289 - Val accuracy: 0.9313 - Val loss: 0.2188 - Val F1: 0.9316 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.0166 - Val accuracy: 0.9237 - Val loss: 0.2153 - Val F1: 0.9235 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.0083 - Val accuracy: 0.9313 - Val loss: 0.2209 - Val F1: 0.9316 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.0046 - Val accuracy: 0.9313 - Val loss: 0.2230 - Val F1: 0.9316 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.0032 - Val accuracy: 0.9313 - Val loss: 0.2320 - Val F1: 0.9316 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0024 - Val accuracy: 0.9313 - Val loss: 0.2251 - Val F1: 0.9316 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0014 - Val accuracy: 0.9313 - Val loss: 0.2429 - Val F1: 0.9316 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0025 - Val accuracy: 0.9313 - Val loss: 0.2348 - Val F1: 0.9316 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0027 - Val accuracy: 0.9313 - Val loss: 0.2354 - Val F1: 0.9316 - LR: 0.00e+00\n","\tBest epoch: 58 - Best val accuracy: 0.9313 - Best val loss: 0.2086 - Best val F1: 0.9316\n","\n","\tEpoch 10/100 - Train loss: 0.1119 - Val accuracy: 0.9466 - Val loss: 0.2102 - Val F1: 0.9471 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.0360 - Val accuracy: 0.9542 - Val loss: 0.1943 - Val F1: 0.9548 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.0146 - Val accuracy: 0.9542 - Val loss: 0.1919 - Val F1: 0.9548 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.0060 - Val accuracy: 0.9542 - Val loss: 0.1973 - Val F1: 0.9548 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.0082 - Val accuracy: 0.9542 - Val loss: 0.2033 - Val F1: 0.9548 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.0059 - Val accuracy: 0.9542 - Val loss: 0.2017 - Val F1: 0.9548 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0025 - Val accuracy: 0.9542 - Val loss: 0.1946 - Val F1: 0.9548 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0037 - Val accuracy: 0.9542 - Val loss: 0.2111 - Val F1: 0.9548 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0017 - Val accuracy: 0.9542 - Val loss: 0.2088 - Val F1: 0.9548 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0019 - Val accuracy: 0.9542 - Val loss: 0.1973 - Val F1: 0.9548 - LR: 0.00e+00\n","\tBest epoch: 76 - Best val accuracy: 0.9542 - Best val loss: 0.1790 - Best val F1: 0.9545\n","\n","\tEpoch 10/100 - Train loss: 0.1486 - Val accuracy: 0.9084 - Val loss: 0.2382 - Val F1: 0.9088 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.0346 - Val accuracy: 0.9313 - Val loss: 0.2077 - Val F1: 0.9314 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.0183 - Val accuracy: 0.9313 - Val loss: 0.2266 - Val F1: 0.9314 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.0068 - Val accuracy: 0.9313 - Val loss: 0.2211 - Val F1: 0.9314 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.0040 - Val accuracy: 0.9313 - Val loss: 0.2311 - Val F1: 0.9314 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.0049 - Val accuracy: 0.9313 - Val loss: 0.2287 - Val F1: 0.9314 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0019 - Val accuracy: 0.9313 - Val loss: 0.2344 - Val F1: 0.9314 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0025 - Val accuracy: 0.9313 - Val loss: 0.2426 - Val F1: 0.9314 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0020 - Val accuracy: 0.9313 - Val loss: 0.2408 - Val F1: 0.9314 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0029 - Val accuracy: 0.9313 - Val loss: 0.2398 - Val F1: 0.9314 - LR: 0.00e+00\n","\tBest epoch: 25 - Best val accuracy: 0.9313 - Best val loss: 0.1962 - Best val F1: 0.9314\n","\n","\tEpoch 10/100 - Train loss: 0.1282 - Val accuracy: 0.9313 - Val loss: 0.1983 - Val F1: 0.9302 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.0310 - Val accuracy: 0.9618 - Val loss: 0.1239 - Val F1: 0.9613 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.0143 - Val accuracy: 0.9618 - Val loss: 0.1004 - Val F1: 0.9615 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.0185 - Val accuracy: 0.9695 - Val loss: 0.1029 - Val F1: 0.9694 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.0054 - Val accuracy: 0.9771 - Val loss: 0.0860 - Val F1: 0.9770 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.0042 - Val accuracy: 0.9771 - Val loss: 0.0895 - Val F1: 0.9770 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0020 - Val accuracy: 0.9695 - Val loss: 0.0965 - Val F1: 0.9692 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0028 - Val accuracy: 0.9695 - Val loss: 0.1070 - Val F1: 0.9692 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0027 - Val accuracy: 0.9695 - Val loss: 0.0928 - Val F1: 0.9692 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0019 - Val accuracy: 0.9695 - Val loss: 0.0926 - Val F1: 0.9692 - LR: 0.00e+00\n","\tBest epoch: 93 - Best val accuracy: 0.9771 - Best val loss: 0.0845 - Best val F1: 0.9770\n","\n","Source class: WAL | Domain: 73 | Accuracy: 0.9521 | Loss: 0.1428 | F1: 0.9521\n","\n","Domain: 74\n","Domain: 75\n","x_dp_dom.shape: (823, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Training and evaluating on Dp data via cross-validation...\n","\tEpoch 10/100 - Train loss: 0.1051 - Val accuracy: 0.9621 - Val loss: 0.1295 - Val F1: 0.9617 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.0229 - Val accuracy: 0.9545 - Val loss: 0.1121 - Val F1: 0.9538 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.0171 - Val accuracy: 0.9545 - Val loss: 0.0860 - Val F1: 0.9538 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.0089 - Val accuracy: 0.9545 - Val loss: 0.1185 - Val F1: 0.9538 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.0046 - Val accuracy: 0.9545 - Val loss: 0.1132 - Val F1: 0.9538 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.0034 - Val accuracy: 0.9545 - Val loss: 0.1188 - Val F1: 0.9538 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0034 - Val accuracy: 0.9545 - Val loss: 0.1072 - Val F1: 0.9538 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0018 - Val accuracy: 0.9545 - Val loss: 0.0952 - Val F1: 0.9538 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0027 - Val accuracy: 0.9545 - Val loss: 0.1116 - Val F1: 0.9538 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0035 - Val accuracy: 0.9545 - Val loss: 0.1028 - Val F1: 0.9538 - LR: 0.00e+00\n","\tBest epoch: 57 - Best val accuracy: 0.9773 - Best val loss: 0.0610 - Best val F1: 0.9771\n","\n","\tEpoch 10/100 - Train loss: 0.1198 - Val accuracy: 0.9470 - Val loss: 0.1518 - Val F1: 0.9473 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.0269 - Val accuracy: 0.9470 - Val loss: 0.1338 - Val F1: 0.9473 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.0111 - Val accuracy: 0.9545 - Val loss: 0.1333 - Val F1: 0.9549 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.0173 - Val accuracy: 0.9621 - Val loss: 0.1153 - Val F1: 0.9622 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.0047 - Val accuracy: 0.9621 - Val loss: 0.1325 - Val F1: 0.9622 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.0069 - Val accuracy: 0.9621 - Val loss: 0.1469 - Val F1: 0.9622 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0030 - Val accuracy: 0.9697 - Val loss: 0.1330 - Val F1: 0.9696 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0025 - Val accuracy: 0.9621 - Val loss: 0.1437 - Val F1: 0.9622 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0052 - Val accuracy: 0.9621 - Val loss: 0.1424 - Val F1: 0.9622 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0017 - Val accuracy: 0.9621 - Val loss: 0.1518 - Val F1: 0.9622 - LR: 0.00e+00\n","\tBest epoch: 28 - Best val accuracy: 0.9697 - Best val loss: 0.1081 - Best val F1: 0.9696\n","\n","\tEpoch 10/100 - Train loss: 0.1254 - Val accuracy: 0.9394 - Val loss: 0.1448 - Val F1: 0.9396 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.0338 - Val accuracy: 0.9545 - Val loss: 0.1227 - Val F1: 0.9538 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.0120 - Val accuracy: 0.9621 - Val loss: 0.1152 - Val F1: 0.9617 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.0080 - Val accuracy: 0.9470 - Val loss: 0.1482 - Val F1: 0.9459 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.0082 - Val accuracy: 0.9621 - Val loss: 0.1024 - Val F1: 0.9619 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.0032 - Val accuracy: 0.9621 - Val loss: 0.1334 - Val F1: 0.9617 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0052 - Val accuracy: 0.9470 - Val loss: 0.1871 - Val F1: 0.9459 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0025 - Val accuracy: 0.9621 - Val loss: 0.1462 - Val F1: 0.9617 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0019 - Val accuracy: 0.9621 - Val loss: 0.1281 - Val F1: 0.9617 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0022 - Val accuracy: 0.9621 - Val loss: 0.1522 - Val F1: 0.9617 - LR: 0.00e+00\n","\tBest epoch: 31 - Best val accuracy: 0.9697 - Best val loss: 0.0935 - Best val F1: 0.9694\n","\n","\tEpoch 10/100 - Train loss: 0.0806 - Val accuracy: 0.9470 - Val loss: 0.1805 - Val F1: 0.9470 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.0294 - Val accuracy: 0.9545 - Val loss: 0.1617 - Val F1: 0.9534 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.0108 - Val accuracy: 0.9545 - Val loss: 0.1714 - Val F1: 0.9534 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.0053 - Val accuracy: 0.9470 - Val loss: 0.1755 - Val F1: 0.9454 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.0060 - Val accuracy: 0.9621 - Val loss: 0.1663 - Val F1: 0.9613 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.0058 - Val accuracy: 0.9621 - Val loss: 0.1678 - Val F1: 0.9613 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0026 - Val accuracy: 0.9545 - Val loss: 0.1846 - Val F1: 0.9534 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0024 - Val accuracy: 0.9545 - Val loss: 0.1943 - Val F1: 0.9534 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0026 - Val accuracy: 0.9545 - Val loss: 0.1860 - Val F1: 0.9534 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0015 - Val accuracy: 0.9545 - Val loss: 0.1826 - Val F1: 0.9534 - LR: 0.00e+00\n","\tBest epoch: 32 - Best val accuracy: 0.9621 - Best val loss: 0.1505 - Best val F1: 0.9613\n","\n","\tEpoch 10/100 - Train loss: 0.1081 - Val accuracy: 0.9242 - Val loss: 0.1864 - Val F1: 0.9242 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.0377 - Val accuracy: 0.9318 - Val loss: 0.1584 - Val F1: 0.9319 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.0154 - Val accuracy: 0.9318 - Val loss: 0.1704 - Val F1: 0.9319 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.0117 - Val accuracy: 0.9318 - Val loss: 0.1753 - Val F1: 0.9319 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.0080 - Val accuracy: 0.9318 - Val loss: 0.2026 - Val F1: 0.9319 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.0069 - Val accuracy: 0.9318 - Val loss: 0.2018 - Val F1: 0.9319 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0022 - Val accuracy: 0.9394 - Val loss: 0.1791 - Val F1: 0.9392 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0024 - Val accuracy: 0.9394 - Val loss: 0.1905 - Val F1: 0.9392 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0029 - Val accuracy: 0.9318 - Val loss: 0.2036 - Val F1: 0.9319 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0023 - Val accuracy: 0.9394 - Val loss: 0.1836 - Val F1: 0.9392 - LR: 0.00e+00\n","\tBest epoch: 14 - Best val accuracy: 0.9470 - Best val loss: 0.1468 - Best val F1: 0.9469\n","\n","Source class: WAL | Domain: 75 | Accuracy: 0.9672 | Loss: 0.1029 | F1: 0.9671\n","\n","Mean accuracy: 0.9709 +- 0.0157\n","Mean F1: 0.9709 +- 0.0156\n","\n"]}],"source":["def compute_TSTR_Dp(dataset):\n","    accs = []\n","    f1s = []\n","\n","    for src_class in config[dataset]['class_names']:\n","        if src_class != 'WAL':\n","            continue\n","\n","        print(f\"Source class: {src_class}\\n\")\n","\n","        for domain in range(config[dataset]['num_df_domains'], config[dataset]['num_df_domains'] + config[dataset]['num_dp_domains']):\n","            print(f\"Domain: {domain}\")\n","\n","            if domain == 74:\n","              continue\n","\n","            # Load Dp data\n","            x_dp_dom, y_dp_dom, k_dp_dom = get_data(dataset, 'dp', src_class, domain)\n","            print(f'x_dp_dom.shape: {x_dp_dom.shape} | np.unique(y_dp_dom): {np.unique(y_dp_dom)}\\n')\n","\n","            # Train and evaluate via cross-validation on Dp data\n","            print('Training and evaluating on Dp data via cross-validation...')\n","            acc, loss, f1 = train_classifier_cv(x_dp_dom, y_dp_dom, dataset, num_epochs=num_epochs)\n","            save_scores(src_class, domain, acc, loss, f1, 'Dp', dataset)\n","            accs.append(acc)\n","            f1s.append(f1)\n","            print(f'Source class: {src_class} | Domain: {domain} | Accuracy: {acc:.4f} | Loss: {loss:.4f} | F1: {f1:.4f}\\n')\n","\n","    print(f\"Mean accuracy: {np.mean(accs):.4f} +- {np.std(accs):.4f}\")\n","    print(f\"Mean F1: {np.mean(f1s):.4f} +- {np.std(f1s):.4f}\\n\")\n","\n","\n","\n","compute_TSTR_Dp('mobiact_realworld')"]},{"cell_type":"code","execution_count":6,"metadata":{"executionInfo":{"elapsed":5,"status":"ok","timestamp":1732701416976,"user":{"displayName":"Pietro Castelvetri","userId":"04218697278633758016"},"user_tz":-60},"id":"M7S9IU2VVAmx"},"outputs":[],"source":["def compute_TSTR_Dpc(dataset):\n","\n","    raise NotImplementedError\n","\n","\n","\n","# compute_TSTR_Dpc('mobiact_realworld')"]},{"cell_type":"code","execution_count":7,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":959343,"status":"ok","timestamp":1732702376314,"user":{"displayName":"Pietro Castelvetri","userId":"04218697278633758016"},"user_tz":-60},"id":"zhTuwDtYCPto","outputId":"977ab2fe-a8fe-4d8b-da30-ab9d1168314c"},"outputs":[{"output_type":"stream","name":"stdout","text":["Source class: WAL\n","\n","x_df.shape: (10816, 3, 128) | np.unique(y_df): [0 1 2 3]\n","\n","Training on Df data...\n","\tEpoch 10/100 - Train loss: 0.0282 - Val accuracy: 0.9917 - Val loss: 0.0242 - Val F1: 0.9916 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.0053 - Val accuracy: 0.9945 - Val loss: 0.0137 - Val F1: 0.9944 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.0039 - Val accuracy: 0.9958 - Val loss: 0.0113 - Val F1: 0.9958 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.0010 - Val accuracy: 0.9968 - Val loss: 0.0085 - Val F1: 0.9968 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.0022 - Val accuracy: 0.9958 - Val loss: 0.0114 - Val F1: 0.9958 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.0006 - Val accuracy: 0.9977 - Val loss: 0.0069 - Val F1: 0.9977 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0004 - Val accuracy: 0.9972 - Val loss: 0.0091 - Val F1: 0.9972 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0005 - Val accuracy: 0.9977 - Val loss: 0.0089 - Val F1: 0.9977 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0002 - Val accuracy: 0.9968 - Val loss: 0.0098 - Val F1: 0.9968 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0004 - Val accuracy: 0.9954 - Val loss: 0.0112 - Val F1: 0.9954 - LR: 0.00e+00\n","\tBest epoch: 60 - Best val accuracy: 0.9977 - Best val loss: 0.0069 - Best val F1: 0.9977\n","\n","Domain: 61\n","x_dp_dom.shape: (855, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 61 | Accuracy: 0.4304 | Loss: 3.1088 | F1: 0.3287\n","\n","Domain: 62\n","x_dp_dom.shape: (780, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 62 | Accuracy: 0.4872 | Loss: 4.2839 | F1: 0.3953\n","\n","Domain: 63\n","x_dp_dom.shape: (859, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 63 | Accuracy: 0.3341 | Loss: 4.3019 | F1: 0.2211\n","\n","Domain: 64\n","x_dp_dom.shape: (481, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 64 | Accuracy: 0.6923 | Loss: 2.4218 | F1: 0.6076\n","\n","Domain: 65\n","x_dp_dom.shape: (840, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 65 | Accuracy: 0.4321 | Loss: 3.2109 | F1: 0.3413\n","\n","Domain: 66\n","x_dp_dom.shape: (792, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 66 | Accuracy: 0.3763 | Loss: 3.3230 | F1: 0.2975\n","\n","Domain: 67\n","x_dp_dom.shape: (572, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 67 | Accuracy: 0.5052 | Loss: 2.1792 | F1: 0.4259\n","\n","Domain: 68\n","x_dp_dom.shape: (877, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 68 | Accuracy: 0.3615 | Loss: 1.9636 | F1: 0.3367\n","\n","Domain: 69\n","x_dp_dom.shape: (799, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 69 | Accuracy: 0.6308 | Loss: 2.3707 | F1: 0.5603\n","\n","Domain: 70\n","x_dp_dom.shape: (762, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 70 | Accuracy: 0.6076 | Loss: 3.3079 | F1: 0.4990\n","\n","Domain: 71\n","x_dp_dom.shape: (854, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 71 | Accuracy: 0.4614 | Loss: 2.7257 | F1: 0.3565\n","\n","Domain: 72\n","x_dp_dom.shape: (811, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 72 | Accuracy: 0.4464 | Loss: 3.1995 | F1: 0.3493\n","\n","Domain: 73\n","x_dp_dom.shape: (815, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 73 | Accuracy: 0.4920 | Loss: 2.6218 | F1: 0.4029\n","\n","Domain: 74\n","x_dp_dom.shape: (563, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 74 | Accuracy: 0.8508 | Loss: 2.0099 | F1: 0.8122\n","\n","Domain: 75\n","x_dp_dom.shape: (823, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 75 | Accuracy: 0.4678 | Loss: 2.3629 | F1: 0.4249\n","\n","Mean accuracy for run 0: 0.5051\n","Mean F1 for run 0: 0.4239\n","\n","Source class: WAL\n","\n","x_df.shape: (10816, 3, 128) | np.unique(y_df): [0 1 2 3]\n","\n","Training on Df data...\n","\tEpoch 10/100 - Train loss: 0.0261 - Val accuracy: 0.9898 - Val loss: 0.0286 - Val F1: 0.9897 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.0061 - Val accuracy: 0.9949 - Val loss: 0.0125 - Val F1: 0.9949 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.0028 - Val accuracy: 0.9954 - Val loss: 0.0136 - Val F1: 0.9954 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.0010 - Val accuracy: 0.9954 - Val loss: 0.0132 - Val F1: 0.9954 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.0008 - Val accuracy: 0.9968 - Val loss: 0.0091 - Val F1: 0.9968 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.0004 - Val accuracy: 0.9949 - Val loss: 0.0130 - Val F1: 0.9949 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0003 - Val accuracy: 0.9954 - Val loss: 0.0135 - Val F1: 0.9954 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0002 - Val accuracy: 0.9954 - Val loss: 0.0172 - Val F1: 0.9954 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0004 - Val accuracy: 0.9963 - Val loss: 0.0108 - Val F1: 0.9963 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0002 - Val accuracy: 0.9968 - Val loss: 0.0090 - Val F1: 0.9968 - LR: 0.00e+00\n","\tBest epoch: 65 - Best val accuracy: 0.9963 - Best val loss: 0.0084 - Best val F1: 0.9963\n","\n","Domain: 61\n","x_dp_dom.shape: (855, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 61 | Accuracy: 0.5251 | Loss: 3.1390 | F1: 0.4681\n","\n","Domain: 62\n","x_dp_dom.shape: (780, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 62 | Accuracy: 0.4269 | Loss: 4.5823 | F1: 0.3301\n","\n","Domain: 63\n","x_dp_dom.shape: (859, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 63 | Accuracy: 0.4435 | Loss: 3.7895 | F1: 0.3547\n","\n","Domain: 64\n","x_dp_dom.shape: (481, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 64 | Accuracy: 0.6403 | Loss: 1.9277 | F1: 0.5723\n","\n","Domain: 65\n","x_dp_dom.shape: (840, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 65 | Accuracy: 0.5179 | Loss: 2.8134 | F1: 0.4549\n","\n","Domain: 66\n","x_dp_dom.shape: (792, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 66 | Accuracy: 0.3220 | Loss: 5.2181 | F1: 0.2117\n","\n","Domain: 67\n","x_dp_dom.shape: (572, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 67 | Accuracy: 0.4633 | Loss: 3.5833 | F1: 0.3406\n","\n","Domain: 68\n","x_dp_dom.shape: (877, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 68 | Accuracy: 0.4116 | Loss: 3.4688 | F1: 0.3943\n","\n","Domain: 69\n","x_dp_dom.shape: (799, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 69 | Accuracy: 0.7372 | Loss: 1.3031 | F1: 0.7049\n","\n","Domain: 70\n","x_dp_dom.shape: (762, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 70 | Accuracy: 0.7073 | Loss: 2.9054 | F1: 0.6434\n","\n","Domain: 71\n","x_dp_dom.shape: (854, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 71 | Accuracy: 0.4836 | Loss: 4.0696 | F1: 0.3981\n","\n","Domain: 72\n","x_dp_dom.shape: (811, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 72 | Accuracy: 0.4698 | Loss: 4.4419 | F1: 0.3667\n","\n","Domain: 73\n","x_dp_dom.shape: (815, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 73 | Accuracy: 0.4233 | Loss: 3.5932 | F1: 0.3230\n","\n","Domain: 74\n","x_dp_dom.shape: (563, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 74 | Accuracy: 0.6092 | Loss: 3.2873 | F1: 0.5471\n","\n","Domain: 75\n","x_dp_dom.shape: (823, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 75 | Accuracy: 0.4569 | Loss: 3.6552 | F1: 0.3756\n","\n","Mean accuracy for run 1: 0.5092\n","Mean F1 for run 1: 0.4324\n","\n","Source class: WAL\n","\n","x_df.shape: (10816, 3, 128) | np.unique(y_df): [0 1 2 3]\n","\n","Training on Df data...\n","\tEpoch 10/100 - Train loss: 0.0261 - Val accuracy: 0.9935 - Val loss: 0.0224 - Val F1: 0.9935 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.0056 - Val accuracy: 0.9977 - Val loss: 0.0110 - Val F1: 0.9977 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.0061 - Val accuracy: 0.9977 - Val loss: 0.0081 - Val F1: 0.9977 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.0015 - Val accuracy: 0.9977 - Val loss: 0.0078 - Val F1: 0.9977 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.0013 - Val accuracy: 0.9982 - Val loss: 0.0064 - Val F1: 0.9981 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.0003 - Val accuracy: 0.9972 - Val loss: 0.0067 - Val F1: 0.9972 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0007 - Val accuracy: 0.9977 - Val loss: 0.0083 - Val F1: 0.9977 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0009 - Val accuracy: 0.9968 - Val loss: 0.0113 - Val F1: 0.9968 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0002 - Val accuracy: 0.9972 - Val loss: 0.0095 - Val F1: 0.9972 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0002 - Val accuracy: 0.9977 - Val loss: 0.0077 - Val F1: 0.9977 - LR: 0.00e+00\n","\tBest epoch: 32 - Best val accuracy: 0.9991 - Best val loss: 0.0062 - Best val F1: 0.9991\n","\n","Domain: 61\n","x_dp_dom.shape: (855, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 61 | Accuracy: 0.5626 | Loss: 2.5979 | F1: 0.5034\n","\n","Domain: 62\n","x_dp_dom.shape: (780, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 62 | Accuracy: 0.7090 | Loss: 1.4016 | F1: 0.6563\n","\n","Domain: 63\n","x_dp_dom.shape: (859, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 63 | Accuracy: 0.2549 | Loss: 4.4973 | F1: 0.1811\n","\n","Domain: 64\n","x_dp_dom.shape: (481, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 64 | Accuracy: 0.4761 | Loss: 2.0537 | F1: 0.4626\n","\n","Domain: 65\n","x_dp_dom.shape: (840, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 65 | Accuracy: 0.4155 | Loss: 2.1950 | F1: 0.3638\n","\n","Domain: 66\n","x_dp_dom.shape: (792, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 66 | Accuracy: 0.4040 | Loss: 3.1323 | F1: 0.3946\n","\n","Domain: 67\n","x_dp_dom.shape: (572, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 67 | Accuracy: 0.4283 | Loss: 3.1186 | F1: 0.3632\n","\n","Domain: 68\n","x_dp_dom.shape: (877, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 68 | Accuracy: 0.5120 | Loss: 2.4044 | F1: 0.4262\n","\n","Domain: 69\n","x_dp_dom.shape: (799, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 69 | Accuracy: 0.5169 | Loss: 2.0069 | F1: 0.4190\n","\n","Domain: 70\n","x_dp_dom.shape: (762, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 70 | Accuracy: 0.4265 | Loss: 2.7078 | F1: 0.3922\n","\n","Domain: 71\n","x_dp_dom.shape: (854, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 71 | Accuracy: 0.3560 | Loss: 2.9186 | F1: 0.2987\n","\n","Domain: 72\n","x_dp_dom.shape: (811, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 72 | Accuracy: 0.2972 | Loss: 3.2445 | F1: 0.2262\n","\n","Domain: 73\n","x_dp_dom.shape: (815, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 73 | Accuracy: 0.3215 | Loss: 3.2003 | F1: 0.2460\n","\n","Domain: 74\n","x_dp_dom.shape: (563, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 74 | Accuracy: 0.5861 | Loss: 2.4272 | F1: 0.5293\n","\n","Domain: 75\n","x_dp_dom.shape: (823, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 75 | Accuracy: 0.5006 | Loss: 2.4190 | F1: 0.4010\n","\n","Mean accuracy for run 2: 0.4511\n","Mean F1 for run 2: 0.3909\n","\n","Source class: WAL\n","\n","x_df.shape: (10816, 3, 128) | np.unique(y_df): [0 1 2 3]\n","\n","Training on Df data...\n","\tEpoch 10/100 - Train loss: 0.0218 - Val accuracy: 0.9908 - Val loss: 0.0300 - Val F1: 0.9907 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.0050 - Val accuracy: 0.9972 - Val loss: 0.0104 - Val F1: 0.9972 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.0062 - Val accuracy: 0.9940 - Val loss: 0.0197 - Val F1: 0.9939 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.0009 - Val accuracy: 0.9963 - Val loss: 0.0113 - Val F1: 0.9963 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.0006 - Val accuracy: 0.9963 - Val loss: 0.0079 - Val F1: 0.9963 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.0010 - Val accuracy: 0.9954 - Val loss: 0.0130 - Val F1: 0.9953 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0004 - Val accuracy: 0.9972 - Val loss: 0.0085 - Val F1: 0.9972 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0005 - Val accuracy: 0.9968 - Val loss: 0.0084 - Val F1: 0.9967 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0002 - Val accuracy: 0.9972 - Val loss: 0.0084 - Val F1: 0.9972 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0002 - Val accuracy: 0.9972 - Val loss: 0.0080 - Val F1: 0.9972 - LR: 0.00e+00\n","\tBest epoch: 84 - Best val accuracy: 0.9968 - Best val loss: 0.0068 - Best val F1: 0.9968\n","\n","Domain: 61\n","x_dp_dom.shape: (855, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 61 | Accuracy: 0.3509 | Loss: 4.0590 | F1: 0.3780\n","\n","Domain: 62\n","x_dp_dom.shape: (780, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 62 | Accuracy: 0.5538 | Loss: 3.8978 | F1: 0.5048\n","\n","Domain: 63\n","x_dp_dom.shape: (859, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 63 | Accuracy: 0.2969 | Loss: 4.7283 | F1: 0.2101\n","\n","Domain: 64\n","x_dp_dom.shape: (481, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 64 | Accuracy: 0.6819 | Loss: 2.2489 | F1: 0.6495\n","\n","Domain: 65\n","x_dp_dom.shape: (840, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 65 | Accuracy: 0.4452 | Loss: 3.7454 | F1: 0.3860\n","\n","Domain: 66\n","x_dp_dom.shape: (792, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 66 | Accuracy: 0.2096 | Loss: 5.1844 | F1: 0.2724\n","\n","Domain: 67\n","x_dp_dom.shape: (572, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 67 | Accuracy: 0.4598 | Loss: 3.9467 | F1: 0.3290\n","\n","Domain: 68\n","x_dp_dom.shape: (877, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 68 | Accuracy: 0.7252 | Loss: 1.2187 | F1: 0.7302\n","\n","Domain: 69\n","x_dp_dom.shape: (799, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 69 | Accuracy: 0.6796 | Loss: 1.7056 | F1: 0.6554\n","\n","Domain: 70\n","x_dp_dom.shape: (762, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 70 | Accuracy: 0.6076 | Loss: 3.1204 | F1: 0.5635\n","\n","Domain: 71\n","x_dp_dom.shape: (854, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 71 | Accuracy: 0.5480 | Loss: 1.5280 | F1: 0.5395\n","\n","Domain: 72\n","x_dp_dom.shape: (811, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 72 | Accuracy: 0.4192 | Loss: 3.6691 | F1: 0.3518\n","\n","Domain: 73\n","x_dp_dom.shape: (815, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 73 | Accuracy: 0.4883 | Loss: 2.3786 | F1: 0.4603\n","\n","Domain: 74\n","x_dp_dom.shape: (563, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 74 | Accuracy: 0.5080 | Loss: 4.9219 | F1: 0.4037\n","\n","Domain: 75\n","x_dp_dom.shape: (823, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 75 | Accuracy: 0.5650 | Loss: 2.0865 | F1: 0.5424\n","\n","Mean accuracy for run 3: 0.5026\n","Mean F1 for run 3: 0.4651\n","\n","Source class: WAL\n","\n","x_df.shape: (10816, 3, 128) | np.unique(y_df): [0 1 2 3]\n","\n","Training on Df data...\n","\tEpoch 10/100 - Train loss: 0.0249 - Val accuracy: 0.9871 - Val loss: 0.0335 - Val F1: 0.9871 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.0055 - Val accuracy: 0.9926 - Val loss: 0.0167 - Val F1: 0.9925 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.0046 - Val accuracy: 0.9935 - Val loss: 0.0173 - Val F1: 0.9935 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.0014 - Val accuracy: 0.9945 - Val loss: 0.0140 - Val F1: 0.9944 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.0008 - Val accuracy: 0.9954 - Val loss: 0.0140 - Val F1: 0.9953 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.0006 - Val accuracy: 0.9949 - Val loss: 0.0153 - Val F1: 0.9949 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0008 - Val accuracy: 0.9954 - Val loss: 0.0136 - Val F1: 0.9954 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0003 - Val accuracy: 0.9963 - Val loss: 0.0121 - Val F1: 0.9963 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0002 - Val accuracy: 0.9968 - Val loss: 0.0124 - Val F1: 0.9968 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0004 - Val accuracy: 0.9963 - Val loss: 0.0139 - Val F1: 0.9963 - LR: 0.00e+00\n","\tBest epoch: 56 - Best val accuracy: 0.9963 - Best val loss: 0.0106 - Best val F1: 0.9963\n","\n","Domain: 61\n","x_dp_dom.shape: (855, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 61 | Accuracy: 0.4023 | Loss: 2.9098 | F1: 0.3141\n","\n","Domain: 62\n","x_dp_dom.shape: (780, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 62 | Accuracy: 0.6987 | Loss: 1.9624 | F1: 0.6633\n","\n","Domain: 63\n","x_dp_dom.shape: (859, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 63 | Accuracy: 0.5157 | Loss: 2.1350 | F1: 0.4526\n","\n","Domain: 64\n","x_dp_dom.shape: (481, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 64 | Accuracy: 0.6944 | Loss: 1.4249 | F1: 0.6869\n","\n","Domain: 65\n","x_dp_dom.shape: (840, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 65 | Accuracy: 0.6488 | Loss: 1.0575 | F1: 0.6533\n","\n","Domain: 66\n","x_dp_dom.shape: (792, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 66 | Accuracy: 0.4141 | Loss: 3.1517 | F1: 0.4543\n","\n","Domain: 67\n","x_dp_dom.shape: (572, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 67 | Accuracy: 0.5682 | Loss: 1.1088 | F1: 0.5932\n","\n","Domain: 68\n","x_dp_dom.shape: (877, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 68 | Accuracy: 0.7127 | Loss: 1.0536 | F1: 0.6878\n","\n","Domain: 69\n","x_dp_dom.shape: (799, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 69 | Accuracy: 0.5232 | Loss: 1.6448 | F1: 0.5209\n","\n","Domain: 70\n","x_dp_dom.shape: (762, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 70 | Accuracy: 0.5105 | Loss: 2.3040 | F1: 0.5214\n","\n","Domain: 71\n","x_dp_dom.shape: (854, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 71 | Accuracy: 0.5773 | Loss: 1.2503 | F1: 0.5885\n","\n","Domain: 72\n","x_dp_dom.shape: (811, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 72 | Accuracy: 0.3958 | Loss: 2.1484 | F1: 0.3804\n","\n","Domain: 73\n","x_dp_dom.shape: (815, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 73 | Accuracy: 0.5730 | Loss: 1.3721 | F1: 0.5825\n","\n","Domain: 74\n","x_dp_dom.shape: (563, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 74 | Accuracy: 0.7460 | Loss: 1.2412 | F1: 0.7285\n","\n","Domain: 75\n","x_dp_dom.shape: (823, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 75 | Accuracy: 0.5115 | Loss: 1.5496 | F1: 0.5019\n","\n","Mean accuracy for run 4: 0.5661\n","Mean F1 for run 4: 0.5553\n","\n","Source class: WAL\n","\n","x_df.shape: (10816, 3, 128) | np.unique(y_df): [0 1 2 3]\n","\n","Training on Df data...\n","\tEpoch 10/100 - Train loss: 0.0333 - Val accuracy: 0.9880 - Val loss: 0.0340 - Val F1: 0.9880 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.0087 - Val accuracy: 0.9940 - Val loss: 0.0161 - Val F1: 0.9940 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.0038 - Val accuracy: 0.9963 - Val loss: 0.0137 - Val F1: 0.9963 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.0024 - Val accuracy: 0.9958 - Val loss: 0.0139 - Val F1: 0.9958 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.0009 - Val accuracy: 0.9968 - Val loss: 0.0130 - Val F1: 0.9968 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.0007 - Val accuracy: 0.9963 - Val loss: 0.0137 - Val F1: 0.9963 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0008 - Val accuracy: 0.9958 - Val loss: 0.0131 - Val F1: 0.9958 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0007 - Val accuracy: 0.9949 - Val loss: 0.0127 - Val F1: 0.9949 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0004 - Val accuracy: 0.9963 - Val loss: 0.0113 - Val F1: 0.9963 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0003 - Val accuracy: 0.9958 - Val loss: 0.0128 - Val F1: 0.9958 - LR: 0.00e+00\n","\tBest epoch: 69 - Best val accuracy: 0.9958 - Best val loss: 0.0105 - Best val F1: 0.9958\n","\n","Domain: 61\n","x_dp_dom.shape: (855, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 61 | Accuracy: 0.3556 | Loss: 5.8310 | F1: 0.2534\n","\n","Domain: 62\n","x_dp_dom.shape: (780, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 62 | Accuracy: 0.5731 | Loss: 4.8688 | F1: 0.4640\n","\n","Domain: 63\n","x_dp_dom.shape: (859, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 63 | Accuracy: 0.2957 | Loss: 7.8173 | F1: 0.1422\n","\n","Domain: 64\n","x_dp_dom.shape: (481, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 64 | Accuracy: 0.6570 | Loss: 3.5991 | F1: 0.5782\n","\n","Domain: 65\n","x_dp_dom.shape: (840, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 65 | Accuracy: 0.3357 | Loss: 6.9054 | F1: 0.2059\n","\n","Domain: 66\n","x_dp_dom.shape: (792, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 66 | Accuracy: 0.2942 | Loss: 7.6667 | F1: 0.1444\n","\n","Domain: 67\n","x_dp_dom.shape: (572, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 67 | Accuracy: 0.3969 | Loss: 7.9607 | F1: 0.2331\n","\n","Domain: 68\n","x_dp_dom.shape: (877, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 68 | Accuracy: 0.5245 | Loss: 2.6072 | F1: 0.5141\n","\n","Domain: 69\n","x_dp_dom.shape: (799, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 69 | Accuracy: 0.5569 | Loss: 3.4805 | F1: 0.4620\n","\n","Domain: 70\n","x_dp_dom.shape: (762, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 70 | Accuracy: 0.5236 | Loss: 5.4035 | F1: 0.4296\n","\n","Domain: 71\n","x_dp_dom.shape: (854, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 71 | Accuracy: 0.3653 | Loss: 5.7824 | F1: 0.2638\n","\n","Domain: 72\n","x_dp_dom.shape: (811, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 72 | Accuracy: 0.3046 | Loss: 6.1089 | F1: 0.1682\n","\n","Domain: 73\n","x_dp_dom.shape: (815, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 73 | Accuracy: 0.3509 | Loss: 5.2500 | F1: 0.2450\n","\n","Domain: 74\n","x_dp_dom.shape: (563, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 74 | Accuracy: 0.4813 | Loss: 5.9619 | F1: 0.3578\n","\n","Domain: 75\n","x_dp_dom.shape: (823, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 75 | Accuracy: 0.3584 | Loss: 4.7558 | F1: 0.2670\n","\n","Mean accuracy for run 5: 0.4249\n","Mean F1 for run 5: 0.3152\n","\n","Source class: WAL\n","\n","x_df.shape: (10816, 3, 128) | np.unique(y_df): [0 1 2 3]\n","\n","Training on Df data...\n","\tEpoch 10/100 - Train loss: 0.0204 - Val accuracy: 0.9931 - Val loss: 0.0251 - Val F1: 0.9930 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.0058 - Val accuracy: 0.9935 - Val loss: 0.0179 - Val F1: 0.9935 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.0014 - Val accuracy: 0.9949 - Val loss: 0.0137 - Val F1: 0.9949 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.0012 - Val accuracy: 0.9968 - Val loss: 0.0134 - Val F1: 0.9968 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.0006 - Val accuracy: 0.9958 - Val loss: 0.0121 - Val F1: 0.9958 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.0003 - Val accuracy: 0.9958 - Val loss: 0.0137 - Val F1: 0.9958 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0009 - Val accuracy: 0.9949 - Val loss: 0.0161 - Val F1: 0.9949 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0016 - Val accuracy: 0.9963 - Val loss: 0.0117 - Val F1: 0.9963 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0002 - Val accuracy: 0.9954 - Val loss: 0.0138 - Val F1: 0.9954 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0002 - Val accuracy: 0.9958 - Val loss: 0.0127 - Val F1: 0.9958 - LR: 0.00e+00\n","\tBest epoch: 64 - Best val accuracy: 0.9968 - Best val loss: 0.0111 - Best val F1: 0.9968\n","\n","Domain: 61\n","x_dp_dom.shape: (855, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 61 | Accuracy: 0.3111 | Loss: 4.6126 | F1: 0.3049\n","\n","Domain: 62\n","x_dp_dom.shape: (780, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 62 | Accuracy: 0.5974 | Loss: 2.7670 | F1: 0.5119\n","\n","Domain: 63\n","x_dp_dom.shape: (859, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 63 | Accuracy: 0.3364 | Loss: 2.8349 | F1: 0.2844\n","\n","Domain: 64\n","x_dp_dom.shape: (481, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 64 | Accuracy: 0.7318 | Loss: 1.2186 | F1: 0.6990\n","\n","Domain: 65\n","x_dp_dom.shape: (840, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 65 | Accuracy: 0.4393 | Loss: 2.2504 | F1: 0.4086\n","\n","Domain: 66\n","x_dp_dom.shape: (792, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 66 | Accuracy: 0.2828 | Loss: 4.4408 | F1: 0.3422\n","\n","Domain: 67\n","x_dp_dom.shape: (572, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 67 | Accuracy: 0.3811 | Loss: 3.4122 | F1: 0.2550\n","\n","Domain: 68\n","x_dp_dom.shape: (877, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 68 | Accuracy: 0.7286 | Loss: 2.0545 | F1: 0.6779\n","\n","Domain: 69\n","x_dp_dom.shape: (799, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 69 | Accuracy: 0.5970 | Loss: 1.7949 | F1: 0.5484\n","\n","Domain: 70\n","x_dp_dom.shape: (762, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 70 | Accuracy: 0.4291 | Loss: 3.7173 | F1: 0.4001\n","\n","Domain: 71\n","x_dp_dom.shape: (854, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 71 | Accuracy: 0.4953 | Loss: 1.7744 | F1: 0.5021\n","\n","Domain: 72\n","x_dp_dom.shape: (811, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 72 | Accuracy: 0.2799 | Loss: 4.3611 | F1: 0.1765\n","\n","Domain: 73\n","x_dp_dom.shape: (815, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 73 | Accuracy: 0.3706 | Loss: 3.5290 | F1: 0.2687\n","\n","Domain: 74\n","x_dp_dom.shape: (563, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 74 | Accuracy: 0.7922 | Loss: 1.5564 | F1: 0.7595\n","\n","Domain: 75\n","x_dp_dom.shape: (823, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 75 | Accuracy: 0.6598 | Loss: 3.1931 | F1: 0.5905\n","\n","Mean accuracy for run 6: 0.4955\n","Mean F1 for run 6: 0.4487\n","\n","Source class: WAL\n","\n","x_df.shape: (10816, 3, 128) | np.unique(y_df): [0 1 2 3]\n","\n","Training on Df data...\n","\tEpoch 10/100 - Train loss: 0.0287 - Val accuracy: 0.9884 - Val loss: 0.0333 - Val F1: 0.9884 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.0065 - Val accuracy: 0.9917 - Val loss: 0.0177 - Val F1: 0.9917 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.0021 - Val accuracy: 0.9926 - Val loss: 0.0197 - Val F1: 0.9926 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.0011 - Val accuracy: 0.9977 - Val loss: 0.0110 - Val F1: 0.9977 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.0006 - Val accuracy: 0.9954 - Val loss: 0.0147 - Val F1: 0.9954 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.0006 - Val accuracy: 0.9963 - Val loss: 0.0108 - Val F1: 0.9963 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0002 - Val accuracy: 0.9963 - Val loss: 0.0106 - Val F1: 0.9963 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0002 - Val accuracy: 0.9977 - Val loss: 0.0103 - Val F1: 0.9977 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0002 - Val accuracy: 0.9977 - Val loss: 0.0098 - Val F1: 0.9977 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0002 - Val accuracy: 0.9968 - Val loss: 0.0125 - Val F1: 0.9968 - LR: 0.00e+00\n","\tBest epoch: 71 - Best val accuracy: 0.9977 - Best val loss: 0.0097 - Best val F1: 0.9977\n","\n","Domain: 61\n","x_dp_dom.shape: (855, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 61 | Accuracy: 0.5485 | Loss: 2.5777 | F1: 0.4858\n","\n","Domain: 62\n","x_dp_dom.shape: (780, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 62 | Accuracy: 0.6397 | Loss: 2.3575 | F1: 0.5857\n","\n","Domain: 63\n","x_dp_dom.shape: (859, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 63 | Accuracy: 0.5367 | Loss: 2.7687 | F1: 0.4574\n","\n","Domain: 64\n","x_dp_dom.shape: (481, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 64 | Accuracy: 0.7963 | Loss: 0.9731 | F1: 0.7843\n","\n","Domain: 65\n","x_dp_dom.shape: (840, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 65 | Accuracy: 0.6738 | Loss: 0.9556 | F1: 0.6790\n","\n","Domain: 66\n","x_dp_dom.shape: (792, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 66 | Accuracy: 0.4571 | Loss: 2.6228 | F1: 0.4707\n","\n","Domain: 67\n","x_dp_dom.shape: (572, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 67 | Accuracy: 0.8409 | Loss: 0.5764 | F1: 0.8235\n","\n","Domain: 68\n","x_dp_dom.shape: (877, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 68 | Accuracy: 0.5644 | Loss: 1.9520 | F1: 0.5364\n","\n","Domain: 69\n","x_dp_dom.shape: (799, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 69 | Accuracy: 0.4994 | Loss: 1.7319 | F1: 0.4822\n","\n","Domain: 70\n","x_dp_dom.shape: (762, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 70 | Accuracy: 0.5276 | Loss: 2.5613 | F1: 0.5304\n","\n","Domain: 71\n","x_dp_dom.shape: (854, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 71 | Accuracy: 0.4602 | Loss: 1.8061 | F1: 0.4333\n","\n","Domain: 72\n","x_dp_dom.shape: (811, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 72 | Accuracy: 0.7127 | Loss: 1.2140 | F1: 0.7036\n","\n","Domain: 73\n","x_dp_dom.shape: (815, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 73 | Accuracy: 0.7092 | Loss: 1.2292 | F1: 0.6854\n","\n","Domain: 74\n","x_dp_dom.shape: (563, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 74 | Accuracy: 0.8828 | Loss: 0.9268 | F1: 0.8528\n","\n","Domain: 75\n","x_dp_dom.shape: (823, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 75 | Accuracy: 0.7315 | Loss: 1.8668 | F1: 0.6549\n","\n","Mean accuracy for run 7: 0.6387\n","Mean F1 for run 7: 0.6110\n","\n","Source class: WAL\n","\n","x_df.shape: (10816, 3, 128) | np.unique(y_df): [0 1 2 3]\n","\n","Training on Df data...\n","\tEpoch 10/100 - Train loss: 0.0326 - Val accuracy: 0.9852 - Val loss: 0.0404 - Val F1: 0.9851 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.0092 - Val accuracy: 0.9931 - Val loss: 0.0254 - Val F1: 0.9930 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.0027 - Val accuracy: 0.9958 - Val loss: 0.0164 - Val F1: 0.9958 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.0020 - Val accuracy: 0.9940 - Val loss: 0.0298 - Val F1: 0.9939 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.0021 - Val accuracy: 0.9935 - Val loss: 0.0208 - Val F1: 0.9935 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.0006 - Val accuracy: 0.9949 - Val loss: 0.0232 - Val F1: 0.9949 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0004 - Val accuracy: 0.9963 - Val loss: 0.0149 - Val F1: 0.9963 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0002 - Val accuracy: 0.9949 - Val loss: 0.0178 - Val F1: 0.9949 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0002 - Val accuracy: 0.9958 - Val loss: 0.0120 - Val F1: 0.9958 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0003 - Val accuracy: 0.9958 - Val loss: 0.0112 - Val F1: 0.9958 - LR: 0.00e+00\n","\tBest epoch: 100 - Best val accuracy: 0.9958 - Best val loss: 0.0112 - Best val F1: 0.9958\n","\n","Domain: 61\n","x_dp_dom.shape: (855, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 61 | Accuracy: 0.2596 | Loss: 3.6775 | F1: 0.2437\n","\n","Domain: 62\n","x_dp_dom.shape: (780, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 62 | Accuracy: 0.5462 | Loss: 2.6504 | F1: 0.4915\n","\n","Domain: 63\n","x_dp_dom.shape: (859, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 63 | Accuracy: 0.2747 | Loss: 4.7661 | F1: 0.1898\n","\n","Domain: 64\n","x_dp_dom.shape: (481, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 64 | Accuracy: 0.7027 | Loss: 2.0980 | F1: 0.6571\n","\n","Domain: 65\n","x_dp_dom.shape: (840, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 65 | Accuracy: 0.4179 | Loss: 3.2303 | F1: 0.3705\n","\n","Domain: 66\n","x_dp_dom.shape: (792, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 66 | Accuracy: 0.0795 | Loss: 5.6896 | F1: 0.1044\n","\n","Domain: 67\n","x_dp_dom.shape: (572, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 67 | Accuracy: 0.4143 | Loss: 6.2947 | F1: 0.2707\n","\n","Domain: 68\n","x_dp_dom.shape: (877, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 68 | Accuracy: 0.7047 | Loss: 0.9385 | F1: 0.7014\n","\n","Domain: 69\n","x_dp_dom.shape: (799, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 69 | Accuracy: 0.6233 | Loss: 2.0640 | F1: 0.5691\n","\n","Domain: 70\n","x_dp_dom.shape: (762, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 70 | Accuracy: 0.5879 | Loss: 2.9601 | F1: 0.5367\n","\n","Domain: 71\n","x_dp_dom.shape: (854, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 71 | Accuracy: 0.3642 | Loss: 2.7497 | F1: 0.3196\n","\n","Domain: 72\n","x_dp_dom.shape: (811, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 72 | Accuracy: 0.2935 | Loss: 4.9893 | F1: 0.1953\n","\n","Domain: 73\n","x_dp_dom.shape: (815, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 73 | Accuracy: 0.3571 | Loss: 3.8253 | F1: 0.2659\n","\n","Domain: 74\n","x_dp_dom.shape: (563, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 74 | Accuracy: 0.7691 | Loss: 2.6253 | F1: 0.7355\n","\n","Domain: 75\n","x_dp_dom.shape: (823, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 75 | Accuracy: 0.5346 | Loss: 2.6099 | F1: 0.4592\n","\n","Mean accuracy for run 8: 0.4620\n","Mean F1 for run 8: 0.4074\n","\n","Source class: WAL\n","\n","x_df.shape: (10816, 3, 128) | np.unique(y_df): [0 1 2 3]\n","\n","Training on Df data...\n","\tEpoch 10/100 - Train loss: 0.0307 - Val accuracy: 0.9898 - Val loss: 0.0297 - Val F1: 0.9897 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.0069 - Val accuracy: 0.9940 - Val loss: 0.0165 - Val F1: 0.9940 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.0032 - Val accuracy: 0.9972 - Val loss: 0.0091 - Val F1: 0.9972 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.0035 - Val accuracy: 0.9954 - Val loss: 0.0117 - Val F1: 0.9954 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.0011 - Val accuracy: 0.9958 - Val loss: 0.0102 - Val F1: 0.9958 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.0014 - Val accuracy: 0.9972 - Val loss: 0.0100 - Val F1: 0.9972 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0019 - Val accuracy: 0.9972 - Val loss: 0.0106 - Val F1: 0.9972 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0004 - Val accuracy: 0.9972 - Val loss: 0.0091 - Val F1: 0.9972 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0005 - Val accuracy: 0.9968 - Val loss: 0.0086 - Val F1: 0.9968 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0002 - Val accuracy: 0.9977 - Val loss: 0.0089 - Val F1: 0.9977 - LR: 0.00e+00\n","\tBest epoch: 92 - Best val accuracy: 0.9986 - Best val loss: 0.0077 - Best val F1: 0.9986\n","\n","Domain: 61\n","x_dp_dom.shape: (855, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 61 | Accuracy: 0.3848 | Loss: 3.4161 | F1: 0.3100\n","\n","Domain: 62\n","x_dp_dom.shape: (780, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 62 | Accuracy: 0.6090 | Loss: 2.1806 | F1: 0.5384\n","\n","Domain: 63\n","x_dp_dom.shape: (859, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 63 | Accuracy: 0.1513 | Loss: 2.8867 | F1: 0.1612\n","\n","Domain: 64\n","x_dp_dom.shape: (481, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 64 | Accuracy: 0.7277 | Loss: 1.4599 | F1: 0.6638\n","\n","Domain: 65\n","x_dp_dom.shape: (840, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 65 | Accuracy: 0.5298 | Loss: 1.6000 | F1: 0.5060\n","\n","Domain: 66\n","x_dp_dom.shape: (792, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 66 | Accuracy: 0.3902 | Loss: 3.2425 | F1: 0.3070\n","\n","Domain: 67\n","x_dp_dom.shape: (572, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 67 | Accuracy: 0.4878 | Loss: 1.9958 | F1: 0.4014\n","\n","Domain: 68\n","x_dp_dom.shape: (877, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 68 | Accuracy: 0.7138 | Loss: 1.2054 | F1: 0.6824\n","\n","Domain: 69\n","x_dp_dom.shape: (799, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 69 | Accuracy: 0.6771 | Loss: 1.2773 | F1: 0.6395\n","\n","Domain: 70\n","x_dp_dom.shape: (762, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 70 | Accuracy: 0.6234 | Loss: 2.5770 | F1: 0.5245\n","\n","Domain: 71\n","x_dp_dom.shape: (854, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 71 | Accuracy: 0.5047 | Loss: 2.3533 | F1: 0.4427\n","\n","Domain: 72\n","x_dp_dom.shape: (811, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 72 | Accuracy: 0.4254 | Loss: 2.4539 | F1: 0.3748\n","\n","Domain: 73\n","x_dp_dom.shape: (815, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 73 | Accuracy: 0.5853 | Loss: 1.6713 | F1: 0.5514\n","\n","Domain: 74\n","x_dp_dom.shape: (563, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 74 | Accuracy: 0.8703 | Loss: 1.2630 | F1: 0.8331\n","\n","Domain: 75\n","x_dp_dom.shape: (823, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 75 | Accuracy: 0.7169 | Loss: 1.1805 | F1: 0.6996\n","\n","Mean accuracy for run 9: 0.5598\n","Mean F1 for run 9: 0.5091\n","\n","Mean accuracy over 10 runs: 0.5115 +- 0.0596\n","Mean F1 over 10 runs: 0.4559 +- 0.0805\n","\n"]}],"source":["def compute_TSTR_Df(dataset):\n","    accs = []\n","    f1s = []\n","\n","    for i in range(num_runs):\n","\n","        accs_run = []\n","        f1s_run = []\n","\n","        for src_class in config[dataset]['class_names']:\n","            if src_class != 'WAL':\n","                continue\n","\n","            print(f\"Source class: {src_class}\\n\")\n","\n","            # Load Df data\n","            x_df, y_df, k_df = get_data(dataset, 'df', src_class)\n","            print(f'x_df.shape: {x_df.shape} | np.unique(y_df): {np.unique(y_df)}\\n')\n","\n","            # Train on Df data\n","            print('Training on Df data...')\n","            df_model = train_only(x_df, y_df, dataset, num_epochs=num_epochs)\n","\n","            for domain in range(config[dataset]['num_df_domains'], config[dataset]['num_df_domains'] + config[dataset]['num_dp_domains']):\n","                print(f\"Domain: {domain}\")\n","\n","                # Load Dp data\n","                x_dp_dom, y_dp_dom, k_dp_dom = get_data(dataset, 'dp', src_class, domain)\n","                print(f'x_dp_dom.shape: {x_dp_dom.shape} | np.unique(y_dp_dom): {np.unique(y_dp_dom)}\\n')\n","\n","                # Evaluate on Dp data\n","                acc, loss, f1 = evaluate_model(df_model, get_dataloader(x_dp_dom, y_dp_dom))\n","                save_scores(src_class, domain, acc, loss, f1, 'Df', dataset)\n","                accs_run.append(acc)\n","                f1s_run.append(f1)\n","                print(f'Source class: {src_class} | Domain: {domain} | Accuracy: {acc:.4f} | Loss: {loss:.4f} | F1: {f1:.4f}\\n')\n","\n","        print(f\"Mean accuracy for run {i}: {np.mean(accs_run):.4f}\")\n","        print(f\"Mean F1 for run {i}: {np.mean(f1s_run):.4f}\\n\")\n","        accs.append(np.mean(accs_run))\n","        f1s.append(np.mean(f1s_run))\n","\n","    print(f\"Mean accuracy over {num_runs} runs: {np.mean(accs):.4f} +- {np.std(accs):.4f}\")\n","    print(f\"Mean F1 over {num_runs} runs: {np.mean(f1s):.4f} +- {np.std(f1s):.4f}\\n\")\n","\n","\n","\n","\n","compute_TSTR_Df('mobiact_realworld')"]},{"cell_type":"code","execution_count":8,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1158975,"status":"ok","timestamp":1732703535261,"user":{"displayName":"Pietro Castelvetri","userId":"04218697278633758016"},"user_tz":-60},"id":"6X3sBMvtdTCl","outputId":"aff1604a-d2a8-46ab-8328-6bb3f60f8a1c"},"outputs":[{"output_type":"stream","name":"stdout","text":["Source class: WAL\n","\n","x_df.shape: (10816, 3, 128) | np.unique(y_df): [0 1 2 3]\n","\n","Training on Df data...\n","\tEpoch 10/100 - Train loss: 0.1839 - Val accuracy: 0.8124 - Val loss: 0.4645 - Val F1: 0.8275 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.1139 - Val accuracy: 0.8614 - Val loss: 0.3531 - Val F1: 0.8657 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.0758 - Val accuracy: 0.8729 - Val loss: 0.3180 - Val F1: 0.8812 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.0631 - Val accuracy: 0.8327 - Val loss: 0.4430 - Val F1: 0.8542 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.0508 - Val accuracy: 0.8669 - Val loss: 0.3632 - Val F1: 0.8794 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.0370 - Val accuracy: 0.8831 - Val loss: 0.3135 - Val F1: 0.8944 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0302 - Val accuracy: 0.8826 - Val loss: 0.3473 - Val F1: 0.8937 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0302 - Val accuracy: 0.8789 - Val loss: 0.3289 - Val F1: 0.8920 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0294 - Val accuracy: 0.8863 - Val loss: 0.3187 - Val F1: 0.8975 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0231 - Val accuracy: 0.9002 - Val loss: 0.2600 - Val F1: 0.9078 - LR: 0.00e+00\n","\tBest epoch: 94 - Best val accuracy: 0.9080 - Best val loss: 0.2427 - Best val F1: 0.9145\n","\n","Domain: 61\n","x_dp_dom.shape: (855, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 61 | Accuracy: 0.5509 | Loss: 2.1479 | F1: 0.4850\n","\n","Domain: 62\n","x_dp_dom.shape: (780, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 62 | Accuracy: 0.5141 | Loss: 3.6141 | F1: 0.4290\n","\n","Domain: 63\n","x_dp_dom.shape: (859, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 63 | Accuracy: 0.6461 | Loss: 1.1418 | F1: 0.6016\n","\n","Domain: 64\n","x_dp_dom.shape: (481, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 64 | Accuracy: 0.3888 | Loss: 5.2710 | F1: 0.3374\n","\n","Domain: 65\n","x_dp_dom.shape: (840, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 65 | Accuracy: 0.5417 | Loss: 3.3521 | F1: 0.4801\n","\n","Domain: 66\n","x_dp_dom.shape: (792, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 66 | Accuracy: 0.5379 | Loss: 1.5217 | F1: 0.4924\n","\n","Domain: 67\n","x_dp_dom.shape: (572, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 67 | Accuracy: 0.5280 | Loss: 4.6378 | F1: 0.4830\n","\n","Domain: 68\n","x_dp_dom.shape: (877, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 68 | Accuracy: 0.6716 | Loss: 2.0702 | F1: 0.6046\n","\n","Domain: 69\n","x_dp_dom.shape: (799, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 69 | Accuracy: 0.5745 | Loss: 1.2091 | F1: 0.5236\n","\n","Domain: 70\n","x_dp_dom.shape: (762, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 70 | Accuracy: 0.4593 | Loss: 2.9955 | F1: 0.3824\n","\n","Domain: 71\n","x_dp_dom.shape: (854, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 71 | Accuracy: 0.6253 | Loss: 2.2548 | F1: 0.5501\n","\n","Domain: 72\n","x_dp_dom.shape: (811, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 72 | Accuracy: 0.5734 | Loss: 2.5685 | F1: 0.5095\n","\n","Domain: 73\n","x_dp_dom.shape: (815, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 73 | Accuracy: 0.5828 | Loss: 2.1744 | F1: 0.5198\n","\n","Domain: 74\n","x_dp_dom.shape: (563, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 74 | Accuracy: 0.4636 | Loss: 6.3129 | F1: 0.4544\n","\n","Domain: 75\n","x_dp_dom.shape: (823, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 75 | Accuracy: 0.5747 | Loss: 1.1615 | F1: 0.5602\n","\n","Mean accuracy for run 0: 0.5488\n","Mean F1 for run 0: 0.4942\n","\n","Source class: WAL\n","\n","x_df.shape: (10816, 3, 128) | np.unique(y_df): [0 1 2 3]\n","\n","Training on Df data...\n","\tEpoch 10/100 - Train loss: 0.1984 - Val accuracy: 0.8540 - Val loss: 0.3803 - Val F1: 0.8359 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.1224 - Val accuracy: 0.8711 - Val loss: 0.3571 - Val F1: 0.8793 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.0789 - Val accuracy: 0.8507 - Val loss: 0.3795 - Val F1: 0.8684 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.0630 - Val accuracy: 0.8387 - Val loss: 0.3949 - Val F1: 0.8598 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.0545 - Val accuracy: 0.8470 - Val loss: 0.3943 - Val F1: 0.8678 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.0412 - Val accuracy: 0.8831 - Val loss: 0.3053 - Val F1: 0.8940 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0383 - Val accuracy: 0.8951 - Val loss: 0.2692 - Val F1: 0.9044 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0380 - Val accuracy: 0.9011 - Val loss: 0.2496 - Val F1: 0.9086 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0344 - Val accuracy: 0.9034 - Val loss: 0.2466 - Val F1: 0.9111 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0301 - Val accuracy: 0.8396 - Val loss: 0.4111 - Val F1: 0.8634 - LR: 0.00e+00\n","\tBest epoch: 77 - Best val accuracy: 0.9067 - Best val loss: 0.2396 - Best val F1: 0.9121\n","\n","Domain: 61\n","x_dp_dom.shape: (855, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 61 | Accuracy: 0.5836 | Loss: 1.6950 | F1: 0.5091\n","\n","Domain: 62\n","x_dp_dom.shape: (780, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 62 | Accuracy: 0.4974 | Loss: 4.0644 | F1: 0.4282\n","\n","Domain: 63\n","x_dp_dom.shape: (859, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 63 | Accuracy: 0.6077 | Loss: 1.0970 | F1: 0.5735\n","\n","Domain: 64\n","x_dp_dom.shape: (481, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 64 | Accuracy: 0.3825 | Loss: 4.9323 | F1: 0.3291\n","\n","Domain: 65\n","x_dp_dom.shape: (840, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 65 | Accuracy: 0.5762 | Loss: 2.1646 | F1: 0.5061\n","\n","Domain: 66\n","x_dp_dom.shape: (792, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 66 | Accuracy: 0.5543 | Loss: 1.7096 | F1: 0.4893\n","\n","Domain: 67\n","x_dp_dom.shape: (572, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 67 | Accuracy: 0.5157 | Loss: 4.1175 | F1: 0.4776\n","\n","Domain: 68\n","x_dp_dom.shape: (877, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 68 | Accuracy: 0.6488 | Loss: 1.8307 | F1: 0.5834\n","\n","Domain: 69\n","x_dp_dom.shape: (799, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 69 | Accuracy: 0.6258 | Loss: 1.2415 | F1: 0.5533\n","\n","Domain: 70\n","x_dp_dom.shape: (762, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 70 | Accuracy: 0.4672 | Loss: 3.1283 | F1: 0.3860\n","\n","Domain: 71\n","x_dp_dom.shape: (854, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 71 | Accuracy: 0.6288 | Loss: 1.7864 | F1: 0.5466\n","\n","Domain: 72\n","x_dp_dom.shape: (811, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 72 | Accuracy: 0.6202 | Loss: 2.2152 | F1: 0.5518\n","\n","Domain: 73\n","x_dp_dom.shape: (815, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 73 | Accuracy: 0.6491 | Loss: 1.7020 | F1: 0.5563\n","\n","Domain: 74\n","x_dp_dom.shape: (563, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 74 | Accuracy: 0.4600 | Loss: 6.2221 | F1: 0.4546\n","\n","Domain: 75\n","x_dp_dom.shape: (823, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 75 | Accuracy: 0.5905 | Loss: 1.0050 | F1: 0.5543\n","\n","Mean accuracy for run 1: 0.5605\n","Mean F1 for run 1: 0.4999\n","\n","Source class: WAL\n","\n","x_df.shape: (10816, 3, 128) | np.unique(y_df): [0 1 2 3]\n","\n","Training on Df data...\n","\tEpoch 10/100 - Train loss: 0.1858 - Val accuracy: 0.8512 - Val loss: 0.3920 - Val F1: 0.8349 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.1107 - Val accuracy: 0.8872 - Val loss: 0.2947 - Val F1: 0.8866 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.0733 - Val accuracy: 0.8909 - Val loss: 0.2907 - Val F1: 0.8976 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.0474 - Val accuracy: 0.9034 - Val loss: 0.2471 - Val F1: 0.9072 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.0474 - Val accuracy: 0.8498 - Val loss: 0.4538 - Val F1: 0.8655 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.0374 - Val accuracy: 0.9122 - Val loss: 0.2421 - Val F1: 0.9171 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0352 - Val accuracy: 0.8877 - Val loss: 0.3080 - Val F1: 0.8966 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0310 - Val accuracy: 0.9159 - Val loss: 0.2649 - Val F1: 0.9208 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0236 - Val accuracy: 0.9053 - Val loss: 0.2804 - Val F1: 0.9121 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0285 - Val accuracy: 0.9117 - Val loss: 0.2827 - Val F1: 0.9175 - LR: 0.00e+00\n","\tBest epoch: 58 - Best val accuracy: 0.9233 - Best val loss: 0.2278 - Best val F1: 0.9263\n","\n","Domain: 61\n","x_dp_dom.shape: (855, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 61 | Accuracy: 0.6386 | Loss: 1.1549 | F1: 0.5807\n","\n","Domain: 62\n","x_dp_dom.shape: (780, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 62 | Accuracy: 0.5538 | Loss: 2.5486 | F1: 0.4898\n","\n","Domain: 63\n","x_dp_dom.shape: (859, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 63 | Accuracy: 0.5541 | Loss: 1.1339 | F1: 0.5204\n","\n","Domain: 64\n","x_dp_dom.shape: (481, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 64 | Accuracy: 0.3992 | Loss: 2.7756 | F1: 0.3552\n","\n","Domain: 65\n","x_dp_dom.shape: (840, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 65 | Accuracy: 0.5643 | Loss: 1.5776 | F1: 0.5048\n","\n","Domain: 66\n","x_dp_dom.shape: (792, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 66 | Accuracy: 0.6288 | Loss: 0.9865 | F1: 0.6143\n","\n","Domain: 67\n","x_dp_dom.shape: (572, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 67 | Accuracy: 0.5420 | Loss: 3.5604 | F1: 0.5059\n","\n","Domain: 68\n","x_dp_dom.shape: (877, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 68 | Accuracy: 0.6750 | Loss: 1.4439 | F1: 0.5918\n","\n","Domain: 69\n","x_dp_dom.shape: (799, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 69 | Accuracy: 0.6045 | Loss: 0.9577 | F1: 0.5376\n","\n","Domain: 70\n","x_dp_dom.shape: (762, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 70 | Accuracy: 0.4659 | Loss: 2.4303 | F1: 0.3861\n","\n","Domain: 71\n","x_dp_dom.shape: (854, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 71 | Accuracy: 0.6230 | Loss: 1.2380 | F1: 0.5631\n","\n","Domain: 72\n","x_dp_dom.shape: (811, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 72 | Accuracy: 0.6584 | Loss: 1.3490 | F1: 0.5764\n","\n","Domain: 73\n","x_dp_dom.shape: (815, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 73 | Accuracy: 0.6245 | Loss: 1.0953 | F1: 0.5542\n","\n","Domain: 74\n","x_dp_dom.shape: (563, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 74 | Accuracy: 0.4476 | Loss: 5.6505 | F1: 0.4461\n","\n","Domain: 75\n","x_dp_dom.shape: (823, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 75 | Accuracy: 0.5772 | Loss: 0.9204 | F1: 0.5495\n","\n","Mean accuracy for run 2: 0.5705\n","Mean F1 for run 2: 0.5184\n","\n","Source class: WAL\n","\n","x_df.shape: (10816, 3, 128) | np.unique(y_df): [0 1 2 3]\n","\n","Training on Df data...\n","\tEpoch 10/100 - Train loss: 0.2010 - Val accuracy: 0.7837 - Val loss: 0.5563 - Val F1: 0.7981 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.1177 - Val accuracy: 0.8457 - Val loss: 0.4076 - Val F1: 0.8508 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.0819 - Val accuracy: 0.8438 - Val loss: 0.4167 - Val F1: 0.8559 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.0597 - Val accuracy: 0.8433 - Val loss: 0.3911 - Val F1: 0.8608 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.0433 - Val accuracy: 0.8720 - Val loss: 0.3389 - Val F1: 0.8824 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.0433 - Val accuracy: 0.8378 - Val loss: 0.4531 - Val F1: 0.8572 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0383 - Val accuracy: 0.8831 - Val loss: 0.3382 - Val F1: 0.8917 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0364 - Val accuracy: 0.8683 - Val loss: 0.3750 - Val F1: 0.8820 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0267 - Val accuracy: 0.8443 - Val loss: 0.4365 - Val F1: 0.8640 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0246 - Val accuracy: 0.8535 - Val loss: 0.4079 - Val F1: 0.8704 - LR: 0.00e+00\n","\tBest epoch: 71 - Best val accuracy: 0.8951 - Best val loss: 0.2813 - Best val F1: 0.9021\n","\n","Domain: 61\n","x_dp_dom.shape: (855, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 61 | Accuracy: 0.6643 | Loss: 0.8224 | F1: 0.6576\n","\n","Domain: 62\n","x_dp_dom.shape: (780, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 62 | Accuracy: 0.5256 | Loss: 3.2459 | F1: 0.4580\n","\n","Domain: 63\n","x_dp_dom.shape: (859, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 63 | Accuracy: 0.5925 | Loss: 1.0717 | F1: 0.5731\n","\n","Domain: 64\n","x_dp_dom.shape: (481, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 64 | Accuracy: 0.4116 | Loss: 4.1899 | F1: 0.3697\n","\n","Domain: 65\n","x_dp_dom.shape: (840, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 65 | Accuracy: 0.5964 | Loss: 1.3952 | F1: 0.5686\n","\n","Domain: 66\n","x_dp_dom.shape: (792, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 66 | Accuracy: 0.6162 | Loss: 0.8778 | F1: 0.6237\n","\n","Domain: 67\n","x_dp_dom.shape: (572, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 67 | Accuracy: 0.5350 | Loss: 2.9387 | F1: 0.5083\n","\n","Domain: 68\n","x_dp_dom.shape: (877, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 68 | Accuracy: 0.6431 | Loss: 0.7931 | F1: 0.6334\n","\n","Domain: 69\n","x_dp_dom.shape: (799, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 69 | Accuracy: 0.8098 | Loss: 0.5256 | F1: 0.8084\n","\n","Domain: 70\n","x_dp_dom.shape: (762, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 70 | Accuracy: 0.5131 | Loss: 1.3521 | F1: 0.4768\n","\n","Domain: 71\n","x_dp_dom.shape: (854, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 71 | Accuracy: 0.6358 | Loss: 0.9082 | F1: 0.6284\n","\n","Domain: 72\n","x_dp_dom.shape: (811, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 72 | Accuracy: 0.6646 | Loss: 0.7535 | F1: 0.6491\n","\n","Domain: 73\n","x_dp_dom.shape: (815, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 73 | Accuracy: 0.6761 | Loss: 0.8286 | F1: 0.6615\n","\n","Domain: 74\n","x_dp_dom.shape: (563, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 74 | Accuracy: 0.4547 | Loss: 6.0048 | F1: 0.4482\n","\n","Domain: 75\n","x_dp_dom.shape: (823, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 75 | Accuracy: 0.7618 | Loss: 0.6978 | F1: 0.7477\n","\n","Mean accuracy for run 3: 0.6067\n","Mean F1 for run 3: 0.5875\n","\n","Source class: WAL\n","\n","x_df.shape: (10816, 3, 128) | np.unique(y_df): [0 1 2 3]\n","\n","Training on Df data...\n","\tEpoch 10/100 - Train loss: 0.1807 - Val accuracy: 0.8184 - Val loss: 0.4448 - Val F1: 0.8306 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.0979 - Val accuracy: 0.8743 - Val loss: 0.3277 - Val F1: 0.8816 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.0701 - Val accuracy: 0.8715 - Val loss: 0.3340 - Val F1: 0.8843 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.0472 - Val accuracy: 0.8729 - Val loss: 0.3323 - Val F1: 0.8865 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.0423 - Val accuracy: 0.8909 - Val loss: 0.3061 - Val F1: 0.9010 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.0374 - Val accuracy: 0.8475 - Val loss: 0.4501 - Val F1: 0.8677 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0308 - Val accuracy: 0.8905 - Val loss: 0.3165 - Val F1: 0.9013 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0297 - Val accuracy: 0.8891 - Val loss: 0.3298 - Val F1: 0.9002 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0218 - Val accuracy: 0.9136 - Val loss: 0.2521 - Val F1: 0.9200 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0241 - Val accuracy: 0.9071 - Val loss: 0.2680 - Val F1: 0.9152 - LR: 0.00e+00\n","\tBest epoch: 44 - Best val accuracy: 0.9164 - Best val loss: 0.2285 - Best val F1: 0.9185\n","\n","Domain: 61\n","x_dp_dom.shape: (855, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 61 | Accuracy: 0.7135 | Loss: 0.8856 | F1: 0.7062\n","\n","Domain: 62\n","x_dp_dom.shape: (780, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 62 | Accuracy: 0.5372 | Loss: 2.5746 | F1: 0.4845\n","\n","Domain: 63\n","x_dp_dom.shape: (859, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 63 | Accuracy: 0.6147 | Loss: 1.4657 | F1: 0.5601\n","\n","Domain: 64\n","x_dp_dom.shape: (481, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 64 | Accuracy: 0.4220 | Loss: 3.4456 | F1: 0.3915\n","\n","Domain: 65\n","x_dp_dom.shape: (840, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 65 | Accuracy: 0.5774 | Loss: 1.8353 | F1: 0.5487\n","\n","Domain: 66\n","x_dp_dom.shape: (792, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 66 | Accuracy: 0.6717 | Loss: 0.8910 | F1: 0.6758\n","\n","Domain: 67\n","x_dp_dom.shape: (572, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 67 | Accuracy: 0.5350 | Loss: 3.2788 | F1: 0.5126\n","\n","Domain: 68\n","x_dp_dom.shape: (877, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 68 | Accuracy: 0.6739 | Loss: 1.1599 | F1: 0.6106\n","\n","Domain: 69\n","x_dp_dom.shape: (799, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 69 | Accuracy: 0.8561 | Loss: 0.5140 | F1: 0.8533\n","\n","Domain: 70\n","x_dp_dom.shape: (762, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 70 | Accuracy: 0.5499 | Loss: 1.6446 | F1: 0.5167\n","\n","Domain: 71\n","x_dp_dom.shape: (854, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 71 | Accuracy: 0.6593 | Loss: 1.0759 | F1: 0.6250\n","\n","Domain: 72\n","x_dp_dom.shape: (811, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 72 | Accuracy: 0.7275 | Loss: 0.6856 | F1: 0.7119\n","\n","Domain: 73\n","x_dp_dom.shape: (815, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 73 | Accuracy: 0.7350 | Loss: 0.6891 | F1: 0.7270\n","\n","Domain: 74\n","x_dp_dom.shape: (563, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 74 | Accuracy: 0.4458 | Loss: 6.5345 | F1: 0.4422\n","\n","Domain: 75\n","x_dp_dom.shape: (823, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 75 | Accuracy: 0.7035 | Loss: 0.7362 | F1: 0.7037\n","\n","Mean accuracy for run 4: 0.6282\n","Mean F1 for run 4: 0.6047\n","\n","Source class: WAL\n","\n","x_df.shape: (10816, 3, 128) | np.unique(y_df): [0 1 2 3]\n","\n","Training on Df data...\n","\tEpoch 10/100 - Train loss: 0.2001 - Val accuracy: 0.8452 - Val loss: 0.4208 - Val F1: 0.8259 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.1191 - Val accuracy: 0.8674 - Val loss: 0.3523 - Val F1: 0.8691 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.0799 - Val accuracy: 0.8988 - Val loss: 0.2891 - Val F1: 0.8954 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.0582 - Val accuracy: 0.8729 - Val loss: 0.3305 - Val F1: 0.8845 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.0525 - Val accuracy: 0.8378 - Val loss: 0.4179 - Val F1: 0.8587 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.0446 - Val accuracy: 0.8660 - Val loss: 0.3479 - Val F1: 0.8809 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0299 - Val accuracy: 0.8993 - Val loss: 0.2748 - Val F1: 0.9063 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0347 - Val accuracy: 0.8919 - Val loss: 0.2944 - Val F1: 0.9015 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0300 - Val accuracy: 0.8928 - Val loss: 0.2928 - Val F1: 0.9022 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0307 - Val accuracy: 0.8970 - Val loss: 0.2675 - Val F1: 0.9037 - LR: 0.00e+00\n","\tBest epoch: 66 - Best val accuracy: 0.9205 - Best val loss: 0.2288 - Best val F1: 0.9203\n","\n","Domain: 61\n","x_dp_dom.shape: (855, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 61 | Accuracy: 0.6760 | Loss: 1.2399 | F1: 0.6134\n","\n","Domain: 62\n","x_dp_dom.shape: (780, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 62 | Accuracy: 0.5756 | Loss: 3.2244 | F1: 0.5127\n","\n","Domain: 63\n","x_dp_dom.shape: (859, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 63 | Accuracy: 0.6147 | Loss: 1.6303 | F1: 0.5538\n","\n","Domain: 64\n","x_dp_dom.shape: (481, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 64 | Accuracy: 0.3867 | Loss: 5.0182 | F1: 0.3457\n","\n","Domain: 65\n","x_dp_dom.shape: (840, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 65 | Accuracy: 0.5750 | Loss: 2.5186 | F1: 0.5046\n","\n","Domain: 66\n","x_dp_dom.shape: (792, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 66 | Accuracy: 0.6540 | Loss: 1.0775 | F1: 0.6381\n","\n","Domain: 67\n","x_dp_dom.shape: (572, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 67 | Accuracy: 0.5315 | Loss: 3.6102 | F1: 0.4835\n","\n","Domain: 68\n","x_dp_dom.shape: (877, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 68 | Accuracy: 0.6807 | Loss: 2.1899 | F1: 0.5983\n","\n","Domain: 69\n","x_dp_dom.shape: (799, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 69 | Accuracy: 0.7096 | Loss: 0.7154 | F1: 0.6857\n","\n","Domain: 70\n","x_dp_dom.shape: (762, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 70 | Accuracy: 0.5118 | Loss: 1.8348 | F1: 0.4652\n","\n","Domain: 71\n","x_dp_dom.shape: (854, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 71 | Accuracy: 0.6417 | Loss: 1.8188 | F1: 0.5546\n","\n","Domain: 72\n","x_dp_dom.shape: (811, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 72 | Accuracy: 0.6634 | Loss: 1.7024 | F1: 0.5739\n","\n","Domain: 73\n","x_dp_dom.shape: (815, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 73 | Accuracy: 0.6650 | Loss: 1.4163 | F1: 0.5814\n","\n","Domain: 74\n","x_dp_dom.shape: (563, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 74 | Accuracy: 0.4583 | Loss: 6.7724 | F1: 0.4523\n","\n","Domain: 75\n","x_dp_dom.shape: (823, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 75 | Accuracy: 0.6294 | Loss: 0.9514 | F1: 0.5904\n","\n","Mean accuracy for run 5: 0.5982\n","Mean F1 for run 5: 0.5436\n","\n","Source class: WAL\n","\n","x_df.shape: (10816, 3, 128) | np.unique(y_df): [0 1 2 3]\n","\n","Training on Df data...\n","\tEpoch 10/100 - Train loss: 0.1792 - Val accuracy: 0.8235 - Val loss: 0.4401 - Val F1: 0.8408 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.0988 - Val accuracy: 0.8738 - Val loss: 0.3236 - Val F1: 0.8784 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.0713 - Val accuracy: 0.8438 - Val loss: 0.4023 - Val F1: 0.8609 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.0551 - Val accuracy: 0.8817 - Val loss: 0.3061 - Val F1: 0.8913 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.0516 - Val accuracy: 0.8720 - Val loss: 0.3044 - Val F1: 0.8846 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.0415 - Val accuracy: 0.8540 - Val loss: 0.3970 - Val F1: 0.8699 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0309 - Val accuracy: 0.8521 - Val loss: 0.3944 - Val F1: 0.8699 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0385 - Val accuracy: 0.8771 - Val loss: 0.3306 - Val F1: 0.8899 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0281 - Val accuracy: 0.8734 - Val loss: 0.3504 - Val F1: 0.8865 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0292 - Val accuracy: 0.8785 - Val loss: 0.3269 - Val F1: 0.8898 - LR: 0.00e+00\n","\tBest epoch: 42 - Best val accuracy: 0.9057 - Best val loss: 0.2460 - Best val F1: 0.9104\n","\n","Domain: 61\n","x_dp_dom.shape: (855, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 61 | Accuracy: 0.6865 | Loss: 0.7477 | F1: 0.6379\n","\n","Domain: 62\n","x_dp_dom.shape: (780, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 62 | Accuracy: 0.5590 | Loss: 3.1519 | F1: 0.5068\n","\n","Domain: 63\n","x_dp_dom.shape: (859, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 63 | Accuracy: 0.5867 | Loss: 1.8638 | F1: 0.5276\n","\n","Domain: 64\n","x_dp_dom.shape: (481, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 64 | Accuracy: 0.4116 | Loss: 3.6691 | F1: 0.3654\n","\n","Domain: 65\n","x_dp_dom.shape: (840, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 65 | Accuracy: 0.6440 | Loss: 1.3016 | F1: 0.5825\n","\n","Domain: 66\n","x_dp_dom.shape: (792, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 66 | Accuracy: 0.6124 | Loss: 1.0361 | F1: 0.5618\n","\n","Domain: 67\n","x_dp_dom.shape: (572, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 67 | Accuracy: 0.5647 | Loss: 2.8429 | F1: 0.5104\n","\n","Domain: 68\n","x_dp_dom.shape: (877, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 68 | Accuracy: 0.6773 | Loss: 1.3744 | F1: 0.5863\n","\n","Domain: 69\n","x_dp_dom.shape: (799, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 69 | Accuracy: 0.6834 | Loss: 0.9434 | F1: 0.6355\n","\n","Domain: 70\n","x_dp_dom.shape: (762, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 70 | Accuracy: 0.5341 | Loss: 1.4567 | F1: 0.4995\n","\n","Domain: 71\n","x_dp_dom.shape: (854, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 71 | Accuracy: 0.6721 | Loss: 1.0937 | F1: 0.6077\n","\n","Domain: 72\n","x_dp_dom.shape: (811, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 72 | Accuracy: 0.6806 | Loss: 1.0850 | F1: 0.5995\n","\n","Domain: 73\n","x_dp_dom.shape: (815, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 73 | Accuracy: 0.6552 | Loss: 1.2414 | F1: 0.5745\n","\n","Domain: 74\n","x_dp_dom.shape: (563, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 74 | Accuracy: 0.4636 | Loss: 5.5949 | F1: 0.4638\n","\n","Domain: 75\n","x_dp_dom.shape: (823, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 75 | Accuracy: 0.5990 | Loss: 0.9804 | F1: 0.5810\n","\n","Mean accuracy for run 6: 0.6020\n","Mean F1 for run 6: 0.5493\n","\n","Source class: WAL\n","\n","x_df.shape: (10816, 3, 128) | np.unique(y_df): [0 1 2 3]\n","\n","Training on Df data...\n","\tEpoch 10/100 - Train loss: 0.2146 - Val accuracy: 0.8142 - Val loss: 0.4673 - Val F1: 0.8152 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.1237 - Val accuracy: 0.8360 - Val loss: 0.4107 - Val F1: 0.8563 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.0799 - Val accuracy: 0.8433 - Val loss: 0.3901 - Val F1: 0.8624 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.0548 - Val accuracy: 0.8309 - Val loss: 0.3892 - Val F1: 0.8550 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.0475 - Val accuracy: 0.8563 - Val loss: 0.3510 - Val F1: 0.8733 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.0382 - Val accuracy: 0.8512 - Val loss: 0.3615 - Val F1: 0.8695 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0397 - Val accuracy: 0.8669 - Val loss: 0.3149 - Val F1: 0.8840 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0310 - Val accuracy: 0.8706 - Val loss: 0.3158 - Val F1: 0.8857 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0303 - Val accuracy: 0.8665 - Val loss: 0.3137 - Val F1: 0.8826 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0295 - Val accuracy: 0.8623 - Val loss: 0.3337 - Val F1: 0.8783 - LR: 0.00e+00\n","\tBest epoch: 69 - Best val accuracy: 0.9140 - Best val loss: 0.2293 - Best val F1: 0.9177\n","\n","Domain: 61\n","x_dp_dom.shape: (855, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 61 | Accuracy: 0.6596 | Loss: 0.9827 | F1: 0.6582\n","\n","Domain: 62\n","x_dp_dom.shape: (780, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 62 | Accuracy: 0.4936 | Loss: 4.2881 | F1: 0.3898\n","\n","Domain: 63\n","x_dp_dom.shape: (859, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 63 | Accuracy: 0.6321 | Loss: 0.9130 | F1: 0.5926\n","\n","Domain: 64\n","x_dp_dom.shape: (481, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 64 | Accuracy: 0.3805 | Loss: 4.8695 | F1: 0.3229\n","\n","Domain: 65\n","x_dp_dom.shape: (840, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 65 | Accuracy: 0.5321 | Loss: 2.0120 | F1: 0.4930\n","\n","Domain: 66\n","x_dp_dom.shape: (792, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 66 | Accuracy: 0.5265 | Loss: 1.3787 | F1: 0.4948\n","\n","Domain: 67\n","x_dp_dom.shape: (572, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 67 | Accuracy: 0.5087 | Loss: 3.9529 | F1: 0.4725\n","\n","Domain: 68\n","x_dp_dom.shape: (877, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 68 | Accuracy: 0.6328 | Loss: 1.8374 | F1: 0.5888\n","\n","Domain: 69\n","x_dp_dom.shape: (799, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 69 | Accuracy: 0.5557 | Loss: 1.2721 | F1: 0.5184\n","\n","Domain: 70\n","x_dp_dom.shape: (762, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 70 | Accuracy: 0.4619 | Loss: 2.8732 | F1: 0.3755\n","\n","Domain: 71\n","x_dp_dom.shape: (854, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 71 | Accuracy: 0.6499 | Loss: 1.2876 | F1: 0.6283\n","\n","Domain: 72\n","x_dp_dom.shape: (811, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 72 | Accuracy: 0.5623 | Loss: 1.9281 | F1: 0.5015\n","\n","Domain: 73\n","x_dp_dom.shape: (815, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 73 | Accuracy: 0.5656 | Loss: 1.5232 | F1: 0.5047\n","\n","Domain: 74\n","x_dp_dom.shape: (563, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 74 | Accuracy: 0.4352 | Loss: 6.9695 | F1: 0.4266\n","\n","Domain: 75\n","x_dp_dom.shape: (823, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 75 | Accuracy: 0.5638 | Loss: 1.1943 | F1: 0.5388\n","\n","Mean accuracy for run 7: 0.5440\n","Mean F1 for run 7: 0.5004\n","\n","Source class: WAL\n","\n","x_df.shape: (10816, 3, 128) | np.unique(y_df): [0 1 2 3]\n","\n","Training on Df data...\n","\tEpoch 10/100 - Train loss: 0.1937 - Val accuracy: 0.8392 - Val loss: 0.4047 - Val F1: 0.8339 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.1179 - Val accuracy: 0.8369 - Val loss: 0.3728 - Val F1: 0.8571 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.0874 - Val accuracy: 0.8170 - Val loss: 0.4103 - Val F1: 0.8417 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.0688 - Val accuracy: 0.8424 - Val loss: 0.3587 - Val F1: 0.8646 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.0495 - Val accuracy: 0.8933 - Val loss: 0.2435 - Val F1: 0.9013 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.0487 - Val accuracy: 0.9196 - Val loss: 0.1987 - Val F1: 0.9204 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0384 - Val accuracy: 0.8909 - Val loss: 0.2570 - Val F1: 0.9014 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0352 - Val accuracy: 0.9140 - Val loss: 0.2105 - Val F1: 0.9182 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0354 - Val accuracy: 0.9002 - Val loss: 0.2276 - Val F1: 0.9096 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0307 - Val accuracy: 0.9159 - Val loss: 0.2022 - Val F1: 0.9216 - LR: 0.00e+00\n","\tBest epoch: 76 - Best val accuracy: 0.9311 - Best val loss: 0.1795 - Best val F1: 0.9311\n","\n","Domain: 61\n","x_dp_dom.shape: (855, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 61 | Accuracy: 0.5368 | Loss: 1.5866 | F1: 0.5028\n","\n","Domain: 62\n","x_dp_dom.shape: (780, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 62 | Accuracy: 0.4808 | Loss: 3.5582 | F1: 0.3939\n","\n","Domain: 63\n","x_dp_dom.shape: (859, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 63 | Accuracy: 0.6333 | Loss: 0.9056 | F1: 0.6088\n","\n","Domain: 64\n","x_dp_dom.shape: (481, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 64 | Accuracy: 0.3742 | Loss: 4.4284 | F1: 0.3224\n","\n","Domain: 65\n","x_dp_dom.shape: (840, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 65 | Accuracy: 0.5333 | Loss: 2.3669 | F1: 0.4753\n","\n","Domain: 66\n","x_dp_dom.shape: (792, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 66 | Accuracy: 0.5265 | Loss: 1.2880 | F1: 0.4848\n","\n","Domain: 67\n","x_dp_dom.shape: (572, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 67 | Accuracy: 0.5227 | Loss: 3.6538 | F1: 0.4754\n","\n","Domain: 68\n","x_dp_dom.shape: (877, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 68 | Accuracy: 0.6534 | Loss: 1.2764 | F1: 0.5893\n","\n","Domain: 69\n","x_dp_dom.shape: (799, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 69 | Accuracy: 0.6033 | Loss: 1.0223 | F1: 0.5776\n","\n","Domain: 70\n","x_dp_dom.shape: (762, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 70 | Accuracy: 0.4724 | Loss: 2.5355 | F1: 0.3876\n","\n","Domain: 71\n","x_dp_dom.shape: (854, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 71 | Accuracy: 0.6054 | Loss: 1.4983 | F1: 0.5649\n","\n","Domain: 72\n","x_dp_dom.shape: (811, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 72 | Accuracy: 0.6042 | Loss: 1.6145 | F1: 0.5546\n","\n","Domain: 73\n","x_dp_dom.shape: (815, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 73 | Accuracy: 0.6123 | Loss: 1.4102 | F1: 0.5516\n","\n","Domain: 74\n","x_dp_dom.shape: (563, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 74 | Accuracy: 0.4423 | Loss: 6.5039 | F1: 0.4389\n","\n","Domain: 75\n","x_dp_dom.shape: (823, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 75 | Accuracy: 0.6185 | Loss: 0.9037 | F1: 0.6052\n","\n","Mean accuracy for run 8: 0.5480\n","Mean F1 for run 8: 0.5022\n","\n","Source class: WAL\n","\n","x_df.shape: (10816, 3, 128) | np.unique(y_df): [0 1 2 3]\n","\n","Training on Df data...\n","\tEpoch 10/100 - Train loss: 0.1783 - Val accuracy: 0.8235 - Val loss: 0.4759 - Val F1: 0.8124 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.1128 - Val accuracy: 0.7629 - Val loss: 0.6520 - Val F1: 0.8013 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.0663 - Val accuracy: 0.8628 - Val loss: 0.3554 - Val F1: 0.8762 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.0498 - Val accuracy: 0.8119 - Val loss: 0.5321 - Val F1: 0.8386 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.0450 - Val accuracy: 0.8332 - Val loss: 0.4334 - Val F1: 0.8559 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.0399 - Val accuracy: 0.8641 - Val loss: 0.3755 - Val F1: 0.8782 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0325 - Val accuracy: 0.8530 - Val loss: 0.4501 - Val F1: 0.8702 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0306 - Val accuracy: 0.8355 - Val loss: 0.4887 - Val F1: 0.8583 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0233 - Val accuracy: 0.8641 - Val loss: 0.4089 - Val F1: 0.8813 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0309 - Val accuracy: 0.8655 - Val loss: 0.3812 - Val F1: 0.8818 - LR: 0.00e+00\n","\tBest epoch: 65 - Best val accuracy: 0.8956 - Best val loss: 0.2514 - Best val F1: 0.9043\n","\n","Domain: 61\n","x_dp_dom.shape: (855, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 61 | Accuracy: 0.5754 | Loss: 2.3339 | F1: 0.5129\n","\n","Domain: 62\n","x_dp_dom.shape: (780, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 62 | Accuracy: 0.5077 | Loss: 5.2941 | F1: 0.4227\n","\n","Domain: 63\n","x_dp_dom.shape: (859, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 63 | Accuracy: 0.5716 | Loss: 1.5237 | F1: 0.5197\n","\n","Domain: 64\n","x_dp_dom.shape: (481, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 64 | Accuracy: 0.3846 | Loss: 7.1028 | F1: 0.3307\n","\n","Domain: 65\n","x_dp_dom.shape: (840, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 65 | Accuracy: 0.5690 | Loss: 2.8837 | F1: 0.5062\n","\n","Domain: 66\n","x_dp_dom.shape: (792, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 66 | Accuracy: 0.5492 | Loss: 2.0227 | F1: 0.4751\n","\n","Domain: 67\n","x_dp_dom.shape: (572, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 67 | Accuracy: 0.5280 | Loss: 5.1507 | F1: 0.4840\n","\n","Domain: 68\n","x_dp_dom.shape: (877, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 68 | Accuracy: 0.6556 | Loss: 2.4048 | F1: 0.5998\n","\n","Domain: 69\n","x_dp_dom.shape: (799, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 69 | Accuracy: 0.6033 | Loss: 1.3132 | F1: 0.5427\n","\n","Domain: 70\n","x_dp_dom.shape: (762, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 70 | Accuracy: 0.4646 | Loss: 3.5995 | F1: 0.3818\n","\n","Domain: 71\n","x_dp_dom.shape: (854, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 71 | Accuracy: 0.6206 | Loss: 2.5543 | F1: 0.5540\n","\n","Domain: 72\n","x_dp_dom.shape: (811, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 72 | Accuracy: 0.6215 | Loss: 2.4036 | F1: 0.5519\n","\n","Domain: 73\n","x_dp_dom.shape: (815, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 73 | Accuracy: 0.6196 | Loss: 1.9788 | F1: 0.5353\n","\n","Domain: 74\n","x_dp_dom.shape: (563, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 74 | Accuracy: 0.4565 | Loss: 7.6062 | F1: 0.4508\n","\n","Domain: 75\n","x_dp_dom.shape: (823, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Source class: WAL | Domain: 75 | Accuracy: 0.5334 | Loss: 1.3308 | F1: 0.4838\n","\n","Mean accuracy for run 9: 0.5507\n","Mean F1 for run 9: 0.4901\n","\n","Mean accuracy over 10 runs: 0.5758 +- 0.0288\n","Mean F1 over 10 runs: 0.5290 +- 0.0387\n","\n"]}],"source":["def compute_TSTR_Df_aug(dataset):\n","    accs = []\n","    f1s = []\n","\n","    for i in range(num_runs):\n","\n","        accs_run = []\n","        f1s_run = []\n","\n","        for src_class in config[dataset]['class_names']:\n","            if src_class != 'WAL':\n","                continue\n","\n","            print(f\"Source class: {src_class}\\n\")\n","\n","            # Load Df data\n","            x_df, y_df, k_df = get_data(dataset, 'df', src_class)\n","            print(f'x_df.shape: {x_df.shape} | np.unique(y_df): {np.unique(y_df)}\\n')\n","\n","            # Train on Df data\n","            print('Training on Df data...')\n","            df_model = train_only(x_df, y_df, dataset, num_epochs=num_epochs, augment=True)\n","\n","            for domain in range(config[dataset]['num_df_domains'], config[dataset]['num_df_domains'] + config[dataset]['num_dp_domains']):\n","                print(f\"Domain: {domain}\")\n","\n","                # Load Dp data\n","                x_dp_dom, y_dp_dom, k_dp_dom = get_data(dataset, 'dp', src_class, domain)\n","                print(f'x_dp_dom.shape: {x_dp_dom.shape} | np.unique(y_dp_dom): {np.unique(y_dp_dom)}\\n')\n","\n","                # Evaluate on Dp data\n","                acc, loss, f1 = evaluate_model(df_model, get_dataloader(x_dp_dom, y_dp_dom))\n","                save_scores(src_class, domain, acc, loss, f1, 'Df_aug', dataset)\n","                accs_run.append(acc)\n","                f1s_run.append(f1)\n","                print(f'Source class: {src_class} | Domain: {domain} | Accuracy: {acc:.4f} | Loss: {loss:.4f} | F1: {f1:.4f}\\n')\n","\n","        print(f\"Mean accuracy for run {i}: {np.mean(accs_run):.4f}\")\n","        print(f\"Mean F1 for run {i}: {np.mean(f1s_run):.4f}\\n\")\n","        accs.append(np.mean(accs_run))\n","        f1s.append(np.mean(f1s_run))\n","\n","    print(f\"Mean accuracy over {num_runs} runs: {np.mean(accs):.4f} +- {np.std(accs):.4f}\")\n","    print(f\"Mean F1 over {num_runs} runs: {np.mean(f1s):.4f} +- {np.std(f1s):.4f}\\n\")\n","\n","\n","\n","\n","compute_TSTR_Df_aug('mobiact_realworld')"]},{"cell_type":"code","execution_count":9,"metadata":{"executionInfo":{"elapsed":30,"status":"ok","timestamp":1732703535262,"user":{"displayName":"Pietro Castelvetri","userId":"04218697278633758016"},"user_tz":-60},"id":"aDSS4eIiUHeq"},"outputs":[],"source":["# def compute_TSTR_Df_rot(dataset):\n","#     accs = []\n","#     f1s = []\n","\n","#     for i in range(num_runs):\n","\n","#         accs_run = []\n","#         f1s_run = []\n","\n","#         for src_class in config[dataset]['class_names']:\n","#             if src_class != 'WAL':\n","#                 continue\n","\n","#             print(f\"Source class: {src_class}\\n\")\n","\n","#             # Load Df data\n","#             x_df, y_df, k_df = get_data(dataset, 'df', src_class, rot=True)\n","#             print(f'x_df.shape: {x_df.shape} | np.unique(y_df): {np.unique(y_df)}\\n')\n","\n","#             # Train on Df data\n","#             print('Training on Df data...')\n","#             df_model = train_only(x_df, y_df, dataset, num_epochs=num_epochs)\n","\n","#             for domain in range(config[dataset]['num_df_domains'], config[dataset]['num_df_domains'] + config[dataset]['num_dp_domains']):\n","#                 print(f\"Domain: {domain}\")\n","\n","#                 # Load Dp data\n","#                 x_dp_dom, y_dp_dom, k_dp_dom = get_data(dataset, 'dp', src_class, domain)\n","#                 print(f'x_dp_dom.shape: {x_dp_dom.shape} | np.unique(y_dp_dom): {np.unique(y_dp_dom)}\\n')\n","\n","#                 # Evaluate on Dp data\n","#                 acc, loss, f1 = evaluate_model(df_model, get_dataloader(x_dp_dom, y_dp_dom))\n","#                 save_scores(src_class, domain, acc, loss, f1, 'Df_rot', dataset)\n","#                 accs_run.append(acc)\n","#                 f1s_run.append(f1)\n","#                 print(f'Source class: {src_class} | Domain: {domain} | Accuracy: {acc:.4f} | Loss: {loss:.4f} | F1: {f1:.4f}\\n')\n","\n","#         print(f\"Mean accuracy for run {i}: {np.mean(accs_run):.4f}\")\n","#         print(f\"Mean F1 for run {i}: {np.mean(f1s_run):.4f}\\n\")\n","#         accs.append(np.mean(accs_run))\n","#         f1s.append(np.mean(f1s_run))\n","\n","#     print(f\"Mean accuracy over {num_runs} runs: {np.mean(accs):.4f} +- {np.std(accs):.4f}\")\n","#     print(f\"Mean F1 over {num_runs} runs: {np.mean(f1s):.4f} +- {np.std(f1s):.4f}\\n\")\n","\n","\n","\n","\n","# compute_TSTR_Df_rot('mobiact_realworld')"]},{"cell_type":"code","execution_count":10,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":370702,"status":"ok","timestamp":1732703905936,"user":{"displayName":"Pietro Castelvetri","userId":"04218697278633758016"},"user_tz":-60},"id":"SmGQm1ZFCPto","outputId":"c0383541-29e1-4419-d140-1f75be295f6d"},"outputs":[{"output_type":"stream","name":"stdout","text":["Source class: WAL\n","\n","Domain: 61\n","x_syn_dom.shape: (928, 3, 128) | np.unique(y_syn_dom): [0 1 2 3]\n","x_dp_dom.shape: (855, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","x_syn_dom.shape: (812, 3, 128) | np.unique(y_syn_dom): [0 1 2 3]\n","x_dp_dom.shape: (739, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Training on synthetic data...\n","\tEpoch 10/100 - Train loss: 0.0177 - Val accuracy: 1.0000 - Val loss: 0.0137 - Val F1: 1.0000 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.0046 - Val accuracy: 1.0000 - Val loss: 0.0035 - Val F1: 1.0000 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.0013 - Val accuracy: 1.0000 - Val loss: 0.0019 - Val F1: 1.0000 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.0007 - Val accuracy: 1.0000 - Val loss: 0.0012 - Val F1: 1.0000 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.0010 - Val accuracy: 1.0000 - Val loss: 0.0011 - Val F1: 1.0000 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.0005 - Val accuracy: 1.0000 - Val loss: 0.0009 - Val F1: 1.0000 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0005 - Val accuracy: 1.0000 - Val loss: 0.0006 - Val F1: 1.0000 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0002 - Val accuracy: 1.0000 - Val loss: 0.0005 - Val F1: 1.0000 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0002 - Val accuracy: 1.0000 - Val loss: 0.0006 - Val F1: 1.0000 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0002 - Val accuracy: 1.0000 - Val loss: 0.0006 - Val F1: 1.0000 - LR: 0.00e+00\n","\tBest epoch: 92 - Best val accuracy: 1.0000 - Best val loss: 0.0004 - Best val F1: 1.0000\n","\n","Source class: WAL | Domain: 61 | Accuracy: 0.3762 | Loss: 4.4189 | F1: 0.3366\n","\n","Domain: 62\n","x_syn_dom.shape: (888, 3, 128) | np.unique(y_syn_dom): [0 1 2 3]\n","x_dp_dom.shape: (780, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","x_syn_dom.shape: (777, 3, 128) | np.unique(y_syn_dom): [0 1 2 3]\n","x_dp_dom.shape: (669, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Training on synthetic data...\n","\tEpoch 10/100 - Train loss: 0.0228 - Val accuracy: 0.9936 - Val loss: 0.0487 - Val F1: 0.9936 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.0055 - Val accuracy: 0.9936 - Val loss: 0.0404 - Val F1: 0.9936 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.0015 - Val accuracy: 0.9936 - Val loss: 0.0449 - Val F1: 0.9936 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.0021 - Val accuracy: 0.9936 - Val loss: 0.0448 - Val F1: 0.9936 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.0008 - Val accuracy: 0.9936 - Val loss: 0.0442 - Val F1: 0.9936 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.0011 - Val accuracy: 0.9936 - Val loss: 0.0439 - Val F1: 0.9936 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0004 - Val accuracy: 0.9936 - Val loss: 0.0450 - Val F1: 0.9936 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0002 - Val accuracy: 0.9936 - Val loss: 0.0461 - Val F1: 0.9936 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0003 - Val accuracy: 0.9936 - Val loss: 0.0485 - Val F1: 0.9936 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0013 - Val accuracy: 0.9872 - Val loss: 0.0513 - Val F1: 0.9872 - LR: 0.00e+00\n","\tBest epoch: 14 - Best val accuracy: 0.9936 - Best val loss: 0.0363 - Best val F1: 0.9936\n","\n","Source class: WAL | Domain: 62 | Accuracy: 0.5725 | Loss: 2.7356 | F1: 0.5264\n","\n","Domain: 63\n","x_syn_dom.shape: (996, 3, 128) | np.unique(y_syn_dom): [0 1 2 3]\n","x_dp_dom.shape: (859, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","x_syn_dom.shape: (871, 3, 128) | np.unique(y_syn_dom): [0 1 2 3]\n","x_dp_dom.shape: (735, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Training on synthetic data...\n","\tEpoch 10/100 - Train loss: 0.0102 - Val accuracy: 1.0000 - Val loss: 0.0049 - Val F1: 1.0000 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.0040 - Val accuracy: 1.0000 - Val loss: 0.0011 - Val F1: 1.0000 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.0011 - Val accuracy: 1.0000 - Val loss: 0.0005 - Val F1: 1.0000 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.0005 - Val accuracy: 1.0000 - Val loss: 0.0003 - Val F1: 1.0000 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.0004 - Val accuracy: 1.0000 - Val loss: 0.0002 - Val F1: 1.0000 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.0002 - Val accuracy: 1.0000 - Val loss: 0.0002 - Val F1: 1.0000 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0002 - Val accuracy: 1.0000 - Val loss: 0.0001 - Val F1: 1.0000 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0002 - Val accuracy: 1.0000 - Val loss: 0.0002 - Val F1: 1.0000 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0002 - Val accuracy: 1.0000 - Val loss: 0.0001 - Val F1: 1.0000 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0001 - Val accuracy: 1.0000 - Val loss: 0.0001 - Val F1: 1.0000 - LR: 0.00e+00\n","\tBest epoch: 94 - Best val accuracy: 1.0000 - Best val loss: 0.0001 - Best val F1: 1.0000\n","\n","Source class: WAL | Domain: 63 | Accuracy: 0.4626 | Loss: 4.3571 | F1: 0.3748\n","\n","Domain: 64\n","x_syn_dom.shape: (896, 3, 128) | np.unique(y_syn_dom): [0 1 2 3]\n","x_dp_dom.shape: (481, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","x_syn_dom.shape: (784, 3, 128) | np.unique(y_syn_dom): [0 1 2 3]\n","x_dp_dom.shape: (369, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Training on synthetic data...\n","\tEpoch 10/100 - Train loss: 0.0214 - Val accuracy: 0.9873 - Val loss: 0.1544 - Val F1: 0.9873 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.0044 - Val accuracy: 0.9873 - Val loss: 0.1598 - Val F1: 0.9873 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.0024 - Val accuracy: 0.9873 - Val loss: 0.1459 - Val F1: 0.9873 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.0008 - Val accuracy: 0.9873 - Val loss: 0.1622 - Val F1: 0.9873 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.0009 - Val accuracy: 0.9873 - Val loss: 0.1826 - Val F1: 0.9873 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.0008 - Val accuracy: 0.9873 - Val loss: 0.1776 - Val F1: 0.9873 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0003 - Val accuracy: 0.9873 - Val loss: 0.1782 - Val F1: 0.9873 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0003 - Val accuracy: 0.9873 - Val loss: 0.1897 - Val F1: 0.9873 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0003 - Val accuracy: 0.9873 - Val loss: 0.1779 - Val F1: 0.9873 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0003 - Val accuracy: 0.9873 - Val loss: 0.1609 - Val F1: 0.9873 - LR: 0.00e+00\n","\tBest epoch: 29 - Best val accuracy: 0.9873 - Best val loss: 0.1363 - Best val F1: 0.9873\n","\n","Source class: WAL | Domain: 64 | Accuracy: 0.7751 | Loss: 1.5995 | F1: 0.7601\n","\n","Domain: 65\n","x_syn_dom.shape: (1016, 3, 128) | np.unique(y_syn_dom): [0 1 2 3]\n","x_dp_dom.shape: (840, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","x_syn_dom.shape: (889, 3, 128) | np.unique(y_syn_dom): [0 1 2 3]\n","x_dp_dom.shape: (713, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Training on synthetic data...\n","\tEpoch 10/100 - Train loss: 0.0271 - Val accuracy: 1.0000 - Val loss: 0.0096 - Val F1: 1.0000 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.0039 - Val accuracy: 1.0000 - Val loss: 0.0024 - Val F1: 1.0000 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.0024 - Val accuracy: 1.0000 - Val loss: 0.0010 - Val F1: 1.0000 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.0015 - Val accuracy: 1.0000 - Val loss: 0.0012 - Val F1: 1.0000 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.0004 - Val accuracy: 1.0000 - Val loss: 0.0008 - Val F1: 1.0000 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.0007 - Val accuracy: 1.0000 - Val loss: 0.0005 - Val F1: 1.0000 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0003 - Val accuracy: 1.0000 - Val loss: 0.0007 - Val F1: 1.0000 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0003 - Val accuracy: 1.0000 - Val loss: 0.0005 - Val F1: 1.0000 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0002 - Val accuracy: 1.0000 - Val loss: 0.0004 - Val F1: 1.0000 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0002 - Val accuracy: 1.0000 - Val loss: 0.0006 - Val F1: 1.0000 - LR: 0.00e+00\n","\tBest epoch: 83 - Best val accuracy: 1.0000 - Best val loss: 0.0004 - Best val F1: 1.0000\n","\n","Source class: WAL | Domain: 65 | Accuracy: 0.5091 | Loss: 2.8936 | F1: 0.4419\n","\n","Domain: 66\n","x_syn_dom.shape: (916, 3, 128) | np.unique(y_syn_dom): [0 1 2 3]\n","x_dp_dom.shape: (792, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","x_syn_dom.shape: (801, 3, 128) | np.unique(y_syn_dom): [0 1 2 3]\n","x_dp_dom.shape: (678, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Training on synthetic data...\n","\tEpoch 10/100 - Train loss: 0.0194 - Val accuracy: 1.0000 - Val loss: 0.0193 - Val F1: 1.0000 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.0024 - Val accuracy: 1.0000 - Val loss: 0.0051 - Val F1: 1.0000 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.0012 - Val accuracy: 1.0000 - Val loss: 0.0021 - Val F1: 1.0000 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.0006 - Val accuracy: 1.0000 - Val loss: 0.0021 - Val F1: 1.0000 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.0005 - Val accuracy: 1.0000 - Val loss: 0.0018 - Val F1: 1.0000 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.0003 - Val accuracy: 1.0000 - Val loss: 0.0011 - Val F1: 1.0000 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0003 - Val accuracy: 1.0000 - Val loss: 0.0009 - Val F1: 1.0000 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0002 - Val accuracy: 1.0000 - Val loss: 0.0006 - Val F1: 1.0000 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0002 - Val accuracy: 1.0000 - Val loss: 0.0011 - Val F1: 1.0000 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0002 - Val accuracy: 1.0000 - Val loss: 0.0012 - Val F1: 1.0000 - LR: 0.00e+00\n","\tBest epoch: 80 - Best val accuracy: 1.0000 - Best val loss: 0.0006 - Best val F1: 1.0000\n","\n","Source class: WAL | Domain: 66 | Accuracy: 0.5162 | Loss: 3.9023 | F1: 0.4291\n","\n","Domain: 67\n","x_syn_dom.shape: (892, 3, 128) | np.unique(y_syn_dom): [0 1 2 3]\n","x_dp_dom.shape: (572, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","x_syn_dom.shape: (780, 3, 128) | np.unique(y_syn_dom): [0 1 2 3]\n","x_dp_dom.shape: (461, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Training on synthetic data...\n","\tEpoch 10/100 - Train loss: 0.0216 - Val accuracy: 1.0000 - Val loss: 0.0143 - Val F1: 1.0000 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.0095 - Val accuracy: 1.0000 - Val loss: 0.0061 - Val F1: 1.0000 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.0042 - Val accuracy: 1.0000 - Val loss: 0.0030 - Val F1: 1.0000 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.0023 - Val accuracy: 1.0000 - Val loss: 0.0027 - Val F1: 1.0000 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.0016 - Val accuracy: 1.0000 - Val loss: 0.0026 - Val F1: 1.0000 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.0007 - Val accuracy: 1.0000 - Val loss: 0.0018 - Val F1: 1.0000 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0007 - Val accuracy: 1.0000 - Val loss: 0.0018 - Val F1: 1.0000 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0005 - Val accuracy: 1.0000 - Val loss: 0.0013 - Val F1: 1.0000 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0005 - Val accuracy: 1.0000 - Val loss: 0.0010 - Val F1: 1.0000 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0004 - Val accuracy: 1.0000 - Val loss: 0.0015 - Val F1: 1.0000 - LR: 0.00e+00\n","\tBest epoch: 88 - Best val accuracy: 1.0000 - Best val loss: 0.0009 - Best val F1: 1.0000\n","\n","Source class: WAL | Domain: 67 | Accuracy: 0.8764 | Loss: 0.6965 | F1: 0.8397\n","\n","Domain: 68\n","x_syn_dom.shape: (956, 3, 128) | np.unique(y_syn_dom): [0 1 2 3]\n","x_dp_dom.shape: (877, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","x_syn_dom.shape: (836, 3, 128) | np.unique(y_syn_dom): [0 1 2 3]\n","x_dp_dom.shape: (758, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Training on synthetic data...\n","\tEpoch 10/100 - Train loss: 0.0160 - Val accuracy: 1.0000 - Val loss: 0.0092 - Val F1: 1.0000 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.0025 - Val accuracy: 1.0000 - Val loss: 0.0020 - Val F1: 1.0000 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.0011 - Val accuracy: 1.0000 - Val loss: 0.0008 - Val F1: 1.0000 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.0005 - Val accuracy: 1.0000 - Val loss: 0.0006 - Val F1: 1.0000 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.0004 - Val accuracy: 1.0000 - Val loss: 0.0003 - Val F1: 1.0000 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.0002 - Val accuracy: 1.0000 - Val loss: 0.0004 - Val F1: 1.0000 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0002 - Val accuracy: 1.0000 - Val loss: 0.0003 - Val F1: 1.0000 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0003 - Val accuracy: 1.0000 - Val loss: 0.0002 - Val F1: 1.0000 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0001 - Val accuracy: 1.0000 - Val loss: 0.0002 - Val F1: 1.0000 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0002 - Val accuracy: 1.0000 - Val loss: 0.0002 - Val F1: 1.0000 - LR: 0.00e+00\n","\tBest epoch: 98 - Best val accuracy: 1.0000 - Best val loss: 0.0002 - Best val F1: 1.0000\n","\n","Source class: WAL | Domain: 68 | Accuracy: 0.4591 | Loss: 4.1291 | F1: 0.3556\n","\n","Domain: 69\n","x_syn_dom.shape: (908, 3, 128) | np.unique(y_syn_dom): [0 1 2 3]\n","x_dp_dom.shape: (799, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","x_syn_dom.shape: (794, 3, 128) | np.unique(y_syn_dom): [0 1 2 3]\n","x_dp_dom.shape: (686, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Training on synthetic data...\n","\tEpoch 10/100 - Train loss: 0.0220 - Val accuracy: 1.0000 - Val loss: 0.0181 - Val F1: 1.0000 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.0041 - Val accuracy: 1.0000 - Val loss: 0.0053 - Val F1: 1.0000 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.0022 - Val accuracy: 1.0000 - Val loss: 0.0025 - Val F1: 1.0000 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.0013 - Val accuracy: 1.0000 - Val loss: 0.0016 - Val F1: 1.0000 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.0007 - Val accuracy: 1.0000 - Val loss: 0.0019 - Val F1: 1.0000 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.0006 - Val accuracy: 1.0000 - Val loss: 0.0014 - Val F1: 1.0000 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0004 - Val accuracy: 1.0000 - Val loss: 0.0013 - Val F1: 1.0000 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0004 - Val accuracy: 1.0000 - Val loss: 0.0014 - Val F1: 1.0000 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0003 - Val accuracy: 1.0000 - Val loss: 0.0008 - Val F1: 1.0000 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0004 - Val accuracy: 1.0000 - Val loss: 0.0010 - Val F1: 1.0000 - LR: 0.00e+00\n","\tBest epoch: 88 - Best val accuracy: 1.0000 - Best val loss: 0.0007 - Best val F1: 1.0000\n","\n","Source class: WAL | Domain: 69 | Accuracy: 0.5671 | Loss: 2.4814 | F1: 0.5113\n","\n","Domain: 70\n","x_syn_dom.shape: (920, 3, 128) | np.unique(y_syn_dom): [0 1 2 3]\n","x_dp_dom.shape: (762, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","x_syn_dom.shape: (805, 3, 128) | np.unique(y_syn_dom): [0 1 2 3]\n","x_dp_dom.shape: (647, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Training on synthetic data...\n","\tEpoch 10/100 - Train loss: 0.0149 - Val accuracy: 1.0000 - Val loss: 0.0149 - Val F1: 1.0000 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.0036 - Val accuracy: 1.0000 - Val loss: 0.0032 - Val F1: 1.0000 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.0014 - Val accuracy: 1.0000 - Val loss: 0.0015 - Val F1: 1.0000 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.0007 - Val accuracy: 1.0000 - Val loss: 0.0009 - Val F1: 1.0000 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.0005 - Val accuracy: 1.0000 - Val loss: 0.0006 - Val F1: 1.0000 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.0004 - Val accuracy: 1.0000 - Val loss: 0.0004 - Val F1: 1.0000 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0003 - Val accuracy: 1.0000 - Val loss: 0.0004 - Val F1: 1.0000 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0002 - Val accuracy: 1.0000 - Val loss: 0.0004 - Val F1: 1.0000 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0002 - Val accuracy: 1.0000 - Val loss: 0.0004 - Val F1: 1.0000 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0002 - Val accuracy: 1.0000 - Val loss: 0.0003 - Val F1: 1.0000 - LR: 0.00e+00\n","\tBest epoch: 93 - Best val accuracy: 1.0000 - Best val loss: 0.0003 - Best val F1: 1.0000\n","\n","Source class: WAL | Domain: 70 | Accuracy: 0.5348 | Loss: 4.6355 | F1: 0.4114\n","\n","Domain: 71\n","x_syn_dom.shape: (968, 3, 128) | np.unique(y_syn_dom): [0 1 2 3]\n","x_dp_dom.shape: (854, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","x_syn_dom.shape: (847, 3, 128) | np.unique(y_syn_dom): [0 1 2 3]\n","x_dp_dom.shape: (733, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Training on synthetic data...\n","\tEpoch 10/100 - Train loss: 0.0189 - Val accuracy: 1.0000 - Val loss: 0.0176 - Val F1: 1.0000 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.0036 - Val accuracy: 1.0000 - Val loss: 0.0063 - Val F1: 1.0000 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.0012 - Val accuracy: 1.0000 - Val loss: 0.0034 - Val F1: 1.0000 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.0007 - Val accuracy: 1.0000 - Val loss: 0.0027 - Val F1: 1.0000 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.0008 - Val accuracy: 1.0000 - Val loss: 0.0028 - Val F1: 1.0000 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.0005 - Val accuracy: 1.0000 - Val loss: 0.0022 - Val F1: 1.0000 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0004 - Val accuracy: 1.0000 - Val loss: 0.0011 - Val F1: 1.0000 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0003 - Val accuracy: 1.0000 - Val loss: 0.0015 - Val F1: 1.0000 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0002 - Val accuracy: 1.0000 - Val loss: 0.0013 - Val F1: 1.0000 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0003 - Val accuracy: 1.0000 - Val loss: 0.0016 - Val F1: 1.0000 - LR: 0.00e+00\n","\tBest epoch: 75 - Best val accuracy: 1.0000 - Best val loss: 0.0010 - Best val F1: 1.0000\n","\n","Source class: WAL | Domain: 71 | Accuracy: 0.5853 | Loss: 2.1581 | F1: 0.5498\n","\n","Domain: 72\n","x_syn_dom.shape: (920, 3, 128) | np.unique(y_syn_dom): [0 1 2 3]\n","x_dp_dom.shape: (811, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","x_syn_dom.shape: (805, 3, 128) | np.unique(y_syn_dom): [0 1 2 3]\n","x_dp_dom.shape: (696, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Training on synthetic data...\n","\tEpoch 10/100 - Train loss: 0.0137 - Val accuracy: 0.9938 - Val loss: 0.0196 - Val F1: 0.9938 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.0031 - Val accuracy: 0.9938 - Val loss: 0.0084 - Val F1: 0.9938 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.0015 - Val accuracy: 1.0000 - Val loss: 0.0050 - Val F1: 1.0000 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.0009 - Val accuracy: 1.0000 - Val loss: 0.0021 - Val F1: 1.0000 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.0004 - Val accuracy: 1.0000 - Val loss: 0.0022 - Val F1: 1.0000 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.0003 - Val accuracy: 1.0000 - Val loss: 0.0023 - Val F1: 1.0000 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0003 - Val accuracy: 1.0000 - Val loss: 0.0013 - Val F1: 1.0000 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0002 - Val accuracy: 1.0000 - Val loss: 0.0017 - Val F1: 1.0000 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0002 - Val accuracy: 1.0000 - Val loss: 0.0026 - Val F1: 1.0000 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0002 - Val accuracy: 1.0000 - Val loss: 0.0018 - Val F1: 1.0000 - LR: 0.00e+00\n","\tBest epoch: 65 - Best val accuracy: 1.0000 - Best val loss: 0.0009 - Best val F1: 1.0000\n","\n","Source class: WAL | Domain: 72 | Accuracy: 0.4856 | Loss: 4.5919 | F1: 0.3893\n","\n","Domain: 73\n","x_syn_dom.shape: (952, 3, 128) | np.unique(y_syn_dom): [0 1 2 3]\n","x_dp_dom.shape: (815, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","x_syn_dom.shape: (833, 3, 128) | np.unique(y_syn_dom): [0 1 2 3]\n","x_dp_dom.shape: (696, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Training on synthetic data...\n","\tEpoch 10/100 - Train loss: 0.0178 - Val accuracy: 0.9940 - Val loss: 0.0197 - Val F1: 0.9940 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.0043 - Val accuracy: 1.0000 - Val loss: 0.0081 - Val F1: 1.0000 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.0015 - Val accuracy: 0.9940 - Val loss: 0.0060 - Val F1: 0.9940 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.0007 - Val accuracy: 1.0000 - Val loss: 0.0052 - Val F1: 1.0000 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.0005 - Val accuracy: 0.9940 - Val loss: 0.0059 - Val F1: 0.9940 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.0004 - Val accuracy: 0.9940 - Val loss: 0.0053 - Val F1: 0.9940 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0003 - Val accuracy: 1.0000 - Val loss: 0.0043 - Val F1: 1.0000 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0002 - Val accuracy: 1.0000 - Val loss: 0.0046 - Val F1: 1.0000 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0003 - Val accuracy: 1.0000 - Val loss: 0.0043 - Val F1: 1.0000 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0002 - Val accuracy: 1.0000 - Val loss: 0.0031 - Val F1: 1.0000 - LR: 0.00e+00\n","\tBest epoch: 86 - Best val accuracy: 1.0000 - Best val loss: 0.0031 - Best val F1: 1.0000\n","\n","Source class: WAL | Domain: 73 | Accuracy: 0.4885 | Loss: 5.3797 | F1: 0.3904\n","\n","Domain: 74\n","x_syn_dom.shape: (976, 3, 128) | np.unique(y_syn_dom): [0 1 2 3]\n","x_dp_dom.shape: (563, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","x_syn_dom.shape: (854, 3, 128) | np.unique(y_syn_dom): [0 1 2 3]\n","x_dp_dom.shape: (441, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Training on synthetic data...\n","\tEpoch 10/100 - Train loss: 0.0132 - Val accuracy: 1.0000 - Val loss: 0.0082 - Val F1: 1.0000 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.0033 - Val accuracy: 1.0000 - Val loss: 0.0020 - Val F1: 1.0000 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.0033 - Val accuracy: 1.0000 - Val loss: 0.0014 - Val F1: 1.0000 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.0008 - Val accuracy: 1.0000 - Val loss: 0.0006 - Val F1: 1.0000 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.0004 - Val accuracy: 1.0000 - Val loss: 0.0006 - Val F1: 1.0000 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.0005 - Val accuracy: 1.0000 - Val loss: 0.0004 - Val F1: 1.0000 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0003 - Val accuracy: 1.0000 - Val loss: 0.0003 - Val F1: 1.0000 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0002 - Val accuracy: 1.0000 - Val loss: 0.0002 - Val F1: 1.0000 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0001 - Val accuracy: 1.0000 - Val loss: 0.0002 - Val F1: 1.0000 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0002 - Val accuracy: 1.0000 - Val loss: 0.0002 - Val F1: 1.0000 - LR: 0.00e+00\n","\tBest epoch: 95 - Best val accuracy: 1.0000 - Best val loss: 0.0002 - Best val F1: 1.0000\n","\n","Source class: WAL | Domain: 74 | Accuracy: 0.8639 | Loss: 0.8276 | F1: 0.8222\n","\n","Domain: 75\n","x_syn_dom.shape: (968, 3, 128) | np.unique(y_syn_dom): [0 1 2 3]\n","x_dp_dom.shape: (823, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","x_syn_dom.shape: (847, 3, 128) | np.unique(y_syn_dom): [0 1 2 3]\n","x_dp_dom.shape: (702, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Training on synthetic data...\n","\tEpoch 10/100 - Train loss: 0.0097 - Val accuracy: 1.0000 - Val loss: 0.0073 - Val F1: 1.0000 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.0019 - Val accuracy: 1.0000 - Val loss: 0.0020 - Val F1: 1.0000 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.0010 - Val accuracy: 1.0000 - Val loss: 0.0010 - Val F1: 1.0000 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.0007 - Val accuracy: 1.0000 - Val loss: 0.0007 - Val F1: 1.0000 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.0003 - Val accuracy: 1.0000 - Val loss: 0.0003 - Val F1: 1.0000 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.0004 - Val accuracy: 1.0000 - Val loss: 0.0006 - Val F1: 1.0000 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0033 - Val accuracy: 1.0000 - Val loss: 0.0003 - Val F1: 1.0000 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0002 - Val accuracy: 1.0000 - Val loss: 0.0002 - Val F1: 1.0000 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0012 - Val accuracy: 1.0000 - Val loss: 0.0002 - Val F1: 1.0000 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0001 - Val accuracy: 1.0000 - Val loss: 0.0002 - Val F1: 1.0000 - LR: 0.00e+00\n","\tBest epoch: 97 - Best val accuracy: 1.0000 - Best val loss: 0.0001 - Best val F1: 1.0000\n","\n","Source class: WAL | Domain: 75 | Accuracy: 0.4872 | Loss: 4.5817 | F1: 0.4060\n","\n","Mean accuracy: 0.5706 +- 0.1443\n","Mean F1: 0.5030 +- 0.1638\n","\n"]}],"source":["def compute_TSTR_Syn(dataset):\n","    accs = []\n","    f1s = []\n","\n","    for src_class in config[dataset]['class_names']:\n","        if src_class != 'WAL':\n","            continue\n","\n","        print(f\"Source class: {src_class}\\n\")\n","\n","        for domain in range(config[dataset]['num_df_domains'], config[dataset]['num_df_domains'] + config[dataset]['num_dp_domains']):\n","            print(f\"Domain: {domain}\")\n","\n","            # Load synthetic data\n","            x_syn_dom, y_syn_dom, k_syn_dom = get_syn_data(dataset, syn_name, src_class, domain)\n","            print(f'x_syn_dom.shape: {x_syn_dom.shape} | np.unique(y_syn_dom): {np.unique(y_syn_dom)}')\n","\n","            # Load Dp data\n","            x_dp_dom, y_dp_dom, k_dp_dom = get_data(dataset, 'dp', src_class, domain)\n","            print(f'x_dp_dom.shape: {x_dp_dom.shape} | np.unique(y_dp_dom): {np.unique(y_dp_dom)}\\n')\n","\n","            y0_indices_syn = np.where(y_syn_dom == 0)[0]\n","            y0_indices_dp = np.where(y_dp_dom == 0)[0]\n","            assert np.array_equal(y0_indices_syn, y0_indices_dp), \"Labels do not match\"\n","            assert np.array_equal(y_syn_dom[y0_indices_syn], y_dp_dom[y0_indices_dp]), \"Labels do not match\"\n","\n","            y0_indices_train, y0_indices_test = train_test_split(y0_indices_syn, test_size=0.5, shuffle=True, random_state=seed)\n","\n","            x_syn_dom_y0, y_syn_dom_y0 = x_syn_dom[y0_indices_train], y_syn_dom[y0_indices_train]\n","            x_dp_dom_y0, y_dp_dom_y0 = x_dp_dom[y0_indices_test], y_dp_dom[y0_indices_test]\n","\n","            x_syn_dom = np.concatenate([x_syn_dom_y0, x_syn_dom[y_syn_dom != 0]])\n","            y_syn_dom = np.concatenate([y_syn_dom_y0, y_syn_dom[y_syn_dom != 0]])\n","            x_dp_dom = np.concatenate([x_dp_dom_y0, x_dp_dom[y_dp_dom != 0]])\n","            y_dp_dom = np.concatenate([y_dp_dom_y0, y_dp_dom[y_dp_dom != 0]])\n","\n","            print(f'x_syn_dom.shape: {x_syn_dom.shape} | np.unique(y_syn_dom): {np.unique(y_syn_dom)}')\n","            print(f'x_dp_dom.shape: {x_dp_dom.shape} | np.unique(y_dp_dom): {np.unique(y_dp_dom)}\\n')\n","\n","            # Train on synthetic data and evaluate on Dp data\n","            print('Training on synthetic data...')\n","            acc, loss, f1 = train_and_test(x_syn_dom, y_syn_dom, x_dp_dom, y_dp_dom, dataset, num_epochs=num_epochs)\n","            save_scores(src_class, domain, acc, loss, f1, 'Syn', dataset)\n","            accs.append(acc)\n","            f1s.append(f1)\n","            print(f'Source class: {src_class} | Domain: {domain} | Accuracy: {acc:.4f} | Loss: {loss:.4f} | F1: {f1:.4f}\\n')\n","\n","    print(f\"Mean accuracy: {np.mean(accs):.4f} +- {np.std(accs):.4f}\")\n","    print(f\"Mean F1: {np.mean(f1s):.4f} +- {np.std(f1s):.4f}\\n\")\n","\n","\n","\n","compute_TSTR_Syn('mobiact_realworld')"]},{"cell_type":"code","execution_count":11,"metadata":{"executionInfo":{"elapsed":451058,"status":"ok","timestamp":1732704356973,"user":{"displayName":"Pietro Castelvetri","userId":"04218697278633758016"},"user_tz":-60},"id":"iKHIjEk_0q0O","colab":{"base_uri":"https://localhost:8080/"},"outputId":"decb455c-847a-42e6-8b1f-2338b2249288"},"outputs":[{"output_type":"stream","name":"stdout","text":["Source class: WAL\n","\n","Domain: 61\n","x_syn_dom.shape: (928, 3, 128) | np.unique(y_syn_dom): [0 1 2 3]\n","x_dp_dom.shape: (855, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","x_syn_dom.shape: (812, 3, 128) | np.unique(y_syn_dom): [0 1 2 3]\n","x_dp_dom.shape: (739, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Training on synthetic data...\n","\tEpoch 10/100 - Train loss: 0.1360 - Val accuracy: 0.2883 - Val loss: 4.5407 - Val F1: 0.1291 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.0385 - Val accuracy: 0.2883 - Val loss: 7.8421 - Val F1: 0.1291 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.0098 - Val accuracy: 0.2883 - Val loss: 9.1583 - Val F1: 0.1291 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.0149 - Val accuracy: 0.2883 - Val loss: 8.7864 - Val F1: 0.1291 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.0166 - Val accuracy: 0.2883 - Val loss: 12.8057 - Val F1: 0.1291 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.0147 - Val accuracy: 0.2883 - Val loss: 11.0980 - Val F1: 0.1291 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0138 - Val accuracy: 0.2883 - Val loss: 10.9196 - Val F1: 0.1291 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0108 - Val accuracy: 0.2883 - Val loss: 12.3987 - Val F1: 0.1291 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0093 - Val accuracy: 0.2883 - Val loss: 12.2690 - Val F1: 0.1291 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0046 - Val accuracy: 0.2883 - Val loss: 10.3988 - Val F1: 0.1291 - LR: 0.00e+00\n","\tBest epoch: 1 - Best val accuracy: 0.2822 - Best val loss: 1.4457 - Best val F1: 0.1484\n","\n","Source class: WAL | Domain: 61 | Accuracy: 0.2923 | Loss: 10.9587 | F1: 0.1322\n","\n","Domain: 62\n","x_syn_dom.shape: (888, 3, 128) | np.unique(y_syn_dom): [0 1 2 3]\n","x_dp_dom.shape: (780, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","x_syn_dom.shape: (777, 3, 128) | np.unique(y_syn_dom): [0 1 2 3]\n","x_dp_dom.shape: (669, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Training on synthetic data...\n","\tEpoch 10/100 - Train loss: 0.1372 - Val accuracy: 0.2949 - Val loss: 3.8522 - Val F1: 0.1423 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.0602 - Val accuracy: 0.2949 - Val loss: 5.0746 - Val F1: 0.1423 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.0156 - Val accuracy: 0.2885 - Val loss: 4.5594 - Val F1: 0.1298 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.0154 - Val accuracy: 0.2885 - Val loss: 4.8555 - Val F1: 0.1298 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.0083 - Val accuracy: 0.2885 - Val loss: 3.3641 - Val F1: 0.1298 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.0091 - Val accuracy: 0.2949 - Val loss: 4.2025 - Val F1: 0.1423 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0081 - Val accuracy: 0.2885 - Val loss: 3.4198 - Val F1: 0.1298 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0067 - Val accuracy: 0.2885 - Val loss: 4.7532 - Val F1: 0.1298 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0070 - Val accuracy: 0.2949 - Val loss: 3.4446 - Val F1: 0.1430 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0058 - Val accuracy: 0.2949 - Val loss: 4.3898 - Val F1: 0.1423 - LR: 0.00e+00\n","\tBest epoch: 1 - Best val accuracy: 0.2821 - Best val loss: 1.3403 - Best val F1: 0.1402\n","\n","Source class: WAL | Domain: 62 | Accuracy: 0.3229 | Loss: 6.9166 | F1: 0.1576\n","\n","Domain: 63\n","x_syn_dom.shape: (996, 3, 128) | np.unique(y_syn_dom): [0 1 2 3]\n","x_dp_dom.shape: (859, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","x_syn_dom.shape: (871, 3, 128) | np.unique(y_syn_dom): [0 1 2 3]\n","x_dp_dom.shape: (735, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Training on synthetic data...\n","\tEpoch 10/100 - Train loss: 0.1148 - Val accuracy: 0.5714 - Val loss: 5.1177 - Val F1: 0.4490 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.0380 - Val accuracy: 0.5714 - Val loss: 6.2171 - Val F1: 0.4471 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.0221 - Val accuracy: 0.3200 - Val loss: 4.9234 - Val F1: 0.1904 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.0224 - Val accuracy: 0.2914 - Val loss: 6.3430 - Val F1: 0.1388 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.0128 - Val accuracy: 0.5600 - Val loss: 7.4181 - Val F1: 0.4110 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.0086 - Val accuracy: 0.4514 - Val loss: 6.3460 - Val F1: 0.3305 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0027 - Val accuracy: 0.3257 - Val loss: 5.9455 - Val F1: 0.1996 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0060 - Val accuracy: 0.3257 - Val loss: 8.2114 - Val F1: 0.2012 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0018 - Val accuracy: 0.5371 - Val loss: 6.2426 - Val F1: 0.3957 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0057 - Val accuracy: 0.3086 - Val loss: 7.7159 - Val F1: 0.1716 - LR: 0.00e+00\n","\tBest epoch: 1 - Best val accuracy: 0.2971 - Best val loss: 1.3538 - Best val F1: 0.1747\n","\n","Source class: WAL | Domain: 63 | Accuracy: 0.3388 | Loss: 8.6213 | F1: 0.2203\n","\n","Domain: 64\n","x_syn_dom.shape: (896, 3, 128) | np.unique(y_syn_dom): [0 1 2 3]\n","x_dp_dom.shape: (481, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","x_syn_dom.shape: (784, 3, 128) | np.unique(y_syn_dom): [0 1 2 3]\n","x_dp_dom.shape: (369, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Training on synthetic data...\n","\tEpoch 10/100 - Train loss: 0.0882 - Val accuracy: 0.2994 - Val loss: 4.1283 - Val F1: 0.1539 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.0306 - Val accuracy: 0.2994 - Val loss: 5.9578 - Val F1: 0.1539 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.0141 - Val accuracy: 0.2994 - Val loss: 7.3913 - Val F1: 0.1539 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.0184 - Val accuracy: 0.2994 - Val loss: 5.8633 - Val F1: 0.1539 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.0145 - Val accuracy: 0.3057 - Val loss: 4.6247 - Val F1: 0.1665 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.0062 - Val accuracy: 0.2994 - Val loss: 6.1739 - Val F1: 0.1539 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0050 - Val accuracy: 0.2994 - Val loss: 8.9127 - Val F1: 0.1539 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0075 - Val accuracy: 0.2994 - Val loss: 11.8338 - Val F1: 0.1539 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0041 - Val accuracy: 0.2994 - Val loss: 8.9195 - Val F1: 0.1539 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0049 - Val accuracy: 0.2994 - Val loss: 9.4812 - Val F1: 0.1539 - LR: 0.00e+00\n","\tBest epoch: 1 - Best val accuracy: 0.5669 - Best val loss: 1.0944 - Best val F1: 0.4573\n","\n","Source class: WAL | Domain: 64 | Accuracy: 0.3577 | Loss: 12.4810 | F1: 0.1885\n","\n","Domain: 65\n","x_syn_dom.shape: (1016, 3, 128) | np.unique(y_syn_dom): [0 1 2 3]\n","x_dp_dom.shape: (840, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","x_syn_dom.shape: (889, 3, 128) | np.unique(y_syn_dom): [0 1 2 3]\n","x_dp_dom.shape: (713, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Training on synthetic data...\n","\tEpoch 10/100 - Train loss: 0.1132 - Val accuracy: 0.2921 - Val loss: 3.4882 - Val F1: 0.1399 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.0407 - Val accuracy: 0.4888 - Val loss: 2.0305 - Val F1: 0.3726 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.0232 - Val accuracy: 0.5169 - Val loss: 2.1057 - Val F1: 0.4257 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.0186 - Val accuracy: 0.6966 - Val loss: 1.7333 - Val F1: 0.6460 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.0195 - Val accuracy: 0.4438 - Val loss: 2.0201 - Val F1: 0.3828 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.0121 - Val accuracy: 0.4888 - Val loss: 2.0797 - Val F1: 0.4406 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0069 - Val accuracy: 0.3315 - Val loss: 2.5982 - Val F1: 0.2124 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0195 - Val accuracy: 0.5225 - Val loss: 2.0828 - Val F1: 0.4776 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0075 - Val accuracy: 0.4101 - Val loss: 2.4828 - Val F1: 0.3323 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0032 - Val accuracy: 0.3034 - Val loss: 3.8185 - Val F1: 0.1620 - LR: 0.00e+00\n","\tBest epoch: 1 - Best val accuracy: 0.5281 - Best val loss: 1.1323 - Best val F1: 0.4211\n","\n","Source class: WAL | Domain: 65 | Accuracy: 0.2903 | Loss: 5.0687 | F1: 0.1455\n","\n","Domain: 66\n","x_syn_dom.shape: (916, 3, 128) | np.unique(y_syn_dom): [0 1 2 3]\n","x_dp_dom.shape: (792, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","x_syn_dom.shape: (801, 3, 128) | np.unique(y_syn_dom): [0 1 2 3]\n","x_dp_dom.shape: (678, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Training on synthetic data...\n","\tEpoch 10/100 - Train loss: 0.1545 - Val accuracy: 0.2857 - Val loss: 7.0063 - Val F1: 0.1270 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.0494 - Val accuracy: 0.2857 - Val loss: 8.5826 - Val F1: 0.1270 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.0344 - Val accuracy: 0.2857 - Val loss: 10.7124 - Val F1: 0.1270 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.0103 - Val accuracy: 0.2857 - Val loss: 11.4907 - Val F1: 0.1270 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.0121 - Val accuracy: 0.2857 - Val loss: 9.9524 - Val F1: 0.1270 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.0038 - Val accuracy: 0.2857 - Val loss: 11.7384 - Val F1: 0.1270 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0118 - Val accuracy: 0.2857 - Val loss: 12.7633 - Val F1: 0.1270 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0069 - Val accuracy: 0.2857 - Val loss: 8.9485 - Val F1: 0.1270 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0033 - Val accuracy: 0.2857 - Val loss: 8.9896 - Val F1: 0.1270 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0052 - Val accuracy: 0.2857 - Val loss: 9.1137 - Val F1: 0.1270 - LR: 0.00e+00\n","\tBest epoch: 1 - Best val accuracy: 0.5466 - Best val loss: 1.1248 - Best val F1: 0.4320\n","\n","Source class: WAL | Domain: 66 | Accuracy: 0.3186 | Loss: 12.1260 | F1: 0.1539\n","\n","Domain: 67\n","x_syn_dom.shape: (892, 3, 128) | np.unique(y_syn_dom): [0 1 2 3]\n","x_dp_dom.shape: (572, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","x_syn_dom.shape: (780, 3, 128) | np.unique(y_syn_dom): [0 1 2 3]\n","x_dp_dom.shape: (461, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Training on synthetic data...\n","\tEpoch 10/100 - Train loss: 0.1258 - Val accuracy: 0.5385 - Val loss: 1.3564 - Val F1: 0.5000 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.0675 - Val accuracy: 0.8590 - Val loss: 1.4162 - Val F1: 0.7963 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.0266 - Val accuracy: 0.8462 - Val loss: 1.7096 - Val F1: 0.7894 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.0249 - Val accuracy: 0.8526 - Val loss: 1.9448 - Val F1: 0.7940 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.0260 - Val accuracy: 0.8205 - Val loss: 2.0367 - Val F1: 0.7674 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.0091 - Val accuracy: 0.8269 - Val loss: 2.2169 - Val F1: 0.7742 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0087 - Val accuracy: 0.8205 - Val loss: 2.3028 - Val F1: 0.7662 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0150 - Val accuracy: 0.6859 - Val loss: 2.7374 - Val F1: 0.6337 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0158 - Val accuracy: 0.8526 - Val loss: 2.3237 - Val F1: 0.7959 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0115 - Val accuracy: 0.8462 - Val loss: 2.2475 - Val F1: 0.7894 - LR: 0.00e+00\n","\tBest epoch: 3 - Best val accuracy: 0.6731 - Best val loss: 0.8155 - Best val F1: 0.6356\n","\n","Source class: WAL | Domain: 67 | Accuracy: 0.6226 | Loss: 4.0119 | F1: 0.5224\n","\n","Domain: 68\n","x_syn_dom.shape: (956, 3, 128) | np.unique(y_syn_dom): [0 1 2 3]\n","x_dp_dom.shape: (877, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","x_syn_dom.shape: (836, 3, 128) | np.unique(y_syn_dom): [0 1 2 3]\n","x_dp_dom.shape: (758, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Training on synthetic data...\n","\tEpoch 10/100 - Train loss: 0.0888 - Val accuracy: 0.2857 - Val loss: 8.6402 - Val F1: 0.1270 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.0286 - Val accuracy: 0.2857 - Val loss: 8.6808 - Val F1: 0.1270 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.0065 - Val accuracy: 0.2857 - Val loss: 11.6536 - Val F1: 0.1270 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.0074 - Val accuracy: 0.2857 - Val loss: 10.3123 - Val F1: 0.1270 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.0058 - Val accuracy: 0.2857 - Val loss: 12.0143 - Val F1: 0.1270 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.0016 - Val accuracy: 0.2857 - Val loss: 14.0783 - Val F1: 0.1270 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0015 - Val accuracy: 0.2857 - Val loss: 14.5110 - Val F1: 0.1270 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0020 - Val accuracy: 0.2857 - Val loss: 14.5266 - Val F1: 0.1270 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0012 - Val accuracy: 0.2857 - Val loss: 13.5955 - Val F1: 0.1270 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0008 - Val accuracy: 0.2857 - Val loss: 12.9349 - Val F1: 0.1270 - LR: 0.00e+00\n","\tBest epoch: 1 - Best val accuracy: 0.2857 - Best val loss: 1.2440 - Best val F1: 0.1270\n","\n","Source class: WAL | Domain: 68 | Accuracy: 0.2876 | Loss: 13.1815 | F1: 0.1285\n","\n","Domain: 69\n","x_syn_dom.shape: (908, 3, 128) | np.unique(y_syn_dom): [0 1 2 3]\n","x_dp_dom.shape: (799, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","x_syn_dom.shape: (794, 3, 128) | np.unique(y_syn_dom): [0 1 2 3]\n","x_dp_dom.shape: (686, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Training on synthetic data...\n","\tEpoch 10/100 - Train loss: 0.0750 - Val accuracy: 0.2893 - Val loss: 4.8530 - Val F1: 0.1298 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.0278 - Val accuracy: 0.2893 - Val loss: 3.2029 - Val F1: 0.1298 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.0063 - Val accuracy: 0.2893 - Val loss: 3.6978 - Val F1: 0.1298 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.0044 - Val accuracy: 0.3899 - Val loss: 2.3270 - Val F1: 0.2893 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.0024 - Val accuracy: 0.3082 - Val loss: 2.9325 - Val F1: 0.1671 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.0020 - Val accuracy: 0.2893 - Val loss: 3.8285 - Val F1: 0.1298 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0020 - Val accuracy: 0.3019 - Val loss: 3.5290 - Val F1: 0.1552 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0023 - Val accuracy: 0.5094 - Val loss: 2.1862 - Val F1: 0.4042 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0014 - Val accuracy: 0.3019 - Val loss: 3.6983 - Val F1: 0.1552 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0022 - Val accuracy: 0.3019 - Val loss: 3.8894 - Val F1: 0.1552 - LR: 0.00e+00\n","\tBest epoch: 1 - Best val accuracy: 0.5723 - Best val loss: 1.1450 - Best val F1: 0.4484\n","\n","Source class: WAL | Domain: 69 | Accuracy: 0.3120 | Loss: 5.8852 | F1: 0.1538\n","\n","Domain: 70\n","x_syn_dom.shape: (920, 3, 128) | np.unique(y_syn_dom): [0 1 2 3]\n","x_dp_dom.shape: (762, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","x_syn_dom.shape: (805, 3, 128) | np.unique(y_syn_dom): [0 1 2 3]\n","x_dp_dom.shape: (647, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Training on synthetic data...\n","\tEpoch 10/100 - Train loss: 0.1182 - Val accuracy: 0.2857 - Val loss: 4.1339 - Val F1: 0.1270 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.0367 - Val accuracy: 0.4783 - Val loss: 2.5568 - Val F1: 0.3487 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.0108 - Val accuracy: 0.2857 - Val loss: 6.0109 - Val F1: 0.1270 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.0082 - Val accuracy: 0.2857 - Val loss: 6.2434 - Val F1: 0.1270 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.0036 - Val accuracy: 0.2857 - Val loss: 6.0476 - Val F1: 0.1270 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.0055 - Val accuracy: 0.2857 - Val loss: 4.9332 - Val F1: 0.1270 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0025 - Val accuracy: 0.2857 - Val loss: 5.7245 - Val F1: 0.1270 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0026 - Val accuracy: 0.2857 - Val loss: 5.3003 - Val F1: 0.1270 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0023 - Val accuracy: 0.2857 - Val loss: 5.8784 - Val F1: 0.1270 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0029 - Val accuracy: 0.2857 - Val loss: 5.8503 - Val F1: 0.1270 - LR: 0.00e+00\n","\tBest epoch: 1 - Best val accuracy: 0.5590 - Best val loss: 1.1546 - Best val F1: 0.5313\n","\n","Source class: WAL | Domain: 70 | Accuracy: 0.3539 | Loss: 8.5677 | F1: 0.1851\n","\n","Domain: 71\n","x_syn_dom.shape: (968, 3, 128) | np.unique(y_syn_dom): [0 1 2 3]\n","x_dp_dom.shape: (854, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","x_syn_dom.shape: (847, 3, 128) | np.unique(y_syn_dom): [0 1 2 3]\n","x_dp_dom.shape: (733, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Training on synthetic data...\n","\tEpoch 10/100 - Train loss: 0.1000 - Val accuracy: 0.2882 - Val loss: 4.8121 - Val F1: 0.1296 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.0198 - Val accuracy: 0.2882 - Val loss: 5.0851 - Val F1: 0.1296 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.0192 - Val accuracy: 0.2882 - Val loss: 6.0127 - Val F1: 0.1290 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.0065 - Val accuracy: 0.2882 - Val loss: 8.2072 - Val F1: 0.1290 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.0110 - Val accuracy: 0.2882 - Val loss: 8.1155 - Val F1: 0.1290 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.0058 - Val accuracy: 0.2941 - Val loss: 4.7903 - Val F1: 0.1415 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0022 - Val accuracy: 0.2882 - Val loss: 9.6741 - Val F1: 0.1290 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0046 - Val accuracy: 0.2882 - Val loss: 7.7754 - Val F1: 0.1290 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0039 - Val accuracy: 0.2882 - Val loss: 10.3764 - Val F1: 0.1290 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0058 - Val accuracy: 0.2882 - Val loss: 6.9803 - Val F1: 0.1290 - LR: 0.00e+00\n","\tBest epoch: 1 - Best val accuracy: 0.5529 - Best val loss: 1.1221 - Best val F1: 0.4383\n","\n","Source class: WAL | Domain: 71 | Accuracy: 0.3001 | Loss: 9.0867 | F1: 0.1386\n","\n","Domain: 72\n","x_syn_dom.shape: (920, 3, 128) | np.unique(y_syn_dom): [0 1 2 3]\n","x_dp_dom.shape: (811, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","x_syn_dom.shape: (805, 3, 128) | np.unique(y_syn_dom): [0 1 2 3]\n","x_dp_dom.shape: (696, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Training on synthetic data...\n","\tEpoch 10/100 - Train loss: 0.1325 - Val accuracy: 0.2857 - Val loss: 5.4579 - Val F1: 0.1270 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.0234 - Val accuracy: 0.2857 - Val loss: 6.3515 - Val F1: 0.1270 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.0117 - Val accuracy: 0.2857 - Val loss: 6.0872 - Val F1: 0.1270 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.0077 - Val accuracy: 0.2857 - Val loss: 6.8775 - Val F1: 0.1270 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.0093 - Val accuracy: 0.2857 - Val loss: 6.2833 - Val F1: 0.1270 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.0036 - Val accuracy: 0.2857 - Val loss: 7.7977 - Val F1: 0.1270 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0028 - Val accuracy: 0.2857 - Val loss: 8.1568 - Val F1: 0.1270 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0031 - Val accuracy: 0.2857 - Val loss: 5.3368 - Val F1: 0.1270 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0081 - Val accuracy: 0.2857 - Val loss: 6.9833 - Val F1: 0.1270 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0035 - Val accuracy: 0.2857 - Val loss: 8.0154 - Val F1: 0.1270 - LR: 0.00e+00\n","\tBest epoch: 1 - Best val accuracy: 0.7019 - Best val loss: 1.1212 - Best val F1: 0.6539\n","\n","Source class: WAL | Domain: 72 | Accuracy: 0.3147 | Loss: 9.6863 | F1: 0.1506\n","\n","Domain: 73\n","x_syn_dom.shape: (952, 3, 128) | np.unique(y_syn_dom): [0 1 2 3]\n","x_dp_dom.shape: (815, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","x_syn_dom.shape: (833, 3, 128) | np.unique(y_syn_dom): [0 1 2 3]\n","x_dp_dom.shape: (696, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Training on synthetic data...\n","\tEpoch 10/100 - Train loss: 0.1405 - Val accuracy: 0.4311 - Val loss: 1.7822 - Val F1: 0.3458 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.0497 - Val accuracy: 0.2874 - Val loss: 4.7059 - Val F1: 0.1283 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.0228 - Val accuracy: 0.2994 - Val loss: 3.8363 - Val F1: 0.1530 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.0122 - Val accuracy: 0.2934 - Val loss: 4.8431 - Val F1: 0.1407 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.0118 - Val accuracy: 0.3713 - Val loss: 3.3168 - Val F1: 0.2651 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.0061 - Val accuracy: 0.2934 - Val loss: 4.7813 - Val F1: 0.1407 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0087 - Val accuracy: 0.3234 - Val loss: 4.1740 - Val F1: 0.1952 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0028 - Val accuracy: 0.2934 - Val loss: 5.1985 - Val F1: 0.1407 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0037 - Val accuracy: 0.2934 - Val loss: 5.1215 - Val F1: 0.1407 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0032 - Val accuracy: 0.2934 - Val loss: 4.3502 - Val F1: 0.1410 - LR: 0.00e+00\n","\tBest epoch: 1 - Best val accuracy: 0.8024 - Best val loss: 0.9921 - Best val F1: 0.7449\n","\n","Source class: WAL | Domain: 73 | Accuracy: 0.3147 | Loss: 5.2965 | F1: 0.1508\n","\n","Domain: 74\n","x_syn_dom.shape: (976, 3, 128) | np.unique(y_syn_dom): [0 1 2 3]\n","x_dp_dom.shape: (563, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","x_syn_dom.shape: (854, 3, 128) | np.unique(y_syn_dom): [0 1 2 3]\n","x_dp_dom.shape: (441, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Training on synthetic data...\n","\tEpoch 10/100 - Train loss: 0.0709 - Val accuracy: 0.2865 - Val loss: 7.1905 - Val F1: 0.1276 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.0259 - Val accuracy: 0.2865 - Val loss: 9.1596 - Val F1: 0.1276 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.0151 - Val accuracy: 0.2865 - Val loss: 11.9739 - Val F1: 0.1276 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.0150 - Val accuracy: 0.2865 - Val loss: 6.9338 - Val F1: 0.1276 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.0052 - Val accuracy: 0.2865 - Val loss: 6.3123 - Val F1: 0.1276 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.0069 - Val accuracy: 0.2865 - Val loss: 8.2784 - Val F1: 0.1276 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0042 - Val accuracy: 0.2865 - Val loss: 8.8253 - Val F1: 0.1276 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0062 - Val accuracy: 0.2865 - Val loss: 7.5739 - Val F1: 0.1276 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0039 - Val accuracy: 0.2865 - Val loss: 8.0272 - Val F1: 0.1276 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0045 - Val accuracy: 0.2865 - Val loss: 7.4929 - Val F1: 0.1276 - LR: 0.00e+00\n","\tBest epoch: 1 - Best val accuracy: 0.5556 - Best val loss: 1.1449 - Best val F1: 0.4093\n","\n","Source class: WAL | Domain: 74 | Accuracy: 0.4989 | Loss: 7.3002 | F1: 0.3345\n","\n","Domain: 75\n","x_syn_dom.shape: (968, 3, 128) | np.unique(y_syn_dom): [0 1 2 3]\n","x_dp_dom.shape: (823, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","x_syn_dom.shape: (847, 3, 128) | np.unique(y_syn_dom): [0 1 2 3]\n","x_dp_dom.shape: (702, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Training on synthetic data...\n","\tEpoch 10/100 - Train loss: 0.0727 - Val accuracy: 0.5765 - Val loss: 5.1884 - Val F1: 0.4544 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.0267 - Val accuracy: 0.5765 - Val loss: 5.9284 - Val F1: 0.4506 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.0101 - Val accuracy: 0.5765 - Val loss: 8.3877 - Val F1: 0.4356 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.0029 - Val accuracy: 0.5765 - Val loss: 8.5552 - Val F1: 0.4488 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.0052 - Val accuracy: 0.5765 - Val loss: 7.3348 - Val F1: 0.4544 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.0048 - Val accuracy: 0.5765 - Val loss: 10.2700 - Val F1: 0.4408 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0012 - Val accuracy: 0.5706 - Val loss: 8.0031 - Val F1: 0.4275 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0020 - Val accuracy: 0.4529 - Val loss: 7.2485 - Val F1: 0.3253 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0039 - Val accuracy: 0.4000 - Val loss: 6.8395 - Val F1: 0.2783 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0019 - Val accuracy: 0.3529 - Val loss: 8.0433 - Val F1: 0.2333 - LR: 0.00e+00\n","\tBest epoch: 1 - Best val accuracy: 0.5647 - Best val loss: 1.0577 - Best val F1: 0.4465\n","\n","Source class: WAL | Domain: 75 | Accuracy: 0.2863 | Loss: 12.0187 | F1: 0.1285\n","\n","Mean accuracy: 0.3474 +- 0.0893\n","Mean F1: 0.1927 +- 0.1015\n","\n"]}],"source":["def compute_TSTR_Syn_aug(dataset):\n","    accs = []\n","    f1s = []\n","\n","    for src_class in config[dataset]['class_names']:\n","        if src_class != 'WAL':\n","            continue\n","\n","        print(f\"Source class: {src_class}\\n\")\n","\n","        for domain in range(config[dataset]['num_df_domains'], config[dataset]['num_df_domains'] + config[dataset]['num_dp_domains']):\n","            print(f\"Domain: {domain}\")\n","\n","            # Load synthetic data\n","            x_syn_dom, y_syn_dom, k_syn_dom = get_syn_data(dataset, syn_name, src_class, domain)\n","            print(f'x_syn_dom.shape: {x_syn_dom.shape} | np.unique(y_syn_dom): {np.unique(y_syn_dom)}')\n","\n","            # Load Dp data\n","            x_dp_dom, y_dp_dom, k_dp_dom = get_data(dataset, 'dp', src_class, domain)\n","            print(f'x_dp_dom.shape: {x_dp_dom.shape} | np.unique(y_dp_dom): {np.unique(y_dp_dom)}\\n')\n","\n","            y0_indices_syn = np.where(y_syn_dom == 0)[0]\n","            y0_indices_dp = np.where(y_dp_dom == 0)[0]\n","            assert np.array_equal(y0_indices_syn, y0_indices_dp), \"Labels do not match\"\n","            assert np.array_equal(y_syn_dom[y0_indices_syn], y_dp_dom[y0_indices_dp]), \"Labels do not match\"\n","\n","            y0_indices_train, y0_indices_test = train_test_split(y0_indices_syn, test_size=0.5, shuffle=True, random_state=seed)\n","\n","            x_syn_dom_y0, y_syn_dom_y0 = x_syn_dom[y0_indices_train], y_syn_dom[y0_indices_train]\n","            x_dp_dom_y0, y_dp_dom_y0 = x_dp_dom[y0_indices_test], y_dp_dom[y0_indices_test]\n","\n","            x_syn_dom = np.concatenate([x_syn_dom_y0, x_syn_dom[y_syn_dom != 0]])\n","            y_syn_dom = np.concatenate([y_syn_dom_y0, y_syn_dom[y_syn_dom != 0]])\n","            x_dp_dom = np.concatenate([x_dp_dom_y0, x_dp_dom[y_dp_dom != 0]])\n","            y_dp_dom = np.concatenate([y_dp_dom_y0, y_dp_dom[y_dp_dom != 0]])\n","\n","            print(f'x_syn_dom.shape: {x_syn_dom.shape} | np.unique(y_syn_dom): {np.unique(y_syn_dom)}')\n","            print(f'x_dp_dom.shape: {x_dp_dom.shape} | np.unique(y_dp_dom): {np.unique(y_dp_dom)}\\n')\n","\n","            # Train on synthetic data and evaluate on Dp data\n","            print('Training on synthetic data...')\n","            acc, loss, f1 = train_and_test(x_syn_dom, y_syn_dom, x_dp_dom, y_dp_dom, dataset, num_epochs=num_epochs, augment=True)\n","            save_scores(src_class, domain, acc, loss, f1, 'Syn_aug', dataset)\n","            accs.append(acc)\n","            f1s.append(f1)\n","            print(f'Source class: {src_class} | Domain: {domain} | Accuracy: {acc:.4f} | Loss: {loss:.4f} | F1: {f1:.4f}\\n')\n","\n","    print(f\"Mean accuracy: {np.mean(accs):.4f} +- {np.std(accs):.4f}\")\n","    print(f\"Mean F1: {np.mean(f1s):.4f} +- {np.std(f1s):.4f}\\n\")\n","\n","\n","\n","\n","compute_TSTR_Syn_aug('mobiact_realworld')"]},{"cell_type":"code","execution_count":12,"metadata":{"executionInfo":{"elapsed":27,"status":"ok","timestamp":1732704356974,"user":{"displayName":"Pietro Castelvetri","userId":"04218697278633758016"},"user_tz":-60},"id":"KKvjK_PAMxLm"},"outputs":[],"source":["# def compute_TSTR_Syn_all(dataset):\n","#     accs = []\n","\n","#     for src_class in config[dataset]['class_names']:\n","#         if src_class != 'WAL':\n","#             continue\n","\n","#         print(f\"Source class: {src_class}\\n\")\n","\n","#         # Load synthetic data\n","#         x_syn, y_syn, k_syn = get_syn_data(dataset, syn_name, src_class)\n","#         print(f'x_syn.shape: {x_syn.shape} | np.unique(y_syn): {np.unique(y_syn)}')\n","\n","#         # Load Dp data\n","#         x_dp, y_dp, k_dp = get_data(dataset, 'dp', src_class)\n","#         print(f'x_dp.shape: {x_dp.shape} | np.unique(y_dp): {np.unique(y_dp)}\\n')\n","\n","#         # Train on synthetic data and evaluate on Dp data\n","#         print('Training on synthetic data...')\n","#         acc, loss = train_and_test(x_syn, y_syn, x_dp, y_dp, dataset, num_epochs=num_epochs)\n","#         save_scores(src_class, 100, acc, loss, 'Syn_all', dataset)\n","#         accs.append(acc)\n","#         print(f'Source class: {src_class} | Domain: All | Accuracy: {acc:.4f} | Loss: {loss:.4f}\\n')\n","\n","#     print(f\"Mean accuracy: {np.mean(accs):.4f}\\n\")\n","\n","\n","\n","\n","# compute_TSTR_Syn_all('mobiact_realworld')"]},{"cell_type":"code","execution_count":13,"metadata":{"executionInfo":{"elapsed":328032,"status":"ok","timestamp":1732704684983,"user":{"displayName":"Pietro Castelvetri","userId":"04218697278633758016"},"user_tz":-60},"id":"LA71th1bCPto","colab":{"base_uri":"https://localhost:8080/"},"outputId":"4c7a1752-e271-44cb-8e3b-ec94ec86cbe9"},"outputs":[{"output_type":"stream","name":"stdout","text":["Source class: WAL\n","\n","x_df.shape: (10816, 3, 128) | np.unique(y_df): [0 1 2 3]\n","\n","Training on Df data...\n","\tEpoch 10/100 - Train loss: 0.0246 - Val accuracy: 0.9903 - Val loss: 0.0306 - Val F1: 0.9902 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.0056 - Val accuracy: 0.9931 - Val loss: 0.0219 - Val F1: 0.9930 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.0035 - Val accuracy: 0.9954 - Val loss: 0.0139 - Val F1: 0.9954 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.0006 - Val accuracy: 0.9958 - Val loss: 0.0126 - Val F1: 0.9958 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.0005 - Val accuracy: 0.9945 - Val loss: 0.0127 - Val F1: 0.9944 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.0007 - Val accuracy: 0.9963 - Val loss: 0.0134 - Val F1: 0.9963 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0009 - Val accuracy: 0.9954 - Val loss: 0.0123 - Val F1: 0.9953 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0003 - Val accuracy: 0.9968 - Val loss: 0.0105 - Val F1: 0.9967 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0002 - Val accuracy: 0.9972 - Val loss: 0.0105 - Val F1: 0.9972 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0001 - Val accuracy: 0.9977 - Val loss: 0.0079 - Val F1: 0.9977 - LR: 0.00e+00\n","\tBest epoch: 100 - Best val accuracy: 0.9977 - Best val loss: 0.0079 - Best val F1: 0.9977\n","\n","Domain: 61\n","x_syn_dom.shape: (928, 3, 128) | np.unique(y_syn_dom): [0 1 2 3]\n","x_dp_dom.shape: (855, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","x_syn_dom.shape: (812, 3, 128) | np.unique(y_syn_dom): [0 1 2 3]\n","x_dp_dom.shape: (739, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Fine-tuning on synthetic data...\n","\tEpoch 10/100 - Train loss: 1.0510 - Val accuracy: 0.7362 - Val loss: 0.7576 - Val F1: 0.7345 - LR: 9.00e-06\n","\tEpoch 20/100 - Train loss: 0.8265 - Val accuracy: 0.7669 - Val loss: 0.6050 - Val F1: 0.7667 - LR: 8.00e-06\n","\tEpoch 30/100 - Train loss: 0.7501 - Val accuracy: 0.8098 - Val loss: 0.5350 - Val F1: 0.8097 - LR: 7.00e-06\n","\tEpoch 40/100 - Train loss: 0.6609 - Val accuracy: 0.8160 - Val loss: 0.4584 - Val F1: 0.8156 - LR: 6.00e-06\n","\tEpoch 50/100 - Train loss: 0.6186 - Val accuracy: 0.8282 - Val loss: 0.4197 - Val F1: 0.8276 - LR: 5.00e-06\n","\tEpoch 60/100 - Train loss: 0.5691 - Val accuracy: 0.8405 - Val loss: 0.3912 - Val F1: 0.8402 - LR: 4.00e-06\n","\tEpoch 70/100 - Train loss: 0.5263 - Val accuracy: 0.8466 - Val loss: 0.3885 - Val F1: 0.8446 - LR: 3.00e-06\n","\tEpoch 80/100 - Train loss: 0.5448 - Val accuracy: 0.8405 - Val loss: 0.3540 - Val F1: 0.8402 - LR: 2.00e-06\n","\tEpoch 90/100 - Train loss: 0.5209 - Val accuracy: 0.8528 - Val loss: 0.3434 - Val F1: 0.8519 - LR: 1.00e-06\n","\tEpoch 100/100 - Train loss: 0.4803 - Val accuracy: 0.8344 - Val loss: 0.3583 - Val F1: 0.8339 - LR: 0.00e+00\n","\tBest epoch: 94 - Best val accuracy: 0.8528 - Best val loss: 0.3060 - Best val F1: 0.8526\n","\n","Source class: WAL | Domain: 61 | Accuracy: 0.8078 | Loss: 0.6883 | F1: 0.8055\n","\n","Domain: 62\n","x_syn_dom.shape: (888, 3, 128) | np.unique(y_syn_dom): [0 1 2 3]\n","x_dp_dom.shape: (780, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","x_syn_dom.shape: (777, 3, 128) | np.unique(y_syn_dom): [0 1 2 3]\n","x_dp_dom.shape: (669, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Fine-tuning on synthetic data...\n","\tEpoch 10/100 - Train loss: 1.5240 - Val accuracy: 0.7179 - Val loss: 1.2726 - Val F1: 0.7186 - LR: 9.00e-06\n","\tEpoch 20/100 - Train loss: 1.1582 - Val accuracy: 0.7308 - Val loss: 1.0520 - Val F1: 0.7313 - LR: 8.00e-06\n","\tEpoch 30/100 - Train loss: 1.1071 - Val accuracy: 0.7500 - Val loss: 0.9128 - Val F1: 0.7510 - LR: 7.00e-06\n","\tEpoch 40/100 - Train loss: 0.9576 - Val accuracy: 0.7564 - Val loss: 0.8316 - Val F1: 0.7560 - LR: 6.00e-06\n","\tEpoch 50/100 - Train loss: 0.7776 - Val accuracy: 0.8077 - Val loss: 0.7563 - Val F1: 0.8097 - LR: 5.00e-06\n","\tEpoch 60/100 - Train loss: 0.7702 - Val accuracy: 0.7949 - Val loss: 0.7222 - Val F1: 0.7942 - LR: 4.00e-06\n","\tEpoch 70/100 - Train loss: 0.7113 - Val accuracy: 0.8141 - Val loss: 0.6756 - Val F1: 0.8144 - LR: 3.00e-06\n","\tEpoch 80/100 - Train loss: 0.7328 - Val accuracy: 0.8269 - Val loss: 0.6477 - Val F1: 0.8277 - LR: 2.00e-06\n","\tEpoch 90/100 - Train loss: 0.6472 - Val accuracy: 0.8269 - Val loss: 0.6377 - Val F1: 0.8278 - LR: 1.00e-06\n","\tEpoch 100/100 - Train loss: 0.7212 - Val accuracy: 0.8333 - Val loss: 0.6350 - Val F1: 0.8343 - LR: 0.00e+00\n","\tBest epoch: 91 - Best val accuracy: 0.8269 - Best val loss: 0.6216 - Best val F1: 0.8279\n","\n","Source class: WAL | Domain: 62 | Accuracy: 0.6951 | Loss: 1.1023 | F1: 0.6868\n","\n","Domain: 63\n","x_syn_dom.shape: (996, 3, 128) | np.unique(y_syn_dom): [0 1 2 3]\n","x_dp_dom.shape: (859, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","x_syn_dom.shape: (871, 3, 128) | np.unique(y_syn_dom): [0 1 2 3]\n","x_dp_dom.shape: (735, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Fine-tuning on synthetic data...\n","\tEpoch 10/100 - Train loss: 1.7620 - Val accuracy: 0.5314 - Val loss: 1.9212 - Val F1: 0.5246 - LR: 9.00e-06\n","\tEpoch 20/100 - Train loss: 1.2815 - Val accuracy: 0.5714 - Val loss: 1.4116 - Val F1: 0.5698 - LR: 8.00e-06\n","\tEpoch 30/100 - Train loss: 1.1534 - Val accuracy: 0.6343 - Val loss: 1.1372 - Val F1: 0.6317 - LR: 7.00e-06\n","\tEpoch 40/100 - Train loss: 1.0146 - Val accuracy: 0.6514 - Val loss: 0.9568 - Val F1: 0.6516 - LR: 6.00e-06\n","\tEpoch 50/100 - Train loss: 0.8930 - Val accuracy: 0.6914 - Val loss: 0.8117 - Val F1: 0.6924 - LR: 5.00e-06\n","\tEpoch 60/100 - Train loss: 0.8443 - Val accuracy: 0.6857 - Val loss: 0.7424 - Val F1: 0.6913 - LR: 4.00e-06\n","\tEpoch 70/100 - Train loss: 0.8502 - Val accuracy: 0.7143 - Val loss: 0.6846 - Val F1: 0.7170 - LR: 3.00e-06\n","\tEpoch 80/100 - Train loss: 0.7329 - Val accuracy: 0.7257 - Val loss: 0.6416 - Val F1: 0.7280 - LR: 2.00e-06\n","\tEpoch 90/100 - Train loss: 0.7036 - Val accuracy: 0.7543 - Val loss: 0.6227 - Val F1: 0.7547 - LR: 1.00e-06\n","\tEpoch 100/100 - Train loss: 0.6549 - Val accuracy: 0.7543 - Val loss: 0.6066 - Val F1: 0.7545 - LR: 0.00e+00\n","\tBest epoch: 100 - Best val accuracy: 0.7543 - Best val loss: 0.6066 - Best val F1: 0.7545\n","\n","Source class: WAL | Domain: 63 | Accuracy: 0.6340 | Loss: 1.1572 | F1: 0.6208\n","\n","Domain: 64\n","x_syn_dom.shape: (896, 3, 128) | np.unique(y_syn_dom): [0 1 2 3]\n","x_dp_dom.shape: (481, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","x_syn_dom.shape: (784, 3, 128) | np.unique(y_syn_dom): [0 1 2 3]\n","x_dp_dom.shape: (369, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Fine-tuning on synthetic data...\n","\tEpoch 10/100 - Train loss: 1.3242 - Val accuracy: 0.7006 - Val loss: 1.0895 - Val F1: 0.7001 - LR: 9.00e-06\n","\tEpoch 20/100 - Train loss: 1.0610 - Val accuracy: 0.7389 - Val loss: 0.9426 - Val F1: 0.7370 - LR: 8.00e-06\n","\tEpoch 30/100 - Train loss: 0.9217 - Val accuracy: 0.7707 - Val loss: 0.8856 - Val F1: 0.7669 - LR: 7.00e-06\n","\tEpoch 40/100 - Train loss: 0.8510 - Val accuracy: 0.7898 - Val loss: 0.8437 - Val F1: 0.7804 - LR: 6.00e-06\n","\tEpoch 50/100 - Train loss: 0.7508 - Val accuracy: 0.8153 - Val loss: 0.7354 - Val F1: 0.8094 - LR: 5.00e-06\n","\tEpoch 60/100 - Train loss: 0.7185 - Val accuracy: 0.8217 - Val loss: 0.7128 - Val F1: 0.8153 - LR: 4.00e-06\n","\tEpoch 70/100 - Train loss: 0.6468 - Val accuracy: 0.8089 - Val loss: 0.6785 - Val F1: 0.8029 - LR: 3.00e-06\n","\tEpoch 80/100 - Train loss: 0.6381 - Val accuracy: 0.8217 - Val loss: 0.6216 - Val F1: 0.8167 - LR: 2.00e-06\n","\tEpoch 90/100 - Train loss: 0.5924 - Val accuracy: 0.8280 - Val loss: 0.6396 - Val F1: 0.8217 - LR: 1.00e-06\n","\tEpoch 100/100 - Train loss: 0.6070 - Val accuracy: 0.8217 - Val loss: 0.6741 - Val F1: 0.8153 - LR: 0.00e+00\n","\tBest epoch: 80 - Best val accuracy: 0.8217 - Best val loss: 0.6216 - Best val F1: 0.8167\n","\n","Source class: WAL | Domain: 64 | Accuracy: 0.7127 | Loss: 0.9732 | F1: 0.7181\n","\n","Domain: 65\n","x_syn_dom.shape: (1016, 3, 128) | np.unique(y_syn_dom): [0 1 2 3]\n","x_dp_dom.shape: (840, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","x_syn_dom.shape: (889, 3, 128) | np.unique(y_syn_dom): [0 1 2 3]\n","x_dp_dom.shape: (713, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Fine-tuning on synthetic data...\n","\tEpoch 10/100 - Train loss: 1.5048 - Val accuracy: 0.6798 - Val loss: 1.1256 - Val F1: 0.6761 - LR: 9.00e-06\n","\tEpoch 20/100 - Train loss: 1.1449 - Val accuracy: 0.6742 - Val loss: 0.9577 - Val F1: 0.6741 - LR: 8.00e-06\n","\tEpoch 30/100 - Train loss: 0.9620 - Val accuracy: 0.7360 - Val loss: 0.6704 - Val F1: 0.7368 - LR: 7.00e-06\n","\tEpoch 40/100 - Train loss: 0.8877 - Val accuracy: 0.7697 - Val loss: 0.6118 - Val F1: 0.7696 - LR: 6.00e-06\n","\tEpoch 50/100 - Train loss: 0.7459 - Val accuracy: 0.7978 - Val loss: 0.5745 - Val F1: 0.7988 - LR: 5.00e-06\n","\tEpoch 60/100 - Train loss: 0.6394 - Val accuracy: 0.8146 - Val loss: 0.4918 - Val F1: 0.8144 - LR: 4.00e-06\n","\tEpoch 70/100 - Train loss: 0.5558 - Val accuracy: 0.8371 - Val loss: 0.4200 - Val F1: 0.8375 - LR: 3.00e-06\n","\tEpoch 80/100 - Train loss: 0.5955 - Val accuracy: 0.8315 - Val loss: 0.4199 - Val F1: 0.8318 - LR: 2.00e-06\n","\tEpoch 90/100 - Train loss: 0.5906 - Val accuracy: 0.8596 - Val loss: 0.3952 - Val F1: 0.8590 - LR: 1.00e-06\n","\tEpoch 100/100 - Train loss: 0.5989 - Val accuracy: 0.8258 - Val loss: 0.4349 - Val F1: 0.8265 - LR: 0.00e+00\n","\tBest epoch: 95 - Best val accuracy: 0.8708 - Best val loss: 0.3857 - Best val F1: 0.8701\n","\n","Source class: WAL | Domain: 65 | Accuracy: 0.7041 | Loss: 1.0045 | F1: 0.6981\n","\n","Domain: 66\n","x_syn_dom.shape: (916, 3, 128) | np.unique(y_syn_dom): [0 1 2 3]\n","x_dp_dom.shape: (792, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","x_syn_dom.shape: (801, 3, 128) | np.unique(y_syn_dom): [0 1 2 3]\n","x_dp_dom.shape: (678, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Fine-tuning on synthetic data...\n","\tEpoch 10/100 - Train loss: 1.1555 - Val accuracy: 0.7329 - Val loss: 0.7895 - Val F1: 0.7319 - LR: 9.00e-06\n","\tEpoch 20/100 - Train loss: 0.9014 - Val accuracy: 0.7578 - Val loss: 0.6514 - Val F1: 0.7554 - LR: 8.00e-06\n","\tEpoch 30/100 - Train loss: 0.8212 - Val accuracy: 0.7702 - Val loss: 0.5752 - Val F1: 0.7679 - LR: 7.00e-06\n","\tEpoch 40/100 - Train loss: 0.6998 - Val accuracy: 0.7888 - Val loss: 0.5258 - Val F1: 0.7861 - LR: 6.00e-06\n","\tEpoch 50/100 - Train loss: 0.6083 - Val accuracy: 0.8012 - Val loss: 0.4956 - Val F1: 0.7976 - LR: 5.00e-06\n","\tEpoch 60/100 - Train loss: 0.6595 - Val accuracy: 0.8075 - Val loss: 0.4670 - Val F1: 0.8034 - LR: 4.00e-06\n","\tEpoch 70/100 - Train loss: 0.5493 - Val accuracy: 0.8137 - Val loss: 0.4356 - Val F1: 0.8105 - LR: 3.00e-06\n","\tEpoch 80/100 - Train loss: 0.4943 - Val accuracy: 0.8137 - Val loss: 0.4191 - Val F1: 0.8099 - LR: 2.00e-06\n","\tEpoch 90/100 - Train loss: 0.5711 - Val accuracy: 0.8199 - Val loss: 0.4117 - Val F1: 0.8170 - LR: 1.00e-06\n","\tEpoch 100/100 - Train loss: 0.5217 - Val accuracy: 0.8075 - Val loss: 0.4197 - Val F1: 0.8034 - LR: 0.00e+00\n","\tBest epoch: 99 - Best val accuracy: 0.8199 - Best val loss: 0.4096 - Best val F1: 0.8170\n","\n","Source class: WAL | Domain: 66 | Accuracy: 0.7124 | Loss: 0.9889 | F1: 0.7022\n","\n","Domain: 67\n","x_syn_dom.shape: (892, 3, 128) | np.unique(y_syn_dom): [0 1 2 3]\n","x_dp_dom.shape: (572, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","x_syn_dom.shape: (780, 3, 128) | np.unique(y_syn_dom): [0 1 2 3]\n","x_dp_dom.shape: (461, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Fine-tuning on synthetic data...\n","\tEpoch 10/100 - Train loss: 1.0410 - Val accuracy: 0.7628 - Val loss: 0.8333 - Val F1: 0.7649 - LR: 9.00e-06\n","\tEpoch 20/100 - Train loss: 0.8012 - Val accuracy: 0.8013 - Val loss: 0.6844 - Val F1: 0.8005 - LR: 8.00e-06\n","\tEpoch 30/100 - Train loss: 0.7336 - Val accuracy: 0.8462 - Val loss: 0.5424 - Val F1: 0.8459 - LR: 7.00e-06\n","\tEpoch 40/100 - Train loss: 0.7014 - Val accuracy: 0.8205 - Val loss: 0.5544 - Val F1: 0.8194 - LR: 6.00e-06\n","\tEpoch 50/100 - Train loss: 0.6588 - Val accuracy: 0.8269 - Val loss: 0.5208 - Val F1: 0.8244 - LR: 5.00e-06\n","\tEpoch 60/100 - Train loss: 0.6347 - Val accuracy: 0.8526 - Val loss: 0.4730 - Val F1: 0.8511 - LR: 4.00e-06\n","\tEpoch 70/100 - Train loss: 0.5634 - Val accuracy: 0.8526 - Val loss: 0.4677 - Val F1: 0.8520 - LR: 3.00e-06\n","\tEpoch 80/100 - Train loss: 0.5260 - Val accuracy: 0.8590 - Val loss: 0.4424 - Val F1: 0.8591 - LR: 2.00e-06\n","\tEpoch 90/100 - Train loss: 0.5778 - Val accuracy: 0.8654 - Val loss: 0.4102 - Val F1: 0.8647 - LR: 1.00e-06\n","\tEpoch 100/100 - Train loss: 0.6664 - Val accuracy: 0.8654 - Val loss: 0.4266 - Val F1: 0.8647 - LR: 0.00e+00\n","\tBest epoch: 94 - Best val accuracy: 0.8782 - Best val loss: 0.3970 - Best val F1: 0.8792\n","\n","Source class: WAL | Domain: 67 | Accuracy: 0.7549 | Loss: 0.7399 | F1: 0.7545\n","\n","Domain: 68\n","x_syn_dom.shape: (956, 3, 128) | np.unique(y_syn_dom): [0 1 2 3]\n","x_dp_dom.shape: (877, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","x_syn_dom.shape: (836, 3, 128) | np.unique(y_syn_dom): [0 1 2 3]\n","x_dp_dom.shape: (758, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Fine-tuning on synthetic data...\n","\tEpoch 10/100 - Train loss: 1.2038 - Val accuracy: 0.6190 - Val loss: 1.1111 - Val F1: 0.6271 - LR: 9.00e-06\n","\tEpoch 20/100 - Train loss: 0.9881 - Val accuracy: 0.6786 - Val loss: 0.9766 - Val F1: 0.6803 - LR: 8.00e-06\n","\tEpoch 30/100 - Train loss: 0.8784 - Val accuracy: 0.7143 - Val loss: 0.9376 - Val F1: 0.7126 - LR: 7.00e-06\n","\tEpoch 40/100 - Train loss: 0.7926 - Val accuracy: 0.7024 - Val loss: 0.8710 - Val F1: 0.7019 - LR: 6.00e-06\n","\tEpoch 50/100 - Train loss: 0.7434 - Val accuracy: 0.7381 - Val loss: 0.7827 - Val F1: 0.7343 - LR: 5.00e-06\n","\tEpoch 60/100 - Train loss: 0.6602 - Val accuracy: 0.7738 - Val loss: 0.7216 - Val F1: 0.7636 - LR: 4.00e-06\n","\tEpoch 70/100 - Train loss: 0.6638 - Val accuracy: 0.7560 - Val loss: 0.7009 - Val F1: 0.7515 - LR: 3.00e-06\n","\tEpoch 80/100 - Train loss: 0.6301 - Val accuracy: 0.7500 - Val loss: 0.6802 - Val F1: 0.7460 - LR: 2.00e-06\n","\tEpoch 90/100 - Train loss: 0.6558 - Val accuracy: 0.7560 - Val loss: 0.6741 - Val F1: 0.7509 - LR: 1.00e-06\n","\tEpoch 100/100 - Train loss: 0.5840 - Val accuracy: 0.7500 - Val loss: 0.6920 - Val F1: 0.7455 - LR: 0.00e+00\n","\tBest epoch: 97 - Best val accuracy: 0.7798 - Best val loss: 0.6495 - Best val F1: 0.7724\n","\n","Source class: WAL | Domain: 68 | Accuracy: 0.6491 | Loss: 2.1310 | F1: 0.6303\n","\n","Domain: 69\n","x_syn_dom.shape: (908, 3, 128) | np.unique(y_syn_dom): [0 1 2 3]\n","x_dp_dom.shape: (799, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","x_syn_dom.shape: (794, 3, 128) | np.unique(y_syn_dom): [0 1 2 3]\n","x_dp_dom.shape: (686, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Fine-tuning on synthetic data...\n","\tEpoch 10/100 - Train loss: 0.9911 - Val accuracy: 0.7044 - Val loss: 0.9110 - Val F1: 0.7064 - LR: 9.00e-06\n","\tEpoch 20/100 - Train loss: 0.8222 - Val accuracy: 0.7673 - Val loss: 0.6441 - Val F1: 0.7675 - LR: 8.00e-06\n","\tEpoch 30/100 - Train loss: 0.6584 - Val accuracy: 0.8050 - Val loss: 0.5977 - Val F1: 0.8045 - LR: 7.00e-06\n","\tEpoch 40/100 - Train loss: 0.6548 - Val accuracy: 0.7987 - Val loss: 0.5497 - Val F1: 0.7983 - LR: 6.00e-06\n","\tEpoch 50/100 - Train loss: 0.5761 - Val accuracy: 0.8428 - Val loss: 0.4907 - Val F1: 0.8425 - LR: 5.00e-06\n","\tEpoch 60/100 - Train loss: 0.5366 - Val accuracy: 0.8302 - Val loss: 0.4919 - Val F1: 0.8304 - LR: 4.00e-06\n","\tEpoch 70/100 - Train loss: 0.4967 - Val accuracy: 0.8491 - Val loss: 0.4623 - Val F1: 0.8491 - LR: 3.00e-06\n","\tEpoch 80/100 - Train loss: 0.4556 - Val accuracy: 0.8553 - Val loss: 0.4307 - Val F1: 0.8550 - LR: 2.00e-06\n","\tEpoch 90/100 - Train loss: 0.4876 - Val accuracy: 0.8553 - Val loss: 0.4104 - Val F1: 0.8550 - LR: 1.00e-06\n","\tEpoch 100/100 - Train loss: 0.4849 - Val accuracy: 0.8553 - Val loss: 0.4072 - Val F1: 0.8550 - LR: 0.00e+00\n","\tBest epoch: 98 - Best val accuracy: 0.8616 - Best val loss: 0.4002 - Best val F1: 0.8612\n","\n","Source class: WAL | Domain: 69 | Accuracy: 0.6953 | Loss: 1.0241 | F1: 0.6897\n","\n","Domain: 70\n","x_syn_dom.shape: (920, 3, 128) | np.unique(y_syn_dom): [0 1 2 3]\n","x_dp_dom.shape: (762, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","x_syn_dom.shape: (805, 3, 128) | np.unique(y_syn_dom): [0 1 2 3]\n","x_dp_dom.shape: (647, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Fine-tuning on synthetic data...\n","\tEpoch 10/100 - Train loss: 1.3135 - Val accuracy: 0.6335 - Val loss: 1.2218 - Val F1: 0.6394 - LR: 9.00e-06\n","\tEpoch 20/100 - Train loss: 1.0154 - Val accuracy: 0.6584 - Val loss: 1.0596 - Val F1: 0.6654 - LR: 8.00e-06\n","\tEpoch 30/100 - Train loss: 0.9519 - Val accuracy: 0.6708 - Val loss: 0.9524 - Val F1: 0.6782 - LR: 7.00e-06\n","\tEpoch 40/100 - Train loss: 0.8146 - Val accuracy: 0.7019 - Val loss: 0.7818 - Val F1: 0.7051 - LR: 6.00e-06\n","\tEpoch 50/100 - Train loss: 0.7779 - Val accuracy: 0.6957 - Val loss: 0.8313 - Val F1: 0.7041 - LR: 5.00e-06\n","\tEpoch 60/100 - Train loss: 0.6918 - Val accuracy: 0.7391 - Val loss: 0.7325 - Val F1: 0.7451 - LR: 4.00e-06\n","\tEpoch 70/100 - Train loss: 0.6646 - Val accuracy: 0.7453 - Val loss: 0.6918 - Val F1: 0.7487 - LR: 3.00e-06\n","\tEpoch 80/100 - Train loss: 0.6275 - Val accuracy: 0.7453 - Val loss: 0.6569 - Val F1: 0.7513 - LR: 2.00e-06\n","\tEpoch 90/100 - Train loss: 0.6464 - Val accuracy: 0.7826 - Val loss: 0.6570 - Val F1: 0.7831 - LR: 1.00e-06\n","\tEpoch 100/100 - Train loss: 0.6354 - Val accuracy: 0.7516 - Val loss: 0.6396 - Val F1: 0.7594 - LR: 0.00e+00\n","\tBest epoch: 93 - Best val accuracy: 0.7826 - Best val loss: 0.6026 - Best val F1: 0.7826\n","\n","Source class: WAL | Domain: 70 | Accuracy: 0.5487 | Loss: 2.9457 | F1: 0.5025\n","\n","Domain: 71\n","x_syn_dom.shape: (968, 3, 128) | np.unique(y_syn_dom): [0 1 2 3]\n","x_dp_dom.shape: (854, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","x_syn_dom.shape: (847, 3, 128) | np.unique(y_syn_dom): [0 1 2 3]\n","x_dp_dom.shape: (733, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Fine-tuning on synthetic data...\n","\tEpoch 10/100 - Train loss: 0.9783 - Val accuracy: 0.8118 - Val loss: 0.5793 - Val F1: 0.8156 - LR: 9.00e-06\n","\tEpoch 20/100 - Train loss: 0.7417 - Val accuracy: 0.8529 - Val loss: 0.4109 - Val F1: 0.8530 - LR: 8.00e-06\n","\tEpoch 30/100 - Train loss: 0.6718 - Val accuracy: 0.8882 - Val loss: 0.3769 - Val F1: 0.8872 - LR: 7.00e-06\n","\tEpoch 40/100 - Train loss: 0.5664 - Val accuracy: 0.8882 - Val loss: 0.3376 - Val F1: 0.8879 - LR: 6.00e-06\n","\tEpoch 50/100 - Train loss: 0.5211 - Val accuracy: 0.8882 - Val loss: 0.3006 - Val F1: 0.8879 - LR: 5.00e-06\n","\tEpoch 60/100 - Train loss: 0.5576 - Val accuracy: 0.8882 - Val loss: 0.2879 - Val F1: 0.8879 - LR: 4.00e-06\n","\tEpoch 70/100 - Train loss: 0.5461 - Val accuracy: 0.9059 - Val loss: 0.2834 - Val F1: 0.9053 - LR: 3.00e-06\n","\tEpoch 80/100 - Train loss: 0.5205 - Val accuracy: 0.9118 - Val loss: 0.2705 - Val F1: 0.9130 - LR: 2.00e-06\n","\tEpoch 90/100 - Train loss: 0.4729 - Val accuracy: 0.9118 - Val loss: 0.2564 - Val F1: 0.9127 - LR: 1.00e-06\n","\tEpoch 100/100 - Train loss: 0.5015 - Val accuracy: 0.9118 - Val loss: 0.2582 - Val F1: 0.9116 - LR: 0.00e+00\n","\tBest epoch: 89 - Best val accuracy: 0.9118 - Best val loss: 0.2418 - Best val F1: 0.9116\n","\n","Source class: WAL | Domain: 71 | Accuracy: 0.7885 | Loss: 0.7935 | F1: 0.7904\n","\n","Domain: 72\n","x_syn_dom.shape: (920, 3, 128) | np.unique(y_syn_dom): [0 1 2 3]\n","x_dp_dom.shape: (811, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","x_syn_dom.shape: (805, 3, 128) | np.unique(y_syn_dom): [0 1 2 3]\n","x_dp_dom.shape: (696, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Fine-tuning on synthetic data...\n","\tEpoch 10/100 - Train loss: 1.1494 - Val accuracy: 0.7391 - Val loss: 0.9223 - Val F1: 0.7421 - LR: 9.00e-06\n","\tEpoch 20/100 - Train loss: 0.8993 - Val accuracy: 0.7702 - Val loss: 0.7792 - Val F1: 0.7711 - LR: 8.00e-06\n","\tEpoch 30/100 - Train loss: 0.7892 - Val accuracy: 0.7826 - Val loss: 0.6857 - Val F1: 0.7828 - LR: 7.00e-06\n","\tEpoch 40/100 - Train loss: 0.7177 - Val accuracy: 0.8012 - Val loss: 0.6364 - Val F1: 0.7992 - LR: 6.00e-06\n","\tEpoch 50/100 - Train loss: 0.6477 - Val accuracy: 0.8199 - Val loss: 0.5691 - Val F1: 0.8180 - LR: 5.00e-06\n","\tEpoch 60/100 - Train loss: 0.5262 - Val accuracy: 0.8012 - Val loss: 0.5186 - Val F1: 0.8005 - LR: 4.00e-06\n","\tEpoch 70/100 - Train loss: 0.5474 - Val accuracy: 0.8509 - Val loss: 0.5016 - Val F1: 0.8514 - LR: 3.00e-06\n","\tEpoch 80/100 - Train loss: 0.5100 - Val accuracy: 0.8385 - Val loss: 0.4909 - Val F1: 0.8373 - LR: 2.00e-06\n","\tEpoch 90/100 - Train loss: 0.5210 - Val accuracy: 0.8323 - Val loss: 0.4840 - Val F1: 0.8306 - LR: 1.00e-06\n","\tEpoch 100/100 - Train loss: 0.5177 - Val accuracy: 0.8385 - Val loss: 0.4649 - Val F1: 0.8377 - LR: 0.00e+00\n","\tBest epoch: 99 - Best val accuracy: 0.8385 - Best val loss: 0.4607 - Best val F1: 0.8377\n","\n","Source class: WAL | Domain: 72 | Accuracy: 0.7385 | Loss: 0.8865 | F1: 0.7245\n","\n","Domain: 73\n","x_syn_dom.shape: (952, 3, 128) | np.unique(y_syn_dom): [0 1 2 3]\n","x_dp_dom.shape: (815, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","x_syn_dom.shape: (833, 3, 128) | np.unique(y_syn_dom): [0 1 2 3]\n","x_dp_dom.shape: (696, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Fine-tuning on synthetic data...\n","\tEpoch 10/100 - Train loss: 1.4196 - Val accuracy: 0.6886 - Val loss: 1.3286 - Val F1: 0.6855 - LR: 9.00e-06\n","\tEpoch 20/100 - Train loss: 1.1382 - Val accuracy: 0.7126 - Val loss: 1.2337 - Val F1: 0.7071 - LR: 8.00e-06\n","\tEpoch 30/100 - Train loss: 1.0035 - Val accuracy: 0.7186 - Val loss: 1.1495 - Val F1: 0.7125 - LR: 7.00e-06\n","\tEpoch 40/100 - Train loss: 0.9479 - Val accuracy: 0.7305 - Val loss: 1.1077 - Val F1: 0.7241 - LR: 6.00e-06\n","\tEpoch 50/100 - Train loss: 0.8763 - Val accuracy: 0.7485 - Val loss: 1.0790 - Val F1: 0.7412 - LR: 5.00e-06\n","\tEpoch 60/100 - Train loss: 0.8001 - Val accuracy: 0.7725 - Val loss: 0.9736 - Val F1: 0.7681 - LR: 4.00e-06\n","\tEpoch 70/100 - Train loss: 0.8007 - Val accuracy: 0.7605 - Val loss: 0.9688 - Val F1: 0.7555 - LR: 3.00e-06\n","\tEpoch 80/100 - Train loss: 0.7599 - Val accuracy: 0.7725 - Val loss: 0.9456 - Val F1: 0.7672 - LR: 2.00e-06\n","\tEpoch 90/100 - Train loss: 0.8501 - Val accuracy: 0.7725 - Val loss: 0.9728 - Val F1: 0.7654 - LR: 1.00e-06\n","\tEpoch 100/100 - Train loss: 0.7089 - Val accuracy: 0.7605 - Val loss: 0.9556 - Val F1: 0.7548 - LR: 0.00e+00\n","\tBest epoch: 87 - Best val accuracy: 0.7784 - Best val loss: 0.9065 - Best val F1: 0.7743\n","\n","Source class: WAL | Domain: 73 | Accuracy: 0.7773 | Loss: 0.8507 | F1: 0.7651\n","\n","Domain: 74\n","x_syn_dom.shape: (976, 3, 128) | np.unique(y_syn_dom): [0 1 2 3]\n","x_dp_dom.shape: (563, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","x_syn_dom.shape: (854, 3, 128) | np.unique(y_syn_dom): [0 1 2 3]\n","x_dp_dom.shape: (441, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Fine-tuning on synthetic data...\n","\tEpoch 10/100 - Train loss: 1.2139 - Val accuracy: 0.7661 - Val loss: 0.7636 - Val F1: 0.7622 - LR: 9.00e-06\n","\tEpoch 20/100 - Train loss: 0.8679 - Val accuracy: 0.7778 - Val loss: 0.6470 - Val F1: 0.7742 - LR: 8.00e-06\n","\tEpoch 30/100 - Train loss: 0.7983 - Val accuracy: 0.8187 - Val loss: 0.5145 - Val F1: 0.8170 - LR: 7.00e-06\n","\tEpoch 40/100 - Train loss: 0.6535 - Val accuracy: 0.8421 - Val loss: 0.4697 - Val F1: 0.8414 - LR: 6.00e-06\n","\tEpoch 50/100 - Train loss: 0.6289 - Val accuracy: 0.8480 - Val loss: 0.4126 - Val F1: 0.8464 - LR: 5.00e-06\n","\tEpoch 60/100 - Train loss: 0.5602 - Val accuracy: 0.8713 - Val loss: 0.3730 - Val F1: 0.8714 - LR: 4.00e-06\n","\tEpoch 70/100 - Train loss: 0.5178 - Val accuracy: 0.8713 - Val loss: 0.3709 - Val F1: 0.8708 - LR: 3.00e-06\n","\tEpoch 80/100 - Train loss: 0.5334 - Val accuracy: 0.8772 - Val loss: 0.3459 - Val F1: 0.8764 - LR: 2.00e-06\n","\tEpoch 90/100 - Train loss: 0.4755 - Val accuracy: 0.8713 - Val loss: 0.3469 - Val F1: 0.8690 - LR: 1.00e-06\n","\tEpoch 100/100 - Train loss: 0.4895 - Val accuracy: 0.8830 - Val loss: 0.3440 - Val F1: 0.8821 - LR: 0.00e+00\n","\tBest epoch: 94 - Best val accuracy: 0.8713 - Best val loss: 0.3368 - Best val F1: 0.8702\n","\n","Source class: WAL | Domain: 74 | Accuracy: 0.7732 | Loss: 1.1544 | F1: 0.7735\n","\n","Domain: 75\n","x_syn_dom.shape: (968, 3, 128) | np.unique(y_syn_dom): [0 1 2 3]\n","x_dp_dom.shape: (823, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","x_syn_dom.shape: (847, 3, 128) | np.unique(y_syn_dom): [0 1 2 3]\n","x_dp_dom.shape: (702, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","Fine-tuning on synthetic data...\n","\tEpoch 10/100 - Train loss: 0.9068 - Val accuracy: 0.8000 - Val loss: 0.5348 - Val F1: 0.7984 - LR: 9.00e-06\n","\tEpoch 20/100 - Train loss: 0.6499 - Val accuracy: 0.8176 - Val loss: 0.4734 - Val F1: 0.8175 - LR: 8.00e-06\n","\tEpoch 30/100 - Train loss: 0.6292 - Val accuracy: 0.8529 - Val loss: 0.3961 - Val F1: 0.8529 - LR: 7.00e-06\n","\tEpoch 40/100 - Train loss: 0.5176 - Val accuracy: 0.8882 - Val loss: 0.3670 - Val F1: 0.8878 - LR: 6.00e-06\n","\tEpoch 50/100 - Train loss: 0.4846 - Val accuracy: 0.8824 - Val loss: 0.3290 - Val F1: 0.8827 - LR: 5.00e-06\n","\tEpoch 60/100 - Train loss: 0.5450 - Val accuracy: 0.8882 - Val loss: 0.3061 - Val F1: 0.8885 - LR: 4.00e-06\n","\tEpoch 70/100 - Train loss: 0.4676 - Val accuracy: 0.9118 - Val loss: 0.3045 - Val F1: 0.9110 - LR: 3.00e-06\n","\tEpoch 80/100 - Train loss: 0.4220 - Val accuracy: 0.8941 - Val loss: 0.2804 - Val F1: 0.8948 - LR: 2.00e-06\n","\tEpoch 90/100 - Train loss: 0.4103 - Val accuracy: 0.9118 - Val loss: 0.2677 - Val F1: 0.9115 - LR: 1.00e-06\n","\tEpoch 100/100 - Train loss: 0.4263 - Val accuracy: 0.9000 - Val loss: 0.2644 - Val F1: 0.9007 - LR: 0.00e+00\n","\tBest epoch: 96 - Best val accuracy: 0.9118 - Best val loss: 0.2620 - Best val F1: 0.9118\n","\n","Source class: WAL | Domain: 75 | Accuracy: 0.6838 | Loss: 1.7364 | F1: 0.6363\n","\n","Mean accuracy: 0.7117 +- 0.0652\n","Mean F1: 0.6999 +- 0.0763\n","\n"]}],"source":["def compute_TSTR_Df_Syn(dataset):\n","    accs = []\n","    f1s = []\n","\n","    for src_class in config[dataset]['class_names']:\n","        if src_class != 'WAL':\n","            continue\n","\n","        print(f\"Source class: {src_class}\\n\")\n","\n","        # Load Df data\n","        x_df, y_df, k_df = get_data(dataset, 'df', src_class)\n","        print(f'x_df.shape: {x_df.shape} | np.unique(y_df): {np.unique(y_df)}\\n')\n","\n","        # Train on Df data\n","        print('Training on Df data...')\n","        df_model = train_only(x_df, y_df, dataset, num_epochs=num_epochs)\n","\n","        for domain in range(config[dataset]['num_df_domains'], config[dataset]['num_df_domains'] + config[dataset]['num_dp_domains']):\n","            print(f\"Domain: {domain}\")\n","\n","            # Load synthetic data\n","            x_syn_dom, y_syn_dom, k_syn_dom = get_syn_data(dataset, syn_name, src_class, domain)\n","            print(f'x_syn_dom.shape: {x_syn_dom.shape} | np.unique(y_syn_dom): {np.unique(y_syn_dom)}')\n","\n","            # Load Dp data\n","            x_dp_dom, y_dp_dom, k_dp_dom = get_data(dataset, 'dp', src_class, domain)\n","            print(f'x_dp_dom.shape: {x_dp_dom.shape} | np.unique(y_dp_dom): {np.unique(y_dp_dom)}\\n')\n","\n","            y0_indices_syn = np.where(y_syn_dom == 0)[0]\n","            y0_indices_dp = np.where(y_dp_dom == 0)[0]\n","            assert np.array_equal(y0_indices_syn, y0_indices_dp), \"Labels do not match\"\n","            assert np.array_equal(y_syn_dom[y0_indices_syn], y_dp_dom[y0_indices_dp]), \"Labels do not match\"\n","\n","            y0_indices_train, y0_indices_test = train_test_split(y0_indices_syn, test_size=0.5, shuffle=True, random_state=seed)\n","\n","            x_syn_dom_y0, y_syn_dom_y0 = x_syn_dom[y0_indices_train], y_syn_dom[y0_indices_train]\n","            x_dp_dom_y0, y_dp_dom_y0 = x_dp_dom[y0_indices_test], y_dp_dom[y0_indices_test]\n","\n","            x_syn_dom = np.concatenate([x_syn_dom_y0, x_syn_dom[y_syn_dom != 0]])\n","            y_syn_dom = np.concatenate([y_syn_dom_y0, y_syn_dom[y_syn_dom != 0]])\n","            x_dp_dom = np.concatenate([x_dp_dom_y0, x_dp_dom[y_dp_dom != 0]])\n","            y_dp_dom = np.concatenate([y_dp_dom_y0, y_dp_dom[y_dp_dom != 0]])\n","\n","            print(f'x_syn_dom.shape: {x_syn_dom.shape} | np.unique(y_syn_dom): {np.unique(y_syn_dom)}')\n","            print(f'x_dp_dom.shape: {x_dp_dom.shape} | np.unique(y_dp_dom): {np.unique(y_dp_dom)}\\n')\n","\n","            # Fine-tune Df model on synthetic data and evaluate on Dp data\n","            print('Fine-tuning on synthetic data...')\n","            df_syn_model = fine_tune(copy.deepcopy(df_model), x_syn_dom, y_syn_dom, num_epochs=num_epochs)\n","            acc, loss, f1 = evaluate_model(df_syn_model, get_dataloader(x_dp_dom, y_dp_dom))\n","            save_scores(src_class, domain, acc, loss, f1, 'Df_Syn', dataset)\n","            accs.append(acc)\n","            f1s.append(f1)\n","            print(f'Source class: {src_class} | Domain: {domain} | Accuracy: {acc:.4f} | Loss: {loss:.4f} | F1: {f1:.4f}\\n')\n","\n","    print(f\"Mean accuracy: {np.mean(accs):.4f} +- {np.std(accs):.4f}\")\n","    print(f\"Mean F1: {np.mean(f1s):.4f} +- {np.std(f1s):.4f}\\n\")\n","\n","\n","\n","\n","compute_TSTR_Df_Syn('mobiact_realworld')"]},{"cell_type":"code","execution_count":14,"metadata":{"executionInfo":{"elapsed":10,"status":"ok","timestamp":1732704684983,"user":{"displayName":"Pietro Castelvetri","userId":"04218697278633758016"},"user_tz":-60},"id":"WrQyLH7NMxLn"},"outputs":[],"source":["# def compute_TSTR_Df_Syn_all(dataset):\n","#     accs = []\n","\n","#     for src_class in config[dataset]['class_names']:\n","#         if src_class != 'WAL':\n","#             continue\n","\n","#         print(f\"Source class: {src_class}\\n\")\n","\n","#         # Load Df data\n","#         x_df, y_df, k_df = get_data(dataset, 'df', src_class)\n","#         print(f'x_df.shape: {x_df.shape} | np.unique(y_df): {np.unique(y_df)}\\n')\n","\n","#         # Train on Df data\n","#         print('Training on Df data...')\n","#         df_model = train_only(x_df, y_df, dataset, num_epochs=num_epochs)\n","\n","#         # Load synthetic data\n","#         x_syn, y_syn, k_syn = get_syn_data(dataset, syn_name, src_class)\n","#         print(f'x_syn.shape: {x_syn.shape} | np.unique(y_syn): {np.unique(y_syn)}')\n","\n","#         # Load Dp data\n","#         x_dp, y_dp, k_dp = get_data(dataset, 'dp', src_class)\n","#         print(f'x_dp.shape: {x_dp.shape} | np.unique(y_dp): {np.unique(y_dp)}\\n')\n","\n","#         # Fine-tune Df model on synthetic data and evaluate on Dp data\n","#         print('Fine-tuning on synthetic data...')\n","#         df_syn_model = fine_tune(copy.deepcopy(df_model), x_syn, y_syn, num_epochs=num_epochs)\n","#         acc, loss = evaluate_model(df_syn_model, get_dataloader(x_dp, y_dp))\n","#         save_scores(src_class, 100, acc, loss, 'Df_Syn_all', dataset)\n","#         accs.append(acc)\n","#         print(f'Source class: {src_class} | Domain: All | Accuracy: {acc:.4f} | Loss: {loss:.4f}\\n')\n","\n","#     print(f\"Mean accuracy: {np.mean(accs):.4f}\\n\")\n","\n","\n","\n","\n","# compute_TSTR_Df_Syn_all('mobiact_realworld')"]},{"cell_type":"code","execution_count":15,"metadata":{"executionInfo":{"elapsed":1391145,"status":"ok","timestamp":1732706076120,"user":{"displayName":"Pietro Castelvetri","userId":"04218697278633758016"},"user_tz":-60},"id":"Y53G-W-A0q0P","colab":{"base_uri":"https://localhost:8080/"},"outputId":"c12d64a5-2191-45c7-b1c6-b952a14a3380"},"outputs":[{"output_type":"stream","name":"stdout","text":["Source class: WAL\n","\n","x_df.shape: (10816, 3, 128) | np.unique(y_df): [0 1 2 3]\n","\n","Domain: 61\n","x_syn_dom.shape: (928, 3, 128) | np.unique(y_syn_dom): [0 1 2 3]\n","x_dp_dom.shape: (855, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","x_syn_dom.shape: (812, 3, 128) | np.unique(y_syn_dom): [0 1 2 3]\n","x_dp_dom.shape: (739, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","x_df_syn.shape: (11628, 3, 128) | np.unique(y_df_syn): [0 1 2 3]\n","Training on Df plus synthetic data...\n","\tEpoch 10/100 - Train loss: 0.0240 - Val accuracy: 0.9898 - Val loss: 0.0334 - Val F1: 0.9898 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.0075 - Val accuracy: 0.9949 - Val loss: 0.0187 - Val F1: 0.9949 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.0031 - Val accuracy: 0.9958 - Val loss: 0.0157 - Val F1: 0.9958 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.0019 - Val accuracy: 0.9972 - Val loss: 0.0129 - Val F1: 0.9972 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.0022 - Val accuracy: 0.9968 - Val loss: 0.0132 - Val F1: 0.9968 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.0006 - Val accuracy: 0.9972 - Val loss: 0.0122 - Val F1: 0.9972 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0004 - Val accuracy: 0.9968 - Val loss: 0.0123 - Val F1: 0.9968 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0003 - Val accuracy: 0.9968 - Val loss: 0.0129 - Val F1: 0.9968 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0003 - Val accuracy: 0.9972 - Val loss: 0.0126 - Val F1: 0.9972 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0004 - Val accuracy: 0.9968 - Val loss: 0.0125 - Val F1: 0.9968 - LR: 0.00e+00\n","\tBest epoch: 43 - Best val accuracy: 0.9977 - Best val loss: 0.0115 - Best val F1: 0.9977\n","\n","Source class: WAL | Domain: 61 | Accuracy: 0.4330 | Loss: 1.6426 | F1: 0.4677\n","\n","Domain: 62\n","x_syn_dom.shape: (888, 3, 128) | np.unique(y_syn_dom): [0 1 2 3]\n","x_dp_dom.shape: (780, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","x_syn_dom.shape: (777, 3, 128) | np.unique(y_syn_dom): [0 1 2 3]\n","x_dp_dom.shape: (669, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","x_df_syn.shape: (11593, 3, 128) | np.unique(y_df_syn): [0 1 2 3]\n","Training on Df plus synthetic data...\n","\tEpoch 10/100 - Train loss: 0.0292 - Val accuracy: 0.9866 - Val loss: 0.0420 - Val F1: 0.9865 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.0074 - Val accuracy: 0.9921 - Val loss: 0.0239 - Val F1: 0.9921 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.0028 - Val accuracy: 0.9912 - Val loss: 0.0295 - Val F1: 0.9912 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.0014 - Val accuracy: 0.9912 - Val loss: 0.0271 - Val F1: 0.9912 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.0008 - Val accuracy: 0.9921 - Val loss: 0.0220 - Val F1: 0.9921 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.0020 - Val accuracy: 0.9931 - Val loss: 0.0277 - Val F1: 0.9930 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0003 - Val accuracy: 0.9935 - Val loss: 0.0213 - Val F1: 0.9935 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0006 - Val accuracy: 0.9921 - Val loss: 0.0261 - Val F1: 0.9921 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0001 - Val accuracy: 0.9931 - Val loss: 0.0230 - Val F1: 0.9931 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0002 - Val accuracy: 0.9926 - Val loss: 0.0246 - Val F1: 0.9926 - LR: 0.00e+00\n","\tBest epoch: 63 - Best val accuracy: 0.9931 - Best val loss: 0.0197 - Best val F1: 0.9930\n","\n","Source class: WAL | Domain: 62 | Accuracy: 0.5022 | Loss: 3.5709 | F1: 0.4196\n","\n","Domain: 63\n","x_syn_dom.shape: (996, 3, 128) | np.unique(y_syn_dom): [0 1 2 3]\n","x_dp_dom.shape: (859, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","x_syn_dom.shape: (871, 3, 128) | np.unique(y_syn_dom): [0 1 2 3]\n","x_dp_dom.shape: (735, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","x_df_syn.shape: (11687, 3, 128) | np.unique(y_df_syn): [0 1 2 3]\n","Training on Df plus synthetic data...\n","\tEpoch 10/100 - Train loss: 0.0289 - Val accuracy: 0.9921 - Val loss: 0.0240 - Val F1: 0.9921 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.0064 - Val accuracy: 0.9935 - Val loss: 0.0157 - Val F1: 0.9935 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.0074 - Val accuracy: 0.9945 - Val loss: 0.0150 - Val F1: 0.9944 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.0014 - Val accuracy: 0.9972 - Val loss: 0.0096 - Val F1: 0.9972 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.0014 - Val accuracy: 0.9958 - Val loss: 0.0138 - Val F1: 0.9958 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.0018 - Val accuracy: 0.9963 - Val loss: 0.0100 - Val F1: 0.9963 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0003 - Val accuracy: 0.9968 - Val loss: 0.0095 - Val F1: 0.9968 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0003 - Val accuracy: 0.9972 - Val loss: 0.0098 - Val F1: 0.9972 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0003 - Val accuracy: 0.9968 - Val loss: 0.0100 - Val F1: 0.9968 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0002 - Val accuracy: 0.9963 - Val loss: 0.0113 - Val F1: 0.9963 - LR: 0.00e+00\n","\tBest epoch: 44 - Best val accuracy: 0.9963 - Best val loss: 0.0080 - Best val F1: 0.9963\n","\n","Source class: WAL | Domain: 63 | Accuracy: 0.2272 | Loss: 4.2253 | F1: 0.1560\n","\n","Domain: 64\n","x_syn_dom.shape: (896, 3, 128) | np.unique(y_syn_dom): [0 1 2 3]\n","x_dp_dom.shape: (481, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","x_syn_dom.shape: (784, 3, 128) | np.unique(y_syn_dom): [0 1 2 3]\n","x_dp_dom.shape: (369, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","x_df_syn.shape: (11600, 3, 128) | np.unique(y_df_syn): [0 1 2 3]\n","Training on Df plus synthetic data...\n","\tEpoch 10/100 - Train loss: 0.0366 - Val accuracy: 0.9884 - Val loss: 0.0328 - Val F1: 0.9884 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.0076 - Val accuracy: 0.9857 - Val loss: 0.0438 - Val F1: 0.9858 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.0048 - Val accuracy: 0.9949 - Val loss: 0.0169 - Val F1: 0.9949 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.0012 - Val accuracy: 0.9958 - Val loss: 0.0158 - Val F1: 0.9958 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.0029 - Val accuracy: 0.9958 - Val loss: 0.0144 - Val F1: 0.9958 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.0005 - Val accuracy: 0.9972 - Val loss: 0.0120 - Val F1: 0.9972 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0008 - Val accuracy: 0.9958 - Val loss: 0.0161 - Val F1: 0.9958 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0003 - Val accuracy: 0.9968 - Val loss: 0.0126 - Val F1: 0.9968 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0006 - Val accuracy: 0.9968 - Val loss: 0.0120 - Val F1: 0.9968 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0002 - Val accuracy: 0.9963 - Val loss: 0.0133 - Val F1: 0.9963 - LR: 0.00e+00\n","\tBest epoch: 90 - Best val accuracy: 0.9968 - Best val loss: 0.0120 - Best val F1: 0.9968\n","\n","Source class: WAL | Domain: 64 | Accuracy: 0.6369 | Loss: 2.0819 | F1: 0.6056\n","\n","Domain: 65\n","x_syn_dom.shape: (1016, 3, 128) | np.unique(y_syn_dom): [0 1 2 3]\n","x_dp_dom.shape: (840, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","x_syn_dom.shape: (889, 3, 128) | np.unique(y_syn_dom): [0 1 2 3]\n","x_dp_dom.shape: (713, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","x_df_syn.shape: (11705, 3, 128) | np.unique(y_df_syn): [0 1 2 3]\n","Training on Df plus synthetic data...\n","\tEpoch 10/100 - Train loss: 0.0233 - Val accuracy: 0.9898 - Val loss: 0.0304 - Val F1: 0.9898 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.0062 - Val accuracy: 0.9963 - Val loss: 0.0143 - Val F1: 0.9963 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.0034 - Val accuracy: 0.9968 - Val loss: 0.0135 - Val F1: 0.9968 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.0012 - Val accuracy: 0.9972 - Val loss: 0.0110 - Val F1: 0.9972 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.0019 - Val accuracy: 0.9954 - Val loss: 0.0121 - Val F1: 0.9954 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.0005 - Val accuracy: 0.9982 - Val loss: 0.0082 - Val F1: 0.9981 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0007 - Val accuracy: 0.9972 - Val loss: 0.0122 - Val F1: 0.9972 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0002 - Val accuracy: 0.9977 - Val loss: 0.0097 - Val F1: 0.9977 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0008 - Val accuracy: 0.9977 - Val loss: 0.0121 - Val F1: 0.9977 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0002 - Val accuracy: 0.9977 - Val loss: 0.0103 - Val F1: 0.9977 - LR: 0.00e+00\n","\tBest epoch: 65 - Best val accuracy: 0.9958 - Best val loss: 0.0078 - Best val F1: 0.9958\n","\n","Source class: WAL | Domain: 65 | Accuracy: 0.3086 | Loss: 4.2844 | F1: 0.2669\n","\n","Domain: 66\n","x_syn_dom.shape: (916, 3, 128) | np.unique(y_syn_dom): [0 1 2 3]\n","x_dp_dom.shape: (792, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","x_syn_dom.shape: (801, 3, 128) | np.unique(y_syn_dom): [0 1 2 3]\n","x_dp_dom.shape: (678, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","x_df_syn.shape: (11617, 3, 128) | np.unique(y_df_syn): [0 1 2 3]\n","Training on Df plus synthetic data...\n","\tEpoch 10/100 - Train loss: 0.0336 - Val accuracy: 0.9732 - Val loss: 0.0685 - Val F1: 0.9734 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.0099 - Val accuracy: 0.9912 - Val loss: 0.0239 - Val F1: 0.9912 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.0028 - Val accuracy: 0.9931 - Val loss: 0.0230 - Val F1: 0.9930 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.0017 - Val accuracy: 0.9926 - Val loss: 0.0189 - Val F1: 0.9926 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.0007 - Val accuracy: 0.9921 - Val loss: 0.0183 - Val F1: 0.9921 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.0009 - Val accuracy: 0.9926 - Val loss: 0.0210 - Val F1: 0.9926 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0004 - Val accuracy: 0.9926 - Val loss: 0.0221 - Val F1: 0.9926 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0003 - Val accuracy: 0.9935 - Val loss: 0.0213 - Val F1: 0.9935 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0006 - Val accuracy: 0.9926 - Val loss: 0.0210 - Val F1: 0.9926 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0001 - Val accuracy: 0.9940 - Val loss: 0.0204 - Val F1: 0.9940 - LR: 0.00e+00\n","\tBest epoch: 50 - Best val accuracy: 0.9921 - Best val loss: 0.0183 - Best val F1: 0.9921\n","\n","Source class: WAL | Domain: 66 | Accuracy: 0.4764 | Loss: 2.5480 | F1: 0.4384\n","\n","Domain: 67\n","x_syn_dom.shape: (892, 3, 128) | np.unique(y_syn_dom): [0 1 2 3]\n","x_dp_dom.shape: (572, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","x_syn_dom.shape: (780, 3, 128) | np.unique(y_syn_dom): [0 1 2 3]\n","x_dp_dom.shape: (461, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","x_df_syn.shape: (11596, 3, 128) | np.unique(y_df_syn): [0 1 2 3]\n","Training on Df plus synthetic data...\n","\tEpoch 10/100 - Train loss: 0.0401 - Val accuracy: 0.9848 - Val loss: 0.0445 - Val F1: 0.9846 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.0070 - Val accuracy: 0.9917 - Val loss: 0.0328 - Val F1: 0.9916 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.0039 - Val accuracy: 0.9926 - Val loss: 0.0205 - Val F1: 0.9926 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.0022 - Val accuracy: 0.9926 - Val loss: 0.0177 - Val F1: 0.9926 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.0009 - Val accuracy: 0.9931 - Val loss: 0.0183 - Val F1: 0.9931 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.0014 - Val accuracy: 0.9940 - Val loss: 0.0173 - Val F1: 0.9940 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0005 - Val accuracy: 0.9940 - Val loss: 0.0181 - Val F1: 0.9940 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0014 - Val accuracy: 0.9954 - Val loss: 0.0156 - Val F1: 0.9954 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0003 - Val accuracy: 0.9949 - Val loss: 0.0164 - Val F1: 0.9949 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0003 - Val accuracy: 0.9945 - Val loss: 0.0175 - Val F1: 0.9944 - LR: 0.00e+00\n","\tBest epoch: 72 - Best val accuracy: 0.9940 - Best val loss: 0.0125 - Best val F1: 0.9940\n","\n","Source class: WAL | Domain: 67 | Accuracy: 0.5011 | Loss: 2.6815 | F1: 0.4998\n","\n","Domain: 68\n","x_syn_dom.shape: (956, 3, 128) | np.unique(y_syn_dom): [0 1 2 3]\n","x_dp_dom.shape: (877, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","x_syn_dom.shape: (836, 3, 128) | np.unique(y_syn_dom): [0 1 2 3]\n","x_dp_dom.shape: (758, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","x_df_syn.shape: (11652, 3, 128) | np.unique(y_df_syn): [0 1 2 3]\n","Training on Df plus synthetic data...\n","\tEpoch 10/100 - Train loss: 0.0302 - Val accuracy: 0.9917 - Val loss: 0.0321 - Val F1: 0.9916 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.0109 - Val accuracy: 0.9949 - Val loss: 0.0199 - Val F1: 0.9949 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.0026 - Val accuracy: 0.9954 - Val loss: 0.0138 - Val F1: 0.9954 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.0010 - Val accuracy: 0.9963 - Val loss: 0.0142 - Val F1: 0.9963 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.0020 - Val accuracy: 0.9940 - Val loss: 0.0165 - Val F1: 0.9940 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.0004 - Val accuracy: 0.9954 - Val loss: 0.0133 - Val F1: 0.9954 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0005 - Val accuracy: 0.9949 - Val loss: 0.0186 - Val F1: 0.9949 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0007 - Val accuracy: 0.9963 - Val loss: 0.0129 - Val F1: 0.9963 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0002 - Val accuracy: 0.9958 - Val loss: 0.0138 - Val F1: 0.9958 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0002 - Val accuracy: 0.9958 - Val loss: 0.0137 - Val F1: 0.9958 - LR: 0.00e+00\n","\tBest epoch: 53 - Best val accuracy: 0.9972 - Best val loss: 0.0111 - Best val F1: 0.9972\n","\n","Source class: WAL | Domain: 68 | Accuracy: 0.8193 | Loss: 0.6531 | F1: 0.8095\n","\n","Domain: 69\n","x_syn_dom.shape: (908, 3, 128) | np.unique(y_syn_dom): [0 1 2 3]\n","x_dp_dom.shape: (799, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","x_syn_dom.shape: (794, 3, 128) | np.unique(y_syn_dom): [0 1 2 3]\n","x_dp_dom.shape: (686, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","x_df_syn.shape: (11610, 3, 128) | np.unique(y_df_syn): [0 1 2 3]\n","Training on Df plus synthetic data...\n","\tEpoch 10/100 - Train loss: 0.0273 - Val accuracy: 0.9908 - Val loss: 0.0307 - Val F1: 0.9906 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.0076 - Val accuracy: 0.9949 - Val loss: 0.0153 - Val F1: 0.9949 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.0040 - Val accuracy: 0.9958 - Val loss: 0.0130 - Val F1: 0.9958 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.0025 - Val accuracy: 0.9954 - Val loss: 0.0141 - Val F1: 0.9954 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.0007 - Val accuracy: 0.9972 - Val loss: 0.0135 - Val F1: 0.9972 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.0004 - Val accuracy: 0.9963 - Val loss: 0.0145 - Val F1: 0.9963 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0004 - Val accuracy: 0.9972 - Val loss: 0.0126 - Val F1: 0.9972 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0004 - Val accuracy: 0.9972 - Val loss: 0.0118 - Val F1: 0.9972 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0002 - Val accuracy: 0.9977 - Val loss: 0.0119 - Val F1: 0.9977 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0002 - Val accuracy: 0.9977 - Val loss: 0.0120 - Val F1: 0.9977 - LR: 0.00e+00\n","\tBest epoch: 84 - Best val accuracy: 0.9977 - Best val loss: 0.0107 - Best val F1: 0.9977\n","\n","Source class: WAL | Domain: 69 | Accuracy: 0.5714 | Loss: 2.8728 | F1: 0.4712\n","\n","Domain: 70\n","x_syn_dom.shape: (920, 3, 128) | np.unique(y_syn_dom): [0 1 2 3]\n","x_dp_dom.shape: (762, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","x_syn_dom.shape: (805, 3, 128) | np.unique(y_syn_dom): [0 1 2 3]\n","x_dp_dom.shape: (647, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","x_df_syn.shape: (11621, 3, 128) | np.unique(y_df_syn): [0 1 2 3]\n","Training on Df plus synthetic data...\n","\tEpoch 10/100 - Train loss: 0.0335 - Val accuracy: 0.9871 - Val loss: 0.0426 - Val F1: 0.9869 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.0075 - Val accuracy: 0.9917 - Val loss: 0.0224 - Val F1: 0.9917 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.0041 - Val accuracy: 0.9926 - Val loss: 0.0186 - Val F1: 0.9925 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.0019 - Val accuracy: 0.9940 - Val loss: 0.0163 - Val F1: 0.9939 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.0015 - Val accuracy: 0.9940 - Val loss: 0.0182 - Val F1: 0.9939 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.0005 - Val accuracy: 0.9954 - Val loss: 0.0121 - Val F1: 0.9954 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0005 - Val accuracy: 0.9958 - Val loss: 0.0126 - Val F1: 0.9958 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0004 - Val accuracy: 0.9945 - Val loss: 0.0125 - Val F1: 0.9944 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0007 - Val accuracy: 0.9954 - Val loss: 0.0124 - Val F1: 0.9954 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0003 - Val accuracy: 0.9949 - Val loss: 0.0133 - Val F1: 0.9949 - LR: 0.00e+00\n","\tBest epoch: 72 - Best val accuracy: 0.9963 - Best val loss: 0.0107 - Best val F1: 0.9963\n","\n","Source class: WAL | Domain: 70 | Accuracy: 0.4328 | Loss: 3.3915 | F1: 0.3919\n","\n","Domain: 71\n","x_syn_dom.shape: (968, 3, 128) | np.unique(y_syn_dom): [0 1 2 3]\n","x_dp_dom.shape: (854, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","x_syn_dom.shape: (847, 3, 128) | np.unique(y_syn_dom): [0 1 2 3]\n","x_dp_dom.shape: (733, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","x_df_syn.shape: (11663, 3, 128) | np.unique(y_df_syn): [0 1 2 3]\n","Training on Df plus synthetic data...\n","\tEpoch 10/100 - Train loss: 0.0314 - Val accuracy: 0.9880 - Val loss: 0.0366 - Val F1: 0.9878 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.0073 - Val accuracy: 0.9940 - Val loss: 0.0164 - Val F1: 0.9940 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.0027 - Val accuracy: 0.9940 - Val loss: 0.0192 - Val F1: 0.9940 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.0053 - Val accuracy: 0.9940 - Val loss: 0.0177 - Val F1: 0.9940 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.0009 - Val accuracy: 0.9945 - Val loss: 0.0164 - Val F1: 0.9944 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.0007 - Val accuracy: 0.9945 - Val loss: 0.0152 - Val F1: 0.9944 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0010 - Val accuracy: 0.9958 - Val loss: 0.0164 - Val F1: 0.9958 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0004 - Val accuracy: 0.9940 - Val loss: 0.0142 - Val F1: 0.9940 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0003 - Val accuracy: 0.9949 - Val loss: 0.0133 - Val F1: 0.9949 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0002 - Val accuracy: 0.9949 - Val loss: 0.0143 - Val F1: 0.9949 - LR: 0.00e+00\n","\tBest epoch: 38 - Best val accuracy: 0.9954 - Best val loss: 0.0114 - Best val F1: 0.9954\n","\n","Source class: WAL | Domain: 71 | Accuracy: 0.2660 | Loss: 3.9966 | F1: 0.2221\n","\n","Domain: 72\n","x_syn_dom.shape: (920, 3, 128) | np.unique(y_syn_dom): [0 1 2 3]\n","x_dp_dom.shape: (811, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","x_syn_dom.shape: (805, 3, 128) | np.unique(y_syn_dom): [0 1 2 3]\n","x_dp_dom.shape: (696, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","x_df_syn.shape: (11621, 3, 128) | np.unique(y_df_syn): [0 1 2 3]\n","Training on Df plus synthetic data...\n","\tEpoch 10/100 - Train loss: 0.0325 - Val accuracy: 0.9871 - Val loss: 0.0344 - Val F1: 0.9869 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.0123 - Val accuracy: 0.9945 - Val loss: 0.0165 - Val F1: 0.9944 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.0024 - Val accuracy: 0.9949 - Val loss: 0.0161 - Val F1: 0.9949 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.0015 - Val accuracy: 0.9963 - Val loss: 0.0100 - Val F1: 0.9963 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.0009 - Val accuracy: 0.9954 - Val loss: 0.0161 - Val F1: 0.9954 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.0009 - Val accuracy: 0.9949 - Val loss: 0.0154 - Val F1: 0.9949 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0007 - Val accuracy: 0.9972 - Val loss: 0.0122 - Val F1: 0.9972 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0004 - Val accuracy: 0.9963 - Val loss: 0.0120 - Val F1: 0.9963 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0004 - Val accuracy: 0.9977 - Val loss: 0.0137 - Val F1: 0.9977 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0002 - Val accuracy: 0.9968 - Val loss: 0.0121 - Val F1: 0.9968 - LR: 0.00e+00\n","\tBest epoch: 37 - Best val accuracy: 0.9968 - Best val loss: 0.0088 - Best val F1: 0.9968\n","\n","Source class: WAL | Domain: 72 | Accuracy: 0.1681 | Loss: 6.2812 | F1: 0.0552\n","\n","Domain: 73\n","x_syn_dom.shape: (952, 3, 128) | np.unique(y_syn_dom): [0 1 2 3]\n","x_dp_dom.shape: (815, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","x_syn_dom.shape: (833, 3, 128) | np.unique(y_syn_dom): [0 1 2 3]\n","x_dp_dom.shape: (696, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","x_df_syn.shape: (11649, 3, 128) | np.unique(y_df_syn): [0 1 2 3]\n","Training on Df plus synthetic data...\n","\tEpoch 10/100 - Train loss: 0.0312 - Val accuracy: 0.9843 - Val loss: 0.0432 - Val F1: 0.9841 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.0094 - Val accuracy: 0.9903 - Val loss: 0.0265 - Val F1: 0.9903 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.0040 - Val accuracy: 0.9898 - Val loss: 0.0302 - Val F1: 0.9898 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.0020 - Val accuracy: 0.9935 - Val loss: 0.0218 - Val F1: 0.9935 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.0015 - Val accuracy: 0.9926 - Val loss: 0.0252 - Val F1: 0.9926 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.0014 - Val accuracy: 0.9917 - Val loss: 0.0246 - Val F1: 0.9916 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0010 - Val accuracy: 0.9921 - Val loss: 0.0225 - Val F1: 0.9922 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0004 - Val accuracy: 0.9949 - Val loss: 0.0217 - Val F1: 0.9949 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0006 - Val accuracy: 0.9940 - Val loss: 0.0241 - Val F1: 0.9940 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0003 - Val accuracy: 0.9945 - Val loss: 0.0225 - Val F1: 0.9944 - LR: 0.00e+00\n","\tBest epoch: 93 - Best val accuracy: 0.9940 - Best val loss: 0.0206 - Best val F1: 0.9940\n","\n","Source class: WAL | Domain: 73 | Accuracy: 0.4138 | Loss: 3.2602 | F1: 0.3804\n","\n","Domain: 74\n","x_syn_dom.shape: (976, 3, 128) | np.unique(y_syn_dom): [0 1 2 3]\n","x_dp_dom.shape: (563, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","x_syn_dom.shape: (854, 3, 128) | np.unique(y_syn_dom): [0 1 2 3]\n","x_dp_dom.shape: (441, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","x_df_syn.shape: (11670, 3, 128) | np.unique(y_df_syn): [0 1 2 3]\n","Training on Df plus synthetic data...\n","\tEpoch 10/100 - Train loss: 0.0264 - Val accuracy: 0.9898 - Val loss: 0.0296 - Val F1: 0.9899 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.0069 - Val accuracy: 0.9917 - Val loss: 0.0244 - Val F1: 0.9916 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.0024 - Val accuracy: 0.9926 - Val loss: 0.0200 - Val F1: 0.9926 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.0014 - Val accuracy: 0.9945 - Val loss: 0.0173 - Val F1: 0.9945 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.0006 - Val accuracy: 0.9931 - Val loss: 0.0202 - Val F1: 0.9930 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.0008 - Val accuracy: 0.9935 - Val loss: 0.0175 - Val F1: 0.9935 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0004 - Val accuracy: 0.9921 - Val loss: 0.0219 - Val F1: 0.9921 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0004 - Val accuracy: 0.9945 - Val loss: 0.0170 - Val F1: 0.9944 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0009 - Val accuracy: 0.9935 - Val loss: 0.0208 - Val F1: 0.9935 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0003 - Val accuracy: 0.9954 - Val loss: 0.0172 - Val F1: 0.9954 - LR: 0.00e+00\n","\tBest epoch: 97 - Best val accuracy: 0.9958 - Best val loss: 0.0161 - Best val F1: 0.9958\n","\n","Source class: WAL | Domain: 74 | Accuracy: 0.6032 | Loss: 2.0631 | F1: 0.5954\n","\n","Domain: 75\n","x_syn_dom.shape: (968, 3, 128) | np.unique(y_syn_dom): [0 1 2 3]\n","x_dp_dom.shape: (823, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","x_syn_dom.shape: (847, 3, 128) | np.unique(y_syn_dom): [0 1 2 3]\n","x_dp_dom.shape: (702, 3, 128) | np.unique(y_dp_dom): [0 1 2 3]\n","\n","x_df_syn.shape: (11663, 3, 128) | np.unique(y_df_syn): [0 1 2 3]\n","Training on Df plus synthetic data...\n","\tEpoch 10/100 - Train loss: 0.0241 - Val accuracy: 0.9912 - Val loss: 0.0257 - Val F1: 0.9912 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.0063 - Val accuracy: 0.9917 - Val loss: 0.0228 - Val F1: 0.9916 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.0021 - Val accuracy: 0.9949 - Val loss: 0.0130 - Val F1: 0.9949 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.0022 - Val accuracy: 0.9945 - Val loss: 0.0132 - Val F1: 0.9944 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.0007 - Val accuracy: 0.9963 - Val loss: 0.0084 - Val F1: 0.9963 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.0012 - Val accuracy: 0.9963 - Val loss: 0.0095 - Val F1: 0.9963 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0009 - Val accuracy: 0.9958 - Val loss: 0.0098 - Val F1: 0.9958 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0005 - Val accuracy: 0.9958 - Val loss: 0.0102 - Val F1: 0.9958 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0008 - Val accuracy: 0.9954 - Val loss: 0.0105 - Val F1: 0.9954 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0003 - Val accuracy: 0.9958 - Val loss: 0.0101 - Val F1: 0.9958 - LR: 0.00e+00\n","\tBest epoch: 56 - Best val accuracy: 0.9958 - Best val loss: 0.0075 - Best val F1: 0.9959\n","\n","Source class: WAL | Domain: 75 | Accuracy: 0.4444 | Loss: 3.7155 | F1: 0.3924\n","\n","Mean accuracy: 0.4536 +- 0.1633\n","Mean F1: 0.4115 +- 0.1818\n","\n"]}],"source":["def compute_TSTR_Df_plus_Syn(dataset):\n","    accs = []\n","    f1s = []\n","\n","    for src_class in config[dataset]['class_names']:\n","        if src_class != 'WAL':\n","            continue\n","\n","        print(f\"Source class: {src_class}\\n\")\n","\n","        # Load Df data\n","        x_df, y_df, k_df = get_data(dataset, 'df', src_class)\n","        print(f'x_df.shape: {x_df.shape} | np.unique(y_df): {np.unique(y_df)}\\n')\n","\n","        for domain in range(config[dataset]['num_df_domains'], config[dataset]['num_df_domains'] + config[dataset]['num_dp_domains']):\n","            print(f\"Domain: {domain}\")\n","\n","            # Load synthetic data\n","            x_syn_dom, y_syn_dom, k_syn_dom = get_syn_data(dataset, syn_name, src_class, domain)\n","            print(f'x_syn_dom.shape: {x_syn_dom.shape} | np.unique(y_syn_dom): {np.unique(y_syn_dom)}')\n","\n","            # Load Dp data\n","            x_dp_dom, y_dp_dom, k_dp_dom = get_data(dataset, 'dp', src_class, domain)\n","            print(f'x_dp_dom.shape: {x_dp_dom.shape} | np.unique(y_dp_dom): {np.unique(y_dp_dom)}\\n')\n","\n","            y0_indices_syn = np.where(y_syn_dom == 0)[0]\n","            y0_indices_dp = np.where(y_dp_dom == 0)[0]\n","            assert np.array_equal(y0_indices_syn, y0_indices_dp), \"Labels do not match\"\n","            assert np.array_equal(y_syn_dom[y0_indices_syn], y_dp_dom[y0_indices_dp]), \"Labels do not match\"\n","\n","            y0_indices_train, y0_indices_test = train_test_split(y0_indices_syn, test_size=0.5, shuffle=True, random_state=seed)\n","\n","            x_syn_dom_y0, y_syn_dom_y0 = x_syn_dom[y0_indices_train], y_syn_dom[y0_indices_train]\n","            x_dp_dom_y0, y_dp_dom_y0 = x_dp_dom[y0_indices_test], y_dp_dom[y0_indices_test]\n","\n","            x_syn_dom = np.concatenate([x_syn_dom_y0, x_syn_dom[y_syn_dom != 0]])\n","            y_syn_dom = np.concatenate([y_syn_dom_y0, y_syn_dom[y_syn_dom != 0]])\n","            x_dp_dom = np.concatenate([x_dp_dom_y0, x_dp_dom[y_dp_dom != 0]])\n","            y_dp_dom = np.concatenate([y_dp_dom_y0, y_dp_dom[y_dp_dom != 0]])\n","\n","            print(f'x_syn_dom.shape: {x_syn_dom.shape} | np.unique(y_syn_dom): {np.unique(y_syn_dom)}')\n","            print(f'x_dp_dom.shape: {x_dp_dom.shape} | np.unique(y_dp_dom): {np.unique(y_dp_dom)}\\n')\n","\n","            # Join Df and synthetic data\n","            x_df_syn = np.concatenate([x_df, x_syn_dom], axis=0)\n","            y_df_syn = np.concatenate([y_df, y_syn_dom], axis=0)\n","            k_df_syn = np.concatenate([k_df, k_syn_dom], axis=0)\n","            print(f'x_df_syn.shape: {x_df_syn.shape} | np.unique(y_df_syn): {np.unique(y_df_syn)}')\n","\n","            # Train on Df plus synthetic data and test on Dp data\n","            print('Training on Df plus synthetic data...')\n","            acc, loss, f1 = train_and_test(x_df, y_df, x_dp_dom, y_dp_dom, dataset, num_epochs=num_epochs)\n","            save_scores(src_class, domain, acc, loss, f1, 'Df_plus_Syn', dataset)\n","            accs.append(acc)\n","            f1s.append(f1)\n","            print(f'Source class: {src_class} | Domain: {domain} | Accuracy: {acc:.4f} | Loss: {loss:.4f} | F1: {f1:.4f}\\n')\n","\n","    print(f\"Mean accuracy: {np.mean(accs):.4f} +- {np.std(accs):.4f}\")\n","    print(f\"Mean F1: {np.mean(f1s):.4f} +- {np.std(f1s):.4f}\\n\")\n","\n","\n","\n","\n","compute_TSTR_Df_plus_Syn('mobiact_realworld')"]},{"cell_type":"markdown","metadata":{"id":"fLSuTddOmD5c"},"source":["# TSTRFS"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"wZqvTTwNCPto"},"outputs":[],"source":["def compute_TSTRFS_Dpfs(dataset):\n","    accs = []\n","\n","    for src_class in config[dataset]['class_names']:\n","        if src_class != 'WAL':\n","            continue\n","\n","        print(f\"Source class: {src_class}\\n\")\n","\n","        for domain in range(config[dataset]['num_df_domains'], config[dataset]['num_df_domains'] + config[dataset]['num_dp_domains']):\n","            print(f\"Domain: {domain}\")\n","\n","            # Load Dpfs data\n","            x_dpfs_dom, y_dpfs_dom, k_dpfs_dom = get_data(dataset, 'dpfs', src_class, domain)\n","            print(f'x_dpfs_dom.shape: {x_dpfs_dom.shape} | np.unique(y_dpfs_dom): {np.unique(y_dpfs_dom)}')\n","\n","            # Load Dp data\n","            x_dp_dom, y_dp_dom, k_dp_dom = get_data(dataset, 'dp', src_class, domain)\n","            print(f'x_dp_dom.shape: {x_dp_dom.shape} | np.unique(y_dp_dom): {np.unique(y_dp_dom)}\\n')\n","\n","            # Train on Dpfs data and test on Dp data\n","            print('Training on Dpfs data...')\n","            acc, loss = train_and_test(x_dpfs_dom, y_dpfs_dom, x_dp_dom, y_dp_dom, dataset, num_epochs=num_epochs)\n","            save_scores(src_class, domain, acc, loss, 'FS_Dpfs', dataset)\n","            accs.append(acc)\n","            print(f'Source class: {src_class} | Domain: {domain} | Accuracy: {acc:.4f} | Loss: {loss:.4f}\\n')\n","\n","    print(f\"Mean accuracy: {np.mean(accs):.4f}\\n\")\n","\n","\n","\n","compute_TSTRFS_Dpfs('mobiact_realworld')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"YOqZB6ARCPtp"},"outputs":[],"source":["def compute_TSTRFS_Df_Dpfs(dataset):\n","    accs = []\n","\n","    for src_class in config[dataset]['class_names']:\n","        if src_class != 'WAL':\n","            continue\n","\n","        print(f\"Source class: {src_class}\\n\")\n","\n","        # Load Df data\n","        x_df, y_df, k_df = get_data(dataset, 'df', src_class)\n","        print(f'x_df.shape: {x_df.shape} | np.unique(y_df): {np.unique(y_df)}\\n')\n","\n","        # Train on Df data\n","        print('Training on Df data...')\n","        df_model = train_only(x_df, y_df, dataset, num_epochs=num_epochs)\n","\n","        for domain in range(config[dataset]['num_df_domains'], config[dataset]['num_df_domains'] + config[dataset]['num_dp_domains']):\n","            print(f\"Domain: {domain}\")\n","\n","            # Load Dpfs data\n","            x_dpfs_dom, y_dpfs_dom, k_dpfs_dom = get_data(dataset, 'dpfs', src_class, domain)\n","            print(f'x_dpfs_dom.shape: {x_dpfs_dom.shape} | np.unique(y_dpfs_dom): {np.unique(y_dpfs_dom)}')\n","\n","            # Load Dp data\n","            x_dp_dom, y_dp_dom, k_dp_dom = get_data(dataset, 'dp', src_class, domain)\n","            print(f'x_dp_dom.shape: {x_dp_dom.shape} | np.unique(y_dp_dom): {np.unique(y_dp_dom)}\\n')\n","\n","            # Fine-tune Df model on Dpfs data and test on Dp data\n","            print('Fine-tuning on Dpfs data...')\n","            df_dpfs_model = fine_tune(copy.deepcopy(df_model), x_dpfs_dom, y_dpfs_dom, num_epochs=num_epochs)\n","            acc, loss = evaluate_model(df_dpfs_model, get_dataloader(x_dp_dom, y_dp_dom))\n","            save_scores(src_class, domain, acc, loss, 'FS_Df_Dpfs', dataset)\n","            accs.append(acc)\n","            print(f'Source class: {src_class} | Domain: {domain} | Accuracy: {acc:.4f} | Loss: {loss:.4f}\\n')\n","\n","    print(f\"Mean accuracy: {np.mean(accs):.4f}\\n\")\n","\n","\n","\n","compute_TSTRFS_Df_Dpfs('mobiact_realworld')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"oA89psVZg5yb"},"outputs":[],"source":["def compute_TSTRFS_Syn(dataset):\n","    accs = []\n","\n","    for src_class in config[dataset]['class_names']:\n","        if src_class != 'WAL':\n","            continue\n","\n","        print(f\"Source class: {src_class}\\n\")\n","\n","        for domain in range(config[dataset]['num_df_domains'], config[dataset]['num_df_domains'] + config[dataset]['num_dp_domains']):\n","            print(f\"Domain: {domain}\")\n","\n","            # Load synthetic data\n","            x_syn_dom, y_syn_dom, k_syn_dom = get_syn_data(dataset, syn_name, src_class, domain)\n","            print(f'x_syn_dom.shape: {x_syn_dom.shape} | np.unique(y_syn_dom): {np.unique(y_syn_dom)}')\n","\n","            # Load Dp data\n","            x_dp_dom, y_dp_dom, k_dp_dom = get_data(dataset, 'dp', src_class, domain)\n","            print(f'x_dp_dom.shape: {x_dp_dom.shape} | np.unique(y_dp_dom): {np.unique(y_dp_dom)}\\n')\n","\n","            # Train on synthetic data and evaluate on Dp data\n","            print('Training on synthetic data...')\n","            acc, loss = train_and_test(x_syn_dom, y_syn_dom, x_dp_dom, y_dp_dom, dataset, num_epochs=num_epochs)\n","            save_scores(src_class, domain, acc, loss, 'FS_Syn', dataset)\n","            accs.append(acc)\n","            print(f'Source class: {src_class} | Domain: {domain} | Accuracy: {acc:.4f} | Loss: {loss:.4f}\\n')\n","\n","    print(f\"Mean accuracy: {np.mean(accs):.4f}\\n\")\n","\n","\n","\n","\n","compute_TSTRFS_Syn('mobiact_realworld')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"38LHCQjRCPtp"},"outputs":[],"source":["def compute_TSTRFS_Df_Syn(dataset):\n","    accs = []\n","\n","    for src_class in config[dataset]['class_names']:\n","        if src_class != 'WAL':\n","            continue\n","\n","        print(f\"Source class: {src_class}\\n\")\n","\n","        # Load Df data\n","        x_df, y_df, k_df = get_data(dataset, 'df', src_class)\n","        print(f'x_df.shape: {x_df.shape} | np.unique(y_df): {np.unique(y_df)}\\n')\n","\n","        # Train on Df data\n","        print('Training on Df data...')\n","        df_model = train_only(x_df, y_df, dataset, num_epochs=num_epochs)\n","\n","        for domain in range(config[dataset]['num_df_domains'], config[dataset]['num_df_domains'] + config[dataset]['num_dp_domains']):\n","            print(f\"Domain: {domain}\")\n","\n","            # Load synthetic data\n","            x_syn_dom, y_syn_dom, k_syn_dom = get_syn_data(dataset, syn_name, src_class, domain)\n","            print(f'x_syn_dom.shape: {x_syn_dom.shape} | np.unique(y_syn_dom): {np.unique(y_syn_dom)}')\n","\n","            # Load Dp data\n","            x_dp_dom, y_dp_dom, k_dp_dom = get_data(dataset, 'dp', src_class, domain)\n","            print(f'x_dp_dom.shape: {x_dp_dom.shape} | np.unique(y_dp_dom): {np.unique(y_dp_dom)}\\n')\n","\n","            # Fine-tune Df model on synthetic data and evaluate on Dp data\n","            print('Fine-tuning on synthetic data...')\n","            df_syn_model = fine_tune(copy.deepcopy(df_model), x_syn_dom, y_syn_dom, num_epochs=num_epochs)\n","            acc, loss = evaluate_model(df_syn_model, get_dataloader(x_dp_dom, y_dp_dom))\n","            save_scores(src_class, domain, acc, loss, 'FS_Df_Syn', dataset)\n","            accs.append(acc)\n","            print(f'Source class: {src_class} | Domain: {domain} | Accuracy: {acc:.4f} | Loss: {loss:.4f}\\n')\n","\n","    print(f\"Mean accuracy: {np.mean(accs):.4f}\\n\")\n","\n","\n","\n","\n","compute_TSTRFS_Df_Syn('mobiact_realworld')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ueNEmwhVCPtp"},"outputs":[],"source":["def compute_TSTRFS_Syn_Dpfs(dataset):\n","    accs = []\n","\n","    for src_class in config[dataset]['class_names']:\n","        if src_class != 'WAL':\n","            continue\n","\n","        print(f\"Source class: {src_class}\\n\")\n","\n","        for domain in range(config[dataset]['num_df_domains'], config[dataset]['num_df_domains'] + config[dataset]['num_dp_domains']):\n","            print(f\"Domain: {domain}\")\n","\n","            # Load synthetic data\n","            x_syn_dom, y_syn_dom, k_syn_dom = get_syn_data(dataset, syn_name, src_class, domain)\n","            print(f'x_syn_dom.shape: {x_syn_dom.shape} | np.unique(y_syn_dom): {np.unique(y_syn_dom)}')\n","\n","            # Load Dpfs data\n","            x_dpfs_dom, y_dpfs_dom, k_dpfs_dom = get_data(dataset, 'dpfs', src_class, domain)\n","            print(f'x_dpfs_dom.shape: {x_dpfs_dom.shape} | np.unique(y_dpfs_dom): {np.unique(y_dpfs_dom)}')\n","\n","            # Load Dp data\n","            x_dp_dom, y_dp_dom, k_dp_dom = get_data(dataset, 'dp', src_class, domain)\n","            print(f'x_dp_dom.shape: {x_dp_dom.shape} | np.unique(y_dp_dom): {np.unique(y_dp_dom)}\\n')\n","\n","            # Train on synthetic data\n","            print('Training on synthetic data...')\n","            syn_model = train_only(x_syn_dom, y_syn_dom, dataset, num_epochs=num_epochs)\n","\n","            # Fine-tune synthetic model on Dpfs data and evaluate on Dp data\n","            print('Fine-tuning on Dpfs data...')\n","            syn_dpfs_model = fine_tune(copy.deepcopy(syn_model), x_dpfs_dom, y_dpfs_dom, num_epochs=num_epochs)\n","            acc, loss = evaluate_model(syn_dpfs_model, get_dataloader(x_dp_dom, y_dp_dom))\n","            save_scores(src_class, domain, acc, loss, 'FS_Syn_Dpfs', dataset)\n","            accs.append(acc)\n","            print(f'Source class: {src_class} | Domain: {domain} | Accuracy: {acc:.4f} | Loss: {loss:.4f}\\n')\n","\n","    print(f\"Mean accuracy: {np.mean(accs):.4f}\\n\")\n","\n","\n","\n","\n","compute_TSTRFS_Syn_Dpfs('mobiact_realworld')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"7z0xuuhhCPtp"},"outputs":[],"source":["def compute_TSTRFS_Df_Syn_Dpfs(dataset):\n","    accs = []\n","\n","    for src_class in config[dataset]['class_names']:\n","        if src_class != 'WAL':\n","            continue\n","\n","        print(f\"Source class: {src_class}\\n\")\n","\n","        # Load Df data\n","        x_df, y_df, k_df = get_data(dataset, 'df', src_class)\n","        print(f'x_df.shape: {x_df.shape} | np.unique(y_df): {np.unique(y_df)}\\n')\n","\n","        # Train on Df data\n","        print('Training on Df data...')\n","        df_model = train_only(x_df, y_df, dataset, num_epochs=num_epochs)\n","\n","        for domain in range(config[dataset]['num_df_domains'], config[dataset]['num_df_domains'] + config[dataset]['num_dp_domains']):\n","            print(f\"Domain: {domain}\")\n","\n","            # Load synthetic data\n","            x_syn_dom, y_syn_dom, k_syn_dom = get_syn_data(dataset, syn_name, src_class, domain)\n","            print(f'x_syn_dom.shape: {x_syn_dom.shape} | np.unique(y_syn_dom): {np.unique(y_syn_dom)}')\n","\n","            # Load Dpfs data\n","            x_dpfs_dom, y_dpfs_dom, k_dpfs_dom = get_data(dataset, 'dpfs', src_class, domain)\n","            print(f'x_dpfs_dom.shape: {x_dpfs_dom.shape} | np.unique(y_dpfs_dom): {np.unique(y_dpfs_dom)}')\n","\n","            # Load Dp data\n","            x_dp_dom, y_dp_dom, k_dp_dom = get_data(dataset, 'dp', src_class, domain)\n","            print(f'x_dp_dom.shape: {x_dp_dom.shape} | np.unique(y_dp_dom): {np.unique(y_dp_dom)}\\n')\n","\n","            # Fine-tune Df model on synthetic data\n","            print('Fine-tuning on synthetic data...')\n","            df_syn_model = fine_tune(copy.deepcopy(df_model), x_syn_dom, y_syn_dom, num_epochs=num_epochs)\n","\n","            # Fine-tune Df-syn model on Dpfs data and evaluate on Dp data\n","            print('Fine-tuning on Dpfs data...')\n","            df_syn_dpfs_model = fine_tune(copy.deepcopy(df_syn_model), x_dpfs_dom, y_dpfs_dom, num_epochs=num_epochs)\n","            acc, loss = evaluate_model(df_syn_dpfs_model, get_dataloader(x_dp_dom, y_dp_dom))\n","            save_scores(src_class, domain, acc, loss, 'FS_Df_Syn_Dpfs', dataset)\n","            accs.append(acc)\n","            print(f'Source class: {src_class} | Domain: {domain} | Accuracy: {acc:.4f} | Loss: {loss:.4f}\\n')\n","\n","    print(f\"Mean accuracy: {np.mean(accs):.4f}\\n\")\n","\n","\n","\n","\n","compute_TSTRFS_Df_Syn_Dpfs('mobiact_realworld')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"zpB3ecNGmD5f"},"outputs":[],"source":["def compute_TSTRFS_Df_plus_Dpfs(dataset):\n","    accs = []\n","\n","    for src_class in config[dataset]['class_names']:\n","        if src_class != 'WAL':\n","            continue\n","\n","        print(f\"Source class: {src_class}\\n\")\n","\n","        # Load Df data\n","        x_df, y_df, k_df = get_data(dataset, 'df', src_class)\n","        print(f'x_df.shape: {x_df.shape} | np.unique(y_df): {np.unique(y_df)}\\n')\n","\n","        for domain in range(config[dataset]['num_df_domains'], config[dataset]['num_df_domains'] + config[dataset]['num_dp_domains']):\n","            print(f\"Domain: {domain}\")\n","\n","            # Load Dpfs data\n","            x_dpfs_dom, y_dpfs_dom, k_dpfs_dom = get_data(dataset, 'dpfs', src_class, domain)\n","            print(f'x_dpfs_dom.shape: {x_dpfs_dom.shape} | np.unique(y_dpfs_dom): {np.unique(y_dpfs_dom)}')\n","\n","            # Join Df and Dpfs data\n","            x_df_dpfs = np.concatenate([x_df, x_dpfs_dom], axis=0)\n","            y_df_dpfs = np.concatenate([y_df, y_dpfs_dom], axis=0)\n","            k_df_dpfs = np.concatenate([k_df, k_dpfs_dom], axis=0)\n","            print(f'x_df_dpfs.shape: {x_df_dpfs.shape} | np.unique(y_df_dpfs): {np.unique(y_df_dpfs)}')\n","\n","            # Load Dp data\n","            x_dp_dom, y_dp_dom, k_dp_dom = get_data(dataset, 'dp', src_class, domain)\n","            print(f'x_dp_dom.shape: {x_dp_dom.shape} | np.unique(y_dp_dom): {np.unique(y_dp_dom)}\\n')\n","\n","            # Train on Df plus Dpfs data and test on Dp data\n","            print('Training on Df plus Dpfs data...')\n","            acc, loss = train_and_test(x_df_dpfs, y_df_dpfs, x_dp_dom, y_dp_dom, dataset, num_epochs=num_epochs)\n","            save_scores(src_class, domain, acc, loss, 'FS_Df_plus_Dpfs', dataset)\n","            accs.append(acc)\n","            print(f'Source class: {src_class} | Domain: {domain} | Accuracy: {acc:.4f} | Loss: {loss:.4f}\\n')\n","\n","    print(f\"Mean accuracy: {np.mean(accs):.4f}\\n\")\n","\n","\n","\n","compute_TSTRFS_Df_plus_Dpfs('mobiact_realworld')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"RYl0a9ZJmD5f"},"outputs":[],"source":["def compute_TSTRFS_Df_plus_Syn(dataset):\n","    accs = []\n","\n","    for src_class in config[dataset]['class_names']:\n","        if src_class != 'WAL':\n","            continue\n","\n","        print(f\"Source class: {src_class}\\n\")\n","\n","        # Load Df data\n","        x_df, y_df, k_df = get_data(dataset, 'df', src_class)\n","        print(f'x_df.shape: {x_df.shape} | np.unique(y_df): {np.unique(y_df)}\\n')\n","\n","        for domain in range(config[dataset]['num_df_domains'], config[dataset]['num_df_domains'] + config[dataset]['num_dp_domains']):\n","            print(f\"Domain: {domain}\")\n","\n","            # Load synthetic data\n","            x_syn_dom, y_syn_dom, k_syn_dom = get_syn_data(dataset, syn_name, src_class, domain)\n","            print(f'x_syn_dom.shape: {x_syn_dom.shape} | np.unique(y_syn_dom): {np.unique(y_syn_dom)}')\n","\n","            # Join Df and synthetic data\n","            x_df_syn = np.concatenate([x_df, x_syn_dom], axis=0)\n","            y_df_syn = np.concatenate([y_df, y_syn_dom], axis=0)\n","            k_df_syn = np.concatenate([k_df, k_syn_dom], axis=0)\n","            print(f'x_df_syn.shape: {x_df_syn.shape} | np.unique(y_df_syn): {np.unique(y_df_syn)}')\n","\n","            # Load Dp data\n","            x_dp_dom, y_dp_dom, k_dp_dom = get_data(dataset, 'dp', src_class, domain)\n","            print(f'x_dp_dom.shape: {x_dp_dom.shape} | np.unique(y_dp_dom): {np.unique(y_dp_dom)}\\n')\n","\n","            # Train on Df plus synthetic data and test on Dp data\n","            print('Training on Df plus synthetic data...')\n","            acc, loss = train_and_test(x_df, y_df, x_dp_dom, y_dp_dom, dataset, num_epochs=num_epochs)\n","            save_scores(src_class, domain, acc, loss, 'FS_Df_plus_Syn', dataset)\n","            accs.append(acc)\n","            print(f'Source class: {src_class} | Domain: {domain} | Accuracy: {acc:.4f} | Loss: {loss:.4f}\\n')\n","\n","    print(f\"Mean accuracy: {np.mean(accs):.4f}\\n\")\n","\n","\n","\n","\n","compute_TSTRFS_Df_plus_Syn('mobiact_realworld')"]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[]},"kernelspec":{"display_name":"stargan-v2","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.13"}},"nbformat":4,"nbformat_minor":0}