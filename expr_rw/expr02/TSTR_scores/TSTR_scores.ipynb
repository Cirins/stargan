{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":22404,"status":"ok","timestamp":1731516144577,"user":{"displayName":"Giovanna Pasini","userId":"02341854514736870674"},"user_tz":-60},"id":"I0_1KsKpCPtk","outputId":"e0fcc0ee-1dd4-44cc-a71d-0a5a5e9ba49e"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n","/content/drive/MyDrive/ST/stargan\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')\n","\n","%cd drive/MyDrive/ST/stargan"]},{"cell_type":"markdown","metadata":{"id":"lLVVBGiQmD5W"},"source":["# Configuration"]},{"cell_type":"code","execution_count":2,"metadata":{"executionInfo":{"elapsed":11540,"status":"ok","timestamp":1731516156115,"user":{"displayName":"Giovanna Pasini","userId":"02341854514736870674"},"user_tz":-60},"id":"yh05UGFkCPtm"},"outputs":[],"source":["import pickle\n","import numpy as np\n","from sklearn.model_selection import train_test_split, StratifiedKFold\n","import torch\n","import torch.nn as nn\n","from torch.utils.data import DataLoader, TensorDataset\n","from torch.optim.lr_scheduler import LambdaLR\n","import torch.optim as optim\n","import os\n","import csv\n","import random\n","import copy\n","\n","seed = 2710\n","torch.manual_seed(seed)\n","torch.cuda.manual_seed(seed)\n","np.random.seed(seed)\n","random.seed(seed)"]},{"cell_type":"code","execution_count":3,"metadata":{"executionInfo":{"elapsed":5,"status":"ok","timestamp":1731516156115,"user":{"displayName":"Giovanna Pasini","userId":"02341854514736870674"},"user_tz":-60},"id":"UJN2bKbaCPtm"},"outputs":[],"source":["config = {\n","    'realworld': {\n","        'dataset_name': 'realworld',\n","        'num_df_domains': 10,\n","        'num_dp_domains': 5,\n","        'num_classes': 4,\n","        'class_names': ['WAL', 'RUN', 'CLD', 'CLU'],\n","        'num_timesteps': 128,\n","        'num_channels': 3,\n","        'num_classes': 4,\n","    },\n","    'cwru': {\n","        'dataset_name': 'cwru_256_3ch_5cl',\n","        'num_df_domains': 4,\n","        'num_dp_domains': 4,\n","        'num_classes': 5,\n","        'class_names': ['IR', 'Ball', 'OR_centred', 'OR_orthogonal', 'OR_opposite'],\n","        'num_timesteps': 256,\n","        'num_channels': 3,\n","        'num_classes': 5,\n","    },\n","    'realworld_mobiact': {\n","        'dataset_name': 'realworld_mobiact',\n","        'num_df_domains': 15,\n","        'num_dp_domains': 61,\n","        'num_classes': 4,\n","        'class_names': ['WAL', 'RUN', 'CLD', 'CLU'],\n","        'num_timesteps': 128,\n","        'num_channels': 3,\n","        'num_classes': 4,\n","    }\n","}\n","\n","syn_name = 'rw02'"]},{"cell_type":"code","execution_count":4,"metadata":{"executionInfo":{"elapsed":5,"status":"ok","timestamp":1731516156116,"user":{"displayName":"Giovanna Pasini","userId":"02341854514736870674"},"user_tz":-60},"id":"XwSwaF-LCPtn"},"outputs":[],"source":["def get_data(dataset, domains_set, src_class, domain=None):\n","    # Load configurations\n","    dataset_name = config[dataset]['dataset_name']\n","    class_idx = config[dataset]['class_names'].index(src_class)\n","    num_df_domains = config[dataset]['num_df_domains']\n","\n","    try:\n","        with open(f'data/{dataset_name}.pkl', 'rb') as f:\n","            x, y, k = pickle.load(f)\n","        with open(f'data/{dataset_name}_fs.pkl', 'rb') as f:\n","            fs = pickle.load(f)\n","    except FileNotFoundError:\n","        raise FileNotFoundError(f\"Dataset files for {dataset} not found.\")\n","\n","\n","    if domains_set == 'df':\n","        mask = (y != class_idx) & (k < num_df_domains) & (fs == 0)\n","    elif domains_set == 'dp':\n","        mask = (y != class_idx) & (k >= num_df_domains) & (fs == 0)\n","    elif domains_set == 'dpfs':\n","        mask = (y != class_idx) & (k >= num_df_domains) & (fs == 1)\n","    else:\n","        raise ValueError(f\"Invalid domains set: {domains_set}\")\n","\n","    # Apply initial mask\n","    x, y, k = x[mask], y[mask], k[mask]\n","\n","    # Additional domain filtering if specified\n","    if domain is not None:\n","        domain_mask = (k == domain)\n","        x, y, k = x[domain_mask], y[domain_mask], k[domain_mask]\n","\n","    assert len(x) > 0, f\"No data found\"\n","    assert len(x) == len(y) == len(k), f\"Data length mismatch\"\n","\n","    return x, y, k\n","\n","\n","\n","def get_syn_data(dataset, syn_name, src_class, domain=None, fs=False):\n","    # Load configurations\n","    class_names = config[dataset]['class_names']\n","\n","    try:\n","        with open(f'data/{dataset}_{syn_name}.pkl', 'rb') as f:\n","            x, y, k = pickle.load(f)\n","    except FileNotFoundError:\n","        raise FileNotFoundError(f\"Dataset files for {dataset} not found.\")\n","\n","    with open(f'data/{dataset}_fs_{syn_name}.pkl', 'rb') as f:\n","        fs = pickle.load(f)\n","\n","    x, y, k = x[fs == 0], y[fs == 0], k[fs == 0]\n","\n","    if domain is not None:\n","        domain_mask = (k == domain)\n","        x, y, k = x[domain_mask], y[domain_mask], k[domain_mask]\n","\n","    assert len(x) > 0, f\"No data found\"\n","    assert len(x) == len(y) == len(k), f\"Data length mismatch\"\n","\n","    return x, y, k\n","\n","\n","\n","class TSTRClassifier(nn.Module):\n","    def __init__(self, num_timesteps=128, num_channels=3, num_classes=5):\n","        super(TSTRClassifier, self).__init__()\n","\n","        self.conv1 = nn.Conv1d(num_channels, 16, kernel_size=5, stride=1, padding=2)\n","        self.bn1 = nn.BatchNorm1d(16)\n","        self.conv2 = nn.Conv1d(16, 32, kernel_size=5, stride=1, padding=2)\n","        self.bn2 = nn.BatchNorm1d(32)\n","        self.conv3 = nn.Conv1d(32, 64, kernel_size=5, stride=1, padding=2)\n","        self.bn3 = nn.BatchNorm1d(64)\n","        self.conv4 = nn.Conv1d(64, 128, kernel_size=5, stride=1, padding=2)\n","        self.bn4 = nn.BatchNorm1d(128)\n","        self.pool = nn.MaxPool1d(kernel_size=2, stride=2)\n","        self.relu = nn.ReLU()\n","        self.dropout = nn.Dropout(p=0.25)\n","\n","        self.fc_shared = nn.Linear(num_timesteps * 8, 100)\n","\n","        self.fc_class = nn.Linear(100, num_classes)\n","\n","    def forward(self, x):\n","        x = self.pool(self.relu(self.bn1(self.conv1(x))))\n","        x = self.pool(self.relu(self.bn2(self.conv2(x))))\n","        x = self.pool(self.relu(self.bn3(self.conv3(x))))\n","        x = self.pool(self.relu(self.bn4(self.conv4(x))))\n","        x = x.view(x.size(0), -1)  # Flatten\n","        x = self.dropout(x)\n","        x = self.relu(self.fc_shared(x))\n","\n","        # Final output for class prediction\n","        class_outputs = self.fc_class(x)\n","        return class_outputs\n","\n","\n","\n","def remap_labels(y):\n","    label_map = {clss: i for i, clss in enumerate(np.unique(y))}\n","    return np.array([label_map[clss] for clss in y])\n","\n","\n","\n","def get_dataloader(x, y, shuffle=False):\n","    x = torch.tensor(x, dtype=torch.float32)\n","    y = remap_labels(y)\n","    y = torch.tensor(y, dtype=torch.long)\n","\n","    # Determine dataset size and batch size\n","    dataset_size = len(x)\n","    if dataset_size <= 100:\n","        batch_size = dataset_size\n","    elif dataset_size <= 1000:\n","        batch_size = 16\n","    elif dataset_size <= 5000:\n","        batch_size = 32\n","    else:\n","        batch_size = 64\n","\n","    dataset = TensorDataset(x, y)\n","    loader = DataLoader(dataset, batch_size=batch_size, shuffle=shuffle)\n","\n","    return loader\n","\n","\n","\n","def evaluate_model(model, test_loader):\n","    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","    model.to(device)\n","    model.eval()\n","\n","    loss_fn = nn.CrossEntropyLoss()\n","\n","    total_loss = 0\n","    correct_predictions = 0\n","    total_predictions = 0\n","\n","    with torch.no_grad():\n","        for x_batch, y_batch in test_loader:\n","            x_batch, y_batch = x_batch.to(device), y_batch.to(device)\n","            outputs = model(x_batch)\n","            loss = loss_fn(outputs, y_batch)\n","            total_loss += loss.item()\n","\n","            _, predicted_labels = torch.max(outputs, 1)\n","            correct_predictions += (predicted_labels == y_batch).sum().item()\n","            total_predictions += len(y_batch)\n","\n","    total_loss /= len(test_loader)\n","    accuracy = correct_predictions / total_predictions\n","\n","    return accuracy, total_loss\n","\n","\n","\n","def train_model(model, train_loader, val_loader, optimizer, num_epochs=100):\n","    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","    model.to(device)\n","\n","    loss_fn = nn.CrossEntropyLoss()\n","\n","    loss_train = []\n","    loss_val = []\n","    accuracy_val = []\n","    best_model_state = None\n","    best_loss = np.inf\n","    best_accuracy = 0\n","\n","    # Set up linear learning rate decay\n","    lambda_lr = lambda epoch: 1 - epoch / num_epochs\n","    scheduler = LambdaLR(optimizer, lr_lambda=lambda_lr)\n","\n","    for epoch in range(num_epochs):\n","        model.train()\n","        total_loss = 0\n","        for x_batch, y_batch in train_loader:\n","            x_batch, y_batch = x_batch.to(device), y_batch.to(device)\n","            optimizer.zero_grad()\n","            outputs = model(x_batch)\n","            loss = loss_fn(outputs, y_batch)\n","            loss.backward()\n","            optimizer.step()\n","            total_loss += loss.item()\n","        total_loss /= len(train_loader)\n","        loss_train.append(total_loss)\n","\n","        # Update learning rate\n","        scheduler.step()\n","\n","        val_accuracy, val_loss = evaluate_model(model, val_loader)\n","        if val_loss < best_loss:\n","            best_epoch = epoch\n","            best_accuracy = val_accuracy\n","            best_loss = val_loss\n","            best_model_state = model.state_dict().copy()\n","\n","        loss_val.append(val_loss)\n","        accuracy_val.append(val_accuracy)\n","\n","        current_lr = scheduler.get_last_lr()[0]\n","        if (epoch+1) % 10 == 0:\n","            print(f\"\\tEpoch {epoch + 1}/{num_epochs} - Train loss: {total_loss:.4f} - Val accuracy: {val_accuracy:.4f} - Val loss: {val_loss:.4f} - LR: {current_lr:.2e}\")\n","\n","    print(f\"\\tBest epoch: {best_epoch + 1} - Best val accuracy: {best_accuracy:.4f} - Best val loss: {best_loss:.4f}\\n\")\n","\n","    # Load best model state\n","    model.load_state_dict(best_model_state)\n","\n","    return model\n","\n","\n","\n","def train_and_test(x_train, y_train, x_test, y_test, dataset, num_epochs=100):\n","    assert np.array_equal(np.unique(y_train), np.unique(y_test)), \"Training and test labels do not match\"\n","\n","    x_tr, x_val, y_tr, y_val = train_test_split(x_train, y_train, test_size=0.2, stratify=y_train, shuffle=True, random_state=seed)\n","\n","    train_loader = get_dataloader(x_tr, y_tr, shuffle=True)\n","    val_loader = get_dataloader(x_val, y_val)\n","    test_loader = get_dataloader(x_test, y_test)\n","\n","    model = TSTRClassifier(num_timesteps=config[dataset]['num_timesteps'],\n","                           num_channels=config[dataset]['num_channels'],\n","                           num_classes=config[dataset]['num_classes']-1)\n","    initial_lr = 0.0001\n","    optimizer = optim.Adam(model.parameters(), lr=initial_lr)\n","\n","    trained_model = train_model(model, train_loader, val_loader, optimizer, num_epochs)\n","\n","    test_accuracy, test_loss = evaluate_model(trained_model, test_loader)\n","\n","    return test_accuracy, test_loss\n","\n","\n","\n","def train_only(x_train, y_train, dataset, num_epochs=100):\n","\n","    x_tr, x_val, y_tr, y_val = train_test_split(x_train, y_train, test_size=0.2, stratify=y_train, shuffle=True, random_state=seed)\n","\n","    train_loader = get_dataloader(x_tr, y_tr, shuffle=True)\n","    val_loader = get_dataloader(x_val, y_val)\n","\n","    model = TSTRClassifier(num_timesteps=config[dataset]['num_timesteps'],\n","                           num_channels=config[dataset]['num_channels'],\n","                           num_classes=config[dataset]['num_classes']-1)\n","    initial_lr = 0.0001\n","    optimizer = optim.Adam(model.parameters(), lr=initial_lr)\n","\n","    trained_model = train_model(model, train_loader, val_loader, optimizer, num_epochs)\n","\n","    return trained_model\n","\n","\n","\n","def train_classifier_cv(x_train, y_train, dataset, num_epochs=100):\n","    skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=seed)\n","\n","    accs = []\n","    losses = []\n","\n","    for train_index, test_index in skf.split(x_train, y_train):\n","        x_train_fold, x_test_fold = x_train[train_index], x_train[test_index]\n","        y_train_fold, y_test_fold = y_train[train_index], y_train[test_index]\n","\n","        acc, loss = train_and_test(x_train_fold, y_train_fold, x_test_fold, y_test_fold, dataset, num_epochs)\n","        accs.append(acc)\n","        losses.append(loss)\n","\n","    return np.mean(accs), np.mean(losses)\n","\n","\n","\n","def fine_tune(model, x_train, y_train, num_epochs=100):\n","    # Freeze feature extraction layers\n","    for name, param in model.named_parameters():\n","        if 'conv' in name or 'bn' in name:\n","            param.requires_grad = False\n","\n","    x_tr, x_val, y_tr, y_val = train_test_split(x_train, y_train, test_size=0.2, stratify=y_train, shuffle=True, random_state=seed)\n","\n","    train_loader = get_dataloader(x_tr, y_tr, shuffle=True)\n","    val_loader = get_dataloader(x_val, y_val)\n","\n","    initial_lr = 0.00001\n","    optimizer = optim.Adam(filter(lambda p: p.requires_grad, model.parameters()), lr=initial_lr)\n","\n","    trained_model = train_model(model, train_loader, val_loader, optimizer, num_epochs)\n","\n","    return trained_model\n","\n","\n","\n","def save_scores(source, domain, accuracy, loss, name, dataset):\n","    results_dir = 'results'\n","    # Ensure the directory exists\n","    os.makedirs(results_dir, exist_ok=True)\n","    # Path to the CSV file\n","    file_path = os.path.join(results_dir, f'{dataset}_{name}.csv')\n","    # Check if the file exists\n","    file_exists = os.path.exists(file_path)\n","\n","    # Open the file in append mode if it exists, or write mode if it doesn't\n","    with open(file_path, mode='a' if file_exists else 'w', newline='') as file:\n","        writer = csv.writer(file)\n","        # If the file does not exist, write the header\n","        if not file_exists:\n","            writer.writerow(['source', 'domain', 'accuracy', 'loss'])\n","        # Write the data rows\n","        writer.writerow([source, domain, accuracy, loss])"]},{"cell_type":"markdown","metadata":{"id":"PRAlLTPumD5Z"},"source":["# TSTR"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":262296,"status":"ok","timestamp":1731515186445,"user":{"displayName":"Giovanna Pasini","userId":"02341854514736870674"},"user_tz":-60},"id":"XrDIDrL9CPtn","outputId":"85c105ca-e027-4f00-9f28-2d72cdacba0b"},"outputs":[{"name":"stdout","output_type":"stream","text":["Source class: WAL\n","\n","Domain: 10\n","x_dp_dom.shape: (612, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Training and evaluating on Dp data via cross-validation...\n","\tEpoch 10/100 - Train loss: 0.0310 - Val accuracy: 0.9898 - Val loss: 0.0477 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.0085 - Val accuracy: 0.9796 - Val loss: 0.0488 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.0061 - Val accuracy: 0.9796 - Val loss: 0.0478 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.0035 - Val accuracy: 0.9796 - Val loss: 0.0500 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.0028 - Val accuracy: 0.9898 - Val loss: 0.0441 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.0017 - Val accuracy: 0.9898 - Val loss: 0.0496 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0034 - Val accuracy: 0.9898 - Val loss: 0.0420 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0019 - Val accuracy: 0.9898 - Val loss: 0.0529 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0007 - Val accuracy: 0.9898 - Val loss: 0.0470 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0006 - Val accuracy: 0.9898 - Val loss: 0.0478 - LR: 0.00e+00\n","\tBest epoch: 33 - Best val accuracy: 0.9898 - Best val loss: 0.0220\n","\n","\tEpoch 10/100 - Train loss: 0.0411 - Val accuracy: 0.9796 - Val loss: 0.0505 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.0116 - Val accuracy: 0.9898 - Val loss: 0.0247 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.0060 - Val accuracy: 1.0000 - Val loss: 0.0180 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.0041 - Val accuracy: 0.9898 - Val loss: 0.0173 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.0033 - Val accuracy: 1.0000 - Val loss: 0.0147 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.0010 - Val accuracy: 1.0000 - Val loss: 0.0145 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0025 - Val accuracy: 0.9898 - Val loss: 0.0149 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0014 - Val accuracy: 0.9898 - Val loss: 0.0144 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0008 - Val accuracy: 1.0000 - Val loss: 0.0132 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0009 - Val accuracy: 0.9898 - Val loss: 0.0141 - LR: 0.00e+00\n","\tBest epoch: 92 - Best val accuracy: 1.0000 - Best val loss: 0.0131\n","\n","\tEpoch 10/100 - Train loss: 0.0317 - Val accuracy: 0.9796 - Val loss: 0.0400 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.0100 - Val accuracy: 1.0000 - Val loss: 0.0110 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.0064 - Val accuracy: 1.0000 - Val loss: 0.0080 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.0021 - Val accuracy: 1.0000 - Val loss: 0.0044 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.0025 - Val accuracy: 1.0000 - Val loss: 0.0040 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.0012 - Val accuracy: 1.0000 - Val loss: 0.0043 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0012 - Val accuracy: 1.0000 - Val loss: 0.0036 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0036 - Val accuracy: 1.0000 - Val loss: 0.0027 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0010 - Val accuracy: 1.0000 - Val loss: 0.0034 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0019 - Val accuracy: 1.0000 - Val loss: 0.0028 - LR: 0.00e+00\n","\tBest epoch: 82 - Best val accuracy: 1.0000 - Best val loss: 0.0022\n","\n","\tEpoch 10/100 - Train loss: 0.0421 - Val accuracy: 1.0000 - Val loss: 0.0260 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.0111 - Val accuracy: 0.9898 - Val loss: 0.0192 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.0054 - Val accuracy: 1.0000 - Val loss: 0.0131 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.0021 - Val accuracy: 1.0000 - Val loss: 0.0117 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.0028 - Val accuracy: 0.9898 - Val loss: 0.0124 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.0007 - Val accuracy: 1.0000 - Val loss: 0.0088 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0008 - Val accuracy: 0.9898 - Val loss: 0.0130 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0005 - Val accuracy: 1.0000 - Val loss: 0.0103 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0005 - Val accuracy: 0.9898 - Val loss: 0.0106 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0008 - Val accuracy: 1.0000 - Val loss: 0.0094 - LR: 0.00e+00\n","\tBest epoch: 85 - Best val accuracy: 1.0000 - Best val loss: 0.0079\n","\n","\tEpoch 10/100 - Train loss: 0.0380 - Val accuracy: 0.9898 - Val loss: 0.0525 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.0078 - Val accuracy: 0.9898 - Val loss: 0.0304 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.0068 - Val accuracy: 0.9898 - Val loss: 0.0429 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.0035 - Val accuracy: 0.9898 - Val loss: 0.0270 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.0042 - Val accuracy: 0.9898 - Val loss: 0.0263 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.0027 - Val accuracy: 0.9898 - Val loss: 0.0287 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0008 - Val accuracy: 0.9796 - Val loss: 0.0346 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0024 - Val accuracy: 0.9898 - Val loss: 0.0296 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0018 - Val accuracy: 0.9898 - Val loss: 0.0187 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0013 - Val accuracy: 0.9898 - Val loss: 0.0316 - LR: 0.00e+00\n","\tBest epoch: 90 - Best val accuracy: 0.9898 - Best val loss: 0.0187\n","\n","Source class: WAL | Domain: 10 | Accuracy: 0.9918 | Loss: 0.0166\n","\n","Domain: 11\n","x_dp_dom.shape: (581, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Training and evaluating on Dp data via cross-validation...\n","\tEpoch 10/100 - Train loss: 0.0302 - Val accuracy: 0.9785 - Val loss: 0.0787 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.0136 - Val accuracy: 0.9892 - Val loss: 0.0738 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.0033 - Val accuracy: 0.9892 - Val loss: 0.0713 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.0025 - Val accuracy: 0.9892 - Val loss: 0.0636 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.0044 - Val accuracy: 0.9892 - Val loss: 0.0712 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.0558 - Val accuracy: 0.9785 - Val loss: 0.0447 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0028 - Val accuracy: 0.9892 - Val loss: 0.0545 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0011 - Val accuracy: 0.9892 - Val loss: 0.0581 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0008 - Val accuracy: 0.9892 - Val loss: 0.0570 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0034 - Val accuracy: 0.9892 - Val loss: 0.0555 - LR: 0.00e+00\n","\tBest epoch: 60 - Best val accuracy: 0.9785 - Best val loss: 0.0447\n","\n","\tEpoch 10/100 - Train loss: 0.0236 - Val accuracy: 0.9892 - Val loss: 0.0374 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.0138 - Val accuracy: 0.9892 - Val loss: 0.0299 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.0065 - Val accuracy: 0.9892 - Val loss: 0.0280 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.0024 - Val accuracy: 0.9892 - Val loss: 0.0206 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.0043 - Val accuracy: 0.9892 - Val loss: 0.0219 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.0011 - Val accuracy: 0.9892 - Val loss: 0.0217 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0027 - Val accuracy: 0.9892 - Val loss: 0.0359 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0009 - Val accuracy: 0.9892 - Val loss: 0.0202 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0010 - Val accuracy: 0.9892 - Val loss: 0.0229 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0012 - Val accuracy: 0.9892 - Val loss: 0.0214 - LR: 0.00e+00\n","\tBest epoch: 48 - Best val accuracy: 0.9892 - Best val loss: 0.0168\n","\n","\tEpoch 10/100 - Train loss: 0.0452 - Val accuracy: 0.9785 - Val loss: 0.0416 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.0130 - Val accuracy: 0.9785 - Val loss: 0.0277 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.0072 - Val accuracy: 0.9785 - Val loss: 0.0357 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.0043 - Val accuracy: 0.9785 - Val loss: 0.0263 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.0030 - Val accuracy: 0.9785 - Val loss: 0.0356 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.0074 - Val accuracy: 0.9785 - Val loss: 0.0428 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0068 - Val accuracy: 0.9785 - Val loss: 0.0334 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0015 - Val accuracy: 0.9785 - Val loss: 0.0350 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0254 - Val accuracy: 0.9892 - Val loss: 0.0161 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0014 - Val accuracy: 0.9785 - Val loss: 0.0380 - LR: 0.00e+00\n","\tBest epoch: 90 - Best val accuracy: 0.9892 - Best val loss: 0.0161\n","\n","\tEpoch 10/100 - Train loss: 0.0304 - Val accuracy: 0.9677 - Val loss: 0.0715 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.0162 - Val accuracy: 0.9785 - Val loss: 0.0532 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.0101 - Val accuracy: 0.9785 - Val loss: 0.0684 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.0025 - Val accuracy: 0.9785 - Val loss: 0.0737 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.0027 - Val accuracy: 0.9785 - Val loss: 0.0914 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.0029 - Val accuracy: 0.9785 - Val loss: 0.0854 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0158 - Val accuracy: 0.9785 - Val loss: 0.0805 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0012 - Val accuracy: 0.9785 - Val loss: 0.0839 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0023 - Val accuracy: 0.9785 - Val loss: 0.0698 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0007 - Val accuracy: 0.9785 - Val loss: 0.0817 - LR: 0.00e+00\n","\tBest epoch: 20 - Best val accuracy: 0.9785 - Best val loss: 0.0532\n","\n","\tEpoch 10/100 - Train loss: 0.0553 - Val accuracy: 0.9785 - Val loss: 0.0442 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.0125 - Val accuracy: 0.9785 - Val loss: 0.0458 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.0064 - Val accuracy: 0.9785 - Val loss: 0.0513 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.0513 - Val accuracy: 0.9785 - Val loss: 0.0549 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.0022 - Val accuracy: 0.9785 - Val loss: 0.0662 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.0030 - Val accuracy: 0.9677 - Val loss: 0.0815 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0024 - Val accuracy: 0.9785 - Val loss: 0.0476 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0018 - Val accuracy: 0.9785 - Val loss: 0.0657 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0014 - Val accuracy: 0.9785 - Val loss: 0.0536 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0014 - Val accuracy: 0.9785 - Val loss: 0.0569 - LR: 0.00e+00\n","\tBest epoch: 28 - Best val accuracy: 0.9785 - Best val loss: 0.0376\n","\n","Source class: WAL | Domain: 11 | Accuracy: 0.9845 | Loss: 0.0321\n","\n","Domain: 12\n","x_dp_dom.shape: (577, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Training and evaluating on Dp data via cross-validation...\n","\tEpoch 10/100 - Train loss: 0.0605 - Val accuracy: 1.0000 - Val loss: 0.0260 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.0257 - Val accuracy: 1.0000 - Val loss: 0.0105 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.0100 - Val accuracy: 1.0000 - Val loss: 0.0065 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.0062 - Val accuracy: 1.0000 - Val loss: 0.0055 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.0016 - Val accuracy: 1.0000 - Val loss: 0.0036 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.0017 - Val accuracy: 1.0000 - Val loss: 0.0036 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0029 - Val accuracy: 1.0000 - Val loss: 0.0030 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0010 - Val accuracy: 1.0000 - Val loss: 0.0028 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0023 - Val accuracy: 1.0000 - Val loss: 0.0031 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0010 - Val accuracy: 1.0000 - Val loss: 0.0031 - LR: 0.00e+00\n","\tBest epoch: 89 - Best val accuracy: 1.0000 - Best val loss: 0.0025\n","\n","\tEpoch 10/100 - Train loss: 0.0661 - Val accuracy: 0.9892 - Val loss: 0.0559 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.0102 - Val accuracy: 0.9892 - Val loss: 0.0409 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.0070 - Val accuracy: 0.9892 - Val loss: 0.0342 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.0028 - Val accuracy: 0.9892 - Val loss: 0.0414 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.0033 - Val accuracy: 0.9892 - Val loss: 0.0385 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.0022 - Val accuracy: 0.9892 - Val loss: 0.0321 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0053 - Val accuracy: 0.9892 - Val loss: 0.0257 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0007 - Val accuracy: 0.9892 - Val loss: 0.0306 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0013 - Val accuracy: 0.9892 - Val loss: 0.0337 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0037 - Val accuracy: 0.9892 - Val loss: 0.0280 - LR: 0.00e+00\n","\tBest epoch: 96 - Best val accuracy: 0.9892 - Best val loss: 0.0252\n","\n","\tEpoch 10/100 - Train loss: 0.1072 - Val accuracy: 1.0000 - Val loss: 0.0484 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.0379 - Val accuracy: 0.9892 - Val loss: 0.0265 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.0342 - Val accuracy: 0.9892 - Val loss: 0.0226 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.0171 - Val accuracy: 0.9892 - Val loss: 0.0283 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.0656 - Val accuracy: 0.9892 - Val loss: 0.0194 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.0100 - Val accuracy: 0.9892 - Val loss: 0.0284 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0127 - Val accuracy: 0.9892 - Val loss: 0.0173 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0163 - Val accuracy: 0.9892 - Val loss: 0.0149 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0096 - Val accuracy: 0.9892 - Val loss: 0.0181 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0055 - Val accuracy: 0.9892 - Val loss: 0.0277 - LR: 0.00e+00\n","\tBest epoch: 74 - Best val accuracy: 1.0000 - Best val loss: 0.0107\n","\n","\tEpoch 10/100 - Train loss: 0.1173 - Val accuracy: 1.0000 - Val loss: 0.0405 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.0475 - Val accuracy: 1.0000 - Val loss: 0.0213 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.0623 - Val accuracy: 1.0000 - Val loss: 0.0121 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.0660 - Val accuracy: 0.9892 - Val loss: 0.0313 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.0059 - Val accuracy: 0.9892 - Val loss: 0.0288 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.0057 - Val accuracy: 0.9892 - Val loss: 0.0217 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0093 - Val accuracy: 0.9892 - Val loss: 0.0318 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0129 - Val accuracy: 0.9892 - Val loss: 0.0308 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0037 - Val accuracy: 0.9892 - Val loss: 0.0307 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0044 - Val accuracy: 0.9892 - Val loss: 0.0162 - LR: 0.00e+00\n","\tBest epoch: 63 - Best val accuracy: 1.0000 - Best val loss: 0.0108\n","\n","\tEpoch 10/100 - Train loss: 0.0865 - Val accuracy: 0.9785 - Val loss: 0.0823 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.0189 - Val accuracy: 0.9785 - Val loss: 0.0382 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.0168 - Val accuracy: 0.9677 - Val loss: 0.0550 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.0066 - Val accuracy: 1.0000 - Val loss: 0.0184 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.0054 - Val accuracy: 0.9892 - Val loss: 0.0187 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.0036 - Val accuracy: 1.0000 - Val loss: 0.0192 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0040 - Val accuracy: 1.0000 - Val loss: 0.0157 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0035 - Val accuracy: 1.0000 - Val loss: 0.0097 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0081 - Val accuracy: 1.0000 - Val loss: 0.0121 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0028 - Val accuracy: 1.0000 - Val loss: 0.0170 - LR: 0.00e+00\n","\tBest epoch: 94 - Best val accuracy: 1.0000 - Best val loss: 0.0096\n","\n","Source class: WAL | Domain: 12 | Accuracy: 0.9879 | Loss: 0.0335\n","\n","Domain: 13\n","x_dp_dom.shape: (319, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Training and evaluating on Dp data via cross-validation...\n","\tEpoch 10/100 - Train loss: 0.0613 - Val accuracy: 1.0000 - Val loss: 0.0272 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.0161 - Val accuracy: 1.0000 - Val loss: 0.0078 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.0042 - Val accuracy: 1.0000 - Val loss: 0.0035 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.0023 - Val accuracy: 1.0000 - Val loss: 0.0022 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.0010 - Val accuracy: 1.0000 - Val loss: 0.0012 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.0012 - Val accuracy: 1.0000 - Val loss: 0.0007 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0029 - Val accuracy: 1.0000 - Val loss: 0.0005 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0012 - Val accuracy: 1.0000 - Val loss: 0.0007 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0024 - Val accuracy: 1.0000 - Val loss: 0.0007 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0021 - Val accuracy: 1.0000 - Val loss: 0.0005 - LR: 0.00e+00\n","\tBest epoch: 95 - Best val accuracy: 1.0000 - Best val loss: 0.0004\n","\n","\tEpoch 10/100 - Train loss: 0.0386 - Val accuracy: 1.0000 - Val loss: 0.0322 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.0268 - Val accuracy: 1.0000 - Val loss: 0.0077 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.0054 - Val accuracy: 1.0000 - Val loss: 0.0036 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.0071 - Val accuracy: 1.0000 - Val loss: 0.0021 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.0013 - Val accuracy: 1.0000 - Val loss: 0.0011 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.0049 - Val accuracy: 1.0000 - Val loss: 0.0008 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0020 - Val accuracy: 1.0000 - Val loss: 0.0007 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0010 - Val accuracy: 1.0000 - Val loss: 0.0006 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0069 - Val accuracy: 1.0000 - Val loss: 0.0008 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0011 - Val accuracy: 1.0000 - Val loss: 0.0012 - LR: 0.00e+00\n","\tBest epoch: 78 - Best val accuracy: 1.0000 - Best val loss: 0.0005\n","\n","\tEpoch 10/100 - Train loss: 0.0815 - Val accuracy: 1.0000 - Val loss: 0.0297 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.0121 - Val accuracy: 1.0000 - Val loss: 0.0100 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.0066 - Val accuracy: 1.0000 - Val loss: 0.0053 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.0044 - Val accuracy: 1.0000 - Val loss: 0.0033 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.0024 - Val accuracy: 1.0000 - Val loss: 0.0065 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.0015 - Val accuracy: 1.0000 - Val loss: 0.0042 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0025 - Val accuracy: 1.0000 - Val loss: 0.0048 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0010 - Val accuracy: 1.0000 - Val loss: 0.0037 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0011 - Val accuracy: 1.0000 - Val loss: 0.0039 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0014 - Val accuracy: 1.0000 - Val loss: 0.0040 - LR: 0.00e+00\n","\tBest epoch: 41 - Best val accuracy: 1.0000 - Best val loss: 0.0023\n","\n","\tEpoch 10/100 - Train loss: 0.0538 - Val accuracy: 1.0000 - Val loss: 0.0298 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.0100 - Val accuracy: 1.0000 - Val loss: 0.0057 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.0107 - Val accuracy: 1.0000 - Val loss: 0.0024 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.0156 - Val accuracy: 1.0000 - Val loss: 0.0014 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.0014 - Val accuracy: 1.0000 - Val loss: 0.0007 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.0030 - Val accuracy: 1.0000 - Val loss: 0.0008 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0017 - Val accuracy: 1.0000 - Val loss: 0.0005 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0070 - Val accuracy: 1.0000 - Val loss: 0.0003 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0011 - Val accuracy: 1.0000 - Val loss: 0.0005 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0041 - Val accuracy: 1.0000 - Val loss: 0.0006 - LR: 0.00e+00\n","\tBest epoch: 80 - Best val accuracy: 1.0000 - Best val loss: 0.0003\n","\n","\tEpoch 10/100 - Train loss: 0.0439 - Val accuracy: 1.0000 - Val loss: 0.0202 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.0062 - Val accuracy: 1.0000 - Val loss: 0.0025 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.0026 - Val accuracy: 1.0000 - Val loss: 0.0010 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.0014 - Val accuracy: 1.0000 - Val loss: 0.0006 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.0024 - Val accuracy: 1.0000 - Val loss: 0.0004 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.0008 - Val accuracy: 1.0000 - Val loss: 0.0003 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0009 - Val accuracy: 1.0000 - Val loss: 0.0002 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0007 - Val accuracy: 1.0000 - Val loss: 0.0002 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0013 - Val accuracy: 1.0000 - Val loss: 0.0002 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0010 - Val accuracy: 1.0000 - Val loss: 0.0002 - LR: 0.00e+00\n","\tBest epoch: 96 - Best val accuracy: 1.0000 - Best val loss: 0.0002\n","\n","Source class: WAL | Domain: 13 | Accuracy: 0.9905 | Loss: 0.0268\n","\n","Domain: 14\n","x_dp_dom.shape: (581, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Training and evaluating on Dp data via cross-validation...\n","\tEpoch 10/100 - Train loss: 0.0461 - Val accuracy: 0.9892 - Val loss: 0.0809 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.0255 - Val accuracy: 0.9892 - Val loss: 0.0733 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.0096 - Val accuracy: 0.9892 - Val loss: 0.0755 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.0421 - Val accuracy: 0.9892 - Val loss: 0.0912 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.0040 - Val accuracy: 0.9892 - Val loss: 0.0792 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.0022 - Val accuracy: 0.9892 - Val loss: 0.0838 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0069 - Val accuracy: 0.9892 - Val loss: 0.0865 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0332 - Val accuracy: 0.9892 - Val loss: 0.0887 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0014 - Val accuracy: 0.9892 - Val loss: 0.0957 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0021 - Val accuracy: 0.9892 - Val loss: 0.0941 - LR: 0.00e+00\n","\tBest epoch: 41 - Best val accuracy: 0.9892 - Best val loss: 0.0567\n","\n","\tEpoch 10/100 - Train loss: 0.0560 - Val accuracy: 0.9785 - Val loss: 0.0854 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.0249 - Val accuracy: 0.9892 - Val loss: 0.0653 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.0216 - Val accuracy: 0.9892 - Val loss: 0.0748 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.0055 - Val accuracy: 0.9785 - Val loss: 0.0878 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.0064 - Val accuracy: 0.9892 - Val loss: 0.0720 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.0097 - Val accuracy: 0.9892 - Val loss: 0.0957 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0017 - Val accuracy: 0.9892 - Val loss: 0.0908 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0024 - Val accuracy: 0.9892 - Val loss: 0.0921 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0014 - Val accuracy: 0.9892 - Val loss: 0.0889 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0019 - Val accuracy: 0.9892 - Val loss: 0.0906 - LR: 0.00e+00\n","\tBest epoch: 18 - Best val accuracy: 0.9892 - Best val loss: 0.0604\n","\n","\tEpoch 10/100 - Train loss: 0.0656 - Val accuracy: 1.0000 - Val loss: 0.0298 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.0344 - Val accuracy: 0.9892 - Val loss: 0.0323 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.0246 - Val accuracy: 0.9892 - Val loss: 0.0210 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.0077 - Val accuracy: 1.0000 - Val loss: 0.0180 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.0060 - Val accuracy: 1.0000 - Val loss: 0.0129 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.0046 - Val accuracy: 0.9892 - Val loss: 0.0141 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0023 - Val accuracy: 0.9892 - Val loss: 0.0161 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0024 - Val accuracy: 0.9892 - Val loss: 0.0156 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0042 - Val accuracy: 0.9892 - Val loss: 0.0158 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0027 - Val accuracy: 0.9892 - Val loss: 0.0146 - LR: 0.00e+00\n","\tBest epoch: 72 - Best val accuracy: 1.0000 - Best val loss: 0.0084\n","\n","\tEpoch 10/100 - Train loss: 0.0923 - Val accuracy: 0.9892 - Val loss: 0.0860 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.0241 - Val accuracy: 0.9892 - Val loss: 0.0699 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.0117 - Val accuracy: 0.9892 - Val loss: 0.0741 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.0257 - Val accuracy: 0.9892 - Val loss: 0.0797 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.0069 - Val accuracy: 0.9892 - Val loss: 0.0830 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.0096 - Val accuracy: 0.9892 - Val loss: 0.0816 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0043 - Val accuracy: 0.9892 - Val loss: 0.0802 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0033 - Val accuracy: 0.9892 - Val loss: 0.0806 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0030 - Val accuracy: 0.9892 - Val loss: 0.0871 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0019 - Val accuracy: 0.9892 - Val loss: 0.0836 - LR: 0.00e+00\n","\tBest epoch: 23 - Best val accuracy: 0.9892 - Best val loss: 0.0605\n","\n","\tEpoch 10/100 - Train loss: 0.0556 - Val accuracy: 0.9892 - Val loss: 0.0778 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.0163 - Val accuracy: 0.9892 - Val loss: 0.0728 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.0066 - Val accuracy: 0.9892 - Val loss: 0.0803 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.0055 - Val accuracy: 0.9892 - Val loss: 0.0809 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.0038 - Val accuracy: 0.9892 - Val loss: 0.0753 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.0084 - Val accuracy: 0.9892 - Val loss: 0.0661 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0022 - Val accuracy: 0.9892 - Val loss: 0.0738 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0030 - Val accuracy: 0.9892 - Val loss: 0.0662 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0012 - Val accuracy: 0.9892 - Val loss: 0.0669 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0012 - Val accuracy: 0.9892 - Val loss: 0.0717 - LR: 0.00e+00\n","\tBest epoch: 62 - Best val accuracy: 0.9892 - Best val loss: 0.0624\n","\n","Source class: WAL | Domain: 14 | Accuracy: 0.9862 | Loss: 0.0506\n","\n","Mean accuracy: 0.9882\n","\n"]}],"source":["def compute_TSTR_Dp(dataset):\n","    accs = []\n","\n","    for src_class in config[dataset]['class_names']:\n","        if src_class != 'WAL':\n","            continue\n","\n","        print(f\"Source class: {src_class}\\n\")\n","\n","        for domain in range(config[dataset]['num_df_domains'], config[dataset]['num_df_domains'] + config[dataset]['num_dp_domains']):\n","            print(f\"Domain: {domain}\")\n","\n","            # Load Dp data\n","            x_dp_dom, y_dp_dom, k_dp_dom = get_data(dataset, 'dp', src_class, domain)\n","            print(f'x_dp_dom.shape: {x_dp_dom.shape} | np.unique(y_dp_dom): {np.unique(y_dp_dom)}\\n')\n","\n","            # Train and evaluate via cross-validation on Dp data\n","            print('Training and evaluating on Dp data via cross-validation...')\n","            acc, loss = train_classifier_cv(x_dp_dom, y_dp_dom, dataset, num_epochs=100)\n","            save_scores(src_class, domain, acc, loss, 'Dp', dataset)\n","            accs.append(acc)\n","            print(f'Source class: {src_class} | Domain: {domain} | Accuracy: {acc:.4f} | Loss: {loss:.4f}\\n')\n","\n","    print(f\"Mean accuracy: {np.mean(accs):.4f}\\n\")\n","\n","\n","\n","compute_TSTR_Dp('realworld')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"M7S9IU2VVAmx"},"outputs":[],"source":["def compute_TSTR_Dpc(dataset):\n","\n","    raise NotImplementedError\n","\n","\n","\n","# compute_TSTR_Dpc('realworld')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":65299,"status":"ok","timestamp":1731515251737,"user":{"displayName":"Giovanna Pasini","userId":"02341854514736870674"},"user_tz":-60},"id":"zhTuwDtYCPto","outputId":"c815dedf-1a7e-425e-bf03-626cb2a030b7"},"outputs":[{"name":"stdout","output_type":"stream","text":["Source class: WAL\n","\n","x_df.shape: (5288, 3, 128) | np.unique(y_df): [1 2 3]\n","\n","Training on Df data...\n","\tEpoch 10/100 - Train loss: 0.0378 - Val accuracy: 0.9773 - Val loss: 0.0586 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.0088 - Val accuracy: 0.9764 - Val loss: 0.0508 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.0034 - Val accuracy: 0.9792 - Val loss: 0.0536 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.0015 - Val accuracy: 0.9764 - Val loss: 0.0655 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.0022 - Val accuracy: 0.9773 - Val loss: 0.0608 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.0006 - Val accuracy: 0.9802 - Val loss: 0.0671 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0003 - Val accuracy: 0.9802 - Val loss: 0.0692 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0015 - Val accuracy: 0.9811 - Val loss: 0.0803 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0003 - Val accuracy: 0.9830 - Val loss: 0.0822 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0005 - Val accuracy: 0.9811 - Val loss: 0.0760 - LR: 0.00e+00\n","\tBest epoch: 21 - Best val accuracy: 0.9764 - Best val loss: 0.0454\n","\n","Domain: 10\n","x_dp_dom.shape: (612, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 10 | Accuracy: 0.9788 | Loss: 0.0748\n","\n","Domain: 11\n","x_dp_dom.shape: (581, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 11 | Accuracy: 0.9742 | Loss: 0.0851\n","\n","Domain: 12\n","x_dp_dom.shape: (577, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 12 | Accuracy: 0.9584 | Loss: 0.1678\n","\n","Domain: 13\n","x_dp_dom.shape: (319, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 13 | Accuracy: 0.9843 | Loss: 0.0393\n","\n","Domain: 14\n","x_dp_dom.shape: (581, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Source class: WAL | Domain: 14 | Accuracy: 0.9725 | Loss: 0.0946\n","\n","Mean accuracy: 0.9736\n","\n"]}],"source":["def compute_TSTR_Df(dataset):\n","    accs = []\n","\n","    for src_class in config[dataset]['class_names']:\n","        if src_class != 'WAL':\n","            continue\n","\n","        print(f\"Source class: {src_class}\\n\")\n","\n","        # Load Df data\n","        x_df, y_df, k_df = get_data(dataset, 'df', src_class)\n","        print(f'x_df.shape: {x_df.shape} | np.unique(y_df): {np.unique(y_df)}\\n')\n","\n","        # Train on Df data\n","        print('Training on Df data...')\n","        df_model = train_only(x_df, y_df, dataset, num_epochs=100)\n","\n","        for domain in range(config[dataset]['num_df_domains'], config[dataset]['num_df_domains'] + config[dataset]['num_dp_domains']):\n","            print(f\"Domain: {domain}\")\n","\n","            # Load Dp data\n","            x_dp_dom, y_dp_dom, k_dp_dom = get_data(dataset, 'dp', src_class, domain)\n","            print(f'x_dp_dom.shape: {x_dp_dom.shape} | np.unique(y_dp_dom): {np.unique(y_dp_dom)}\\n')\n","\n","            # Evaluate on Dp data\n","            acc, loss = evaluate_model(df_model, get_dataloader(x_dp_dom, y_dp_dom))\n","            save_scores(src_class, domain, acc, loss, 'Df', dataset)\n","            accs.append(acc)\n","            print(f'Source class: {src_class} | Domain: {domain} | Accuracy: {acc:.4f} | Loss: {loss:.4f}\\n')\n","\n","    print(f\"Mean accuracy: {np.mean(accs):.4f}\\n\")\n","\n","\n","\n","\n","compute_TSTR_Df('realworld')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":89752,"status":"ok","timestamp":1731515341478,"user":{"displayName":"Giovanna Pasini","userId":"02341854514736870674"},"user_tz":-60},"id":"SmGQm1ZFCPto","outputId":"3989a8e7-d8e9-42fc-b4db-4a72684ab1bf"},"outputs":[{"name":"stdout","output_type":"stream","text":["Source class: WAL\n","\n","Domain: 10\n","x_syn_dom.shape: (726, 3, 128) | np.unique(y_syn_dom): [1 2 3]\n","x_dp_dom.shape: (612, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Training on synthetic data...\n","\tEpoch 10/100 - Train loss: 0.0321 - Val accuracy: 1.0000 - Val loss: 0.0039 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.0030 - Val accuracy: 1.0000 - Val loss: 0.0011 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.0065 - Val accuracy: 1.0000 - Val loss: 0.0005 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.0065 - Val accuracy: 1.0000 - Val loss: 0.0003 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.0065 - Val accuracy: 1.0000 - Val loss: 0.0005 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.0008 - Val accuracy: 1.0000 - Val loss: 0.0002 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0004 - Val accuracy: 1.0000 - Val loss: 0.0001 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0005 - Val accuracy: 1.0000 - Val loss: 0.0001 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0003 - Val accuracy: 1.0000 - Val loss: 0.0001 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0002 - Val accuracy: 1.0000 - Val loss: 0.0001 - LR: 0.00e+00\n","\tBest epoch: 95 - Best val accuracy: 1.0000 - Best val loss: 0.0001\n","\n","Source class: WAL | Domain: 10 | Accuracy: 0.9608 | Loss: 0.1137\n","\n","Domain: 11\n","x_syn_dom.shape: (690, 3, 128) | np.unique(y_syn_dom): [1 2 3]\n","x_dp_dom.shape: (581, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Training on synthetic data...\n","\tEpoch 10/100 - Train loss: 0.0097 - Val accuracy: 0.9928 - Val loss: 0.0103 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.0017 - Val accuracy: 1.0000 - Val loss: 0.0025 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.0009 - Val accuracy: 1.0000 - Val loss: 0.0007 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.0004 - Val accuracy: 1.0000 - Val loss: 0.0003 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.0002 - Val accuracy: 1.0000 - Val loss: 0.0003 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.0004 - Val accuracy: 1.0000 - Val loss: 0.0004 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0002 - Val accuracy: 1.0000 - Val loss: 0.0004 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0004 - Val accuracy: 1.0000 - Val loss: 0.0001 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0001 - Val accuracy: 1.0000 - Val loss: 0.0002 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0001 - Val accuracy: 1.0000 - Val loss: 0.0001 - LR: 0.00e+00\n","\tBest epoch: 96 - Best val accuracy: 1.0000 - Best val loss: 0.0001\n","\n","Source class: WAL | Domain: 11 | Accuracy: 0.9707 | Loss: 0.0939\n","\n","Domain: 12\n","x_syn_dom.shape: (714, 3, 128) | np.unique(y_syn_dom): [1 2 3]\n","x_dp_dom.shape: (577, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Training on synthetic data...\n","\tEpoch 10/100 - Train loss: 0.0111 - Val accuracy: 1.0000 - Val loss: 0.0027 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.0014 - Val accuracy: 1.0000 - Val loss: 0.0006 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.0028 - Val accuracy: 1.0000 - Val loss: 0.0003 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.0018 - Val accuracy: 1.0000 - Val loss: 0.0002 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.0008 - Val accuracy: 1.0000 - Val loss: 0.0001 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.0003 - Val accuracy: 1.0000 - Val loss: 0.0001 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0003 - Val accuracy: 1.0000 - Val loss: 0.0001 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0014 - Val accuracy: 1.0000 - Val loss: 0.0001 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0005 - Val accuracy: 1.0000 - Val loss: 0.0001 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0003 - Val accuracy: 1.0000 - Val loss: 0.0001 - LR: 0.00e+00\n","\tBest epoch: 94 - Best val accuracy: 1.0000 - Best val loss: 0.0001\n","\n","Source class: WAL | Domain: 12 | Accuracy: 0.9428 | Loss: 0.2093\n","\n","Domain: 13\n","x_syn_dom.shape: (732, 3, 128) | np.unique(y_syn_dom): [1 2 3]\n","x_dp_dom.shape: (319, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Training on synthetic data...\n","\tEpoch 10/100 - Train loss: 0.0031 - Val accuracy: 1.0000 - Val loss: 0.0009 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.0017 - Val accuracy: 1.0000 - Val loss: 0.0002 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.0009 - Val accuracy: 1.0000 - Val loss: 0.0001 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.0003 - Val accuracy: 1.0000 - Val loss: 0.0001 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.0002 - Val accuracy: 1.0000 - Val loss: 0.0001 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.0001 - Val accuracy: 1.0000 - Val loss: 0.0000 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0001 - Val accuracy: 1.0000 - Val loss: 0.0000 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0003 - Val accuracy: 1.0000 - Val loss: 0.0001 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0001 - Val accuracy: 1.0000 - Val loss: 0.0000 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0035 - Val accuracy: 1.0000 - Val loss: 0.0000 - LR: 0.00e+00\n","\tBest epoch: 76 - Best val accuracy: 1.0000 - Best val loss: 0.0000\n","\n","Source class: WAL | Domain: 13 | Accuracy: 0.9812 | Loss: 0.0356\n","\n","Domain: 14\n","x_syn_dom.shape: (726, 3, 128) | np.unique(y_syn_dom): [1 2 3]\n","x_dp_dom.shape: (581, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Training on synthetic data...\n","\tEpoch 10/100 - Train loss: 0.0106 - Val accuracy: 1.0000 - Val loss: 0.0020 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.0027 - Val accuracy: 1.0000 - Val loss: 0.0006 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.0012 - Val accuracy: 1.0000 - Val loss: 0.0003 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.0006 - Val accuracy: 1.0000 - Val loss: 0.0003 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.0006 - Val accuracy: 1.0000 - Val loss: 0.0002 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.0006 - Val accuracy: 1.0000 - Val loss: 0.0001 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0005 - Val accuracy: 1.0000 - Val loss: 0.0001 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0027 - Val accuracy: 1.0000 - Val loss: 0.0005 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0059 - Val accuracy: 1.0000 - Val loss: 0.0001 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0004 - Val accuracy: 1.0000 - Val loss: 0.0002 - LR: 0.00e+00\n","\tBest epoch: 90 - Best val accuracy: 1.0000 - Best val loss: 0.0001\n","\n","Source class: WAL | Domain: 14 | Accuracy: 0.9398 | Loss: 0.2526\n","\n","Mean accuracy: 0.9591\n","\n"]}],"source":["def compute_TSTR_Syn(dataset):\n","    accs = []\n","\n","    for src_class in config[dataset]['class_names']:\n","        if src_class != 'WAL':\n","            continue\n","\n","        print(f\"Source class: {src_class}\\n\")\n","\n","        for domain in range(config[dataset]['num_df_domains'], config[dataset]['num_df_domains'] + config[dataset]['num_dp_domains']):\n","            print(f\"Domain: {domain}\")\n","\n","            # Load synthetic data\n","            x_syn_dom, y_syn_dom, k_syn_dom = get_syn_data(dataset, syn_name, src_class, domain)\n","            print(f'x_syn_dom.shape: {x_syn_dom.shape} | np.unique(y_syn_dom): {np.unique(y_syn_dom)}')\n","\n","            # Load Dp data\n","            x_dp_dom, y_dp_dom, k_dp_dom = get_data(dataset, 'dp', src_class, domain)\n","            print(f'x_dp_dom.shape: {x_dp_dom.shape} | np.unique(y_dp_dom): {np.unique(y_dp_dom)}\\n')\n","\n","            # Train on synthetic data and evaluate on Dp data\n","            print('Training on synthetic data...')\n","            acc, loss = train_and_test(x_syn_dom, y_syn_dom, x_dp_dom, y_dp_dom, dataset, num_epochs=100)\n","            save_scores(src_class, domain, acc, loss, 'Syn', dataset)\n","            accs.append(acc)\n","            print(f'Source class: {src_class} | Domain: {domain} | Accuracy: {acc:.4f} | Loss: {loss:.4f}\\n')\n","\n","    print(f\"Mean accuracy: {np.mean(accs):.4f}\\n\")\n","\n","\n","\n","\n","compute_TSTR_Syn('realworld')"]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":141565,"status":"ok","timestamp":1731516297677,"user":{"displayName":"Giovanna Pasini","userId":"02341854514736870674"},"user_tz":-60},"id":"LA71th1bCPto","outputId":"57f7867a-816a-49d6-d95d-26fc30eb4cc6"},"outputs":[{"output_type":"stream","name":"stdout","text":["Source class: WAL\n","\n","x_df.shape: (5288, 3, 128) | np.unique(y_df): [1 2 3]\n","\n","Training on Df data...\n","\tEpoch 10/100 - Train loss: 0.0320 - Val accuracy: 0.9764 - Val loss: 0.0446 - LR: 9.00e-05\n","\tEpoch 20/100 - Train loss: 0.0119 - Val accuracy: 0.9811 - Val loss: 0.0450 - LR: 8.00e-05\n","\tEpoch 30/100 - Train loss: 0.0052 - Val accuracy: 0.9839 - Val loss: 0.0542 - LR: 7.00e-05\n","\tEpoch 40/100 - Train loss: 0.0022 - Val accuracy: 0.9830 - Val loss: 0.0487 - LR: 6.00e-05\n","\tEpoch 50/100 - Train loss: 0.0020 - Val accuracy: 0.9839 - Val loss: 0.0550 - LR: 5.00e-05\n","\tEpoch 60/100 - Train loss: 0.0005 - Val accuracy: 0.9849 - Val loss: 0.0505 - LR: 4.00e-05\n","\tEpoch 70/100 - Train loss: 0.0006 - Val accuracy: 0.9858 - Val loss: 0.0512 - LR: 3.00e-05\n","\tEpoch 80/100 - Train loss: 0.0004 - Val accuracy: 0.9858 - Val loss: 0.0532 - LR: 2.00e-05\n","\tEpoch 90/100 - Train loss: 0.0008 - Val accuracy: 0.9868 - Val loss: 0.0499 - LR: 1.00e-05\n","\tEpoch 100/100 - Train loss: 0.0004 - Val accuracy: 0.9849 - Val loss: 0.0592 - LR: 0.00e+00\n","\tBest epoch: 21 - Best val accuracy: 0.9830 - Best val loss: 0.0362\n","\n","Domain: 10\n","x_syn_dom.shape: (726, 3, 128) | np.unique(y_syn_dom): [1 2 3]\n","x_dp_dom.shape: (612, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Fine-tuning on synthetic data...\n","\tEpoch 10/100 - Train loss: 0.0012 - Val accuracy: 1.0000 - Val loss: 0.0000 - LR: 9.00e-06\n","\tEpoch 20/100 - Train loss: 0.0007 - Val accuracy: 1.0000 - Val loss: 0.0000 - LR: 8.00e-06\n","\tEpoch 30/100 - Train loss: 0.0025 - Val accuracy: 1.0000 - Val loss: 0.0000 - LR: 7.00e-06\n","\tEpoch 40/100 - Train loss: 0.0038 - Val accuracy: 1.0000 - Val loss: 0.0000 - LR: 6.00e-06\n","\tEpoch 50/100 - Train loss: 0.0002 - Val accuracy: 1.0000 - Val loss: 0.0000 - LR: 5.00e-06\n","\tEpoch 60/100 - Train loss: 0.0005 - Val accuracy: 1.0000 - Val loss: 0.0000 - LR: 4.00e-06\n","\tEpoch 70/100 - Train loss: 0.0006 - Val accuracy: 1.0000 - Val loss: 0.0000 - LR: 3.00e-06\n","\tEpoch 80/100 - Train loss: 0.0018 - Val accuracy: 1.0000 - Val loss: 0.0000 - LR: 2.00e-06\n","\tEpoch 90/100 - Train loss: 0.0004 - Val accuracy: 1.0000 - Val loss: 0.0000 - LR: 1.00e-06\n","\tEpoch 100/100 - Train loss: 0.0042 - Val accuracy: 1.0000 - Val loss: 0.0000 - LR: 0.00e+00\n","\tBest epoch: 14 - Best val accuracy: 1.0000 - Best val loss: 0.0000\n","\n","Source class: WAL | Domain: 10 | Accuracy: 0.9886 | Loss: 0.0522\n","\n","Domain: 11\n","x_syn_dom.shape: (690, 3, 128) | np.unique(y_syn_dom): [1 2 3]\n","x_dp_dom.shape: (581, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Fine-tuning on synthetic data...\n","\tEpoch 10/100 - Train loss: 0.0003 - Val accuracy: 1.0000 - Val loss: 0.0001 - LR: 9.00e-06\n","\tEpoch 20/100 - Train loss: 0.0002 - Val accuracy: 1.0000 - Val loss: 0.0001 - LR: 8.00e-06\n","\tEpoch 30/100 - Train loss: 0.0005 - Val accuracy: 1.0000 - Val loss: 0.0000 - LR: 7.00e-06\n","\tEpoch 40/100 - Train loss: 0.0001 - Val accuracy: 1.0000 - Val loss: 0.0000 - LR: 6.00e-06\n","\tEpoch 50/100 - Train loss: 0.0001 - Val accuracy: 1.0000 - Val loss: 0.0000 - LR: 5.00e-06\n","\tEpoch 60/100 - Train loss: 0.0001 - Val accuracy: 1.0000 - Val loss: 0.0001 - LR: 4.00e-06\n","\tEpoch 70/100 - Train loss: 0.0001 - Val accuracy: 1.0000 - Val loss: 0.0001 - LR: 3.00e-06\n","\tEpoch 80/100 - Train loss: 0.0000 - Val accuracy: 1.0000 - Val loss: 0.0001 - LR: 2.00e-06\n","\tEpoch 90/100 - Train loss: 0.0002 - Val accuracy: 1.0000 - Val loss: 0.0001 - LR: 1.00e-06\n","\tEpoch 100/100 - Train loss: 0.0001 - Val accuracy: 1.0000 - Val loss: 0.0001 - LR: 0.00e+00\n","\tBest epoch: 45 - Best val accuracy: 1.0000 - Best val loss: 0.0000\n","\n","Source class: WAL | Domain: 11 | Accuracy: 0.9845 | Loss: 0.0589\n","\n","Domain: 12\n","x_syn_dom.shape: (714, 3, 128) | np.unique(y_syn_dom): [1 2 3]\n","x_dp_dom.shape: (577, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Fine-tuning on synthetic data...\n","\tEpoch 10/100 - Train loss: 0.0020 - Val accuracy: 1.0000 - Val loss: 0.0000 - LR: 9.00e-06\n","\tEpoch 20/100 - Train loss: 0.0005 - Val accuracy: 1.0000 - Val loss: 0.0000 - LR: 8.00e-06\n","\tEpoch 30/100 - Train loss: 0.0038 - Val accuracy: 1.0000 - Val loss: 0.0000 - LR: 7.00e-06\n","\tEpoch 40/100 - Train loss: 0.0058 - Val accuracy: 1.0000 - Val loss: 0.0000 - LR: 6.00e-06\n","\tEpoch 50/100 - Train loss: 0.0010 - Val accuracy: 1.0000 - Val loss: 0.0000 - LR: 5.00e-06\n","\tEpoch 60/100 - Train loss: 0.0009 - Val accuracy: 1.0000 - Val loss: 0.0000 - LR: 4.00e-06\n","\tEpoch 70/100 - Train loss: 0.0012 - Val accuracy: 1.0000 - Val loss: 0.0000 - LR: 3.00e-06\n","\tEpoch 80/100 - Train loss: 0.0008 - Val accuracy: 1.0000 - Val loss: 0.0000 - LR: 2.00e-06\n","\tEpoch 90/100 - Train loss: 0.0103 - Val accuracy: 1.0000 - Val loss: 0.0000 - LR: 1.00e-06\n","\tEpoch 100/100 - Train loss: 0.0002 - Val accuracy: 1.0000 - Val loss: 0.0000 - LR: 0.00e+00\n","\tBest epoch: 12 - Best val accuracy: 1.0000 - Best val loss: 0.0000\n","\n","Source class: WAL | Domain: 12 | Accuracy: 0.9567 | Loss: 0.2398\n","\n","Domain: 13\n","x_syn_dom.shape: (732, 3, 128) | np.unique(y_syn_dom): [1 2 3]\n","x_dp_dom.shape: (319, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Fine-tuning on synthetic data...\n","\tEpoch 10/100 - Train loss: 0.0026 - Val accuracy: 1.0000 - Val loss: 0.0000 - LR: 9.00e-06\n","\tEpoch 20/100 - Train loss: 0.0019 - Val accuracy: 1.0000 - Val loss: 0.0000 - LR: 8.00e-06\n","\tEpoch 30/100 - Train loss: 0.0014 - Val accuracy: 1.0000 - Val loss: 0.0000 - LR: 7.00e-06\n","\tEpoch 40/100 - Train loss: 0.0037 - Val accuracy: 1.0000 - Val loss: 0.0000 - LR: 6.00e-06\n","\tEpoch 50/100 - Train loss: 0.0024 - Val accuracy: 1.0000 - Val loss: 0.0000 - LR: 5.00e-06\n","\tEpoch 60/100 - Train loss: 0.0012 - Val accuracy: 1.0000 - Val loss: 0.0000 - LR: 4.00e-06\n","\tEpoch 70/100 - Train loss: 0.0004 - Val accuracy: 1.0000 - Val loss: 0.0000 - LR: 3.00e-06\n","\tEpoch 80/100 - Train loss: 0.0052 - Val accuracy: 1.0000 - Val loss: 0.0000 - LR: 2.00e-06\n","\tEpoch 90/100 - Train loss: 0.0068 - Val accuracy: 1.0000 - Val loss: 0.0000 - LR: 1.00e-06\n","\tEpoch 100/100 - Train loss: 0.0028 - Val accuracy: 1.0000 - Val loss: 0.0000 - LR: 0.00e+00\n","\tBest epoch: 68 - Best val accuracy: 1.0000 - Best val loss: 0.0000\n","\n","Source class: WAL | Domain: 13 | Accuracy: 0.9624 | Loss: 0.1266\n","\n","Domain: 14\n","x_syn_dom.shape: (726, 3, 128) | np.unique(y_syn_dom): [1 2 3]\n","x_dp_dom.shape: (581, 3, 128) | np.unique(y_dp_dom): [1 2 3]\n","\n","Fine-tuning on synthetic data...\n","\tEpoch 10/100 - Train loss: 0.0036 - Val accuracy: 1.0000 - Val loss: 0.0001 - LR: 9.00e-06\n","\tEpoch 20/100 - Train loss: 0.0002 - Val accuracy: 1.0000 - Val loss: 0.0000 - LR: 8.00e-06\n","\tEpoch 30/100 - Train loss: 0.0011 - Val accuracy: 1.0000 - Val loss: 0.0002 - LR: 7.00e-06\n","\tEpoch 40/100 - Train loss: 0.0003 - Val accuracy: 1.0000 - Val loss: 0.0001 - LR: 6.00e-06\n","\tEpoch 50/100 - Train loss: 0.0002 - Val accuracy: 1.0000 - Val loss: 0.0000 - LR: 5.00e-06\n","\tEpoch 60/100 - Train loss: 0.0002 - Val accuracy: 1.0000 - Val loss: 0.0001 - LR: 4.00e-06\n","\tEpoch 70/100 - Train loss: 0.0004 - Val accuracy: 1.0000 - Val loss: 0.0000 - LR: 3.00e-06\n","\tEpoch 80/100 - Train loss: 0.0016 - Val accuracy: 1.0000 - Val loss: 0.0000 - LR: 2.00e-06\n","\tEpoch 90/100 - Train loss: 0.0040 - Val accuracy: 1.0000 - Val loss: 0.0000 - LR: 1.00e-06\n","\tEpoch 100/100 - Train loss: 0.0001 - Val accuracy: 1.0000 - Val loss: 0.0000 - LR: 0.00e+00\n","\tBest epoch: 90 - Best val accuracy: 1.0000 - Best val loss: 0.0000\n","\n","Source class: WAL | Domain: 14 | Accuracy: 0.9656 | Loss: 0.1334\n","\n","Mean accuracy: 0.9715\n","\n"]}],"source":["def compute_TSTR_Df_Syn(dataset):\n","    accs = []\n","\n","    for src_class in config[dataset]['class_names']:\n","        if src_class != 'WAL':\n","            continue\n","\n","        print(f\"Source class: {src_class}\\n\")\n","\n","        # Load Df data\n","        x_df, y_df, k_df = get_data(dataset, 'df', src_class)\n","        print(f'x_df.shape: {x_df.shape} | np.unique(y_df): {np.unique(y_df)}\\n')\n","\n","        # Train on Df data\n","        print('Training on Df data...')\n","        df_model = train_only(x_df, y_df, dataset, num_epochs=100)\n","\n","        for domain in range(config[dataset]['num_df_domains'], config[dataset]['num_df_domains'] + config[dataset]['num_dp_domains']):\n","            print(f\"Domain: {domain}\")\n","\n","            # Load synthetic data\n","            x_syn_dom, y_syn_dom, k_syn_dom = get_syn_data(dataset, syn_name, src_class, domain)\n","            print(f'x_syn_dom.shape: {x_syn_dom.shape} | np.unique(y_syn_dom): {np.unique(y_syn_dom)}')\n","\n","            # Load Dp data\n","            x_dp_dom, y_dp_dom, k_dp_dom = get_data(dataset, 'dp', src_class, domain)\n","            print(f'x_dp_dom.shape: {x_dp_dom.shape} | np.unique(y_dp_dom): {np.unique(y_dp_dom)}\\n')\n","\n","            # Fine-tune Df model on synthetic data and evaluate on Dp data\n","            print('Fine-tuning on synthetic data...')\n","            df_syn_model = fine_tune(copy.deepcopy(df_model), x_syn_dom, y_syn_dom, num_epochs=100)\n","            acc, loss = evaluate_model(df_syn_model, get_dataloader(x_dp_dom, y_dp_dom))\n","            save_scores(src_class, domain, acc, loss, 'Df_Syn', dataset)\n","            accs.append(acc)\n","            print(f'Source class: {src_class} | Domain: {domain} | Accuracy: {acc:.4f} | Loss: {loss:.4f}\\n')\n","\n","    print(f\"Mean accuracy: {np.mean(accs):.4f}\\n\")\n","\n","\n","\n","\n","compute_TSTR_Df_Syn('realworld')"]},{"cell_type":"markdown","metadata":{"id":"fLSuTddOmD5c"},"source":["# TSTRFS"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"wZqvTTwNCPto"},"outputs":[],"source":["def compute_TSTRFS_Dpfs(dataset):\n","    accs = []\n","\n","    for src_class in config[dataset]['class_names']:\n","        if dataset == 'realworld_mobiact' and src_class != 'WAL':\n","            continue\n","\n","        print(f\"Source class: {src_class}\\n\")\n","\n","        for domain in range(config[dataset]['num_df_domains'], config[dataset]['num_df_domains'] + config[dataset]['num_dp_domains']):\n","            print(f\"Domain: {domain}\")\n","\n","            # Load Dpfs data\n","            x_dpfs_dom, y_dpfs_dom, k_dpfs_dom = get_data(dataset, 'dpfs', src_class, domain)\n","            print(f'x_dpfs_dom.shape: {x_dpfs_dom.shape} | np.unique(y_dpfs_dom): {np.unique(y_dpfs_dom)}')\n","\n","            # Load Dp data\n","            x_dp_dom, y_dp_dom, k_dp_dom = get_data(dataset, 'dp', src_class, domain)\n","            print(f'x_dp_dom.shape: {x_dp_dom.shape} | np.unique(y_dp_dom): {np.unique(y_dp_dom)}\\n')\n","\n","            # Train on Dpfs data and test on Dp data\n","            print('Training on Dpfs data...')\n","            acc, loss = train_and_test(x_dpfs_dom, y_dpfs_dom, x_dp_dom, y_dp_dom, dataset, num_epochs=100)\n","            save_scores(src_class, domain, 'real', acc, loss, 'FS_Dpfs', dataset)\n","            accs.append(acc)\n","            print(f'Source class: {src_class} | Domain: {domain} | Accuracy: {acc:.4f} | Loss: {loss:.4f}\\n')\n","\n","    print(f\"Mean accuracy: {np.mean(accs):.4f}\\n\")\n","\n","\n","\n","compute_TSTRFS_Dpfs('realworld')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"YOqZB6ARCPtp"},"outputs":[],"source":["def compute_TSTRFS_Df_Dpfs(dataset):\n","    accs = []\n","\n","    for src_class in config[dataset]['class_names']:\n","        if dataset == 'realworld_mobiact' and src_class != 'WAL':\n","            continue\n","\n","        print(f\"Source class: {src_class}\\n\")\n","\n","        # Load Df data\n","        x_df, y_df, k_df = get_data(dataset, 'df', src_class)\n","        print(f'x_df.shape: {x_df.shape} | np.unique(y_df): {np.unique(y_df)}\\n')\n","\n","        # Train on Df data\n","        print('Training on Df data...')\n","        df_model = train_only(x_df, y_df, dataset, num_epochs=100)\n","\n","        for domain in range(config[dataset]['num_df_domains'], config[dataset]['num_df_domains'] + config[dataset]['num_dp_domains']):\n","            print(f\"Domain: {domain}\")\n","\n","            # Load Dpfs data\n","            x_dpfs_dom, y_dpfs_dom, k_dpfs_dom = get_data(dataset, 'dpfs', src_class, domain)\n","            print(f'x_dpfs_dom.shape: {x_dpfs_dom.shape} | np.unique(y_dpfs_dom): {np.unique(y_dpfs_dom)}')\n","\n","            # Load Dp data\n","            x_dp_dom, y_dp_dom, k_dp_dom = get_data(dataset, 'dp', src_class, domain)\n","            print(f'x_dp_dom.shape: {x_dp_dom.shape} | np.unique(y_dp_dom): {np.unique(y_dp_dom)}\\n')\n","\n","            # Fine-tune Df model on Dpfs data and test on Dp data\n","            print('Fine-tuning on Dpfs data...')\n","            df_dpfs_model = fine_tune(copy.deepcopy(df_model), x_dpfs_dom, y_dpfs_dom, num_epochs=100)\n","            acc, loss = evaluate_model(df_dpfs_model, get_dataloader(x_dp_dom, y_dp_dom))\n","            save_scores(src_class, domain, 'real', acc, loss, 'FS_Df_Dpfs', dataset)\n","            accs.append(acc)\n","            print(f'Source class: {src_class} | Domain: {domain} | Accuracy: {acc:.4f} | Loss: {loss:.4f}\\n')\n","\n","    print(f\"Mean accuracy: {np.mean(accs):.4f}\\n\")\n","\n","\n","\n","compute_TSTRFS_Df_Dpfs('realworld')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"oA89psVZg5yb"},"outputs":[],"source":["def compute_TSTRFS_Syn(dataset):\n","    accs = []\n","\n","    for src_class in config[dataset]['class_names']:\n","        if dataset == 'realworld_mobiact' and src_class != 'WAL':\n","            continue\n","\n","        print(f\"Source class: {src_class}\\n\")\n","\n","        for domain in range(config[dataset]['num_df_domains'], config[dataset]['num_df_domains'] + config[dataset]['num_dp_domains']):\n","            print(f\"Domain: {domain}\")\n","\n","            # Load latent synthetic data\n","            x_syn_dom_lat, y_syn_dom_lat, k_syn_dom_lat = get_syn_data(dataset, src_class, domain, mode='lat', fs=True)\n","            print(f'x_syn_dom_lat.shape: {x_syn_dom_lat.shape} | np.unique(y_syn_dom_lat): {np.unique(y_syn_dom_lat)}')\n","\n","            # Load reference synthetic data\n","            x_syn_dom_ref, y_syn_dom_ref, k_syn_dom_ref = get_syn_data(dataset, src_class, domain, mode='ref', fs=True)\n","            print(f'x_syn_dom_ref.shape: {x_syn_dom_ref.shape} | np.unique(y_syn_dom_ref): {np.unique(y_syn_dom_ref)}')\n","\n","            # Join latent and reference synthetic data\n","            x_syn_dom_joint = np.concatenate([x_syn_dom_lat, x_syn_dom_ref], axis=0)\n","            y_syn_dom_joint = np.concatenate([y_syn_dom_lat, y_syn_dom_ref], axis=0)\n","            k_syn_dom_joint = np.concatenate([k_syn_dom_lat, k_syn_dom_ref], axis=0)\n","            print(f'x_syn_dom_joint.shape: {x_syn_dom_joint.shape} | np.unique(y_syn_dom_joint): {np.unique(y_syn_dom_joint)}')\n","\n","            # Load Dp data\n","            x_dp_dom, y_dp_dom, k_dp_dom = get_data(dataset, 'dp', src_class, domain)\n","            print(f'x_dp_dom.shape: {x_dp_dom.shape} | np.unique(y_dp_dom): {np.unique(y_dp_dom)}\\n')\n","\n","            # Train on latent synthetic data and evaluate on Dp data\n","            print('Training on latent synthetic data...')\n","            acc_lat, loss_lat = train_and_test(x_syn_dom_lat, y_syn_dom_lat, x_dp_dom, y_dp_dom, dataset, num_epochs=100)\n","            save_scores(src_class, domain, 'lat', acc_lat, loss_lat, 'FS_Syn', dataset)\n","            accs.append(acc_lat)\n","            print(f'Source class: {src_class} | Domain: {domain} | Accuracy (Latent): {acc_lat:.4f} | Loss: {loss_lat:.4f}\\n')\n","\n","            # Train on reference synthetic data and evaluate on Dp data\n","            print('Training on reference synthetic data...')\n","            acc_ref, loss_ref = train_and_test(x_syn_dom_ref, y_syn_dom_ref, x_dp_dom, y_dp_dom, dataset, num_epochs=100)\n","            save_scores(src_class, domain, 'ref', acc_ref, loss_ref, 'FS_Syn', dataset)\n","            accs.append(acc_ref)\n","            print(f'Source class: {src_class} | Domain: {domain} | Accuracy (Reference): {acc_ref:.4f} | Loss: {loss_ref:.4f}\\n')\n","\n","            # Train on joint synthetic data and evaluate on Dp data\n","            print('Training on joint synthetic data...')\n","            acc_joint, loss_joint = train_and_test(x_syn_dom_joint, y_syn_dom_joint, x_dp_dom, y_dp_dom, dataset, num_epochs=100)\n","            save_scores(src_class, domain, 'joint', acc_joint, loss_joint, 'FS_Syn', dataset)\n","            accs.append(acc_joint)\n","            print(f'Source class: {src_class} | Domain: {domain} | Accuracy (Joint): {acc_joint:.4f} | Loss: {loss_joint:.4f}\\n')\n","\n","    print(f\"Mean accuracy: {np.mean(accs):.4f}\\n\")\n","\n","\n","\n","\n","# compute_TSTRFS_Syn('realworld')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"38LHCQjRCPtp"},"outputs":[],"source":["def compute_TSTRFS_Df_Syn(dataset):\n","    accs = []\n","\n","    for src_class in config[dataset]['class_names']:\n","        if dataset == 'realworld_mobiact' and src_class != 'WAL':\n","            continue\n","\n","        print(f\"Source class: {src_class}\\n\")\n","\n","        # Load Df data\n","        x_df, y_df, k_df = get_data(dataset, 'df', src_class)\n","        print(f'x_df.shape: {x_df.shape} | np.unique(y_df): {np.unique(y_df)}\\n')\n","\n","        # Train on Df data\n","        print('Training on Df data...')\n","        df_model = train_only(x_df, y_df, dataset, num_epochs=100)\n","\n","        for domain in range(config[dataset]['num_df_domains'], config[dataset]['num_df_domains'] + config[dataset]['num_dp_domains']):\n","            print(f\"Domain: {domain}\")\n","\n","            # Load latent synthetic data\n","            x_syn_dom_lat, y_syn_dom_lat, k_syn_dom_lat = get_syn_data(dataset, src_class, domain, mode='lat', fs=True)\n","            print(f'x_syn_dom_lat.shape: {x_syn_dom_lat.shape} | np.unique(y_syn_dom_lat): {np.unique(y_syn_dom_lat)}')\n","\n","            # Load reference synthetic data\n","            x_syn_dom_ref, y_syn_dom_ref, k_syn_dom_ref = get_syn_data(dataset, src_class, domain, mode='ref', fs=True)\n","            print(f'x_syn_dom_ref.shape: {x_syn_dom_ref.shape} | np.unique(y_syn_dom_ref): {np.unique(y_syn_dom_ref)}')\n","\n","            # Join latent and reference synthetic data\n","            x_syn_dom_joint = np.concatenate([x_syn_dom_lat, x_syn_dom_ref], axis=0)\n","            y_syn_dom_joint = np.concatenate([y_syn_dom_lat, y_syn_dom_ref], axis=0)\n","            k_syn_dom_joint = np.concatenate([k_syn_dom_lat, k_syn_dom_ref], axis=0)\n","            print(f'x_syn_dom_joint.shape: {x_syn_dom_joint.shape} | np.unique(y_syn_dom_joint): {np.unique(y_syn_dom_joint)}')\n","\n","            # Load Dp data\n","            x_dp_dom, y_dp_dom, k_dp_dom = get_data(dataset, 'dp', src_class, domain)\n","            print(f'x_dp_dom.shape: {x_dp_dom.shape} | np.unique(y_dp_dom): {np.unique(y_dp_dom)}\\n')\n","\n","            # Fine-tune Df model on latent synthetic data and evaluate on Dp data\n","            print('Fine-tuning on latent synthetic data...')\n","            df_lat_model = fine_tune(copy.deepcopy(df_model), x_syn_dom_lat, y_syn_dom_lat, num_epochs=100)\n","            acc_lat, loss_lat = evaluate_model(df_lat_model, get_dataloader(x_dp_dom, y_dp_dom))\n","            save_scores(src_class, domain, 'lat', acc_lat, loss_lat, 'FS_Df_Syn', dataset)\n","            accs.append(acc_lat)\n","            print(f'Source class: {src_class} | Domain: {domain} | Accuracy (Latent): {acc_lat:.4f} | Loss: {loss_lat:.4f}\\n')\n","\n","            # Fine-tune Df model on reference synthetic data and evaluate on Dp data\n","            print('Fine-tuning on reference synthetic data...')\n","            df_ref_model = fine_tune(copy.deepcopy(df_model), x_syn_dom_ref, y_syn_dom_ref, num_epochs=100)\n","            acc_ref, loss_ref = evaluate_model(df_ref_model, get_dataloader(x_dp_dom, y_dp_dom))\n","            save_scores(src_class, domain, 'ref', acc_ref, loss_ref, 'FS_Df_Syn', dataset)\n","            accs.append(acc_ref)\n","            print(f'Source class: {src_class} | Domain: {domain} | Accuracy (Reference): {acc_ref:.4f} | Loss: {loss_ref:.4f}\\n')\n","\n","            # Fine-tune Df model on joint synthetic data and evaluate on Dp data\n","            print('Fine-tuning on joint synthetic data...')\n","            df_joint_model = fine_tune(copy.deepcopy(df_model), x_syn_dom_joint, y_syn_dom_joint, num_epochs=100)\n","            acc_joint, loss_joint = evaluate_model(df_joint_model, get_dataloader(x_dp_dom, y_dp_dom))\n","            save_scores(src_class, domain, 'joint', acc_joint, loss_joint, 'FS_Df_Syn', dataset)\n","            accs.append(acc_joint)\n","\n","    print(f\"Mean accuracy: {np.mean(accs):.4f}\\n\")\n","\n","\n","\n","\n","# compute_TSTRFS_Df_Syn('realworld')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ueNEmwhVCPtp"},"outputs":[],"source":["def compute_TSTRFS_Syn_Dpfs(dataset):\n","    accs = []\n","\n","    for src_class in config[dataset]['class_names']:\n","        if dataset == 'realworld_mobiact' and src_class != 'WAL':\n","            continue\n","\n","        print(f\"Source class: {src_class}\\n\")\n","\n","        for domain in range(config[dataset]['num_df_domains'], config[dataset]['num_df_domains'] + config[dataset]['num_dp_domains']):\n","            print(f\"Domain: {domain}\")\n","\n","            # Load latent synthetic data\n","            x_syn_dom_lat, y_syn_dom_lat, k_syn_dom_lat = get_syn_data(dataset, src_class, domain, mode='lat', fs=True)\n","            print(f'x_syn_dom_lat.shape: {x_syn_dom_lat.shape} | np.unique(y_syn_dom_lat): {np.unique(y_syn_dom_lat)}')\n","\n","            # Load reference synthetic data\n","            x_syn_dom_ref, y_syn_dom_ref, k_syn_dom_ref = get_syn_data(dataset, src_class, domain, mode='ref', fs=True)\n","            print(f'x_syn_dom_ref.shape: {x_syn_dom_ref.shape} | np.unique(y_syn_dom_ref): {np.unique(y_syn_dom_ref)}')\n","\n","            # Join latent and reference synthetic data\n","            x_syn_dom_joint = np.concatenate([x_syn_dom_lat, x_syn_dom_ref], axis=0)\n","            y_syn_dom_joint = np.concatenate([y_syn_dom_lat, y_syn_dom_ref], axis=0)\n","            k_syn_dom_joint = np.concatenate([k_syn_dom_lat, k_syn_dom_ref], axis=0)\n","            print(f'x_syn_dom_joint.shape: {x_syn_dom_joint.shape} | np.unique(y_syn_dom_joint): {np.unique(y_syn_dom_joint)}')\n","\n","            # Load Dpfs data\n","            x_dpfs_dom, y_dpfs_dom, k_dpfs_dom = get_data(dataset, 'dpfs', src_class, domain)\n","            print(f'x_dpfs_dom.shape: {x_dpfs_dom.shape} | np.unique(y_dpfs_dom): {np.unique(y_dpfs_dom)}')\n","\n","            # Load Dp data\n","            x_dp_dom, y_dp_dom, k_dp_dom = get_data(dataset, 'dp', src_class, domain)\n","            print(f'x_dp_dom.shape: {x_dp_dom.shape} | np.unique(y_dp_dom): {np.unique(y_dp_dom)}\\n')\n","\n","            # Train on latent synthetic data\n","            print('Training on latent synthetic data...')\n","            lat_model = train_only(x_syn_dom_lat, y_syn_dom_lat, dataset, num_epochs=100)\n","\n","            # Fine-tune latent model on Dpfs data and evaluate on Dp data\n","            print('Fine-tuning on Dpfs data...')\n","            lat_dpfs_model = fine_tune(copy.deepcopy(lat_model), x_dpfs_dom, y_dpfs_dom, num_epochs=100)\n","            acc_lat, loss_lat = evaluate_model(lat_dpfs_model, get_dataloader(x_dp_dom, y_dp_dom))\n","            save_scores(src_class, domain, 'lat', acc_lat, loss_lat, 'FS_Syn_Dpfs', dataset)\n","            accs.append(acc_lat)\n","            print(f'Source class: {src_class} | Domain: {domain} | Accuracy (Latent): {acc_lat:.4f} | Loss: {loss_lat:.4f}\\n')\n","\n","            # Train on reference synthetic data\n","            print('Training on reference synthetic data...')\n","            ref_model = train_only(x_syn_dom_ref, y_syn_dom_ref, dataset, num_epochs=100)\n","\n","            # Fine-tune reference model on Dpfs data and evaluate on Dp data\n","            print('Fine-tuning on Dpfs data...')\n","            ref_dpfs_model = fine_tune(copy.deepcopy(ref_model), x_dpfs_dom, y_dpfs_dom, num_epochs=100)\n","            acc_ref, loss_ref = evaluate_model(ref_dpfs_model, get_dataloader(x_dp_dom, y_dp_dom))\n","            save_scores(src_class, domain, 'ref', acc_ref, loss_ref, 'FS_Syn_Dpfs', dataset)\n","            accs.append(acc_ref)\n","            print(f'Source class: {src_class} | Domain: {domain} | Accuracy (Reference): {acc_ref:.4f} | Loss: {loss_ref:.4f}\\n')\n","\n","            # Train on joint synthetic data\n","            print('Training on joint synthetic data...')\n","            joint_model = train_only(x_syn_dom_joint, y_syn_dom_joint, dataset, num_epochs=100)\n","\n","            # Fine-tune joint model on Dpfs data and evaluate on Dp data\n","            print('Fine-tuning on Dpfs data...')\n","            joint_dpfs_model = fine_tune(copy.deepcopy(joint_model), x_dpfs_dom, y_dpfs_dom, num_epochs=100)\n","            acc_joint, loss_joint = evaluate_model(joint_dpfs_model, get_dataloader(x_dp_dom, y_dp_dom))\n","            save_scores(src_class, domain, 'joint', acc_joint, loss_joint, 'FS_Syn_Dpfs', dataset)\n","            accs.append(acc_joint)\n","            print(f'Source class: {src_class} | Domain: {domain} | Accuracy (Joint): {acc_joint:.4f} | Loss: {loss_joint:.4f}\\n')\n","\n","    print(f\"Mean accuracy: {np.mean(accs):.4f}\\n\")\n","\n","\n","\n","\n","# compute_TSTRFS_Syn_Dpfs('realworld')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"7z0xuuhhCPtp"},"outputs":[],"source":["def compute_TSTRFS_Df_Syn_Dpfs(dataset):\n","    accs = []\n","\n","    for src_class in config[dataset]['class_names']:\n","        if dataset == 'realworld_mobiact' and src_class != 'WAL':\n","            continue\n","\n","        print(f\"Source class: {src_class}\\n\")\n","\n","        # Load Df data\n","        x_df, y_df, k_df = get_data(dataset, 'df', src_class)\n","        print(f'x_df.shape: {x_df.shape} | np.unique(y_df): {np.unique(y_df)}\\n')\n","\n","        # Train on Df data\n","        print('Training on Df data...')\n","        df_model = train_only(x_df, y_df, dataset, num_epochs=100)\n","\n","        for domain in range(config[dataset]['num_df_domains'], config[dataset]['num_df_domains'] + config[dataset]['num_dp_domains']):\n","            print(f\"Domain: {domain}\")\n","\n","            # Load latent synthetic data\n","            x_syn_dom_lat, y_syn_dom_lat, k_syn_dom_lat = get_syn_data(dataset, src_class, domain, mode='lat', fs=True)\n","            print(f'x_syn_dom_lat.shape: {x_syn_dom_lat.shape} | np.unique(y_syn_dom_lat): {np.unique(y_syn_dom_lat)}')\n","\n","            # Load reference synthetic data\n","            x_syn_dom_ref, y_syn_dom_ref, k_syn_dom_ref = get_syn_data(dataset, src_class, domain, mode='ref', fs=True)\n","            print(f'x_syn_dom_ref.shape: {x_syn_dom_ref.shape} | np.unique(y_syn_dom_ref): {np.unique(y_syn_dom_ref)}')\n","\n","            # Join latent and reference synthetic data\n","            x_syn_dom_joint = np.concatenate([x_syn_dom_lat, x_syn_dom_ref], axis=0)\n","            y_syn_dom_joint = np.concatenate([y_syn_dom_lat, y_syn_dom_ref], axis=0)\n","            k_syn_dom_joint = np.concatenate([k_syn_dom_lat, k_syn_dom_ref], axis=0)\n","            print(f'x_syn_dom_joint.shape: {x_syn_dom_joint.shape} | np.unique(y_syn_dom_joint): {np.unique(y_syn_dom_joint)}')\n","\n","            # Load Dpfs data\n","            x_dpfs_dom, y_dpfs_dom, k_dpfs_dom = get_data(dataset, 'dpfs', src_class, domain)\n","            print(f'x_dpfs_dom.shape: {x_dpfs_dom.shape} | np.unique(y_dpfs_dom): {np.unique(y_dpfs_dom)}')\n","\n","            # Load Dp data\n","            x_dp_dom, y_dp_dom, k_dp_dom = get_data(dataset, 'dp', src_class, domain)\n","            print(f'x_dp_dom.shape: {x_dp_dom.shape} | np.unique(y_dp_dom): {np.unique(y_dp_dom)}\\n')\n","\n","            # Fine-tune Df model on latent synthetic data\n","            print('Fine-tuning on latent synthetic data...')\n","            df_lat_model = fine_tune(copy.deepcopy(df_model), x_syn_dom_lat, y_syn_dom_lat, num_epochs=100)\n","\n","            # Fine-tune Df-latent model on Dpfs data and evaluate on Dp data\n","            print('Fine-tuning on Dpfs data...')\n","            df_lat_dpfs_model = fine_tune(copy.deepcopy(df_lat_model), x_dpfs_dom, y_dpfs_dom, num_epochs=100)\n","            acc_lat, loss_lat = evaluate_model(df_lat_dpfs_model, get_dataloader(x_dp_dom, y_dp_dom))\n","            save_scores(src_class, domain, 'lat', acc_lat, loss_lat, 'FS_Df_Syn_Dpfs', dataset)\n","            accs.append(acc_lat)\n","            print(f'Source class: {src_class} | Domain: {domain} | Accuracy (Latent): {acc_lat:.4f} | Loss: {loss_lat:.4f}\\n')\n","\n","            # Fine-tune Df model on reference synthetic data\n","            print('Fine-tuning on reference synthetic data...')\n","            df_ref_model = fine_tune(copy.deepcopy(df_model), x_syn_dom_ref, y_syn_dom_ref, num_epochs=100)\n","\n","            # Fine-tune Df-reference model on Dpfs data and evaluate on Dp data\n","            print('Fine-tuning on Dpfs data...')\n","            df_ref_dpfs_model = fine_tune(copy.deepcopy(df_ref_model), x_dpfs_dom, y_dpfs_dom, num_epochs=100)\n","            acc_ref, loss_ref = evaluate_model(df_ref_dpfs_model, get_dataloader(x_dp_dom, y_dp_dom))\n","            save_scores(src_class, domain, 'ref', acc_ref, loss_ref, 'FS_Df_Syn_Dpfs', dataset)\n","            accs.append(acc_ref)\n","            print(f'Source class: {src_class} | Domain: {domain} | Accuracy (Reference): {acc_ref:.4f} | Loss: {loss_ref:.4f}\\n')\n","\n","            # Fine-tune Df model on joint synthetic data\n","            print('Fine-tuning on joint synthetic data...')\n","            df_joint_model = fine_tune(copy.deepcopy(df_model), x_syn_dom_joint, y_syn_dom_joint, num_epochs=100)\n","\n","            # Fine-tune Df-joint model on Dpfs data and evaluate on Dp data\n","            print('Fine-tuning on Dpfs data...')\n","            df_joint_dpfs_model = fine_tune(copy.deepcopy(df_joint_model), x_dpfs_dom, y_dpfs_dom, num_epochs=100)\n","            acc_joint, loss_joint = evaluate_model(df_joint_dpfs_model, get_dataloader(x_dp_dom, y_dp_dom))\n","            save_scores(src_class, domain, 'joint', acc_joint, loss_joint, 'FS_Df_Syn_Dpfs', dataset)\n","            accs.append(acc_joint)\n","            print(f'Source class: {src_class} | Domain: {domain} | Accuracy (Joint): {acc_joint:.4f} | Loss: {loss_joint:.4f}\\n')\n","\n","    print(f\"Mean accuracy: {np.mean(accs):.4f}\\n\")\n","\n","\n","\n","\n","# compute_TSTRFS_Df_Syn_Dpfs('realworld')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"zpB3ecNGmD5f"},"outputs":[],"source":["def compute_TSTRFS_Df_plus_Dpfs(dataset):\n","    accs = []\n","\n","    for src_class in config[dataset]['class_names']:\n","        if dataset == 'realworld_mobiact' and src_class != 'WAL':\n","            continue\n","\n","        print(f\"Source class: {src_class}\\n\")\n","\n","        # Load Df data\n","        x_df, y_df, k_df = get_data(dataset, 'df', src_class)\n","        print(f'x_df.shape: {x_df.shape} | np.unique(y_df): {np.unique(y_df)}\\n')\n","\n","        for domain in range(config[dataset]['num_df_domains'], config[dataset]['num_df_domains'] + config[dataset]['num_dp_domains']):\n","            print(f\"Domain: {domain}\")\n","\n","            # Load Dpfs data\n","            x_dpfs_dom, y_dpfs_dom, k_dpfs_dom = get_data(dataset, 'dpfs', src_class, domain)\n","            print(f'x_dpfs_dom.shape: {x_dpfs_dom.shape} | np.unique(y_dpfs_dom): {np.unique(y_dpfs_dom)}')\n","\n","            # Join Df and Dpfs data\n","            x_df_dpfs = np.concatenate([x_df, x_dpfs_dom], axis=0)\n","            y_df_dpfs = np.concatenate([y_df, y_dpfs_dom], axis=0)\n","            k_df_dpfs = np.concatenate([k_df, k_dpfs_dom], axis=0)\n","            print(f'x_df_dpfs.shape: {x_df_dpfs.shape} | np.unique(y_df_dpfs): {np.unique(y_df_dpfs)}')\n","\n","            # Load Dp data\n","            x_dp_dom, y_dp_dom, k_dp_dom = get_data(dataset, 'dp', src_class, domain)\n","            print(f'x_dp_dom.shape: {x_dp_dom.shape} | np.unique(y_dp_dom): {np.unique(y_dp_dom)}\\n')\n","\n","            # Train on Df plus Dpfs data and test on Dp data\n","            print('Training on Df plus Dpfs data...')\n","            acc, loss = train_and_test(x_df_dpfs, y_df_dpfs, x_dp_dom, y_dp_dom, dataset, num_epochs=100)\n","            save_scores(src_class, domain, 'real', acc, loss, 'FS_Df_plus_Dpfs', dataset)\n","            accs.append(acc)\n","            print(f'Source class: {src_class} | Domain: {domain} | Accuracy: {acc:.4f} | Loss: {loss:.4f}\\n')\n","\n","    print(f\"Mean accuracy: {np.mean(accs):.4f}\\n\")\n","\n","\n","\n","compute_TSTRFS_Df_plus_Dpfs('realworld')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"RYl0a9ZJmD5f"},"outputs":[],"source":["def compute_TSTRFS_Df_plus_Syn(dataset):\n","    accs = []\n","\n","    for src_class in config[dataset]['class_names']:\n","        if dataset == 'realworld_mobiact' and src_class != 'WAL':\n","            continue\n","\n","        print(f\"Source class: {src_class}\\n\")\n","\n","        # Load Df data\n","        x_df, y_df, k_df = get_data(dataset, 'df', src_class)\n","        print(f'x_df.shape: {x_df.shape} | np.unique(y_df): {np.unique(y_df)}\\n')\n","\n","        for domain in range(config[dataset]['num_df_domains'], config[dataset]['num_df_domains'] + config[dataset]['num_dp_domains']):\n","            print(f\"Domain: {domain}\")\n","\n","            # Load latent synthetic data\n","            x_syn_dom_lat, y_syn_dom_lat, k_syn_dom_lat = get_syn_data(dataset, src_class, domain, mode='lat', fs=True)\n","            print(f'x_syn_dom_lat.shape: {x_syn_dom_lat.shape} | np.unique(y_syn_dom_lat): {np.unique(y_syn_dom_lat)}')\n","\n","            # Join Df and latent synthetic data\n","            x_df_lat = np.concatenate([x_df, x_syn_dom_lat], axis=0)\n","            y_df_lat = np.concatenate([y_df, y_syn_dom_lat], axis=0)\n","            k_df_lat = np.concatenate([k_df, k_syn_dom_lat], axis=0)\n","            print(f'x_df_lat.shape: {x_df_lat.shape} | np.unique(y_df_lat): {np.unique(y_df_lat)}')\n","\n","            # Load reference synthetic data\n","            x_syn_dom_ref, y_syn_dom_ref, k_syn_dom_ref = get_syn_data(dataset, src_class, domain, mode='ref', fs=True)\n","            print(f'x_syn_dom_ref.shape: {x_syn_dom_ref.shape} | np.unique(y_syn_dom_ref): {np.unique(y_syn_dom_ref)}')\n","\n","            # Join Df and reference synthetic data\n","            x_df_ref = np.concatenate([x_df, x_syn_dom_ref], axis=0)\n","            y_df_ref = np.concatenate([y_df, y_syn_dom_ref], axis=0)\n","            k_df_ref = np.concatenate([k_df, k_syn_dom_ref], axis=0)\n","            print(f'x_df_ref.shape: {x_df_ref.shape} | np.unique(y_df_ref): {np.unique(y_df_ref)}')\n","\n","            # Join latent and reference synthetic data\n","            x_syn_dom_joint = np.concatenate([x_syn_dom_lat, x_syn_dom_ref], axis=0)\n","            y_syn_dom_joint = np.concatenate([y_syn_dom_lat, y_syn_dom_ref], axis=0)\n","            k_syn_dom_joint = np.concatenate([k_syn_dom_lat, k_syn_dom_ref], axis=0)\n","            print(f'x_syn_dom_joint.shape: {x_syn_dom_joint.shape} | np.unique(y_syn_dom_joint): {np.unique(y_syn_dom_joint)}')\n","\n","            # Join Df and joint synthetic data\n","            x_df_joint = np.concatenate([x_df, x_syn_dom_joint], axis=0)\n","            y_df_joint = np.concatenate([y_df, y_syn_dom_joint], axis=0)\n","            k_df_joint = np.concatenate([k_df, k_syn_dom_joint], axis=0)\n","            print(f'x_df_joint.shape: {x_df_joint.shape} | np.unique(y_df_joint): {np.unique(y_df_joint)}')\n","\n","            # Load Dp data\n","            x_dp_dom, y_dp_dom, k_dp_dom = get_data(dataset, 'dp', src_class, domain)\n","            print(f'x_dp_dom.shape: {x_dp_dom.shape} | np.unique(y_dp_dom): {np.unique(y_dp_dom)}\\n')\n","\n","            # Train on Df plus latent synthetic data and test on Dp data\n","            print('Training on Df plus latent synthetic data...')\n","            acc_lat, loss_lat = train_and_test(x_df_lat, y_df_lat, x_dp_dom, y_dp_dom, dataset, num_epochs=100)\n","            save_scores(src_class, domain, 'lat', acc_lat, loss_lat, 'FS_Df_plus_Syn', dataset)\n","            accs.append(acc_lat)\n","            print(f'Source class: {src_class} | Domain: {domain} | Accuracy (Latent): {acc_lat:.4f} | Loss: {loss_lat:.4f}\\n')\n","\n","            # Train on Df plus reference synthetic data and test on Dp data\n","            print('Training on Df plus reference synthetic data...')\n","            acc_ref, loss_ref = train_and_test(x_df_ref, y_df_ref, x_dp_dom, y_dp_dom, dataset, num_epochs=100)\n","            save_scores(src_class, domain, 'ref', acc_ref, loss_ref, 'FS_Df_plus_Syn', dataset)\n","            accs.append(acc_ref)\n","            print(f'Source class: {src_class} | Domain: {domain} | Accuracy (Reference): {acc_ref:.4f} | Loss: {loss_ref:.4f}\\n')\n","\n","            # Train on Df plus joint synthetic data and test on Dp data\n","            print('Training on Df plus joint synthetic data...')\n","            acc_joint, loss_joint = train_and_test(x_df_joint, y_df_joint, x_dp_dom, y_dp_dom, dataset, num_epochs=100)\n","            save_scores(src_class, domain, 'joint', acc_joint, loss_joint, 'FS_Df_plus_Syn', dataset)\n","            accs.append(acc_joint)\n","\n","    print(f\"Mean accuracy: {np.mean(accs):.4f}\\n\")\n","\n","\n","\n","\n","# compute_TSTRFS_Df_plus_Syn('realworld')"]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[]},"kernelspec":{"display_name":"stargan-v2","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.13"}},"nbformat":4,"nbformat_minor":0}